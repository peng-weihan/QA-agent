{"question": "What architectural pattern does the class defined in the third module use to resolve the circular dependency between the first module and the second module in the test package?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"name": "ModuleAnalyzer", "docstring": "", "methods": ["get_module_source", "for_string", "for_file", "for_module", "__init__", "analyze", "find_attr_docs", "find_tags"], "attributes": [], "code_location": {"file": "__init__.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/pycode", "start_line": 19, "end_line": 170}, "type": "class"}, {"name": "TestSkipMember", "docstring": "", "methods": ["assert_skip", "test_namedtuple", "test_class_private_doc", "test_class_private_undoc", "test_class_special_doc", "test_class_special_undoc", "test_class_decorated_doc", "test_exception_private_doc", "test_exception_private_undoc", "test_exception_special_doc", "test_exception_special_undoc", "test_module_private_doc", "test_module_private_undoc", "test_module_special_doc", "test_module_special_undoc"], "attributes": [], "code_location": {"file": "test_ext_napoleon.py", "path": "/data3/pwh/swebench-repos/sphinx/tests/test_extensions", "start_line": 143, "end_line": 292}, "type": "class"}, {"name": "ModuleEntry", "docstring": "", "methods": [], "attributes": [], "code_location": {"file": "__init__.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/domains/python", "start_line": 77, "end_line": 82}, "type": "class"}, {"name": "__get__", "is_method": true, "class_name": "_Descriptor", "parameters": ["self"], "calls": [], "code_location": {"file": "typed_vars.py", "path": "/data3/pwh/swebench-repos/sphinx/tests/roots/test-ext-autodoc/target", "start_line": 13, "end_line": 14}, "code_snippet": "    def __get__(self):  # NoQA: PLE0302\n        pass\n", "type": "function"}, {"name": "bar", "is_method": true, "class_name": "Foo", "parameters": ["self"], "calls": [], "code_location": {"file": "autosummary_dummy_module.py", "path": "/data3/pwh/swebench-repos/sphinx/tests/roots/test-ext-autosummary", "start_line": 33, "end_line": 34}, "code_snippet": "    def bar(self):\n        pass\n", "type": "function"}, {"name": "_unload_target_module", "is_method": false, "class_name": null, "parameters": [], "calls": ["pytest.fixture", "sys.modules.pop"], "code_location": {"file": "test_ext_autosummary.py", "path": "/data3/pwh/swebench-repos/sphinx/tests/test_extensions", "start_line": 45, "end_line": 46}, "code_snippet": "def _unload_target_module():\n    sys.modules.pop('target', None)\n", "type": "function"}, {"name": "bar", "is_method": true, "class_name": "Foo", "parameters": ["self"], "calls": [], "code_location": {"file": "autosummary_dummy_module.py", "path": "/data3/pwh/swebench-repos/sphinx/tests/roots/test-ext-autosummary-filename-map", "start_line": 14, "end_line": 15}, "code_snippet": "    def bar(self):\n        pass\n", "type": "function"}, {"name": "bar", "is_method": true, "class_name": "Foo", "parameters": ["self"], "calls": [], "code_location": {"file": "module.py", "path": "/data3/pwh/swebench-repos/sphinx/tests/roots/test-ext-autosummary-recursive/package2", "start_line": 8, "end_line": 9}, "code_snippet": "    def bar(self):\n        pass\n", "type": "function"}, {"name": "bar", "is_method": true, "class_name": "Foo", "parameters": ["self"], "calls": [], "code_location": {"file": "module.py", "path": "/data3/pwh/swebench-repos/sphinx/tests/roots/test-ext-autosummary-recursive/package/package", "start_line": 8, "end_line": 9}, "code_snippet": "    def bar(self):\n        pass\n", "type": "function"}, {"name": "bar", "is_method": true, "class_name": "Foo", "parameters": ["self"], "calls": [], "code_location": {"file": "module.py", "path": "/data3/pwh/swebench-repos/sphinx/tests/roots/test-ext-autosummary-recursive/package", "start_line": 8, "end_line": 9}, "code_snippet": "    def bar(self):\n        pass\n", "type": "function"}], "retrieved_count": 10, "cost_time": 1.0369980335235596}
{"question": "How does the equality comparison method in the class representing user-defined parenthesized attributes implement guard clauses to handle type mismatches before performing equality comparison?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"name": "__eq__", "is_method": true, "class_name": "ASTParenAttribute", "parameters": ["self", "other"], "calls": ["isinstance"], "code_location": {"file": "cfamily.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/util", "start_line": 230, "end_line": 233}, "code_snippet": "    def __eq__(self, other: object) -> bool:\n        if not isinstance(other, ASTParenAttribute):\n            return NotImplemented\n        return self.id == other.id and self.arg == other.arg\n", "type": "function"}, {"name": "paren_attributes", "is_method": true, "class_name": "BaseParser", "parameters": ["self"], "calls": [], "code_location": {"file": "cfamily.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/util", "start_line": 433, "end_line": 434}, "code_snippet": "    def paren_attributes(self) -> Sequence[str]:\n        raise NotImplementedError\n", "type": "function"}, {"name": "__eq__", "is_method": true, "class_name": "ASTParenExpr", "parameters": ["self", "other"], "calls": ["isinstance"], "code_location": {"file": "_ast.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/domains/cpp", "start_line": 663, "end_line": 666}, "code_snippet": "    def __eq__(self, other: object) -> bool:\n        if not isinstance(other, ASTParenExpr):\n            return NotImplemented\n        return self.expr == other.expr\n", "type": "function"}, {"name": "__eq__", "is_method": true, "class_name": "ASTParenExpr", "parameters": ["self", "other"], "calls": ["isinstance"], "code_location": {"file": "_ast.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/domains/c", "start_line": 363, "end_line": 366}, "code_snippet": "    def __eq__(self, other: object) -> bool:\n        if not isinstance(other, ASTParenExpr):\n            return NotImplemented\n        return self.expr == other.expr\n", "type": "function"}, {"name": "__eq__", "is_method": true, "class_name": "ASTAttributeList", "parameters": ["self", "other"], "calls": ["isinstance"], "code_location": {"file": "cfamily.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/util", "start_line": 249, "end_line": 252}, "code_snippet": "    def __eq__(self, other: object) -> bool:\n        if not isinstance(other, ASTAttributeList):\n            return NotImplemented\n        return self.attrs == other.attrs\n", "type": "function"}, {"name": "__eq__", "is_method": true, "class_name": "ASTParenExprList", "parameters": ["self", "other"], "calls": ["isinstance"], "code_location": {"file": "_ast.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/domains/cpp", "start_line": 3290, "end_line": 3293}, "code_snippet": "    def __eq__(self, other: object) -> bool:\n        if not isinstance(other, ASTParenExprList):\n            return NotImplemented\n        return self.exprs == other.exprs\n", "type": "function"}, {"name": "__eq__", "is_method": true, "class_name": "ASTParenExprList", "parameters": ["self", "other"], "calls": ["isinstance"], "code_location": {"file": "_ast.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/domains/c", "start_line": 1448, "end_line": 1451}, "code_snippet": "    def __eq__(self, other: object) -> bool:\n        if not isinstance(other, ASTParenExprList):\n            return NotImplemented\n        return self.exprs == other.exprs\n", "type": "function"}, {"name": "__eq__", "is_method": true, "class_name": "ASTGnuAttributeList", "parameters": ["self", "other"], "calls": ["isinstance"], "code_location": {"file": "cfamily.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/util", "start_line": 186, "end_line": 189}, "code_snippet": "    def __eq__(self, other: object) -> bool:\n        if not isinstance(other, ASTGnuAttributeList):\n            return NotImplemented\n        return self.attrs == other.attrs\n", "type": "function"}, {"name": "__eq__", "is_method": true, "class_name": "ASTUnion", "parameters": ["self", "other"], "calls": ["isinstance"], "code_location": {"file": "_ast.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/domains/cpp", "start_line": 3786, "end_line": 3789}, "code_snippet": "    def __eq__(self, other: object) -> bool:\n        if not isinstance(other, ASTUnion):\n            return NotImplemented\n        return self.name == other.name and self.attrs == other.attrs\n", "type": "function"}, {"name": "__eq__", "is_method": true, "class_name": "ASTGnuAttribute", "parameters": ["self", "other"], "calls": ["isinstance"], "code_location": {"file": "cfamily.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/util", "start_line": 168, "end_line": 171}, "code_snippet": "    def __eq__(self, other: object) -> bool:\n        if not isinstance(other, ASTGnuAttribute):\n            return NotImplemented\n        return self.name == other.name and self.args == other.args\n", "type": "function"}], "retrieved_count": 10, "cost_time": 1.025418996810913}
{"question": "What is the dependency relationship between the class that never matches any member for the exclude-members option and the base sentinel class that provides immutability and type union support?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"name": "_Empty", "docstring": "A special value for :exclude-members: that never matches to any member.", "methods": ["__contains__"], "attributes": [], "code_location": {"file": "_sentinels.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/ext/autodoc", "start_line": 52, "end_line": 56}, "type": "class"}, {"name": "_SunderMissingInNonEnumMixin", "docstring": "", "methods": ["_missing_"], "attributes": [], "code_location": {"file": "enums.py", "path": "/data3/pwh/swebench-repos/sphinx/tests/roots/test-ext-autodoc/target", "start_line": 163, "end_line": 167}, "type": "class"}, {"name": "_All", "docstring": "A special value for :*-members: that matches to any member.", "methods": ["__contains__", "append"], "attributes": [], "code_location": {"file": "_sentinels.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/ext/autodoc", "start_line": 42, "end_line": 49}, "type": "class"}, {"name": "_Sentinel", "docstring": "Create a unique sentinel object.", "methods": ["__new__", "__repr__", "__setattr__", "__or__", "__ror__", "__getstate__"], "attributes": ["__slots__"], "code_location": {"file": "_sentinels.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/ext/autodoc", "start_line": 8, "end_line": 39}, "type": "class"}, {"name": "_SunderMissingInEnumMixin", "docstring": "", "methods": ["_missing_"], "attributes": [], "code_location": {"file": "enums.py", "path": "/data3/pwh/swebench-repos/sphinx/tests/roots/test-ext-autodoc/target", "start_line": 170, "end_line": 174}, "type": "class"}, {"name": "test_final", "is_method": false, "class_name": null, "parameters": ["app"], "calls": ["pytest.mark.sphinx", "do_autodoc", "list"], "code_location": {"file": "test_ext_autodoc.py", "path": "/data3/pwh/swebench-repos/sphinx/tests/test_extensions", "start_line": 2830, "end_line": 2871}, "code_snippet": "def test_final(app):\n    options = {'members': None}\n    actual = do_autodoc(app, 'module', 'target.final', options)\n    assert list(actual) == [\n        '',\n        '.. py:module:: target.final',\n        '',\n        '',\n        '.. py:class:: Class()',\n        '   :module: target.final',\n        '   :final:',\n        '',\n        '   docstring',\n        '',\n        '',\n        '   .. py:method:: Class.meth1()',\n        '      :module: target.final',\n        '      :final:',\n        '',\n        '      docstring',\n        '',\n        '',\n        '   .. py:method:: Class.meth2()',\n        '      :module: target.final',\n        '',\n        '      docstring',\n        '',\n        '',\n        '   .. py:method:: Class.meth3()',\n        '      :module: target.final',\n        '      :final:',\n        '',\n        '      docstring',\n        '',\n        '',\n        '   .. py:method:: Class.meth4()',\n        '      :module: target.final',\n        '      :final:',\n        '',\n        '      docstring',\n        '',\n    ]\n", "type": "function"}, {"name": "ASTUnion", "docstring": "", "methods": ["__init__", "__eq__", "__hash__", "get_id", "_stringify", "describe_signature", "__init__", "__eq__", "__hash__", "get_id", "_stringify", "describe_signature"], "attributes": [], "code_location": {"file": "_ast.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/domains/c", "start_line": 1751, "end_line": 1773}, "type": "class"}, {"name": "ASTUnion", "docstring": "", "methods": [], "attributes": [], "code_location": {"file": "_ast.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/domains/cpp", "start_line": 3781, "end_line": 3813}, "type": "class"}, {"name": "ASTNoexceptSpec", "docstring": "", "methods": ["__init__", "__eq__", "__hash__", "_stringify", "describe_signature"], "attributes": [], "code_location": {"file": "_ast.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/domains/cpp", "start_line": 2064, "end_line": 2088}, "type": "class"}, {"name": "MemberType", "docstring": "Custom data type with a simple API.", "methods": ["__new__", "__str__", "__repr__", "__reduce__", "dtype", "isupper"], "attributes": ["__slots__"], "code_location": {"file": "enums.py", "path": "/data3/pwh/swebench-repos/sphinx/tests/roots/test-ext-autodoc/target", "start_line": 6, "end_line": 39}, "type": "class"}], "retrieved_count": 10, "cost_time": 1.0608642101287842}
{"question": "What is the contract established by the return value of the required method in the tutorial example directive class between the directive implementation and the document tree processing pipeline?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"name": "TestcodeDirective", "docstring": "", "methods": [], "attributes": [], "code_location": {"file": "doctest.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/ext", "start_line": 173, "end_line": 180}, "type": "class"}, {"name": "FakeDirective", "docstring": "", "methods": ["__init__"], "attributes": [], "code_location": {"file": "__init__.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/ext/autosummary", "start_line": 173, "end_line": 182}, "type": "class"}, {"name": "DoctestDirective", "docstring": "", "methods": [], "attributes": [], "code_location": {"file": "doctest.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/ext", "start_line": 162, "end_line": 170}, "type": "class"}, {"name": "ReSTDirective", "docstring": "Description of a reST directive.", "methods": ["handle_signature", "get_index_text", "before_content", "after_content"], "attributes": [], "code_location": {"file": "rst.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/domains", "start_line": 118, "end_line": 141}, "type": "class"}, {"name": "run", "is_method": true, "class_name": "AutodocDirective", "parameters": ["self"], "calls": ["logger.debug", "DocumenterBridge", "doccls", "documenter.generate", "logger.debug", "parse_generated_content", "reporter.get_source_and_line", "_process_documenter_options", "_AutoDocumenterOptions.from_directive_options", "join", "self.state.document.settings.record_dependencies.add", "logger.error"], "code_location": {"file": "directive.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/ext/autodoc", "start_line": 104, "end_line": 154}, "code_snippet": "    def run(self) -> list[Node]:\n        reporter = self.state.document.reporter\n\n        try:\n            source, lineno = reporter.get_source_and_line(  # type: ignore[attr-defined]\n                self.lineno\n            )\n        except AttributeError:\n            source, lineno = (None, None)\n        logger.debug('[autodoc] %s:%s: input:\\n%s', source, lineno, self.block_text)\n\n        # look up target Documenter\n        objtype = self.name[4:]  # strip prefix (auto-).\n        doccls = self.env._registry.documenters[objtype]\n\n        # process the options with the selected documenter's option_spec\n        try:\n            opts = _process_documenter_options(\n                option_spec=doccls.option_spec,\n                default_options=self.config.autodoc_default_options,\n                options=self.options,\n            )\n            documenter_options = _AutoDocumenterOptions.from_directive_options(opts)\n        except (KeyError, ValueError, TypeError) as exc:\n            # an option is either unknown or has a wrong type\n            logger.error(  # NoQA: TRY400\n                'An option to %s is either unknown or has an invalid value: %s',\n                self.name,\n                exc,\n                location=(self.env.current_document.docname, lineno),\n            )\n            return []\n\n        # generate the output\n        params = DocumenterBridge(\n            self.env, reporter, documenter_options, lineno, self.state\n        )\n        documenter = doccls(params, self.arguments[0])\n        documenter.generate(more_content=self.content)\n        if not params.result:\n            return []\n\n        logger.debug('[autodoc] output:\\n%s', '\\n'.join(params.result))\n\n        # record all filenames as dependencies -- this will at least\n        # partially make automatic invalidation possible\n        for fn in params.record_dependencies:\n            self.state.document.settings.record_dependencies.add(fn)\n\n        result = parse_generated_content(self.state, params.result, documenter)\n        return result\n", "type": "function"}, {"name": "make_directive", "is_method": false, "class_name": null, "parameters": [], "calls": ["make_directive_and_state"], "code_location": {"file": "test_util_docutils_sphinx_directive.py", "path": "/data3/pwh/swebench-repos/sphinx/tests/test_util", "start_line": 18, "end_line": 22}, "code_snippet": "def make_directive(\n    *, env: SimpleNamespace, input_lines: StringList | None = None\n) -> SphinxDirective:\n    _, directive = make_directive_and_state(env=env, input_lines=input_lines)\n    return directive\n", "type": "function"}, {"name": "run", "is_method": true, "class_name": "HelloDirective", "parameters": ["self"], "calls": ["nodes.paragraph"], "code_location": {"file": "helloworld.py", "path": "/data3/pwh/swebench-repos/sphinx/doc/development/tutorials/examples", "start_line": 23, "end_line": 25}, "code_snippet": "    def run(self) -> list[nodes.Node]:\n        paragraph_node = nodes.paragraph(text=f'hello {self.arguments[0]}!')\n        return [paragraph_node]\n", "type": "function"}, {"name": "TestDirective", "docstring": "Base class for doctest-related directives.", "methods": ["run"], "attributes": ["has_content", "required_arguments", "optional_arguments", "final_argument_whitespace"], "code_location": {"file": "doctest.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/ext", "start_line": 66, "end_line": 147}, "type": "class"}, {"name": "TodoDirective", "docstring": "", "methods": ["run"], "attributes": ["has_content"], "code_location": {"file": "todo.py", "path": "/data3/pwh/swebench-repos/sphinx/doc/development/tutorials/examples", "start_line": 31, "end_line": 53}, "type": "class"}, {"name": "RecipeDirective", "docstring": "A custom directive that describes a recipe.", "methods": ["handle_signature", "add_target_and_index"], "attributes": ["has_content", "required_arguments", "option_spec"], "code_location": {"file": "recipe.py", "path": "/data3/pwh/swebench-repos/sphinx/doc/development/tutorials/examples", "start_line": 14, "end_line": 33}, "type": "class"}], "retrieved_count": 10, "cost_time": 1.0602238178253174}
{"question": "How does the theme retrieval method in the LaTeX theme factory resolve precedence when a name exists in both predefined themes and user theme directories?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"name": "find_user_theme", "is_method": true, "class_name": "ThemeFactory", "parameters": ["self", "name"], "calls": ["config_path.is_file", "UserTheme", "logger.warning"], "code_location": {"file": "theming.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/builders/latex", "start_line": 125, "end_line": 135}, "code_snippet": "    def find_user_theme(self, name: str) -> Theme | None:\n        \"\"\"Find a theme named as *name* from latex_theme_path.\"\"\"\n        for theme_path in self.theme_paths:\n            config_path = theme_path / name / 'theme.conf'\n            if config_path.is_file():\n                try:\n                    return UserTheme(name, config_path)\n                except ThemeError as exc:\n                    logger.warning(exc)\n\n        return None\n", "type": "function"}, {"name": "get", "is_method": true, "class_name": "ThemeFactory", "parameters": ["self", "name"], "calls": ["theme.update", "self.find_user_theme", "Theme"], "code_location": {"file": "theming.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/builders/latex", "start_line": 115, "end_line": 123}, "code_snippet": "    def get(self, name: str) -> Theme:\n        \"\"\"Get a theme for given *name*.\"\"\"\n        if name in self.themes:\n            theme = self.themes[name]\n        else:\n            theme = self.find_user_theme(name) or Theme(name)\n\n        theme.update(self.config)\n        return theme\n", "type": "function"}, {"name": "_load_entry_point_themes", "is_method": true, "class_name": "HTMLThemeFactory", "parameters": ["self"], "calls": ["entry_points", "app.setup_extension", "_config_post_init"], "code_location": {"file": "theming.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx", "start_line": 184, "end_line": 201}, "code_snippet": "    def _load_entry_point_themes(self) -> None:\n        \"\"\"Try to load a theme with the specified name.\n\n        This uses the ``sphinx.html_themes`` entry point from package metadata.\n        \"\"\"\n        for entry_point in entry_points(group='sphinx.html_themes'):\n            if entry_point.name in self._themes:\n                continue  # don't overwrite loaded themes\n\n            def _load_theme_closure(\n                # bind variables in the function definition\n                app: Sphinx = self._app,\n                theme_module: str = entry_point.module,\n            ) -> None:\n                app.setup_extension(theme_module)\n                _config_post_init(app, app.config)\n\n            self._entry_point_themes[entry_point.name] = _load_theme_closure\n", "type": "function"}, {"name": "__init__", "is_method": true, "class_name": "ThemeFactory", "parameters": ["self"], "calls": ["self.load_builtin_themes"], "code_location": {"file": "theming.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/builders/latex", "start_line": 104, "end_line": 108}, "code_snippet": "    def __init__(self, *, srcdir: Path, config: Config) -> None:\n        self.themes: dict[str, Theme] = {}\n        self.theme_paths = [srcdir / p for p in config.latex_theme_path]\n        self.config = config\n        self.load_builtin_themes(config)\n", "type": "function"}, {"name": "_load_theme", "is_method": false, "class_name": null, "parameters": [], "calls": ["theme_path.is_dir", "is_file", "Path", "_extract_zip", "_load_theme_toml", "_validate_theme_toml", "_convert_theme_toml", "is_file", "tempfile.mkdtemp", "_load_theme_conf", "_validate_theme_conf", "_convert_theme_conf", "ThemeError", "__"], "code_location": {"file": "theming.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx", "start_line": 298, "end_line": 322}, "code_snippet": "def _load_theme(\n    name: str, theme_path: Path, /\n) -> tuple[str, Path, Path | None, _ConfigFile]:\n    if theme_path.is_dir():\n        # already a directory, do nothing\n        tmp_dir = None\n        theme_dir = theme_path\n    else:\n        # extract the theme to a temp directory\n        tmp_dir = Path(tempfile.mkdtemp('sxt'))\n        theme_dir = tmp_dir / name\n        _extract_zip(theme_path, theme_dir)\n\n    if (toml_path := theme_dir / _THEME_TOML).is_file():\n        _cfg_table = _load_theme_toml(toml_path)\n        inherit = _validate_theme_toml(_cfg_table, name)\n        config = _convert_theme_toml(_cfg_table)\n    elif (conf_path := theme_dir / _THEME_CONF).is_file():\n        _cfg_parser = _load_theme_conf(conf_path)\n        inherit = _validate_theme_conf(_cfg_parser, name)\n        config = _convert_theme_conf(_cfg_parser)\n    else:\n        raise ThemeError(__('no theme configuration file found in %r') % theme_dir)\n\n    return inherit, theme_dir, tmp_dir, config\n", "type": "function"}, {"name": "_validate_theme_conf", "is_method": false, "class_name": null, "parameters": ["cfg", "name"], "calls": ["ThemeError", "cfg.has_section", "ThemeError", "cfg.get", "__", "__"], "code_location": {"file": "theming.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx", "start_line": 396, "end_line": 402}, "code_snippet": "def _validate_theme_conf(cfg: configparser.RawConfigParser, name: str) -> str:\n    if not cfg.has_section('theme'):\n        raise ThemeError(__('theme %r doesn\\'t have the \"theme\" table') % name)\n    if inherit := cfg.get('theme', 'inherit', fallback=None):\n        return inherit\n    msg = __('The %r theme must define the \"theme.inherit\" setting') % name\n    raise ThemeError(msg)\n", "type": "function"}, {"name": "get_config", "is_method": true, "class_name": "Theme", "parameters": ["self", "section", "name", "default"], "calls": ["ThemeError", "self._options.get", "__", "ThemeError", "__", "join", "join"], "code_location": {"file": "theming.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx", "start_line": 98, "end_line": 127}, "code_snippet": "    def get_config(self, section: str, name: str, default: Any = _NO_DEFAULT) -> Any:\n        \"\"\"Return the value for a theme configuration setting, searching the\n        base theme chain.\n        \"\"\"\n        if section == 'theme':\n            if name == 'stylesheet':\n                value = ', '.join(self.stylesheets) or default\n            elif name == 'sidebars':\n                value = ', '.join(self.sidebar_templates) or default\n            elif name == 'pygments_style':\n                value = self.pygments_style_default or default\n            elif name == 'pygments_dark_style':\n                value = self.pygments_style_dark or default\n            else:\n                value = default\n        elif section == 'options':\n            value = self._options.get(name, default)\n        else:\n            msg = __(\n                'Theme configuration sections other than [theme] and [options] '\n                'are not supported (tried to get a value from %r).'\n            )\n            raise ThemeError(msg)\n        if value is _NO_DEFAULT:\n            msg = __('setting %s.%s occurs in none of the searched theme configs') % (\n                section,\n                name,\n            )\n            raise ThemeError(msg)\n        return value\n", "type": "function"}, {"name": "_find_themes", "is_method": true, "class_name": "HTMLThemeFactory", "parameters": ["theme_path"], "calls": ["theme_path.iterdir", "theme_path.is_dir", "pathname.is_file", "_is_archived_theme", "pathname.suffix.lower", "logger.warning", "toml_path.is_file", "conf_path.is_file", "__"], "code_location": {"file": "theming.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx", "start_line": 204, "end_line": 229}, "code_snippet": "    def _find_themes(theme_path: Path) -> dict[str, Path]:\n        \"\"\"Search themes from specified directory.\"\"\"\n        themes: dict[str, Path] = {}\n        if not theme_path.is_dir():\n            return themes\n\n        for pathname in theme_path.iterdir():\n            entry = pathname.name\n            if pathname.is_file() and pathname.suffix.lower() == '.zip':\n                if _is_archived_theme(pathname):\n                    themes[pathname.stem] = pathname\n                else:\n                    logger.warning(\n                        __(\n                            'file %r on theme path is not a valid '\n                            'zipfile or contains no theme'\n                        ),\n                        entry,\n                    )\n            else:\n                toml_path = pathname / _THEME_TOML\n                conf_path = pathname / _THEME_CONF\n                if toml_path.is_file() or conf_path.is_file():\n                    themes[entry] = pathname\n\n        return themes\n", "type": "function"}, {"name": "_load_builtin_themes", "is_method": true, "class_name": "HTMLThemeFactory", "parameters": ["self"], "calls": ["self._find_themes", "themes.items", "_StrPath"], "code_location": {"file": "theming.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx", "start_line": 170, "end_line": 174}, "code_snippet": "    def _load_builtin_themes(self) -> None:\n        \"\"\"Load built-in themes.\"\"\"\n        themes = self._find_themes(package_dir / 'themes')\n        for name, theme in themes.items():\n            self._themes[name] = _StrPath(theme)\n", "type": "function"}, {"name": "_load_theme_with_ancestors", "is_method": false, "class_name": null, "parameters": [], "calls": ["range", "_load_theme", "theme_dirs.append", "ThemeError", "tmp_dirs.append", "ThemeError", "entry_point_loader", "ThemeError", "__", "__", "__", "join", "sorted"], "code_location": {"file": "theming.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx", "start_line": 258, "end_line": 295}, "code_snippet": "def _load_theme_with_ancestors(\n    name: str,\n    theme_paths: dict[str, _StrPath],\n    entry_point_themes: dict[str, Callable[[], None]],\n    /,\n) -> tuple[dict[str, _ConfigFile], list[Path], list[Path]]:\n    themes: dict[str, _ConfigFile] = {}\n    theme_dirs: list[Path] = []\n    tmp_dirs: list[Path] = []\n\n    # having 10+ theme ancestors is ludicrous\n    for _ in range(10):\n        inherit, theme_dir, tmp_dir, config = _load_theme(name, theme_paths[name])\n        theme_dirs.append(theme_dir)\n        if tmp_dir is not None:\n            tmp_dirs.append(tmp_dir)\n        themes[name] = config\n        if inherit == 'none':\n            break\n        if inherit in themes:\n            msg = __('The %r theme has circular inheritance') % name\n            raise ThemeError(msg)\n        if inherit in entry_point_themes and inherit not in theme_paths:\n            # Load a deferred theme from an entry point\n            entry_point_loader = entry_point_themes[inherit]\n            entry_point_loader()\n        if inherit not in theme_paths:\n            msg = __(\n                'The %r theme inherits from %r, which is not a loaded theme. '\n                'Loaded themes are: %s'\n            ) % (name, inherit, ', '.join(sorted(theme_paths)))\n            raise ThemeError(msg)\n        name = inherit\n    else:\n        msg = __('The %r theme has too many ancestors') % name\n        raise ThemeError(msg)\n\n    return themes, theme_dirs, tmp_dirs\n", "type": "function"}], "retrieved_count": 10, "cost_time": 1.0457258224487305}
{"question": "How does the documentation generation system determine which class members should be excluded from generated documentation?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"name": "filter_members", "is_method": true, "class_name": "Documenter", "parameters": ["self", "members", "want_all"], "calls": ["set", "inspect.isclass", "self.analyzer.find_attr_docs", "set", "getdoc", "self.get_attr", "separate_metadata", "bool", "ret.append", "isinstance", "self.get_attr", "isinstance", "ismock", "isinstance", "self._events.emit_firstresult", "logger.warning", "seen.add", "any", "self.get_attr", "isinstance", "membername.startswith", "__", "special_member_re.match", "issubclass", "is_filtered_inherited_member", "is_filtered_inherited_member", "is_filtered_inherited_member"], "code_location": {"file": "_documenters.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/ext/autodoc", "start_line": 618, "end_line": 802}, "code_snippet": "    def filter_members(\n        self, members: list[ObjectMember], want_all: bool\n    ) -> list[tuple[str, Any, bool]]:\n        \"\"\"Filter the given member list.\n\n        Members are skipped if\n\n        - they are private (except if given explicitly or the private-members\n          option is set)\n        - they are special methods (except if given explicitly or the\n          special-members option is set)\n        - they are undocumented (except if the undoc-members option is set)\n\n        The user can override the skipping decision by connecting to the\n        ``autodoc-skip-member`` event.\n        \"\"\"\n\n        def is_filtered_inherited_member(name: str, obj: Any) -> bool:\n            inherited_members = self.options.inherited_members or set()\n            seen = set()\n\n            if inspect.isclass(self.props._obj):\n                for cls in self.props._obj.__mro__:\n                    if name in cls.__dict__:\n                        seen.add(cls)\n                    if (\n                        cls.__name__ in inherited_members\n                        and cls != self.props._obj\n                        and any(\n                            issubclass(potential_child, cls) for potential_child in seen\n                        )\n                    ):\n                        # given member is a member of specified *super class*\n                        return True\n                    if name in cls.__dict__:\n                        return False\n                    if name in self.get_attr(cls, '__annotations__', {}):\n                        return False\n                    if isinstance(obj, ObjectMember) and obj.class_ is cls:\n                        return False\n\n            return False\n\n        ret = []\n\n        # search for members in source code too\n        namespace = self.props.dotted_parts  # will be empty for modules\n\n        if self.analyzer:\n            attr_docs = self.analyzer.find_attr_docs()\n        else:\n            attr_docs = {}\n\n        # process members and determine which to skip\n        for obj in members:\n            membername = obj.__name__\n            member = obj.object\n\n            # if isattr is True, the member is documented as an attribute\n            isattr = member is INSTANCE_ATTR or (namespace, membername) in attr_docs\n\n            try:\n                doc = getdoc(\n                    member,\n                    self.get_attr,\n                    self.config.autodoc_inherit_docstrings,\n                    self.props._obj,\n                    membername,\n                )\n                if not isinstance(doc, str):\n                    # Ignore non-string __doc__\n                    doc = None\n\n                # if the member __doc__ is the same as self's __doc__, it's just\n                # inherited and therefore not the member's doc\n                cls = self.get_attr(member, '__class__', None)\n                if cls:\n                    cls_doc = self.get_attr(cls, '__doc__', None)\n                    if cls_doc == doc:\n                        doc = None\n\n                if isinstance(obj, ObjectMember) and obj.docstring:\n                    # hack for ClassDocumenter to inject docstring via ObjectMember\n                    doc = obj.docstring\n\n                doc, metadata = separate_metadata(doc)\n                has_doc = bool(doc)\n\n                if 'private' in metadata:\n                    # consider a member private if docstring has \"private\" metadata\n                    isprivate = True\n                elif 'public' in metadata:\n                    # consider a member public if docstring has \"public\" metadata\n                    isprivate = False\n                else:\n                    isprivate = membername.startswith('_')\n\n                keep = False\n                if ismock(member) and (namespace, membername) not in attr_docs:\n                    # mocked module or object\n                    pass\n                elif (\n                    self.options.exclude_members\n                    and membername in self.options.exclude_members\n                ):\n                    # remove members given by exclude-members\n                    keep = False\n                elif want_all and special_member_re.match(membername):\n                    # special __methods__\n                    if (\n                        self.options.special_members\n                        and membername in self.options.special_members\n                    ):\n                        if membername == '__doc__':  # NoQA: SIM114\n                            keep = False\n                        elif is_filtered_inherited_member(membername, obj):\n                            keep = False\n                        else:\n                            keep = has_doc or self.options.undoc_members  # type: ignore[assignment]\n                    else:\n                        keep = False\n                elif (namespace, membername) in attr_docs:\n                    if want_all and isprivate:\n                        if self.options.private_members is None:\n                            keep = False\n                        else:\n                            keep = membername in self.options.private_members\n                    else:\n                        # keep documented attributes\n                        keep = True\n                elif want_all and isprivate:\n                    if has_doc or self.options.undoc_members:\n                        if self.options.private_members is None:  # NoQA: SIM114\n                            keep = False\n                        elif is_filtered_inherited_member(membername, obj):\n                            keep = False\n                        else:\n                            keep = membername in self.options.private_members\n                    else:\n                        keep = False\n                else:\n                    if self.options.members is ALL and is_filtered_inherited_member(\n                        membername, obj\n                    ):\n                        keep = False\n                    else:\n                        # ignore undocumented members if :undoc-members: is not given\n                        keep = has_doc or self.options.undoc_members  # type: ignore[assignment]\n\n                if isinstance(obj, ObjectMember) and obj.skipped:\n                    # forcedly skipped member (ex. a module attribute not defined in __all__)\n                    keep = False\n\n                # give the user a chance to decide whether this member\n                # should be skipped\n                if self._events is not None:\n                    # let extensions preprocess docstrings\n                    skip_user = self._events.emit_firstresult(\n                        'autodoc-skip-member',\n                        self.objtype,\n                        membername,\n                        member,\n                        not keep,\n                        self.options,\n                    )\n                    if skip_user is not None:\n                        keep = not skip_user\n            except Exception as exc:\n                logger.warning(\n                    __(\n                        'autodoc: failed to determine %s.%s (%r) to be documented, '\n                        'the following exception was raised:\\n%s'\n                    ),\n                    self.name,\n                    membername,\n                    member,\n                    exc,\n                    type='autodoc',\n                )\n                keep = False\n\n            if keep:\n                ret.append((membername, member, isattr))\n\n        return ret\n", "type": "function"}, {"name": "_skip_member", "is_method": false, "class_name": null, "parameters": ["app", "what", "name", "obj", "skip", "options"], "calls": ["getattr", "getattr", "qualname.rpartition", "name.startswith", "name.endswith", "name.startswith", "importlib.import_module", "cls_path.split", "functools.reduce", "hasattr", "inspect.unwrap"], "code_location": {"file": "__init__.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/ext/napoleon", "start_line": 417, "end_line": 503}, "code_snippet": "def _skip_member(\n    app: Sphinx, what: str, name: str, obj: Any, skip: bool, options: Any\n) -> bool | None:\n    \"\"\"Determine if private and special class members are included in docs.\n\n    The following settings in conf.py determine if private and special class\n    members or init methods are included in the generated documentation:\n\n    * ``napoleon_include_init_with_doc`` --\n      include init methods if they have docstrings\n    * ``napoleon_include_private_with_doc`` --\n      include private members if they have docstrings\n    * ``napoleon_include_special_with_doc`` --\n      include special members if they have docstrings\n\n    Parameters\n    ----------\n    app : sphinx.application.Sphinx\n        Application object representing the Sphinx process\n    what : str\n        A string specifying the type of the object to which the member\n        belongs. Valid values: \"module\", \"class\", \"exception\", \"function\",\n        \"method\", \"attribute\".\n    name : str\n        The name of the member.\n    obj : module, class, exception, function, method, or attribute.\n        For example, if the member is the __init__ method of class A, then\n        `obj` will be `A.__init__`.\n    skip : bool\n        A boolean indicating if autodoc will skip this member if `_skip_member`\n        does not override the decision\n    options : sphinx.ext.autodoc.Options\n        The options given to the directive: an object with attributes\n        inherited_members, undoc_members, show_inheritance and no_index that\n        are True if the flag option of same name was given to the auto\n        directive.\n\n    Returns\n    -------\n    bool\n        True if the member should be skipped during creation of the docs,\n        False if it should be included in the docs.\n\n    \"\"\"\n    has_doc = getattr(obj, '__doc__', False)\n    is_member = what in {'class', 'exception', 'module'}\n    if name != '__weakref__' and has_doc and is_member:\n        cls_is_owner = False\n        if what in {'class', 'exception'}:\n            qualname = getattr(obj, '__qualname__', '')\n            cls_path, _, _ = qualname.rpartition('.')\n            if cls_path:\n                try:\n                    if '.' in cls_path:\n                        import functools\n                        import importlib\n\n                        mod = importlib.import_module(obj.__module__)\n                        mod_path = cls_path.split('.')\n                        cls = functools.reduce(getattr, mod_path, mod)\n                    else:\n                        cls = inspect.unwrap(obj).__globals__[cls_path]\n                except Exception:\n                    cls_is_owner = False\n                else:\n                    cls_is_owner = (\n                        cls  # type: ignore[assignment]\n                        and hasattr(cls, name)\n                        and name in cls.__dict__\n                    )\n            else:\n                cls_is_owner = False\n\n        if what == 'module' or cls_is_owner:\n            is_init = name == '__init__'\n            is_special = not is_init and name.startswith('__') and name.endswith('__')\n            is_private = not is_init and not is_special and name.startswith('_')\n            inc_init = app.config.napoleon_include_init_with_doc\n            inc_special = app.config.napoleon_include_special_with_doc\n            inc_private = app.config.napoleon_include_private_with_doc\n            if (\n                (is_special and inc_special)\n                or (is_private and inc_private)\n                or (is_init and inc_init)\n            ):\n                return False\n    return None\n", "type": "function"}, {"name": "can_document_member", "is_method": true, "class_name": "AttributeDocumenter", "parameters": ["cls", "member", "membername", "isattr", "parent"], "calls": ["isinstance", "inspect.isattributedescriptor", "inspect.isroutine", "isinstance"], "code_location": {"file": "_documenters.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/ext/autodoc", "start_line": 2270, "end_line": 2277}, "code_snippet": "    def can_document_member(\n        cls: type[Documenter], member: Any, membername: str, isattr: bool, parent: Any\n    ) -> bool:\n        if isinstance(parent, ModuleDocumenter):\n            return False\n        if inspect.isattributedescriptor(member):\n            return True\n        return not inspect.isroutine(member) and not isinstance(member, type)\n", "type": "function"}, {"name": "skip_member", "is_method": false, "class_name": null, "parameters": ["app", "what", "name", "obj", "skip", "options"], "calls": [], "code_location": {"file": "conf.py", "path": "/data3/pwh/swebench-repos/sphinx/tests/roots/test-ext-autosummary-skip-member", "start_line": 11, "end_line": 16}, "code_snippet": "def skip_member(app, what, name, obj, skip, options):\n    if name == 'skipmeth':\n        return True\n    elif name == '_privatemeth':\n        return False\n    return None\n", "type": "function"}, {"name": "_skip_member", "is_method": false, "class_name": null, "parameters": ["obj", "name", "objtype"], "calls": ["events.emit_firstresult", "logger.warning", "__"], "code_location": {"file": "generate.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/ext/autosummary", "start_line": 442, "end_line": 457}, "code_snippet": "def _skip_member(obj: Any, name: str, objtype: str, *, events: EventManager) -> bool:\n    try:\n        return events.emit_firstresult(\n            'autodoc-skip-member', objtype, name, obj, False, {}\n        )\n    except Exception as exc:\n        logger.warning(\n            __(\n                'autosummary: failed to determine %r to be documented, '\n                'the following exception was raised:\\n%s'\n            ),\n            name,\n            exc,\n            type='autosummary',\n        )\n        return False\n", "type": "function"}, {"name": "is_skipped", "is_method": true, "class_name": "ModuleScanner", "parameters": ["self", "name", "value", "objtype"], "calls": ["self.events.emit_firstresult", "logger.warning", "__"], "code_location": {"file": "generate.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/ext/autosummary", "start_line": 224, "end_line": 239}, "code_snippet": "    def is_skipped(self, name: str, value: Any, objtype: str) -> bool:\n        try:\n            return self.events.emit_firstresult(\n                'autodoc-skip-member', objtype, name, value, False, {}\n            )\n        except Exception as exc:\n            logger.warning(\n                __(\n                    'autosummary: failed to determine %r to be documented, '\n                    'the following exception was raised:\\n%s'\n                ),\n                name,\n                exc,\n                type='autosummary',\n            )\n            return False\n", "type": "function"}, {"name": "_Empty", "docstring": "A special value for :exclude-members: that never matches to any member.", "methods": ["__contains__"], "attributes": [], "code_location": {"file": "_sentinels.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/ext/autodoc", "start_line": 52, "end_line": 56}, "type": "class"}, {"name": "can_document_member", "is_method": true, "class_name": "MethodDocumenter", "parameters": ["cls", "member", "membername", "isattr", "parent"], "calls": ["inspect.isroutine", "isinstance"], "code_location": {"file": "_documenters.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/ext/autodoc", "start_line": 2002, "end_line": 2005}, "code_snippet": "    def can_document_member(\n        cls: type[Documenter], member: Any, membername: str, isattr: bool, parent: Any\n    ) -> bool:\n        return inspect.isroutine(member) and not isinstance(parent, ModuleDocumenter)\n", "type": "function"}, {"name": "can_document_member", "is_method": true, "class_name": "_MyDocumenter", "parameters": ["cls", "member", "membername", "isattr", "parent"], "calls": ["isinstance"], "code_location": {"file": "test_ext_autodoc.py", "path": "/data3/pwh/swebench-repos/sphinx/tests/test_extensions", "start_line": 450, "end_line": 451}, "code_snippet": "    def can_document_member(cls, member, membername, isattr, parent):\n        return isinstance(member, int)\n", "type": "function"}, {"name": "can_document_member", "is_method": true, "class_name": "ModuleDocumenter", "parameters": ["cls", "member", "membername", "isattr", "parent"], "calls": [], "code_location": {"file": "_documenters.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/ext/autodoc", "start_line": 1041, "end_line": 1045}, "code_snippet": "    def can_document_member(\n        cls: type[Documenter], member: Any, membername: str, isattr: bool, parent: Any\n    ) -> bool:\n        # don't document submodules automatically\n        return False\n", "type": "function"}], "retrieved_count": 10, "cost_time": 1.0606684684753418}
{"question": "What is the interaction mechanism between the conditional logic that checks the object type attribute in the index text generation method and the translation system that produces semantically different index entries for class-like objects in the Python documentation domain?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"name": "get_index_text", "is_method": true, "class_name": "JSObject", "parameters": ["self", "objectname", "name_obj"], "calls": ["_", "_", "_", "_", "_"], "code_location": {"file": "javascript.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/domains", "start_line": 179, "end_line": 191}, "code_snippet": "    def get_index_text(self, objectname: str, name_obj: tuple[str, str]) -> str:\n        name, obj = name_obj\n        if self.objtype == 'function':\n            if not obj:\n                return _('%s() (built-in function)') % name\n            return _('%s() (%s method)') % (name, obj)\n        elif self.objtype == 'class':\n            return _('%s() (class)') % name\n        elif self.objtype == 'data':\n            return _('%s (global variable or constant)') % name\n        elif self.objtype == 'attribute':\n            return _('%s (%s attribute)') % (name, obj)\n        return ''\n", "type": "function"}, {"name": "get_index_text", "is_method": true, "class_name": "PyClasslike", "parameters": ["self", "modname", "name_cls"], "calls": ["_", "_"], "code_location": {"file": "__init__.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/domains/python", "start_line": 216, "end_line": 224}, "code_snippet": "    def get_index_text(self, modname: str, name_cls: tuple[str, str]) -> str:\n        if self.objtype == 'class':\n            if not modname:\n                return _('%s (built-in class)') % name_cls[0]\n            return _('%s (class in %s)') % (name_cls[0], modname)\n        elif self.objtype == 'exception':\n            return name_cls[0]\n        else:\n            return ''\n", "type": "function"}, {"name": "get_index_text", "is_method": true, "class_name": "ReSTDirective", "parameters": ["self", "objectname", "name"], "calls": ["_"], "code_location": {"file": "rst.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/domains", "start_line": 130, "end_line": 131}, "code_snippet": "    def get_index_text(self, objectname: str, name: str) -> str:\n        return _('%s (directive)') % name\n", "type": "function"}, {"name": "get_index_text", "is_method": true, "class_name": "PyMethod", "parameters": ["self", "modname", "name_cls"], "calls": ["name.rsplit", "_", "_", "_", "_"], "code_location": {"file": "__init__.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/domains/python", "start_line": 272, "end_line": 289}, "code_snippet": "    def get_index_text(self, modname: str, name_cls: tuple[str, str]) -> str:\n        name, _cls = name_cls\n        try:\n            clsname, methname = name.rsplit('.', 1)\n            if modname and self.config.add_module_names:\n                clsname = f'{modname}.{clsname}'\n        except ValueError:\n            if modname:\n                return _('%s() (in module %s)') % (name, modname)\n            else:\n                return '%s()' % name\n\n        if 'classmethod' in self.options:\n            return _('%s() (%s class method)') % (methname, clsname)\n        elif 'staticmethod' in self.options:\n            return _('%s() (%s static method)') % (methname, clsname)\n        else:\n            return _('%s() (%s method)') % (methname, clsname)\n", "type": "function"}, {"name": "get_index_text", "is_method": true, "class_name": "PyAttribute", "parameters": ["self", "modname", "name_cls"], "calls": ["name.rsplit", "_", "_"], "code_location": {"file": "__init__.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/domains/python", "start_line": 368, "end_line": 380}, "code_snippet": "    def get_index_text(self, modname: str, name_cls: tuple[str, str]) -> str:\n        name, _cls = name_cls\n        try:\n            clsname, attrname = name.rsplit('.', 1)\n            if modname and self.config.add_module_names:\n                clsname = f'{modname}.{clsname}'\n        except ValueError:\n            if modname:\n                return _('%s (in module %s)') % (name, modname)\n            else:\n                return name\n\n        return _('%s (%s attribute)') % (attrname, clsname)\n", "type": "function"}, {"name": "get_index_text", "is_method": true, "class_name": "PyProperty", "parameters": ["self", "modname", "name_cls"], "calls": ["name.rsplit", "_", "_"], "code_location": {"file": "__init__.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/domains/python", "start_line": 428, "end_line": 440}, "code_snippet": "    def get_index_text(self, modname: str, name_cls: tuple[str, str]) -> str:\n        name, _cls = name_cls\n        try:\n            clsname, attrname = name.rsplit('.', 1)\n            if modname and self.config.add_module_names:\n                clsname = f'{modname}.{clsname}'\n        except ValueError:\n            if modname:\n                return _('%s (in module %s)') % (name, modname)\n            else:\n                return name\n\n        return _('%s (%s property)') % (attrname, clsname)\n", "type": "function"}, {"name": "get_index_text", "is_method": true, "class_name": "PyTypeAlias", "parameters": ["self", "modname", "name_cls"], "calls": ["name.rsplit", "_", "_"], "code_location": {"file": "__init__.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/domains/python", "start_line": 468, "end_line": 480}, "code_snippet": "    def get_index_text(self, modname: str, name_cls: tuple[str, str]) -> str:\n        name, _cls = name_cls\n        try:\n            clsname, attrname = name.rsplit('.', 1)\n            if modname and self.config.add_module_names:\n                clsname = f'{modname}.{clsname}'\n        except ValueError:\n            if modname:\n                return _('%s (in module %s)') % (name, modname)\n            else:\n                return name\n\n        return _('%s (type alias in %s)') % (attrname, clsname)\n", "type": "function"}, {"name": "get_index_text", "is_method": true, "class_name": "CPPObject", "parameters": ["self", "name"], "calls": ["_"], "code_location": {"file": "__init__.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/domains/cpp", "start_line": 301, "end_line": 302}, "code_snippet": "    def get_index_text(self, name: str) -> str:\n        return _('%s (C++ %s)') % (name, self.display_object_type)\n", "type": "function"}, {"name": "get_index_text", "is_method": true, "class_name": "PyObject", "parameters": ["self", "modname", "name"], "calls": ["NotImplementedError"], "code_location": {"file": "_object.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/domains/python", "start_line": 410, "end_line": 413}, "code_snippet": "    def get_index_text(self, modname: str, name: tuple[str, str]) -> str:\n        \"\"\"Return the text for the index entry of the object.\"\"\"\n        msg = 'must be implemented in subclasses'\n        raise NotImplementedError(msg)\n", "type": "function"}, {"name": "get_index_text", "is_method": true, "class_name": "ReSTRole", "parameters": ["self", "objectname", "name"], "calls": ["_"], "code_location": {"file": "rst.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/domains", "start_line": 223, "end_line": 224}, "code_snippet": "    def get_index_text(self, objectname: str, name: str) -> str:\n        return _('%s (role)') % name\n", "type": "function"}], "retrieved_count": 10, "cost_time": 1.0903868675231934}
{"question": "What is the dependency mechanism in the directive class that handles CSV table rendering in the patches module's execution method on the build environment context to correctly resolve file paths?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"name": "CSVTable", "docstring": "The csv-table directive which searches a CSV file from Sphinx project's source\ndirectory when an absolute path is given via :file: option.", "methods": ["run"], "attributes": [], "code_location": {"file": "patches.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/directives", "start_line": 59, "end_line": 82}, "type": "class"}, {"name": "run", "is_method": true, "class_name": "CSVTable", "parameters": ["self"], "calls": ["run", "startswith", "Path", "filename.exists", "logger.warning", "relpath", "super", "__", "env.doc2path"], "code_location": {"file": "patches.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/directives", "start_line": 64, "end_line": 82}, "code_snippet": "    def run(self) -> list[Node]:\n        if 'file' in self.options and self.options['file'].startswith((SEP, os.sep)):\n            env = self.state.document.settings.env\n            filename = Path(self.options['file'])\n            if filename.exists():\n                logger.warning(\n                    __(\n                        '\":file:\" option for csv-table directive now recognizes '\n                        'an absolute path as a relative path from source directory. '\n                        'Please update your document.'\n                    ),\n                    location=(env.current_document.docname, self.lineno),\n                )\n            else:\n                abspath = env.srcdir / self.options['file'][1:]\n                doc_dir = env.doc2path(env.current_document.docname).parent\n                self.options['file'] = relpath(abspath, doc_dir)\n\n        return super().run()\n", "type": "function"}, {"name": "DependenciesCollector", "docstring": "dependencies collector for sphinx.environment.", "methods": ["clear_doc", "merge_other", "process_doc"], "attributes": [], "code_location": {"file": "dependencies.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/environment/collectors", "start_line": 21, "end_line": 50}, "type": "class"}, {"name": "run", "is_method": true, "class_name": "Include", "parameters": ["self"], "calls": ["self.env.events.listeners.get", "self.env.relfn2path", "str", "self.env.note_included", "run", "join", "Path", "self.env.events.emit", "StateMachine.insert_input", "startswith", "endswith", "run", "relpath", "text.splitlines", "super", "resolve", "super", "Path"], "code_location": {"file": "other.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/directives", "start_line": 376, "end_line": 417}, "code_snippet": "    def run(self) -> Sequence[Node]:\n        # To properly emit \"include-read\" events from included RST text,\n        # we must patch the ``StateMachine.insert_input()`` method.\n        # In the future, docutils will hopefully offer a way for Sphinx\n        # to provide the RST parser to use\n        # when parsing RST text that comes in via Include directive.\n        def _insert_input(include_lines: list[str], source: str) -> None:\n            # First, we need to combine the lines back into text so that\n            # we can send it with the include-read event.\n            # In docutils 0.18 and later, there are two lines at the end\n            # that act as markers.\n            # We must preserve them and leave them out of the include-read event:\n            text = '\\n'.join(include_lines[:-2])\n\n            path = Path(relpath(Path(source).resolve(), start=self.env.srcdir))\n            docname = self.env.current_document.docname\n\n            # Emit the \"include-read\" event\n            arg = [text]\n            self.env.events.emit('include-read', path, docname, arg)\n            text = arg[0]\n\n            # Split back into lines and reattach the two marker lines\n            include_lines = text.splitlines() + include_lines[-2:]\n\n            # Call the parent implementation.\n            # Note that this snake does not eat its tail because we patch\n            # the *Instance* method and this call is to the *Class* method.\n            return StateMachine.insert_input(self.state_machine, include_lines, source)\n\n        # Only enable this patch if there are listeners for 'include-read'.\n        if self.env.events.listeners.get('include-read'):\n            # See https://github.com/python/mypy/issues/2427 for details on the mypy issue\n            self.state_machine.insert_input = _insert_input\n\n        if self.arguments[0].startswith('<') and self.arguments[0].endswith('>'):\n            # docutils \"standard\" includes, do not do path processing\n            return super().run()\n        _rel_filename, filename = self.env.relfn2path(self.arguments[0])\n        self.arguments[0] = str(filename)\n        self.env.note_included(filename)\n        return super().run()\n", "type": "function"}, {"name": "Include", "docstring": "Like the standard \"Include\" directive, but interprets absolute paths\n\"correctly\", i.e. relative to source directory.", "methods": ["run"], "attributes": [], "code_location": {"file": "other.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/directives", "start_line": 371, "end_line": 417}, "type": "class"}, {"name": "RecipeDirective", "docstring": "A custom directive that describes a recipe.", "methods": ["handle_signature", "add_target_and_index"], "attributes": ["has_content", "required_arguments", "option_spec"], "code_location": {"file": "recipe.py", "path": "/data3/pwh/swebench-repos/sphinx/doc/development/tutorials/examples", "start_line": 14, "end_line": 33}, "type": "class"}, {"name": "BuildEnvironment", "docstring": "The environment in which the ReST files are translated.\nStores an inventory of cross-file targets and provides doctree\ntransformations to resolve links to them.", "methods": ["__init__", "__getstate__", "__setstate__", "setup", "app", "app", "app", "_registry", "_tags", "_config_status", "_update_settings", "set_versioning_method", "clear_doc", "merge_info_from", "path2doc", "doc2path", "relfn2path", "found_docs", "find_files", "get_outdated_files", "check_dependents", "prepare_settings", "temp_data", "docname", "parser", "new_serialno", "note_dependency", "note_included", "note_reread", "get_domain", "get_doctree", "master_doctree", "get_and_resolve_doctree", "resolve_toctree", "resolve_references", "apply_post_transforms", "collect_relations", "check_consistency"], "attributes": ["srcdir", "doctreedir"], "code_location": {"file": "__init__.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/environment", "start_line": 100, "end_line": 812}, "type": "class"}, {"name": "test_record_dependencies_cleared", "is_method": false, "class_name": null, "parameters": ["app"], "calls": ["pytest.mark.sphinx", "app.builder.read"], "code_location": {"file": "test_environment_record_dependencies.py", "path": "/data3/pwh/swebench-repos/sphinx/tests/test_environment", "start_line": 14, "end_line": 17}, "code_snippet": "def test_record_dependencies_cleared(app: SphinxTestApp) -> None:\n    app.builder.read()\n    assert 'index' not in app.env.dependencies\n    assert app.env.dependencies['api'] == {app.srcdir / 'example_module.py'}\n", "type": "function"}, {"name": "FakeDirective", "docstring": "", "methods": ["__init__"], "attributes": [], "code_location": {"file": "__init__.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/ext/autosummary", "start_line": 173, "end_line": 182}, "type": "class"}, {"name": "InheritanceDiagram", "docstring": "Run when the inheritance_diagram directive is first encountered.", "methods": ["run"], "attributes": ["has_content", "required_arguments", "optional_arguments", "final_argument_whitespace"], "code_location": {"file": "inheritance_diagram.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/ext", "start_line": 391, "end_line": 453}, "type": "class"}], "retrieved_count": 10, "cost_time": 1.0948600769042969}
{"question": "How should the mechanism that resolves parameter type annotations in docstrings be refactored to remove duplicate parsing when multiple type field tags describe the same type for keyword-only arguments?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"name": "augment_descriptions_with_types", "is_method": false, "class_name": null, "parameters": ["node", "annotations", "force_rtype"], "calls": ["cast", "set", "set", "annotations.items", "astext", "re.split", "nodes.field", "nodes.field_name", "nodes.field_body", "nodes.field", "nodes.field_name", "nodes.field_body", "len", "has_description.add", "join", "has_type.add", "nodes.paragraph", "nodes.paragraph", "len", "join", "has_description.add", "has_type.add", "has_description.add", "has_type.add"], "code_location": {"file": "typehints.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/ext/autodoc", "start_line": 179, "end_line": 232}, "code_snippet": "def augment_descriptions_with_types(\n    node: nodes.field_list,\n    annotations: dict[str, str],\n    force_rtype: bool,\n) -> None:\n    fields = cast('Iterable[nodes.field]', node)\n    has_description: set[str] = set()\n    has_type: set[str] = set()\n    for field in fields:\n        field_name = field[0].astext()\n        parts = re.split(' +', field_name)\n        if parts[0] == 'param':\n            if len(parts) == 2:\n                # :param xxx:\n                has_description.add(parts[1])\n            elif len(parts) > 2:\n                # :param xxx yyy:\n                name = ' '.join(parts[2:])\n                has_description.add(name)\n                has_type.add(name)\n        elif parts[0] == 'type':\n            name = ' '.join(parts[1:])\n            has_type.add(name)\n        elif parts[0] in {'return', 'returns'}:\n            has_description.add('return')\n        elif parts[0] == 'rtype':\n            has_type.add('return')\n\n    # Add 'type' for parameters with a description but no declared type.\n    for name, annotation in annotations.items():\n        if name in {'return', 'returns'}:\n            continue\n\n        if '*' + name in has_description:\n            name = '*' + name\n        elif '**' + name in has_description:\n            name = '**' + name\n\n        if name in has_description and name not in has_type:\n            field = nodes.field()\n            field += nodes.field_name('', 'type ' + name)\n            field += nodes.field_body('', nodes.paragraph('', annotation))\n            node += field\n\n    # Add 'rtype' if 'return' is present and 'rtype' isn't.\n    if 'return' in annotations:\n        rtype = annotations['return']\n        if 'return' not in has_type and (\n            'return' in has_description or (force_rtype and rtype != 'None')\n        ):\n            field = nodes.field()\n            field += nodes.field_name('', 'rtype')\n            field += nodes.field_body('', nodes.paragraph('', rtype))\n            node += field\n", "type": "function"}, {"name": "modify_field_list", "is_method": false, "class_name": null, "parameters": ["node", "annotations", "suppress_rtype"], "calls": ["cast", "annotations.items", "astext", "re.split", "nodes.field", "nodes.field_name", "nodes.field_body", "arguments.get", "arg.get", "nodes.field", "nodes.field_name", "nodes.field_body", "arg.get", "nodes.field", "nodes.field_name", "nodes.field_body", "nodes.paragraph", "len", "arguments.setdefault", "join", "arguments.setdefault", "arguments.get", "arguments.get", "nodes.paragraph", "nodes.paragraph", "len", "join", "arguments.setdefault"], "code_location": {"file": "typehints.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/ext/autodoc", "start_line": 118, "end_line": 176}, "code_snippet": "def modify_field_list(\n    node: nodes.field_list, annotations: dict[str, str], suppress_rtype: bool = False\n) -> None:\n    arguments: dict[str, dict[str, bool]] = {}\n    fields = cast('Iterable[nodes.field]', node)\n    for field in fields:\n        field_name = field[0].astext()\n        parts = re.split(' +', field_name)\n        if parts[0] == 'param':\n            if len(parts) == 2:\n                # :param xxx:\n                arg = arguments.setdefault(parts[1], {})\n                arg['param'] = True\n            elif len(parts) > 2:\n                # :param xxx yyy:\n                name = ' '.join(parts[2:])\n                arg = arguments.setdefault(name, {})\n                arg['param'] = True\n                arg['type'] = True\n        elif parts[0] == 'type':\n            name = ' '.join(parts[1:])\n            arg = arguments.setdefault(name, {})\n            arg['type'] = True\n        elif parts[0] == 'rtype':\n            arguments['return'] = {'type': True}\n\n    for name, annotation in annotations.items():\n        if name == 'return':\n            continue\n\n        if '*' + name in arguments:\n            name = '*' + name\n            arguments.get(name)\n        elif '**' + name in arguments:\n            name = '**' + name\n            arguments.get(name)\n        else:\n            arg = arguments.get(name, {})\n\n        if not arg.get('type'):\n            field = nodes.field()\n            field += nodes.field_name('', 'type ' + name)\n            field += nodes.field_body('', nodes.paragraph('', annotation))\n            node += field\n        if not arg.get('param'):\n            field = nodes.field()\n            field += nodes.field_name('', 'param ' + name)\n            field += nodes.field_body('', nodes.paragraph('', ''))\n            node += field\n\n    if 'return' in annotations and 'return' not in arguments:\n        annotation = annotations['return']\n        if annotation == 'None' and suppress_rtype:\n            return\n\n        field = nodes.field()\n        field += nodes.field_name('', 'rtype')\n        field += nodes.field_body('', nodes.paragraph('', annotation))\n        node += field\n", "type": "function"}, {"name": "merge_typehints", "is_method": false, "class_name": null, "parameters": ["app", "domain", "objtype", "contentnode"], "calls": ["annotations.get", "cast", "insert_field_list", "field_lists.append", "isinstance", "modify_field_list", "modify_field_list", "augment_descriptions_with_types", "augment_descriptions_with_types"], "code_location": {"file": "typehints.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/ext/autodoc", "start_line": 62, "end_line": 102}, "code_snippet": "def merge_typehints(\n    app: Sphinx, domain: str, objtype: str, contentnode: Element\n) -> None:\n    if domain != 'py':\n        return\n    if app.config.autodoc_typehints not in {'both', 'description'}:\n        return\n\n    try:\n        signature = cast('addnodes.desc_signature', contentnode.parent[0])\n        if signature['module']:\n            fullname = f'{signature[\"module\"]}.{signature[\"fullname\"]}'\n        else:\n            fullname = signature['fullname']\n    except KeyError:\n        # signature node does not have valid context info for the target object\n        return\n\n    annotations = app.env.current_document.autodoc_annotations\n    if annotations.get(fullname, {}):\n        field_lists = [n for n in contentnode if isinstance(n, nodes.field_list)]\n        if field_lists == []:\n            field_list = insert_field_list(contentnode)\n            field_lists.append(field_list)\n\n        for field_list in field_lists:\n            if app.config.autodoc_typehints_description_target == 'all':\n                if objtype == 'class':\n                    modify_field_list(\n                        field_list, annotations[fullname], suppress_rtype=True\n                    )\n                else:\n                    modify_field_list(field_list, annotations[fullname])\n            elif app.config.autodoc_typehints_description_target == 'documented_params':\n                augment_descriptions_with_types(\n                    field_list, annotations[fullname], force_rtype=True\n                )\n            else:\n                augment_descriptions_with_types(\n                    field_list, annotations[fullname], force_rtype=False\n                )\n", "type": "function"}, {"name": "_patch_python_domain", "is_method": false, "class_name": null, "parameters": [], "calls": ["PyObject.doc_field_types.append", "PyTypedField", "_"], "code_location": {"file": "__init__.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/ext/napoleon", "start_line": 344, "end_line": 361}, "code_snippet": "def _patch_python_domain() -> None:\n    from sphinx.domains.python._object import PyObject, PyTypedField\n    from sphinx.locale import _\n\n    for doc_field in PyObject.doc_field_types:\n        if doc_field.name == 'parameter':\n            doc_field.names = ('param', 'parameter', 'arg', 'argument')\n            break\n    PyObject.doc_field_types.append(\n        PyTypedField(\n            'keyword',\n            label=_('Keyword Arguments'),\n            names=('keyword', 'kwarg', 'kwparam'),\n            typerolename='class',\n            typenames=('paramtype', 'kwtype'),\n            can_collapse=True,\n        )\n    )\n", "type": "function"}, {"name": "_consume_field", "is_method": true, "class_name": "NumpyDocstring", "parameters": ["self", "parse_type", "prefer_type"], "calls": ["self._lines.next", "self._escape_args_and_kwargs", "self._dedent", "lines", "self._partition_field_on_colon", "_name.strip", "_type.strip", "self._lookup_annotation", "_convert_type_spec", "self._get_indent", "self._consume_indented_block", "self.__class__", "self._get_location"], "code_location": {"file": "docstring.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/ext/napoleon", "start_line": 1225, "end_line": 1252}, "code_snippet": "    def _consume_field(\n        self, parse_type: bool = True, prefer_type: bool = False\n    ) -> tuple[str, str, list[str]]:\n        line = self._lines.next()\n        if parse_type:\n            _name, _, _type = self._partition_field_on_colon(line)\n        else:\n            _name, _type = line, ''\n        _name, _type = _name.strip(), _type.strip()\n        _name = self._escape_args_and_kwargs(_name)\n\n        if parse_type and not _type:\n            _type = self._lookup_annotation(_name)\n\n        if prefer_type and not _type:\n            _type, _name = _name, _type\n\n        if self._config.napoleon_preprocess_types:\n            _type = _convert_type_spec(\n                _type,\n                translations=self._config.napoleon_type_aliases or {},\n                debug_location=self._get_location(),\n            )\n\n        indent = self._get_indent(line) + 1\n        _desc = self._dedent(self._consume_indented_block(indent))\n        _desc = self.__class__(_desc, self._config).lines()\n        return _name, _type, _desc\n", "type": "function"}, {"name": "test_parse_annotation_suppress", "is_method": false, "class_name": null, "parameters": ["app"], "calls": ["pytest.mark.sphinx", "_parse_annotation", "assert_node", "assert_node"], "code_location": {"file": "test_domain_py.py", "path": "/data3/pwh/swebench-repos/sphinx/tests/test_domains", "start_line": 540, "end_line": 556}, "code_snippet": "def test_parse_annotation_suppress(app):\n    doctree = _parse_annotation('~typing.Dict[str, str]', app.env)\n    assert_node(\n        doctree,\n        (\n            [pending_xref, 'Dict'],\n            [desc_sig_punctuation, '['],\n            [pending_xref, 'str'],\n            [desc_sig_punctuation, ','],\n            desc_sig_space,\n            [pending_xref, 'str'],\n            [desc_sig_punctuation, ']'],\n        ),\n    )\n    assert_node(\n        doctree[0], pending_xref, refdomain='py', reftype='obj', reftarget='typing.Dict'\n    )\n", "type": "function"}, {"name": "test_parse_annotation", "is_method": false, "class_name": null, "parameters": ["app"], "calls": ["pytest.mark.sphinx", "_parse_annotation", "assert_node", "assert_node", "_parse_annotation", "assert_node", "_parse_annotation", "assert_node", "_parse_annotation", "assert_node", "_parse_annotation", "assert_node", "_parse_annotation", "assert_node", "_parse_annotation", "assert_node", "_parse_annotation", "assert_node", "_parse_annotation", "assert_node", "assert_node", "_parse_annotation", "assert_node", "assert_node", "_parse_annotation", "assert_node", "_parse_annotation", "assert_node", "assert_node"], "code_location": {"file": "test_domain_py.py", "path": "/data3/pwh/swebench-repos/sphinx/tests/test_domains", "start_line": 358, "end_line": 536}, "code_snippet": "def test_parse_annotation(app):\n    doctree = _parse_annotation('int', app.env)\n    assert_node(doctree, ([pending_xref, 'int'],))\n    assert_node(\n        doctree[0], pending_xref, refdomain='py', reftype='class', reftarget='int'\n    )\n\n    doctree = _parse_annotation('List[int]', app.env)\n    assert_node(\n        doctree,\n        (\n            [pending_xref, 'List'],\n            [desc_sig_punctuation, '['],\n            [pending_xref, 'int'],\n            [desc_sig_punctuation, ']'],\n        ),\n    )\n\n    doctree = _parse_annotation('Tuple[int, int]', app.env)\n    assert_node(\n        doctree,\n        (\n            [pending_xref, 'Tuple'],\n            [desc_sig_punctuation, '['],\n            [pending_xref, 'int'],\n            [desc_sig_punctuation, ','],\n            desc_sig_space,\n            [pending_xref, 'int'],\n            [desc_sig_punctuation, ']'],\n        ),\n    )\n\n    doctree = _parse_annotation('Tuple[()]', app.env)\n    assert_node(\n        doctree,\n        (\n            [pending_xref, 'Tuple'],\n            [desc_sig_punctuation, '['],\n            [desc_sig_punctuation, '('],\n            [desc_sig_punctuation, ')'],\n            [desc_sig_punctuation, ']'],\n        ),\n    )\n\n    doctree = _parse_annotation('Tuple[int, ...]', app.env)\n    assert_node(\n        doctree,\n        (\n            [pending_xref, 'Tuple'],\n            [desc_sig_punctuation, '['],\n            [pending_xref, 'int'],\n            [desc_sig_punctuation, ','],\n            desc_sig_space,\n            [desc_sig_punctuation, '...'],\n            [desc_sig_punctuation, ']'],\n        ),\n    )\n\n    doctree = _parse_annotation('Callable[[int, int], int]', app.env)\n    assert_node(\n        doctree,\n        (\n            [pending_xref, 'Callable'],\n            [desc_sig_punctuation, '['],\n            [desc_sig_punctuation, '['],\n            [pending_xref, 'int'],\n            [desc_sig_punctuation, ','],\n            desc_sig_space,\n            [pending_xref, 'int'],\n            [desc_sig_punctuation, ']'],\n            [desc_sig_punctuation, ','],\n            desc_sig_space,\n            [pending_xref, 'int'],\n            [desc_sig_punctuation, ']'],\n        ),\n    )\n\n    doctree = _parse_annotation('Callable[[], int]', app.env)\n    assert_node(\n        doctree,\n        (\n            [pending_xref, 'Callable'],\n            [desc_sig_punctuation, '['],\n            [desc_sig_punctuation, '['],\n            [desc_sig_punctuation, ']'],\n            [desc_sig_punctuation, ','],\n            desc_sig_space,\n            [pending_xref, 'int'],\n            [desc_sig_punctuation, ']'],\n        ),\n    )\n\n    doctree = _parse_annotation('List[None]', app.env)\n    assert_node(\n        doctree,\n        (\n            [pending_xref, 'List'],\n            [desc_sig_punctuation, '['],\n            [pending_xref, 'None'],\n            [desc_sig_punctuation, ']'],\n        ),\n    )\n\n    # None type makes an object-reference (not a class reference)\n    doctree = _parse_annotation('None', app.env)\n    assert_node(doctree, ([pending_xref, 'None'],))\n    assert_node(\n        doctree[0], pending_xref, refdomain='py', reftype='obj', reftarget='None'\n    )\n\n    # Literal type makes an object-reference (not a class reference)\n    doctree = _parse_annotation(\"typing.Literal['a', 'b']\", app.env)\n    assert_node(\n        doctree,\n        (\n            [pending_xref, 'Literal'],\n            [desc_sig_punctuation, '['],\n            [desc_sig_literal_string, \"'a'\"],\n            [desc_sig_punctuation, ','],\n            desc_sig_space,\n            [desc_sig_literal_string, \"'b'\"],\n            [desc_sig_punctuation, ']'],\n        ),\n    )\n    assert_node(\n        doctree[0],\n        pending_xref,\n        refdomain='py',\n        reftype='obj',\n        reftarget='typing.Literal',\n    )\n\n    # Annotated type with callable gets parsed\n    doctree = _parse_annotation(\n        'Annotated[Optional[str], annotated_types.MaxLen(max_length=10)]', app.env\n    )\n    assert_node(\n        doctree,\n        (\n            [pending_xref, 'Annotated'],\n            [desc_sig_punctuation, '['],\n            [pending_xref, 'str'],\n            [desc_sig_space, ' '],\n            [desc_sig_punctuation, '|'],\n            [desc_sig_space, ' '],\n            [pending_xref, 'None'],\n            [desc_sig_punctuation, ','],\n            [desc_sig_space, ' '],\n            [pending_xref, 'annotated_types.MaxLen'],\n            [desc_sig_punctuation, '('],\n            [desc_sig_name, 'max_length'],\n            [desc_sig_operator, '='],\n            [desc_sig_literal_number, '10'],\n            [desc_sig_punctuation, ')'],\n            [desc_sig_punctuation, ']'],\n        ),\n    )\n\n    doctree = _parse_annotation('*tuple[str, int]', app.env)\n    assert_node(\n        doctree,\n        (\n            [desc_sig_operator, '*'],\n            [pending_xref, 'tuple'],\n            [desc_sig_punctuation, '['],\n            [pending_xref, 'str'],\n            [desc_sig_punctuation, ','],\n            desc_sig_space,\n            [pending_xref, 'int'],\n            [desc_sig_punctuation, ']'],\n        ),\n    )\n    assert_node(\n        doctree[1],\n        pending_xref,\n        refdomain='py',\n        reftype='class',\n        reftarget='tuple',\n    )\n", "type": "function"}, {"name": "_transform_step_1", "is_method": true, "class_name": "DocFieldTransformer", "parameters": ["self", "field", "entries", "types", "group_indices"], "calls": ["cast", "cast", "self.typemap.get", "_is_single_paragraph", "nodes.inline", "len", "split", "cast", "nodes.Text", "entries.append", "typedesc.make_entry", "append", "typedesc.make_entry", "entries.append", "bool", "upper", "isinstance", "cast", "astext", "typed_field.make_xrefs", "_is_single_paragraph", "fieldarg.rsplit", "cast", "len", "entries.append", "field_name.astext", "field_name.astext", "len", "cast", "paragraph.clear", "paragraph.extend", "field_body.clear", "nodes.paragraph", "isinstance", "types.setdefault", "types.setdefault", "nodes.Text"], "code_location": {"file": "docfields.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/util", "start_line": 377, "end_line": 482}, "code_snippet": "    def _transform_step_1(\n        self,\n        field: nodes.field,\n        entries: list[nodes.field | _EntriesTriple],\n        types: dict[str, _FieldTypes],\n        group_indices: dict[str, int],\n    ) -> None:\n        assert len(field) == 2\n        field_name = cast('nodes.field_name', field[0])\n        field_body = cast('nodes.field_body', field[1])\n        try:\n            # split into field type and argument\n            fieldtype_name, fieldarg = field_name.astext().split(None, maxsplit=1)\n        except ValueError:\n            # maybe an argument-less field type?\n            fieldtype_name, fieldarg = field_name.astext(), ''\n        typedesc, is_typefield = self.typemap.get(fieldtype_name, (None, None))\n\n        # collect the content, trying not to keep unnecessary paragraphs\n        if _is_single_paragraph(field_body):\n            paragraph = cast('nodes.paragraph', field_body[0])\n            content = paragraph.children\n        else:\n            content = field_body.children\n\n        # sort out unknown fields\n        if typedesc is None or typedesc.has_arg != bool(fieldarg):\n            # either the field name is unknown, or the argument doesn't\n            # match the spec; capitalize field name and be done with it\n            new_fieldname = fieldtype_name[0:1].upper() + fieldtype_name[1:]\n            if fieldarg:\n                new_fieldname += ' ' + fieldarg\n            field_name[0] = nodes.Text(new_fieldname)\n            entries.append(field)\n\n            # but if this has a type then we can at least link it\n            if (\n                typedesc\n                and is_typefield\n                and content\n                and len(content) == 1\n                and isinstance(content[0], nodes.Text)\n            ):\n                typed_field = cast('TypedField', typedesc)\n                target = content[0].astext()\n                xrefs = typed_field.make_xrefs(\n                    typed_field.typerolename,\n                    self.directive.domain or '',\n                    target,\n                    contnode=content[0],\n                    env=self.directive.env,\n                )\n                if _is_single_paragraph(field_body):\n                    paragraph = cast('nodes.paragraph', field_body[0])\n                    paragraph.clear()\n                    paragraph.extend(xrefs)\n                else:\n                    field_body.clear()\n                    field_body += nodes.paragraph('', '', *xrefs)\n\n            return\n\n        typename = typedesc.name\n\n        # if the field specifies a type, put it in the types collection\n        if is_typefield:\n            # filter out only inline nodes; others will result in invalid\n            # markup being written out\n            content = [n for n in content if isinstance(n, nodes.Inline | nodes.Text)]\n            if content:\n                types.setdefault(typename, {})[fieldarg] = content\n            return\n\n        # also support syntax like ``:param type name:``\n        if typedesc.is_typed:\n            try:\n                argtype, argname = fieldarg.rsplit(None, 1)\n            except ValueError:\n                pass\n            else:\n                types.setdefault(typename, {})[argname] = [nodes.Text(argtype)]\n                fieldarg = argname\n\n        translatable_content = nodes.inline(field_body.rawsource, translatable=True)\n        translatable_content.document = field_body.parent.document\n        translatable_content.source = field_body.parent.source\n        translatable_content.line = field_body.parent.line\n        translatable_content += content\n\n        # grouped entries need to be collected in one entry, while others\n        # get one entry per field\n        if typedesc.is_grouped:\n            if typename in group_indices:\n                group = cast(\n                    'tuple[Field, list[_FieldEntry], Node]',\n                    entries[group_indices[typename]],\n                )\n            else:\n                group_indices[typename] = len(entries)\n                group = (typedesc, [], field)\n                entries.append(group)\n            new_entry = typedesc.make_entry(fieldarg, [translatable_content])\n            group[1].append(new_entry)\n        else:\n            new_entry = typedesc.make_entry(fieldarg, [translatable_content])\n            entries.append((typedesc, new_entry, field))\n", "type": "function"}, {"name": "_consume_field", "is_method": true, "class_name": "GoogleDocstring", "parameters": ["self", "parse_type", "prefer_type"], "calls": ["self._lines.next", "self._partition_field_on_colon", "self._escape_args_and_kwargs", "lines", "_google_typed_arg_regex.match", "_convert_type_spec", "self._get_indent", "strip", "match.group", "self._dedent", "self.__class__", "self._get_location", "self._consume_indented_block", "match.group"], "code_location": {"file": "docstring.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/ext/napoleon", "start_line": 472, "end_line": 503}, "code_snippet": "    def _consume_field(\n        self,\n        parse_type: bool = True,\n        prefer_type: bool = False,\n    ) -> tuple[str, str, list[str]]:\n        line = self._lines.next()\n\n        before, _colon, after = self._partition_field_on_colon(line)\n        _name, _type, _desc = before, '', after\n\n        if parse_type:\n            match = _google_typed_arg_regex.match(before)\n            if match:\n                _name = match.group(1).strip()\n                _type = match.group(2)\n\n        _name = self._escape_args_and_kwargs(_name)\n\n        if prefer_type and not _type:\n            _type, _name = _name, _type\n\n        if _type and self._config.napoleon_preprocess_types:\n            _type = _convert_type_spec(\n                _type,\n                translations=self._config.napoleon_type_aliases or {},\n                debug_location=self._get_location(),\n            )\n\n        indent = self._get_indent(line) + 1\n        _descs = [_desc, *self._dedent(self._consume_indented_block(indent))]\n        _descs = self.__class__(_descs, self._config).lines()\n        return _name, _type, _descs\n", "type": "function"}, {"name": "_parse_annotation", "is_method": false, "class_name": null, "parameters": ["annotation", "env"], "calls": ["isinstance", "isinstance", "isinstance", "isinstance", "isinstance", "isinstance", "isinstance", "isinstance", "isinstance", "isinstance", "isinstance", "isinstance", "isinstance", "isinstance", "isinstance", "SyntaxError", "isinstance", "ast.parse", "unparse", "unparse", "result.extend", "result.extend", "isinstance", "isinstance", "isinstance", "unparse", "result.extend", "result.append", "functools.reduce", "unparse", "result.append", "result.extend", "result.append", "flattened.extend", "flattened.extend", "getattr", "flattened.extend", "flattened.append", "isinstance", "nodes.Text", "unparse", "unparse", "addnodes.desc_sig_space", "addnodes.desc_sig_punctuation", "addnodes.desc_sig_space", "addnodes.desc_sig_operator", "unparse", "addnodes.desc_sig_punctuation", "addnodes.desc_sig_punctuation", "addnodes.desc_sig_punctuation", "result.pop", "result.pop", "addnodes.desc_sig_punctuation", "nodes.Text", "getattr", "_unparse_pep_604_annotation", "_unparse_pep_604_annotation", "addnodes.desc_sig_punctuation", "unparse", "addnodes.desc_sig_punctuation", "enumerate", "unparse", "unparse", "result.pop", "result.pop", "unparse", "args.append", "args.append", "args.append", "args.append", "unparse", "args.append", "args.append", "addnodes.desc_sig_punctuation", "addnodes.desc_sig_punctuation", "unparse", "flattened.extend", "flattened.extend", "unparse", "unparse", "nodes.Text", "result.append", "type_to_xref", "addnodes.desc_sig_punctuation", "addnodes.desc_sig_keyword", "addnodes.desc_sig_literal_number", "addnodes.desc_sig_literal_string", "nodes.Text", "result.extend", "result.append", "result.append", "unparse", "getattr", "isinstance", "result.extend", "result.append", "result.append", "addnodes.desc_sig_punctuation", "addnodes.desc_sig_punctuation", "addnodes.desc_sig_punctuation", "addnodes.desc_sig_space", "addnodes.desc_sig_name", "addnodes.desc_sig_operator", "addnodes.desc_sig_punctuation", "addnodes.desc_sig_space", "unparse", "unparse", "unparse", "ast.BitOr", "isinstance", "node.strip", "result.append", "repr", "repr", "repr", "repr", "unparse", "addnodes.desc_sig_punctuation", "addnodes.desc_sig_space", "nodes.literal", "unparse", "addnodes.desc_sig_punctuation", "addnodes.desc_sig_space", "ast.BitOr", "isinstance", "result.pop", "result.append", "result.append", "astext", "type_to_xref", "type_to_xref", "unparse", "str", "str"], "code_location": {"file": "_annotations.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/domains/python", "start_line": 95, "end_line": 251}, "code_snippet": "def _parse_annotation(annotation: str, env: BuildEnvironment) -> list[Node]:\n    \"\"\"Parse type annotation.\"\"\"\n    short_literals = env.config.python_display_short_literal_types\n\n    def unparse(node: ast.AST) -> list[Node]:\n        if isinstance(node, ast.Attribute):\n            return [nodes.Text(f'{unparse(node.value)[0]}.{node.attr}')]\n        if isinstance(node, ast.BinOp):\n            result: list[Node] = unparse(node.left)\n            result.extend(unparse(node.op))\n            result.extend(unparse(node.right))\n            return result\n        if isinstance(node, ast.BitOr):\n            return [\n                addnodes.desc_sig_space(),\n                addnodes.desc_sig_punctuation('', '|'),\n                addnodes.desc_sig_space(),\n            ]\n        if isinstance(node, ast.Constant):\n            if node.value is Ellipsis:\n                return [addnodes.desc_sig_punctuation('', '...')]\n            if isinstance(node.value, bool):\n                return [addnodes.desc_sig_keyword('', repr(node.value))]\n            if isinstance(node.value, int):\n                return [addnodes.desc_sig_literal_number('', repr(node.value))]\n            if isinstance(node.value, str):\n                return [addnodes.desc_sig_literal_string('', repr(node.value))]\n            else:\n                # handles None, which is further handled by type_to_xref later\n                # and fallback for other types that should be converted\n                return [nodes.Text(repr(node.value))]\n        if isinstance(node, ast.Expr):\n            return unparse(node.value)\n        if isinstance(node, ast.Starred):\n            result = [addnodes.desc_sig_operator('', '*')]\n            result.extend(unparse(node.value))\n            return result\n        if isinstance(node, ast.Invert):\n            return [addnodes.desc_sig_punctuation('', '~')]\n        if isinstance(node, ast.USub):\n            return [addnodes.desc_sig_punctuation('', '-')]\n        if isinstance(node, ast.List):\n            result = [addnodes.desc_sig_punctuation('', '[')]\n            if node.elts:\n                # check if there are elements in node.elts to only pop the\n                # last element of result if the for-loop was run at least\n                # once\n                for elem in node.elts:\n                    result.extend(unparse(elem))\n                    result.append(addnodes.desc_sig_punctuation('', ','))\n                    result.append(addnodes.desc_sig_space())\n                result.pop()\n                result.pop()\n            result.append(addnodes.desc_sig_punctuation('', ']'))\n            return result\n        if isinstance(node, ast.Module):\n            return functools.reduce(operator.iadd, (unparse(e) for e in node.body), [])\n        if isinstance(node, ast.Name):\n            return [nodes.Text(node.id)]\n        if isinstance(node, ast.Subscript):\n            if getattr(node.value, 'id', '') in {'Optional', 'Union'}:\n                return _unparse_pep_604_annotation(node)\n            if short_literals and getattr(node.value, 'id', '') == 'Literal':\n                return _unparse_pep_604_annotation(node)\n            result = unparse(node.value)\n            result.append(addnodes.desc_sig_punctuation('', '['))\n            result.extend(unparse(node.slice))\n            result.append(addnodes.desc_sig_punctuation('', ']'))\n\n            # Wrap the Text nodes inside brackets by literal node if the subscript is a Literal\n            if result[0] in {'Literal', 'typing.Literal'}:\n                for i, subnode in enumerate(result[1:], start=1):\n                    if isinstance(subnode, nodes.Text):\n                        result[i] = nodes.literal('', '', subnode)\n            return result\n        if isinstance(node, ast.UnaryOp):\n            return unparse(node.op) + unparse(node.operand)\n        if isinstance(node, ast.Tuple):\n            if node.elts:\n                result = []\n                for elem in node.elts:\n                    result.extend(unparse(elem))\n                    result.append(addnodes.desc_sig_punctuation('', ','))\n                    result.append(addnodes.desc_sig_space())\n                result.pop()\n                result.pop()\n            else:\n                result = [\n                    addnodes.desc_sig_punctuation('', '('),\n                    addnodes.desc_sig_punctuation('', ')'),\n                ]\n\n            return result\n        if isinstance(node, ast.Call):\n            # Call nodes can be used in Annotated type metadata,\n            # for example Annotated[str, ArbitraryTypeValidator(str, len=10)]\n            args = []\n            for arg in node.args:\n                args += unparse(arg)\n                args.append(addnodes.desc_sig_punctuation('', ','))\n                args.append(addnodes.desc_sig_space())\n            for kwd in node.keywords:\n                args.append(addnodes.desc_sig_name(kwd.arg, kwd.arg))  # type: ignore[arg-type]\n                args.append(addnodes.desc_sig_operator('', '='))\n                args += unparse(kwd.value)\n                args.append(addnodes.desc_sig_punctuation('', ','))\n                args.append(addnodes.desc_sig_space())\n            result = [\n                *unparse(node.func),\n                addnodes.desc_sig_punctuation('', '('),\n                *args[:-2],  # skip the final comma and space\n                addnodes.desc_sig_punctuation('', ')'),\n            ]\n            return result\n        msg = f'unsupported syntax: {node}'\n        raise SyntaxError(msg)  # unsupported syntax\n\n    def _unparse_pep_604_annotation(node: ast.Subscript) -> list[Node]:\n        subscript = node.slice\n\n        flattened: list[Node] = []\n        if isinstance(subscript, ast.Tuple):\n            flattened.extend(unparse(subscript.elts[0]))\n            for elt in subscript.elts[1:]:\n                flattened.extend(unparse(ast.BitOr()))\n                flattened.extend(unparse(elt))\n        else:\n            # e.g. a Union[] inside an Optional[]\n            flattened.extend(unparse(subscript))\n\n        if getattr(node.value, 'id', '') == 'Optional':\n            flattened.extend(unparse(ast.BitOr()))\n            flattened.append(nodes.Text('None'))\n\n        return flattened\n\n    try:\n        tree = ast.parse(annotation, type_comments=True)\n        result: list[Node] = []\n        for node in unparse(tree):\n            if isinstance(node, nodes.literal):\n                result.append(node[0])\n            elif isinstance(node, nodes.Text) and node.strip():\n                if (\n                    result\n                    and isinstance(result[-1], addnodes.desc_sig_punctuation)\n                    and result[-1].astext() == '~'\n                ):\n                    result.pop()\n                    result.append(type_to_xref(str(node), env, suppress_prefix=True))\n                else:\n                    result.append(type_to_xref(str(node), env))\n            else:\n                result.append(node)\n        return result\n    except SyntaxError:\n        return [type_to_xref(annotation, env)]\n", "type": "function"}], "retrieved_count": 10, "cost_time": 1.0812618732452393}
{"question": "What is the dependency of the hash implementation in the C++ postfix member-of-pointer operator AST node class on the nested name attribute's hashability?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"name": "ASTPostfixMemberOfPointer", "docstring": "", "methods": [], "attributes": [], "code_location": {"file": "_ast.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/domains/cpp", "start_line": 775, "end_line": 797}, "type": "class"}, {"name": "ASTPostfixMemberOfPointer", "docstring": "", "methods": ["__init__", "__eq__", "__hash__", "_stringify", "describe_signature", "__init__", "__eq__", "__hash__", "_stringify", "get_id", "describe_signature"], "attributes": [], "code_location": {"file": "_ast.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/domains/c", "start_line": 457, "end_line": 476}, "type": "class"}, {"name": "ASTPostfixMember", "docstring": "", "methods": ["__init__", "__eq__", "__hash__", "_stringify", "get_id", "describe_signature"], "attributes": [], "code_location": {"file": "_ast.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/domains/cpp", "start_line": 750, "end_line": 772}, "type": "class"}, {"name": "__hash__", "is_method": true, "class_name": "ASTNamespace", "parameters": ["self"], "calls": ["hash"], "code_location": {"file": "_ast.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/domains/cpp", "start_line": 4740, "end_line": 4741}, "code_snippet": "    def __hash__(self) -> int:\n        return hash((self.nestedName, self.templatePrefix))\n", "type": "function"}, {"name": "__hash__", "is_method": true, "class_name": "ASTConcept", "parameters": ["self"], "calls": ["hash"], "code_location": {"file": "_ast.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/domains/cpp", "start_line": 3636, "end_line": 3637}, "code_snippet": "    def __hash__(self) -> int:\n        return hash((self.nestedName, self.initializer))\n", "type": "function"}, {"name": "__hash__", "is_method": true, "class_name": "ASTTrailingTypeSpecName", "parameters": ["self"], "calls": ["hash"], "code_location": {"file": "_ast.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/domains/c", "start_line": 799, "end_line": 800}, "code_snippet": "    def __hash__(self) -> int:\n        return hash((self.prefix, self.nestedName))\n", "type": "function"}, {"name": "__eq__", "is_method": true, "class_name": "ASTPostfixMemberOfPointer", "parameters": ["self", "other"], "calls": ["isinstance"], "code_location": {"file": "_ast.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/domains/cpp", "start_line": 779, "end_line": 782}, "code_snippet": "    def __eq__(self, other: object) -> bool:\n        if not isinstance(other, ASTPostfixMemberOfPointer):\n            return NotImplemented\n        return self.name == other.name\n", "type": "function"}, {"name": "__eq__", "is_method": true, "class_name": "ASTPostfixMemberOfPointer", "parameters": ["self", "other"], "calls": ["isinstance"], "code_location": {"file": "_ast.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/domains/c", "start_line": 461, "end_line": 464}, "code_snippet": "    def __eq__(self, other: object) -> bool:\n        if not isinstance(other, ASTPostfixMemberOfPointer):\n            return NotImplemented\n        return self.name == other.name\n", "type": "function"}, {"name": "__eq__", "is_method": true, "class_name": "ASTPostfixMember", "parameters": ["self", "other"], "calls": ["isinstance"], "code_location": {"file": "_ast.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/domains/cpp", "start_line": 754, "end_line": 757}, "code_snippet": "    def __eq__(self, other: object) -> bool:\n        if not isinstance(other, ASTPostfixMember):\n            return NotImplemented\n        return self.name == other.name\n", "type": "function"}, {"name": "__hash__", "is_method": true, "class_name": "ASTParametersQualifiers", "parameters": ["self"], "calls": ["hash"], "code_location": {"file": "_ast.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/domains/cpp", "start_line": 2132, "end_line": 2144}, "code_snippet": "    def __hash__(self) -> int:\n        return hash((\n            self.args,\n            self.volatile,\n            self.const,\n            self.refQual,\n            self.exceptionSpec,\n            self.trailingReturn,\n            self.override,\n            self.final,\n            self.attrs,\n            self.initializer,\n        ))\n", "type": "function"}], "retrieved_count": 10, "cost_time": 1.0886187553405762}
{"question": "What is the integration mechanism between the test function that validates glossary term reference consistency and the translation processing transform system?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"name": "test_gettext_glossary_term_inconsistencies", "is_method": false, "class_name": null, "parameters": ["app"], "calls": ["pytest.mark.sphinx", "pytest.mark.test_params", "app.build", "read_po", "read_po"], "code_location": {"file": "test_intl.py", "path": "/data3/pwh/swebench-repos/sphinx/tests/test_intl", "start_line": 671, "end_line": 681}, "code_snippet": "def test_gettext_glossary_term_inconsistencies(app):\n    app.build()\n    # --- glossary term inconsistencies: regression test for\n    # https://github.com/sphinx-doc/sphinx/issues/1090\n    expect = read_po(\n        app.srcdir / _CATALOG_LOCALE / 'LC_MESSAGES' / 'glossary_terms_inconsistency.po'\n    )\n    actual = read_po(app.outdir / 'glossary_terms_inconsistency.pot')\n    actual_msg_ids = {msg.id for msg in actual if msg.id}  # pyright: ignore[reportUnhashable]\n    for expect_msg in (msg for msg in expect if msg.id):\n        assert expect_msg.id in actual_msg_ids\n", "type": "function"}, {"name": "test_text_glossary_term_inconsistencies", "is_method": false, "class_name": null, "parameters": ["app"], "calls": ["pytest.mark.sphinx", "pytest.mark.test_params", "app.build", "read_text", "getwarning", "re.search", "re.search"], "code_location": {"file": "test_intl.py", "path": "/data3/pwh/swebench-repos/sphinx/tests/test_intl", "start_line": 341, "end_line": 372}, "code_snippet": "def test_text_glossary_term_inconsistencies(app):\n    app.build()\n    # --- glossary term inconsistencies: regression test for\n    # https://github.com/sphinx-doc/sphinx/issues/1090\n    result = (app.outdir / 'glossary_terms_inconsistency.txt').read_text(\n        encoding='utf8'\n    )\n    expect = (\n        '19. I18N WITH GLOSSARY TERMS INCONSISTENCY'\n        '\\n******************************************\\n'\n        '\\n1. LINK TO *SOME NEW TERM*.\\n'\n        '\\n2. LINK TO *TERM NOT IN GLOSSARY*.\\n'\n    )\n    assert result == expect\n\n    warnings = getwarning(app.warning)\n    expected_warning_expr = (\n        '.*/glossary_terms_inconsistency.txt:\\\\d+: '\n        'WARNING: inconsistent term references in translated message.'\n        \" original: \\\\[':term:`Some term`', ':term:`Some other term`'\\\\],\"\n        \" translated: \\\\[':term:`SOME NEW TERM`'\\\\] \\\\[i18n.inconsistent_references\\\\]\\n\"\n    )\n    assert re.search(expected_warning_expr, warnings), (\n        f'{expected_warning_expr!r} did not match {warnings!r}'\n    )\n    expected_warning_expr = (\n        '.*/glossary_terms_inconsistency.txt:\\\\d+:<translated>:1: '\n        \"WARNING: term not in glossary: 'TERM NOT IN GLOSSARY'\"\n    )\n    assert re.search(expected_warning_expr, warnings), (\n        f'{expected_warning_expr!r} did not match {warnings!r}'\n    )\n", "type": "function"}, {"name": "test_text_glossary_term", "is_method": false, "class_name": null, "parameters": ["app"], "calls": ["pytest.mark.sphinx", "pytest.mark.test_params", "app.build", "read_text", "getwarning", "warnings.count"], "code_location": {"file": "test_intl.py", "path": "/data3/pwh/swebench-repos/sphinx/tests/test_intl", "start_line": 305, "end_line": 335}, "code_snippet": "def test_text_glossary_term(app):\n    app.build()\n    # --- glossary terms: regression test for\n    # https://github.com/sphinx-doc/sphinx/issues/1090\n    result = (app.outdir / 'glossary_terms.txt').read_text(encoding='utf8')\n    expect = r\"\"\"18. I18N WITH GLOSSARY TERMS\n****************************\n\nSOME NEW TERM\n   THE CORRESPONDING GLOSSARY\n\nSOME OTHER NEW TERM\n   THE CORRESPONDING GLOSSARY #2\n\nLINK TO *SOME NEW TERM*.\n\nTRANSLATED GLOSSARY SHOULD BE SORTED BY TRANSLATED TERMS:\n\nTRANSLATED TERM XXX\n   DEFINE XXX\n\nTRANSLATED TERM YYY\n   DEFINE YYY\n\nTRANSLATED TERM ZZZ\nVVV\n   DEFINE ZZZ\n\"\"\"\n    assert result == expect\n    warnings = getwarning(app.warning)\n    assert warnings.count('term not in glossary') == 1\n", "type": "function"}, {"name": "test_gettext_glossary_terms", "is_method": false, "class_name": null, "parameters": ["app"], "calls": ["pytest.mark.sphinx", "pytest.mark.test_params", "app.build", "read_po", "read_po", "replace", "app.warning.getvalue"], "code_location": {"file": "test_intl.py", "path": "/data3/pwh/swebench-repos/sphinx/tests/test_intl", "start_line": 655, "end_line": 665}, "code_snippet": "def test_gettext_glossary_terms(app):\n    app.build()\n    # --- glossary terms: regression test for\n    # https://github.com/sphinx-doc/sphinx/issues/1090\n    expect = read_po(app.srcdir / _CATALOG_LOCALE / 'LC_MESSAGES' / 'glossary_terms.po')\n    actual = read_po(app.outdir / 'glossary_terms.pot')\n    actual_msg_ids = {msg.id for msg in actual if msg.id}  # pyright: ignore[reportUnhashable]\n    for expect_msg in (msg for msg in expect if msg.id):\n        assert expect_msg.id in actual_msg_ids\n    warnings = app.warning.getvalue().replace(os.sep, '/')\n    assert 'term not in glossary' not in warnings\n", "type": "function"}, {"name": "update_pending_xrefs", "is_method": true, "class_name": "_NodeUpdater", "parameters": ["self"], "calls": ["self.compare_references", "__", "get_ref_key", "get_ref_key", "items", "self.node.findall", "self.patch.findall", "xref_reftarget_map.get"], "code_location": {"file": "i18n.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/transforms", "start_line": 338, "end_line": 376}, "code_snippet": "    def update_pending_xrefs(self) -> None:\n        # Original pending_xref['reftarget'] contain not-translated\n        # target name, new pending_xref must use original one.\n        # This code restricts to change ref-targets in the translation.\n        old_xrefs = [*self.node.findall(addnodes.pending_xref)]\n        new_xrefs = [*self.patch.findall(addnodes.pending_xref)]\n        self.compare_references(\n            old_xrefs,\n            new_xrefs,\n            __(\n                'inconsistent term references in translated message.'\n                ' original: {0}, translated: {1}'\n            ),\n        )\n\n        xref_reftarget_map: dict[tuple[str, str, str] | None, dict[str, Any]] = {}\n\n        def get_ref_key(node: addnodes.pending_xref) -> tuple[str, str, str] | None:\n            case = node['refdomain'], node['reftype']\n            if case == ('std', 'term'):\n                return None\n            else:\n                return (\n                    node['refdomain'],\n                    node['reftype'],\n                    node['reftarget'],\n                )\n\n        for old in old_xrefs:\n            key = get_ref_key(old)\n            if key:\n                xref_reftarget_map[key] = old.attributes\n        for new in new_xrefs:\n            key = get_ref_key(new)\n            # Copy attributes to keep original node behavior. Especially\n            # copying 'reftarget', 'py:module', 'py:class' are needed.\n            for k, v in xref_reftarget_map.get(key, {}).items():\n                if k not in EXCLUDED_PENDING_XREF_ATTRIBUTES:\n                    new[k] = v\n", "type": "function"}, {"name": "test_gettext_definition_terms", "is_method": false, "class_name": null, "parameters": ["app"], "calls": ["pytest.mark.sphinx", "pytest.mark.test_params", "app.build", "read_po", "read_po"], "code_location": {"file": "test_intl.py", "path": "/data3/pwh/swebench-repos/sphinx/tests/test_intl", "start_line": 638, "end_line": 649}, "code_snippet": "def test_gettext_definition_terms(app):\n    app.build()\n    # --- definition terms: regression test for\n    # https://github.com/sphinx-doc/sphinx/issues/2198,\n    # https://github.com/sphinx-doc/sphinx/issues/2205\n    expect = read_po(\n        app.srcdir / _CATALOG_LOCALE / 'LC_MESSAGES' / 'definition_terms.po'\n    )\n    actual = read_po(app.outdir / 'definition_terms.pot')\n    actual_msg_ids = {msg.id for msg in actual if msg.id}  # pyright: ignore[reportUnhashable]\n    for expect_msg in (msg for msg in expect if msg.id):\n        assert expect_msg.id in actual_msg_ids\n", "type": "function"}, {"name": "test_glossary_conflicted_labels", "is_method": false, "class_name": null, "parameters": ["app"], "calls": ["pytest.mark.sphinx", "restructuredtext.parse", "list", "app.env.domains.standard_domain.get_objects"], "code_location": {"file": "test_domain_std.py", "path": "/data3/pwh/swebench-repos/sphinx/tests/test_domains", "start_line": 390, "end_line": 394}, "code_snippet": "def test_glossary_conflicted_labels(app: SphinxTestApp) -> None:\n    text = '.. _term-foo:\\n.. glossary::\\n\\n   foo\\n'\n    restructuredtext.parse(app, text)\n    objects = list(app.env.domains.standard_domain.get_objects())\n    assert ('foo', 'foo', 'term', 'index', 'term-0', -1) in objects\n", "type": "function"}, {"name": "test_glossary", "is_method": false, "class_name": null, "parameters": ["app"], "calls": ["pytest.mark.sphinx", "restructuredtext.parse", "assert_node", "assert_node", "assert_node", "assert_node", "assert_node", "assert_node", "assert_node", "assert_node", "list", "domain.resolve_xref", "assert_node", "domain.resolve_xref", "assert_node", "domain.get_objects", "pending_xref", "nodes.paragraph", "pending_xref", "nodes.paragraph"], "code_location": {"file": "test_domain_std.py", "path": "/data3/pwh/swebench-repos/sphinx/tests/test_domains", "start_line": 155, "end_line": 247}, "code_snippet": "def test_glossary(app):\n    text = (\n        '.. glossary::\\n'\n        '\\n'\n        '   term1\\n'\n        '   TERM2\\n'\n        '       description\\n'\n        '\\n'\n        '   term3 : classifier\\n'\n        '       description\\n'\n        '       description\\n'\n        '\\n'\n        '   term4 : class1 : class2\\n'\n        '       description\\n'\n    )\n\n    # doctree\n    doctree = restructuredtext.parse(app, text)\n    assert_node(\n        doctree,\n        (\n            [\n                glossary,\n                definition_list,\n                (\n                    [\n                        definition_list_item,\n                        (\n                            [term, ('term1', index)],\n                            [term, ('TERM2', index)],\n                            definition,\n                        ),\n                    ],\n                    [definition_list_item, ([term, ('term3', index)], definition)],\n                    [definition_list_item, ([term, ('term4', index)], definition)],\n                ),\n            ],\n        ),\n    )\n    assert_node(\n        doctree[0][0][0][0][1],\n        entries=[('single', 'term1', 'term-term1', 'main', None)],\n    )\n    assert_node(\n        doctree[0][0][0][1][1],\n        entries=[('single', 'TERM2', 'term-TERM2', 'main', None)],\n    )\n    assert_node(doctree[0][0][0][2], [definition, nodes.paragraph, 'description'])\n    assert_node(\n        doctree[0][0][1][0][1],\n        entries=[('single', 'term3', 'term-term3', 'main', 'classifier')],\n    )\n    assert_node(\n        doctree[0][0][1][1],\n        [definition, nodes.paragraph, 'description\\ndescription'],\n    )\n    assert_node(\n        doctree[0][0][2][0][1],\n        entries=[('single', 'term4', 'term-term4', 'main', 'class1')],\n    )\n    assert_node(doctree[0][0][2][1], [nodes.definition, nodes.paragraph, 'description'])\n\n    # index\n    domain = app.env.domains.standard_domain\n    objects = list(domain.get_objects())\n    assert ('term1', 'term1', 'term', 'index', 'term-term1', -1) in objects\n    assert ('TERM2', 'TERM2', 'term', 'index', 'term-TERM2', -1) in objects\n    assert ('term3', 'term3', 'term', 'index', 'term-term3', -1) in objects\n    assert ('term4', 'term4', 'term', 'index', 'term-term4', -1) in objects\n\n    # term reference (case sensitive)\n    refnode = domain.resolve_xref(\n        app.env,\n        'index',\n        app.builder,\n        'term',\n        'term1',\n        pending_xref(),\n        nodes.paragraph(),\n    )\n    assert_node(refnode, nodes.reference, refid='term-term1')\n\n    # term reference (case insensitive)\n    refnode = domain.resolve_xref(\n        app.env,\n        'index',\n        app.builder,\n        'term',\n        'term2',\n        pending_xref(),\n        nodes.paragraph(),\n    )\n    assert_node(refnode, nodes.reference, refid='term-TERM2')\n", "type": "function"}, {"name": "test_latex_glossary", "is_method": false, "class_name": null, "parameters": ["app"], "calls": ["pytest.mark.sphinx", "app.build", "read_text"], "code_location": {"file": "test_build_latex.py", "path": "/data3/pwh/swebench-repos/sphinx/tests/test_builders", "start_line": 1883, "end_line": 1913}, "code_snippet": "def test_latex_glossary(app: SphinxTestApp) -> None:\n    app.build(force_all=True)\n\n    result = (app.outdir / 'projectnamenotset.tex').read_text(encoding='utf8')\n    assert (\n        r'\\sphinxlineitem{hnlich\\index{hnlich@\\spxentry{hnlich}|spxpagem}'\n        r'\\phantomsection'\n        r'\\label{\\detokenize{index:term-ahnlich}}}'\n    ) in result\n    assert (\n        r'\\sphinxlineitem{boson\\index{boson@\\spxentry{boson}|spxpagem}\\phantomsection'\n        r'\\label{\\detokenize{index:term-boson}}}'\n    ) in result\n    assert (\n        r'\\sphinxlineitem{\\sphinxstyleemphasis{fermion}'\n        r'\\index{fermion@\\spxentry{fermion}|spxpagem}'\n        r'\\phantomsection'\n        r'\\label{\\detokenize{index:term-fermion}}}'\n    ) in result\n    assert (\n        r'\\sphinxlineitem{tauon\\index{tauon@\\spxentry{tauon}|spxpagem}\\phantomsection'\n        r'\\label{\\detokenize{index:term-tauon}}}'\n        r'\\sphinxlineitem{myon\\index{myon@\\spxentry{myon}|spxpagem}\\phantomsection'\n        r'\\label{\\detokenize{index:term-myon}}}'\n        r'\\sphinxlineitem{electron\\index{electron@\\spxentry{electron}|spxpagem}\\phantomsection'\n        r'\\label{\\detokenize{index:term-electron}}}'\n    ) in result\n    assert (\n        r'\\sphinxlineitem{ber\\index{ber@\\spxentry{ber}|spxpagem}\\phantomsection'\n        r'\\label{\\detokenize{index:term-uber}}}'\n    ) in result\n", "type": "function"}, {"name": "test_xml_role_xref", "is_method": false, "class_name": null, "parameters": ["app"], "calls": ["pytest.mark.sphinx", "pytest.mark.test_params", "app.build", "etree_parse", "et.findall", "sec1.findall", "assert_elem", "sec1.findall", "sec1_1.findall", "assert_elem", "sec2.findall", "assert_elem", "assert_elem", "assert_elem", "assert_elem", "assert_elem", "assert_elem", "assert_elem"], "code_location": {"file": "test_intl.py", "path": "/data3/pwh/swebench-repos/sphinx/tests/test_intl", "start_line": 1336, "end_line": 1407}, "code_snippet": "def test_xml_role_xref(app):\n    app.build()\n    # --- role xref: regression test for\n    # https://github.com/sphinx-doc/sphinx/issues/1090,\n    # https://github.com/sphinx-doc/sphinx/issues/1193\n    et = etree_parse(app.outdir / 'role_xref.xml')\n    sec1, sec2 = et.findall('section')\n\n    (para1,) = sec1.findall('paragraph')\n    assert_elem(\n        para1,\n        [\n            'LINK TO',\n            \"I18N ROCK'N ROLE XREF\",\n            ',',\n            'CONTENTS',\n            ',',\n            'SOME NEW TERM',\n            '.',\n        ],\n        ['i18n-role-xref', 'index', 'glossary_terms#term-Some-term'],\n    )\n\n    (sec1_1,) = sec1.findall('section')\n    (title,) = sec1_1.findall('title')\n    assert_elem(\n        title,\n        [\n            'LINK TO',\n            \"I18N ROCK'N ROLE XREF\",\n            ',',\n            'CONTENTS',\n            ',',\n            'SOME NEW TERM',\n            '.',\n        ],\n        ['i18n-role-xref', 'index', 'glossary_terms#term-Some-term'],\n    )\n\n    para2 = sec2.findall('paragraph')\n    assert_elem(\n        para2[0],\n        ['LINK TO', 'SOME OTHER NEW TERM', 'AND', 'SOME NEW TERM', '.'],\n        ['glossary_terms#term-Some-other-term', 'glossary_terms#term-Some-term'],\n    )\n    assert_elem(\n        para2[1],\n        ['LINK TO', 'LABEL', 'AND', 'SAME TYPE LINKS', 'AND', 'SAME TYPE LINKS', '.'],\n        ['i18n-role-xref', 'same-type-links', 'same-type-links'],\n    )\n    assert_elem(\n        para2[2],\n        ['LINK TO', 'I18N WITH GLOSSARY TERMS', 'AND', 'CONTENTS', '.'],\n        ['glossary_terms', 'index'],\n    )\n    assert_elem(\n        para2[3],\n        ['LINK TO', '--module', 'AND', '-m', '.'],\n        ['cmdoption-module', 'cmdoption-m'],\n    )\n    assert_elem(\n        para2[4],\n        ['LINK TO', 'env2', 'AND', 'env1', '.'],\n        ['envvar-env2', 'envvar-env1'],\n    )\n    # TODO: how do I link token role to productionlist?\n    assert_elem(para2[5], ['LINK TO', 'token2', 'AND', 'token1', '.'], [])\n    assert_elem(\n        para2[6],\n        ['LINK TO', 'same-type-links', 'AND', 'i18n-role-xref', '.'],\n        ['same-type-links', 'i18n-role-xref'],\n    )\n", "type": "function"}], "retrieved_count": 10, "cost_time": 1.1104745864868164}
{"question": "What is the algorithmic approach used by the test function that validates parsing of type delimiters in Napoleon-style docstrings to correctly nest and structure document tree nodes for types representing multiple possible values?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"name": "test_info_field_list_napoleon_deliminator_or", "is_method": false, "class_name": null, "parameters": ["app"], "calls": ["pytest.mark.sphinx", "restructuredtext.parse", "assert_node", "assert_node"], "code_location": {"file": "test_domain_py_fields.py", "path": "/data3/pwh/swebench-repos/sphinx/tests/test_domains", "start_line": 441, "end_line": 483}, "code_snippet": "def test_info_field_list_napoleon_deliminator_or(app):\n    text = (\n        '.. py:module:: example\\n'\n        '.. py:class:: Class\\n'\n        '\\n'\n        '   :param bool_str_var: example description.\\n'\n        '   :type bool_str_var: bool or str\\n'\n        '   :param str_float_int_var: example description.\\n'\n        '   :type str_float_int_var: str or float or int\\n'\n    )\n    doctree = restructuredtext.parse(app, text)\n\n    # :param bool or str bool_str_var:\n    assert_node(\n        doctree[3][1][0][0][1][0][0][0],\n        (\n            [addnodes.literal_strong, 'bool_str_var'],\n            ' (',\n            [pending_xref, addnodes.literal_emphasis, 'bool'],\n            [addnodes.literal_emphasis, ' or '],\n            [pending_xref, addnodes.literal_emphasis, 'str'],\n            ')',\n            ' -- ',\n            'example description.',\n        ),\n    )\n\n    # :param str or float or int str_float_int_var:\n    assert_node(\n        doctree[3][1][0][0][1][0][1][0],\n        (\n            [addnodes.literal_strong, 'str_float_int_var'],\n            ' (',\n            [pending_xref, addnodes.literal_emphasis, 'str'],\n            [addnodes.literal_emphasis, ' or '],\n            [pending_xref, addnodes.literal_emphasis, 'float'],\n            [addnodes.literal_emphasis, ' or '],\n            [pending_xref, addnodes.literal_emphasis, 'int'],\n            ')',\n            ' -- ',\n            'example description.',\n        ),\n    )\n", "type": "function"}, {"name": "test_info_field_list_napoleon_deliminator_of", "is_method": false, "class_name": null, "parameters": ["app"], "calls": ["pytest.mark.sphinx", "restructuredtext.parse", "assert_node", "assert_node"], "code_location": {"file": "test_domain_py_fields.py", "path": "/data3/pwh/swebench-repos/sphinx/tests/test_domains", "start_line": 395, "end_line": 437}, "code_snippet": "def test_info_field_list_napoleon_deliminator_of(app):\n    text = (\n        '.. py:module:: example\\n'\n        '.. py:class:: Class\\n'\n        '\\n'\n        '   :param list_str_var: example description.\\n'\n        '   :type list_str_var: list of str\\n'\n        '   :param tuple_int_var: example description.\\n'\n        '   :type tuple_int_var: tuple of tuple of int\\n'\n    )\n    doctree = restructuredtext.parse(app, text)\n\n    # :param list of str list_str_var:\n    assert_node(\n        doctree[3][1][0][0][1][0][0][0],\n        (\n            [addnodes.literal_strong, 'list_str_var'],\n            ' (',\n            [pending_xref, addnodes.literal_emphasis, 'list'],\n            [addnodes.literal_emphasis, ' of '],\n            [pending_xref, addnodes.literal_emphasis, 'str'],\n            ')',\n            ' -- ',\n            'example description.',\n        ),\n    )\n\n    # :param tuple of tuple of int tuple_int_var:\n    assert_node(\n        doctree[3][1][0][0][1][0][1][0],\n        (\n            [addnodes.literal_strong, 'tuple_int_var'],\n            ' (',\n            [pending_xref, addnodes.literal_emphasis, 'tuple'],\n            [addnodes.literal_emphasis, ' of '],\n            [pending_xref, addnodes.literal_emphasis, 'tuple'],\n            [addnodes.literal_emphasis, ' of '],\n            [pending_xref, addnodes.literal_emphasis, 'int'],\n            ')',\n            ' -- ',\n            'example description.',\n        ),\n    )\n", "type": "function"}, {"name": "test_info_field_list_piped_type", "is_method": false, "class_name": null, "parameters": ["app"], "calls": ["pytest.mark.sphinx", "restructuredtext.parse", "assert_node", "assert_node", "assert_node", "assert_node"], "code_location": {"file": "test_domain_py_fields.py", "path": "/data3/pwh/swebench-repos/sphinx/tests/test_domains", "start_line": 205, "end_line": 278}, "code_snippet": "def test_info_field_list_piped_type(app):\n    text = (\n        '.. py:module:: example\\n'\n        '.. py:class:: Class\\n'\n        '\\n'\n        '   :param age: blah blah\\n'\n        '   :type age: int | str\\n'\n    )\n    doctree = restructuredtext.parse(app, text)\n\n    assert_node(\n        doctree,\n        (\n            addnodes.index,\n            addnodes.index,\n            nodes.target,\n            [\n                desc,\n                (\n                    [\n                        desc_signature,\n                        (\n                            [\n                                desc_annotation,\n                                ([desc_sig_keyword, 'class'], desc_sig_space),\n                            ],\n                            [desc_addname, 'example.'],\n                            [desc_name, 'Class'],\n                        ),\n                    ],\n                    [\n                        desc_content,\n                        nodes.field_list,\n                        nodes.field,\n                        (nodes.field_name, nodes.field_body),\n                    ],\n                ),\n            ],\n        ),\n    )\n    assert_node(\n        doctree[3][1][0][0][1],\n        (\n            [\n                nodes.paragraph,\n                (\n                    [addnodes.literal_strong, 'age'],\n                    ' (',\n                    [pending_xref, addnodes.literal_emphasis, 'int'],\n                    [addnodes.literal_emphasis, ' | '],\n                    [pending_xref, addnodes.literal_emphasis, 'str'],\n                    ')',\n                    ' -- ',\n                    'blah blah',\n                ),\n            ],\n        ),\n    )\n    assert_node(\n        doctree[3][1][0][0][1][0][2],\n        pending_xref,\n        refdomain='py',\n        reftype='class',\n        reftarget='int',\n        **{'py:module': 'example', 'py:class': 'Class'},\n    )\n    assert_node(\n        doctree[3][1][0][0][1][0][4],\n        pending_xref,\n        refdomain='py',\n        reftype='class',\n        reftarget='str',\n        **{'py:module': 'example', 'py:class': 'Class'},\n    )\n", "type": "function"}, {"name": "test_raises_types", "is_method": true, "class_name": "TestNumpyDocstring", "parameters": ["self"], "calls": ["Config", "mock.Mock", "NumpyDocstring", "str"], "code_location": {"file": "test_ext_napoleon_docstring.py", "path": "/data3/pwh/swebench-repos/sphinx/tests/test_extensions", "start_line": 1918, "end_line": 2175}, "code_snippet": "    def test_raises_types(self):\n        docstrings = [\n            (\n                \"\"\"\nExample Function\n\nRaises\n------\n  RuntimeError\n\n      A setting wasn't specified, or was invalid.\n  ValueError\n\n      Something something value error.\n\n\"\"\",\n                \"\"\"\nExample Function\n\n:raises RuntimeError: A setting wasn't specified, or was invalid.\n:raises ValueError: Something something value error.\n\"\"\",\n            ),\n            ################################\n            (\n                \"\"\"\nExample Function\n\nRaises\n------\nInvalidDimensionsError\n\n\"\"\",\n                \"\"\"\nExample Function\n\n:raises InvalidDimensionsError:\n\"\"\",\n            ),\n            ################################\n            (\n                \"\"\"\nExample Function\n\nRaises\n------\nInvalid Dimensions Error\n\n\"\"\",\n                \"\"\"\nExample Function\n\n:raises Invalid Dimensions Error:\n\"\"\",\n            ),\n            ################################\n            (\n                \"\"\"\nExample Function\n\nRaises\n------\nInvalid Dimensions Error\n    With description\n\n\"\"\",\n                \"\"\"\nExample Function\n\n:raises Invalid Dimensions Error: With description\n\"\"\",\n            ),\n            ################################\n            (\n                \"\"\"\nExample Function\n\nRaises\n------\nInvalidDimensionsError\n    If the dimensions couldn't be parsed.\n\n\"\"\",\n                \"\"\"\nExample Function\n\n:raises InvalidDimensionsError: If the dimensions couldn't be parsed.\n\"\"\",\n            ),\n            ################################\n            (\n                \"\"\"\nExample Function\n\nRaises\n------\nInvalid Dimensions Error\n    If the dimensions couldn't be parsed.\n\n\"\"\",\n                \"\"\"\nExample Function\n\n:raises Invalid Dimensions Error: If the dimensions couldn't be parsed.\n\"\"\",\n            ),\n            ################################\n            (\n                \"\"\"\nExample Function\n\nRaises\n------\nIf the dimensions couldn't be parsed.\n\n\"\"\",\n                \"\"\"\nExample Function\n\n:raises If the dimensions couldn't be parsed.:\n\"\"\",\n            ),\n            ################################\n            (\n                \"\"\"\nExample Function\n\nRaises\n------\n:class:`exc.InvalidDimensionsError`\n\n\"\"\",\n                \"\"\"\nExample Function\n\n:raises exc.InvalidDimensionsError:\n\"\"\",\n            ),\n            ################################\n            (\n                \"\"\"\nExample Function\n\nRaises\n------\n:class:`exc.InvalidDimensionsError`\n    If the dimensions couldn't be parsed.\n\n\"\"\",\n                \"\"\"\nExample Function\n\n:raises exc.InvalidDimensionsError: If the dimensions couldn't be parsed.\n\"\"\",\n            ),\n            ################################\n            (\n                \"\"\"\nExample Function\n\nRaises\n------\n:class:`exc.InvalidDimensionsError`\n    If the dimensions couldn't be parsed,\n    then a :class:`exc.InvalidDimensionsError` will be raised.\n\n\"\"\",\n                \"\"\"\nExample Function\n\n:raises exc.InvalidDimensionsError: If the dimensions couldn't be parsed,\n    then a :class:`exc.InvalidDimensionsError` will be raised.\n\"\"\",\n            ),\n            ################################\n            (\n                \"\"\"\nExample Function\n\nRaises\n------\n:class:`exc.InvalidDimensionsError`\n    If the dimensions couldn't be parsed.\n:class:`exc.InvalidArgumentsError`\n    If the arguments are invalid.\n\n\"\"\",\n                \"\"\"\nExample Function\n\n:raises exc.InvalidDimensionsError: If the dimensions couldn't be parsed.\n:raises exc.InvalidArgumentsError: If the arguments are invalid.\n\"\"\",\n            ),\n            ################################\n            (\n                \"\"\"\nExample Function\n\nRaises\n------\nCustomError\n    If the dimensions couldn't be parsed.\n\n\"\"\",\n                \"\"\"\nExample Function\n\n:raises package.CustomError: If the dimensions couldn't be parsed.\n\"\"\",\n            ),\n            ################################\n            (\n                \"\"\"\nExample Function\n\nRaises\n------\nAnotherError\n    If the dimensions couldn't be parsed.\n\n\"\"\",\n                \"\"\"\nExample Function\n\n:raises ~package.AnotherError: If the dimensions couldn't be parsed.\n\"\"\",\n            ),\n            ################################\n            (\n                \"\"\"\nExample Function\n\nRaises\n------\n:class:`exc.InvalidDimensionsError`\n:class:`exc.InvalidArgumentsError`\n\n\"\"\",\n                \"\"\"\nExample Function\n\n:raises exc.InvalidDimensionsError:\n:raises exc.InvalidArgumentsError:\n\"\"\",\n            ),\n        ]\n        for docstring, expected in docstrings:\n            translations = {\n                'CustomError': 'package.CustomError',\n                'AnotherError': ':py:exc:`~package.AnotherError`',\n            }\n            config = Config(\n                napoleon_type_aliases=translations, napoleon_preprocess_types=True\n            )\n            app = mock.Mock()\n            actual = NumpyDocstring(docstring, config, app, 'method')\n            assert str(actual) == expected\n", "type": "function"}, {"name": "test_parameter_types", "is_method": true, "class_name": "TestNumpyDocstring", "parameters": ["self"], "calls": ["dedent", "dedent", "Config", "NumpyDocstring", "str"], "code_location": {"file": "test_ext_napoleon_docstring.py", "path": "/data3/pwh/swebench-repos/sphinx/tests/test_extensions", "start_line": 2687, "end_line": 2742}, "code_snippet": "    def test_parameter_types(self):\n        docstring = dedent(\"\"\"\\\n            Parameters\n            ----------\n            param1 : DataFrame\n                the data to work on\n            param2 : int or float or None, optional\n                a parameter with different types\n            param3 : dict-like, optional\n                a optional mapping\n            param4 : int or float or None, optional\n                a optional parameter with different types\n            param5 : {\"F\", \"C\", \"N\"}, optional\n                a optional parameter with fixed values\n            param6 : int, default None\n                different default format\n            param7 : mapping of hashable to str, optional\n                a optional mapping\n            param8 : ... or Ellipsis\n                ellipsis\n            param9 : tuple of list of int\n                a parameter with tuple of list of int\n        \"\"\")\n        expected = dedent(\"\"\"\\\n            :param param1: the data to work on\n            :type param1: :py:class:`DataFrame`\n            :param param2: a parameter with different types\n            :type param2: :py:class:`int` or :py:class:`float` or :py:obj:`None`, *optional*\n            :param param3: a optional mapping\n            :type param3: :term:`dict-like <mapping>`, *optional*\n            :param param4: a optional parameter with different types\n            :type param4: :py:class:`int` or :py:class:`float` or :py:obj:`None`, *optional*\n            :param param5: a optional parameter with fixed values\n            :type param5: ``{\"F\", \"C\", \"N\"}``, *optional*\n            :param param6: different default format\n            :type param6: :py:class:`int`, *default* :py:obj:`None`\n            :param param7: a optional mapping\n            :type param7: :term:`mapping` of :term:`hashable` to :py:class:`str`, *optional*\n            :param param8: ellipsis\n            :type param8: :py:obj:`... <Ellipsis>` or :py:obj:`Ellipsis`\n            :param param9: a parameter with tuple of list of int\n            :type param9: :py:class:`tuple` of :py:class:`list` of :py:class:`int`\n        \"\"\")\n        translations = {\n            'dict-like': ':term:`dict-like <mapping>`',\n            'mapping': ':term:`mapping`',\n            'hashable': ':term:`hashable`',\n        }\n        config = Config(\n            napoleon_use_param=True,\n            napoleon_use_rtype=True,\n            napoleon_preprocess_types=True,\n            napoleon_type_aliases=translations,\n        )\n        actual = NumpyDocstring(docstring, config)\n        assert str(actual) == expected\n", "type": "function"}, {"name": "test_pydata_with_union_type_operator", "is_method": false, "class_name": null, "parameters": ["app"], "calls": ["pytest.mark.sphinx", "restructuredtext.parse", "assert_node"], "code_location": {"file": "test_domain_py_pyobject.py", "path": "/data3/pwh/swebench-repos/sphinx/tests/test_domains", "start_line": 146, "end_line": 166}, "code_snippet": "def test_pydata_with_union_type_operator(app):\n    text = '.. py:data:: version\\n   :type: int | str'\n    doctree = restructuredtext.parse(app, text)\n    assert_node(\n        doctree[1][0],\n        (\n            [desc_name, 'version'],\n            [\n                desc_annotation,\n                (\n                    [desc_sig_punctuation, ':'],\n                    desc_sig_space,\n                    [pending_xref, 'int'],\n                    desc_sig_space,\n                    [desc_sig_punctuation, '|'],\n                    desc_sig_space,\n                    [pending_xref, 'str'],\n                ),\n            ],\n        ),\n    )\n", "type": "function"}, {"name": "test_parse_annotation", "is_method": false, "class_name": null, "parameters": ["app"], "calls": ["pytest.mark.sphinx", "_parse_annotation", "assert_node", "assert_node", "_parse_annotation", "assert_node", "_parse_annotation", "assert_node", "_parse_annotation", "assert_node", "_parse_annotation", "assert_node", "_parse_annotation", "assert_node", "_parse_annotation", "assert_node", "_parse_annotation", "assert_node", "_parse_annotation", "assert_node", "assert_node", "_parse_annotation", "assert_node", "assert_node", "_parse_annotation", "assert_node", "_parse_annotation", "assert_node", "assert_node"], "code_location": {"file": "test_domain_py.py", "path": "/data3/pwh/swebench-repos/sphinx/tests/test_domains", "start_line": 358, "end_line": 536}, "code_snippet": "def test_parse_annotation(app):\n    doctree = _parse_annotation('int', app.env)\n    assert_node(doctree, ([pending_xref, 'int'],))\n    assert_node(\n        doctree[0], pending_xref, refdomain='py', reftype='class', reftarget='int'\n    )\n\n    doctree = _parse_annotation('List[int]', app.env)\n    assert_node(\n        doctree,\n        (\n            [pending_xref, 'List'],\n            [desc_sig_punctuation, '['],\n            [pending_xref, 'int'],\n            [desc_sig_punctuation, ']'],\n        ),\n    )\n\n    doctree = _parse_annotation('Tuple[int, int]', app.env)\n    assert_node(\n        doctree,\n        (\n            [pending_xref, 'Tuple'],\n            [desc_sig_punctuation, '['],\n            [pending_xref, 'int'],\n            [desc_sig_punctuation, ','],\n            desc_sig_space,\n            [pending_xref, 'int'],\n            [desc_sig_punctuation, ']'],\n        ),\n    )\n\n    doctree = _parse_annotation('Tuple[()]', app.env)\n    assert_node(\n        doctree,\n        (\n            [pending_xref, 'Tuple'],\n            [desc_sig_punctuation, '['],\n            [desc_sig_punctuation, '('],\n            [desc_sig_punctuation, ')'],\n            [desc_sig_punctuation, ']'],\n        ),\n    )\n\n    doctree = _parse_annotation('Tuple[int, ...]', app.env)\n    assert_node(\n        doctree,\n        (\n            [pending_xref, 'Tuple'],\n            [desc_sig_punctuation, '['],\n            [pending_xref, 'int'],\n            [desc_sig_punctuation, ','],\n            desc_sig_space,\n            [desc_sig_punctuation, '...'],\n            [desc_sig_punctuation, ']'],\n        ),\n    )\n\n    doctree = _parse_annotation('Callable[[int, int], int]', app.env)\n    assert_node(\n        doctree,\n        (\n            [pending_xref, 'Callable'],\n            [desc_sig_punctuation, '['],\n            [desc_sig_punctuation, '['],\n            [pending_xref, 'int'],\n            [desc_sig_punctuation, ','],\n            desc_sig_space,\n            [pending_xref, 'int'],\n            [desc_sig_punctuation, ']'],\n            [desc_sig_punctuation, ','],\n            desc_sig_space,\n            [pending_xref, 'int'],\n            [desc_sig_punctuation, ']'],\n        ),\n    )\n\n    doctree = _parse_annotation('Callable[[], int]', app.env)\n    assert_node(\n        doctree,\n        (\n            [pending_xref, 'Callable'],\n            [desc_sig_punctuation, '['],\n            [desc_sig_punctuation, '['],\n            [desc_sig_punctuation, ']'],\n            [desc_sig_punctuation, ','],\n            desc_sig_space,\n            [pending_xref, 'int'],\n            [desc_sig_punctuation, ']'],\n        ),\n    )\n\n    doctree = _parse_annotation('List[None]', app.env)\n    assert_node(\n        doctree,\n        (\n            [pending_xref, 'List'],\n            [desc_sig_punctuation, '['],\n            [pending_xref, 'None'],\n            [desc_sig_punctuation, ']'],\n        ),\n    )\n\n    # None type makes an object-reference (not a class reference)\n    doctree = _parse_annotation('None', app.env)\n    assert_node(doctree, ([pending_xref, 'None'],))\n    assert_node(\n        doctree[0], pending_xref, refdomain='py', reftype='obj', reftarget='None'\n    )\n\n    # Literal type makes an object-reference (not a class reference)\n    doctree = _parse_annotation(\"typing.Literal['a', 'b']\", app.env)\n    assert_node(\n        doctree,\n        (\n            [pending_xref, 'Literal'],\n            [desc_sig_punctuation, '['],\n            [desc_sig_literal_string, \"'a'\"],\n            [desc_sig_punctuation, ','],\n            desc_sig_space,\n            [desc_sig_literal_string, \"'b'\"],\n            [desc_sig_punctuation, ']'],\n        ),\n    )\n    assert_node(\n        doctree[0],\n        pending_xref,\n        refdomain='py',\n        reftype='obj',\n        reftarget='typing.Literal',\n    )\n\n    # Annotated type with callable gets parsed\n    doctree = _parse_annotation(\n        'Annotated[Optional[str], annotated_types.MaxLen(max_length=10)]', app.env\n    )\n    assert_node(\n        doctree,\n        (\n            [pending_xref, 'Annotated'],\n            [desc_sig_punctuation, '['],\n            [pending_xref, 'str'],\n            [desc_sig_space, ' '],\n            [desc_sig_punctuation, '|'],\n            [desc_sig_space, ' '],\n            [pending_xref, 'None'],\n            [desc_sig_punctuation, ','],\n            [desc_sig_space, ' '],\n            [pending_xref, 'annotated_types.MaxLen'],\n            [desc_sig_punctuation, '('],\n            [desc_sig_name, 'max_length'],\n            [desc_sig_operator, '='],\n            [desc_sig_literal_number, '10'],\n            [desc_sig_punctuation, ')'],\n            [desc_sig_punctuation, ']'],\n        ),\n    )\n\n    doctree = _parse_annotation('*tuple[str, int]', app.env)\n    assert_node(\n        doctree,\n        (\n            [desc_sig_operator, '*'],\n            [pending_xref, 'tuple'],\n            [desc_sig_punctuation, '['],\n            [pending_xref, 'str'],\n            [desc_sig_punctuation, ','],\n            desc_sig_space,\n            [pending_xref, 'int'],\n            [desc_sig_punctuation, ']'],\n        ),\n    )\n    assert_node(\n        doctree[1],\n        pending_xref,\n        refdomain='py',\n        reftype='class',\n        reftarget='tuple',\n    )\n", "type": "function"}, {"name": "test_list_in_parameter_description", "is_method": true, "class_name": "TestNumpyDocstring", "parameters": ["self"], "calls": ["Config", "NumpyDocstring", "Config", "NumpyDocstring", "str", "str"], "code_location": {"file": "test_ext_napoleon_docstring.py", "path": "/data3/pwh/swebench-repos/sphinx/tests/test_extensions", "start_line": 2285, "end_line": 2549}, "code_snippet": "    def test_list_in_parameter_description(self):\n        docstring = \"\"\"One line summary.\n\nParameters\n----------\nno_list : int\none_bullet_empty : int\n    *\none_bullet_single_line : int\n    - first line\none_bullet_two_lines : int\n    +   first line\n        continued\ntwo_bullets_single_line : int\n    -  first line\n    -  second line\ntwo_bullets_two_lines : int\n    * first line\n      continued\n    * second line\n      continued\none_enumeration_single_line : int\n    1.  first line\none_enumeration_two_lines : int\n    1)   first line\n         continued\ntwo_enumerations_one_line : int\n    (iii) first line\n    (iv) second line\ntwo_enumerations_two_lines : int\n    a. first line\n       continued\n    b. second line\n       continued\none_definition_one_line : int\n    item 1\n        first line\none_definition_two_lines : int\n    item 1\n        first line\n        continued\ntwo_definitions_one_line : int\n    item 1\n        first line\n    item 2\n        second line\ntwo_definitions_two_lines : int\n    item 1\n        first line\n        continued\n    item 2\n        second line\n        continued\none_definition_blank_line : int\n    item 1\n\n        first line\n\n        extra first line\n\ntwo_definitions_blank_lines : int\n    item 1\n\n        first line\n\n        extra first line\n\n    item 2\n\n        second line\n\n        extra second line\n\ndefinition_after_normal_text : int\n    text line\n\n    item 1\n        first line\n\"\"\"\n\n        expected = \"\"\"One line summary.\n\n:param no_list:\n:type no_list: int\n:param one_bullet_empty:\n                         *\n:type one_bullet_empty: int\n:param one_bullet_single_line:\n                               - first line\n:type one_bullet_single_line: int\n:param one_bullet_two_lines:\n                             +   first line\n                                 continued\n:type one_bullet_two_lines: int\n:param two_bullets_single_line:\n                                -  first line\n                                -  second line\n:type two_bullets_single_line: int\n:param two_bullets_two_lines:\n                              * first line\n                                continued\n                              * second line\n                                continued\n:type two_bullets_two_lines: int\n:param one_enumeration_single_line:\n                                    1.  first line\n:type one_enumeration_single_line: int\n:param one_enumeration_two_lines:\n                                  1)   first line\n                                       continued\n:type one_enumeration_two_lines: int\n:param two_enumerations_one_line:\n                                  (iii) first line\n                                  (iv) second line\n:type two_enumerations_one_line: int\n:param two_enumerations_two_lines:\n                                   a. first line\n                                      continued\n                                   b. second line\n                                      continued\n:type two_enumerations_two_lines: int\n:param one_definition_one_line:\n                                item 1\n                                    first line\n:type one_definition_one_line: int\n:param one_definition_two_lines:\n                                 item 1\n                                     first line\n                                     continued\n:type one_definition_two_lines: int\n:param two_definitions_one_line:\n                                 item 1\n                                     first line\n                                 item 2\n                                     second line\n:type two_definitions_one_line: int\n:param two_definitions_two_lines:\n                                  item 1\n                                      first line\n                                      continued\n                                  item 2\n                                      second line\n                                      continued\n:type two_definitions_two_lines: int\n:param one_definition_blank_line:\n                                  item 1\n\n                                      first line\n\n                                      extra first line\n:type one_definition_blank_line: int\n:param two_definitions_blank_lines:\n                                    item 1\n\n                                        first line\n\n                                        extra first line\n\n                                    item 2\n\n                                        second line\n\n                                        extra second line\n:type two_definitions_blank_lines: int\n:param definition_after_normal_text: text line\n\n                                     item 1\n                                         first line\n:type definition_after_normal_text: int\n\"\"\"\n        config = Config(napoleon_use_param=True)\n        actual = NumpyDocstring(docstring, config)\n        assert str(actual) == expected\n\n        expected = \"\"\"One line summary.\n\n:Parameters: * **no_list** (:py:class:`int`)\n             * **one_bullet_empty** (:py:class:`int`) --\n\n               *\n             * **one_bullet_single_line** (:py:class:`int`) --\n\n               - first line\n             * **one_bullet_two_lines** (:py:class:`int`) --\n\n               +   first line\n                   continued\n             * **two_bullets_single_line** (:py:class:`int`) --\n\n               -  first line\n               -  second line\n             * **two_bullets_two_lines** (:py:class:`int`) --\n\n               * first line\n                 continued\n               * second line\n                 continued\n             * **one_enumeration_single_line** (:py:class:`int`) --\n\n               1.  first line\n             * **one_enumeration_two_lines** (:py:class:`int`) --\n\n               1)   first line\n                    continued\n             * **two_enumerations_one_line** (:py:class:`int`) --\n\n               (iii) first line\n               (iv) second line\n             * **two_enumerations_two_lines** (:py:class:`int`) --\n\n               a. first line\n                  continued\n               b. second line\n                  continued\n             * **one_definition_one_line** (:py:class:`int`) --\n\n               item 1\n                   first line\n             * **one_definition_two_lines** (:py:class:`int`) --\n\n               item 1\n                   first line\n                   continued\n             * **two_definitions_one_line** (:py:class:`int`) --\n\n               item 1\n                   first line\n               item 2\n                   second line\n             * **two_definitions_two_lines** (:py:class:`int`) --\n\n               item 1\n                   first line\n                   continued\n               item 2\n                   second line\n                   continued\n             * **one_definition_blank_line** (:py:class:`int`) --\n\n               item 1\n\n                   first line\n\n                   extra first line\n             * **two_definitions_blank_lines** (:py:class:`int`) --\n\n               item 1\n\n                   first line\n\n                   extra first line\n\n               item 2\n\n                   second line\n\n                   extra second line\n             * **definition_after_normal_text** (:py:class:`int`) -- text line\n\n               item 1\n                   first line\n\"\"\"\n        config = Config(napoleon_use_param=False, napoleon_preprocess_types=True)\n        actual = NumpyDocstring(docstring, config)\n        assert str(actual) == expected\n", "type": "function"}, {"name": "test_tokenize_type_spec", "is_method": true, "class_name": "TestNumpyDocstring", "parameters": ["self"], "calls": ["zip", "_tokenize_type_spec"], "code_location": {"file": "test_ext_napoleon_docstring.py", "path": "/data3/pwh/swebench-repos/sphinx/tests/test_extensions", "start_line": 2576, "end_line": 2615}, "code_snippet": "    def test_tokenize_type_spec(self):\n        specs = (\n            'str',\n            'defaultdict',\n            'int, float, or complex',\n            'int or float or None, optional',\n            'list of list of int or float, optional',\n            'tuple of list of str, float, or int',\n            '{\"F\", \"C\", \"N\"}',\n            \"{'F', 'C', 'N'}, default: 'F'\",\n            \"{'F', 'C', 'N or C'}, default 'F'\",\n            \"str, default: 'F or C'\",\n            'int, default: None',\n            'int, default None',\n            'int, default :obj:`None`',\n            '\"ma{icious\"',\n            r\"'with \\'quotes\\''\",\n        )\n\n        tokens = (\n            ['str'],\n            ['defaultdict'],\n            ['int', ', ', 'float', ', or ', 'complex'],\n            ['int', ' or ', 'float', ' or ', 'None', ', ', 'optional'],\n            ['list', ' of ', 'list', ' of ', 'int', ' or ', 'float', ', ', 'optional'],\n            ['tuple', ' of ', 'list', ' of ', 'str', ', ', 'float', ', or ', 'int'],\n            ['{', '\"F\"', ', ', '\"C\"', ', ', '\"N\"', '}'],\n            ['{', \"'F'\", ', ', \"'C'\", ', ', \"'N'\", '}', ', ', 'default', ': ', \"'F'\"],\n            ['{', \"'F'\", ', ', \"'C'\", ', ', \"'N or C'\", '}', ', ', 'default', ' ', \"'F'\"],\n            ['str', ', ', 'default', ': ', \"'F or C'\"],\n            ['int', ', ', 'default', ': ', 'None'],\n            ['int', ', ', 'default', ' ', 'None'],\n            ['int', ', ', 'default', ' ', ':obj:`None`'],\n            ['\"ma{icious\"'],\n            [r\"'with \\'quotes\\''\"],\n        )  # fmt: skip\n\n        for spec, expected in zip(specs, tokens, strict=True):\n            actual = _tokenize_type_spec(spec)\n            assert actual == expected\n", "type": "function"}, {"name": "test_pyfunction_with_union_type_operator", "is_method": false, "class_name": null, "parameters": ["app"], "calls": ["pytest.mark.sphinx", "restructuredtext.parse", "assert_node"], "code_location": {"file": "test_domain_py_pyfunction.py", "path": "/data3/pwh/swebench-repos/sphinx/tests/test_domains", "start_line": 418, "end_line": 444}, "code_snippet": "def test_pyfunction_with_union_type_operator(app):\n    text = '.. py:function:: hello(age: int | None)'\n    doctree = restructuredtext.parse(app, text)\n    assert_node(\n        doctree[1][0][1],\n        [\n            desc_parameterlist,\n            ([\n                desc_parameter,\n                (\n                    [desc_sig_name, 'age'],\n                    [desc_sig_punctuation, ':'],\n                    desc_sig_space,\n                    [\n                        desc_sig_name,\n                        (\n                            [pending_xref, 'int'],\n                            desc_sig_space,\n                            [desc_sig_punctuation, '|'],\n                            desc_sig_space,\n                            [pending_xref, 'None'],\n                        ),\n                    ],\n                ),\n            ]),\n        ],\n    )\n", "type": "function"}], "retrieved_count": 10, "cost_time": 1.0955405235290527}
{"question": "Why does the standard domain method that resolves cross-references across multiple object types apply case-lowering selectively to only heading references and glossary terms rather than normalizing targets uniformly?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"name": "_resolve_term_xref", "is_method": true, "class_name": "StandardDomain", "parameters": ["self", "env", "fromdocname", "builder", "typ", "target", "node", "contnode"], "calls": ["self._resolve_obj_xref", "target.lower", "make_refnode", "target.lower"], "code_location": {"file": "__init__.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/domains/std", "start_line": 1250, "end_line": 1271}, "code_snippet": "    def _resolve_term_xref(\n        self,\n        env: BuildEnvironment,\n        fromdocname: str,\n        builder: Builder,\n        typ: str,\n        target: str,\n        node: pending_xref,\n        contnode: Element,\n    ) -> nodes.reference | None:\n        result = self._resolve_obj_xref(\n            env, fromdocname, builder, typ, target, node, contnode\n        )\n        if result:\n            return result\n        else:\n            # fallback to case insensitive match\n            if target.lower() in self._terms:\n                docname, labelid = self._terms[target.lower()]\n                return make_refnode(builder, fromdocname, docname, labelid, contnode)\n            else:\n                return None\n", "type": "function"}, {"name": "_resolve_reference_in_domain_by_target", "is_method": false, "class_name": null, "parameters": ["inv_name", "inventory", "domain_name", "objtypes", "target", "node", "contnode"], "calls": ["_create_element_from_result", "target.lower", "list", "filter", "len", "keys", "len", "LOGGER.debug", "LOGGER.warning", "__", "__", "k.lower"], "code_location": {"file": "_resolve.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/ext/intersphinx", "start_line": 81, "end_line": 142}, "code_snippet": "def _resolve_reference_in_domain_by_target(\n    inv_name: InventoryName | None,\n    inventory: Inventory,\n    domain_name: str,\n    objtypes: Iterable[str],\n    target: str,\n    node: pending_xref,\n    contnode: TextElement,\n) -> nodes.reference | None:\n    for objtype in objtypes:\n        if objtype not in inventory:\n            # Continue if there's nothing of this kind in the inventory\n            continue\n\n        if target in inventory[objtype]:\n            # Case sensitive match, use it\n            data = inventory[objtype][target]\n        elif objtype in {'std:label', 'std:term'}:\n            # Some types require case insensitive matches:\n            # * 'term': https://github.com/sphinx-doc/sphinx/issues/9291\n            # * 'label': https://github.com/sphinx-doc/sphinx/issues/12008\n            target_lower = target.lower()\n            insensitive_matches = list(\n                filter(lambda k: k.lower() == target_lower, inventory[objtype].keys())\n            )\n            if len(insensitive_matches) > 1:\n                data_items = {\n                    inventory[objtype][match] for match in insensitive_matches\n                }\n                inv_descriptor = inv_name or 'main_inventory'\n                if len(data_items) == 1:  # these are duplicates; relatively innocuous\n                    LOGGER.debug(\n                        __(\"inventory '%s': duplicate matches found for %s:%s\"),\n                        inv_descriptor,\n                        objtype,\n                        target,\n                        type='intersphinx',\n                        subtype='external',\n                        location=node,\n                    )\n                else:\n                    LOGGER.warning(\n                        __(\"inventory '%s': multiple matches found for %s:%s\"),\n                        inv_descriptor,\n                        objtype,\n                        target,\n                        type='intersphinx',\n                        subtype='external',\n                        location=node,\n                    )\n            if insensitive_matches:\n                data = inventory[objtype][insensitive_matches[0]]\n            else:\n                # No case insensitive match either, continue to the next candidate\n                continue\n        else:\n            # Could reach here if we're not a term but have a case insensitive match.\n            # This is a fix for terms specifically, but potentially should apply to\n            # other types.\n            continue\n        return _create_element_from_result(domain_name, inv_name, data, node, contnode)\n    return None\n", "type": "function"}, {"name": "resolve_any_xref", "is_method": true, "class_name": "StandardDomain", "parameters": ["self", "env", "fromdocname", "builder", "target", "node", "contnode"], "calls": ["target.lower", "self.resolve_xref", "results.append", "results.append", "self.role_for_objtype", "make_refnode"], "code_location": {"file": "__init__.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/domains/std", "start_line": 1294, "end_line": 1329}, "code_snippet": "    def resolve_any_xref(\n        self,\n        env: BuildEnvironment,\n        fromdocname: str,\n        builder: Builder,\n        target: str,\n        node: pending_xref,\n        contnode: Element,\n    ) -> list[tuple[str, nodes.reference]]:\n        results: list[tuple[str, nodes.reference]] = []\n        ltarget = target.lower()  # :ref: lowercases its target automatically\n        for role in ('ref', 'option'):  # do not try \"keyword\"\n            res = self.resolve_xref(\n                env,\n                fromdocname,\n                builder,\n                role,\n                ltarget if role == 'ref' else target,\n                node,\n                contnode,\n            )\n            if res:\n                results.append(('std:' + role, res))\n        # all others\n        for objtype in self.object_types:\n            key = (objtype, target)\n            if objtype == 'term':\n                key = (objtype, ltarget)\n            if key in self.objects:\n                docname, labelid = self.objects[key]\n                role = 'std:' + self.role_for_objtype(objtype)  # type: ignore[operator]\n                results.append((\n                    role,\n                    make_refnode(builder, fromdocname, docname, labelid, contnode),\n                ))\n        return results\n", "type": "function"}, {"name": "_resolve_reference_in_domain", "is_method": false, "class_name": null, "parameters": ["inv_name", "inventory", "honor_disabled_refs", "disabled_reftypes", "domain", "objtypes", "node", "contnode"], "calls": ["dict.fromkeys", "_resolve_reference_in_domain_by_target", "domain.get_full_qualified_name", "_resolve_reference_in_domain_by_target", "obj_types.keys"], "code_location": {"file": "_resolve.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/ext/intersphinx", "start_line": 145, "end_line": 192}, "code_snippet": "def _resolve_reference_in_domain(\n    inv_name: InventoryName | None,\n    inventory: Inventory,\n    honor_disabled_refs: bool,\n    disabled_reftypes: Set[str],\n    domain: Domain,\n    objtypes: Iterable[str],\n    node: pending_xref,\n    contnode: TextElement,\n) -> nodes.reference | None:\n    domain_name = domain.name\n    obj_types: dict[str, None] = dict.fromkeys(objtypes)\n\n    # we adjust the object types for backwards compatibility\n    if domain_name == 'std' and 'cmdoption' in obj_types:\n        # cmdoptions were stored as std:option until Sphinx 1.6\n        obj_types['option'] = None\n    if domain_name == 'py' and 'attribute' in obj_types:\n        # properties are stored as py:method since Sphinx 2.1\n        obj_types['method'] = None\n\n    # the inventory contains domain:type as objtype\n    obj_types = {f'{domain_name}:{obj_type}': None for obj_type in obj_types}\n\n    # now that the objtypes list is complete we can remove the disabled ones\n    if honor_disabled_refs:\n        obj_types = {\n            obj_type: None\n            for obj_type in obj_types\n            if obj_type not in disabled_reftypes\n        }\n\n    objtypes = [*obj_types.keys()]\n\n    # without qualification\n    res = _resolve_reference_in_domain_by_target(\n        inv_name, inventory, domain_name, objtypes, node['reftarget'], node, contnode\n    )\n    if res is not None:\n        return res\n\n    # try with qualification of the current scope instead\n    full_qualified_name = domain.get_full_qualified_name(node)\n    if full_qualified_name is None:\n        return None\n    return _resolve_reference_in_domain_by_target(\n        inv_name, inventory, domain_name, objtypes, full_qualified_name, node, contnode\n    )\n", "type": "function"}, {"name": "test_domain_py_xrefs", "is_method": false, "class_name": null, "parameters": ["app"], "calls": ["pytest.mark.sphinx", "app.build", "app.env.get_doctree", "list", "assert_refnode", "assert_refnode", "assert_refnode", "assert_refnode", "assert_refnode", "assert_refnode", "assert_refnode", "assert_refnode", "assert_refnode", "assert_refnode", "assert_refnode", "assert_refnode", "assert_refnode", "assert_refnode", "assert_refnode", "app.env.get_doctree", "list", "assert_refnode", "assert_refnode", "assert_refnode", "assert_refnode", "assert_refnode", "assert_refnode", "assert_refnode", "assert_refnode", "assert_refnode", "assert_refnode", "assert_refnode", "assert_refnode", "assert_refnode", "assert_refnode", "assert_refnode", "assert_refnode", "assert_refnode", "assert_refnode", "assert_refnode", "assert_refnode", "assert_refnode", "app.env.get_doctree", "list", "print", "print", "print", "assert_refnode", "assert_refnode", "assert_node", "doctree.findall", "len", "doctree.findall", "len", "doctree.findall", "len"], "code_location": {"file": "test_domain_py.py", "path": "/data3/pwh/swebench-repos/sphinx/tests/test_domains", "start_line": 83, "end_line": 179}, "code_snippet": "def test_domain_py_xrefs(app):\n    \"\"\"Domain objects have correct prefixes when looking up xrefs\"\"\"\n    app.build(force_all=True)\n\n    def assert_refnode(\n        node, module_name, class_name, target, reftype=None, domain='py'\n    ):\n        attributes = {\n            'refdomain': domain,\n            'reftarget': target,\n        }\n        if reftype is not None:\n            attributes['reftype'] = reftype\n        if module_name is not False:\n            attributes['py:module'] = module_name\n        if class_name is not False:\n            attributes['py:class'] = class_name\n        assert_node(node, **attributes)\n\n    doctree = app.env.get_doctree('roles')\n    refnodes = list(doctree.findall(pending_xref))\n    assert_refnode(refnodes[0], None, None, 'TopLevel', 'class')\n    assert_refnode(refnodes[1], None, None, 'top_level', 'meth')\n    assert_refnode(refnodes[2], None, None, 'TopLevelType', 'type')\n    assert_refnode(refnodes[3], None, 'NestedParentA', 'child_1', 'meth')\n    assert_refnode(\n        refnodes[4], None, 'NestedParentA', 'NestedChildA.subchild_2', 'meth'\n    )\n    assert_refnode(refnodes[5], None, 'NestedParentA', 'child_2', 'meth')\n    assert_refnode(refnodes[6], False, 'NestedParentA', 'any_child', domain='')\n    assert_refnode(refnodes[7], None, 'NestedParentA', 'NestedChildA', 'class')\n    assert_refnode(\n        refnodes[8], None, 'NestedParentA.NestedChildA', 'subchild_2', 'meth'\n    )\n    assert_refnode(\n        refnodes[9], None, 'NestedParentA.NestedChildA', 'NestedParentA.child_1', 'meth'\n    )\n    assert_refnode(\n        refnodes[10], None, 'NestedParentA', 'NestedChildA.subchild_1', 'meth'\n    )\n    assert_refnode(refnodes[11], None, 'NestedParentB', 'child_1', 'meth')\n    assert_refnode(refnodes[12], None, 'NestedParentB', 'NestedParentB', 'class')\n    assert_refnode(refnodes[13], None, None, 'NestedParentA.NestedChildA', 'class')\n    assert_refnode(refnodes[14], None, None, 'NestedParentA.NestedTypeA', 'type')\n    assert len(refnodes) == 15\n\n    doctree = app.env.get_doctree('module')\n    refnodes = list(doctree.findall(pending_xref))\n    assert_refnode(refnodes[0], 'module_a.submodule', None, 'ModTopLevel', 'class')\n    assert_refnode(\n        refnodes[1], 'module_a.submodule', 'ModTopLevel', 'mod_child_1', 'meth'\n    )\n    assert_refnode(\n        refnodes[2],\n        'module_a.submodule',\n        'ModTopLevel',\n        'ModTopLevel.mod_child_1',\n        'meth',\n    )\n    assert_refnode(\n        refnodes[3], 'module_a.submodule', 'ModTopLevel', 'mod_child_2', 'meth'\n    )\n    assert_refnode(\n        refnodes[4],\n        'module_a.submodule',\n        'ModTopLevel',\n        'module_a.submodule.ModTopLevel.mod_child_1',\n        'meth',\n    )\n    assert_refnode(refnodes[5], 'module_a.submodule', 'ModTopLevel', 'prop', 'attr')\n    assert_refnode(refnodes[6], 'module_a.submodule', 'ModTopLevel', 'prop', 'meth')\n    assert_refnode(refnodes[7], 'module_b.submodule', None, 'ModTopLevel', 'class')\n    assert_refnode(\n        refnodes[8], 'module_b.submodule', 'ModTopLevel', 'ModNoModule', 'class'\n    )\n    assert_refnode(refnodes[9], False, False, 'int', 'class')\n    assert_refnode(refnodes[10], False, False, 'tuple', 'class')\n    assert_refnode(refnodes[11], False, False, 'str', 'class')\n    assert_refnode(refnodes[12], False, False, 'float', 'class')\n    assert_refnode(refnodes[13], False, False, 'list', 'class')\n    assert_refnode(refnodes[14], False, False, 'ModTopLevel', 'class')\n    assert_refnode(refnodes[15], False, False, 'index', 'doc', domain='std')\n    assert_refnode(refnodes[16], False, False, 'typing.Literal', 'obj', domain='py')\n    assert_refnode(refnodes[17], False, False, 'typing.Literal', 'obj', domain='py')\n    assert_refnode(refnodes[18], False, False, 'list', 'class', domain='py')\n    assert_refnode(refnodes[19], False, False, 'int', 'class', domain='py')\n    assert_refnode(refnodes[20], False, False, 'str', 'class', domain='py')\n    assert len(refnodes) == 21\n\n    doctree = app.env.get_doctree('module_option')\n    refnodes = list(doctree.findall(pending_xref))\n    print(refnodes)\n    print(refnodes[0])\n    print(refnodes[1])\n    assert_refnode(refnodes[0], 'test.extra', 'B', 'foo', 'meth')\n    assert_refnode(refnodes[1], 'test.extra', 'B', 'foo', 'meth')\n    assert len(refnodes) == 2\n", "type": "function"}, {"name": "test_missing_reference_stddomain", "is_method": false, "class_name": null, "parameters": ["tmp_path", "app"], "calls": ["pytest.mark.sphinx", "inv_file.write_bytes", "set_config", "validate_intersphinx_mapping", "load_mappings", "fake_node", "missing_reference", "fake_node", "missing_reference", "fake_node", "missing_reference", "fake_node", "missing_reference", "fake_node", "missing_reference", "fake_node", "missing_reference", "fake_node", "missing_reference", "rn.astext", "rn.astext", "rn.astext", "rn.astext", "rn.astext", "rn.astext", "str"], "code_location": {"file": "test_ext_intersphinx.py", "path": "/data3/pwh/swebench-repos/sphinx/tests/test_extensions", "start_line": 289, "end_line": 339}, "code_snippet": "def test_missing_reference_stddomain(tmp_path, app):\n    inv_file = tmp_path / 'inventory'\n    inv_file.write_bytes(INVENTORY_V2)\n    set_config(\n        app,\n        {\n            'cmd': ('https://docs.python.org/', str(inv_file)),\n        },\n    )\n\n    # load the inventory and check if it's done correctly\n    validate_intersphinx_mapping(app, app.config)\n    load_mappings(app)\n\n    # no context data\n    kwargs = {}\n    node, contnode = fake_node('std', 'option', '-l', '-l', **kwargs)\n    rn = missing_reference(app, app.env, node, contnode)\n    assert rn is None\n\n    # std:program context helps to search objects\n    kwargs = {'std:program': 'ls'}\n    node, contnode = fake_node('std', 'option', '-l', 'ls -l', **kwargs)\n    rn = missing_reference(app, app.env, node, contnode)\n    assert rn.astext() == 'ls -l'\n\n    # refers inventory by name\n    kwargs = {}\n    node, contnode = fake_node('std', 'option', 'cmd:ls -l', '-l', **kwargs)\n    rn = missing_reference(app, app.env, node, contnode)\n    assert rn.astext() == '-l'\n\n    # term reference (normal)\n    node, contnode = fake_node('std', 'term', 'a term', 'a term')\n    rn = missing_reference(app, app.env, node, contnode)\n    assert rn.astext() == 'a term'\n\n    # term reference (case insensitive)\n    node, contnode = fake_node('std', 'term', 'A TERM', 'A TERM')\n    rn = missing_reference(app, app.env, node, contnode)\n    assert rn.astext() == 'A TERM'\n\n    # label reference (normal)\n    node, contnode = fake_node('std', 'ref', 'The-Julia-Domain', 'The-Julia-Domain')\n    rn = missing_reference(app, app.env, node, contnode)\n    assert rn.astext() == 'The Julia Domain'\n\n    # label reference (case insensitive)\n    node, contnode = fake_node('std', 'ref', 'the-julia-domain', 'the-julia-domain')\n    rn = missing_reference(app, app.env, node, contnode)\n    assert rn.astext() == 'The Julia Domain'\n", "type": "function"}, {"name": "test_glossary_conflicted_labels", "is_method": false, "class_name": null, "parameters": ["app"], "calls": ["pytest.mark.sphinx", "restructuredtext.parse", "list", "app.env.domains.standard_domain.get_objects"], "code_location": {"file": "test_domain_std.py", "path": "/data3/pwh/swebench-repos/sphinx/tests/test_domains", "start_line": 390, "end_line": 394}, "code_snippet": "def test_glossary_conflicted_labels(app: SphinxTestApp) -> None:\n    text = '.. _term-foo:\\n.. glossary::\\n\\n   foo\\n'\n    restructuredtext.parse(app, text)\n    objects = list(app.env.domains.standard_domain.get_objects())\n    assert ('foo', 'foo', 'term', 'index', 'term-0', -1) in objects\n", "type": "function"}, {"name": "resolve_xref", "is_method": true, "class_name": "StandardDomain", "parameters": ["self", "env", "fromdocname", "builder", "typ", "target", "node", "contnode"], "calls": ["resolver"], "code_location": {"file": "__init__.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/domains/std", "start_line": 1033, "end_line": 1058}, "code_snippet": "    def resolve_xref(\n        self,\n        env: BuildEnvironment,\n        fromdocname: str,\n        builder: Builder,\n        typ: str,\n        target: str,\n        node: pending_xref,\n        contnode: Element,\n    ) -> nodes.reference | None:\n        if typ == 'ref':\n            resolver = self._resolve_ref_xref\n        elif typ == 'numref':\n            resolver = self._resolve_numref_xref  # type: ignore[assignment]\n        elif typ == 'keyword':\n            resolver = self._resolve_keyword_xref\n        elif typ == 'doc':\n            resolver = self._resolve_doc_xref\n        elif typ == 'option':\n            resolver = self._resolve_option_xref\n        elif typ == 'term':\n            resolver = self._resolve_term_xref\n        else:\n            resolver = self._resolve_obj_xref\n\n        return resolver(env, fromdocname, builder, typ, target, node, contnode)\n", "type": "function"}, {"name": "_resolve_reference", "is_method": false, "class_name": null, "parameters": ["inv_name", "domains", "inventory", "honor_disabled_refs", "disabled_reftypes", "node", "contnode"], "calls": ["domains.sorted", "node.get", "_resolve_reference_in_domain", "domain.object_types.keys", "_resolve_reference_in_domain", "domain.objtypes_for_role", "ExtensionError", "__"], "code_location": {"file": "_resolve.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/ext/intersphinx", "start_line": 195, "end_line": 254}, "code_snippet": "def _resolve_reference(\n    inv_name: InventoryName | None,\n    domains: _DomainsContainer,\n    inventory: Inventory,\n    honor_disabled_refs: bool,\n    disabled_reftypes: Set[str],\n    node: pending_xref,\n    contnode: TextElement,\n) -> nodes.reference | None:\n    # disabling should only be done if no inventory is given\n    honor_disabled_refs = honor_disabled_refs and inv_name is None\n\n    if honor_disabled_refs and '*' in disabled_reftypes:\n        return None\n\n    typ = node['reftype']\n    if typ == 'any':\n        for domain in domains.sorted():\n            if honor_disabled_refs and f'{domain.name}:*' in disabled_reftypes:\n                continue\n            objtypes: Iterable[str] = domain.object_types.keys()\n            res = _resolve_reference_in_domain(\n                inv_name,\n                inventory,\n                honor_disabled_refs,\n                disabled_reftypes,\n                domain,\n                objtypes,\n                node,\n                contnode,\n            )\n            if res is not None:\n                return res\n        return None\n    else:\n        domain_name = node.get('refdomain')\n        if not domain_name:\n            # only objects in domains are in the inventory\n            return None\n        if honor_disabled_refs and f'{domain_name}:*' in disabled_reftypes:\n            return None\n        try:\n            domain = domains[domain_name]\n        except KeyError as exc:\n            msg = __('Domain %r is not registered') % domain_name\n            raise ExtensionError(msg) from exc\n\n        objtypes = domain.objtypes_for_role(typ) or ()\n        if not objtypes:\n            return None\n        return _resolve_reference_in_domain(\n            inv_name,\n            inventory,\n            honor_disabled_refs,\n            disabled_reftypes,\n            domain,\n            objtypes,\n            node,\n            contnode,\n        )\n", "type": "function"}, {"name": "_resolve_keyword_xref", "is_method": true, "class_name": "StandardDomain", "parameters": ["self", "env", "fromdocname", "builder", "typ", "target", "node", "contnode"], "calls": ["self.labels.get", "make_refnode"], "code_location": {"file": "__init__.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/domains/std", "start_line": 1171, "end_line": 1185}, "code_snippet": "    def _resolve_keyword_xref(\n        self,\n        env: BuildEnvironment,\n        fromdocname: str,\n        builder: Builder,\n        typ: str,\n        target: str,\n        node: pending_xref,\n        contnode: Element,\n    ) -> nodes.reference | None:\n        # keywords are oddballs: they are referenced by named labels\n        docname, labelid, _ = self.labels.get(target, ('', '', ''))\n        if not docname:\n            return None\n        return make_refnode(builder, fromdocname, docname, labelid, contnode)\n", "type": "function"}], "retrieved_count": 10, "cost_time": 1.0754585266113281}
{"question": "Why does the Python domain cross-reference handler's link processing method require optimization to reduce redundant string operations when processing multiple similar cross-references in high-volume builds?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"name": "make_xref", "is_method": true, "class_name": "PyXrefMixin", "parameters": ["self", "rolename", "domain", "target", "innernode", "contnode", "env", "inliner", "location"], "calls": ["make_xref", "isinstance", "env.ref_context.get", "env.ref_context.get", "parse_reftarget", "super", "result.clear", "innernode", "result.clear", "innernode", "result.extend", "target.rpartition", "pending_xref_condition", "pending_xref_condition"], "code_location": {"file": "_object.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/domains/python", "start_line": 56, "end_line": 104}, "code_snippet": "    def make_xref(\n        self,\n        rolename: str,\n        domain: str,\n        target: str,\n        innernode: type[TextlikeNode] = nodes.emphasis,\n        contnode: Node | None = None,\n        env: BuildEnvironment | None = None,\n        inliner: Inliner | None = None,\n        location: Node | None = None,\n    ) -> Node:\n        # we use inliner=None to make sure we get the old behaviour with a single\n        # pending_xref node\n        result = super().make_xref(  # type: ignore[misc]\n            rolename,\n            domain,\n            target,\n            innernode,\n            contnode,\n            env,\n            inliner=None,\n            location=None,\n        )\n        if isinstance(result, pending_xref):\n            assert env is not None\n            result['refspecific'] = True\n            result['py:module'] = env.ref_context.get('py:module')\n            result['py:class'] = env.ref_context.get('py:class')\n\n            reftype, reftarget, reftitle, _ = parse_reftarget(target)\n            if reftarget != reftitle:\n                result['reftype'] = reftype\n                result['reftarget'] = reftarget\n\n                result.clear()\n                result += innernode(reftitle, reftitle)  # type: ignore[call-arg]\n            elif env.config.python_use_unqualified_type_names:\n                children = result.children\n                result.clear()\n\n                shortname = target.rpartition('.')[-1]\n                textnode = innernode('', shortname)  # type: ignore[call-arg]\n                contnodes = [\n                    pending_xref_condition('', '', textnode, condition='resolved'),\n                    pending_xref_condition('', '', *children, condition='*'),\n                ]\n                result.extend(contnodes)\n\n        return result\n", "type": "function"}, {"name": "process_link", "is_method": true, "class_name": "AnyXRefRole", "parameters": ["self", "env", "refnode", "has_explicit_title", "title", "target"], "calls": ["process_link", "refnode.attributes.update", "super"], "code_location": {"file": "roles.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx", "start_line": 184, "end_line": 195}, "code_snippet": "    def process_link(\n        self,\n        env: BuildEnvironment,\n        refnode: Element,\n        has_explicit_title: bool,\n        title: str,\n        target: str,\n    ) -> tuple[str, str]:\n        result = super().process_link(env, refnode, has_explicit_title, title, target)\n        # add all possible context info (i.e. std:program, py:module etc.)\n        refnode.attributes.update(env.ref_context)\n        return result\n", "type": "function"}, {"name": "process_link", "is_method": true, "class_name": "PyXRefRole", "parameters": ["self", "env", "refnode", "has_explicit_title", "title", "target"], "calls": ["env.ref_context.get", "env.ref_context.get", "title.lstrip", "target.lstrip", "title.rfind"], "code_location": {"file": "__init__.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/domains/python", "start_line": 570, "end_line": 595}, "code_snippet": "    def process_link(\n        self,\n        env: BuildEnvironment,\n        refnode: Element,\n        has_explicit_title: bool,\n        title: str,\n        target: str,\n    ) -> tuple[str, str]:\n        refnode['py:module'] = env.ref_context.get('py:module')\n        refnode['py:class'] = env.ref_context.get('py:class')\n        if not has_explicit_title:\n            title = title.lstrip('.')  # only has a meaning for the target\n            target = target.lstrip('~')  # only has a meaning for the title\n            # if the first character is a tilde, don't display the module/class\n            # parts of the contents\n            if title[0:1] == '~':\n                title = title[1:]\n                dot = title.rfind('.')\n                if dot != -1:\n                    title = title[dot + 1 :]\n        # if the first character is a dot, search more specific namespaces first\n        # else search builtins first\n        if target[0:1] == '.':\n            target = target[1:]\n            refnode['refspecific'] = True\n        return title, target\n", "type": "function"}, {"name": "process_link", "is_method": true, "class_name": "CPPXRefRole", "parameters": ["self", "env", "refnode", "has_explicit_title", "title", "target"], "calls": ["refnode.attributes.update", "anon_identifier_re.sub", "target.removesuffix", "target.lstrip", "str", "title.removesuffix", "title.rfind"], "code_location": {"file": "__init__.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/domains/cpp", "start_line": 853, "end_line": 884}, "code_snippet": "    def process_link(\n        self,\n        env: BuildEnvironment,\n        refnode: Element,\n        has_explicit_title: bool,\n        title: str,\n        target: str,\n    ) -> tuple[str, str]:\n        refnode.attributes.update(env.ref_context)\n\n        if not has_explicit_title:\n            # major hax: replace anon names via simple string manipulation.\n            # Can this actually fail?\n            title = anon_identifier_re.sub('[anonymous]', str(title))\n\n        if refnode['reftype'] == 'any':\n            # Assume the removal part of fix_parens for :any: refs.\n            # The addition part is done with the reference is resolved.\n            if not has_explicit_title:\n                title = title.removesuffix('()')\n            target = target.removesuffix('()')\n        # TODO: should this really be here?\n        if not has_explicit_title:\n            target = target.lstrip('~')  # only has a meaning for the title\n            # if the first character is a tilde, don't display the module/class\n            # parts of the contents\n            if title[:1] == '~':\n                title = title[1:]\n                dcolon = title.rfind('::')\n                if dcolon != -1:\n                    title = title[dcolon + 2 :]\n        return title, target\n", "type": "function"}, {"name": "process_link", "is_method": true, "class_name": "CXRefRole", "parameters": ["self", "env", "refnode", "has_explicit_title", "title", "target"], "calls": ["refnode.attributes.update", "anon_identifier_re.sub", "target.lstrip", "str", "title.rfind"], "code_location": {"file": "__init__.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/domains/c", "start_line": 705, "end_line": 729}, "code_snippet": "    def process_link(\n        self,\n        env: BuildEnvironment,\n        refnode: Element,\n        has_explicit_title: bool,\n        title: str,\n        target: str,\n    ) -> tuple[str, str]:\n        refnode.attributes.update(env.ref_context)\n\n        if not has_explicit_title:\n            # major hax: replace anon names via simple string manipulation.\n            # Can this actually fail?\n            title = anon_identifier_re.sub('[anonymous]', str(title))\n\n        if not has_explicit_title:\n            target = target.lstrip('~')  # only has a meaning for the title\n            # if the first character is a tilde, don't display the module/class\n            # parts of the contents\n            if title[0:1] == '~':\n                title = title[1:]\n                dot = title.rfind('.')\n                if dot != -1:\n                    title = title[dot + 1 :]\n        return title, target\n", "type": "function"}, {"name": "process_link", "is_method": true, "class_name": "JSXRefRole", "parameters": ["self", "env", "refnode", "has_explicit_title", "title", "target"], "calls": ["env.ref_context.get", "env.ref_context.get", "title.lstrip", "target.lstrip", "title.rfind"], "code_location": {"file": "javascript.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/domains", "start_line": 387, "end_line": 409}, "code_snippet": "    def process_link(\n        self,\n        env: BuildEnvironment,\n        refnode: Element,\n        has_explicit_title: bool,\n        title: str,\n        target: str,\n    ) -> tuple[str, str]:\n        # basically what sphinx.domains.python.PyXRefRole does\n        refnode['js:object'] = env.ref_context.get('js:object')\n        refnode['js:module'] = env.ref_context.get('js:module')\n        if not has_explicit_title:\n            title = title.lstrip('.')\n            target = target.lstrip('~')\n            if title[0:1] == '~':\n                title = title[1:]\n                dot = title.rfind('.')\n                if dot != -1:\n                    title = title[dot + 1 :]\n        if target[0:1] == '.':\n            target = target[1:]\n            refnode['refspecific'] = True\n        return title, target\n", "type": "function"}, {"name": "test_domain_py_xrefs_abbreviations", "is_method": false, "class_name": null, "parameters": ["app"], "calls": ["pytest.mark.sphinx", "app.build", "read_text", "re.search", "re.search", "re.search", "re.search", "re.search"], "code_location": {"file": "test_domain_py.py", "path": "/data3/pwh/swebench-repos/sphinx/tests/test_domains", "start_line": 183, "end_line": 212}, "code_snippet": "def test_domain_py_xrefs_abbreviations(app):\n    app.build(force_all=True)\n\n    content = (app.outdir / 'abbr.html').read_text(encoding='utf8')\n    assert re.search(\n        r'normal: <a .* href=\"module.html#module_a.submodule.ModTopLevel.'\n        r'mod_child_1\" .*><.*>module_a.submodule.ModTopLevel.mod_child_1\\(\\)'\n        r'<.*></a>',\n        content,\n    )\n    assert re.search(\n        r'relative: <a .* href=\"module.html#module_a.submodule.ModTopLevel.'\n        r'mod_child_1\" .*><.*>ModTopLevel.mod_child_1\\(\\)<.*></a>',\n        content,\n    )\n    assert re.search(\n        r'short name: <a .* href=\"module.html#module_a.submodule.ModTopLevel.'\n        r'mod_child_1\" .*><.*>mod_child_1\\(\\)<.*></a>',\n        content,\n    )\n    assert re.search(\n        r'relative \\+ short name: <a .* href=\"module.html#module_a.submodule.'\n        r'ModTopLevel.mod_child_1\" .*><.*>mod_child_1\\(\\)<.*></a>',\n        content,\n    )\n    assert re.search(\n        r'short name \\+ relative: <a .* href=\"module.html#module_a.submodule.'\n        r'ModTopLevel.mod_child_1\" .*><.*>mod_child_1\\(\\)<.*></a>',\n        content,\n    )\n", "type": "function"}, {"name": "process_link", "is_method": true, "class_name": "_PyDecoXRefRole", "parameters": ["self", "env", "refnode", "has_explicit_title", "title", "target"], "calls": ["process_link", "super"], "code_location": {"file": "__init__.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/domains/python", "start_line": 599, "end_line": 610}, "code_snippet": "    def process_link(\n        self,\n        env: BuildEnvironment,\n        refnode: Element,\n        has_explicit_title: bool,\n        title: str,\n        target: str,\n    ) -> tuple[str, str]:\n        title, target = super().process_link(\n            env, refnode, has_explicit_title, title, target\n        )\n        return f'@{title}', target\n", "type": "function"}, {"name": "process_link", "is_method": true, "class_name": "TokenXRefRole", "parameters": ["self", "env", "refnode", "has_explicit_title", "title", "target"], "calls": ["target.lstrip", "title.split"], "code_location": {"file": "__init__.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/domains/std", "start_line": 703, "end_line": 717}, "code_snippet": "    def process_link(\n        self,\n        env: BuildEnvironment,\n        refnode: Element,\n        has_explicit_title: bool,\n        title: str,\n        target: str,\n    ) -> tuple[str, str]:\n        target = target.lstrip('~')  # a title-specific thing\n        if not self.has_explicit_title and title[0] == '~':\n            if ':' in title:\n                _, title = title.split(':')\n            else:\n                title = title[1:]\n        return title, target\n", "type": "function"}, {"name": "make_xrefs", "is_method": true, "class_name": "PyXrefMixin", "parameters": ["self", "rolename", "domain", "target", "innernode", "contnode", "env", "inliner", "location"], "calls": ["self._delimiters_re.split", "bool", "filter", "nodes.Text", "self._delimiters_re.match", "results.append", "results.append", "contnode.astext", "self.make_xref", "innernode"], "code_location": {"file": "_object.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/domains/python", "start_line": 110, "end_line": 150}, "code_snippet": "    def make_xrefs(\n        self,\n        rolename: str,\n        domain: str,\n        target: str,\n        innernode: type[TextlikeNode] = nodes.emphasis,\n        contnode: Node | None = None,\n        env: BuildEnvironment | None = None,\n        inliner: Inliner | None = None,\n        location: Node | None = None,\n    ) -> list[Node]:\n        sub_targets = self._delimiters_re.split(target)\n\n        split_contnode = bool(contnode and contnode.astext() == target)\n\n        in_literal = False\n        results = []\n        for sub_target in filter(None, sub_targets):\n            if split_contnode:\n                contnode = nodes.Text(sub_target)\n\n            if in_literal or self._delimiters_re.match(sub_target):\n                results.append(contnode or innernode(sub_target, sub_target))  # type: ignore[call-arg]\n            else:\n                results.append(\n                    self.make_xref(\n                        rolename,\n                        domain,\n                        sub_target,\n                        innernode,\n                        contnode,\n                        env,\n                        inliner,\n                        location,\n                    )\n                )\n\n            if sub_target in {'Literal', 'typing.Literal', '~typing.Literal'}:\n                in_literal = True\n\n        return results\n", "type": "function"}], "retrieved_count": 10, "cost_time": 1.080784797668457}
{"question": "How does the collector class that processes downloadable file references integrate with the base collector interface that connects to Sphinx build environment events to expose download file tracking through the build environment API?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"name": "DownloadFileCollector", "docstring": "Download files collector for sphinx.environment.", "methods": ["clear_doc", "merge_other", "process_doc"], "attributes": [], "code_location": {"file": "asset.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/environment/collectors", "start_line": 137, "end_line": 174}, "type": "class"}, {"name": "EnvironmentCollector", "docstring": "An EnvironmentCollector is a specific data collector from each document.\n\nIt gathers data and stores :py:class:`BuildEnvironment\n<sphinx.environment.BuildEnvironment>` as a database.\nExamples of specific data would be images, download files, section titles, metadatas, index\nentries and toctrees, etc.\n\n.. note::\n\n    This class essentially wraps a sub-set of :ref:`Sphinx event callbacks <events>`.", "methods": ["enable", "disable", "clear_doc", "merge_other", "process_doc", "get_updated_docs", "get_outdated_docs"], "attributes": [], "code_location": {"file": "__init__.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/environment/collectors", "start_line": 16, "end_line": 102}, "type": "class"}, {"name": "DependenciesCollector", "docstring": "dependencies collector for sphinx.environment.", "methods": ["clear_doc", "merge_other", "process_doc"], "attributes": [], "code_location": {"file": "dependencies.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/environment/collectors", "start_line": 21, "end_line": 50}, "type": "class"}, {"name": "setup", "is_method": false, "class_name": null, "parameters": ["app"], "calls": ["app.add_env_collector", "app.add_env_collector"], "code_location": {"file": "asset.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/environment/collectors", "start_line": 177, "end_line": 185}, "code_snippet": "def setup(app: Sphinx) -> ExtensionMetadata:\n    app.add_env_collector(ImageCollector)\n    app.add_env_collector(DownloadFileCollector)\n\n    return {\n        'version': 'builtin',\n        'parallel_read_safe': True,\n        'parallel_write_safe': True,\n    }\n", "type": "function"}, {"name": "ImageCollector", "docstring": "Image files collector for sphinx.environment.", "methods": ["clear_doc", "merge_other", "process_doc", "collect_candidates"], "attributes": [], "code_location": {"file": "asset.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/environment/collectors", "start_line": 33, "end_line": 134}, "type": "class"}, {"name": "MetadataCollector", "docstring": "metadata collector for sphinx.environment.", "methods": ["clear_doc", "merge_other", "process_doc"], "attributes": [], "code_location": {"file": "metadata.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/environment/collectors", "start_line": 19, "end_line": 68}, "type": "class"}, {"name": "TitleCollector", "docstring": "title collector for sphinx.environment.", "methods": ["clear_doc", "merge_other", "process_doc"], "attributes": [], "code_location": {"file": "title.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/environment/collectors", "start_line": 20, "end_line": 59}, "type": "class"}, {"name": "merge_other", "is_method": true, "class_name": "DownloadFileCollector", "parameters": ["self", "app", "env", "docnames", "other"], "calls": ["env.dlfiles.merge_other"], "code_location": {"file": "asset.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/environment/collectors", "start_line": 143, "end_line": 150}, "code_snippet": "    def merge_other(\n        self,\n        app: Sphinx,\n        env: BuildEnvironment,\n        docnames: Set[str],\n        other: BuildEnvironment,\n    ) -> None:\n        env.dlfiles.merge_other(docnames, other.dlfiles)\n", "type": "function"}, {"name": "add_env_collector", "is_method": true, "class_name": "Sphinx", "parameters": ["self", "collector"], "calls": ["logger.debug", "enable", "collector"], "code_location": {"file": "application.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx", "start_line": 1717, "end_line": 1725}, "code_snippet": "    def add_env_collector(self, collector: type[EnvironmentCollector]) -> None:\n        \"\"\"Register an environment collector class.\n\n        Refer to :ref:`collector-api`.\n\n        .. versionadded:: 1.6\n        \"\"\"\n        logger.debug('[app] adding environment collector: %r', collector)\n        collector().enable(self)\n", "type": "function"}, {"name": "setup", "is_method": false, "class_name": null, "parameters": ["app"], "calls": ["app.add_env_collector"], "code_location": {"file": "dependencies.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/environment/collectors", "start_line": 53, "end_line": 60}, "code_snippet": "def setup(app: Sphinx) -> ExtensionMetadata:\n    app.add_env_collector(DependenciesCollector)\n\n    return {\n        'version': 'builtin',\n        'parallel_read_safe': True,\n        'parallel_write_safe': True,\n    }\n", "type": "function"}], "retrieved_count": 10, "cost_time": 1.118781566619873}
{"question": "How should the noexcept expression class in the C++ domain's abstract syntax tree be refactored to separate expression wrapping, identifier generation, and documentation rendering while maintaining backward compatibility?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"name": "ASTNoexceptExpr", "docstring": "", "methods": ["__init__", "__eq__", "__hash__", "_stringify", "get_id", "describe_signature"], "attributes": [], "code_location": {"file": "_ast.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/domains/cpp", "start_line": 1125, "end_line": 1149}, "type": "class"}, {"name": "ASTNoexceptSpec", "docstring": "", "methods": ["__init__", "__eq__", "__hash__", "_stringify", "describe_signature"], "attributes": [], "code_location": {"file": "_ast.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/domains/cpp", "start_line": 2064, "end_line": 2088}, "type": "class"}, {"name": "describe_signature", "is_method": true, "class_name": "ASTNoexceptSpec", "parameters": ["self", "signode", "mode", "env", "symbol"], "calls": ["addnodes.desc_sig_keyword", "addnodes.desc_sig_punctuation", "self.expr.describe_signature", "addnodes.desc_sig_punctuation"], "code_location": {"file": "_ast.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/domains/cpp", "start_line": 2081, "end_line": 2088}, "code_snippet": "    def describe_signature(\n        self, signode: TextElement, mode: str, env: BuildEnvironment, symbol: Symbol\n    ) -> None:\n        signode += addnodes.desc_sig_keyword('noexcept', 'noexcept')\n        if self.expr:\n            signode += addnodes.desc_sig_punctuation('(', '(')\n            self.expr.describe_signature(signode, 'markType', env, symbol)\n            signode += addnodes.desc_sig_punctuation(')', ')')\n", "type": "function"}, {"name": "describe_signature", "is_method": true, "class_name": "ASTNoexceptExpr", "parameters": ["self", "signode", "mode", "env", "symbol"], "calls": ["addnodes.desc_sig_keyword", "addnodes.desc_sig_punctuation", "self.expr.describe_signature", "addnodes.desc_sig_punctuation"], "code_location": {"file": "_ast.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/domains/cpp", "start_line": 1143, "end_line": 1149}, "code_snippet": "    def describe_signature(\n        self, signode: TextElement, mode: str, env: BuildEnvironment, symbol: Symbol\n    ) -> None:\n        signode += addnodes.desc_sig_keyword('noexcept', 'noexcept')\n        signode += addnodes.desc_sig_punctuation('(', '(')\n        self.expr.describe_signature(signode, mode, env, symbol)\n        signode += addnodes.desc_sig_punctuation(')', ')')\n", "type": "function"}, {"name": "test_domain_cpp_ast_expressions", "is_method": false, "class_name": null, "parameters": [], "calls": ["expr_check", "expr_check", "expr_check", "expr_check", "expr_check", "expr_check", "expr_check", "expr_check", "expr_check", "expr_check", "expr_check", "expr_check", "expr_check", "expr_check", "expr_check", "expr_check", "expr_check", "expr_check", "expr_check", "expr_check", "expr_check", "expr_check", "expr_check", "expr_check", "expr_check", "expr_check", "expr_check", "expr_check", "expr_check", "expr_check", "expr_check", "expr_check", "expr_check", "expr_check", "expr_check", "expr_check", "expr_check", "expr_check", "expr_check", "expr_check", "expr_check", "expr_check", "expr_check", "expr_check", "expr_check", "expr_check", "expr_check", "expr_check", "expr_check", "expr_check", "expr_check", "expr_check", "expr_check", "expr_check", "expr_check", "expr_check", "expr_check", "expr_check", "expr_check", "expr_check", "expr_check", "expr_check", "expr_check", "expr_check", "expr_check", "expr_check", "expr_check", "expr_check", "expr_check", "expr_check", "expr_check", "expr_check", "expr_check", "expr_check", "expr_check", "expr_check", "expr_check", "expr_check", "expr_check", "expr_check", "expr_check", "expr_check", "expr_check", "expr_check", "expr_check", "expr_check", "expr_check", "expr_check", "expr_check", "expr_check", "expr_check", "expr_check", "expr_check", "expr_check", "expr_check", "expr_check", "expr_check", "expr_check", "expr_check", "expr_check", "expr_check", "expr_check", "expr_check", "expr_check", "check", "expr_check", "check", "check", "expr_check", "expr_check", "expr_check", "check", "DefinitionParser", "parser.parse_expression", "str", "ast.get_display_string", "expr_check", "expr_check", "expr_check", "expr_check", "expr_check", "print", "print", "print", "print", "print", "print", "print", "expr_check", "expr_check", "expr_check", "expr_check", "expr.format", "Config", "expr_check", "expr_check", "i.replace", "i.replace", "f.replace", "f.replace", "f.replace", "expr.replace", "expr.replace", "expr.replace", "expr.replace"], "code_location": {"file": "test_domain_cpp.py", "path": "/data3/pwh/swebench-repos/sphinx/tests/test_domains", "start_line": 181, "end_line": 452}, "code_snippet": "def test_domain_cpp_ast_expressions() -> None:\n    def expr_check(expr, id, id4=None):\n        ids = 'IE1CIA%s_1aE'\n        # call .format() on the expr to unescape double curly braces\n        id_dict = {2: ids % expr.format(), 3: ids % id}\n        if id4 is not None:\n            id_dict[4] = ids % id4\n        check('class', 'template<> {key}C<a[%s]>' % expr, id_dict)\n\n        class Config:\n            cpp_id_attributes = ['id_attr']\n            cpp_paren_attributes = ['paren_attr']\n\n        parser = DefinitionParser(expr, location=None, config=Config())\n        parser.allowFallbackExpressionParsing = False\n        ast = parser.parse_expression()\n        res = str(ast)\n        if res != expr:\n            print()\n            print('Input:    ', expr)\n            print('Result:   ', res)\n            raise DefinitionError\n        display_string = ast.get_display_string()\n        if res != display_string:\n            # note: if the expression contains an anon name then this will trigger a falsely\n            print()\n            print('Input:    ', expr)\n            print('Result:   ', res)\n            print('Display:  ', display_string)\n            raise DefinitionError\n\n    # primary\n    expr_check('nullptr', 'LDnE')\n    expr_check('true', 'L1E')\n    expr_check('false', 'L0E')\n    ints = [\n        '5',\n        '0',\n        '075',\n        '0x0123456789ABCDEF',\n        '0XF',\n        '0b1',\n        '0B1',\n        \"0b0'1'0\",\n        \"00'1'2\",\n        \"0x0'1'2\",\n        \"1'2'3\",\n    ]\n    unsigned_suffix = ['', 'u', 'U']\n    long_suffix = ['', 'l', 'L', 'll', 'LL']\n    for i in ints:\n        for u in unsigned_suffix:\n            for l in long_suffix:\n                expr = i + u + l\n                expr_check(expr, 'L' + expr.replace(\"'\", '') + 'E')\n                expr = i + l + u\n                expr_check(expr, 'L' + expr.replace(\"'\", '') + 'E')\n    decimal_floats = [\n        '5e42',\n        '5e+42',\n        '5e-42',\n        '5.',\n        '5.e42',\n        '5.e+42',\n        '5.e-42',\n        '.5',\n        '.5e42',\n        '.5e+42',\n        '.5e-42',\n        '5.0',\n        '5.0e42',\n        '5.0e+42',\n        '5.0e-42',\n        \"1'2'3e7'8'9\",\n        \"1'2'3.e7'8'9\",\n        \".4'5'6e7'8'9\",\n        \"1'2'3.4'5'6e7'8'9\",\n    ]\n    hex_floats = [\n        'ApF',\n        'Ap+F',\n        'Ap-F',\n        'A.',\n        'A.pF',\n        'A.p+F',\n        'A.p-F',\n        '.A',\n        '.ApF',\n        '.Ap+F',\n        '.Ap-F',\n        'A.B',\n        'A.BpF',\n        'A.Bp+F',\n        'A.Bp-F',\n        \"A'B'Cp1'2'3\",\n        \"A'B'C.p1'2'3\",\n        \".D'E'Fp1'2'3\",\n        \"A'B'C.D'E'Fp1'2'3\",\n    ]\n    for suffix in ('', 'f', 'F', 'l', 'L'):\n        for e in decimal_floats:\n            expr = e + suffix\n            expr_check(expr, 'L' + expr.replace(\"'\", '') + 'E')\n        for e in hex_floats:\n            expr = '0x' + e + suffix\n            expr_check(expr, 'L' + expr.replace(\"'\", '') + 'E')\n    expr_check('\"abc\\\\\"cba\"', 'LA8_KcE')  # string\n    expr_check('this', 'fpT')\n    # character literals\n    char_prefix_and_ids = [('', 'c'), ('u8', 'c'), ('u', 'Ds'), ('U', 'Di'), ('L', 'w')]\n    chars = [\n        ('a', '97'),\n        ('\\\\n', '10'),\n        ('\\\\012', '10'),\n        ('\\\\0', '0'),\n        ('\\\\x0a', '10'),\n        ('\\\\x0A', '10'),\n        ('\\\\u0a42', '2626'),\n        ('\\\\u0A42', '2626'),\n        ('\\\\U0001f34c', '127820'),\n        ('\\\\U0001F34C', '127820'),\n    ]\n    for p, t in char_prefix_and_ids:\n        for c, val in chars:\n            expr_check(f\"{p}'{c}'\", t + val)\n    # user-defined literals\n    for i in ints:\n        expr_check(i + '_udl', 'clL_Zli4_udlEL' + i.replace(\"'\", '') + 'EE')\n        expr_check(i + 'uludl', 'clL_Zli5uludlEL' + i.replace(\"'\", '') + 'EE')\n    for f in decimal_floats:\n        expr_check(f + '_udl', 'clL_Zli4_udlEL' + f.replace(\"'\", '') + 'EE')\n        expr_check(f + 'fudl', 'clL_Zli4fudlEL' + f.replace(\"'\", '') + 'EE')\n    for f in hex_floats:\n        expr_check('0x' + f + '_udl', 'clL_Zli4_udlEL0x' + f.replace(\"'\", '') + 'EE')\n    for p, t in char_prefix_and_ids:\n        for c, val in chars:\n            expr_check(f\"{p}'{c}'_udl\", 'clL_Zli4_udlE' + t + val + 'E')\n    expr_check('\"abc\"_udl', 'clL_Zli4_udlELA3_KcEE')\n    # from https://github.com/sphinx-doc/sphinx/issues/7294\n    expr_check('6.62607015e-34q_J', 'clL_Zli3q_JEL6.62607015e-34EE')\n\n    # fold expressions, paren, name\n    expr_check('(... + Ns)', '(... + Ns)', id4='flpl2Ns')\n    expr_check('(Ns + ...)', '(Ns + ...)', id4='frpl2Ns')\n    expr_check('(Ns + ... + 0)', '(Ns + ... + 0)', id4='fLpl2NsL0E')\n    expr_check('(5)', 'L5E')\n    expr_check('C', '1C')\n    # postfix\n    expr_check('A(2)', 'cl1AL2EE')\n    expr_check('A[2]', 'ix1AL2E')\n    expr_check('a.b.c', 'dtdt1a1b1c')\n    expr_check('a->b->c', 'ptpt1a1b1c')\n    expr_check('i++', 'pp1i')\n    expr_check('i--', 'mm1i')\n    expr_check('dynamic_cast<T&>(i)++', 'ppdcR1T1i')\n    expr_check('static_cast<T&>(i)++', 'ppscR1T1i')\n    expr_check('reinterpret_cast<T&>(i)++', 'pprcR1T1i')\n    expr_check('const_cast<T&>(i)++', 'ppccR1T1i')\n    expr_check('typeid(T).name', 'dtti1T4name')\n    expr_check('typeid(a + b).name', 'dttepl1a1b4name')\n    # unary\n    expr_check('++5', 'pp_L5E')\n    expr_check('--5', 'mm_L5E')\n    expr_check('*5', 'deL5E')\n    expr_check('&5', 'adL5E')\n    expr_check('+5', 'psL5E')\n    expr_check('-5', 'ngL5E')\n    expr_check('!5', 'ntL5E')\n    expr_check('not 5', 'ntL5E')\n    expr_check('~5', 'coL5E')\n    expr_check('compl 5', 'coL5E')\n    expr_check('sizeof...(a)', 'sZ1a')\n    expr_check('sizeof(T)', 'st1T')\n    expr_check('sizeof -42', 'szngL42E')\n    expr_check('alignof(T)', 'at1T')\n    expr_check('noexcept(-42)', 'nxngL42E')\n    # new-expression\n    expr_check('new int', 'nw_iE')\n    expr_check('new volatile int', 'nw_ViE')\n    expr_check('new int[42]', 'nw_AL42E_iE')\n    expr_check('new int()', 'nw_ipiE')\n    expr_check('new int(5, 42)', 'nw_ipiL5EL42EE')\n    expr_check('::new int', 'nw_iE')\n    expr_check('new int{{}}', 'nw_iilE')\n    expr_check('new int{{5, 42}}', 'nw_iilL5EL42EE')\n    # delete-expression\n    expr_check('delete p', 'dl1p')\n    expr_check('delete [] p', 'da1p')\n    expr_check('::delete p', 'dl1p')\n    expr_check('::delete [] p', 'da1p')\n    # cast\n    expr_check('(int)2', 'cviL2E')\n    # binary op\n    expr_check('5 || 42', 'ooL5EL42E')\n    expr_check('5 or 42', 'ooL5EL42E')\n    expr_check('5 && 42', 'aaL5EL42E')\n    expr_check('5 and 42', 'aaL5EL42E')\n    expr_check('5 | 42', 'orL5EL42E')\n    expr_check('5 bitor 42', 'orL5EL42E')\n    expr_check('5 ^ 42', 'eoL5EL42E')\n    expr_check('5 xor 42', 'eoL5EL42E')\n    expr_check('5 & 42', 'anL5EL42E')\n    expr_check('5 bitand 42', 'anL5EL42E')\n    # ['==', '!=']\n    expr_check('5 == 42', 'eqL5EL42E')\n    expr_check('5 != 42', 'neL5EL42E')\n    expr_check('5 not_eq 42', 'neL5EL42E')\n    # ['<=', '>=', '<', '>', '<=>']\n    expr_check('5 <= 42', 'leL5EL42E')\n    expr_check('A <= 42', 'le1AL42E')\n    expr_check('5 >= 42', 'geL5EL42E')\n    expr_check('5 < 42', 'ltL5EL42E')\n    expr_check('A < 42', 'lt1AL42E')\n    expr_check('5 > 42', 'gtL5EL42E')\n    expr_check('A > 42', 'gt1AL42E')\n    expr_check('5 <=> 42', 'ssL5EL42E')\n    expr_check('A <=> 42', 'ss1AL42E')\n    # ['<<', '>>']\n    expr_check('5 << 42', 'lsL5EL42E')\n    expr_check('A << 42', 'ls1AL42E')\n    expr_check('5 >> 42', 'rsL5EL42E')\n    # ['+', '-']\n    expr_check('5 + 42', 'plL5EL42E')\n    expr_check('5 - 42', 'miL5EL42E')\n    # ['*', '/', '%']\n    expr_check('5 * 42', 'mlL5EL42E')\n    expr_check('5 / 42', 'dvL5EL42E')\n    expr_check('5 % 42', 'rmL5EL42E')\n    # ['.*', '->*']\n    expr_check('5 .* 42', 'dsL5EL42E')\n    expr_check('5 ->* 42', 'pmL5EL42E')\n    # conditional\n    expr_check('5 ? 7 : 3', 'quL5EL7EL3E')\n    # assignment\n    expr_check('a = 5', 'aS1aL5E')\n    expr_check('a *= 5', 'mL1aL5E')\n    expr_check('a /= 5', 'dV1aL5E')\n    expr_check('a %= 5', 'rM1aL5E')\n    expr_check('a += 5', 'pL1aL5E')\n    expr_check('a -= 5', 'mI1aL5E')\n    expr_check('a >>= 5', 'rS1aL5E')\n    expr_check('a <<= 5', 'lS1aL5E')\n    expr_check('a &= 5', 'aN1aL5E')\n    expr_check('a and_eq 5', 'aN1aL5E')\n    expr_check('a ^= 5', 'eO1aL5E')\n    expr_check('a xor_eq 5', 'eO1aL5E')\n    expr_check('a |= 5', 'oR1aL5E')\n    expr_check('a or_eq 5', 'oR1aL5E')\n    expr_check('a = {{1, 2, 3}}', 'aS1ailL1EL2EL3EE')\n    # complex assignment and conditional\n    expr_check('5 = 6 = 7', 'aSL5EaSL6EL7E')\n    expr_check('5 = 6 ? 7 = 8 : 3', 'aSL5EquL6EaSL7EL8EL3E')\n    # comma operator\n    expr_check('a, 5', 'cm1aL5E')\n\n    # Additional tests\n    # a < expression that starts with something that could be a template\n    expr_check('A < 42', 'lt1AL42E')\n    check(\n        'function',\n        'template<> void f(A<B, 2> &v)',\n        {2: 'IE1fR1AI1BX2EE', 3: 'IE1fR1AI1BXL2EEE', 4: 'IE1fvR1AI1BXL2EEE'},\n    )\n    expr_check('A<1>::value', 'N1AIXL1EEE5valueE')\n    check('class', 'template<int T = 42> {key}A', {2: 'I_iE1A'})\n    check('enumerator', '{key}A = std::numeric_limits<unsigned long>::max()', {2: '1A'})\n\n    expr_check('operator()()', 'clclE')\n    expr_check('operator()<int>()', 'clclIiEE')\n\n    # pack expansion\n    expr_check('a(b(c, 1 + d...)..., e(f..., g))', 'cl1aspcl1b1cspplL1E1dEcl1esp1f1gEE')\n", "type": "function"}, {"name": "__init__", "is_method": true, "class_name": "CPPExprRole", "parameters": ["self", "asCode"], "calls": ["__init__", "super"], "code_location": {"file": "__init__.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/domains/cpp", "start_line": 888, "end_line": 895}, "code_snippet": "    def __init__(self, asCode: bool) -> None:\n        super().__init__()\n        if asCode:\n            # render the expression as inline code\n            self.class_type = 'cpp-expr'\n        else:\n            # render the expression as inline text\n            self.class_type = 'cpp-texpr'\n", "type": "function"}, {"name": "CPPExprRole", "docstring": "", "methods": ["__init__", "run"], "attributes": [], "code_location": {"file": "__init__.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/domains/cpp", "start_line": 887, "end_line": 922}, "type": "class"}, {"name": "__init__", "is_method": true, "class_name": "ASTDeclaration", "parameters": ["self", "objectType", "directiveType", "visibility", "templatePrefix", "declaration", "trailingRequiresClause", "semicolon"], "calls": [], "code_location": {"file": "_ast.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/domains/cpp", "start_line": 4500, "end_line": 4524}, "code_snippet": "    def __init__(\n        self,\n        objectType: str,\n        directiveType: str | None = None,\n        visibility: str | None = None,\n        templatePrefix: ASTTemplateDeclarationPrefix | None = None,\n        declaration: Any = None,\n        trailingRequiresClause: ASTRequiresClause | None = None,\n        semicolon: bool = False,\n    ) -> None:\n        self.objectType = objectType\n        self.directiveType = directiveType\n        self.visibility = visibility\n        self.templatePrefix = templatePrefix\n        self.declaration = declaration\n        self.trailingRequiresClause = trailingRequiresClause\n        self.semicolon = semicolon\n\n        self.symbol: Symbol | None = None\n        # set by CPPObject._add_enumerator_to_parent\n        self.enumeratorScopedSymbol: Symbol | None = None\n\n        # the cache assumes that by the time get_newest_id is called, no\n        # further changes will be made to this object\n        self._newest_id_cache: str | None = None\n", "type": "function"}, {"name": "test_domain_cpp_ast_class_definitions", "is_method": false, "class_name": null, "parameters": [], "calls": ["check", "check", "check", "check", "check", "check", "check", "check", "check", "check", "check", "check", "check", "check", "check", "check", "check", "check", "check", "check"], "code_location": {"file": "test_domain_cpp.py", "path": "/data3/pwh/swebench-repos/sphinx/tests/test_domains", "start_line": 1004, "end_line": 1050}, "code_snippet": "def test_domain_cpp_ast_class_definitions() -> None:\n    check('class', 'public A', {1: 'A', 2: '1A'}, output='{key}A')\n    check('class', 'private {key}A', {1: 'A', 2: '1A'})\n    check('class', '{key}A final', {1: 'A', 2: '1A'})\n\n    # test bases\n    check('class', '{key}A', {1: 'A', 2: '1A'})\n    check('class', '{key}A::B::C', {1: 'A::B::C', 2: 'N1A1B1CE'})\n    check('class', '{key}A : B', {1: 'A', 2: '1A'})\n    check('class', '{key}A : private B', {1: 'A', 2: '1A'})\n    check('class', '{key}A : public B', {1: 'A', 2: '1A'})\n    check('class', '{key}A : B, C', {1: 'A', 2: '1A'})\n    check('class', '{key}A : B, protected C, D', {1: 'A', 2: '1A'})\n    check(\n        'class',\n        'A : virtual private B',\n        {1: 'A', 2: '1A'},\n        output='{key}A : private virtual B',\n    )\n    check('class', '{key}A : private virtual B', {1: 'A', 2: '1A'})\n    check('class', '{key}A : B, virtual C', {1: 'A', 2: '1A'})\n    check('class', '{key}A : public virtual B', {1: 'A', 2: '1A'})\n    check('class', '{key}A : B, C...', {1: 'A', 2: '1A'})\n    check('class', '{key}A : B..., C', {1: 'A', 2: '1A'})\n\n    # from https://github.com/sphinx-doc/sphinx/issues/4094\n    check(\n        'class',\n        'template<class, class = std::void_t<>> {key}has_var',\n        {2: 'I00E7has_var'},\n    )\n    check(\n        'class',\n        'template<class T> {key}has_var<T, std::void_t<decltype(&T::var)>>',\n        {2: 'I0E7has_varI1TNSt6void_tIDTadN1T3varEEEEE'},\n    )\n\n    check(\n        'class',\n        'template<typename ...Ts> {key}T<int (*)(Ts)...>',\n        {2: 'IDpE1TIJPFi2TsEEE'},\n    )\n    check(\n        'class',\n        'template<int... Is> {key}T<(Is)...>',\n        {2: 'I_DpiE1TIJX(Is)EEE', 3: 'I_DpiE1TIJX2IsEEE'},\n    )\n", "type": "function"}, {"name": "__init__", "is_method": true, "class_name": "CExprRole", "parameters": ["self", "asCode"], "calls": ["__init__", "super"], "code_location": {"file": "__init__.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/domains/c", "start_line": 733, "end_line": 740}, "code_snippet": "    def __init__(self, asCode: bool) -> None:\n        super().__init__()\n        if asCode:\n            # render the expression as inline code\n            self.class_type = 'c-expr'\n        else:\n            # render the expression as inline text\n            self.class_type = 'c-texpr'\n", "type": "function"}], "retrieved_count": 10, "cost_time": 1.1148509979248047}
{"question": "How should the process that records objects for cross-referencing and generates index entries be designed so that flags indicating method decorator types are consistently reflected in both the storage mapping object names to documentation locations and the hierarchical structure of documentation nodes without duplicating the code that checks decorator properties across the components that process these flags?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"name": "add_target_and_index", "is_method": true, "class_name": "ConfigurationValue", "parameters": ["self", "name", "sig", "signode"], "calls": ["make_id", "append", "self.state.document.note_explicit_target", "append", "domain.note_object"], "code_location": {"file": "__init__.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/domains/std", "start_line": 142, "end_line": 151}, "code_snippet": "    def add_target_and_index(\n        self, name: str, sig: str, signode: desc_signature\n    ) -> None:\n        node_id = make_id(self.env, self.state.document, self.objtype, name)\n        signode['ids'].append(node_id)\n        self.state.document.note_explicit_target(signode)\n        index_entry = self.index_template % name\n        self.indexnode['entries'].append(('pair', index_entry, node_id, '', None))\n        domain = self.env.domains.standard_domain\n        domain.note_object(self.objtype, name, node_id, location=signode)\n", "type": "function"}, {"name": "add_target_and_index", "is_method": true, "class_name": "CPPObject", "parameters": ["self", "ast", "sig", "signode"], "calls": ["range", "ids.reverse", "lstrip", "match", "logger.warning", "self.get_index_text", "append", "append", "self.state.document.note_explicit_target", "ast.get_id", "ids.append", "get_display_string", "name.startswith", "re.compile", "self.get_location", "append", "ast.symbol.get_full_nested_name", "len"], "code_location": {"file": "__init__.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/domains/cpp", "start_line": 226, "end_line": 291}, "code_snippet": "    def add_target_and_index(\n        self, ast: ASTDeclaration, sig: str, signode: TextElement\n    ) -> None:\n        # general note: name must be lstrip(':')'ed, to remove \"::\"\n        ids = []\n        for i in range(1, _max_id + 1):\n            try:\n                id = ast.get_id(version=i)\n                ids.append(id)\n            except NoOldIdError:\n                assert i < _max_id\n        # let's keep the newest first\n        ids.reverse()\n        newest_id = ids[0]\n        assert newest_id  # shouldn't be None\n        if not re.compile(r'^[a-zA-Z0-9_]*$').match(newest_id):\n            logger.warning(\n                'Index id generation for C++ object \"%s\" failed, please '\n                'report as bug (id=%s).',\n                ast,\n                newest_id,\n                location=self.get_location(),\n            )\n\n        name = ast.symbol.get_full_nested_name().get_display_string().lstrip(':')\n        # Add index entry, but not if it's a declaration inside a concept\n        is_in_concept = False\n        s = ast.symbol.parent\n        while s is not None:\n            decl = s.declaration\n            s = s.parent\n            if decl is None:\n                continue\n            if decl.objectType == 'concept':\n                is_in_concept = True\n                break\n        if not is_in_concept and 'no-index-entry' not in self.options:\n            stripped_name = name\n            for prefix in self.config.cpp_index_common_prefix:\n                if name.startswith(prefix):\n                    stripped_name = stripped_name[len(prefix) :]\n                    break\n            index_text = self.get_index_text(stripped_name)\n            self.indexnode['entries'].append((\n                'single',\n                index_text,\n                newest_id,\n                '',\n                None,\n            ))\n\n        if newest_id not in self.state.document.ids:\n            # if the name is not unique, the first one will win\n            names = self.env.domaindata['cpp']['names']\n            if name not in names:\n                names[name] = ast.symbol.docname\n            # always add the newest id\n            assert newest_id\n            signode['ids'].append(newest_id)\n            # only add compatibility ids when there are no conflicts\n            for id in ids[1:]:\n                if not id:  # is None when the element didn't exist in that version\n                    continue\n                if id not in self.state.document.ids:\n                    signode['ids'].append(id)\n            self.state.document.note_explicit_target(signode)\n", "type": "function"}, {"name": "add_target_and_index", "is_method": true, "class_name": "ReSTMarkup", "parameters": ["self", "name", "sig", "signode"], "calls": ["make_id", "append", "self.state.document.note_explicit_target", "domain.note_object", "self.get_index_text", "append"], "code_location": {"file": "rst.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/domains", "start_line": 49, "end_line": 67}, "code_snippet": "    def add_target_and_index(\n        self, name: str, sig: str, signode: desc_signature\n    ) -> None:\n        node_id = make_id(self.env, self.state.document, self.objtype, name)\n        signode['ids'].append(node_id)\n        self.state.document.note_explicit_target(signode)\n\n        domain = self.env.domains.restructuredtext_domain\n        domain.note_object(self.objtype, name, node_id, location=signode)\n\n        if 'no-index-entry' not in self.options:\n            if index_text := self.get_index_text(self.objtype, name):\n                self.indexnode['entries'].append((\n                    'single',\n                    index_text,\n                    node_id,\n                    '',\n                    None,\n                ))\n", "type": "function"}, {"name": "add_target_and_index", "is_method": true, "class_name": "GenericObject", "parameters": ["self", "name", "sig", "signode"], "calls": ["make_id", "append", "self.state.document.note_explicit_target", "std.note_object", "self.indextemplate.find", "append", "strip", "strip"], "code_location": {"file": "__init__.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/domains/std", "start_line": 66, "end_line": 84}, "code_snippet": "    def add_target_and_index(\n        self, name: str, sig: str, signode: desc_signature\n    ) -> None:\n        node_id = make_id(self.env, self.state.document, self.objtype, name)\n        signode['ids'].append(node_id)\n        self.state.document.note_explicit_target(signode)\n\n        if self.indextemplate:\n            colon = self.indextemplate.find(':')\n            if colon != -1:\n                indextype = self.indextemplate[:colon].strip()\n                indexentry = self.indextemplate[colon + 1 :].strip() % (name,)\n            else:\n                indextype = 'single'\n                indexentry = self.indextemplate % (name,)\n            self.indexnode['entries'].append((indextype, indexentry, node_id, '', None))\n\n        std = self.env.domains.standard_domain\n        std.note_object(self.objtype, name, node_id, location=signode)\n", "type": "function"}, {"name": "add_target_and_index", "is_method": true, "class_name": "JSObject", "parameters": ["self", "name_obj", "sig", "signode"], "calls": ["self.env.ref_context.get", "make_id", "append", "self.state.document.note_explicit_target", "domain.note_object", "self.get_index_text", "append"], "code_location": {"file": "javascript.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/domains", "start_line": 157, "end_line": 177}, "code_snippet": "    def add_target_and_index(\n        self, name_obj: tuple[str, str], sig: str, signode: desc_signature\n    ) -> None:\n        mod_name = self.env.ref_context.get('js:module', '')\n        fullname = (f'{mod_name}.' if mod_name else '') + name_obj[0]\n        node_id = make_id(self.env, self.state.document, '', fullname)\n        signode['ids'].append(node_id)\n        self.state.document.note_explicit_target(signode)\n\n        domain = self.env.domains.javascript_domain\n        domain.note_object(fullname, self.objtype, node_id, location=signode)\n\n        if 'no-index-entry' not in self.options:\n            if index_text := self.get_index_text(mod_name, name_obj):\n                self.indexnode['entries'].append((\n                    'single',\n                    index_text,\n                    node_id,\n                    '',\n                    None,\n                ))\n", "type": "function"}, {"name": "add_target_and_index", "is_method": true, "class_name": "PyFunction", "parameters": ["self", "name_cls", "sig", "signode"], "calls": ["add_target_and_index", "self.options.get", "super", "self.env.ref_context.get", "append", "append", "_"], "code_location": {"file": "__init__.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/domains/python", "start_line": 105, "end_line": 119}, "code_snippet": "    def add_target_and_index(\n        self, name_cls: tuple[str, str], sig: str, signode: desc_signature\n    ) -> None:\n        super().add_target_and_index(name_cls, sig, signode)\n        if 'no-index-entry' not in self.options:\n            modname = self.options.get('module', self.env.ref_context.get('py:module'))\n            node_id = signode['ids'][0]\n\n            name, _cls = name_cls\n            if modname:\n                text = _('%s() (in module %s)') % (name, modname)\n                self.indexnode['entries'].append(('single', text, node_id, '', None))\n            else:\n                text = f'built-in function; {name}()'\n                self.indexnode['entries'].append(('pair', text, node_id, '', None))\n", "type": "function"}, {"name": "add_target_and_index", "is_method": true, "class_name": "PyObject", "parameters": ["self", "name_cls", "sig", "signode"], "calls": ["self.options.get", "make_id", "append", "self.state.document.note_explicit_target", "domain.note_object", "self.options.get", "self.env.ref_context.get", "domain.note_object", "self.get_index_text", "append"], "code_location": {"file": "_object.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/domains/python", "start_line": 415, "end_line": 441}, "code_snippet": "    def add_target_and_index(\n        self, name_cls: tuple[str, str], sig: str, signode: desc_signature\n    ) -> None:\n        mod_name = self.options.get('module', self.env.ref_context.get('py:module'))\n        fullname = (f'{mod_name}.' if mod_name else '') + name_cls[0]\n        node_id = make_id(self.env, self.state.document, '', fullname)\n        signode['ids'].append(node_id)\n        self.state.document.note_explicit_target(signode)\n\n        domain = self.env.domains.python_domain\n        domain.note_object(fullname, self.objtype, node_id, location=signode)\n\n        canonical_name = self.options.get('canonical')\n        if canonical_name:\n            domain.note_object(\n                canonical_name, self.objtype, node_id, aliased=True, location=signode\n            )\n\n        if 'no-index-entry' not in self.options:\n            if index_text := self.get_index_text(mod_name, name_cls):  # type: ignore[arg-type]\n                self.indexnode['entries'].append((\n                    'single',\n                    index_text,\n                    node_id,\n                    '',\n                    None,\n                ))\n", "type": "function"}, {"name": "test_pydecoratormethod_signature", "is_method": false, "class_name": null, "parameters": ["app"], "calls": ["pytest.mark.sphinx", "restructuredtext.parse", "assert_node", "assert_node"], "code_location": {"file": "test_domain_py_pyobject.py", "path": "/data3/pwh/swebench-repos/sphinx/tests/test_domains", "start_line": 975, "end_line": 1002}, "code_snippet": "def test_pydecoratormethod_signature(app):\n    text = '.. py:decoratormethod:: deco'\n    domain = app.env.domains.python_domain\n    doctree = restructuredtext.parse(app, text)\n    assert_node(\n        doctree,\n        (\n            addnodes.index,\n            [\n                desc,\n                (\n                    [desc_signature, ([desc_addname, '@'], [desc_name, 'deco'])],\n                    desc_content,\n                ),\n            ],\n        ),\n    )\n    assert_node(\n        doctree[1],\n        addnodes.desc,\n        desctype='method',\n        domain='py',\n        objtype='method',\n        no_index=False,\n    )\n\n    assert 'deco' in domain.objects\n    assert domain.objects['deco'] == ('index', 'deco', 'method', False)\n", "type": "function"}, {"name": "add_target_and_index", "is_method": true, "class_name": "ObjectDescription", "parameters": ["self", "name", "sig", "signode"], "calls": [], "code_location": {"file": "__init__.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/directives", "start_line": 116, "end_line": 123}, "code_snippet": "    def add_target_and_index(\n        self, name: ObjDescT, sig: str, signode: desc_signature\n    ) -> None:\n        \"\"\"Add cross-reference IDs and entries to self.indexnode, if applicable.\n\n        *name* is whatever :meth:`handle_signature()` returned.\n        \"\"\"\n        pass  # do nothing by default\n", "type": "function"}, {"name": "add_target_and_index", "is_method": true, "class_name": "CObject", "parameters": ["self", "ast", "sig", "signode"], "calls": ["range", "ids.reverse", "lstrip", "append", "self.state.document.note_explicit_target", "self.get_index_text", "append", "ast.get_id", "ids.append", "get_display_string", "append", "ast.symbol.get_full_nested_name"], "code_location": {"file": "__init__.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/domains/c", "start_line": 163, "end_line": 200}, "code_snippet": "    def add_target_and_index(\n        self, ast: ASTDeclaration, sig: str, signode: TextElement\n    ) -> None:\n        ids = []\n        for i in range(1, _max_id + 1):\n            try:\n                id = ast.get_id(version=i)\n                ids.append(id)\n            except NoOldIdError:\n                assert i < _max_id\n        # let's keep the newest first\n        ids.reverse()\n        newest_id = ids[0]\n        assert newest_id  # shouldn't be None\n\n        name = ast.symbol.get_full_nested_name().get_display_string().lstrip('.')\n        if newest_id not in self.state.document.ids:\n            # always add the newest id\n            assert newest_id\n            signode['ids'].append(newest_id)\n            # only add compatibility ids when there are no conflicts\n            for id in ids[1:]:\n                if not id:  # is None when the element didn't exist in that version\n                    continue\n                if id not in self.state.document.ids:\n                    signode['ids'].append(id)\n\n            self.state.document.note_explicit_target(signode)\n\n        if 'no-index-entry' not in self.options:\n            index_text = self.get_index_text(name)\n            self.indexnode['entries'].append((\n                'single',\n                index_text,\n                newest_id,\n                '',\n                None,\n            ))\n", "type": "function"}], "retrieved_count": 10, "cost_time": 1.1152076721191406}
{"question": "How does the method that exhausts all remaining lines coordinate with the deque-based iterator state management to ensure complete line consumption without causing state inconsistencies in the Google-style docstring parser?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"name": "_consume_to_end", "is_method": true, "class_name": "GoogleDocstring", "parameters": ["self"], "calls": ["lines.append", "self._lines.next"], "code_location": {"file": "docstring.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/ext/napoleon", "start_line": 567, "end_line": 571}, "code_snippet": "    def _consume_to_end(self) -> list[str]:\n        lines = []\n        while self._lines:\n            lines.append(self._lines.next())\n        return lines\n", "type": "function"}, {"name": "_consume_empty", "is_method": true, "class_name": "GoogleDocstring", "parameters": ["self"], "calls": ["self._lines.get", "lines.append", "self._lines.get", "self._lines.next"], "code_location": {"file": "docstring.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/ext/napoleon", "start_line": 464, "end_line": 470}, "code_snippet": "    def _consume_empty(self) -> list[str]:\n        lines = []\n        line = self._lines.get(0)\n        while self._lines and not line:\n            lines.append(self._lines.next())\n            line = self._lines.get(0)\n        return lines\n", "type": "function"}, {"name": "_parse", "is_method": true, "class_name": "GoogleDocstring", "parameters": ["self"], "calls": ["self._consume_empty", "self._parsed_lines.extend", "self._is_section_header", "self._parsed_lines.extend", "contextlib.suppress", "self._parse_attribute_docstring", "self._consume_section_header", "self._get_current_indent", "_directive_regex.match", "self._consume_to_next_section", "self._consume_contiguous", "self._consume_empty", "self._consume_to_next_section", "section.lower"], "code_location": {"file": "docstring.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/ext/napoleon", "start_line": 823, "end_line": 852}, "code_snippet": "    def _parse(self) -> None:\n        self._parsed_lines = self._consume_empty()\n\n        if self._name and self._what in {'attribute', 'data', 'property'}:\n            res: list[str] = []\n            with contextlib.suppress(StopIteration):\n                res = self._parse_attribute_docstring()\n\n            self._parsed_lines.extend(res)\n            return\n\n        while self._lines:\n            if self._is_section_header():\n                try:\n                    section = self._consume_section_header()\n                    self._is_in_section = True\n                    self._section_indent = self._get_current_indent()\n                    if _directive_regex.match(section):\n                        lines = [section, *self._consume_to_next_section()]\n                    else:\n                        lines = self._sections[section.lower()](section)\n                finally:\n                    self._is_in_section = False\n                    self._section_indent = 0\n            else:\n                if not self._parsed_lines:\n                    lines = self._consume_contiguous() + self._consume_empty()\n                else:\n                    lines = self._consume_to_next_section()\n            self._parsed_lines.extend(lines)\n", "type": "function"}, {"name": "_consume_to_next_section", "is_method": true, "class_name": "GoogleDocstring", "parameters": ["self"], "calls": ["self._consume_empty", "self._is_section_break", "lines.append", "self._consume_empty", "self._lines.next"], "code_location": {"file": "docstring.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/ext/napoleon", "start_line": 573, "end_line": 578}, "code_snippet": "    def _consume_to_next_section(self) -> list[str]:\n        self._consume_empty()\n        lines = []\n        while not self._is_section_break():\n            lines.append(self._lines.next())\n        return lines + self._consume_empty()\n", "type": "function"}, {"name": "_consume_contiguous", "is_method": true, "class_name": "GoogleDocstring", "parameters": ["self"], "calls": ["self._lines.get", "lines.append", "self._is_section_header", "self._lines.next"], "code_location": {"file": "docstring.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/ext/napoleon", "start_line": 458, "end_line": 462}, "code_snippet": "    def _consume_contiguous(self) -> list[str]:\n        lines = []\n        while self._lines and self._lines.get(0) and not self._is_section_header():\n            lines.append(self._lines.next())\n        return lines\n", "type": "function"}, {"name": "_consume_usage_section", "is_method": true, "class_name": "GoogleDocstring", "parameters": ["self"], "calls": ["self._dedent", "self._consume_to_next_section"], "code_location": {"file": "docstring.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/ext/napoleon", "start_line": 556, "end_line": 558}, "code_snippet": "    def _consume_usage_section(self) -> list[str]:\n        lines = self._dedent(self._consume_to_next_section())\n        return lines\n", "type": "function"}, {"name": "end_state", "is_method": true, "class_name": "TextTranslator", "parameters": ["self", "wrap", "end", "first"], "calls": ["self.states.pop", "sum", "self.stateindent.pop", "do_format", "extend", "result.append", "my_wrap", "splitlines", "toformat.append", "do_format", "result.append", "result.insert", "result.insert", "join", "pop", "join"], "code_location": {"file": "text.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/writers", "start_line": 427, "end_line": 467}, "code_snippet": "    def end_state(\n        self,\n        wrap: bool = True,\n        end: Sequence[str] | None = ('',),\n        first: str | None = None,\n    ) -> None:\n        content = self.states.pop()\n        maxindent = sum(self.stateindent)\n        indent = self.stateindent.pop()\n        result: list[tuple[int, list[str]]] = []\n        toformat: list[str] = []\n\n        def do_format() -> None:\n            if not toformat:\n                return\n            if wrap:\n                res = my_wrap(''.join(toformat), width=MAXWIDTH - maxindent)\n            else:\n                res = ''.join(toformat).splitlines()\n            if end:\n                res += end\n            result.append((indent, res))\n\n        for itemindent, item in content:\n            if itemindent == -1:\n                toformat.append(item)  # type: ignore[arg-type]\n            else:\n                do_format()\n                result.append((indent + itemindent, item))  # type: ignore[arg-type]\n                toformat = []\n        do_format()\n        if first is not None and result:\n            # insert prefix into first line (ex. *, [1], See also, etc.)\n            newindent = result[0][0] - indent\n            if result[0][1] == ['']:\n                result.insert(0, (newindent, [first]))\n            else:\n                text = first + result[0][1].pop(0)\n                result.insert(0, (newindent, [text]))\n\n        self.states[-1].extend(result)\n", "type": "function"}, {"name": "_strip_empty", "is_method": true, "class_name": "GoogleDocstring", "parameters": ["self", "lines"], "calls": ["enumerate", "reversed", "range", "len", "len"], "code_location": {"file": "docstring.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/ext/napoleon", "start_line": 1063, "end_line": 1080}, "code_snippet": "    def _strip_empty(self, lines: list[str]) -> list[str]:\n        if lines:\n            start = -1\n            for i, line in enumerate(lines):\n                if line:\n                    start = i\n                    break\n            if start == -1:\n                lines = []\n            end = -1\n            for i in reversed(range(len(lines))):\n                line = lines[i]\n                if line:\n                    end = i\n                    break\n            if start > 0 or end + 1 < len(lines):\n                lines = lines[start : end + 1]\n        return lines\n", "type": "function"}, {"name": "_consume_section_header", "is_method": true, "class_name": "NumpyDocstring", "parameters": ["self"], "calls": ["self._lines.next", "_directive_regex.match", "self._lines.next"], "code_location": {"file": "docstring.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/ext/napoleon", "start_line": 1259, "end_line": 1264}, "code_snippet": "    def _consume_section_header(self) -> str:\n        section = self._lines.next()\n        if not _directive_regex.match(section):\n            # Consume the header underline\n            self._lines.next()\n        return section\n", "type": "function"}, {"name": "depart_document", "is_method": true, "class_name": "TextTranslator", "parameters": ["self", "node"], "calls": ["self.end_state", "self.nl.join"], "code_location": {"file": "text.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/writers", "start_line": 472, "end_line": 478}, "code_snippet": "    def depart_document(self, node: Element) -> None:\n        self.end_state()\n        self.body = self.nl.join(\n            line and (' ' * indent + line)\n            for indent, lines in self.states[0]\n            for line in lines\n        )\n", "type": "function"}], "retrieved_count": 10, "cost_time": 1.1380290985107422}
{"question": "Why does the wrapper class for preserving default argument values in the autodoc extension module implement only initialization and representation methods, while the wrapper class for default parameter values in overload function signatures implements equality and hashing methods?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"name": "DefaultValue", "docstring": "A simple wrapper for default value of the parameters of overload functions.", "methods": [], "attributes": [], "code_location": {"file": "inspect.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/util", "start_line": 581, "end_line": 594}, "type": "class"}, {"name": "test_preserve_defaults", "is_method": false, "class_name": null, "parameters": ["app"], "calls": ["pytest.mark.sphinx", "do_autodoc", "list"], "code_location": {"file": "test_ext_autodoc_preserve_defaults.py", "path": "/data3/pwh/swebench-repos/sphinx/tests/test_extensions", "start_line": 20, "end_line": 102}, "code_snippet": "def test_preserve_defaults(app: SphinxTestApp) -> None:\n    color = '0xFFFFFF'\n\n    options = {'members': None}\n    actual = do_autodoc(app, 'module', 'target.preserve_defaults', options)\n    assert list(actual) == [\n        '',\n        '.. py:module:: target.preserve_defaults',\n        '',\n        '',\n        '.. py:class:: Class()',\n        '   :module: target.preserve_defaults',\n        '',\n        '   docstring',\n        '',\n        '',\n        '   .. py:method:: Class.clsmeth(name: str = CONSTANT, sentinel: ~typing.Any = '\n        'SENTINEL, now: ~datetime.datetime = datetime.now(), color: int = %s, *, '\n        'kwarg1, kwarg2=%s) -> None' % (color, color),\n        '      :module: target.preserve_defaults',\n        '      :classmethod:',\n        '',\n        '      docstring',\n        '',\n        '',\n        '   .. py:method:: Class.meth(name: str = CONSTANT, sentinel: ~typing.Any = '\n        'SENTINEL, now: ~datetime.datetime = datetime.now(), color: int = %s, *, '\n        'kwarg1, kwarg2=%s) -> None' % (color, color),\n        '      :module: target.preserve_defaults',\n        '',\n        '      docstring',\n        '',\n        '',\n        '.. py:class:: MultiLine()',\n        '   :module: target.preserve_defaults',\n        '',\n        '   docstring',\n        '',\n        '',\n        '   .. py:property:: MultiLine.prop1',\n        '      :module: target.preserve_defaults',\n        '',\n        '      docstring',\n        '',\n        '',\n        '   .. py:property:: MultiLine.prop2',\n        '      :module: target.preserve_defaults',\n        '',\n        '      docstring',\n        '',\n        '',\n        '   .. py:property:: MultiLine.prop3',\n        '      :module: target.preserve_defaults',\n        '',\n        '      docstring',\n        '',\n        '',\n        '   .. py:property:: MultiLine.prop4',\n        '      :module: target.preserve_defaults',\n        '',\n        '      docstring',\n        '',\n        '',\n        '   .. py:property:: MultiLine.prop5',\n        '      :module: target.preserve_defaults',\n        '',\n        '      docstring',\n        '',\n        '',\n        '.. py:function:: foo(name: str = CONSTANT, sentinel: ~typing.Any = SENTINEL, '\n        'now: ~datetime.datetime = datetime.now(), color: int = %s, *, kwarg1, '\n        'kwarg2=%s) -> None' % (color, color),\n        '   :module: target.preserve_defaults',\n        '',\n        '   docstring',\n        '',\n        '',\n        '.. py:function:: get_sentinel(custom=SENTINEL)',\n        '   :module: target.preserve_defaults',\n        '',\n        '   docstring',\n        '',\n    ]\n", "type": "function"}, {"name": "test_preserve_defaults_special_constructs", "is_method": false, "class_name": null, "parameters": ["app"], "calls": ["pytest.mark.sphinx", "do_autodoc", "list"], "code_location": {"file": "test_ext_autodoc_preserve_defaults.py", "path": "/data3/pwh/swebench-repos/sphinx/tests/test_extensions", "start_line": 110, "end_line": 207}, "code_snippet": "def test_preserve_defaults_special_constructs(app: SphinxTestApp) -> None:\n    options = {'members': None}\n    actual = do_autodoc(\n        app, 'module', 'target.preserve_defaults_special_constructs', options\n    )\n\n    # * dataclasses.dataclass:\n    #   - __init__ source code is not available\n    #   - default values specified at class level are not discovered\n    #   - values wrapped in a field(...) expression cannot be analyzed\n    #     easily even if annotations were to be parsed\n    # * typing.NamedTuple:\n    #   - __init__ source code is not available\n    #   - default values specified at class level are not discovered\n    # * collections.namedtuple:\n    #   - default values are specified as \"default=(d1, d2, ...)\"\n    #\n    # In the future, it might be possible to find some additional default\n    # values by parsing the source code of the annotations but the task is\n    # rather complex.\n\n    assert list(actual) == [\n        '',\n        '.. py:module:: target.preserve_defaults_special_constructs',\n        '',\n        '',\n        '.. py:class:: DataClass('\n        'a: int, b: object = <object object>, c: list[int] = <factory>)',\n        '   :module: target.preserve_defaults_special_constructs',\n        '',\n        '   docstring',\n        '',\n        '',\n        '.. py:class:: DataClassNoInit()',\n        '   :module: target.preserve_defaults_special_constructs',\n        '',\n        '   docstring',\n        '',\n        '',\n        '.. py:class:: MyNamedTuple1('\n        'a: int, b: object = <object object>, c: list[int] = [1, 2, 3])',\n        '   :module: target.preserve_defaults_special_constructs',\n        '',\n        '   docstring',\n        '',\n        '',\n        '   .. py:attribute:: MyNamedTuple1.a',\n        '      :module: target.preserve_defaults_special_constructs',\n        '      :type: int',\n        '',\n        '      Alias for field number 0',\n        '',\n        '',\n        '   .. py:attribute:: MyNamedTuple1.b',\n        '      :module: target.preserve_defaults_special_constructs',\n        '      :type: object',\n        '',\n        '      Alias for field number 1',\n        '',\n        '',\n        '   .. py:attribute:: MyNamedTuple1.c',\n        '      :module: target.preserve_defaults_special_constructs',\n        '      :type: list[int]',\n        '',\n        '      Alias for field number 2',\n        '',\n        '',\n        '.. py:class:: MyNamedTuple2(a=0, b=<object object>)',\n        '   :module: target.preserve_defaults_special_constructs',\n        '',\n        '   docstring',\n        '',\n        '',\n        '.. py:class:: MyTypedDict',\n        '   :module: target.preserve_defaults_special_constructs',\n        '',\n        '   docstring',\n        '',\n        '',\n        '.. py:data:: SENTINEL',\n        '   :module: target.preserve_defaults_special_constructs',\n        '   :value: <object object>',\n        '',\n        '   docstring',\n        '',\n        '',\n        '.. py:function:: foo(x, y, z=SENTINEL)',\n        '   :module: target.preserve_defaults_special_constructs',\n        '',\n        '   docstring',\n        '',\n        '',\n        '.. py:function:: ze_lambda(z=SENTINEL)',\n        '   :module: target.preserve_defaults_special_constructs',\n        '',\n        '   docstring',\n        '',\n    ]\n", "type": "function"}, {"name": "format_signature", "is_method": true, "class_name": "MethodDocumenter", "parameters": ["self"], "calls": ["self.parent.__dict__.get", "inspect.is_singledispatch_method", "join", "kwargs.setdefault", "kwargs.setdefault", "format_signature", "sigs.append", "meth.dispatcher.registry.items", "inspect.isstaticmethod", "safe_getattr", "inspect.signature", "inspect.signature", "self.merge_default_value", "evaluate_signature", "stringify_signature", "sigs.append", "super", "inspect.isclassmethod", "self.annotate_to_first_argument", "inspect.isstaticmethod", "list", "overload.replace", "MethodDocumenter", "_FunctionDefProperties", "sigs.append", "overload.parameters.values", "documenter.format_signature", "frozenset"], "code_location": {"file": "_documenters.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/ext/autodoc", "start_line": 2079, "end_line": 2154}, "code_snippet": "    def format_signature(self, **kwargs: Any) -> str:\n        if self.config.autodoc_typehints_format == 'short':\n            kwargs.setdefault('unqualified_typehints', True)\n        if self.config.python_display_short_literal_types:\n            kwargs.setdefault('short_literals', True)\n\n        sigs = []\n        if (\n            self.analyzer\n            and self.props.dotted_parts in self.analyzer.overloads\n            and self.config.autodoc_typehints != 'none'\n        ):\n            # Use signatures for overloaded methods instead of the implementation method.\n            overloaded = True\n        else:\n            overloaded = False\n            sig = super().format_signature(**kwargs)\n            sigs.append(sig)\n\n        meth = self.parent.__dict__.get(self.props.name)\n        if inspect.is_singledispatch_method(meth):\n            from sphinx.ext.autodoc._property_types import _FunctionDefProperties\n\n            # append signature of singledispatch'ed functions\n            for typ, func in meth.dispatcher.registry.items():\n                if typ is object:\n                    pass  # default implementation. skipped.\n                else:\n                    if inspect.isclassmethod(func):\n                        func = func.__func__\n                    dispatchmeth = self.annotate_to_first_argument(func, typ)\n                    if dispatchmeth:\n                        documenter = MethodDocumenter(self.directive, '')\n                        documenter.props = _FunctionDefProperties(\n                            obj_type='method',\n                            module_name='',\n                            parts=('',),\n                            docstring_lines=(),\n                            _obj=dispatchmeth,\n                            _obj___module__=None,\n                            properties=frozenset(),\n                        )\n                        documenter.parent = self.parent\n                        sigs.append(documenter.format_signature())\n        if overloaded and self.analyzer is not None:\n            if inspect.isstaticmethod(\n                self.props._obj, cls=self.parent, name=self.props.object_name\n            ):\n                actual = inspect.signature(\n                    self.props._obj,\n                    bound_method=False,\n                    type_aliases=self.config.autodoc_type_aliases,\n                )\n            else:\n                actual = inspect.signature(\n                    self.props._obj,\n                    bound_method=True,\n                    type_aliases=self.config.autodoc_type_aliases,\n                )\n\n            __globals__ = safe_getattr(self.props._obj, '__globals__', {})\n            for overload in self.analyzer.overloads[self.props.dotted_parts]:\n                overload = self.merge_default_value(actual, overload)\n                overload = evaluate_signature(\n                    overload, __globals__, self.config.autodoc_type_aliases\n                )\n\n                if not inspect.isstaticmethod(\n                    self.props._obj, cls=self.parent, name=self.props.object_name\n                ):\n                    parameters = list(overload.parameters.values())\n                    overload = overload.replace(parameters=parameters[1:])\n                sig = stringify_signature(overload, **kwargs)\n                sigs.append(sig)\n\n        return '\\n'.join(sigs)\n", "type": "function"}, {"name": "format_signature", "is_method": true, "class_name": "FunctionDocumenter", "parameters": ["self"], "calls": ["inspect.is_singledispatch_function", "join", "kwargs.setdefault", "kwargs.setdefault", "format_signature", "sigs.append", "self.props._obj.registry.items", "inspect.signature", "safe_getattr", "self.merge_default_value", "evaluate_signature", "stringify_signature", "sigs.append", "super", "self.annotate_to_first_argument", "FunctionDocumenter", "_FunctionDefProperties", "sigs.append", "documenter.format_signature", "frozenset"], "code_location": {"file": "_documenters.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/ext/autodoc", "start_line": 1225, "end_line": 1279}, "code_snippet": "    def format_signature(self, **kwargs: Any) -> str:\n        if self.config.autodoc_typehints_format == 'short':\n            kwargs.setdefault('unqualified_typehints', True)\n        if self.config.python_display_short_literal_types:\n            kwargs.setdefault('short_literals', True)\n\n        sigs = []\n        if (\n            self.analyzer\n            and self.props.dotted_parts in self.analyzer.overloads\n            and self.config.autodoc_typehints != 'none'\n        ):\n            # Use signatures for overloaded functions instead of the implementation function.\n            overloaded = True\n        else:\n            overloaded = False\n            sig = super().format_signature(**kwargs)\n            sigs.append(sig)\n\n        if inspect.is_singledispatch_function(self.props._obj):\n            from sphinx.ext.autodoc._property_types import _FunctionDefProperties\n\n            # append signature of singledispatch'ed functions\n            for typ, func in self.props._obj.registry.items():\n                if typ is object:\n                    pass  # default implementation. skipped.\n                else:\n                    dispatchfunc = self.annotate_to_first_argument(func, typ)\n                    if dispatchfunc:\n                        documenter = FunctionDocumenter(self.directive, '')\n                        documenter.props = _FunctionDefProperties(\n                            obj_type='function',\n                            module_name='',\n                            parts=('',),\n                            docstring_lines=(),\n                            _obj=dispatchfunc,\n                            _obj___module__=None,\n                            properties=frozenset(),\n                        )\n                        sigs.append(documenter.format_signature())\n        if overloaded and self.analyzer is not None:\n            actual = inspect.signature(\n                self.props._obj, type_aliases=self.config.autodoc_type_aliases\n            )\n            __globals__ = safe_getattr(self.props._obj, '__globals__', {})\n            for overload in self.analyzer.overloads[self.props.dotted_parts]:\n                overload = self.merge_default_value(actual, overload)\n                overload = evaluate_signature(\n                    overload, __globals__, self.config.autodoc_type_aliases\n                )\n\n                sig = stringify_signature(overload, **kwargs)\n                sigs.append(sig)\n\n        return '\\n'.join(sigs)\n", "type": "function"}, {"name": "test_autodoc_typehints_none_for_overload", "is_method": false, "class_name": null, "parameters": ["app"], "calls": ["pytest.mark.sphinx", "do_autodoc", "list"], "code_location": {"file": "test_ext_autodoc_configs.py", "path": "/data3/pwh/swebench-repos/sphinx/tests/test_extensions", "start_line": 957, "end_line": 1000}, "code_snippet": "def test_autodoc_typehints_none_for_overload(app: SphinxTestApp) -> None:\n    options = {'members': None}\n    actual = do_autodoc(app, 'module', 'target.overload', options)\n    assert list(actual) == [\n        '',\n        '.. py:module:: target.overload',\n        '',\n        '',\n        '.. py:class:: Bar(x, y)',\n        '   :module: target.overload',\n        '',\n        '   docstring',\n        '',\n        '',\n        '.. py:class:: Baz(x, y)',\n        '   :module: target.overload',\n        '',\n        '   docstring',\n        '',\n        '',\n        '.. py:class:: Foo(x, y)',\n        '   :module: target.overload',\n        '',\n        '   docstring',\n        '',\n        '',\n        '.. py:class:: Math()',\n        '   :module: target.overload',\n        '',\n        '   docstring',\n        '',\n        '',\n        '   .. py:method:: Math.sum(x, y=None)',\n        '      :module: target.overload',\n        '',\n        '      docstring',\n        '',\n        '',\n        '.. py:function:: sum(x, y=None)',\n        '   :module: target.overload',\n        '',\n        '   docstring',\n        '',\n    ]\n", "type": "function"}, {"name": "format_signature", "is_method": true, "class_name": "ClassDocumenter", "parameters": ["self"], "calls": ["format_signature", "self.get_overloaded_signatures", "join", "kwargs.setdefault", "kwargs.setdefault", "safe_getattr", "safe_getattr", "sigs.append", "super", "evaluate_signature", "list", "overload.replace", "stringify_signature", "sigs.append", "overload.parameters.values"], "code_location": {"file": "_documenters.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/ext/autodoc", "start_line": 1538, "end_line": 1574}, "code_snippet": "    def format_signature(self, **kwargs: Any) -> str:\n        if self.props.doc_as_attr:\n            return ''\n        if self.config.autodoc_class_signature == 'separated':\n            # do not show signatures\n            return ''\n\n        if self.config.autodoc_typehints_format == 'short':\n            kwargs.setdefault('unqualified_typehints', True)\n        if self.config.python_display_short_literal_types:\n            kwargs.setdefault('short_literals', True)\n\n        sig = super().format_signature()\n        sigs = []\n\n        overloads = self.get_overloaded_signatures()\n        if overloads and self.config.autodoc_typehints != 'none':\n            # Use signatures for overloaded methods instead of the implementation method.\n            method = safe_getattr(\n                self._signature_class, self._signature_method_name, None\n            )\n            __globals__ = safe_getattr(method, '__globals__', {})\n            for overload in overloads:\n                overload = evaluate_signature(\n                    overload, __globals__, self.config.autodoc_type_aliases\n                )\n\n                parameters = list(overload.parameters.values())\n                overload = overload.replace(\n                    parameters=parameters[1:], return_annotation=Parameter.empty\n                )\n                sig = stringify_signature(overload, **kwargs)\n                sigs.append(sig)\n        else:\n            sigs.append(sig)\n\n        return '\\n'.join(sigs)\n", "type": "function"}, {"name": "merge_default_value", "is_method": true, "class_name": "FunctionDocumenter", "parameters": ["self", "actual", "overload"], "calls": ["list", "enumerate", "overload.replace", "overload.parameters.values", "actual.parameters.get", "param.replace"], "code_location": {"file": "_documenters.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/ext/autodoc", "start_line": 1281, "end_line": 1289}, "code_snippet": "    def merge_default_value(self, actual: Signature, overload: Signature) -> Signature:\n        \"\"\"Merge default values of actual implementation to the overload variants.\"\"\"\n        parameters = list(overload.parameters.values())\n        for i, param in enumerate(parameters):\n            actual_param = actual.parameters.get(param.name)\n            if actual_param and param.default == '...':\n                parameters[i] = param.replace(default=actual_param.default)\n\n        return overload.replace(parameters=parameters)\n", "type": "function"}, {"name": "merge_default_value", "is_method": true, "class_name": "MethodDocumenter", "parameters": ["self", "actual", "overload"], "calls": ["list", "enumerate", "overload.replace", "overload.parameters.values", "actual.parameters.get", "param.replace"], "code_location": {"file": "_documenters.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/ext/autodoc", "start_line": 2156, "end_line": 2164}, "code_snippet": "    def merge_default_value(self, actual: Signature, overload: Signature) -> Signature:\n        \"\"\"Merge default values of actual implementation to the overload variants.\"\"\"\n        parameters = list(overload.parameters.values())\n        for i, param in enumerate(parameters):\n            actual_param = actual.parameters.get(param.name)\n            if actual_param and param.default == '...':\n                parameters[i] = param.replace(default=actual_param.default)\n\n        return overload.replace(parameters=parameters)\n", "type": "function"}, {"name": "test_autodoc_default_options_with_values", "is_method": false, "class_name": null, "parameters": ["app"], "calls": ["pytest.mark.sphinx", "do_autodoc", "do_autodoc", "do_autodoc", "do_autodoc", "do_autodoc", "list", "filter"], "code_location": {"file": "test_ext_autodoc_configs.py", "path": "/data3/pwh/swebench-repos/sphinx/tests/test_extensions", "start_line": 1790, "end_line": 1862}, "code_snippet": "def test_autodoc_default_options_with_values(app: SphinxTestApp) -> None:\n    if (3, 11, 7) <= sys.version_info < (3, 12) or sys.version_info >= (3, 12, 1):\n        list_of_weak_references = '      list of weak references to the object'\n    else:\n        list_of_weak_references = '      list of weak references to the object (if defined)'  # fmt: skip\n\n    # with :members:\n    app.config.autodoc_default_options = {'members': 'val1,val2'}\n    actual = do_autodoc(app, 'class', 'target.enums.EnumCls')\n    assert '   .. py:attribute:: EnumCls.val1' in actual\n    assert '   .. py:attribute:: EnumCls.val2' in actual\n    assert '   .. py:attribute:: EnumCls.val3' not in actual\n    assert '   .. py:attribute:: EnumCls.val4' not in actual\n\n    # with :member-order:\n    app.config.autodoc_default_options = {\n        'members': None,\n        'member-order': 'bysource',\n    }\n    actual = do_autodoc(app, 'class', 'target.Class')\n    assert list(filter(lambda l: '::' in l, actual)) == [\n        '.. py:class:: Class(arg)',\n        '   .. py:method:: Class.meth()',\n        '   .. py:method:: Class.skipmeth()',\n        '   .. py:method:: Class.excludemeth()',\n        '   .. py:attribute:: Class.attr',\n        '   .. py:attribute:: Class.docattr',\n        '   .. py:attribute:: Class.udocattr',\n        '   .. py:attribute:: Class.mdocattr',\n        '   .. py:method:: Class.moore(a, e, f) -> happiness',\n        '   .. py:attribute:: Class.inst_attr_inline',\n        '   .. py:attribute:: Class.inst_attr_comment',\n        '   .. py:attribute:: Class.inst_attr_string',\n    ]\n\n    # with :special-members:\n    app.config.autodoc_default_options = {\n        'special-members': '__init__,__iter__',\n    }\n    actual = do_autodoc(app, 'class', 'target.CustomIter')\n    assert '   .. py:method:: CustomIter.__init__()' in actual\n    assert '      Create a new `CustomIter`.' in actual\n    assert '   .. py:method:: CustomIter.__iter__()' in actual\n    assert '      Iterate squares of each value.' in actual\n    if not IS_PYPY:\n        assert '   .. py:attribute:: CustomIter.__weakref__' not in actual\n        assert list_of_weak_references not in actual\n\n    # with :exclude-members:\n    app.config.autodoc_default_options = {\n        'members': None,\n        'exclude-members': 'val1',\n    }\n    actual = do_autodoc(app, 'class', 'target.enums.EnumCls')\n    assert '   .. py:attribute:: EnumCls.val1' not in actual\n    assert '   .. py:attribute:: EnumCls.val2' in actual\n    assert '   .. py:attribute:: EnumCls.val3' in actual\n    assert '   .. py:attribute:: EnumCls.val4' not in actual\n    app.config.autodoc_default_options = {\n        'members': None,\n        'special-members': None,\n        'exclude-members': '__weakref__,snafucate',\n    }\n    actual = do_autodoc(app, 'class', 'target.CustomIter')\n    assert '   .. py:method:: CustomIter.__init__()' in actual\n    assert '      Create a new `CustomIter`.' in actual\n    assert '   .. py:method:: CustomIter.__iter__()' in actual\n    assert '      Iterate squares of each value.' in actual\n    if not IS_PYPY:\n        assert '   .. py:attribute:: CustomIter.__weakref__' not in actual\n        assert list_of_weak_references not in actual\n    assert '   .. py:method:: CustomIter.snafucate()' not in actual\n    assert '      Makes this snafucated.' not in actual\n", "type": "function"}], "retrieved_count": 10, "cost_time": 1.1117277145385742}
{"question": "What implicit contract does the empty test class with no methods or attributes establish for the automatic documentation generation system that processes Python objects and creates summary tables?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"name": "autosummary_table", "docstring": "", "methods": [], "attributes": [], "code_location": {"file": "__init__.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/ext/autosummary", "start_line": 133, "end_line": 134}, "type": "class"}, {"name": "A", "docstring": "A class having no __init__, no __new__", "methods": [], "attributes": [], "code_location": {"file": "autoclass_content.py", "path": "/data3/pwh/swebench-repos/sphinx/tests/roots/test-ext-autodoc/target", "start_line": 1, "end_line": 2}, "type": "class"}, {"name": "DummyTestParser", "docstring": "", "methods": [], "attributes": ["supported"], "code_location": {"file": "conf.py", "path": "/data3/pwh/swebench-repos/sphinx/tests/roots/test-add_source_parser-conflicts-with-users-setting", "start_line": 9, "end_line": 10}, "type": "class"}, {"name": "_Empty", "docstring": "A special value for :exclude-members: that never matches to any member.", "methods": ["__contains__"], "attributes": [], "code_location": {"file": "_sentinels.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/ext/autodoc", "start_line": 52, "end_line": 56}, "type": "class"}, {"name": "TestCode", "docstring": "", "methods": ["__init__", "__repr__"], "attributes": [], "code_location": {"file": "doctest.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/ext", "start_line": 235, "end_line": 254}, "type": "class"}, {"name": "TestGroup", "docstring": "", "methods": ["__init__", "add_code", "__repr__"], "attributes": [], "code_location": {"file": "doctest.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/ext", "start_line": 200, "end_line": 232}, "type": "class"}, {"name": "TestInlineAttribute", "docstring": "", "methods": ["_docstring", "test_class_data_member", "test_class_data_member_inline", "test_class_data_member_inline_no_type", "test_class_data_member_inline_ref_in_type"], "attributes": ["inline_google_docstring"], "code_location": {"file": "test_ext_napoleon_docstring.py", "path": "/data3/pwh/swebench-repos/sphinx/tests/test_extensions", "start_line": 93, "end_line": 129}, "type": "class"}, {"name": "E", "docstring": "A class having no __init__, __new__", "methods": [], "attributes": [], "code_location": {"file": "autoclass_content.py", "path": "/data3/pwh/swebench-repos/sphinx/tests/roots/test-ext-autodoc/target", "start_line": 26, "end_line": 30}, "type": "class"}, {"name": "TestAutodoc", "docstring": "TestAutodoc docstring.", "methods": ["decorated_method"], "attributes": ["Alias"], "code_location": {"file": "need_mocks.py", "path": "/data3/pwh/swebench-repos/sphinx/tests/roots/test-ext-autodoc/target", "start_line": 21, "end_line": 30}, "type": "class"}, {"name": "TestNumpyDocstring", "docstring": "", "methods": ["test_sphinx_admonitions", "test_docstrings", "test_type_preprocessor", "test_parameters_with_class_reference", "test_multiple_parameters", "test_parameters_without_class_reference", "test_see_also_refs", "test_colon_in_return_type", "test_underscore_in_attribute", "test_underscore_in_attribute_strip_signature_backslash", "test_return_types", "test_yield_types", "test_raises_types", "test_xrefs_in_return_type", "test_section_header_underline_length", "test_list_in_parameter_description", "test_token_type", "test_tokenize_type_spec", "test_recombine_set_tokens", "test_recombine_set_tokens_invalid", "test_convert_numpy_type_spec", "test_parameter_types", "test_token_type_invalid", "test_escape_args_and_kwargs", "test_pep526_annotations"], "attributes": ["docstrings"], "code_location": {"file": "test_ext_napoleon_docstring.py", "path": "/data3/pwh/swebench-repos/sphinx/tests/test_extensions", "start_line": 1344, "end_line": 2815}, "type": "class"}], "retrieved_count": 10, "cost_time": 1.1501545906066895}
{"question": "What is the transformation mechanism in the method that converts the binary operator expression class in the C++ domain AST that processes expressions and operators into a formatted string?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"name": "ASTBinOpExpr", "docstring": "", "methods": [], "attributes": [], "code_location": {"file": "_ast.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/domains/cpp", "start_line": 1305, "end_line": 1351}, "type": "class"}, {"name": "ASTBinOpExpr", "docstring": "", "methods": ["__init__", "__eq__", "__hash__", "_stringify", "describe_signature", "__init__", "__eq__", "__hash__", "_stringify", "get_id", "describe_signature"], "attributes": [], "code_location": {"file": "_ast.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/domains/c", "start_line": 646, "end_line": 684}, "type": "class"}, {"name": "_stringify", "is_method": true, "class_name": "ASTOperatorBuildIn", "parameters": ["self", "transform"], "calls": [], "code_location": {"file": "_ast.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/domains/cpp", "start_line": 1668, "end_line": 1672}, "code_snippet": "    def _stringify(self, transform: StringifyTransform) -> str:\n        if self.op in {'new', 'new[]', 'delete', 'delete[]'} or self.op[0] in 'abcnox':\n            return 'operator ' + self.op\n        else:\n            return 'operator' + self.op\n", "type": "function"}, {"name": "_stringify", "is_method": true, "class_name": "ASTAssignmentExpr", "parameters": ["self", "transform"], "calls": ["res.extend", "join", "transform", "transform"], "code_location": {"file": "_ast.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/domains/cpp", "start_line": 1474, "end_line": 1483}, "code_snippet": "    def _stringify(self, transform: StringifyTransform) -> str:\n        res: list[str] = []\n        res.extend((\n            transform(self.leftExpr),\n            ' ',\n            self.op,\n            ' ',\n            transform(self.rightExpr),\n        ))\n        return ''.join(res)\n", "type": "function"}, {"name": "_stringify", "is_method": true, "class_name": "ASTUnaryOpExpr", "parameters": ["self", "transform"], "calls": ["transform", "transform"], "code_location": {"file": "_ast.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/domains/cpp", "start_line": 995, "end_line": 999}, "code_snippet": "    def _stringify(self, transform: StringifyTransform) -> str:\n        if self.op[0] in 'cn':\n            return self.op + ' ' + transform(self.expr)\n        else:\n            return self.op + transform(self.expr)\n", "type": "function"}, {"name": "_stringify", "is_method": true, "class_name": "ASTUnaryOpExpr", "parameters": ["self", "transform"], "calls": ["transform", "transform"], "code_location": {"file": "_ast.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/domains/c", "start_line": 523, "end_line": 527}, "code_snippet": "    def _stringify(self, transform: StringifyTransform) -> str:\n        if self.op[0] in 'cn':\n            return self.op + ' ' + transform(self.expr)\n        else:\n            return self.op + transform(self.expr)\n", "type": "function"}, {"name": "visit_BinOp", "is_method": true, "class_name": "_UnparseVisitor", "parameters": ["self", "node"], "calls": ["isinstance", "join", "join", "map", "map"], "code_location": {"file": "ast.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/pycode", "start_line": 117, "end_line": 121}, "code_snippet": "    def visit_BinOp(self, node: ast.BinOp) -> str:\n        # Special case ``**`` to not have surrounding spaces.\n        if isinstance(node.op, ast.Pow):\n            return ''.join(map(self.visit, (node.left, node.op, node.right)))\n        return ' '.join(map(self.visit, (node.left, node.op, node.right)))\n", "type": "function"}, {"name": "_stringify", "is_method": true, "class_name": "ASTOperatorType", "parameters": ["self", "transform"], "calls": ["transform"], "code_location": {"file": "_ast.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/domains/cpp", "start_line": 1737, "end_line": 1738}, "code_snippet": "    def _stringify(self, transform: StringifyTransform) -> str:\n        return f'operator {transform(self.type)}'\n", "type": "function"}, {"name": "_parse_logical_or_expression", "is_method": true, "class_name": "DefinitionParser", "parameters": ["self", "in_template"], "calls": ["_parse_bin_op_expr", "exprs.append", "ASTBinOpExpr", "len", "parser", "self.skip_ws", "self._parse_cast_expression", "_parse_bin_op_expr", "parser", "exprs.append", "ops.append", "self.skip_word", "self.skip_string"], "code_location": {"file": "_parser.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/domains/cpp", "start_line": 672, "end_line": 730}, "code_snippet": "    def _parse_logical_or_expression(self, in_template: bool) -> ASTExpression:\n        # logical-or     = logical-and      ||\n        # logical-and    = inclusive-or     &&\n        # inclusive-or   = exclusive-or     |\n        # exclusive-or   = and              ^\n        # and            = equality         &\n        # equality       = relational       ==, !=\n        # relational     = shift            <, >, <=, >=, <=>\n        # shift          = additive         <<, >>\n        # additive       = multiplicative   +, -\n        # multiplicative = pm               *, /, %\n        # pm             = cast             .*, ->*\n        def _parse_bin_op_expr(\n            self: DefinitionParser, op_id: int, in_template: bool\n        ) -> ASTExpression:\n            if op_id + 1 == len(_expression_bin_ops):\n\n                def parser(in_template: bool) -> ASTExpression:\n                    return self._parse_cast_expression()\n\n            else:\n\n                def parser(in_template: bool) -> ASTExpression:\n                    return _parse_bin_op_expr(self, op_id + 1, in_template=in_template)\n\n            exprs = []\n            ops = []\n            exprs.append(parser(in_template=in_template))\n            while True:\n                self.skip_ws()\n                if in_template and self.current_char == '>':\n                    break\n                pos = self.pos\n                one_more = False\n                for op in _expression_bin_ops[op_id]:\n                    if op[0] in 'abcnox':\n                        if not self.skip_word(op):\n                            continue\n                    else:\n                        if not self.skip_string(op):\n                            continue\n                    if op == self.current_char == '&':\n                        # don't split the && 'token'\n                        self.pos -= 1\n                        # and btw. && has lower precedence, so we are done\n                        break\n                    try:\n                        expr = parser(in_template=in_template)\n                        exprs.append(expr)\n                        ops.append(op)\n                        one_more = True\n                        break\n                    except DefinitionError:\n                        self.pos = pos\n                if not one_more:\n                    break\n            return ASTBinOpExpr(exprs, ops)\n\n        return _parse_bin_op_expr(self, 0, in_template=in_template)\n", "type": "function"}, {"name": "_stringify", "is_method": true, "class_name": "ASTAssignmentExpr", "parameters": ["self", "transform"], "calls": ["range", "join", "transform", "len", "res.extend", "transform"], "code_location": {"file": "_ast.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/domains/c", "start_line": 702, "end_line": 711}, "code_snippet": "    def _stringify(self, transform: StringifyTransform) -> str:\n        res = [transform(self.exprs[0])]\n        for i in range(1, len(self.exprs)):\n            res.extend((\n                ' ',\n                self.ops[i - 1],\n                ' ',\n                transform(self.exprs[i]),\n            ))\n        return ''.join(res)\n", "type": "function"}], "retrieved_count": 10, "cost_time": 1.170353889465332}
{"question": "How does the EPUB test function validate that manifest item identifiers match spine itemref references?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"name": "test_epub_anchor_id", "is_method": false, "class_name": null, "parameters": ["app"], "calls": ["pytest.mark.sphinx", "app.build", "read_text"], "code_location": {"file": "test_build_epub.py", "path": "/data3/pwh/swebench-repos/sphinx/tests/test_builders", "start_line": 415, "end_line": 425}, "code_snippet": "def test_epub_anchor_id(app: SphinxTestApp) -> None:\n    app.build()\n\n    html = (app.outdir / 'index.xhtml').read_text(encoding='utf8')\n    assert '<p id=\"std-setting-STATICFILES_FINDERS\">blah blah blah</p>' in html\n    assert (\n        '<span id=\"std-setting-STATICFILES_SECTION\"></span><h1>blah blah blah</h1>'\n    ) in html\n    assert (\n        'see <a class=\"reference internal\" href=\"#std-setting-STATICFILES_FINDERS\">'\n    ) in html\n", "type": "function"}, {"name": "test_epub_cover", "is_method": false, "class_name": null, "parameters": ["app"], "calls": ["pytest.mark.sphinx", "app.build", "EPUBElementTree.fromstring", "opf.find", "opf.find", "read_text", "cover.get", "cover_image.get"], "code_location": {"file": "test_build_epub.py", "path": "/data3/pwh/swebench-repos/sphinx/tests/test_builders", "start_line": 200, "end_line": 212}, "code_snippet": "def test_epub_cover(app: SphinxTestApp) -> None:\n    app.build()\n\n    # content.opf / metadata\n    opf = EPUBElementTree.fromstring(\n        (app.outdir / 'content.opf').read_text(encoding='utf8')\n    )\n    cover_image = opf.find(\n        \"./idpf:manifest/idpf:item[@href='%s']\" % app.config.epub_cover[0]\n    )\n    cover = opf.find(\"./idpf:metadata/idpf:meta[@name='cover']\")\n    assert cover\n    assert cover.get('content') == cover_image.get('id')\n", "type": "function"}, {"name": "test_build_epub", "is_method": false, "class_name": null, "parameters": ["app"], "calls": ["pytest.mark.sphinx", "app.build", "exists", "EPUBElementTree.fromstring", "list", "toc.findall", "find", "EPUBElementTree.fromstring", "opf.find", "opf.find", "list", "enumerate", "opf.find", "list", "opf.find", "EPUBElementTree.fromstring", "nav.find", "navlist.findall", "read_text", "read_text", "toc.find", "len", "read_text", "spine.get", "spine.get", "get", "get", "reference.get", "reference.get", "reference.get", "read_text", "len", "get", "toc.find", "find", "metadata.find", "metadata.find", "metadata.find", "metadata.find", "metadata.find", "metadata.find", "metadata.find", "metadata.find", "metadata.find", "metadata.find", "metadata.find", "item.get", "nav.find", "navlist.find", "find", "find"], "code_location": {"file": "test_build_epub.py", "path": "/data3/pwh/swebench-repos/sphinx/tests/test_builders", "start_line": 79, "end_line": 192}, "code_snippet": "def test_build_epub(app: SphinxTestApp) -> None:\n    app.build(force_all=True)\n    assert (app.outdir / 'mimetype').read_text(\n        encoding='utf8'\n    ) == 'application/epub+zip'\n    assert (app.outdir / 'META-INF' / 'container.xml').exists()\n\n    # toc.ncx\n    toc = EPUBElementTree.fromstring(\n        (app.outdir / 'toc.ncx').read_text(encoding='utf8')\n    )\n    assert toc.find('./ncx:docTitle/ncx:text').text == 'Project name not set'\n\n    # toc.ncx / head\n    meta = list(toc.find('./ncx:head'))\n    assert meta[0].attrib == {'name': 'dtb:uid', 'content': 'unknown'}\n    assert meta[1].attrib == {'name': 'dtb:depth', 'content': '1'}\n    assert meta[2].attrib == {'name': 'dtb:totalPageCount', 'content': '0'}\n    assert meta[3].attrib == {'name': 'dtb:maxPageNumber', 'content': '0'}\n\n    # toc.ncx / navMap\n    navpoints = toc.findall('./ncx:navMap/ncx:navPoint')\n    assert len(navpoints) == 1\n    assert navpoints[0].attrib == {'id': 'navPoint1', 'playOrder': '1'}\n    assert navpoints[0].find('./ncx:content').attrib == {'src': 'index.xhtml'}\n\n    navlabel = navpoints[0].find('./ncx:navLabel/ncx:text')\n    assert navlabel.text == 'The basic Sphinx documentation for testing'\n\n    # content.opf\n    opf = EPUBElementTree.fromstring(\n        (app.outdir / 'content.opf').read_text(encoding='utf8')\n    )\n\n    # content.opf / metadata\n    metadata = opf.find('./idpf:metadata')\n    assert metadata.find('./dc:language').text == 'en'\n    assert metadata.find('./dc:title').text == 'Project name not set'\n    assert metadata.find('./dc:description').text == 'unknown'\n    assert metadata.find('./dc:creator').text == 'Author name not set'\n    assert metadata.find('./dc:contributor').text == 'unknown'\n    assert metadata.find('./dc:publisher').text == 'Author name not set'\n    assert metadata.find('./dc:rights').text is None\n    assert metadata.find(\"./idpf:meta[@property='ibooks:version']\").text is None\n    assert (\n        metadata.find(\"./idpf:meta[@property='ibooks:specified-fonts']\").text == 'true'\n    )\n    assert metadata.find(\"./idpf:meta[@property='ibooks:binding']\").text == 'true'\n    assert (\n        metadata.find(\"./idpf:meta[@property='ibooks:scroll-axis']\").text == 'vertical'\n    )\n\n    # content.opf / manifest\n    manifest = opf.find('./idpf:manifest')\n    items = list(manifest)\n    assert items[0].attrib == {\n        'id': 'ncx',\n        'href': 'toc.ncx',\n        'media-type': 'application/x-dtbncx+xml',\n    }\n    assert items[1].attrib == {\n        'id': 'nav',\n        'href': 'nav.xhtml',\n        'media-type': 'application/xhtml+xml',\n        'properties': 'nav',\n    }\n    assert items[2].attrib == {\n        'id': 'epub-0',\n        'href': 'genindex.xhtml',\n        'media-type': 'application/xhtml+xml',\n    }\n    assert items[3].attrib == {\n        'id': 'epub-1',\n        'href': 'index.xhtml',\n        'media-type': 'application/xhtml+xml',\n    }\n\n    for i, item in enumerate(items[2:]):\n        # items are named as epub-NN\n        assert item.get('id') == 'epub-%d' % i\n\n    # content.opf / spine\n    spine = opf.find('./idpf:spine')\n    itemrefs = list(spine)\n    assert spine.get('toc') == 'ncx'\n    assert spine.get('page-progression-direction') == 'ltr'\n    assert itemrefs[0].get('idref') == 'epub-1'\n    assert itemrefs[1].get('idref') == 'epub-0'\n\n    # content.opf / guide\n    reference = opf.find('./idpf:guide/idpf:reference')\n    assert reference.get('type') == 'toc'\n    assert reference.get('title') == 'Table of Contents'\n    assert reference.get('href') == 'index.xhtml'\n\n    # nav.xhtml\n    nav = EPUBElementTree.fromstring(\n        (app.outdir / 'nav.xhtml').read_text(encoding='utf8')\n    )\n    assert nav.attrib == {\n        'lang': 'en',\n        '{http://www.w3.org/XML/1998/namespace}lang': 'en',\n    }\n    assert nav.find('./xhtml:head/xhtml:title').text == 'Table of Contents'\n\n    # nav.xhtml / nav\n    navlist = nav.find('./xhtml:body/xhtml:nav')\n    tocs = navlist.findall('./xhtml:ol/xhtml:li')\n    assert navlist.find('./xhtml:h1').text == 'Table of Contents'\n    assert len(tocs) == 1\n    assert tocs[0].find('./xhtml:a').get('href') == 'index.xhtml'\n    assert (\n        tocs[0].find('./xhtml:a').text == 'The basic Sphinx documentation for testing'\n    )\n", "type": "function"}, {"name": "test_epub_assets", "is_method": false, "class_name": null, "parameters": ["app"], "calls": ["pytest.mark.sphinx", "app.build", "read_text"], "code_location": {"file": "test_build_epub.py", "path": "/data3/pwh/swebench-repos/sphinx/tests/test_builders", "start_line": 429, "end_line": 440}, "code_snippet": "def test_epub_assets(app: SphinxTestApp) -> None:\n    app.build(force_all=True)\n\n    # epub_sytlesheets (same as html_css_files)\n    content = (app.outdir / 'index.xhtml').read_text(encoding='utf8')\n    assert (\n        '<link rel=\"stylesheet\" type=\"text/css\" href=\"_static/css/style.css\" />'\n    ) in content\n    assert (\n        '<link media=\"print\" rel=\"stylesheet\" title=\"title\" type=\"text/css\" '\n        'href=\"https://example.com/custom.css\" />'\n    ) in content\n", "type": "function"}, {"name": "test_epub_css_files", "is_method": false, "class_name": null, "parameters": ["app"], "calls": ["pytest.mark.sphinx", "app.build", "read_text"], "code_location": {"file": "test_build_epub.py", "path": "/data3/pwh/swebench-repos/sphinx/tests/test_builders", "start_line": 448, "end_line": 464}, "code_snippet": "def test_epub_css_files(app: SphinxTestApp) -> None:\n    app.build(force_all=True)\n\n    # epub_css_files\n    content = (app.outdir / 'index.xhtml').read_text(encoding='utf8')\n    assert (\n        '<link rel=\"stylesheet\" type=\"text/css\" href=\"_static/css/epub.css\" />'\n    ) in content\n\n    # files in html_css_files are not outputted\n    assert (\n        '<link rel=\"stylesheet\" type=\"text/css\" href=\"_static/css/style.css\" />'\n    ) not in content\n    assert (\n        '<link media=\"print\" rel=\"stylesheet\" title=\"title\" type=\"text/css\" '\n        'href=\"https://example.com/custom.css\" />'\n    ) not in content\n", "type": "function"}, {"name": "test_epub_writing_mode", "is_method": false, "class_name": null, "parameters": ["app"], "calls": ["pytest.mark.sphinx", "app.build", "EPUBElementTree.fromstring", "opf.find", "read_text", "unlink", "app.build", "EPUBElementTree.fromstring", "opf.find", "read_text", "read_text", "get", "read_text", "get", "metadata.find", "metadata.find", "opf.find", "opf.find"], "code_location": {"file": "test_build_epub.py", "path": "/data3/pwh/swebench-repos/sphinx/tests/test_builders", "start_line": 371, "end_line": 411}, "code_snippet": "def test_epub_writing_mode(app: SphinxTestApp) -> None:\n    # horizontal (default)\n    app.build(force_all=True)\n\n    # horizontal / page-progression-direction\n    opf = EPUBElementTree.fromstring(\n        (app.outdir / 'content.opf').read_text(encoding='utf8')\n    )\n    assert opf.find('./idpf:spine').get('page-progression-direction') == 'ltr'\n\n    # horizontal / ibooks:scroll-axis\n    metadata = opf.find('./idpf:metadata')\n    assert (\n        metadata.find(\"./idpf:meta[@property='ibooks:scroll-axis']\").text == 'vertical'\n    )\n\n    # horizontal / writing-mode (CSS)\n    css = (app.outdir / '_static' / 'epub.css').read_text(encoding='utf8')\n    assert 'writing-mode: horizontal-tb;' in css\n\n    # vertical\n    app.config.epub_writing_mode = 'vertical'\n    (app.outdir / 'index.xhtml').unlink()  # forcely rebuild\n    app.build()\n\n    # vertical / page-progression-direction\n    opf = EPUBElementTree.fromstring(\n        (app.outdir / 'content.opf').read_text(encoding='utf8')\n    )\n    assert opf.find('./idpf:spine').get('page-progression-direction') == 'rtl'\n\n    # vertical / ibooks:scroll-axis\n    metadata = opf.find('./idpf:metadata')\n    assert (\n        metadata.find(\"./idpf:meta[@property='ibooks:scroll-axis']\").text\n        == 'horizontal'\n    )\n\n    # vertical / writing-mode (CSS)\n    css = (app.outdir / '_static' / 'epub.css').read_text(encoding='utf8')\n    assert 'writing-mode: vertical-rl;' in css\n", "type": "function"}, {"name": "test_escaped_toc", "is_method": false, "class_name": null, "parameters": ["app"], "calls": ["pytest.mark.sphinx", "app.build", "EPUBElementTree.fromstring", "toc.findall", "findall", "EPUBElementTree.fromstring", "nav.findall", "findall", "findall", "read_bytes", "elem.find", "elem.find", "len", "navpoint_navinfo", "findall", "navpoint_navinfo", "len", "navpoint_navinfo", "navpoint_navinfo", "navpoint_navinfo", "navpoint_navinfo", "elem.find", "read_bytes", "len", "nav_navinfo", "findall", "nav_navinfo", "len", "nav_navinfo", "nav_navinfo", "nav_navinfo", "len", "nav_navinfo", "toc.find", "elem.get", "elem.get", "content.get", "anchor.get"], "code_location": {"file": "test_build_epub.py", "path": "/data3/pwh/swebench-repos/sphinx/tests/test_builders", "start_line": 298, "end_line": 367}, "code_snippet": "def test_escaped_toc(app: SphinxTestApp) -> None:\n    app.build()\n\n    # toc.ncx\n    toc = EPUBElementTree.fromstring((app.outdir / 'toc.ncx').read_bytes())\n    assert toc.find('./ncx:docTitle/ncx:text').text == 'need <b>\"escaped\"</b> project'\n\n    # toc.ncx / navPoint\n    def navpoint_navinfo(\n        elem: EPUBElementTree,\n    ) -> tuple[str | None, str | None, str | None, str | None]:\n        label = elem.find('./ncx:navLabel/ncx:text')\n        content = elem.find('./ncx:content')\n        ret = elem.get('id'), elem.get('playOrder'), content.get('src'), label.text\n        return ret\n\n    navpoints = toc.findall('./ncx:navMap/ncx:navPoint')\n    assert len(navpoints) == 4\n    assert navpoint_navinfo(navpoints[0]) == (\n        'navPoint1',\n        '1',\n        'index.xhtml',\n        \"Welcome to Sphinx Tests's documentation!\",\n    )\n    assert navpoints[0].findall('./ncx:navPoint') == []\n\n    # toc.ncx / nested navPoints\n    assert navpoint_navinfo(navpoints[1]) == ('navPoint2', '2', 'foo.xhtml', '<foo>')\n    navchildren = navpoints[1].findall('./ncx:navPoint')\n    assert len(navchildren) == 4\n    assert navpoint_navinfo(navchildren[0]) == ('navPoint3', '2', 'foo.xhtml', '<foo>')\n    assert navpoint_navinfo(navchildren[1]) == ('navPoint4', '3', 'quux.xhtml', 'quux')\n    assert navpoint_navinfo(navchildren[2]) == (\n        'navPoint5',\n        '4',\n        'foo.xhtml#foo-1',\n        'foo 1',\n    )\n    assert navpoint_navinfo(navchildren[3]) == (\n        'navPoint8',\n        '6',\n        'foo.xhtml#foo-2',\n        'foo.2',\n    )\n\n    # nav.xhtml / nav\n    def nav_navinfo(elem: EPUBElementTree) -> tuple[str | None, str | None]:\n        anchor = elem.find('./xhtml:a')\n        return anchor.get('href'), anchor.text\n\n    nav = EPUBElementTree.fromstring((app.outdir / 'nav.xhtml').read_bytes())\n    tocs = nav.findall('./xhtml:body/xhtml:nav/xhtml:ol/xhtml:li')\n    assert len(tocs) == 4\n    assert nav_navinfo(tocs[0]) == (\n        'index.xhtml',\n        \"Welcome to Sphinx Tests's documentation!\",\n    )\n    assert tocs[0].findall('./xhtml:ol') == []\n\n    # nav.xhtml / nested toc\n    assert nav_navinfo(tocs[1]) == ('foo.xhtml', '<foo>')\n    tocchildren = tocs[1].findall('./xhtml:ol/xhtml:li')\n    assert len(tocchildren) == 3\n    assert nav_navinfo(tocchildren[0]) == ('quux.xhtml', 'quux')\n    assert nav_navinfo(tocchildren[1]) == ('foo.xhtml#foo-1', 'foo 1')\n    assert nav_navinfo(tocchildren[2]) == ('foo.xhtml#foo-2', 'foo.2')\n\n    grandchild = tocchildren[1].findall('./xhtml:ol/xhtml:li')\n    assert len(grandchild) == 1\n    assert nav_navinfo(grandchild[0]) == ('foo.xhtml#foo-1-1', 'foo.1-1')\n", "type": "function"}, {"name": "check_refnodes", "is_method": true, "class_name": "EpubBuilder", "parameters": ["self", "nodes"], "calls": ["set", "logger.warning", "appeared.add", "__"], "code_location": {"file": "_epub_base.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/builders", "start_line": 218, "end_line": 229}, "code_snippet": "    def check_refnodes(self, nodes: list[dict[str, Any]]) -> None:\n        appeared: set[str] = set()\n        for node in nodes:\n            if node['refuri'] in appeared:\n                logger.warning(\n                    __('duplicated ToC entry found: %s'),\n                    node['refuri'],\n                    type='epub',\n                    subtype='duplicated_toc_entry',\n                )\n            else:\n                appeared.add(node['refuri'])\n", "type": "function"}, {"name": "test_run_epubcheck", "is_method": false, "class_name": null, "parameters": ["app"], "calls": ["pytest.mark.skipif", "pytest.mark.sphinx", "app.build", "Path", "runnable", "pytest.skip", "os.environ.get", "epubcheck.exists", "pytest.skip", "subprocess.run", "print", "print", "AssertionError", "exc.stdout.decode", "exc.stderr.decode"], "code_location": {"file": "test_build_epub.py", "path": "/data3/pwh/swebench-repos/sphinx/tests/test_builders", "start_line": 500, "end_line": 520}, "code_snippet": "def test_run_epubcheck(app: SphinxTestApp) -> None:\n    app.build()\n\n    if not runnable(['java', '-version']):\n        pytest.skip('Unable to run Java; skipping test')\n\n    epubcheck = Path(os.environ.get('EPUBCHECK_PATH', '/usr/share/java/epubcheck.jar'))\n    if not epubcheck.exists():\n        pytest.skip('Could not find epubcheck; skipping test')\n\n    try:\n        subprocess.run(\n            ['java', '-jar', epubcheck, app.outdir / 'SphinxTests.epub'],  # NoQA: S607\n            capture_output=True,\n            check=True,\n        )\n    except CalledProcessError as exc:\n        print(exc.stdout.decode('utf-8'))\n        print(exc.stderr.decode('utf-8'))\n        msg = f'epubcheck exited with return code {exc.returncode}'\n        raise AssertionError(msg) from exc\n", "type": "function"}, {"name": "test_nested_toc", "is_method": false, "class_name": null, "parameters": ["app"], "calls": ["pytest.mark.sphinx", "app.build", "EPUBElementTree.fromstring", "toc.findall", "findall", "EPUBElementTree.fromstring", "nav.findall", "findall", "findall", "read_bytes", "elem.find", "elem.find", "len", "toc_navpoint_navinfo", "findall", "toc_navpoint_navinfo", "len", "toc_navpoint_navinfo", "toc_navpoint_navinfo", "toc_navpoint_navinfo", "toc_navpoint_navinfo", "elem.find", "read_bytes", "len", "nav_nav_navinfo", "findall", "nav_nav_navinfo", "len", "nav_nav_navinfo", "nav_nav_navinfo", "nav_nav_navinfo", "len", "nav_nav_navinfo", "toc.find", "elem.get", "elem.get", "content.get", "anchor.get"], "code_location": {"file": "test_build_epub.py", "path": "/data3/pwh/swebench-repos/sphinx/tests/test_builders", "start_line": 216, "end_line": 294}, "code_snippet": "def test_nested_toc(app: SphinxTestApp) -> None:\n    app.build()\n\n    # toc.ncx\n    toc = EPUBElementTree.fromstring((app.outdir / 'toc.ncx').read_bytes())\n    assert toc.find('./ncx:docTitle/ncx:text').text == 'Project name not set'\n\n    # toc.ncx / navPoint\n    def toc_navpoint_navinfo(\n        elem: EPUBElementTree,\n    ) -> tuple[str | None, str | None, str | None, str | None]:\n        label = elem.find('./ncx:navLabel/ncx:text')\n        content = elem.find('./ncx:content')\n        return elem.get('id'), elem.get('playOrder'), content.get('src'), label.text\n\n    navpoints = toc.findall('./ncx:navMap/ncx:navPoint')\n    assert len(navpoints) == 4\n    assert toc_navpoint_navinfo(navpoints[0]) == (\n        'navPoint1',\n        '1',\n        'index.xhtml',\n        'Welcome to Sphinx Testss documentation!',\n    )\n    assert navpoints[0].findall('./ncx:navPoint') == []\n\n    # toc.ncx / nested navPoints\n    assert toc_navpoint_navinfo(navpoints[1]) == ('navPoint2', '2', 'foo.xhtml', 'foo')\n    navchildren = navpoints[1].findall('./ncx:navPoint')\n    assert len(navchildren) == 4\n    assert toc_navpoint_navinfo(navchildren[0]) == (\n        'navPoint3',\n        '2',\n        'foo.xhtml',\n        'foo',\n    )\n    assert toc_navpoint_navinfo(navchildren[1]) == (\n        'navPoint4',\n        '3',\n        'quux.xhtml',\n        'quux',\n    )\n    assert toc_navpoint_navinfo(navchildren[2]) == (\n        'navPoint5',\n        '4',\n        'foo.xhtml#foo-1',\n        'foo.1',\n    )\n    assert toc_navpoint_navinfo(navchildren[3]) == (\n        'navPoint8',\n        '6',\n        'foo.xhtml#foo-2',\n        'foo.2',\n    )\n\n    # nav.xhtml / nav\n    def nav_nav_navinfo(elem: EPUBElementTree) -> tuple[str | None, str | None]:\n        anchor = elem.find('./xhtml:a')\n        return anchor.get('href'), anchor.text\n\n    nav = EPUBElementTree.fromstring((app.outdir / 'nav.xhtml').read_bytes())\n    tocs = nav.findall('./xhtml:body/xhtml:nav/xhtml:ol/xhtml:li')\n    assert len(tocs) == 4\n    assert nav_nav_navinfo(tocs[0]) == (\n        'index.xhtml',\n        'Welcome to Sphinx Testss documentation!',\n    )\n    assert tocs[0].findall('./xhtml:ol') == []\n\n    # nav.xhtml / nested toc\n    assert nav_nav_navinfo(tocs[1]) == ('foo.xhtml', 'foo')\n    tocchildren = tocs[1].findall('./xhtml:ol/xhtml:li')\n    assert len(tocchildren) == 3\n    assert nav_nav_navinfo(tocchildren[0]) == ('quux.xhtml', 'quux')\n    assert nav_nav_navinfo(tocchildren[1]) == ('foo.xhtml#foo-1', 'foo.1')\n    assert nav_nav_navinfo(tocchildren[2]) == ('foo.xhtml#foo-2', 'foo.2')\n\n    grandchild = tocchildren[1].findall('./xhtml:ol/xhtml:li')\n    assert len(grandchild) == 1\n    assert nav_nav_navinfo(grandchild[0]) == ('foo.xhtml#foo-1-1', 'foo.1-1')\n", "type": "function"}], "retrieved_count": 10, "cost_time": 1.1453564167022705}
{"question": "How does the Python domain grouped field class resolve method conflicts between its cross-reference mixin and grouping base class?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"name": "make_field", "is_method": true, "class_name": "TypedField", "parameters": ["self", "types", "domain", "items", "env", "inliner", "location"], "calls": ["nodes.field_name", "nodes.field_body", "nodes.field", "nodes.paragraph", "par.extend", "any", "handle_item", "self.list_type", "self.make_xrefs", "nodes.Text", "types.pop", "nodes.Text", "nodes.Text", "len", "nodes.list_item", "isinstance", "astext", "par.extend", "strip", "handle_item", "len", "self.make_xrefs", "c.astext"], "code_location": {"file": "docfields.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/util", "start_line": 289, "end_line": 342}, "code_snippet": "    def make_field(\n        self,\n        types: _FieldTypes,\n        domain: str,\n        items: list[_FieldEntry],  # type: ignore[override]\n        env: BuildEnvironment | None = None,\n        inliner: Inliner | None = None,\n        location: Element | None = None,\n    ) -> nodes.field:\n        def handle_item(fieldarg: str, content: list[Node]) -> nodes.paragraph:\n            par = nodes.paragraph()\n            par.extend(\n                self.make_xrefs(\n                    self.rolename, domain, fieldarg, addnodes.literal_strong, env=env\n                )\n            )\n            if fieldarg in types:\n                par += nodes.Text(' (')\n                # NOTE: using .pop() here to prevent a single type node to be\n                # inserted twice into the doctree, which leads to\n                # inconsistencies later when references are resolved\n                fieldtype = types.pop(fieldarg)\n                if len(fieldtype) == 1 and isinstance(fieldtype[0], nodes.Text):\n                    typename = fieldtype[0].astext()\n                    par.extend(\n                        self.make_xrefs(\n                            self.typerolename,\n                            domain,\n                            typename,\n                            addnodes.literal_emphasis,\n                            env=env,\n                            inliner=inliner,\n                            location=location,\n                        )\n                    )\n                else:\n                    par += fieldtype\n                par += nodes.Text(')')\n            has_content = any(c.astext().strip() for c in content)\n            if has_content:\n                par += nodes.Text(' -- ')\n                par += content\n            return par\n\n        fieldname = nodes.field_name('', self.label)\n        if len(items) == 1 and self.can_collapse:\n            fieldarg, content = items[0]\n            bodynode: Node = handle_item(fieldarg, content)\n        else:\n            bodynode = self.list_type()\n            for fieldarg, content in items:\n                bodynode += nodes.list_item('', handle_item(fieldarg, content))\n        fieldbody = nodes.field_body('', bodynode)\n        return nodes.field('', fieldname, fieldbody)\n", "type": "function"}, {"name": "PyXrefMixin", "docstring": "", "methods": ["make_xref", "make_xrefs"], "attributes": ["_delimiters_re"], "code_location": {"file": "_object.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/domains/python", "start_line": 55, "end_line": 150}, "type": "class"}, {"name": "make_xref", "is_method": true, "class_name": "PyXrefMixin", "parameters": ["self", "rolename", "domain", "target", "innernode", "contnode", "env", "inliner", "location"], "calls": ["make_xref", "isinstance", "env.ref_context.get", "env.ref_context.get", "parse_reftarget", "super", "result.clear", "innernode", "result.clear", "innernode", "result.extend", "target.rpartition", "pending_xref_condition", "pending_xref_condition"], "code_location": {"file": "_object.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/domains/python", "start_line": 56, "end_line": 104}, "code_snippet": "    def make_xref(\n        self,\n        rolename: str,\n        domain: str,\n        target: str,\n        innernode: type[TextlikeNode] = nodes.emphasis,\n        contnode: Node | None = None,\n        env: BuildEnvironment | None = None,\n        inliner: Inliner | None = None,\n        location: Node | None = None,\n    ) -> Node:\n        # we use inliner=None to make sure we get the old behaviour with a single\n        # pending_xref node\n        result = super().make_xref(  # type: ignore[misc]\n            rolename,\n            domain,\n            target,\n            innernode,\n            contnode,\n            env,\n            inliner=None,\n            location=None,\n        )\n        if isinstance(result, pending_xref):\n            assert env is not None\n            result['refspecific'] = True\n            result['py:module'] = env.ref_context.get('py:module')\n            result['py:class'] = env.ref_context.get('py:class')\n\n            reftype, reftarget, reftitle, _ = parse_reftarget(target)\n            if reftarget != reftitle:\n                result['reftype'] = reftype\n                result['reftarget'] = reftarget\n\n                result.clear()\n                result += innernode(reftitle, reftitle)  # type: ignore[call-arg]\n            elif env.config.python_use_unqualified_type_names:\n                children = result.children\n                result.clear()\n\n                shortname = target.rpartition('.')[-1]\n                textnode = innernode('', shortname)  # type: ignore[call-arg]\n                contnodes = [\n                    pending_xref_condition('', '', textnode, condition='resolved'),\n                    pending_xref_condition('', '', *children, condition='*'),\n                ]\n                result.extend(contnodes)\n\n        return result\n", "type": "function"}, {"name": "make_field", "is_method": true, "class_name": "GroupedField", "parameters": ["self", "types", "domain", "items", "env", "inliner", "location"], "calls": ["nodes.field_name", "self.list_type", "nodes.field_body", "nodes.field", "nodes.paragraph", "par.extend", "nodes.Text", "nodes.list_item", "cast", "nodes.field_body", "nodes.field", "self.make_xrefs", "len"], "code_location": {"file": "docfields.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/util", "start_line": 217, "end_line": 251}, "code_snippet": "    def make_field(\n        self,\n        types: _FieldTypes,\n        domain: str,\n        items: list[_FieldEntry],  # type: ignore[override]\n        env: BuildEnvironment | None = None,\n        inliner: Inliner | None = None,\n        location: Element | None = None,\n    ) -> nodes.field:\n        fieldname = nodes.field_name('', self.label)\n        listnode = self.list_type()\n        for fieldarg, content in items:\n            par = nodes.paragraph()\n            par.extend(\n                self.make_xrefs(\n                    self.rolename,\n                    domain,\n                    fieldarg,\n                    addnodes.literal_strong,\n                    env=env,\n                    inliner=inliner,\n                    location=location,\n                )\n            )\n            par += nodes.Text(' -- ')\n            par += content\n            listnode += nodes.list_item('', par)\n\n        if len(items) == 1 and self.can_collapse:\n            list_item = cast('nodes.list_item', listnode[0])\n            fieldbody = nodes.field_body('', list_item[0])\n            return nodes.field('', fieldname, fieldbody)\n\n        fieldbody = nodes.field_body('', listnode)\n        return nodes.field('', fieldname, fieldbody)\n", "type": "function"}, {"name": "GroupedField", "docstring": "A doc field that is grouped; i.e., all fields of that type will be\ntransformed into one field with its body being a bulleted list.  It always\nhas an argument.  The argument can be linked using the given *rolename*.\nGroupedField should be used for doc fields that can occur more than once.\nIf *can_collapse* is true, this field will revert to a Field if only used\nonce.\n\nExample::\n\n   :raises ErrorClass: description when it is raised", "methods": ["__init__", "make_field"], "attributes": ["is_grouped", "list_type"], "code_location": {"file": "docfields.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/util", "start_line": 190, "end_line": 251}, "type": "class"}, {"name": "make_xref", "is_method": true, "class_name": "Field", "parameters": ["self", "rolename", "domain", "target", "innernode", "contnode", "env", "inliner", "location"], "calls": ["role", "role", "nodes.inline", "addnodes.pending_xref", "process_field_xref", "innernode", "env.get_domain", "__", "logger.warning", "innernode", "contextlib.suppress", "get_node_line", "__", "env.get_domain"], "code_location": {"file": "docfields.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/util", "start_line": 81, "end_line": 122}, "code_snippet": "    def make_xref(\n        self,\n        rolename: str,\n        domain: str,\n        target: str,\n        innernode: type[TextlikeNode] = addnodes.literal_emphasis,\n        contnode: Node | None = None,\n        env: BuildEnvironment | None = None,\n        inliner: Inliner | None = None,\n        location: Element | None = None,\n    ) -> Node:\n        # note: for backwards compatibility env is last, but not optional\n        assert env is not None\n        assert (inliner is None) == (location is None), (inliner, location)\n        if not rolename:\n            return contnode or innernode(target, target)  # type: ignore[call-arg]\n        # The domain is passed from DocFieldTransformer. So it surely exists.\n        # So we don't need to take care the env.get_domain() raises an exception.\n        role = env.get_domain(domain).role(rolename)\n        if role is None or inliner is None:\n            if role is None and inliner is not None:\n                msg = __(\n                    'Problem in %s domain: field is supposed '\n                    \"to use role '%s', but that role is not in the domain.\"\n                )\n                logger.warning(__(msg), domain, rolename, location=location)\n            refnode = addnodes.pending_xref(\n                '',\n                refdomain=domain,\n                refexplicit=False,\n                reftype=rolename,\n                reftarget=target,\n            )\n            refnode += contnode or innernode(target, target)  # type: ignore[call-arg]\n            env.get_domain(domain).process_field_xref(refnode)\n            return refnode\n        lineno = -1\n        if location is not None:\n            with contextlib.suppress(ValueError):\n                lineno = get_node_line(location)\n        ns, _messages = role(rolename, target, target, lineno, inliner, {}, [])\n        return nodes.inline(target, '', *ns)\n", "type": "function"}, {"name": "resolve_xref", "is_method": true, "class_name": "PythonDomain", "parameters": ["self", "env", "fromdocname", "builder", "type", "target", "node", "contnode"], "calls": ["node.get", "node.get", "self.find_obj", "node.hasattr", "self.find_obj", "self.find_obj", "self.find_obj", "self._make_module_refnode", "find_pending_xref_condition", "make_refnode", "self.find_obj", "len", "len", "logger.warning", "__", "join"], "code_location": {"file": "__init__.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/domains/python", "start_line": 940, "end_line": 1004}, "code_snippet": "    def resolve_xref(\n        self,\n        env: BuildEnvironment,\n        fromdocname: str,\n        builder: Builder,\n        type: str,\n        target: str,\n        node: pending_xref,\n        contnode: Element,\n    ) -> nodes.reference | None:\n        modname = node.get('py:module')\n        clsname = node.get('py:class')\n        searchmode = 1 if node.hasattr('refspecific') else 0\n        matches = self.find_obj(env, modname, clsname, target, type, searchmode)\n\n        if not matches and type == 'class':\n            # fallback to data/attr (for type aliases)\n            # type aliases are documented as data/attr but referenced as class\n            matches = self.find_obj(env, modname, clsname, target, 'data', searchmode)\n            if not matches:\n                matches = self.find_obj(\n                    env, modname, clsname, target, 'attr', searchmode\n                )\n        if not matches and type == 'attr':\n            # fallback to meth (for property; Sphinx 2.4.x)\n            # this ensures that `:attr:` role continues to refer to the old property entry\n            # that defined by ``method`` directive in old reST files.\n            matches = self.find_obj(env, modname, clsname, target, 'meth', searchmode)\n        if not matches and type == 'meth':\n            # fallback to attr (for property)\n            # this ensures that `:meth:` in the old reST files can refer to the property\n            # entry that defined by ``property`` directive.\n            #\n            # Note: _prop is a secret role only for internal look-up.\n            matches = self.find_obj(env, modname, clsname, target, '_prop', searchmode)\n\n        if not matches:\n            return None\n        elif len(matches) > 1:\n            canonicals = [m for m in matches if not m[1].aliased]\n            if len(canonicals) == 1:\n                matches = canonicals\n            else:\n                logger.warning(\n                    __('more than one target found for cross-reference %r: %s'),\n                    target,\n                    ', '.join(match[0] for match in matches),\n                    type='ref',\n                    subtype='python',\n                    location=node,\n                )\n        name, obj = matches[0]\n\n        if obj[2] == 'module':\n            return self._make_module_refnode(builder, fromdocname, name, contnode)\n        else:\n            # determine the content of the reference by conditions\n            content = find_pending_xref_condition(node, 'resolved')\n            if content:\n                children = content.children\n            else:\n                # if not found, use contnode\n                children = [contnode]\n\n            return make_refnode(builder, fromdocname, obj[0], obj[1], children, name)\n", "type": "function"}, {"name": "resolve_any_xref", "is_method": true, "class_name": "CDomain", "parameters": ["self", "env", "fromdocname", "builder", "target", "node", "contnode"], "calls": ["logging.suppress_logging", "self._resolve_xref_inner", "self.role_for_objtype"], "code_location": {"file": "__init__.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/domains/c", "start_line": 941, "end_line": 956}, "code_snippet": "    def resolve_any_xref(\n        self,\n        env: BuildEnvironment,\n        fromdocname: str,\n        builder: Builder,\n        target: str,\n        node: pending_xref,\n        contnode: Element,\n    ) -> list[tuple[str, nodes.reference]]:\n        with logging.suppress_logging():\n            retnode, objtype = self._resolve_xref_inner(\n                env, fromdocname, builder, 'any', target, node, contnode\n            )\n        if retnode:\n            return [('c:' + self.role_for_objtype(objtype), retnode)]\n        return []\n", "type": "function"}, {"name": "resolve_any_xref", "is_method": true, "class_name": "PythonDomain", "parameters": ["self", "env", "fromdocname", "builder", "target", "node", "contnode"], "calls": ["node.get", "node.get", "self.find_obj", "len", "results.append", "find_pending_xref_condition", "results.append", "self.role_for_objtype", "self._make_module_refnode", "make_refnode"], "code_location": {"file": "__init__.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/domains/python", "start_line": 1006, "end_line": 1047}, "code_snippet": "    def resolve_any_xref(\n        self,\n        env: BuildEnvironment,\n        fromdocname: str,\n        builder: Builder,\n        target: str,\n        node: pending_xref,\n        contnode: Element,\n    ) -> list[tuple[str, nodes.reference]]:\n        modname = node.get('py:module')\n        clsname = node.get('py:class')\n        results: list[tuple[str, nodes.reference]] = []\n\n        # always search in \"refspecific\" mode with the :any: role\n        matches = self.find_obj(env, modname, clsname, target, None, 1)\n        multiple_matches = len(matches) > 1\n\n        for name, obj in matches:\n            if multiple_matches and obj.aliased:\n                # Skip duplicated matches\n                continue\n\n            if obj[2] == 'module':\n                results.append((\n                    'py:mod',\n                    self._make_module_refnode(builder, fromdocname, name, contnode),\n                ))\n            else:\n                # determine the content of the reference by conditions\n                content = find_pending_xref_condition(node, 'resolved')\n                if content:\n                    children = content.children\n                else:\n                    # if not found, use contnode\n                    children = [contnode]\n\n                role = 'py:' + self.role_for_objtype(obj[2])  # type: ignore[operator]\n                results.append((\n                    role,\n                    make_refnode(builder, fromdocname, obj[0], obj[1], children, name),\n                ))\n        return results\n", "type": "function"}, {"name": "resolve_any_xref", "is_method": true, "class_name": "ReSTDomain", "parameters": ["self", "env", "fromdocname", "builder", "target", "node", "contnode"], "calls": ["self.objects.get", "results.append", "make_refnode", "self.role_for_objtype"], "code_location": {"file": "rst.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/domains", "start_line": 309, "end_line": 334}, "code_snippet": "    def resolve_any_xref(\n        self,\n        env: BuildEnvironment,\n        fromdocname: str,\n        builder: Builder,\n        target: str,\n        node: pending_xref,\n        contnode: Element,\n    ) -> list[tuple[str, nodes.reference]]:\n        results: list[tuple[str, nodes.reference]] = []\n        for objtype in self.object_types:\n            result = self.objects.get((objtype, target))\n            if result:\n                todocname, node_id = result\n                results.append((\n                    f'rst:{self.role_for_objtype(objtype)}',\n                    make_refnode(\n                        builder,\n                        fromdocname,\n                        todocname,\n                        node_id,\n                        contnode,\n                        f'{target} {objtype}',\n                    ),\n                ))\n        return results\n", "type": "function"}], "retrieved_count": 10, "cost_time": 1.1534504890441895}
{"question": "Why does the remote image downloader use a two-level structure with URI hash parent and sanitized basename, rather than a flat directory?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"name": "handle", "is_method": true, "class_name": "ImageDownloader", "parameters": ["self", "node"], "calls": ["os.path.basename", "CRITICAL_PATH_CHAR_RE.sub", "hexdigest", "Path", "path.parent.mkdir", "self._download_image", "os.path.splitext", "__", "logger.warning", "basename.split", "len", "hexdigest", "sha1", "encode", "sha1", "filename.encode"], "code_location": {"file": "images.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/transforms/post_transforms", "start_line": 61, "end_line": 80}, "code_snippet": "    def handle(self, node: nodes.image) -> None:\n        try:\n            basename = os.path.basename(node['uri'])\n            if '?' in basename:\n                basename = basename.split('?')[0]\n            if not basename or len(basename) > MAX_FILENAME_LEN:\n                filename, ext = os.path.splitext(node['uri'])\n                basename = (\n                    sha1(filename.encode(), usedforsecurity=False).hexdigest() + ext\n                )\n            basename = CRITICAL_PATH_CHAR_RE.sub('_', basename)\n\n            uri_hash = sha1(node['uri'].encode(), usedforsecurity=False).hexdigest()\n            path = Path(self.imagedir, uri_hash, basename)\n            path.parent.mkdir(parents=True, exist_ok=True)\n            self._download_image(node, path)\n\n        except Exception as exc:\n            msg = __('Could not fetch remote image: %s [%s]')\n            logger.warning(msg, node['uri'], exc)\n", "type": "function"}, {"name": "_download_image", "is_method": true, "class_name": "ImageDownloader", "parameters": ["self", "node", "path"], "calls": ["path.exists", "requests.get", "ceil", "epoch_to_rfc1123", "__", "logger.warning", "self._process_image", "_StrPath", "path.write_bytes", "r.headers.get", "rfc1123_to_epoch", "os.utime", "path.stat"], "code_location": {"file": "images.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/transforms/post_transforms", "start_line": 82, "end_line": 107}, "code_snippet": "    def _download_image(self, node: nodes.image, path: Path) -> None:\n        headers = {}\n        if path.exists():\n            timestamp: float = ceil(path.stat().st_mtime)\n            headers['If-Modified-Since'] = epoch_to_rfc1123(timestamp)\n\n        config = self.config\n        r = requests.get(\n            node['uri'],\n            headers=headers,\n            _user_agent=config.user_agent,\n            _tls_info=(config.tls_verify, config.tls_cacerts),\n        )\n        if r.status_code >= 400:\n            msg = __('Could not fetch remote image: %s [%d]')\n            logger.warning(msg, node['uri'], r.status_code)\n        else:\n            self.env.original_image_uri[_StrPath(path)] = node['uri']\n\n            if r.status_code == 200:\n                path.write_bytes(r.content)\n            if last_modified := r.headers.get('Last-Modified'):\n                timestamp = rfc1123_to_epoch(last_modified)\n                os.utime(path, (timestamp, timestamp))\n\n            self._process_image(node, path)\n", "type": "function"}, {"name": "get_original_image_uri", "is_method": true, "class_name": "ImageAdapter", "parameters": ["self", "name"], "calls": ["_StrPath", "_StrPath"], "code_location": {"file": "asset.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/environment/adapters", "start_line": 17, "end_line": 22}, "code_snippet": "    def get_original_image_uri(self, name: str) -> str:\n        \"\"\"Get the original image URI.\"\"\"\n        while _StrPath(name) in self.env.original_image_uri:\n            name = self.env.original_image_uri[_StrPath(name)]\n\n        return name\n", "type": "function"}, {"name": "imagedir", "is_method": true, "class_name": "BaseImageConverter", "parameters": ["self"], "calls": [], "code_location": {"file": "images.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/transforms/post_transforms", "start_line": 47, "end_line": 48}, "code_snippet": "    def imagedir(self) -> _StrPath:\n        return self.env.doctreedir / 'images'\n", "type": "function"}, {"name": "handle", "is_method": true, "class_name": "DataURIExtractor", "parameters": ["self", "node"], "calls": ["parse_data_uri", "get_image_extension", "ensuredir", "hexdigest", "str", "pop", "self.env.images.add_file", "logger.warning", "open", "f.write", "__", "sha1"], "code_location": {"file": "images.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/transforms/post_transforms", "start_line": 137, "end_line": 159}, "code_snippet": "    def handle(self, node: nodes.image) -> None:\n        image = parse_data_uri(node['uri'])\n        assert image is not None\n        ext = get_image_extension(image.mimetype)\n        if ext is None:\n            logger.warning(\n                __('Unknown image format: %s...'), node['uri'][:32], location=node\n            )\n            return\n\n        ensuredir(self.imagedir / 'embeded')\n        digest = sha1(image.data, usedforsecurity=False).hexdigest()\n        path = self.imagedir / 'embeded' / (digest + ext)\n        self.env.original_image_uri[path] = node['uri']\n\n        with open(path, 'wb') as f:\n            f.write(image.data)\n\n        path_str = str(path)\n        node['candidates'].pop('?')\n        node['candidates'][image.mimetype] = path_str\n        node['uri'] = path_str\n        self.env.images.add_file(self.env.current_document.docname, path_str)\n", "type": "function"}, {"name": "get_filename_for", "is_method": false, "class_name": null, "parameters": ["filename", "mimetype"], "calls": ["os.path.basename", "CRITICAL_PATH_CHAR_RE.sub", "os.path.splitext", "get_image_extension"], "code_location": {"file": "images.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/transforms/post_transforms", "start_line": 162, "end_line": 165}, "code_snippet": "def get_filename_for(filename: str, mimetype: str) -> str:\n    basename = os.path.basename(filename)\n    basename = CRITICAL_PATH_CHAR_RE.sub('_', basename)\n    return os.path.splitext(basename)[0] + (get_image_extension(mimetype) or '')\n", "type": "function"}, {"name": "copy_image_files", "is_method": true, "class_name": "StandaloneHTMLBuilder", "parameters": ["self"], "calls": ["ensuredir", "status_iterator", "ImageAdapter", "__", "len", "copyfile", "logger.warning", "__"], "code_location": {"file": "__init__.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/builders/html", "start_line": 775, "end_line": 797}, "code_snippet": "    def copy_image_files(self) -> None:\n        if self.images:\n            stringify_func = ImageAdapter(self.env).get_original_image_uri\n            ensuredir(self._images_dir)\n            for src in status_iterator(\n                self.images,\n                __('copying images... '),\n                'brown',\n                len(self.images),\n                self.config.verbosity,\n                stringify_func=stringify_func,\n            ):\n                dest = self.images[src]\n                try:\n                    copyfile(\n                        self.srcdir / src,\n                        self._images_dir / dest,\n                        force=True,\n                    )\n                except Exception as err:\n                    logger.warning(\n                        __(\"cannot copy image file '%s': %s\"), self.srcdir / src, err\n                    )\n", "type": "function"}, {"name": "visit_image", "is_method": true, "class_name": "HTML5Translator", "parameters": ["self", "node"], "calls": ["visit_image", "posixpath.join", "urllib.parse.quote", "get_image_size", "super", "logger.warning", "__", "str", "str"], "code_location": {"file": "html5.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/writers", "start_line": 750, "end_line": 775}, "code_snippet": "    def visit_image(self, node: nodes.image) -> None:\n        olduri = node['uri']\n        # rewrite the URI if the environment knows about it\n        if olduri in self.builder.images:\n            node['uri'] = posixpath.join(\n                self.builder.imgpath, urllib.parse.quote(self.builder.images[olduri])\n            )\n\n        if 'scale' in node:\n            # Try to figure out image height and width.  Docutils does that too,\n            # but it tries the final file name, which does not necessarily exist\n            # yet at the time the HTML file is written.\n            if not ('width' in node and 'height' in node):\n                size = get_image_size(self.builder.srcdir / olduri)\n                if size is None:\n                    logger.warning(\n                        __('Could not obtain image size. :scale: option is ignored.'),\n                        location=node,\n                    )\n                else:\n                    if 'width' not in node:\n                        node['width'] = str(size[0])\n                    if 'height' not in node:\n                        node['height'] = str(size[1])\n\n        super().visit_image(node)\n", "type": "function"}, {"name": "_file_checksum", "is_method": false, "class_name": null, "parameters": ["outdir", "filename"], "calls": ["os.fspath", "_file_checksum_inner", "ThemeError", "resolve", "outdir.joinpath"], "code_location": {"file": "_assets.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/builders/html", "start_line": 165, "end_line": 177}, "code_snippet": "def _file_checksum(outdir: Path, filename: str | os.PathLike[str]) -> str:\n    filename = os.fspath(filename)\n    # Don't generate checksums for HTTP URIs\n    if '://' in filename:\n        return ''\n    # Some themes and extensions have used query strings\n    # for a similar asset checksum feature.\n    # As we cannot safely strip the query string,\n    # raise an error to the user.\n    if '?' in filename:\n        msg = f'Local asset file paths must not contain query strings: {filename!r}'\n        raise ThemeError(msg)\n    return _file_checksum_inner(outdir.joinpath(filename).resolve())\n", "type": "function"}, {"name": "process_doc", "is_method": true, "class_name": "ImageCollector", "parameters": ["self", "app", "doctree"], "calls": ["doctree.findall", "imguri.startswith", "imguri.endswith", "candidates.values", "imguri.find", "app.env.relfn2path", "get_image_filename_for_language", "app.env.relfn2path", "self.collect_candidates", "self.collect_candidates", "search_image_for_language", "app.env.relfn2path", "app.env.note_dependency", "app.env.images.add_file", "os.access", "logger.warning", "__"], "code_location": {"file": "asset.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/environment/collectors", "start_line": 48, "end_line": 105}, "code_snippet": "    def process_doc(self, app: Sphinx, doctree: nodes.document) -> None:\n        \"\"\"Process and rewrite image URIs.\"\"\"\n        docname = app.env.current_document.docname\n\n        for node in doctree.findall(nodes.image):\n            # Map the mimetype to the corresponding image.  The writer may\n            # choose the best image from these candidates.  The special key * is\n            # set if there is only single candidate to be used by a writer.\n            # The special key ? is set for nonlocal URIs.\n            candidates: dict[str, str] = {}\n            node['candidates'] = candidates\n            imguri = node['uri']\n            if imguri.startswith('data:'):\n                candidates['?'] = imguri\n                continue\n            if imguri.find('://') != -1:\n                candidates['?'] = imguri\n                continue\n\n            if imguri.endswith(os.extsep + '*'):\n                # Update `node['uri']` to a relative path from srcdir\n                # from a relative path from current document.\n                rel_imgpath, full_imgpath = app.env.relfn2path(imguri, docname)\n                node['uri'] = rel_imgpath\n\n                # Search language-specific figures at first\n                i18n_imguri = get_image_filename_for_language(imguri, app.env)\n                _, full_i18n_imgpath = app.env.relfn2path(i18n_imguri, docname)\n                self.collect_candidates(app.srcdir, full_i18n_imgpath, candidates, node)\n\n                self.collect_candidates(app.srcdir, full_imgpath, candidates, node)\n            else:\n                # substitute imguri by figure_language_filename\n                # (ex. foo.png -> foo.en.png)\n                imguri = search_image_for_language(imguri, app.env)\n\n                # Update `node['uri']` to a relative path from srcdir\n                # from a relative path from current document.\n                original_uri = node['uri']\n                node['uri'], _ = app.env.relfn2path(imguri, docname)\n                candidates['*'] = node['uri']\n                if node['uri'] != original_uri:\n                    node['original_uri'] = original_uri\n\n            # map image paths to unique image names (so that they can be put\n            # into a single directory)\n            for imgpath in candidates.values():\n                app.env.note_dependency(imgpath)\n                if not os.access(app.srcdir / imgpath, os.R_OK):\n                    logger.warning(\n                        __('image file not readable: %s'),\n                        imgpath,\n                        location=node,\n                        type='image',\n                        subtype='not_readable',\n                    )\n                    continue\n                app.env.images.add_file(docname, imgpath)\n", "type": "function"}], "retrieved_count": 10, "cost_time": 1.1446533203125}
{"question": "How does the identifier caching dictionary in the EPUB builder's generation method interact with environment pickling to ensure consistent identifier assignment across build runs while maintaining thread safety?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"name": "__init__", "is_method": true, "class_name": "BuildEnvironment", "parameters": ["self", "app"], "calls": ["_get_env_version", "default_settings.copy", "defaultdict", "defaultdict", "set", "defaultdict", "set", "set", "FilenameUniqDict", "DownloadFiles", "_CurrentDocument", "_DomainsContainer._from_environment", "self.setup"], "code_location": {"file": "__init__.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/environment", "start_line": 114, "end_line": 239}, "code_snippet": "    def __init__(self, app: Sphinx) -> None:\n        self._app: Sphinx = app\n        self.doctreedir = app.doctreedir\n        self.srcdir = app.srcdir\n        self.config: Config = None  # type: ignore[assignment]\n        self.config_status: int = CONFIG_UNSET\n        self.config_status_extra: str = ''\n        self.events: EventManager = app.events\n        self.project: Project = app.project\n        self.version: Mapping[str, int] = _get_env_version(app.extensions)\n\n        # the method of doctree versioning; see set_versioning_method\n        self.versioning_condition: Literal[False] | Callable[[Node], bool] | None = None\n        self.versioning_compare: bool | None = None\n\n        # the docutils settings for building\n        self.settings: dict[str, Any] = default_settings.copy()\n        self.settings['env'] = self\n\n        # All \"docnames\" here are /-separated and relative and exclude\n        # the source suffix.\n\n        # docname -> time of reading (in integer microseconds)\n        # contains all read docnames\n        self.all_docs: dict[str, int] = {}\n        # docname -> set of dependent file\n        # names, relative to documentation root\n        self.dependencies: dict[str, set[_StrPath]] = defaultdict(set)\n        # docname -> set of included file\n        # docnames included from other documents\n        self.included: dict[str, set[str]] = defaultdict(set)\n        # docnames to re-read unconditionally on next build\n        self.reread_always: set[str] = set()\n\n        self._pickled_doctree_cache: dict[str, bytes] = {}\n        \"\"\"In-memory cache for reading pickled doctrees from disk.\n        docname -> pickled doctree\n\n        This cache is used in the ``get_doctree`` method to avoid reading the\n        doctree from disk multiple times.\n        \"\"\"\n\n        self._write_doc_doctree_cache: dict[str, nodes.document] = {}\n        \"\"\"In-memory cache for unpickling doctrees from disk.\n        docname -> doctree\n\n        Items are added in ``Builder.write_doctree``, during the read phase,\n        then used only in the ``get_and_resolve_doctree`` method.\n        \"\"\"\n\n        # File metadata\n        # docname -> dict of metadata items\n        self.metadata: dict[str, dict[str, Any]] = defaultdict(dict)\n\n        # TOC inventory\n        # docname -> title node\n        self.titles: dict[str, nodes.title] = {}\n        # docname -> title node; only different if\n        # set differently with title directive\n        self.longtitles: dict[str, nodes.title] = {}\n        # docname -> table of contents nodetree\n        self.tocs: dict[str, nodes.bullet_list] = {}\n        # docname -> number of real entries\n        self.toc_num_entries: dict[str, int] = {}\n\n        # used to determine when to show the TOC\n        # in a sidebar (don't show if it's only one item)\n        # docname -> dict of sectionid -> number\n        self.toc_secnumbers: dict[str, dict[str, tuple[int, ...]]] = {}\n        # docname -> dict of figtype -> dict of figureid -> number\n        self.toc_fignumbers: dict[str, dict[str, dict[str, tuple[int, ...]]]] = {}\n\n        # docname -> list of toctree includefiles\n        self.toctree_includes: dict[str, list[str]] = {}\n        # docname -> set of files (containing its TOCs) to rebuild too\n        self.files_to_rebuild: dict[str, set[str]] = {}\n        # docnames that have :glob: toctrees\n        self.glob_toctrees: set[str] = set()\n        # docnames that have :numbered: toctrees\n        self.numbered_toctrees: set[str] = set()\n\n        # domain-specific inventories, here to be pickled\n        # domainname -> domain-specific dict\n        self.domaindata: dict[str, dict[str, Any]] = {}\n\n        # these map absolute path -> (docnames, unique filename)\n        self.images: FilenameUniqDict = FilenameUniqDict()\n        # filename -> (set of docnames, destination)\n        self.dlfiles: DownloadFiles = DownloadFiles()\n\n        # the original URI for images\n        self.original_image_uri: dict[_StrPath, str] = {}\n\n        # temporary data storage while reading a document\n        self.current_document: _CurrentDocument = _CurrentDocument()\n        # context for cross-references (e.g. current module or class)\n        # this is similar to ``self.current_document``,\n        # but will for example be copied to attributes of \"any\" cross references\n        self.ref_context: dict[str, Any] = {}\n\n        # search index data\n\n        # docname -> title\n        self._search_index_titles: dict[str, str | None] = {}\n        # docname -> filename\n        self._search_index_filenames: dict[str, str] = {}\n        # stemmed words -> set(docname)\n        self._search_index_mapping: dict[str, set[str]] = {}\n        # stemmed words in titles -> set(docname)\n        self._search_index_title_mapping: dict[str, set[str]] = {}\n        # docname -> all titles in document\n        self._search_index_all_titles: dict[str, list[tuple[str, str | None]]] = {}\n        # docname -> list(index entry)\n        self._search_index_index_entries: dict[str, list[tuple[str, str, str]]] = {}\n        # objtype -> index\n        self._search_index_objtypes: dict[tuple[str, str], int] = {}\n        # objtype index -> (domain, type, objname (localized))\n        self._search_index_objnames: dict[int, tuple[str, str, str]] = {}\n\n        # all the registered domains, set by the application\n        self.domains: _DomainsContainer = _DomainsContainer._from_environment(\n            self, registry=app.registry\n        )\n\n        # set up environment\n        self.setup(app)\n", "type": "function"}, {"name": "_init_env", "is_method": true, "class_name": "Sphinx", "parameters": ["self", "freshenv"], "calls": ["self._create_fresh_env", "self._load_existing_env", "filename.exists"], "code_location": {"file": "application.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx", "start_line": 382, "end_line": 387}, "code_snippet": "    def _init_env(self, freshenv: bool) -> BuildEnvironment:\n        filename = self.doctreedir / ENV_PICKLE_FILENAME\n        if freshenv or not filename.exists():\n            return self._create_fresh_env()\n        else:\n            return self._load_existing_env(filename)\n", "type": "function"}, {"name": "test_epub_anchor_id", "is_method": false, "class_name": null, "parameters": ["app"], "calls": ["pytest.mark.sphinx", "app.build", "read_text"], "code_location": {"file": "test_build_epub.py", "path": "/data3/pwh/swebench-repos/sphinx/tests/test_builders", "start_line": 415, "end_line": 425}, "code_snippet": "def test_epub_anchor_id(app: SphinxTestApp) -> None:\n    app.build()\n\n    html = (app.outdir / 'index.xhtml').read_text(encoding='utf8')\n    assert '<p id=\"std-setting-STATICFILES_FINDERS\">blah blah blah</p>' in html\n    assert (\n        '<span id=\"std-setting-STATICFILES_SECTION\"></span><h1>blah blah blah</h1>'\n    ) in html\n    assert (\n        'see <a class=\"reference internal\" href=\"#std-setting-STATICFILES_FINDERS\">'\n    ) in html\n", "type": "function"}, {"name": "build", "is_method": true, "class_name": "SphinxTestApp", "parameters": ["self", "force_all", "filenames"], "calls": ["self.env._pickled_doctree_cache.clear", "build", "super"], "code_location": {"file": "util.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/testing", "start_line": 235, "end_line": 237}, "code_snippet": "    def build(self, force_all: bool = False, filenames: Sequence[Path] = ()) -> None:\n        self.env._pickled_doctree_cache.clear()\n        super().build(force_all, filenames)\n", "type": "function"}, {"name": "test_pickleablility", "is_method": false, "class_name": null, "parameters": [], "calls": ["original.copy", "pickle.loads", "all", "pickle.dumps", "getattr", "loaded.findall"], "code_location": {"file": "test_versioning.py", "path": "/data3/pwh/swebench-repos/sphinx/tests", "start_line": 52, "end_line": 61}, "code_snippet": "def test_pickleablility() -> None:\n    # we have to modify the doctree so we can pickle it\n    copy = original.copy()\n    copy.reporter = None\n    copy.transformer = None\n    copy.settings.warning_stream = None\n    copy.settings.env = None\n    copy.settings.record_dependencies = None\n    loaded = pickle.loads(pickle.dumps(copy, pickle.HIGHEST_PROTOCOL))\n    assert all(getattr(n, 'uid', False) for n in loaded.findall(is_paragraph))\n", "type": "function"}, {"name": "test_load_mappings_cache_revert_update", "is_method": false, "class_name": null, "parameters": ["tmp_path"], "calls": ["touch", "touch", "SingleEntryProject", "SingleEntryProject", "make_inventory_handler", "old_project.make_entry", "dict", "InventoryAdapter", "http_server", "SphinxTestApp", "app1.build", "app1.cleanup", "SphinxTestApp", "app2.build", "app2.cleanup", "SphinxTestApp", "app3.build", "app3.cleanup", "list", "tmp_path.joinpath", "tmp_path.joinpath", "old_project.normalise"], "code_location": {"file": "test_ext_intersphinx_cache.py", "path": "/data3/pwh/swebench-repos/sphinx/tests/test_extensions", "start_line": 285, "end_line": 319}, "code_snippet": "def test_load_mappings_cache_revert_update(tmp_path):\n    tmp_path.joinpath('conf.py').touch()\n    tmp_path.joinpath('index.rst').touch()\n    old_project = SingleEntryProject(1337, 'old')\n    new_project = SingleEntryProject(1701, 'new')\n\n    InventoryHandler = make_inventory_handler(old_project, new_project)\n    with http_server(InventoryHandler, port=SingleEntryProject.port):\n        # build normally to create an initial cache\n        confoverrides1 = BASE_CONFIG | {'intersphinx_mapping': old_project.record}\n        app1 = SphinxTestApp('dummy', srcdir=tmp_path, confoverrides=confoverrides1)\n        app1.build()\n        app1.cleanup()\n\n        # switch to new url and build\n        confoverrides2 = BASE_CONFIG | {'intersphinx_mapping': new_project.record}\n        app2 = SphinxTestApp('dummy', srcdir=tmp_path, confoverrides=confoverrides2)\n        app2.build()\n        app2.cleanup()\n\n        # switch back to old url (reuse 'old_item')\n        confoverrides3 = BASE_CONFIG | {'intersphinx_mapping': old_project.record}\n        app3 = SphinxTestApp('dummy', srcdir=tmp_path, confoverrides=confoverrides3)\n        app3.build()\n        app3.cleanup()\n\n    entry = old_project.make_entry()\n    item = dict((old_project.normalise(entry),))\n    inventories = InventoryAdapter(app3.env)\n    # check that the URLs were changed accordingly\n    assert list(inventories.cache) == ['http://localhost:9341/old']\n    e_name, _e_time, e_inv = inventories.cache['http://localhost:9341/old']\n    assert e_name == 'spam'\n    assert e_inv == {'py:module': item}\n    assert inventories.named_inventory == {'spam': {'py:module': item}}\n", "type": "function"}, {"name": "test_pickle_set_translator_for_pickle", "is_method": false, "class_name": null, "parameters": ["app"], "calls": ["pytest.mark.sphinx", "app.builder.get_translator_class"], "code_location": {"file": "test_api_translator.py", "path": "/data3/pwh/swebench-repos/sphinx/tests/test_writers", "start_line": 51, "end_line": 54}, "code_snippet": "def test_pickle_set_translator_for_pickle(app: SphinxTestApp) -> None:\n    translator_class = app.builder.get_translator_class()\n    assert translator_class\n    assert translator_class.__name__ == 'ConfPickleTranslator'\n", "type": "function"}, {"name": "test_build_epub", "is_method": false, "class_name": null, "parameters": ["app"], "calls": ["pytest.mark.sphinx", "app.build", "exists", "EPUBElementTree.fromstring", "list", "toc.findall", "find", "EPUBElementTree.fromstring", "opf.find", "opf.find", "list", "enumerate", "opf.find", "list", "opf.find", "EPUBElementTree.fromstring", "nav.find", "navlist.findall", "read_text", "read_text", "toc.find", "len", "read_text", "spine.get", "spine.get", "get", "get", "reference.get", "reference.get", "reference.get", "read_text", "len", "get", "toc.find", "find", "metadata.find", "metadata.find", "metadata.find", "metadata.find", "metadata.find", "metadata.find", "metadata.find", "metadata.find", "metadata.find", "metadata.find", "metadata.find", "item.get", "nav.find", "navlist.find", "find", "find"], "code_location": {"file": "test_build_epub.py", "path": "/data3/pwh/swebench-repos/sphinx/tests/test_builders", "start_line": 79, "end_line": 192}, "code_snippet": "def test_build_epub(app: SphinxTestApp) -> None:\n    app.build(force_all=True)\n    assert (app.outdir / 'mimetype').read_text(\n        encoding='utf8'\n    ) == 'application/epub+zip'\n    assert (app.outdir / 'META-INF' / 'container.xml').exists()\n\n    # toc.ncx\n    toc = EPUBElementTree.fromstring(\n        (app.outdir / 'toc.ncx').read_text(encoding='utf8')\n    )\n    assert toc.find('./ncx:docTitle/ncx:text').text == 'Project name not set'\n\n    # toc.ncx / head\n    meta = list(toc.find('./ncx:head'))\n    assert meta[0].attrib == {'name': 'dtb:uid', 'content': 'unknown'}\n    assert meta[1].attrib == {'name': 'dtb:depth', 'content': '1'}\n    assert meta[2].attrib == {'name': 'dtb:totalPageCount', 'content': '0'}\n    assert meta[3].attrib == {'name': 'dtb:maxPageNumber', 'content': '0'}\n\n    # toc.ncx / navMap\n    navpoints = toc.findall('./ncx:navMap/ncx:navPoint')\n    assert len(navpoints) == 1\n    assert navpoints[0].attrib == {'id': 'navPoint1', 'playOrder': '1'}\n    assert navpoints[0].find('./ncx:content').attrib == {'src': 'index.xhtml'}\n\n    navlabel = navpoints[0].find('./ncx:navLabel/ncx:text')\n    assert navlabel.text == 'The basic Sphinx documentation for testing'\n\n    # content.opf\n    opf = EPUBElementTree.fromstring(\n        (app.outdir / 'content.opf').read_text(encoding='utf8')\n    )\n\n    # content.opf / metadata\n    metadata = opf.find('./idpf:metadata')\n    assert metadata.find('./dc:language').text == 'en'\n    assert metadata.find('./dc:title').text == 'Project name not set'\n    assert metadata.find('./dc:description').text == 'unknown'\n    assert metadata.find('./dc:creator').text == 'Author name not set'\n    assert metadata.find('./dc:contributor').text == 'unknown'\n    assert metadata.find('./dc:publisher').text == 'Author name not set'\n    assert metadata.find('./dc:rights').text is None\n    assert metadata.find(\"./idpf:meta[@property='ibooks:version']\").text is None\n    assert (\n        metadata.find(\"./idpf:meta[@property='ibooks:specified-fonts']\").text == 'true'\n    )\n    assert metadata.find(\"./idpf:meta[@property='ibooks:binding']\").text == 'true'\n    assert (\n        metadata.find(\"./idpf:meta[@property='ibooks:scroll-axis']\").text == 'vertical'\n    )\n\n    # content.opf / manifest\n    manifest = opf.find('./idpf:manifest')\n    items = list(manifest)\n    assert items[0].attrib == {\n        'id': 'ncx',\n        'href': 'toc.ncx',\n        'media-type': 'application/x-dtbncx+xml',\n    }\n    assert items[1].attrib == {\n        'id': 'nav',\n        'href': 'nav.xhtml',\n        'media-type': 'application/xhtml+xml',\n        'properties': 'nav',\n    }\n    assert items[2].attrib == {\n        'id': 'epub-0',\n        'href': 'genindex.xhtml',\n        'media-type': 'application/xhtml+xml',\n    }\n    assert items[3].attrib == {\n        'id': 'epub-1',\n        'href': 'index.xhtml',\n        'media-type': 'application/xhtml+xml',\n    }\n\n    for i, item in enumerate(items[2:]):\n        # items are named as epub-NN\n        assert item.get('id') == 'epub-%d' % i\n\n    # content.opf / spine\n    spine = opf.find('./idpf:spine')\n    itemrefs = list(spine)\n    assert spine.get('toc') == 'ncx'\n    assert spine.get('page-progression-direction') == 'ltr'\n    assert itemrefs[0].get('idref') == 'epub-1'\n    assert itemrefs[1].get('idref') == 'epub-0'\n\n    # content.opf / guide\n    reference = opf.find('./idpf:guide/idpf:reference')\n    assert reference.get('type') == 'toc'\n    assert reference.get('title') == 'Table of Contents'\n    assert reference.get('href') == 'index.xhtml'\n\n    # nav.xhtml\n    nav = EPUBElementTree.fromstring(\n        (app.outdir / 'nav.xhtml').read_text(encoding='utf8')\n    )\n    assert nav.attrib == {\n        'lang': 'en',\n        '{http://www.w3.org/XML/1998/namespace}lang': 'en',\n    }\n    assert nav.find('./xhtml:head/xhtml:title').text == 'Table of Contents'\n\n    # nav.xhtml / nav\n    navlist = nav.find('./xhtml:body/xhtml:nav')\n    tocs = navlist.findall('./xhtml:ol/xhtml:li')\n    assert navlist.find('./xhtml:h1').text == 'Table of Contents'\n    assert len(tocs) == 1\n    assert tocs[0].find('./xhtml:a').get('href') == 'index.xhtml'\n    assert (\n        tocs[0].find('./xhtml:a').text == 'The basic Sphinx documentation for testing'\n    )\n", "type": "function"}, {"name": "run", "is_method": true, "class_name": "ViewcodeAnchorTransform", "parameters": ["self"], "calls": ["is_supported_builder", "self.convert_viewcode_anchors", "self.remove_viewcode_anchors"], "code_location": {"file": "viewcode.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/ext", "start_line": 222, "end_line": 228}, "code_snippet": "    def run(self, **kwargs: Any) -> None:\n        if is_supported_builder(\n            self.env._builder_cls, self.config.viewcode_enable_epub\n        ):\n            self.convert_viewcode_anchors()\n        else:\n            self.remove_viewcode_anchors()\n", "type": "function"}, {"name": "test_load_mappings_cache", "is_method": false, "class_name": null, "parameters": ["tmp_path"], "calls": ["touch", "touch", "SingleEntryProject", "make_inventory_handler", "project.make_entry", "dict", "InventoryAdapter", "http_server", "SphinxTestApp", "app.build", "app.cleanup", "list", "tmp_path.joinpath", "tmp_path.joinpath", "project.normalise"], "code_location": {"file": "test_ext_intersphinx_cache.py", "path": "/data3/pwh/swebench-repos/sphinx/tests/test_extensions", "start_line": 228, "end_line": 249}, "code_snippet": "def test_load_mappings_cache(tmp_path):\n    tmp_path.joinpath('conf.py').touch()\n    tmp_path.joinpath('index.rst').touch()\n    project = SingleEntryProject(1, 'a')\n\n    InventoryHandler = make_inventory_handler(project)\n    with http_server(InventoryHandler, port=project.port):\n        # clean build\n        confoverrides = BASE_CONFIG | {'intersphinx_mapping': project.record}\n        app = SphinxTestApp('dummy', srcdir=tmp_path, confoverrides=confoverrides)\n        app.build()\n        app.cleanup()\n\n    # the inventory when querying the 'old' URL\n    entry = project.make_entry()\n    item = dict((project.normalise(entry),))\n    inventories = InventoryAdapter(app.env)\n    assert list(inventories.cache) == ['http://localhost:9341/a']\n    e_name, _e_time, e_inv = inventories.cache['http://localhost:9341/a']\n    assert e_name == 'spam'\n    assert e_inv == {'py:module': item}\n    assert inventories.named_inventory == {'spam': {'py:module': item}}\n", "type": "function"}], "retrieved_count": 10, "cost_time": 1.139174222946167}
{"question": "Why does the custom LaTeX node class that wraps literal blocks with captions and inherits from the docutils container node class cause performance degradation during document traversal when the container's node visitation mechanism performs redundant type checking on every child node?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"name": "captioned_literal_block", "docstring": "A node for a container of literal_block having a caption.", "methods": [], "attributes": [], "code_location": {"file": "nodes.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/builders/latex", "start_line": 8, "end_line": 11}, "type": "class"}, {"name": "LiteralBlockTransform", "docstring": "Replace container nodes for literal_block by captioned_literal_block.", "methods": ["run"], "attributes": ["default_priority", "formats"], "code_location": {"file": "transforms.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/builders/latex", "start_line": 580, "end_line": 590}, "type": "class"}, {"name": "visit_caption", "is_method": true, "class_name": "ManualPageTranslator", "parameters": ["self", "node"], "calls": ["isinstance", "node.parent.get", "self.body.append", "visit_caption", "super"], "code_location": {"file": "manpage.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/writers", "start_line": 408, "end_line": 415}, "code_snippet": "    def visit_caption(self, node: nodes.caption) -> None:\n        if (\n            isinstance(node.parent, nodes.container)\n            and node.parent.get('literal_block')\n        ):  # fmt: skip\n            self.body.append('.sp\\n')\n        else:\n            super().visit_caption(node)\n", "type": "function"}, {"name": "visit_caption", "is_method": true, "class_name": "HTML5Translator", "parameters": ["self", "node"], "calls": ["self.add_fignumber", "self.body.append", "isinstance", "node.parent.get", "self.body.append", "visit_caption", "self.starttag", "super"], "code_location": {"file": "html5.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/writers", "start_line": 617, "end_line": 626}, "code_snippet": "    def visit_caption(self, node: nodes.caption) -> None:\n        if (\n            isinstance(node.parent, nodes.container)\n            and node.parent.get('literal_block')\n        ):  # fmt: skip\n            self.body.append('<div class=\"code-block-caption\">')\n        else:\n            super().visit_caption(node)\n        self.add_fignumber(node.parent)\n        self.body.append(self.starttag(node, 'span', '', CLASS='caption-text'))\n", "type": "function"}, {"name": "visit_caption", "is_method": true, "class_name": "TexinfoTranslator", "parameters": ["self", "node"], "calls": ["isinstance", "self.body.append", "logger.warning", "isinstance", "node.parent.get", "__"], "code_location": {"file": "texinfo.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/writers", "start_line": 1210, "end_line": 1217}, "code_snippet": "    def visit_caption(self, node: Element) -> None:\n        if isinstance(node.parent, nodes.figure) or (\n            isinstance(node.parent, nodes.container)\n            and node.parent.get('literal_block')\n        ):\n            self.body.append('\\n@caption{')\n        else:\n            logger.warning(__('caption not inside a figure.'), location=node)\n", "type": "function"}, {"name": "visit_container", "is_method": true, "class_name": "TexinfoTranslator", "parameters": ["self", "node"], "calls": ["node.get", "self.body.append"], "code_location": {"file": "texinfo.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/writers", "start_line": 1160, "end_line": 1162}, "code_snippet": "    def visit_container(self, node: Element) -> None:\n        if node.get('literal_block'):\n            self.body.append('\\n\\n@float LiteralBlock\\n')\n", "type": "function"}, {"name": "depart_caption", "is_method": true, "class_name": "ManualPageTranslator", "parameters": ["self", "node"], "calls": ["isinstance", "node.parent.get", "self.body.append", "depart_caption", "super"], "code_location": {"file": "manpage.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/writers", "start_line": 417, "end_line": 424}, "code_snippet": "    def depart_caption(self, node: nodes.caption) -> None:\n        if (\n            isinstance(node.parent, nodes.container)\n            and node.parent.get('literal_block')\n        ):  # fmt: skip\n            self.body.append('\\n')\n        else:\n            super().depart_caption(node)\n", "type": "function"}, {"name": "visit_caption", "is_method": true, "class_name": "LaTeXTranslator", "parameters": ["self", "node"], "calls": ["isinstance", "self.body.append", "isinstance", "self.body.append", "self.body.append", "self.body.append"], "code_location": {"file": "latex.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/writers", "start_line": 1763, "end_line": 1772}, "code_snippet": "    def visit_caption(self, node: Element) -> None:\n        self.in_caption += 1\n        if isinstance(node.parent, captioned_literal_block):\n            self.body.append(r'\\sphinxSetupCaptionForVerbatim{')\n        elif self.in_minipage and isinstance(node.parent, nodes.figure):\n            self.body.append(r'\\captionof{figure}{')\n        elif self.table and node.parent.tagname == 'figure':\n            self.body.append(r'\\sphinxfigcaption{')\n        else:\n            self.body.append(r'\\caption{')\n", "type": "function"}, {"name": "visit_container", "is_method": true, "class_name": "LaTeXTranslator", "parameters": ["self", "node"], "calls": ["node.get", "self.body.append"], "code_location": {"file": "latex.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/writers", "start_line": 2398, "end_line": 2401}, "code_snippet": "    def visit_container(self, node: Element) -> None:\n        classes = node.get('classes', [])  # type: ignore[var-annotated]\n        for c in classes:\n            self.body.append('\\n\\\\begin{sphinxuseclass}{%s}' % c)\n", "type": "function"}, {"name": "depart_caption", "is_method": true, "class_name": "TexinfoTranslator", "parameters": ["self", "node"], "calls": ["isinstance", "self.body.append", "isinstance", "node.parent.get"], "code_location": {"file": "texinfo.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/writers", "start_line": 1219, "end_line": 1224}, "code_snippet": "    def depart_caption(self, node: Element) -> None:\n        if isinstance(node.parent, nodes.figure) or (\n            isinstance(node.parent, nodes.container)\n            and node.parent.get('literal_block')\n        ):\n            self.body.append('}\\n')\n", "type": "function"}], "retrieved_count": 10, "cost_time": 1.1946115493774414}
{"question": "Why does the equality comparison method in the parenthesized expression node class return the special sentinel value instead of the boolean false value when comparing with incompatible types?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"name": "__eq__", "is_method": true, "class_name": "ASTParenExpr", "parameters": ["self", "other"], "calls": ["isinstance"], "code_location": {"file": "_ast.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/domains/cpp", "start_line": 663, "end_line": 666}, "code_snippet": "    def __eq__(self, other: object) -> bool:\n        if not isinstance(other, ASTParenExpr):\n            return NotImplemented\n        return self.expr == other.expr\n", "type": "function"}, {"name": "__eq__", "is_method": true, "class_name": "ASTParenExpr", "parameters": ["self", "other"], "calls": ["isinstance"], "code_location": {"file": "_ast.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/domains/c", "start_line": 363, "end_line": 366}, "code_snippet": "    def __eq__(self, other: object) -> bool:\n        if not isinstance(other, ASTParenExpr):\n            return NotImplemented\n        return self.expr == other.expr\n", "type": "function"}, {"name": "ASTParenExpr", "docstring": "", "methods": [], "attributes": [], "code_location": {"file": "_ast.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/domains/cpp", "start_line": 659, "end_line": 682}, "type": "class"}, {"name": "ASTParenExpr", "docstring": "", "methods": ["__init__", "__eq__", "__hash__", "_stringify", "get_id", "describe_signature", "__init__", "__eq__", "__hash__", "_stringify", "get_id", "describe_signature"], "attributes": [], "code_location": {"file": "_ast.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/domains/c", "start_line": 359, "end_line": 382}, "type": "class"}, {"name": "parse_compare", "is_method": true, "class_name": "BooleanParser", "parameters": ["self"], "calls": ["next", "jinja2.nodes.Const", "next", "self.parse_expression", "self.stream.expect", "self.fail", "jinja2.nodes.Const", "jinja2.nodes.Const", "jinja2.nodes.Name"], "code_location": {"file": "tags.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/util", "start_line": 22, "end_line": 41}, "code_snippet": "    def parse_compare(self) -> jinja2.nodes.Expr:\n        node: jinja2.nodes.Expr\n        token = self.stream.current\n        if token.type == 'name':\n            if token.value in {'true', 'True'}:\n                node = jinja2.nodes.Const(True, lineno=token.lineno)\n            elif token.value in {'false', 'False'}:\n                node = jinja2.nodes.Const(False, lineno=token.lineno)\n            elif token.value in {'none', 'None'}:\n                node = jinja2.nodes.Const(None, lineno=token.lineno)\n            else:\n                node = jinja2.nodes.Name(token.value, 'load', lineno=token.lineno)\n            next(self.stream)\n        elif token.type == 'lparen':\n            next(self.stream)\n            node = self.parse_expression()\n            self.stream.expect('rparen')\n        else:\n            self.fail(f\"unexpected token '{token}'\", token.lineno)\n        return node\n", "type": "function"}, {"name": "__eq__", "is_method": true, "class_name": "ASTParenExprList", "parameters": ["self", "other"], "calls": ["isinstance"], "code_location": {"file": "_ast.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/domains/cpp", "start_line": 3290, "end_line": 3293}, "code_snippet": "    def __eq__(self, other: object) -> bool:\n        if not isinstance(other, ASTParenExprList):\n            return NotImplemented\n        return self.exprs == other.exprs\n", "type": "function"}, {"name": "__eq__", "is_method": true, "class_name": "ASTParenExprList", "parameters": ["self", "other"], "calls": ["isinstance"], "code_location": {"file": "_ast.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/domains/c", "start_line": 1448, "end_line": 1451}, "code_snippet": "    def __eq__(self, other: object) -> bool:\n        if not isinstance(other, ASTParenExprList):\n            return NotImplemented\n        return self.exprs == other.exprs\n", "type": "function"}, {"name": "__eq__", "is_method": true, "class_name": "ASTConditionalExpr", "parameters": ["self", "other"], "calls": ["isinstance"], "code_location": {"file": "_ast.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/domains/cpp", "start_line": 1362, "end_line": 1369}, "code_snippet": "    def __eq__(self, other: object) -> bool:\n        if not isinstance(other, ASTConditionalExpr):\n            return NotImplemented\n        return (\n            self.ifExpr == other.ifExpr\n            and self.thenExpr == other.thenExpr\n            and self.elseExpr == other.elseExpr\n        )\n", "type": "function"}, {"name": "__eq__", "is_method": true, "class_name": "ASTFallbackExpr", "parameters": ["self", "other"], "calls": ["isinstance"], "code_location": {"file": "_ast.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/domains/cpp", "start_line": 1546, "end_line": 1549}, "code_snippet": "    def __eq__(self, other: object) -> bool:\n        if not isinstance(other, ASTFallbackExpr):\n            return NotImplemented\n        return self.expr == other.expr\n", "type": "function"}, {"name": "__eq__", "is_method": true, "class_name": "ASTFallbackExpr", "parameters": ["self", "other"], "calls": ["isinstance"], "code_location": {"file": "_ast.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/domains/c", "start_line": 732, "end_line": 735}, "code_snippet": "    def __eq__(self, other: object) -> bool:\n        if not isinstance(other, ASTFallbackExpr):\n            return NotImplemented\n        return self.expr == other.expr\n", "type": "function"}], "retrieved_count": 10, "cost_time": 1.2222630977630615}
{"question": "Why would repeated calls to the reStructuredText parsing function that performs full document transformation cycles and multiple recursive tree validation assertions impact test execution performance when scaling across hundreds of similar domain parsing scenarios?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"name": "_doctree_for_test", "is_method": false, "class_name": null, "parameters": ["app", "env", "docname"], "calls": ["env.doc2path", "filename.read_text", "env.prepare_settings", "registry.create_source_parser", "_parse_str_to_doctree", "registry.get_transforms"], "code_location": {"file": "test_directive_object_description.py", "path": "/data3/pwh/swebench-repos/sphinx/tests/test_directives", "start_line": 21, "end_line": 39}, "code_snippet": "def _doctree_for_test(\n    app: Sphinx, env: BuildEnvironment, docname: str\n) -> nodes.document:\n    config = app.config\n    registry = app.registry\n\n    filename = env.doc2path(docname)\n    content = filename.read_text(encoding='utf-8')\n\n    env.prepare_settings(docname)\n    parser = registry.create_source_parser('restructuredtext', config=config, env=env)\n    return _parse_str_to_doctree(\n        content,\n        filename=filename,\n        default_settings={'env': env},\n        env=env,\n        parser=parser,\n        transforms=registry.get_transforms(),\n    )\n", "type": "function"}, {"name": "test_toctree_twice", "is_method": false, "class_name": null, "parameters": ["app"], "calls": ["pytest.mark.sphinx", "app.env.find_files", "restructuredtext.parse", "assert_node", "assert_node"], "code_location": {"file": "test_directive_other.py", "path": "/data3/pwh/swebench-repos/sphinx/tests/test_directives", "start_line": 152, "end_line": 162}, "code_snippet": "def test_toctree_twice(app):\n    text = '.. toctree::\\n\\n   foo\\n   foo\\n'\n\n    app.env.find_files(app.config, app.builder)\n    doctree = restructuredtext.parse(app, text, 'index')\n    assert_node(doctree, [nodes.document, nodes.compound, addnodes.toctree])\n    assert_node(\n        doctree[0][0],\n        entries=[(None, 'foo'), (None, 'foo')],\n        includefiles=['foo', 'foo'],\n    )\n", "type": "function"}, {"name": "test_domain_objects", "is_method": false, "class_name": null, "parameters": ["app"], "calls": ["pytest.mark.sphinx", "app.build", "assert_node", "assert_node", "assert_node", "assert_node", "set"], "code_location": {"file": "test_environment_toctree.py", "path": "/data3/pwh/swebench-repos/sphinx/tests/test_environment", "start_line": 293, "end_line": 352}, "code_snippet": "def test_domain_objects(app):\n    app.build()\n\n    assert app.env.toc_num_entries['index'] == 0\n    assert app.env.toc_num_entries['domains'] == 9\n    assert app.env.toctree_includes['index'] == ['domains', 'document_scoping']\n    assert 'index' in app.env.files_to_rebuild['domains']\n    assert app.env.glob_toctrees == set()\n    assert app.env.numbered_toctrees == {'index'}\n\n    # tocs\n    toctree = app.env.tocs['domains']\n    assert_node(\n        toctree,\n        [\n            bullet_list,\n            list_item,\n            (\n                compact_paragraph,  # [0][0]\n                [\n                    bullet_list,  # [0][1]\n                    (\n                        list_item,  # [0][1][0]\n                        [\n                            list_item,  # [0][1][1]\n                            (\n                                compact_paragraph,  # [0][1][1][0]\n                                [\n                                    bullet_list,  # [0][1][1][1]\n                                    (\n                                        list_item,  # [0][1][1][1][0]\n                                        list_item,\n                                        list_item,\n                                        list_item,  # [0][1][1][1][3]\n                                    ),\n                                ],\n                            ),\n                        ],\n                        list_item,\n                        list_item,  # [0][1][1]\n                    ),\n                ],\n            ),\n        ],\n    )\n\n    assert_node(toctree[0][0], [compact_paragraph, reference, 'test-domain-objects'])\n\n    assert_node(\n        toctree[0][1][0],\n        [list_item, ([compact_paragraph, reference, literal, 'world()'])],\n    )\n\n    assert_node(\n        toctree[0][1][1][1][3],\n        [\n            list_item,\n            ([compact_paragraph, reference, literal, 'HelloWorldPrinter.print()']),\n        ],\n    )\n", "type": "function"}, {"name": "test_rst_directive", "is_method": false, "class_name": null, "parameters": ["app"], "calls": ["pytest.mark.sphinx", "restructuredtext.parse", "assert_node", "assert_node", "assert_node", "restructuredtext.parse", "assert_node", "assert_node", "assert_node"], "code_location": {"file": "test_domain_rst.py", "path": "/data3/pwh/swebench-repos/sphinx/tests/test_domains", "start_line": 41, "end_line": 86}, "code_snippet": "def test_rst_directive(app: SphinxTestApp) -> None:\n    # bare\n    text = '.. rst:directive:: toctree'\n    doctree = restructuredtext.parse(app, text)\n    assert_node(\n        doctree,\n        (\n            addnodes.index,\n            [desc, ([desc_signature, desc_name, '.. toctree::'], [desc_content, ()])],\n        ),\n    )\n    assert_node(\n        doctree[0],\n        entries=[('single', 'toctree (directive)', 'directive-toctree', '', None)],\n    )\n    assert_node(\n        doctree[1],\n        addnodes.desc,\n        desctype='directive',\n        domain='rst',\n        objtype='directive',\n        no_index=False,\n    )\n\n    # decorated\n    text = '.. rst:directive:: .. toctree::'\n    doctree = restructuredtext.parse(app, text)\n    assert_node(\n        doctree,\n        (\n            addnodes.index,\n            [desc, ([desc_signature, desc_name, '.. toctree::'], [desc_content, ()])],\n        ),\n    )\n    assert_node(\n        doctree[0],\n        entries=[('single', 'toctree (directive)', 'directive-toctree', '', None)],\n    )\n    assert_node(\n        doctree[1],\n        addnodes.desc,\n        desctype='directive',\n        domain='rst',\n        objtype='directive',\n        no_index=False,\n    )\n", "type": "function"}, {"name": "test_process_doc", "is_method": false, "class_name": null, "parameters": ["app"], "calls": ["pytest.mark.sphinx", "pytest.mark.test_params", "app.build", "assert_node", "assert_node", "assert_node", "assert_node", "assert_node", "assert_node", "assert_node", "assert_node", "assert_node", "assert_node", "assert_node", "assert_node", "assert_node", "assert_node", "assert_node", "set", "len"], "code_location": {"file": "test_environment_toctree.py", "path": "/data3/pwh/swebench-repos/sphinx/tests/test_environment", "start_line": 29, "end_line": 181}, "code_snippet": "def test_process_doc(app):\n    app.build()\n    # tocs\n    toctree = app.env.tocs['index']\n    assert_node(\n        toctree,\n        [\n            bullet_list,\n            (\n                [\n                    list_item,  # [0]\n                    (\n                        compact_paragraph,  # [0][0]\n                        [\n                            bullet_list,  # [0][1]\n                            (\n                                addnodes.toctree,  # [0][1][0]\n                                only,  # [0][1][1]\n                                list_item,  # [0][1][2]\n                            ),\n                        ],\n                    ),\n                ],\n                [\n                    list_item,  # [1]\n                    (\n                        compact_paragraph,  # [1][0]\n                        [\n                            bullet_list,  # [1][1]\n                            (\n                                addnodes.toctree,  # [1][1][0]\n                                addnodes.toctree,  # [1][1][1]\n                            ),\n                        ],\n                    ),\n                ],\n                list_item,  # [2]\n            ),\n        ],\n    )\n\n    assert_node(\n        toctree[0][0],\n        [compact_paragraph, reference, 'Welcome to Sphinx Testss documentation!'],\n    )\n    assert_node(toctree[0][0][0], reference, anchorname='')\n    assert_node(\n        toctree[0][1][0],\n        addnodes.toctree,\n        caption='Table of Contents',\n        glob=False,\n        hidden=False,\n        titlesonly=False,\n        maxdepth=2,\n        numbered=999,\n        entries=[\n            (None, 'foo'),\n            (None, 'bar'),\n            (None, 'https://sphinx-doc.org/'),\n            (None, 'self'),\n        ],\n        includefiles=['foo', 'bar'],\n    )\n\n    # only branch\n    assert_node(toctree[0][1][1], addnodes.only, expr='html')\n    assert_node(\n        toctree[0][1][1],\n        [\n            only,\n            list_item,\n            (\n                [compact_paragraph, reference, 'Section for HTML'],\n                [bullet_list, addnodes.toctree],\n            ),\n        ],\n    )\n    assert_node(toctree[0][1][1][0][0][0], reference, anchorname='#section-for-html')\n    assert_node(\n        toctree[0][1][1][0][1][0],\n        addnodes.toctree,\n        caption=None,\n        glob=False,\n        hidden=False,\n        entries=[(None, 'baz')],\n        includefiles=['baz'],\n        titlesonly=False,\n        maxdepth=-1,\n        numbered=0,\n    )\n    assert_node(\n        toctree[0][1][2],\n        (\n            [compact_paragraph, reference, 'subsection'],\n            [bullet_list, list_item, compact_paragraph, reference, 'subsubsection'],\n        ),\n    )\n\n    assert_node(\n        toctree[1][0],\n        [\n            compact_paragraph,\n            reference,\n            'Test for combination of globaltoc.html and hidden toctree',\n        ],\n    )\n    assert_node(\n        toctree[1][0][0],\n        reference,\n        anchorname='#test-for-combination-of-globaltoc-html-and-hidden-toctree',\n    )\n    assert_node(\n        toctree[1][1][0],\n        addnodes.toctree,\n        caption=None,\n        entries=[],\n        glob=False,\n        hidden=False,\n        titlesonly=False,\n        maxdepth=-1,\n        numbered=0,\n    )\n    assert_node(\n        toctree[1][1][1],\n        addnodes.toctree,\n        caption=None,\n        glob=False,\n        hidden=True,\n        titlesonly=False,\n        maxdepth=-1,\n        numbered=0,\n        entries=[\n            ('Latest reference', 'https://sphinx-doc.org/latest/'),\n            ('Python', 'https://python.org/'),\n        ],\n    )\n\n    assert_node(toctree[2][0], [compact_paragraph, reference, 'Indices and tables'])\n\n    # other collections\n    assert app.env.toc_num_entries['index'] == 6\n    assert app.env.toctree_includes['index'] == ['foo', 'bar', 'baz']\n    assert app.env.files_to_rebuild['foo'] == {'index'}\n    assert app.env.files_to_rebuild['bar'] == {'index'}\n    assert app.env.files_to_rebuild['baz'] == {'index'}\n    assert app.env.glob_toctrees == set()\n    assert app.env.numbered_toctrees == {'index'}\n\n    # qux has no section title\n    assert len(app.env.tocs['qux']) == 0\n    assert_node(app.env.tocs['qux'], nodes.bullet_list)\n    assert app.env.toc_num_entries['qux'] == 0\n    assert 'qux' not in app.env.toctree_includes\n", "type": "function"}, {"name": "test_sphinx_directive_parse_text_to_nodes", "is_method": false, "class_name": null, "parameters": [], "calls": ["make_directive", "directive.parse_text_to_nodes", "isinstance", "isinstance", "isinstance", "len", "len", "astext", "astext", "SimpleNamespace"], "code_location": {"file": "test_util_docutils_sphinx_directive.py", "path": "/data3/pwh/swebench-repos/sphinx/tests/test_util", "start_line": 124, "end_line": 136}, "code_snippet": "def test_sphinx_directive_parse_text_to_nodes() -> None:\n    directive = make_directive(env=SimpleNamespace())\n    content = 'spam\\n====\\n\\nEggs! *Lobster thermidor.*'\n\n    parsed = directive.parse_text_to_nodes(content, allow_section_headings=True)\n    assert len(parsed) == 1\n    node = parsed[0]\n    assert isinstance(node, nodes.section)\n    assert len(node.children) == 2\n    assert isinstance(node.children[0], nodes.title)\n    assert node.children[0].astext() == 'spam'\n    assert isinstance(node.children[1], nodes.paragraph)\n    assert node.children[1].astext() == 'Eggs! Lobster thermidor.'\n", "type": "function"}, {"name": "test_toctree", "is_method": false, "class_name": null, "parameters": ["app"], "calls": ["pytest.mark.sphinx", "app.env.find_files", "restructuredtext.parse", "assert_node", "assert_node"], "code_location": {"file": "test_directive_other.py", "path": "/data3/pwh/swebench-repos/sphinx/tests/test_directives", "start_line": 20, "end_line": 30}, "code_snippet": "def test_toctree(app):\n    text = '.. toctree::\\n\\n   foo\\n   bar/index\\n   baz\\n'\n\n    app.env.find_files(app.config, app.builder)\n    doctree = restructuredtext.parse(app, text, 'index')\n    assert_node(doctree, [nodes.document, nodes.compound, addnodes.toctree])\n    assert_node(\n        doctree[0][0],\n        entries=[(None, 'foo'), (None, 'bar/index'), (None, 'baz')],\n        includefiles=['foo', 'bar/index', 'baz'],\n    )\n", "type": "function"}, {"name": "test_docutils_output", "is_method": false, "class_name": null, "parameters": ["app", "cached_etree_parse", "fname", "path", "check"], "calls": ["pytest.mark.parametrize", "pytest.mark.sphinx", "pytest.mark.test_params", "app.build", "check_xpath", "cached_etree_parse"], "code_location": {"file": "test_build_html.py", "path": "/data3/pwh/swebench-repos/sphinx/tests/test_builders", "start_line": 142, "end_line": 144}, "code_snippet": "def test_docutils_output(app, cached_etree_parse, fname, path, check):\n    app.build()\n    check_xpath(cached_etree_parse(app.outdir / fname), fname, path, check)\n", "type": "function"}, {"name": "test_rst_directive_with_argument", "is_method": false, "class_name": null, "parameters": ["app"], "calls": ["pytest.mark.sphinx", "restructuredtext.parse", "assert_node", "assert_node", "assert_node"], "code_location": {"file": "test_domain_rst.py", "path": "/data3/pwh/swebench-repos/sphinx/tests/test_domains", "start_line": 90, "end_line": 120}, "code_snippet": "def test_rst_directive_with_argument(app: SphinxTestApp) -> None:\n    text = '.. rst:directive:: .. toctree:: foo bar baz'\n    doctree = restructuredtext.parse(app, text)\n    assert_node(\n        doctree,\n        (\n            addnodes.index,\n            [\n                desc,\n                (\n                    [\n                        desc_signature,\n                        ([desc_name, '.. toctree::'], [desc_addname, ' foo bar baz']),\n                    ],\n                    [desc_content, ()],\n                ),\n            ],\n        ),\n    )\n    assert_node(\n        doctree[0],\n        entries=[('single', 'toctree (directive)', 'directive-toctree', '', None)],\n    )\n    assert_node(\n        doctree[1],\n        addnodes.desc,\n        desctype='directive',\n        domain='rst',\n        objtype='directive',\n        no_index=False,\n    )\n", "type": "function"}, {"name": "test_document_toc", "is_method": false, "class_name": null, "parameters": ["app"], "calls": ["pytest.mark.sphinx", "pytest.mark.test_params", "app.build", "document_toc", "assert_node", "assert_node", "assert_node", "assert_node", "assert_node"], "code_location": {"file": "test_environment_toctree.py", "path": "/data3/pwh/swebench-repos/sphinx/tests/test_environment", "start_line": 475, "end_line": 527}, "code_snippet": "def test_document_toc(app):\n    app.build()\n    toctree = document_toc(app.env, 'index', app.tags)\n\n    assert_node(\n        toctree,\n        [\n            bullet_list,\n            (\n                [\n                    list_item,\n                    (\n                        compact_paragraph,  # [0][0]\n                        [\n                            bullet_list,\n                            (\n                                addnodes.toctree,  # [0][1][0]\n                                list_item,  # [0][1][1]\n                            ),\n                        ],\n                    ),\n                ],\n                [\n                    list_item,\n                    (\n                        compact_paragraph,  # [1][0]\n                        [bullet_list, (addnodes.toctree, addnodes.toctree)],\n                    ),\n                ],\n                [list_item, compact_paragraph],  # [2][0]\n            ),\n        ],\n    )\n    assert_node(\n        toctree[0][0],\n        [compact_paragraph, reference, 'Welcome to Sphinx Testss documentation!'],\n    )\n    assert_node(\n        toctree[0][1][1],\n        (\n            [compact_paragraph, reference, 'subsection'],\n            [bullet_list, list_item, compact_paragraph, reference, 'subsubsection'],\n        ),\n    )\n    assert_node(\n        toctree[1][0],\n        [\n            compact_paragraph,\n            reference,\n            'Test for combination of globaltoc.html and hidden toctree',\n        ],\n    )\n    assert_node(toctree[2][0], [compact_paragraph, reference, 'Indices and tables'])\n", "type": "function"}], "retrieved_count": 10, "cost_time": 1.2219741344451904}
{"question": "Why does the exception raised when character literal decoding produces multiple characters integrate with the parser's error handling to distinguish valid single-character from invalid multi-character literals during AST construction?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"name": "ASTCharLiteral", "docstring": "", "methods": ["__init__", "__eq__", "__hash__", "_stringify", "describe_signature", "__init__", "__eq__", "__hash__", "_stringify", "get_id", "describe_signature"], "attributes": [], "code_location": {"file": "_ast.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/domains/c", "start_line": 281, "end_line": 309}, "type": "class"}, {"name": "ASTCharLiteral", "docstring": "", "methods": [], "attributes": [], "code_location": {"file": "_ast.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/domains/cpp", "start_line": 491, "end_line": 527}, "type": "class"}, {"name": "_parse_literal", "is_method": true, "class_name": "DefinitionParser", "parameters": ["self"], "calls": ["self.skip_ws", "self.skip_word", "self.skip_word", "self.match", "self._parse_string", "self.match", "ASTBooleanLiteral", "ASTBooleanLiteral", "self.match", "ASTNumberLiteral", "self.match", "ASTStringLiteral", "self.last_match.group", "self.last_match.group", "self.match", "ASTNumberLiteral", "ASTCharLiteral", "self.fail", "self.fail"], "code_location": {"file": "_parser.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/domains/c", "start_line": 122, "end_line": 166}, "code_snippet": "    def _parse_literal(self) -> ASTLiteral | None:\n        # -> integer-literal\n        #  | character-literal\n        #  | floating-literal\n        #  | string-literal\n        #  | boolean-literal -> \"false\" | \"true\"\n        self.skip_ws()\n        if self.skip_word('true'):\n            return ASTBooleanLiteral(True)\n        if self.skip_word('false'):\n            return ASTBooleanLiteral(False)\n        pos = self.pos\n        if self.match(float_literal_re):\n            self.match(float_literal_suffix_re)\n            return ASTNumberLiteral(self.definition[pos : self.pos])\n        for regex in (\n            binary_literal_re,\n            hex_literal_re,\n            integer_literal_re,\n            octal_literal_re,\n        ):\n            if self.match(regex):\n                self.match(integers_literal_suffix_re)\n                return ASTNumberLiteral(self.definition[pos : self.pos])\n\n        string = self._parse_string()\n        if string is not None:\n            return ASTStringLiteral(string)\n\n        # character-literal\n        if self.match(char_literal_re):\n            prefix = self.last_match.group(1)  # may be None when no prefix\n            data = self.last_match.group(2)\n            try:\n                return ASTCharLiteral(prefix, data)\n            except UnicodeDecodeError as e:\n                self.fail(\n                    'Can not handle character literal. Internal error was: %s' % e\n                )\n            except UnsupportedMultiCharacterCharLiteral:\n                self.fail(\n                    'Can not handle character literal'\n                    ' resulting in multiple decoded characters.'\n                )\n        return None\n", "type": "function"}, {"name": "_parse_literal", "is_method": true, "class_name": "DefinitionParser", "parameters": ["self"], "calls": ["self.skip_ws", "self.skip_word", "self.skip_word", "self.skip_word", "self.match", "self._parse_string", "self.match", "ASTIdentifier", "ASTUserDefinedLiteral", "ASTPointerLiteral", "ASTBooleanLiteral", "ASTBooleanLiteral", "self.match", "ASTNumberLiteral", "self.match", "_udl", "self.last_match.group", "self.last_match.group", "_udl", "self.match", "_udl", "self.match", "ASTNumberLiteral", "ASTStringLiteral", "ASTCharLiteral", "_udl", "self.fail", "self.fail"], "code_location": {"file": "_parser.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/domains/cpp", "start_line": 171, "end_line": 237}, "code_snippet": "    def _parse_literal(self) -> ASTLiteral:\n        # -> integer-literal\n        #  | character-literal\n        #  | floating-literal\n        #  | string-literal\n        #  | boolean-literal -> \"false\" | \"true\"\n        #  | pointer-literal -> \"nullptr\"\n        #  | user-defined-literal\n\n        def _udl(literal: ASTLiteral) -> ASTLiteral:\n            if not self.match(udl_identifier_re):\n                return literal\n            # hmm, should we care if it's a keyword?\n            # it looks like GCC does not disallow keywords\n            ident = ASTIdentifier(self.matched_text)\n            return ASTUserDefinedLiteral(literal, ident)\n\n        self.skip_ws()\n        if self.skip_word('nullptr'):\n            return ASTPointerLiteral()\n        if self.skip_word('true'):\n            return ASTBooleanLiteral(True)\n        if self.skip_word('false'):\n            return ASTBooleanLiteral(False)\n        pos = self.pos\n        if self.match(float_literal_re):\n            has_suffix = self.match(float_literal_suffix_re)\n            float_lit = ASTNumberLiteral(self.definition[pos : self.pos])\n            if has_suffix:\n                return float_lit\n            else:\n                return _udl(float_lit)\n        for regex in (\n            binary_literal_re,\n            hex_literal_re,\n            integer_literal_re,\n            octal_literal_re,\n        ):\n            if self.match(regex):\n                has_suffix = self.match(integers_literal_suffix_re)\n                int_lit = ASTNumberLiteral(self.definition[pos : self.pos])\n                if has_suffix:\n                    return int_lit\n                else:\n                    return _udl(int_lit)\n\n        string = self._parse_string()\n        if string is not None:\n            return _udl(ASTStringLiteral(string))\n\n        # character-literal\n        if self.match(char_literal_re):\n            prefix = self.last_match.group(1)  # may be None when no prefix\n            data = self.last_match.group(2)\n            try:\n                char_lit = ASTCharLiteral(prefix, data)\n            except UnicodeDecodeError as e:\n                self.fail(\n                    'Can not handle character literal. Internal error was: %s' % e\n                )\n            except UnsupportedMultiCharacterCharLiteral:\n                self.fail(\n                    'Can not handle character literal'\n                    ' resulting in multiple decoded characters.'\n                )\n            return _udl(char_lit)\n        return None\n", "type": "function"}, {"name": "ASTLiteral", "docstring": "", "methods": [], "attributes": [], "code_location": {"file": "_ast.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/domains/cpp", "start_line": 388, "end_line": 389}, "type": "class"}, {"name": "ASTLiteral", "docstring": "", "methods": [], "attributes": [], "code_location": {"file": "_ast.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/domains/c", "start_line": 230, "end_line": 231}, "type": "class"}, {"name": "desc_sig_literal_char", "docstring": "Node for a character literal in a signature.", "methods": [], "attributes": ["classes"], "code_location": {"file": "addnodes.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx", "start_line": 392, "end_line": 395}, "type": "class"}, {"name": "ASTStringLiteral", "docstring": "", "methods": [], "attributes": [], "code_location": {"file": "_ast.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/domains/cpp", "start_line": 466, "end_line": 488}, "type": "class"}, {"name": "ASTStringLiteral", "docstring": "", "methods": ["__init__", "__eq__", "__hash__", "_stringify", "describe_signature", "__init__", "__eq__", "__hash__", "_stringify", "get_id", "describe_signature"], "attributes": [], "code_location": {"file": "_ast.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/domains/c", "start_line": 312, "end_line": 331}, "type": "class"}, {"name": "ASTUserDefinedLiteral", "docstring": "", "methods": ["__init__", "__eq__", "__hash__", "_stringify", "get_id", "describe_signature"], "attributes": [], "code_location": {"file": "_ast.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/domains/cpp", "start_line": 530, "end_line": 554}, "type": "class"}], "retrieved_count": 10, "cost_time": 1.227602481842041}
{"question": "Why do separate recursive directory traversals for source and compiled translation files in the catalog compilation verification test impact performance with thousands of locale catalog files?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"name": "test_compile_all_catalogs", "is_method": false, "class_name": null, "parameters": ["app"], "calls": ["pytest.mark.usefixtures", "pytest.mark.test_params", "pytest.mark.sphinx", "app.builder.compile_all_catalogs", "set", "x.with_suffix", "catalog_dir.rglob", "catalog_dir.rglob"], "code_location": {"file": "test_catalogs.py", "path": "/data3/pwh/swebench-repos/sphinx/tests/test_intl", "start_line": 47, "end_line": 55}, "code_snippet": "def test_compile_all_catalogs(app: SphinxTestApp) -> None:\n    app.builder.compile_all_catalogs()\n\n    locale_dir = app.srcdir / 'locale'\n    catalog_dir = locale_dir / app.config.language / 'LC_MESSAGES'\n    expect = {x.with_suffix('.mo') for x in catalog_dir.rglob('*.po')}\n    actual = set(catalog_dir.rglob('*.mo'))\n    assert actual  # not empty\n    assert actual == expect\n", "type": "function"}, {"name": "test_compile_update_catalogs", "is_method": false, "class_name": null, "parameters": ["app"], "calls": ["pytest.mark.usefixtures", "pytest.mark.test_params", "pytest.mark.sphinx", "app.builder.compile_update_catalogs", "set", "x.with_suffix", "catalog_dir.rglob", "set", "catalog_dir.rglob"], "code_location": {"file": "test_catalogs.py", "path": "/data3/pwh/swebench-repos/sphinx/tests/test_intl", "start_line": 86, "end_line": 94}, "code_snippet": "def test_compile_update_catalogs(app: SphinxTestApp) -> None:\n    app.builder.compile_update_catalogs()\n\n    locale_dir = app.srcdir / 'locale'\n    catalog_dir = locale_dir / app.config.language / 'LC_MESSAGES'\n    expect = {x.with_suffix('.mo') for x in set(catalog_dir.rglob('*.po'))}\n    actual = set(catalog_dir.rglob('*.mo'))\n    assert actual  # not empty\n    assert actual == expect\n", "type": "function"}, {"name": "test_compile_specific_catalogs", "is_method": false, "class_name": null, "parameters": ["app"], "calls": ["pytest.mark.usefixtures", "pytest.mark.test_params", "pytest.mark.sphinx", "set", "app.builder.compile_specific_catalogs", "catalog_dir.rglob", "str", "x.relative_to", "catalog_dir.rglob"], "code_location": {"file": "test_catalogs.py", "path": "/data3/pwh/swebench-repos/sphinx/tests/test_intl", "start_line": 65, "end_line": 76}, "code_snippet": "def test_compile_specific_catalogs(app: SphinxTestApp) -> None:\n    locale_dir = app.srcdir / 'locale'\n    catalog_dir = locale_dir / app.config.language / 'LC_MESSAGES'\n\n    actual_on_boot = set(catalog_dir.rglob('*.mo'))  # sphinx.mo might be included\n    app.builder.compile_specific_catalogs([app.srcdir / 'admonitions.txt'])\n    actual = {\n        str(x.relative_to(catalog_dir))\n        for x in catalog_dir.rglob('*.mo')\n        if x not in actual_on_boot\n    }\n    assert actual == {'admonitions.mo'}\n", "type": "function"}, {"name": "test_CatalogRepository", "is_method": false, "class_name": null, "parameters": ["tmp_path"], "calls": ["i18n.CatalogRepository", "all", "i18n.CatalogRepository", "i18n.CatalogRepository", "i18n.CatalogRepository", "i18n.CatalogRepository", "i18n.CatalogRepository", "po_file.parent.mkdir", "po_file.write_text", "list", "sorted", "sorted", "sorted", "sorted", "sorted", "sorted", "isinstance"], "code_location": {"file": "test_util_i18n.py", "path": "/data3/pwh/swebench-repos/sphinx/tests/test_util", "start_line": 166, "end_line": 215}, "code_snippet": "def test_CatalogRepository(tmp_path):\n    for po_file in (\n        (tmp_path / 'loc1' / 'xx' / 'LC_MESSAGES' / 'test1.po'),\n        (tmp_path / 'loc1' / 'xx' / 'LC_MESSAGES' / 'test2.po'),\n        (tmp_path / 'loc1' / 'xx' / 'LC_MESSAGES' / 'sub' / 'test3.po'),\n        (tmp_path / 'loc1' / 'xx' / 'LC_MESSAGES' / 'sub' / 'test4.po'),\n        (tmp_path / 'loc1' / 'xx' / 'LC_MESSAGES' / '.dotdir' / 'test5.po'),\n        (tmp_path / 'loc1' / 'yy' / 'LC_MESSAGES' / 'test6.po'),\n        (tmp_path / 'loc2' / 'xx' / 'LC_MESSAGES' / 'test1.po'),\n        (tmp_path / 'loc2' / 'xx' / 'LC_MESSAGES' / 'test7.po'),\n        (tmp_path / 'loc1' / 'xx' / 'LC_MESSAGES' / '.dotdir2' / 'test8.po'),\n    ):\n        po_file.parent.mkdir(parents=True, exist_ok=True)\n        po_file.write_text('#', encoding='utf8')\n\n    # for language xx\n    repo = i18n.CatalogRepository(tmp_path, ['loc1', 'loc2'], 'xx', 'utf-8')\n    assert list(repo.locale_dirs) == [\n        tmp_path / 'loc1',\n        tmp_path / 'loc2',\n    ]\n    assert all(isinstance(c, i18n.CatalogInfo) for c in repo.catalogs)\n    assert sorted(c.domain for c in repo.catalogs) == [\n        'sub/test3',\n        'sub/test4',\n        'test1',\n        'test1',\n        'test2',\n        'test7',\n    ]\n\n    # for language yy\n    repo = i18n.CatalogRepository(tmp_path, ['loc1', 'loc2'], 'yy', 'utf-8')\n    assert sorted(c.domain for c in repo.catalogs) == ['test6']\n\n    # unknown languages\n    repo = i18n.CatalogRepository(tmp_path, ['loc1', 'loc2'], 'zz', 'utf-8')\n    assert sorted(c.domain for c in repo.catalogs) == []\n\n    # no languages\n    repo = i18n.CatalogRepository(tmp_path, ['loc1', 'loc2'], '', 'utf-8')\n    assert sorted(c.domain for c in repo.catalogs) == []\n\n    # unknown locale_dirs\n    repo = i18n.CatalogRepository(tmp_path, ['loc3'], '', 'utf-8')\n    assert sorted(c.domain for c in repo.catalogs) == []\n\n    # no locale_dirs\n    repo = i18n.CatalogRepository(tmp_path, [], '', 'utf-8')\n    assert sorted(c.domain for c in repo.catalogs) == []\n", "type": "function"}, {"name": "compile_all_catalogs", "is_method": true, "class_name": "Builder", "parameters": ["self"], "calls": ["CatalogRepository", "self.compile_catalogs", "__", "len", "set", "list"], "code_location": {"file": "__init__.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/builders", "start_line": 274, "end_line": 282}, "code_snippet": "    def compile_all_catalogs(self) -> None:\n        repo = CatalogRepository(\n            self.srcdir,\n            self.config.locale_dirs,\n            self.config.language,\n            self.config.source_encoding,\n        )\n        message = __('all of %d po files') % len(list(repo.catalogs))\n        self.compile_catalogs(set(repo.catalogs), message)\n", "type": "function"}, {"name": "compile_update_catalogs", "is_method": true, "class_name": "Builder", "parameters": ["self"], "calls": ["CatalogRepository", "self.compile_catalogs", "__", "len", "c.is_outdated"], "code_location": {"file": "__init__.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/builders", "start_line": 307, "end_line": 316}, "code_snippet": "    def compile_update_catalogs(self) -> None:\n        repo = CatalogRepository(\n            self.srcdir,\n            self.config.locale_dirs,\n            self.config.language,\n            self.config.source_encoding,\n        )\n        catalogs = {c for c in repo.catalogs if c.is_outdated()}\n        message = __('targets for %d po files that are out of date') % len(catalogs)\n        self.compile_catalogs(catalogs, message)\n", "type": "function"}, {"name": "test_catalog_outdated", "is_method": false, "class_name": null, "parameters": ["tmp_path"], "calls": ["write_text", "i18n.CatalogInfo", "cat.is_outdated", "mo_file.write_text", "os.utime", "cat.is_outdated", "cat.is_outdated", "mo_file.stat"], "code_location": {"file": "test_util_i18n.py", "path": "/data3/pwh/swebench-repos/sphinx/tests/test_util", "start_line": 37, "end_line": 48}, "code_snippet": "def test_catalog_outdated(tmp_path):\n    (tmp_path / 'test.po').write_text('#', encoding='utf8')\n    cat = i18n.CatalogInfo(tmp_path, 'test', 'utf-8')\n    assert cat.is_outdated()  # if mo is not exist\n\n    mo_file = tmp_path / 'test.mo'\n    mo_file.write_text('#', encoding='utf8')\n    assert not cat.is_outdated()  # if mo is exist and newer than po\n\n    new_mtime = mo_file.stat().st_mtime_ns - 10_000_000_000\n    os.utime(mo_file, ns=(new_mtime, new_mtime))  # to be outdated\n    assert cat.is_outdated()  # if mo is exist and older than po\n", "type": "function"}, {"name": "pofiles", "is_method": true, "class_name": "CatalogRepository", "parameters": ["self"], "calls": ["locale_path.rglob", "abs_path.relative_to", "any", "part.startswith"], "code_location": {"file": "i18n.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/util", "start_line": 149, "end_line": 157}, "code_snippet": "    def pofiles(self) -> Iterator[tuple[_StrPath, _StrPath]]:\n        for locale_dir in self.locale_dirs:\n            locale_path = locale_dir / self.language / 'LC_MESSAGES'\n            for abs_path in locale_path.rglob('*.po'):\n                rel_path = abs_path.relative_to(locale_path)\n                # skip dot-directories\n                if any(part.startswith('.') for part in rel_path.parts[:-1]):\n                    continue\n                yield locale_path, rel_path\n", "type": "function"}, {"name": "compile_specific_catalogs", "is_method": true, "class_name": "Builder", "parameters": ["self", "specified_files"], "calls": ["set", "CatalogRepository", "self.compile_catalogs", "__", "len", "docname_to_domain", "catalog.is_outdated", "catalogs.add", "env.path2doc"], "code_location": {"file": "__init__.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/builders", "start_line": 284, "end_line": 304}, "code_snippet": "    def compile_specific_catalogs(self, specified_files: Iterable[Path]) -> None:\n        env = self.env\n        gettext_compact = self.config.gettext_compact\n\n        domains = {\n            docname_to_domain(docname, gettext_compact) if docname else None\n            for file in specified_files\n            if (docname := env.path2doc(file))\n        }\n        catalogs = set()\n        repo = CatalogRepository(\n            self.srcdir,\n            self.config.locale_dirs,\n            self.config.language,\n            self.config.source_encoding,\n        )\n        for catalog in repo.catalogs:\n            if catalog.domain in domains and catalog.is_outdated():\n                catalogs.add(catalog)\n        message = __('targets for %d po files that are specified') % len(catalogs)\n        self.compile_catalogs(catalogs, message)\n", "type": "function"}, {"name": "compile_catalogs", "is_method": true, "class_name": "Builder", "parameters": ["self", "catalogs", "message"], "calls": ["logger.info", "status_iterator", "as_posix", "__", "len", "catalog.write_mo", "bold", "Path", "__", "relpath"], "code_location": {"file": "__init__.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/builders", "start_line": 254, "end_line": 272}, "code_snippet": "    def compile_catalogs(self, catalogs: set[CatalogInfo], message: str) -> None:\n        if not self.config.gettext_auto_build:\n            return\n\n        def cat2relpath(cat: CatalogInfo, srcdir: Path = self.srcdir) -> str:\n            return Path(relpath(cat.mo_path, srcdir)).as_posix()\n\n        logger.info(bold(__('building [mo]: ')) + message)  # NoQA: G003\n        for catalog in status_iterator(\n            catalogs,\n            __('writing output... '),\n            'darkgreen',\n            len(catalogs),\n            self.config.verbosity,\n            stringify_func=cat2relpath,\n        ):\n            catalog.write_mo(\n                self.config.language, self.config.gettext_allow_fuzzy_translations\n            )\n", "type": "function"}], "retrieved_count": 10, "cost_time": 1.2338356971740723}
{"question": "Why would removing the inherited greeting method from the enum mixin class affect the method resolution order for classes depending on its documented behavior in the automated documentation test suite?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"name": "test_enum_class_with_mixin_enum_type", "is_method": false, "class_name": null, "parameters": ["app", "autodoc_enum_options"], "calls": ["pytest.mark.sphinx", "_EnumFormatter", "do_autodoc", "do_autodoc", "list", "list", "fmt.preamble_lookup", "fmt.method", "fmt.member", "fmt.preamble_lookup", "fmt.method", "fmt.method", "fmt.method", "fmt.member"], "code_location": {"file": "test_ext_autodoc.py", "path": "/data3/pwh/swebench-repos/sphinx/tests/test_extensions", "start_line": 1820, "end_line": 1840}, "code_snippet": "def test_enum_class_with_mixin_enum_type(app, autodoc_enum_options):\n    fmt = _EnumFormatter('EnumClassWithMixinEnumType')\n\n    actual = do_autodoc(app, 'class', fmt.target, autodoc_enum_options)\n    assert list(actual) == [\n        *fmt.preamble_lookup('this is enum class'),\n        # override() is overridden at the class level so it should be rendered\n        *fmt.method('override', 'overridden'),\n        # say_goodbye() and say_hello() are not rendered since they are inherited\n        *fmt.member('x', 'x', ''),\n    ]\n\n    options = autodoc_enum_options | {'inherited-members': None}\n    actual = do_autodoc(app, 'class', fmt.target, options)\n    assert list(actual) == [\n        *fmt.preamble_lookup('this is enum class'),\n        *fmt.method('override', 'overridden'),\n        *fmt.method('say_goodbye', 'inherited', 'classmethod'),\n        *fmt.method('say_hello', 'inherited'),\n        *fmt.member('x', 'x', ''),\n    ]\n", "type": "function"}, {"name": "test_enum_class_with_mixin_type", "is_method": false, "class_name": null, "parameters": ["app", "autodoc_enum_options"], "calls": ["pytest.mark.sphinx", "_EnumFormatter", "do_autodoc", "do_autodoc", "list", "list", "fmt.preamble_lookup", "fmt.method", "fmt.method", "fmt.member", "fmt.preamble_lookup", "fmt.method", "fmt.method", "fmt.entry", "fmt.member"], "code_location": {"file": "test_ext_autodoc.py", "path": "/data3/pwh/swebench-repos/sphinx/tests/test_extensions", "start_line": 1776, "end_line": 1795}, "code_snippet": "def test_enum_class_with_mixin_type(app, autodoc_enum_options):\n    fmt = _EnumFormatter('EnumClassWithMixinType')\n\n    actual = do_autodoc(app, 'class', fmt.target, autodoc_enum_options)\n    assert list(actual) == [\n        *fmt.preamble_lookup('this is enum class'),\n        *fmt.method('say_goodbye', 'docstring', 'classmethod'),\n        *fmt.method('say_hello', 'docstring'),\n        *fmt.member('x', 'X', ''),\n    ]\n\n    options = autodoc_enum_options | {'inherited-members': None}\n    actual = do_autodoc(app, 'class', fmt.target, options)\n    assert list(actual) == [\n        *fmt.preamble_lookup('this is enum class'),\n        *fmt.method('say_goodbye', 'docstring', 'classmethod'),\n        *fmt.method('say_hello', 'docstring'),\n        *fmt.entry('value', 'uppercased', role='property'),\n        *fmt.member('x', 'X', ''),\n    ]\n", "type": "function"}, {"name": "test_enum_class_with_mixin_and_data_type", "is_method": false, "class_name": null, "parameters": ["app", "autodoc_enum_options"], "calls": ["pytest.mark.sphinx", "_EnumFormatter", "do_autodoc", "do_autodoc", "do_autodoc", "list", "list", "list", "fmt.preamble_lookup", "fmt.method", "fmt.method", "fmt.method", "fmt.member", "fmt.preamble_lookup", "fmt.method", "fmt.method", "fmt.method", "fmt.method", "fmt.member", "fmt.preamble_lookup", "fmt.entry", "fmt.method", "fmt.method", "fmt.method", "fmt.entry", "fmt.member"], "code_location": {"file": "test_ext_autodoc.py", "path": "/data3/pwh/swebench-repos/sphinx/tests/test_extensions", "start_line": 1844, "end_line": 1878}, "code_snippet": "def test_enum_class_with_mixin_and_data_type(app, autodoc_enum_options):\n    fmt = _EnumFormatter('EnumClassWithMixinAndDataType')\n\n    actual = do_autodoc(app, 'class', fmt.target, autodoc_enum_options)\n    assert list(actual) == [\n        *fmt.preamble_lookup('this is enum class'),\n        *fmt.method('isupper', 'overridden'),\n        *fmt.method('say_goodbye', 'overridden', 'classmethod'),\n        *fmt.method('say_hello', 'overridden'),\n        *fmt.member('x', 'X', ''),\n    ]\n\n    # add the special member __str__ (but not the inherited members)\n    options = autodoc_enum_options | {'special-members': '__str__'}\n    actual = do_autodoc(app, 'class', fmt.target, options)\n    assert list(actual) == [\n        *fmt.preamble_lookup('this is enum class'),\n        *fmt.method('__str__', 'overridden'),\n        *fmt.method('isupper', 'overridden'),\n        *fmt.method('say_goodbye', 'overridden', 'classmethod'),\n        *fmt.method('say_hello', 'overridden'),\n        *fmt.member('x', 'X', ''),\n    ]\n\n    options = autodoc_enum_options | {'inherited-members': None}\n    actual = do_autodoc(app, 'class', fmt.target, options)\n    assert list(actual) == [\n        *fmt.preamble_lookup('this is enum class'),\n        *fmt.entry('dtype', 'docstring', role='property'),\n        *fmt.method('isupper', 'overridden'),\n        *fmt.method('say_goodbye', 'overridden', 'classmethod'),\n        *fmt.method('say_hello', 'overridden'),\n        *fmt.entry('value', 'uppercased', role='property'),\n        *fmt.member('x', 'X', ''),\n    ]\n", "type": "function"}, {"name": "test_enum_class_with_mixin_type_and_inheritence", "is_method": false, "class_name": null, "parameters": ["app", "autodoc_enum_options"], "calls": ["pytest.mark.sphinx", "_EnumFormatter", "do_autodoc", "do_autodoc", "list", "list", "fmt.preamble_lookup", "fmt.member", "fmt.preamble_lookup", "fmt.method", "fmt.method", "fmt.entry", "fmt.member"], "code_location": {"file": "test_ext_autodoc.py", "path": "/data3/pwh/swebench-repos/sphinx/tests/test_extensions", "start_line": 1799, "end_line": 1816}, "code_snippet": "def test_enum_class_with_mixin_type_and_inheritence(app, autodoc_enum_options):\n    fmt = _EnumFormatter('EnumClassWithMixinTypeInherit')\n\n    actual = do_autodoc(app, 'class', fmt.target, autodoc_enum_options)\n    assert list(actual) == [\n        *fmt.preamble_lookup('this is enum class'),\n        *fmt.member('x', 'X', ''),\n    ]\n\n    options = autodoc_enum_options | {'inherited-members': None}\n    actual = do_autodoc(app, 'class', fmt.target, options)\n    assert list(actual) == [\n        *fmt.preamble_lookup('this is enum class'),\n        *fmt.method('say_goodbye', 'inherited', 'classmethod'),\n        *fmt.method('say_hello', 'inherited'),\n        *fmt.entry('value', 'uppercased', role='property'),\n        *fmt.member('x', 'X', ''),\n    ]\n", "type": "function"}, {"name": "test_enum_inherited_sunder_method", "is_method": false, "class_name": null, "parameters": ["app", "autodoc_enum_options"], "calls": ["pytest.mark.sphinx", "_EnumFormatter", "do_autodoc", "_EnumFormatter", "do_autodoc", "_EnumFormatter", "do_autodoc", "_EnumFormatter", "do_autodoc", "list", "list", "list", "list", "fmt.preamble_constructor", "fmt.method", "fmt.preamble_constructor", "fmt.method", "fmt.preamble_constructor", "fmt.method", "fmt.entry", "fmt.method", "fmt.preamble_constructor", "fmt.method"], "code_location": {"file": "test_ext_autodoc.py", "path": "/data3/pwh/swebench-repos/sphinx/tests/test_extensions", "start_line": 1949, "end_line": 1983}, "code_snippet": "def test_enum_inherited_sunder_method(app, autodoc_enum_options):\n    options = autodoc_enum_options | {\n        'private-members': None,\n        'inherited-members': None,\n    }\n\n    fmt = _EnumFormatter('EnumSunderMissingInNonEnumMixin')\n    actual = do_autodoc(app, 'class', fmt.target, options)\n    assert list(actual) == [\n        *fmt.preamble_constructor('this is enum class'),\n        *fmt.method('_missing_', 'inherited', 'classmethod', args='(value)'),\n    ]\n\n    fmt = _EnumFormatter('EnumSunderMissingInEnumMixin')\n    actual = do_autodoc(app, 'class', fmt.target, options)\n    assert list(actual) == [\n        *fmt.preamble_constructor('this is enum class'),\n        *fmt.method('_missing_', 'inherited', 'classmethod', args='(value)'),\n    ]\n\n    fmt = _EnumFormatter('EnumSunderMissingInDataType')\n    actual = do_autodoc(app, 'class', fmt.target, options)\n    assert list(actual) == [\n        *fmt.preamble_constructor('this is enum class'),\n        *fmt.method('_missing_', 'inherited', 'classmethod', args='(value)'),\n        *fmt.entry('dtype', 'docstring', role='property'),\n        *fmt.method('isupper', 'inherited'),\n    ]\n\n    fmt = _EnumFormatter('EnumSunderMissingInClass')\n    actual = do_autodoc(app, 'class', fmt.target, options)\n    assert list(actual) == [\n        *fmt.preamble_constructor('this is enum class'),\n        *fmt.method('_missing_', 'docstring', 'classmethod', args='(value)'),\n    ]\n", "type": "function"}, {"name": "test_enum_sunder_method", "is_method": false, "class_name": null, "parameters": ["app", "autodoc_enum_options"], "calls": ["pytest.mark.sphinx", "_EnumFormatter", "do_autodoc", "do_autodoc", "_EnumFormatter", "do_autodoc", "do_autodoc", "_EnumFormatter", "do_autodoc", "do_autodoc", "_EnumFormatter", "do_autodoc", "do_autodoc", "list", "list", "list", "list", "list", "list", "list", "list", "fmt.preamble_constructor", "fmt.preamble_constructor", "fmt.preamble_constructor", "fmt.preamble_constructor", "fmt.preamble_constructor", "fmt.preamble_constructor", "fmt.preamble_constructor", "fmt.preamble_constructor", "fmt.method"], "code_location": {"file": "test_ext_autodoc.py", "path": "/data3/pwh/swebench-repos/sphinx/tests/test_extensions", "start_line": 1917, "end_line": 1945}, "code_snippet": "def test_enum_sunder_method(app, autodoc_enum_options):\n    PRIVATE = {'private-members': None}  # sunder methods are recognized as private\n\n    fmt = _EnumFormatter('EnumSunderMissingInNonEnumMixin')\n    actual = do_autodoc(app, 'class', fmt.target, autodoc_enum_options)\n    assert list(actual) == [*fmt.preamble_constructor('this is enum class')]\n    actual = do_autodoc(app, 'class', fmt.target, autodoc_enum_options | PRIVATE)\n    assert list(actual) == [*fmt.preamble_constructor('this is enum class')]\n\n    fmt = _EnumFormatter('EnumSunderMissingInEnumMixin')\n    actual = do_autodoc(app, 'class', fmt.target, autodoc_enum_options)\n    assert list(actual) == [*fmt.preamble_constructor('this is enum class')]\n    actual = do_autodoc(app, 'class', fmt.target, autodoc_enum_options | PRIVATE)\n    assert list(actual) == [*fmt.preamble_constructor('this is enum class')]\n\n    fmt = _EnumFormatter('EnumSunderMissingInDataType')\n    actual = do_autodoc(app, 'class', fmt.target, autodoc_enum_options)\n    assert list(actual) == [*fmt.preamble_constructor('this is enum class')]\n    actual = do_autodoc(app, 'class', fmt.target, autodoc_enum_options | PRIVATE)\n    assert list(actual) == [*fmt.preamble_constructor('this is enum class')]\n\n    fmt = _EnumFormatter('EnumSunderMissingInClass')\n    actual = do_autodoc(app, 'class', fmt.target, autodoc_enum_options)\n    assert list(actual) == [*fmt.preamble_constructor('this is enum class')]\n    actual = do_autodoc(app, 'class', fmt.target, autodoc_enum_options | PRIVATE)\n    assert list(actual) == [\n        *fmt.preamble_constructor('this is enum class'),\n        *fmt.method('_missing_', 'docstring', 'classmethod', args='(value)'),\n    ]\n", "type": "function"}, {"name": "test_enum_inherited_custom_name_property", "is_method": false, "class_name": null, "parameters": ["app", "autodoc_enum_options"], "calls": ["pytest.mark.sphinx", "_EnumFormatter", "do_autodoc", "_EnumFormatter", "do_autodoc", "_EnumFormatter", "do_autodoc", "_EnumFormatter", "do_autodoc", "list", "list", "list", "list", "fmt.preamble_constructor", "fmt.entry", "fmt.preamble_constructor", "fmt.entry", "fmt.preamble_constructor", "fmt.entry", "fmt.method", "fmt.entry", "fmt.preamble_constructor", "fmt.entry"], "code_location": {"file": "test_ext_autodoc.py", "path": "/data3/pwh/swebench-repos/sphinx/tests/test_extensions", "start_line": 2009, "end_line": 2040}, "code_snippet": "def test_enum_inherited_custom_name_property(app, autodoc_enum_options):\n    options = autodoc_enum_options | {'inherited-members': None}\n\n    fmt = _EnumFormatter('EnumNamePropertyInNonEnumMixin')\n    actual = do_autodoc(app, 'class', fmt.target, options)\n    assert list(actual) == [\n        *fmt.preamble_constructor('this is enum class'),\n        *fmt.entry('name', 'inherited', role='property'),\n    ]\n\n    fmt = _EnumFormatter('EnumNamePropertyInEnumMixin')\n    actual = do_autodoc(app, 'class', fmt.target, options)\n    assert list(actual) == [\n        *fmt.preamble_constructor('this is enum class'),\n        *fmt.entry('name', 'inherited', role='property'),\n    ]\n\n    fmt = _EnumFormatter('EnumNamePropertyInDataType')\n    actual = do_autodoc(app, 'class', fmt.target, options)\n    assert list(actual) == [\n        *fmt.preamble_constructor('this is enum class'),\n        *fmt.entry('dtype', 'docstring', role='property'),\n        *fmt.method('isupper', 'inherited'),\n        *fmt.entry('name', 'inherited', role='property'),\n    ]\n\n    fmt = _EnumFormatter('EnumNamePropertyInClass')\n    actual = do_autodoc(app, 'class', fmt.target, options)\n    assert list(actual) == [\n        *fmt.preamble_constructor('this is enum class'),\n        *fmt.entry('name', 'docstring', role='property'),\n    ]\n", "type": "function"}, {"name": "EnumSunderMissingInNonEnumMixin", "docstring": "this is enum class", "methods": [], "attributes": [], "code_location": {"file": "enums.py", "path": "/data3/pwh/swebench-repos/sphinx/tests/roots/test-ext-autodoc/target", "start_line": 184, "end_line": 185}, "type": "class"}, {"name": "_SunderMissingInEnumMixin", "docstring": "", "methods": ["_missing_"], "attributes": [], "code_location": {"file": "enums.py", "path": "/data3/pwh/swebench-repos/sphinx/tests/roots/test-ext-autodoc/target", "start_line": 170, "end_line": 174}, "type": "class"}, {"name": "_SunderMissingInNonEnumMixin", "docstring": "", "methods": ["_missing_"], "attributes": [], "code_location": {"file": "enums.py", "path": "/data3/pwh/swebench-repos/sphinx/tests/roots/test-ext-autodoc/target", "start_line": 163, "end_line": 167}, "type": "class"}], "retrieved_count": 10, "cost_time": 1.2254681587219238}
{"question": "Why does the Python domain's object resolution method reconcile the tension between fully-qualified and unqualified references while maintaining predictable resolution order?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"name": "_resolve_reference_in_domain", "is_method": false, "class_name": null, "parameters": ["inv_name", "inventory", "honor_disabled_refs", "disabled_reftypes", "domain", "objtypes", "node", "contnode"], "calls": ["dict.fromkeys", "_resolve_reference_in_domain_by_target", "domain.get_full_qualified_name", "_resolve_reference_in_domain_by_target", "obj_types.keys"], "code_location": {"file": "_resolve.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/ext/intersphinx", "start_line": 145, "end_line": 192}, "code_snippet": "def _resolve_reference_in_domain(\n    inv_name: InventoryName | None,\n    inventory: Inventory,\n    honor_disabled_refs: bool,\n    disabled_reftypes: Set[str],\n    domain: Domain,\n    objtypes: Iterable[str],\n    node: pending_xref,\n    contnode: TextElement,\n) -> nodes.reference | None:\n    domain_name = domain.name\n    obj_types: dict[str, None] = dict.fromkeys(objtypes)\n\n    # we adjust the object types for backwards compatibility\n    if domain_name == 'std' and 'cmdoption' in obj_types:\n        # cmdoptions were stored as std:option until Sphinx 1.6\n        obj_types['option'] = None\n    if domain_name == 'py' and 'attribute' in obj_types:\n        # properties are stored as py:method since Sphinx 2.1\n        obj_types['method'] = None\n\n    # the inventory contains domain:type as objtype\n    obj_types = {f'{domain_name}:{obj_type}': None for obj_type in obj_types}\n\n    # now that the objtypes list is complete we can remove the disabled ones\n    if honor_disabled_refs:\n        obj_types = {\n            obj_type: None\n            for obj_type in obj_types\n            if obj_type not in disabled_reftypes\n        }\n\n    objtypes = [*obj_types.keys()]\n\n    # without qualification\n    res = _resolve_reference_in_domain_by_target(\n        inv_name, inventory, domain_name, objtypes, node['reftarget'], node, contnode\n    )\n    if res is not None:\n        return res\n\n    # try with qualification of the current scope instead\n    full_qualified_name = domain.get_full_qualified_name(node)\n    if full_qualified_name is None:\n        return None\n    return _resolve_reference_in_domain_by_target(\n        inv_name, inventory, domain_name, objtypes, full_qualified_name, node, contnode\n    )\n", "type": "function"}, {"name": "test_get_full_qualified_name", "is_method": false, "class_name": null, "parameters": [], "calls": ["pytest.mark.sphinx", "Mock", "PythonDomain", "nodes.reference", "nodes.reference", "nodes.reference", "nodes.reference", "nodes.reference", "domain.get_full_qualified_name", "domain.get_full_qualified_name", "domain.get_full_qualified_name", "domain.get_full_qualified_name", "domain.get_full_qualified_name"], "code_location": {"file": "test_domain_py.py", "path": "/data3/pwh/swebench-repos/sphinx/tests/test_domains", "start_line": 329, "end_line": 354}, "code_snippet": "def test_get_full_qualified_name() -> None:\n    env = Mock(domaindata={})\n    domain = PythonDomain(env)\n\n    # non-python references\n    node = nodes.reference()\n    assert domain.get_full_qualified_name(node) is None\n\n    # simple reference\n    node = nodes.reference(reftarget='func')\n    assert domain.get_full_qualified_name(node) == 'func'\n\n    # with py:module context\n    kwargs = {'py:module': 'module1'}\n    node = nodes.reference(reftarget='func', **kwargs)\n    assert domain.get_full_qualified_name(node) == 'module1.func'\n\n    # with py:class context\n    kwargs = {'py:class': 'Class'}\n    node = nodes.reference(reftarget='func', **kwargs)\n    assert domain.get_full_qualified_name(node) == 'Class.func'\n\n    # with both py:module and py:class context\n    kwargs = {'py:module': 'module1', 'py:class': 'Class'}\n    node = nodes.reference(reftarget='func', **kwargs)\n    assert domain.get_full_qualified_name(node) == 'module1.Class.func'\n", "type": "function"}, {"name": "resolve_xref", "is_method": true, "class_name": "PythonDomain", "parameters": ["self", "env", "fromdocname", "builder", "type", "target", "node", "contnode"], "calls": ["node.get", "node.get", "self.find_obj", "node.hasattr", "self.find_obj", "self.find_obj", "self.find_obj", "self._make_module_refnode", "find_pending_xref_condition", "make_refnode", "self.find_obj", "len", "len", "logger.warning", "__", "join"], "code_location": {"file": "__init__.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/domains/python", "start_line": 940, "end_line": 1004}, "code_snippet": "    def resolve_xref(\n        self,\n        env: BuildEnvironment,\n        fromdocname: str,\n        builder: Builder,\n        type: str,\n        target: str,\n        node: pending_xref,\n        contnode: Element,\n    ) -> nodes.reference | None:\n        modname = node.get('py:module')\n        clsname = node.get('py:class')\n        searchmode = 1 if node.hasattr('refspecific') else 0\n        matches = self.find_obj(env, modname, clsname, target, type, searchmode)\n\n        if not matches and type == 'class':\n            # fallback to data/attr (for type aliases)\n            # type aliases are documented as data/attr but referenced as class\n            matches = self.find_obj(env, modname, clsname, target, 'data', searchmode)\n            if not matches:\n                matches = self.find_obj(\n                    env, modname, clsname, target, 'attr', searchmode\n                )\n        if not matches and type == 'attr':\n            # fallback to meth (for property; Sphinx 2.4.x)\n            # this ensures that `:attr:` role continues to refer to the old property entry\n            # that defined by ``method`` directive in old reST files.\n            matches = self.find_obj(env, modname, clsname, target, 'meth', searchmode)\n        if not matches and type == 'meth':\n            # fallback to attr (for property)\n            # this ensures that `:meth:` in the old reST files can refer to the property\n            # entry that defined by ``property`` directive.\n            #\n            # Note: _prop is a secret role only for internal look-up.\n            matches = self.find_obj(env, modname, clsname, target, '_prop', searchmode)\n\n        if not matches:\n            return None\n        elif len(matches) > 1:\n            canonicals = [m for m in matches if not m[1].aliased]\n            if len(canonicals) == 1:\n                matches = canonicals\n            else:\n                logger.warning(\n                    __('more than one target found for cross-reference %r: %s'),\n                    target,\n                    ', '.join(match[0] for match in matches),\n                    type='ref',\n                    subtype='python',\n                    location=node,\n                )\n        name, obj = matches[0]\n\n        if obj[2] == 'module':\n            return self._make_module_refnode(builder, fromdocname, name, contnode)\n        else:\n            # determine the content of the reference by conditions\n            content = find_pending_xref_condition(node, 'resolved')\n            if content:\n                children = content.children\n            else:\n                # if not found, use contnode\n                children = [contnode]\n\n            return make_refnode(builder, fromdocname, obj[0], obj[1], children, name)\n", "type": "function"}, {"name": "resolve_any_xref", "is_method": true, "class_name": "PythonDomain", "parameters": ["self", "env", "fromdocname", "builder", "target", "node", "contnode"], "calls": ["node.get", "node.get", "self.find_obj", "len", "results.append", "find_pending_xref_condition", "results.append", "self.role_for_objtype", "self._make_module_refnode", "make_refnode"], "code_location": {"file": "__init__.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/domains/python", "start_line": 1006, "end_line": 1047}, "code_snippet": "    def resolve_any_xref(\n        self,\n        env: BuildEnvironment,\n        fromdocname: str,\n        builder: Builder,\n        target: str,\n        node: pending_xref,\n        contnode: Element,\n    ) -> list[tuple[str, nodes.reference]]:\n        modname = node.get('py:module')\n        clsname = node.get('py:class')\n        results: list[tuple[str, nodes.reference]] = []\n\n        # always search in \"refspecific\" mode with the :any: role\n        matches = self.find_obj(env, modname, clsname, target, None, 1)\n        multiple_matches = len(matches) > 1\n\n        for name, obj in matches:\n            if multiple_matches and obj.aliased:\n                # Skip duplicated matches\n                continue\n\n            if obj[2] == 'module':\n                results.append((\n                    'py:mod',\n                    self._make_module_refnode(builder, fromdocname, name, contnode),\n                ))\n            else:\n                # determine the content of the reference by conditions\n                content = find_pending_xref_condition(node, 'resolved')\n                if content:\n                    children = content.children\n                else:\n                    # if not found, use contnode\n                    children = [contnode]\n\n                role = 'py:' + self.role_for_objtype(obj[2])  # type: ignore[operator]\n                results.append((\n                    role,\n                    make_refnode(builder, fromdocname, obj[0], obj[1], children, name),\n                ))\n        return results\n", "type": "function"}, {"name": "make_xref", "is_method": true, "class_name": "PyXrefMixin", "parameters": ["self", "rolename", "domain", "target", "innernode", "contnode", "env", "inliner", "location"], "calls": ["make_xref", "isinstance", "env.ref_context.get", "env.ref_context.get", "parse_reftarget", "super", "result.clear", "innernode", "result.clear", "innernode", "result.extend", "target.rpartition", "pending_xref_condition", "pending_xref_condition"], "code_location": {"file": "_object.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/domains/python", "start_line": 56, "end_line": 104}, "code_snippet": "    def make_xref(\n        self,\n        rolename: str,\n        domain: str,\n        target: str,\n        innernode: type[TextlikeNode] = nodes.emphasis,\n        contnode: Node | None = None,\n        env: BuildEnvironment | None = None,\n        inliner: Inliner | None = None,\n        location: Node | None = None,\n    ) -> Node:\n        # we use inliner=None to make sure we get the old behaviour with a single\n        # pending_xref node\n        result = super().make_xref(  # type: ignore[misc]\n            rolename,\n            domain,\n            target,\n            innernode,\n            contnode,\n            env,\n            inliner=None,\n            location=None,\n        )\n        if isinstance(result, pending_xref):\n            assert env is not None\n            result['refspecific'] = True\n            result['py:module'] = env.ref_context.get('py:module')\n            result['py:class'] = env.ref_context.get('py:class')\n\n            reftype, reftarget, reftitle, _ = parse_reftarget(target)\n            if reftarget != reftitle:\n                result['reftype'] = reftype\n                result['reftarget'] = reftarget\n\n                result.clear()\n                result += innernode(reftitle, reftitle)  # type: ignore[call-arg]\n            elif env.config.python_use_unqualified_type_names:\n                children = result.children\n                result.clear()\n\n                shortname = target.rpartition('.')[-1]\n                textnode = innernode('', shortname)  # type: ignore[call-arg]\n                contnodes = [\n                    pending_xref_condition('', '', textnode, condition='resolved'),\n                    pending_xref_condition('', '', *children, condition='*'),\n                ]\n                result.extend(contnodes)\n\n        return result\n", "type": "function"}, {"name": "_resolve_reference_in_domain_by_target", "is_method": false, "class_name": null, "parameters": ["inv_name", "inventory", "domain_name", "objtypes", "target", "node", "contnode"], "calls": ["_create_element_from_result", "target.lower", "list", "filter", "len", "keys", "len", "LOGGER.debug", "LOGGER.warning", "__", "__", "k.lower"], "code_location": {"file": "_resolve.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/ext/intersphinx", "start_line": 81, "end_line": 142}, "code_snippet": "def _resolve_reference_in_domain_by_target(\n    inv_name: InventoryName | None,\n    inventory: Inventory,\n    domain_name: str,\n    objtypes: Iterable[str],\n    target: str,\n    node: pending_xref,\n    contnode: TextElement,\n) -> nodes.reference | None:\n    for objtype in objtypes:\n        if objtype not in inventory:\n            # Continue if there's nothing of this kind in the inventory\n            continue\n\n        if target in inventory[objtype]:\n            # Case sensitive match, use it\n            data = inventory[objtype][target]\n        elif objtype in {'std:label', 'std:term'}:\n            # Some types require case insensitive matches:\n            # * 'term': https://github.com/sphinx-doc/sphinx/issues/9291\n            # * 'label': https://github.com/sphinx-doc/sphinx/issues/12008\n            target_lower = target.lower()\n            insensitive_matches = list(\n                filter(lambda k: k.lower() == target_lower, inventory[objtype].keys())\n            )\n            if len(insensitive_matches) > 1:\n                data_items = {\n                    inventory[objtype][match] for match in insensitive_matches\n                }\n                inv_descriptor = inv_name or 'main_inventory'\n                if len(data_items) == 1:  # these are duplicates; relatively innocuous\n                    LOGGER.debug(\n                        __(\"inventory '%s': duplicate matches found for %s:%s\"),\n                        inv_descriptor,\n                        objtype,\n                        target,\n                        type='intersphinx',\n                        subtype='external',\n                        location=node,\n                    )\n                else:\n                    LOGGER.warning(\n                        __(\"inventory '%s': multiple matches found for %s:%s\"),\n                        inv_descriptor,\n                        objtype,\n                        target,\n                        type='intersphinx',\n                        subtype='external',\n                        location=node,\n                    )\n            if insensitive_matches:\n                data = inventory[objtype][insensitive_matches[0]]\n            else:\n                # No case insensitive match either, continue to the next candidate\n                continue\n        else:\n            # Could reach here if we're not a term but have a case insensitive match.\n            # This is a fix for terms specifically, but potentially should apply to\n            # other types.\n            continue\n        return _create_element_from_result(domain_name, inv_name, data, node, contnode)\n    return None\n", "type": "function"}, {"name": "test_python_python_use_unqualified_type_names", "is_method": false, "class_name": null, "parameters": ["app"], "calls": ["pytest.mark.sphinx", "app.build", "read_text"], "code_location": {"file": "test_domain_py.py", "path": "/data3/pwh/swebench-repos/sphinx/tests/test_domains", "start_line": 882, "end_line": 894}, "code_snippet": "def test_python_python_use_unqualified_type_names(app):\n    app.build()\n    content = (app.outdir / 'index.html').read_text(encoding='utf8')\n    assert (\n        '<span class=\"n\"><a class=\"reference internal\" href=\"#foo.Name\" title=\"foo.Name\">'\n        '<span class=\"pre\">Name</span></a></span>'\n    ) in content\n    assert '<span class=\"n\"><span class=\"pre\">foo.Age</span></span>' in content\n    assert (\n        '<p><strong>name</strong> (<a class=\"reference internal\" href=\"#foo.Name\" '\n        'title=\"foo.Name\"><em>Name</em></a>)  blah blah</p>'\n    ) in content\n    assert '<p><strong>age</strong> (<em>foo.Age</em>)  blah blah</p>' in content\n", "type": "function"}, {"name": "test_pyobject_prefix", "is_method": false, "class_name": null, "parameters": ["app"], "calls": ["pytest.mark.sphinx", "restructuredtext.parse", "assert_node", "strip", "strip", "astext", "astext"], "code_location": {"file": "test_domain_py_pyobject.py", "path": "/data3/pwh/swebench-repos/sphinx/tests/test_domains", "start_line": 170, "end_line": 200}, "code_snippet": "def test_pyobject_prefix(app):\n    text = (\n        '.. py:class:: Foo\\n\\n   .. py:method:: Foo.say\\n   .. py:method:: FooBar.say'\n    )\n    doctree = restructuredtext.parse(app, text)\n    assert_node(\n        doctree,\n        (\n            addnodes.index,\n            [\n                desc,\n                (\n                    [\n                        desc_signature,\n                        (\n                            [\n                                desc_annotation,\n                                ([desc_sig_keyword, 'class'], desc_sig_space),\n                            ],\n                            [desc_name, 'Foo'],\n                        ),\n                    ],\n                    [desc_content, (addnodes.index, desc, addnodes.index, desc)],\n                ),\n            ],\n        ),\n    )\n    # prefix is stripped\n    assert doctree[1][1][1].astext().strip() == 'say()'\n    # not stripped\n    assert doctree[1][1][3].astext().strip() == 'FooBar.say()'\n", "type": "function"}, {"name": "_resolve_reference", "is_method": false, "class_name": null, "parameters": ["inv_name", "domains", "inventory", "honor_disabled_refs", "disabled_reftypes", "node", "contnode"], "calls": ["domains.sorted", "node.get", "_resolve_reference_in_domain", "domain.object_types.keys", "_resolve_reference_in_domain", "domain.objtypes_for_role", "ExtensionError", "__"], "code_location": {"file": "_resolve.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/ext/intersphinx", "start_line": 195, "end_line": 254}, "code_snippet": "def _resolve_reference(\n    inv_name: InventoryName | None,\n    domains: _DomainsContainer,\n    inventory: Inventory,\n    honor_disabled_refs: bool,\n    disabled_reftypes: Set[str],\n    node: pending_xref,\n    contnode: TextElement,\n) -> nodes.reference | None:\n    # disabling should only be done if no inventory is given\n    honor_disabled_refs = honor_disabled_refs and inv_name is None\n\n    if honor_disabled_refs and '*' in disabled_reftypes:\n        return None\n\n    typ = node['reftype']\n    if typ == 'any':\n        for domain in domains.sorted():\n            if honor_disabled_refs and f'{domain.name}:*' in disabled_reftypes:\n                continue\n            objtypes: Iterable[str] = domain.object_types.keys()\n            res = _resolve_reference_in_domain(\n                inv_name,\n                inventory,\n                honor_disabled_refs,\n                disabled_reftypes,\n                domain,\n                objtypes,\n                node,\n                contnode,\n            )\n            if res is not None:\n                return res\n        return None\n    else:\n        domain_name = node.get('refdomain')\n        if not domain_name:\n            # only objects in domains are in the inventory\n            return None\n        if honor_disabled_refs and f'{domain_name}:*' in disabled_reftypes:\n            return None\n        try:\n            domain = domains[domain_name]\n        except KeyError as exc:\n            msg = __('Domain %r is not registered') % domain_name\n            raise ExtensionError(msg) from exc\n\n        objtypes = domain.objtypes_for_role(typ) or ()\n        if not objtypes:\n            return None\n        return _resolve_reference_in_domain(\n            inv_name,\n            inventory,\n            honor_disabled_refs,\n            disabled_reftypes,\n            domain,\n            objtypes,\n            node,\n            contnode,\n        )\n", "type": "function"}, {"name": "test_python_python_use_unqualified_type_names_disabled", "is_method": false, "class_name": null, "parameters": ["app"], "calls": ["pytest.mark.sphinx", "app.build", "read_text"], "code_location": {"file": "test_domain_py.py", "path": "/data3/pwh/swebench-repos/sphinx/tests/test_domains", "start_line": 902, "end_line": 914}, "code_snippet": "def test_python_python_use_unqualified_type_names_disabled(app):\n    app.build()\n    content = (app.outdir / 'index.html').read_text(encoding='utf8')\n    assert (\n        '<span class=\"n\"><a class=\"reference internal\" href=\"#foo.Name\" title=\"foo.Name\">'\n        '<span class=\"pre\">foo.Name</span></a></span>'\n    ) in content\n    assert '<span class=\"n\"><span class=\"pre\">foo.Age</span></span>' in content\n    assert (\n        '<p><strong>name</strong> (<a class=\"reference internal\" href=\"#foo.Name\" '\n        'title=\"foo.Name\"><em>foo.Name</em></a>)  blah blah</p>'\n    ) in content\n    assert '<p><strong>age</strong> (<em>foo.Age</em>)  blah blah</p>' in content\n", "type": "function"}], "retrieved_count": 10, "cost_time": 1.2711710929870605}
{"question": "Where in the method that formats optional command-line arguments for help text does the conditional evaluation control whether the static method that formats metavar information receives its parameters?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"name": "_format_metavar", "is_method": true, "class_name": "_RootArgumentParser", "parameters": ["nargs", "metavar", "choices", "dest"], "calls": ["ValueError", "dest.upper", "join", "len", "sorted"], "code_location": {"file": "__init__.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/_cli", "start_line": 141, "end_line": 168}, "code_snippet": "    def _format_metavar(\n        nargs: int | str | None,\n        metavar: str | tuple[str, ...] | None,\n        choices: Iterable[str] | None,\n        dest: str,\n    ) -> str:\n        if metavar is None:\n            if choices is not None:\n                metavar = '{' + ', '.join(sorted(choices)) + '}'\n            else:\n                metavar = dest.upper()\n        if nargs is None:\n            return f'{metavar}'\n        elif nargs == argparse.OPTIONAL:\n            return f'[{metavar}]'\n        elif nargs == argparse.ZERO_OR_MORE:\n            if len(metavar) == 2:\n                return f'[{metavar[0]} [{metavar[1]} ...]]'\n            else:\n                return f'[{metavar} ...]'\n        elif nargs == argparse.ONE_OR_MORE:\n            return f'{metavar} [{metavar} ...]'\n        elif nargs == argparse.REMAINDER:\n            return '...'\n        elif nargs == argparse.PARSER:\n            return f'{metavar} ...'\n        msg = 'invalid nargs value'\n        raise ValueError(msg)\n", "type": "function"}, {"name": "_format_optional_arguments", "is_method": true, "class_name": "_RootArgumentParser", "parameters": ["self", "actions", "title"], "calls": ["bold", "underline", "all", "join", "strip", "map", "self._format_metavar", "action_help.splitlines"], "code_location": {"file": "__init__.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/_cli", "start_line": 119, "end_line": 138}, "code_snippet": "    def _format_optional_arguments(\n        self,\n        actions: Iterable[argparse.Action],\n        title: str,\n    ) -> Iterator[str]:\n        yield '\\n'\n        yield bold(underline(title + ':'))\n        yield '\\n'\n\n        for action in actions:\n            prefix = '    ' * all(o[1] == '-' for o in action.option_strings)\n            opt = prefix + '  ' + ', '.join(map(bold, action.option_strings))\n            if action.nargs != 0:\n                opt += ' ' + self._format_metavar(\n                    action.nargs, action.metavar, action.choices, action.dest\n                )\n            yield opt\n            yield '\\n'\n            if action_help := (action.help or '').strip():\n                yield from (f'        {line}\\n' for line in action_help.splitlines())\n", "type": "function"}, {"name": "format_help", "is_method": true, "class_name": "_RootArgumentParser", "parameters": ["self"], "calls": ["__", "join", "bold", "format", "__", "list", "map", "min", "help_fragments.append", "__", "underline", "bold", "_load_subcommand_descriptions", "next", "max", "bold", "self._format_optional_arguments", "__", "__", "zip", "underline", "__"], "code_location": {"file": "__init__.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/_cli", "start_line": 71, "end_line": 117}, "code_snippet": "    def format_help(self) -> str:\n        help_fragments: list[str] = [\n            bold(underline(__('Usage:'))),\n            ' ',\n            __('{0} [OPTIONS] <COMMAND> [<ARGS>]').format(bold(self.prog)),\n            '\\n',\n            '\\n',\n            __('  The Sphinx documentation generator.'),\n            '\\n',\n        ]\n\n        if commands := list(_load_subcommand_descriptions()):\n            command_lengths = map(len, next(zip(*commands, strict=True), ()))\n            command_max_length = min(max(command_lengths), 22)\n            help_fragments += [\n                '\\n',\n                bold(underline(__('Commands:'))),\n                '\\n',\n            ]\n            help_fragments += [\n                f'  {command_name: <{command_max_length}}  {command_desc}'\n                for command_name, command_desc in commands\n            ]\n            help_fragments.append('\\n')\n\n        # self._action_groups[1] is self._optionals\n        # Uppercase the title of the Optionals group\n        self._optionals.title = __('Options')\n        for argument_group in self._action_groups[1:]:\n            if arguments := [\n                action\n                for action in argument_group._group_actions\n                if action.help != argparse.SUPPRESS\n            ]:\n                help_fragments += self._format_optional_arguments(\n                    arguments,\n                    argument_group.title or '',\n                )\n\n        help_fragments += [\n            '\\n',\n            __(\n                'For more information, visit https://www.sphinx-doc.org/en/master/man/.'\n            ),\n            '\\n',\n        ]\n        return ''.join(help_fragments)\n", "type": "function"}, {"name": "annotation_option", "is_method": false, "class_name": null, "parameters": ["arg"], "calls": [], "code_location": {"file": "_directive_options.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/ext/autodoc", "start_line": 153, "end_line": 157}, "code_snippet": "def annotation_option(arg: str | None) -> SUPPRESS_T | str | Literal[False]:\n    if arg is None or arg is True:\n        # suppress showing the representation of the object\n        return SUPPRESS\n    return arg\n", "type": "function"}, {"name": "_call_format_args", "is_method": true, "class_name": "Documenter", "parameters": ["self"], "calls": ["self.format_args", "self.format_args"], "code_location": {"file": "_documenters.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/ext/autodoc", "start_line": 359, "end_line": 368}, "code_snippet": "    def _call_format_args(self, **kwargs: Any) -> str:\n        if kwargs:\n            try:\n                return self.format_args(**kwargs)\n            except TypeError:\n                # avoid chaining exceptions, by putting nothing here\n                pass\n\n        # retry without arguments for old documenters\n        return self.format_args()\n", "type": "function"}, {"name": "format_args", "is_method": true, "class_name": "Documenter", "parameters": ["self"], "calls": [], "code_location": {"file": "_documenters.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/ext/autodoc", "start_line": 341, "end_line": 346}, "code_snippet": "    def format_args(self, **kwargs: Any) -> str:\n        \"\"\"Format the argument signature of *self.object*.\n\n        Should return None if the object does not have a signature.\n        \"\"\"\n        return ''\n", "type": "function"}, {"name": "format_args", "is_method": true, "class_name": "PropertyDocumenter", "parameters": ["self"], "calls": ["self._get_property_getter", "self._events.emit", "format_args", "super"], "code_location": {"file": "_documenters.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/ext/autodoc", "start_line": 2475, "end_line": 2483}, "code_snippet": "    def format_args(self, **kwargs: Any) -> str:\n        func = self._get_property_getter()\n        if func is None:\n            return ''\n\n        # update the annotations of the property getter\n        self._events.emit('autodoc-before-process-signature', func, False)\n        # correctly format the arguments for a property\n        return super().format_args(**kwargs)\n", "type": "function"}, {"name": "format_default", "is_method": true, "class_name": "ConfigurationValue", "parameters": ["self", "default"], "calls": ["self.parse_inline", "nodes.field", "nodes.field_name", "nodes.field_body", "_"], "code_location": {"file": "__init__.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/domains/std", "start_line": 177, "end_line": 185}, "code_snippet": "    def format_default(self, default: str) -> tuple[nodes.field, list[system_message]]:\n        \"\"\"Formats the ``:default:`` option.\"\"\"\n        parsed, msgs = self.parse_inline(default, lineno=self.lineno)\n        field = nodes.field(\n            '',\n            nodes.field_name('', _('Default')),\n            nodes.field_body('', *parsed),\n        )\n        return field, msgs\n", "type": "function"}, {"name": "_collapsible_arg", "is_method": false, "class_name": null, "parameters": ["argument"], "calls": ["ValueError", "strip", "argument.lower"], "code_location": {"file": "admonitions.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/directives", "start_line": 20, "end_line": 26}, "code_snippet": "def _collapsible_arg(argument: str | None) -> str:\n    if argument is None:\n        return 'open'\n    if (value := argument.lower().strip()) in {'open', 'closed'}:\n        return value\n    msg = f'\"{argument}\" unknown; choose from \"open\" or \"closed\".'\n    raise ValueError(msg)\n", "type": "function"}, {"name": "format_args", "is_method": true, "class_name": "ClassDocumenter", "parameters": ["self"], "calls": ["stringify_signature", "kwargs.setdefault", "kwargs.setdefault", "kwargs.setdefault", "self._get_signature", "__", "logger.warning"], "code_location": {"file": "_documenters.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/ext/autodoc", "start_line": 1502, "end_line": 1522}, "code_snippet": "    def format_args(self, **kwargs: Any) -> str:\n        if self.config.autodoc_typehints in {'none', 'description'}:\n            kwargs.setdefault('show_annotation', False)\n        if self.config.autodoc_typehints_format == 'short':\n            kwargs.setdefault('unqualified_typehints', True)\n        if self.config.python_display_short_literal_types:\n            kwargs.setdefault('short_literals', True)\n\n        try:\n            self._signature_class, _signature_method_name, sig = self._get_signature()\n        except TypeError as exc:\n            # __signature__ attribute contained junk\n            msg = __('Failed to get a constructor signature for %s: %s')\n            logger.warning(msg, self.props.full_name, exc)\n            return ''\n        self._signature_method_name = _signature_method_name or ''\n\n        if sig is None:\n            return ''\n\n        return stringify_signature(sig, show_return_annotation=False, **kwargs)\n", "type": "function"}], "retrieved_count": 10, "cost_time": 0.34071850776672363}
{"question": "Why does the member documentation method in the specialized class documenter use the alias detection property to conditionally skip delegating to the base documenter's implementation?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"name": "document_members", "is_method": true, "class_name": "ClassDocumenter", "parameters": ["self", "all_members"], "calls": ["document_members", "super"], "code_location": {"file": "_documenters.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/ext/autodoc", "start_line": 1810, "end_line": 1813}, "code_snippet": "    def document_members(self, all_members: bool = False) -> None:\n        if self.props.doc_as_attr:\n            return\n        super().document_members(all_members)\n", "type": "function"}, {"name": "can_document_member", "is_method": true, "class_name": "PropertyDocumenter", "parameters": ["cls", "member", "membername", "isattr", "parent"], "calls": ["isinstance", "inspect.isproperty", "safe_getattr", "__dict__.get", "hasattr", "isinstance", "inspect.isproperty"], "code_location": {"file": "_documenters.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/ext/autodoc", "start_line": 2459, "end_line": 2473}, "code_snippet": "    def can_document_member(\n        cls: type[Documenter], member: Any, membername: str, isattr: bool, parent: Any\n    ) -> bool:\n        if isinstance(parent, ClassDocumenter):\n            if inspect.isproperty(member):\n                return True\n            else:\n                # See FakeDirective &c in autosummary, parent might not be a\n                # 'proper' Documenter.\n                obj = parent.props._obj if hasattr(parent, 'props') else None\n                __dict__ = safe_getattr(obj, '__dict__', {})\n                obj = __dict__.get(membername)\n                return isinstance(obj, classmethod) and inspect.isproperty(obj.__func__)\n        else:\n            return False\n", "type": "function"}, {"name": "can_document_member", "is_method": true, "class_name": "ModuleDocumenter", "parameters": ["cls", "member", "membername", "isattr", "parent"], "calls": [], "code_location": {"file": "_documenters.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/ext/autodoc", "start_line": 1041, "end_line": 1045}, "code_snippet": "    def can_document_member(\n        cls: type[Documenter], member: Any, membername: str, isattr: bool, parent: Any\n    ) -> bool:\n        # don't document submodules automatically\n        return False\n", "type": "function"}, {"name": "can_document_member", "is_method": true, "class_name": "MethodDocumenter", "parameters": ["cls", "member", "membername", "isattr", "parent"], "calls": ["inspect.isroutine", "isinstance"], "code_location": {"file": "_documenters.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/ext/autodoc", "start_line": 2002, "end_line": 2005}, "code_snippet": "    def can_document_member(\n        cls: type[Documenter], member: Any, membername: str, isattr: bool, parent: Any\n    ) -> bool:\n        return inspect.isroutine(member) and not isinstance(parent, ModuleDocumenter)\n", "type": "function"}, {"name": "can_document_member", "is_method": true, "class_name": "AttributeDocumenter", "parameters": ["cls", "member", "membername", "isattr", "parent"], "calls": ["isinstance", "inspect.isattributedescriptor", "inspect.isroutine", "isinstance"], "code_location": {"file": "_documenters.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/ext/autodoc", "start_line": 2270, "end_line": 2277}, "code_snippet": "    def can_document_member(\n        cls: type[Documenter], member: Any, membername: str, isattr: bool, parent: Any\n    ) -> bool:\n        if isinstance(parent, ModuleDocumenter):\n            return False\n        if inspect.isattributedescriptor(member):\n            return True\n        return not inspect.isroutine(member) and not isinstance(member, type)\n", "type": "function"}, {"name": "can_document_member", "is_method": true, "class_name": "DataDocumenter", "parameters": ["cls", "member", "membername", "isattr", "parent"], "calls": ["isinstance"], "code_location": {"file": "_documenters.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/ext/autodoc", "start_line": 1877, "end_line": 1880}, "code_snippet": "    def can_document_member(\n        cls: type[Documenter], member: Any, membername: str, isattr: bool, parent: Any\n    ) -> bool:\n        return isinstance(parent, ModuleDocumenter) and isattr\n", "type": "function"}, {"name": "can_document_member", "is_method": true, "class_name": "IntEnumDocumenter", "parameters": ["cls", "member", "membername", "isattr", "parent"], "calls": ["issubclass"], "code_location": {"file": "autodoc_intenum.py", "path": "/data3/pwh/swebench-repos/sphinx/doc/development/tutorials/examples", "start_line": 25, "end_line": 31}, "code_snippet": "    def can_document_member(\n        cls, member: Any, membername: str, isattr: bool, parent: Any\n    ) -> bool:\n        try:\n            return issubclass(member, IntEnum)\n        except TypeError:\n            return False\n", "type": "function"}, {"name": "document_members", "is_method": true, "class_name": "MethodDocumenter", "parameters": ["self", "all_members"], "calls": [], "code_location": {"file": "_documenters.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/ext/autodoc", "start_line": 2076, "end_line": 2077}, "code_snippet": "    def document_members(self, all_members: bool = False) -> None:\n        pass\n", "type": "function"}, {"name": "document_members", "is_method": true, "class_name": "AttributeDocumenter", "parameters": ["self", "all_members"], "calls": [], "code_location": {"file": "_documenters.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/ext/autodoc", "start_line": 2279, "end_line": 2280}, "code_snippet": "    def document_members(self, all_members: bool = False) -> None:\n        pass\n", "type": "function"}, {"name": "document_members", "is_method": true, "class_name": "DataDocumenter", "parameters": ["self", "all_members"], "calls": [], "code_location": {"file": "_documenters.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/ext/autodoc", "start_line": 1950, "end_line": 1951}, "code_snippet": "    def document_members(self, all_members: bool = False) -> None:\n        pass\n", "type": "function"}], "retrieved_count": 10, "cost_time": 0.3592798709869385}
{"question": "Where would the source code analysis process determine whether a function with no parameters, calls, or control flow statements serves as an actual execution component or merely a documentation-only element in the module's code processing workflow?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"name": "__special_undoc__", "is_method": false, "class_name": null, "parameters": [], "calls": [], "code_location": {"file": "test_ext_napoleon.py", "path": "/data3/pwh/swebench-repos/sphinx/tests/test_extensions", "start_line": 39, "end_line": 40}, "code_snippet": "def __special_undoc__():  # NoQA: N807\n    pass\n", "type": "function"}, {"name": "foo", "is_method": false, "class_name": null, "parameters": [], "calls": [], "code_location": {"file": "metadata.py", "path": "/data3/pwh/swebench-repos/sphinx/tests/roots/test-ext-autodoc/target", "start_line": 1, "end_line": 2}, "code_snippet": "def foo():\n    \"\"\":meta metadata-only-docstring:\"\"\"\n", "type": "function"}, {"name": "__special_doc__", "is_method": false, "class_name": null, "parameters": [], "calls": [], "code_location": {"file": "test_ext_napoleon.py", "path": "/data3/pwh/swebench-repos/sphinx/tests/test_extensions", "start_line": 34, "end_line": 36}, "code_snippet": "def __special_doc__():  # NoQA: N807\n    \"\"\"module.__special_doc__.DOCSTRING\"\"\"\n    pass\n", "type": "function"}, {"name": "bar", "is_method": false, "class_name": null, "parameters": [], "calls": [], "code_location": {"file": "target.py", "path": "/data3/pwh/swebench-repos/sphinx/tests/roots/test-directive-code", "start_line": 16, "end_line": 16}, "code_snippet": "def bar(): pass\n", "type": "function"}, {"name": "func", "is_method": false, "class_name": null, "parameters": [], "calls": [], "code_location": {"file": "functions.py", "path": "/data3/pwh/swebench-repos/sphinx/tests/roots/test-ext-autodoc/target", "start_line": 4, "end_line": 5}, "code_snippet": "def func():\n    pass\n", "type": "function"}, {"name": "func", "is_method": false, "class_name": null, "parameters": [], "calls": [], "code_location": {"file": "test_util_inspect.py", "path": "/data3/pwh/swebench-repos/sphinx/tests/test_util", "start_line": 72, "end_line": 73}, "code_snippet": "def func():\n    pass\n", "type": "function"}, {"name": "_quux", "is_method": false, "class_name": null, "parameters": [], "calls": [], "code_location": {"file": "autosummary_dummy_module.py", "path": "/data3/pwh/swebench-repos/sphinx/tests/roots/test-ext-autosummary", "start_line": 49, "end_line": 50}, "code_snippet": "def _quux():\n    pass\n", "type": "function"}, {"name": "A", "docstring": "A class having no __init__, no __new__", "methods": [], "attributes": [], "code_location": {"file": "autoclass_content.py", "path": "/data3/pwh/swebench-repos/sphinx/tests/roots/test-ext-autodoc/target", "start_line": 1, "end_line": 2}, "type": "class"}, {"name": "foobar", "is_method": false, "class_name": null, "parameters": [], "calls": [], "code_location": {"file": "sort_by_all.py", "path": "/data3/pwh/swebench-repos/sphinx/tests/roots/test-ext-autodoc/target", "start_line": 24, "end_line": 25}, "code_snippet": "def foobar():\n    pass\n", "type": "function"}, {"name": "foo", "is_method": false, "class_name": null, "parameters": [], "calls": [], "code_location": {"file": "sort_by_all.py", "path": "/data3/pwh/swebench-repos/sphinx/tests/roots/test-ext-autodoc/target", "start_line": 4, "end_line": 5}, "code_snippet": "def foo():\n    pass\n", "type": "function"}], "retrieved_count": 10, "cost_time": 0.3348264694213867}
{"question": "Where does the method that closes bullet list itemize blocks integrate within the document tree traversal and output assembly pipeline that generates Texinfo files?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"name": "depart_bullet_list", "is_method": true, "class_name": "TexinfoTranslator", "parameters": ["self", "node"], "calls": ["self.ensure_eol", "self.body.append"], "code_location": {"file": "texinfo.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/writers", "start_line": 917, "end_line": 919}, "code_snippet": "    def depart_bullet_list(self, node: Element) -> None:\n        self.ensure_eol()\n        self.body.append('@end itemize\\n')\n", "type": "function"}, {"name": "depart_bullet_list", "is_method": true, "class_name": "LaTeXTranslator", "parameters": ["self", "node"], "calls": ["self.body.append"], "code_location": {"file": "latex.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/writers", "start_line": 1451, "end_line": 1453}, "code_snippet": "    def depart_bullet_list(self, node: Element) -> None:\n        if not self.compact_list:\n            self.body.append(r'\\end{itemize}' + CR)\n", "type": "function"}, {"name": "depart_bullet_list", "is_method": true, "class_name": "TextTranslator", "parameters": ["self", "node"], "calls": ["self.list_counter.pop"], "code_location": {"file": "text.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/writers", "start_line": 959, "end_line": 960}, "code_snippet": "    def depart_bullet_list(self, node: Element) -> None:\n        self.list_counter.pop()\n", "type": "function"}, {"name": "depart_hlist", "is_method": true, "class_name": "ManualPageTranslator", "parameters": ["self", "node"], "calls": ["self.depart_bullet_list"], "code_location": {"file": "manpage.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/writers", "start_line": 374, "end_line": 375}, "code_snippet": "    def depart_hlist(self, node: nodes.bullet_list) -> None:\n        self.depart_bullet_list(node)\n", "type": "function"}, {"name": "visit_bullet_list", "is_method": true, "class_name": "TexinfoTranslator", "parameters": ["self", "node"], "calls": ["node.get", "self.body.append"], "code_location": {"file": "texinfo.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/writers", "start_line": 913, "end_line": 915}, "code_snippet": "    def visit_bullet_list(self, node: Element) -> None:\n        bullet = node.get('bullet', '*')\n        self.body.append('\\n\\n@itemize %s\\n' % bullet)\n", "type": "function"}, {"name": "depart_hlist", "is_method": true, "class_name": "TexinfoTranslator", "parameters": ["self", "node"], "calls": ["self.depart_bullet_list"], "code_location": {"file": "texinfo.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/writers", "start_line": 1567, "end_line": 1568}, "code_snippet": "    def depart_hlist(self, node: Element) -> None:\n        self.depart_bullet_list(node)\n", "type": "function"}, {"name": "depart_list_item", "is_method": true, "class_name": "TextTranslator", "parameters": ["self", "node"], "calls": ["self.end_state", "self.end_state"], "code_location": {"file": "text.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/writers", "start_line": 986, "end_line": 992}, "code_snippet": "    def depart_list_item(self, node: Element) -> None:\n        if self.list_counter[-1] == -1:\n            self.end_state(first='* ')\n        elif self.list_counter[-1] == -2:\n            pass\n        else:\n            self.end_state(first='%s. ' % self.list_counter[-1])\n", "type": "function"}, {"name": "depart_enumerated_list", "is_method": true, "class_name": "TexinfoTranslator", "parameters": ["self", "node"], "calls": ["self.ensure_eol", "self.body.append"], "code_location": {"file": "texinfo.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/writers", "start_line": 928, "end_line": 930}, "code_snippet": "    def depart_enumerated_list(self, node: Element) -> None:\n        self.ensure_eol()\n        self.body.append('@end enumerate\\n')\n", "type": "function"}, {"name": "depart_document", "is_method": true, "class_name": "TextTranslator", "parameters": ["self", "node"], "calls": ["self.end_state", "self.nl.join"], "code_location": {"file": "text.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/writers", "start_line": 472, "end_line": 478}, "code_snippet": "    def depart_document(self, node: Element) -> None:\n        self.end_state()\n        self.body = self.nl.join(\n            line and (' ' * indent + line)\n            for indent, lines in self.states[0]\n            for line in lines\n        )\n", "type": "function"}, {"name": "visit_bullet_list", "is_method": true, "class_name": "LaTeXTranslator", "parameters": ["self", "node"], "calls": ["self.body.append"], "code_location": {"file": "latex.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/writers", "start_line": 1447, "end_line": 1449}, "code_snippet": "    def visit_bullet_list(self, node: Element) -> None:\n        if not self.compact_list:\n            self.body.append(r'\\begin{itemize}' + CR)\n", "type": "function"}], "retrieved_count": 10, "cost_time": 0.33814573287963867}
{"question": "How do the signature description methods on the inner and next declarator attributes handle recursive traversal of nested parenthesized declarators?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"name": "describe_signature", "is_method": true, "class_name": "ASTDeclaratorParen", "parameters": ["self", "signode", "mode", "env", "symbol"], "calls": ["verify_description_mode", "addnodes.desc_sig_punctuation", "self.inner.describe_signature", "addnodes.desc_sig_punctuation", "self.next.describe_signature"], "code_location": {"file": "_ast.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/domains/cpp", "start_line": 3246, "end_line": 3253}, "code_snippet": "    def describe_signature(\n        self, signode: TextElement, mode: str, env: BuildEnvironment, symbol: Symbol\n    ) -> None:\n        verify_description_mode(mode)\n        signode += addnodes.desc_sig_punctuation('(', '(')\n        self.inner.describe_signature(signode, mode, env, symbol)\n        signode += addnodes.desc_sig_punctuation(')', ')')\n        self.next.describe_signature(signode, 'noneIsName', env, symbol)\n", "type": "function"}, {"name": "describe_signature", "is_method": true, "class_name": "ASTDeclaratorParen", "parameters": ["self", "signode", "mode", "env", "symbol"], "calls": ["verify_description_mode", "addnodes.desc_sig_punctuation", "self.inner.describe_signature", "addnodes.desc_sig_punctuation", "self.next.describe_signature"], "code_location": {"file": "_ast.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/domains/c", "start_line": 1430, "end_line": 1437}, "code_snippet": "    def describe_signature(\n        self, signode: TextElement, mode: str, env: BuildEnvironment, symbol: Symbol\n    ) -> None:\n        verify_description_mode(mode)\n        signode += addnodes.desc_sig_punctuation('(', '(')\n        self.inner.describe_signature(signode, mode, env, symbol)\n        signode += addnodes.desc_sig_punctuation(')', ')')\n        self.next.describe_signature(signode, 'noneIsName', env, symbol)\n", "type": "function"}, {"name": "describe_signature", "is_method": true, "class_name": "ASTDeclaratorParamPack", "parameters": ["self", "signode", "mode", "env", "symbol"], "calls": ["verify_description_mode", "addnodes.desc_sig_punctuation", "self.next.describe_signature", "addnodes.desc_sig_space"], "code_location": {"file": "_ast.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/domains/cpp", "start_line": 3048, "end_line": 3055}, "code_snippet": "    def describe_signature(\n        self, signode: TextElement, mode: str, env: BuildEnvironment, symbol: Symbol\n    ) -> None:\n        verify_description_mode(mode)\n        signode += addnodes.desc_sig_punctuation('...', '...')\n        if self.next.name:\n            signode += addnodes.desc_sig_space()\n        self.next.describe_signature(signode, mode, env, symbol)\n", "type": "function"}, {"name": "describe_signature", "is_method": true, "class_name": "ASTDeclaratorRef", "parameters": ["self", "signode", "mode", "env", "symbol"], "calls": ["verify_description_mode", "addnodes.desc_sig_punctuation", "self.attrs.describe_signature", "self.next.describe_signature", "self.next.require_space_after_declSpecs", "addnodes.desc_sig_space", "len"], "code_location": {"file": "_ast.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/domains/cpp", "start_line": 2975, "end_line": 2983}, "code_snippet": "    def describe_signature(\n        self, signode: TextElement, mode: str, env: BuildEnvironment, symbol: Symbol\n    ) -> None:\n        verify_description_mode(mode)\n        signode += addnodes.desc_sig_punctuation('&', '&')\n        self.attrs.describe_signature(signode)\n        if len(self.attrs) > 0 and self.next.require_space_after_declSpecs():\n            signode += addnodes.desc_sig_space()\n        self.next.describe_signature(signode, mode, env, symbol)\n", "type": "function"}, {"name": "describe_signature", "is_method": true, "class_name": "ASTDeclaratorMemPtr", "parameters": ["self", "signode", "mode", "env", "symbol"], "calls": ["verify_description_mode", "self.className.describe_signature", "addnodes.desc_sig_punctuation", "addnodes.desc_sig_punctuation", "self.next.require_space_after_declSpecs", "self.next.describe_signature", "addnodes.desc_sig_keyword", "_add_anno", "_add_anno", "addnodes.desc_sig_space", "addnodes.desc_sig_space"], "code_location": {"file": "_ast.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/domains/cpp", "start_line": 3151, "end_line": 3170}, "code_snippet": "    def describe_signature(\n        self, signode: TextElement, mode: str, env: BuildEnvironment, symbol: Symbol\n    ) -> None:\n        verify_description_mode(mode)\n        self.className.describe_signature(signode, 'markType', env, symbol)\n        signode += addnodes.desc_sig_punctuation('::', '::')\n        signode += addnodes.desc_sig_punctuation('*', '*')\n\n        def _add_anno(signode: TextElement, text: str) -> None:\n            signode += addnodes.desc_sig_keyword(text, text)\n\n        if self.volatile:\n            _add_anno(signode, 'volatile')\n        if self.const:\n            if self.volatile:\n                signode += addnodes.desc_sig_space()\n            _add_anno(signode, 'const')\n        if self.next.require_space_after_declSpecs():\n            signode += addnodes.desc_sig_space()\n        self.next.describe_signature(signode, mode, env, symbol)\n", "type": "function"}, {"name": "describe_signature", "is_method": true, "class_name": "ASTDeclaratorPtr", "parameters": ["self", "signode", "mode", "env", "symbol"], "calls": ["verify_description_mode", "addnodes.desc_sig_punctuation", "self.attrs.describe_signature", "self.next.describe_signature", "addnodes.desc_sig_space", "addnodes.desc_sig_keyword", "_add_anno", "_add_anno", "self.next.require_space_after_declSpecs", "len", "addnodes.desc_sig_space", "len", "addnodes.desc_sig_space"], "code_location": {"file": "_ast.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/domains/cpp", "start_line": 2887, "end_line": 2908}, "code_snippet": "    def describe_signature(\n        self, signode: TextElement, mode: str, env: BuildEnvironment, symbol: Symbol\n    ) -> None:\n        verify_description_mode(mode)\n        signode += addnodes.desc_sig_punctuation('*', '*')\n        self.attrs.describe_signature(signode)\n        if len(self.attrs) != 0 and (self.volatile or self.const):\n            signode += addnodes.desc_sig_space()\n\n        def _add_anno(signode: TextElement, text: str) -> None:\n            signode += addnodes.desc_sig_keyword(text, text)\n\n        if self.volatile:\n            _add_anno(signode, 'volatile')\n        if self.const:\n            if self.volatile:\n                signode += addnodes.desc_sig_space()\n            _add_anno(signode, 'const')\n        if self.const or self.volatile or len(self.attrs) > 0:\n            if self.next.require_space_after_declSpecs():\n                signode += addnodes.desc_sig_space()\n        self.next.describe_signature(signode, mode, env, symbol)\n", "type": "function"}, {"name": "describe_signature", "is_method": true, "class_name": "ASTDeclaratorPtr", "parameters": ["self", "signode", "mode", "env", "symbol"], "calls": ["verify_description_mode", "addnodes.desc_sig_punctuation", "self.attrs.describe_signature", "self.next.describe_signature", "addnodes.desc_sig_space", "addnodes.desc_sig_keyword", "_add_anno", "_add_anno", "_add_anno", "self.next.require_space_after_declSpecs", "len", "addnodes.desc_sig_space", "addnodes.desc_sig_space", "len", "addnodes.desc_sig_space"], "code_location": {"file": "_ast.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/domains/c", "start_line": 1366, "end_line": 1391}, "code_snippet": "    def describe_signature(\n        self, signode: TextElement, mode: str, env: BuildEnvironment, symbol: Symbol\n    ) -> None:\n        verify_description_mode(mode)\n        signode += addnodes.desc_sig_punctuation('*', '*')\n        self.attrs.describe_signature(signode)\n        if len(self.attrs) != 0 and (self.restrict or self.volatile or self.const):\n            signode += addnodes.desc_sig_space()\n\n        def _add_anno(signode: TextElement, text: str) -> None:\n            signode += addnodes.desc_sig_keyword(text, text)\n\n        if self.restrict:\n            _add_anno(signode, 'restrict')\n        if self.volatile:\n            if self.restrict:\n                signode += addnodes.desc_sig_space()\n            _add_anno(signode, 'volatile')\n        if self.const:\n            if self.restrict or self.volatile:\n                signode += addnodes.desc_sig_space()\n            _add_anno(signode, 'const')\n        if self.const or self.volatile or self.restrict or len(self.attrs) > 0:\n            if self.next.require_space_after_declSpecs():\n                signode += addnodes.desc_sig_space()\n        self.next.describe_signature(signode, mode, env, symbol)\n", "type": "function"}, {"name": "describe_signature", "is_method": true, "class_name": "ASTType", "parameters": ["self", "signode", "mode", "env", "symbol"], "calls": ["verify_description_mode", "self.declSpecs.describe_signature", "self.decl.describe_signature", "self.decl.require_space_after_declSpecs", "addnodes.desc_sig_space", "len", "str"], "code_location": {"file": "_ast.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/domains/cpp", "start_line": 3464, "end_line": 3475}, "code_snippet": "    def describe_signature(\n        self, signode: TextElement, mode: str, env: BuildEnvironment, symbol: Symbol\n    ) -> None:\n        verify_description_mode(mode)\n        self.declSpecs.describe_signature(signode, 'markType', env, symbol)\n        if self.decl.require_space_after_declSpecs() and len(str(self.declSpecs)) > 0:\n            signode += addnodes.desc_sig_space()\n        # for parameters that don't really declare new names we get 'markType',\n        # this should not be propagated, but be 'noneIsName'.\n        if mode == 'markType':\n            mode = 'noneIsName'\n        self.decl.describe_signature(signode, mode, env, symbol)\n", "type": "function"}, {"name": "describe_signature", "is_method": true, "class_name": "ASTType", "parameters": ["self", "signode", "mode", "env", "symbol"], "calls": ["verify_description_mode", "self.declSpecs.describe_signature", "self.decl.describe_signature", "self.decl.require_space_after_declSpecs", "addnodes.desc_sig_space", "len", "str"], "code_location": {"file": "_ast.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/domains/c", "start_line": 1586, "end_line": 1597}, "code_snippet": "    def describe_signature(\n        self, signode: TextElement, mode: str, env: BuildEnvironment, symbol: Symbol\n    ) -> None:\n        verify_description_mode(mode)\n        self.declSpecs.describe_signature(signode, 'markType', env, symbol)\n        if self.decl.require_space_after_declSpecs() and len(str(self.declSpecs)) > 0:\n            signode += addnodes.desc_sig_space()\n        # for parameters that don't really declare new names we get 'markType',\n        # this should not be propagated, but be 'noneIsName'.\n        if mode == 'markType':\n            mode = 'noneIsName'\n        self.decl.describe_signature(signode, mode, env, symbol)\n", "type": "function"}, {"name": "describe_signature", "is_method": true, "class_name": "ASTTrailingTypeSpecDecltype", "parameters": ["self", "signode", "mode", "env", "symbol"], "calls": ["addnodes.desc_sig_keyword", "addnodes.desc_sig_punctuation", "self.expr.describe_signature", "addnodes.desc_sig_punctuation"], "code_location": {"file": "_ast.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/domains/cpp", "start_line": 1953, "end_line": 1959}, "code_snippet": "    def describe_signature(\n        self, signode: TextElement, mode: str, env: BuildEnvironment, symbol: Symbol\n    ) -> None:\n        signode += addnodes.desc_sig_keyword('decltype', 'decltype')\n        signode += addnodes.desc_sig_punctuation('(', '(')\n        self.expr.describe_signature(signode, mode, env, symbol)\n        signode += addnodes.desc_sig_punctuation(')', ')')\n", "type": "function"}], "retrieved_count": 10, "cost_time": 0.34470319747924805}
{"question": "Where does the MRO in the enum class inheriting from both a non-enum mixin and the standard enum base affect which data attributes from the non-enum mixin are accessible versus shadowed by the standard enum base's internal mechanisms?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"name": "test_enum_class_with_mixin_and_data_type", "is_method": false, "class_name": null, "parameters": ["app", "autodoc_enum_options"], "calls": ["pytest.mark.sphinx", "_EnumFormatter", "do_autodoc", "do_autodoc", "do_autodoc", "list", "list", "list", "fmt.preamble_lookup", "fmt.method", "fmt.method", "fmt.method", "fmt.member", "fmt.preamble_lookup", "fmt.method", "fmt.method", "fmt.method", "fmt.method", "fmt.member", "fmt.preamble_lookup", "fmt.entry", "fmt.method", "fmt.method", "fmt.method", "fmt.entry", "fmt.member"], "code_location": {"file": "test_ext_autodoc.py", "path": "/data3/pwh/swebench-repos/sphinx/tests/test_extensions", "start_line": 1844, "end_line": 1878}, "code_snippet": "def test_enum_class_with_mixin_and_data_type(app, autodoc_enum_options):\n    fmt = _EnumFormatter('EnumClassWithMixinAndDataType')\n\n    actual = do_autodoc(app, 'class', fmt.target, autodoc_enum_options)\n    assert list(actual) == [\n        *fmt.preamble_lookup('this is enum class'),\n        *fmt.method('isupper', 'overridden'),\n        *fmt.method('say_goodbye', 'overridden', 'classmethod'),\n        *fmt.method('say_hello', 'overridden'),\n        *fmt.member('x', 'X', ''),\n    ]\n\n    # add the special member __str__ (but not the inherited members)\n    options = autodoc_enum_options | {'special-members': '__str__'}\n    actual = do_autodoc(app, 'class', fmt.target, options)\n    assert list(actual) == [\n        *fmt.preamble_lookup('this is enum class'),\n        *fmt.method('__str__', 'overridden'),\n        *fmt.method('isupper', 'overridden'),\n        *fmt.method('say_goodbye', 'overridden', 'classmethod'),\n        *fmt.method('say_hello', 'overridden'),\n        *fmt.member('x', 'X', ''),\n    ]\n\n    options = autodoc_enum_options | {'inherited-members': None}\n    actual = do_autodoc(app, 'class', fmt.target, options)\n    assert list(actual) == [\n        *fmt.preamble_lookup('this is enum class'),\n        *fmt.entry('dtype', 'docstring', role='property'),\n        *fmt.method('isupper', 'overridden'),\n        *fmt.method('say_goodbye', 'overridden', 'classmethod'),\n        *fmt.method('say_hello', 'overridden'),\n        *fmt.entry('value', 'uppercased', role='property'),\n        *fmt.member('x', 'X', ''),\n    ]\n", "type": "function"}, {"name": "EnumSunderMissingInNonEnumMixin", "docstring": "this is enum class", "methods": [], "attributes": [], "code_location": {"file": "enums.py", "path": "/data3/pwh/swebench-repos/sphinx/tests/roots/test-ext-autodoc/target", "start_line": 184, "end_line": 185}, "type": "class"}, {"name": "_SunderMissingInEnumMixin", "docstring": "", "methods": ["_missing_"], "attributes": [], "code_location": {"file": "enums.py", "path": "/data3/pwh/swebench-repos/sphinx/tests/roots/test-ext-autodoc/target", "start_line": 170, "end_line": 174}, "type": "class"}, {"name": "_NamePropertyInEnumMixin", "docstring": "", "methods": ["name"], "attributes": [], "code_location": {"file": "enums.py", "path": "/data3/pwh/swebench-repos/sphinx/tests/roots/test-ext-autodoc/target", "start_line": 212, "end_line": 216}, "type": "class"}, {"name": "EnumNamePropertyInNonEnumMixin", "docstring": "this is enum class", "methods": [], "attributes": [], "code_location": {"file": "enums.py", "path": "/data3/pwh/swebench-repos/sphinx/tests/roots/test-ext-autodoc/target", "start_line": 226, "end_line": 227}, "type": "class"}, {"name": "_SunderMissingInNonEnumMixin", "docstring": "", "methods": ["_missing_"], "attributes": [], "code_location": {"file": "enums.py", "path": "/data3/pwh/swebench-repos/sphinx/tests/roots/test-ext-autodoc/target", "start_line": 163, "end_line": 167}, "type": "class"}, {"name": "test_enum_class_with_mixin_enum_type", "is_method": false, "class_name": null, "parameters": ["app", "autodoc_enum_options"], "calls": ["pytest.mark.sphinx", "_EnumFormatter", "do_autodoc", "do_autodoc", "list", "list", "fmt.preamble_lookup", "fmt.method", "fmt.member", "fmt.preamble_lookup", "fmt.method", "fmt.method", "fmt.method", "fmt.member"], "code_location": {"file": "test_ext_autodoc.py", "path": "/data3/pwh/swebench-repos/sphinx/tests/test_extensions", "start_line": 1820, "end_line": 1840}, "code_snippet": "def test_enum_class_with_mixin_enum_type(app, autodoc_enum_options):\n    fmt = _EnumFormatter('EnumClassWithMixinEnumType')\n\n    actual = do_autodoc(app, 'class', fmt.target, autodoc_enum_options)\n    assert list(actual) == [\n        *fmt.preamble_lookup('this is enum class'),\n        # override() is overridden at the class level so it should be rendered\n        *fmt.method('override', 'overridden'),\n        # say_goodbye() and say_hello() are not rendered since they are inherited\n        *fmt.member('x', 'x', ''),\n    ]\n\n    options = autodoc_enum_options | {'inherited-members': None}\n    actual = do_autodoc(app, 'class', fmt.target, options)\n    assert list(actual) == [\n        *fmt.preamble_lookup('this is enum class'),\n        *fmt.method('override', 'overridden'),\n        *fmt.method('say_goodbye', 'inherited', 'classmethod'),\n        *fmt.method('say_hello', 'inherited'),\n        *fmt.member('x', 'x', ''),\n    ]\n", "type": "function"}, {"name": "test_enum_class_with_mixin_type", "is_method": false, "class_name": null, "parameters": ["app", "autodoc_enum_options"], "calls": ["pytest.mark.sphinx", "_EnumFormatter", "do_autodoc", "do_autodoc", "list", "list", "fmt.preamble_lookup", "fmt.method", "fmt.method", "fmt.member", "fmt.preamble_lookup", "fmt.method", "fmt.method", "fmt.entry", "fmt.member"], "code_location": {"file": "test_ext_autodoc.py", "path": "/data3/pwh/swebench-repos/sphinx/tests/test_extensions", "start_line": 1776, "end_line": 1795}, "code_snippet": "def test_enum_class_with_mixin_type(app, autodoc_enum_options):\n    fmt = _EnumFormatter('EnumClassWithMixinType')\n\n    actual = do_autodoc(app, 'class', fmt.target, autodoc_enum_options)\n    assert list(actual) == [\n        *fmt.preamble_lookup('this is enum class'),\n        *fmt.method('say_goodbye', 'docstring', 'classmethod'),\n        *fmt.method('say_hello', 'docstring'),\n        *fmt.member('x', 'X', ''),\n    ]\n\n    options = autodoc_enum_options | {'inherited-members': None}\n    actual = do_autodoc(app, 'class', fmt.target, options)\n    assert list(actual) == [\n        *fmt.preamble_lookup('this is enum class'),\n        *fmt.method('say_goodbye', 'docstring', 'classmethod'),\n        *fmt.method('say_hello', 'docstring'),\n        *fmt.entry('value', 'uppercased', role='property'),\n        *fmt.member('x', 'X', ''),\n    ]\n", "type": "function"}, {"name": "_NamePropertyInNonEnumMixin", "docstring": "", "methods": ["name"], "attributes": [], "code_location": {"file": "enums.py", "path": "/data3/pwh/swebench-repos/sphinx/tests/roots/test-ext-autodoc/target", "start_line": 205, "end_line": 209}, "type": "class"}, {"name": "EnumSunderMissingInEnumMixin", "docstring": "this is enum class", "methods": [], "attributes": [], "code_location": {"file": "enums.py", "path": "/data3/pwh/swebench-repos/sphinx/tests/roots/test-ext-autodoc/target", "start_line": 188, "end_line": 189}, "type": "class"}], "retrieved_count": 10, "cost_time": 0.33625030517578125}
{"question": "Where are the conditional branches that determine whether the pointer suffix identifier generation method in the parenthesized declarator node class of the C++ domain applies version-specific transformations?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"name": "get_ptr_suffix_id", "is_method": true, "class_name": "ASTDeclaratorParamPack", "parameters": ["self", "version"], "calls": ["self.next.get_ptr_suffix_id", "self.next.get_ptr_suffix_id"], "code_location": {"file": "_ast.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/domains/cpp", "start_line": 3034, "end_line": 3038}, "code_snippet": "    def get_ptr_suffix_id(self, version: int) -> str:\n        if version == 1:\n            return 'Dp' + self.next.get_ptr_suffix_id(version)\n        else:\n            return self.next.get_ptr_suffix_id(version) + 'Dp'\n", "type": "function"}, {"name": "get_ptr_suffix_id", "is_method": true, "class_name": "ASTDeclaratorPtr", "parameters": ["self", "version"], "calls": ["join", "res.append", "join", "self.next.get_ptr_suffix_id", "res.append", "res.append", "res.append", "res.append", "self.next.get_ptr_suffix_id"], "code_location": {"file": "_ast.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/domains/cpp", "start_line": 2857, "end_line": 2872}, "code_snippet": "    def get_ptr_suffix_id(self, version: int) -> str:\n        if version == 1:\n            res = ['P']\n            if self.volatile:\n                res.append('V')\n            if self.const:\n                res.append('C')\n            res.append(self.next.get_ptr_suffix_id(version))\n            return ''.join(res)\n\n        res = [self.next.get_ptr_suffix_id(version), 'P']\n        if self.volatile:\n            res.append('V')\n        if self.const:\n            res.append('C')\n        return ''.join(res)\n", "type": "function"}, {"name": "get_ptr_suffix_id", "is_method": true, "class_name": "ASTDeclaratorRef", "parameters": ["self", "version"], "calls": ["self.next.get_ptr_suffix_id", "self.next.get_ptr_suffix_id"], "code_location": {"file": "_ast.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/domains/cpp", "start_line": 2961, "end_line": 2965}, "code_snippet": "    def get_ptr_suffix_id(self, version: int) -> str:\n        if version == 1:\n            return 'R' + self.next.get_ptr_suffix_id(version)\n        else:\n            return self.next.get_ptr_suffix_id(version) + 'R'\n", "type": "function"}, {"name": "get_ptr_suffix_id", "is_method": true, "class_name": "ASTDeclaratorNameBitField", "parameters": ["self", "version"], "calls": [], "code_location": {"file": "_ast.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/domains/cpp", "start_line": 2759, "end_line": 2760}, "code_snippet": "    def get_ptr_suffix_id(self, version: int) -> str:  # only the array specifiers\n        return ''\n", "type": "function"}, {"name": "get_ptr_suffix_id", "is_method": true, "class_name": "ASTDeclaratorMemPtr", "parameters": ["self", "version"], "calls": ["self.next.get_ptr_suffix_id"], "code_location": {"file": "_ast.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/domains/cpp", "start_line": 3129, "end_line": 3133}, "code_snippet": "    def get_ptr_suffix_id(self, version: int) -> str:\n        if version == 1:\n            raise NoOldIdError\n        raise NotImplementedError\n        return self.next.get_ptr_suffix_id(version) + 'Dp'\n", "type": "function"}, {"name": "get_ptr_suffix_id", "is_method": true, "class_name": "ASTDeclarator", "parameters": ["self", "version"], "calls": ["NotImplementedError", "repr"], "code_location": {"file": "_ast.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/domains/cpp", "start_line": 2616, "end_line": 2617}, "code_snippet": "    def get_ptr_suffix_id(self, version: int) -> str:\n        raise NotImplementedError(repr(self))\n", "type": "function"}, {"name": "get_ptr_suffix_id", "is_method": true, "class_name": "ASTDeclaratorNameParamQual", "parameters": ["self", "version"], "calls": ["join", "a.get_id"], "code_location": {"file": "_ast.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/domains/cpp", "start_line": 2687, "end_line": 2688}, "code_snippet": "    def get_ptr_suffix_id(self, version: int) -> str:  # only the array specifiers\n        return ''.join(a.get_id(version) for a in self.arrayOps)\n", "type": "function"}, {"name": "get_ptr_suffix_id", "is_method": true, "class_name": "ASTDeclaratorParen", "parameters": ["self", "version"], "calls": ["self.inner.get_ptr_suffix_id", "self.next.get_ptr_suffix_id", "self.next.get_ptr_suffix_id", "self.inner.get_ptr_suffix_id"], "code_location": {"file": "_ast.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/domains/cpp", "start_line": 3227, "end_line": 3235}, "code_snippet": "    def get_ptr_suffix_id(self, version: int) -> str:\n        if version == 1:\n            raise NoOldIdError  # TODO: was this implemented before?\n            ptr_suffix_id_next = self.next.get_ptr_suffix_id(version)\n            ptr_suffix_id_inner = self.inner.get_ptr_suffix_id(version)\n            return ptr_suffix_id_next + ptr_suffix_id_inner\n        ptr_suffix_id_inner = self.inner.get_ptr_suffix_id(version)\n        ptr_suffix_id_next = self.next.get_ptr_suffix_id(version)\n        return ptr_suffix_id_inner + ptr_suffix_id_next\n", "type": "function"}, {"name": "get_id", "is_method": true, "class_name": "ASTDeclaration", "parameters": ["self", "version", "prefixed"], "calls": ["res.append", "join", "self.declaration.get_id", "self.enumeratorScopedSymbol.declaration.get_id", "res.append", "self.templatePrefix.get_requires_clause_in_last", "res.append", "res.append", "self.declaration.get_id", "self.enumeratorScopedSymbol.declaration.get_id", "self.templatePrefix.get_id_except_requires_clause_in_last", "res.append", "res.append", "res.append", "requires_clause_in_last.expr.get_id", "self.trailingRequiresClause.expr.get_id"], "code_location": {"file": "_ast.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/domains/cpp", "start_line": 4581, "end_line": 4626}, "code_snippet": "    def get_id(self, version: int, prefixed: bool = True) -> str:\n        if version == 1:\n            if self.templatePrefix or self.trailingRequiresClause:\n                raise NoOldIdError\n            if self.objectType == 'enumerator' and self.enumeratorScopedSymbol:\n                return self.enumeratorScopedSymbol.declaration.get_id(version)\n            return self.declaration.get_id(version, self.objectType, self.symbol)\n        # version >= 2\n        if self.objectType == 'enumerator' and self.enumeratorScopedSymbol:\n            return self.enumeratorScopedSymbol.declaration.get_id(version, prefixed)\n        if prefixed:\n            res = [_id_prefix[version]]\n        else:\n            res = []\n        # (See also https://github.com/sphinx-doc/sphinx/pull/10286#issuecomment-1168102147)\n        # The first implementation of requires clauses only supported a single clause after the\n        # template prefix, and no trailing clause. It put the ID after the template parameter\n        # list, i.e.,\n        #    \"I\" + template_parameter_list_id + \"E\" + \"IQ\" + requires_clause_id + \"E\"\n        # but the second implementation associates the requires clause with each list, i.e.,\n        #    \"I\" + template_parameter_list_id + \"IQ\" + requires_clause_id + \"E\" + \"E\"\n        # To avoid making a new ID version, we make an exception for the last requires clause\n        # in the template prefix, and still put it in the end.\n        # As we now support trailing requires clauses we add that as if it was a conjunction.\n        if self.templatePrefix is not None:\n            res.append(\n                self.templatePrefix.get_id_except_requires_clause_in_last(version)\n            )\n            requires_clause_in_last = self.templatePrefix.get_requires_clause_in_last()\n        else:\n            requires_clause_in_last = None\n\n        if requires_clause_in_last or self.trailingRequiresClause:\n            if version < 4:\n                raise NoOldIdError\n            res.append('IQ')\n            if requires_clause_in_last and self.trailingRequiresClause:\n                # make a conjunction of them\n                res.append('aa')\n            if requires_clause_in_last:\n                res.append(requires_clause_in_last.expr.get_id(version))\n            if self.trailingRequiresClause:\n                res.append(self.trailingRequiresClause.expr.get_id(version))\n            res.append('E')\n        res.append(self.declaration.get_id(version, self.objectType, self.symbol))\n        return ''.join(res)\n", "type": "function"}, {"name": "get_id", "is_method": true, "class_name": "ASTTemplateParamNonType", "parameters": ["self", "version", "objectType", "symbol"], "calls": ["symbol.parent.declaration.get_id", "self.param.get_id"], "code_location": {"file": "_ast.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/domains/cpp", "start_line": 4157, "end_line": 4169}, "code_snippet": "    def get_id(\n        self, version: int, objectType: str | None = None, symbol: Symbol | None = None\n    ) -> str:\n        assert version >= 2\n        # this is not part of the normal name mangling in C++\n        if symbol:\n            # the anchor will be our parent\n            return symbol.parent.declaration.get_id(version, prefixed=None)\n        else:\n            res = '_'\n            if self.parameterPack:\n                res += 'Dp'\n            return res + self.param.get_id(version)\n", "type": "function"}], "retrieved_count": 10, "cost_time": 0.34169793128967285}
{"question": "Where is the method that handles the departure of parameter list nodes in domain-specific object descriptions implemented within the manual page translator class that extends both the Sphinx base translator and the docutils manpage translator?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"name": "depart_desc_parameterlist", "is_method": true, "class_name": "TextTranslator", "parameters": ["self", "node"], "calls": ["self._depart_sig_parameter_list"], "code_location": {"file": "text.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/writers", "start_line": 664, "end_line": 665}, "code_snippet": "    def depart_desc_parameterlist(self, node: Element) -> None:\n        self._depart_sig_parameter_list(node)\n", "type": "function"}, {"name": "depart_desc_parameterlist", "is_method": true, "class_name": "HTML5Translator", "parameters": ["self", "node"], "calls": ["self._depart_sig_parameter_list"], "code_location": {"file": "html5.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/writers", "start_line": 191, "end_line": 192}, "code_snippet": "    def depart_desc_parameterlist(self, node: Element) -> None:\n        self._depart_sig_parameter_list(node)\n", "type": "function"}, {"name": "depart_desc_parameter", "is_method": true, "class_name": "HTML5Translator", "parameters": ["self", "node"], "calls": ["node.hasattr", "self.body.append", "len", "self.body.append", "self.body.append", "self.body.append"], "code_location": {"file": "html5.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/writers", "start_line": 224, "end_line": 249}, "code_snippet": "    def depart_desc_parameter(self, node: Element) -> None:\n        if not node.hasattr('noemph'):\n            self.body.append('</em>')\n        is_required = self.list_is_required_param[self.param_group_index]\n        if self.multi_line_parameter_list:\n            len_lirp = len(self.list_is_required_param)\n            is_last_group = self.param_group_index + 1 == len_lirp\n            next_is_required = (\n                not is_last_group\n                and self.list_is_required_param[self.param_group_index + 1]\n            )\n            opt_param_left_at_level = self.params_left_at_level > 0\n            if (\n                opt_param_left_at_level\n                or is_required\n                and (is_last_group or next_is_required)\n            ):\n                if not is_last_group or opt_param_left_at_level or self.trailing_comma:\n                    self.body.append(self.param_separator)\n                self.body.append('</dd>\\n')\n\n        elif self.required_params_left:\n            self.body.append(self.param_separator)\n\n        if is_required:\n            self.param_group_index += 1\n", "type": "function"}, {"name": "depart_manpage", "is_method": true, "class_name": "ManualPageTranslator", "parameters": ["self", "node"], "calls": ["self.depart_strong"], "code_location": {"file": "manpage.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/writers", "start_line": 404, "end_line": 405}, "code_snippet": "    def depart_manpage(self, node: nodes.strong) -> None:\n        return self.depart_strong(node)\n", "type": "function"}, {"name": "depart_desc_parameter", "is_method": true, "class_name": "ManualPageTranslator", "parameters": ["self", "node"], "calls": [], "code_location": {"file": "manpage.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/writers", "start_line": 210, "end_line": 211}, "code_snippet": "    def depart_desc_parameter(self, node: Element) -> None:\n        pass\n", "type": "function"}, {"name": "depart_manpage", "is_method": true, "class_name": "TexinfoTranslator", "parameters": ["self", "node"], "calls": ["self.depart_literal_emphasis"], "code_location": {"file": "texinfo.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/writers", "start_line": 1555, "end_line": 1556}, "code_snippet": "    def depart_manpage(self, node: Element) -> None:\n        return self.depart_literal_emphasis(node)\n", "type": "function"}, {"name": "depart_manpage", "is_method": true, "class_name": "TextTranslator", "parameters": ["self", "node"], "calls": ["self.depart_literal_emphasis"], "code_location": {"file": "text.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/writers", "start_line": 1246, "end_line": 1247}, "code_snippet": "    def depart_manpage(self, node: Element) -> None:\n        return self.depart_literal_emphasis(node)\n", "type": "function"}, {"name": "depart_manpage", "is_method": true, "class_name": "LaTeXTranslator", "parameters": ["self", "node"], "calls": ["self.depart_literal_emphasis"], "code_location": {"file": "latex.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/writers", "start_line": 2112, "end_line": 2113}, "code_snippet": "    def depart_manpage(self, node: Element) -> None:\n        return self.depart_literal_emphasis(node)\n", "type": "function"}, {"name": "depart_manpage", "is_method": true, "class_name": "HTML5Translator", "parameters": ["self", "node"], "calls": ["self.depart_literal_emphasis"], "code_location": {"file": "html5.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/writers", "start_line": 919, "end_line": 920}, "code_snippet": "    def depart_manpage(self, node: nodes.emphasis) -> None:\n        self.depart_literal_emphasis(node)\n", "type": "function"}, {"name": "_depart_sig_parameter_list", "is_method": true, "class_name": "HTML5Translator", "parameters": ["self", "node"], "calls": ["node.get", "self.context.pop", "self.body.append", "self.body.append"], "code_location": {"file": "html5.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/writers", "start_line": 182, "end_line": 186}, "code_snippet": "    def _depart_sig_parameter_list(self, node: Element) -> None:\n        if node.get('multi_line_parameter_list'):\n            self.body.append('</dl>\\n\\n')\n        sig_close_paren = self.context.pop()\n        self.body.append(f'<span class=\"sig-paren\">{sig_close_paren}</span>')\n", "type": "function"}], "retrieved_count": 10, "cost_time": 0.3354501724243164}
{"question": "Where does the path property descriptor class in the utility pathlib module resolve the instance attribute name dynamically?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"name": "_StrPathProperty", "docstring": "", "methods": ["__init__", "__set_name__", "__get__", "__get__", "__get__", "__set__", "__delete__"], "attributes": [], "code_location": {"file": "_pathlib.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/util", "start_line": 149, "end_line": 181}, "type": "class"}, {"name": "__get__", "is_method": true, "class_name": "_StrPathProperty", "parameters": ["self", "obj", "objtype"], "calls": [], "code_location": {"file": "_pathlib.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/util", "start_line": 157, "end_line": 157}, "code_snippet": "    def __get__(self, obj: None, objtype: None) -> _StrPathProperty: ...\n", "type": "function"}, {"name": "__get__", "is_method": true, "class_name": "_StrPathProperty", "parameters": ["self", "obj", "objtype"], "calls": ["getattr"], "code_location": {"file": "_pathlib.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/util", "start_line": 162, "end_line": 169}, "code_snippet": "    def __get__(\n        self, obj: object | None, objtype: type[object] | None = None\n    ) -> _StrPathProperty | _StrPath:\n        if obj is None:\n            return self\n        if not self.instance_attr:\n            raise AttributeError\n        return getattr(obj, self.instance_attr)\n", "type": "function"}, {"name": "__get__", "is_method": true, "class_name": "_StrPathProperty", "parameters": ["self", "obj", "objtype"], "calls": [], "code_location": {"file": "_pathlib.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/util", "start_line": 160, "end_line": 160}, "code_snippet": "    def __get__(self, obj: object, objtype: type[object]) -> _StrPath: ...\n", "type": "function"}, {"name": "__set_name__", "is_method": true, "class_name": "_StrPathProperty", "parameters": ["self", "owner", "name"], "calls": [], "code_location": {"file": "_pathlib.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/util", "start_line": 153, "end_line": 154}, "code_snippet": "    def __set_name__(self, owner: object, name: str) -> None:\n        self.instance_attr = f'_{name}'  # i.e. '_srcdir'\n", "type": "function"}, {"name": "__set__", "is_method": true, "class_name": "_StrPathProperty", "parameters": ["self", "obj", "value"], "calls": ["setattr", "_StrPath", "self.instance_attr.removeprefix", "TypeError", "type"], "code_location": {"file": "_pathlib.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/util", "start_line": 171, "end_line": 178}, "code_snippet": "    def __set__(self, obj: Any, value: _StrPath | Path) -> None:\n        try:\n            setattr(obj, self.instance_attr, _StrPath(value))\n        except TypeError as err:\n            cls_name = type(obj).__qualname__\n            name = self.instance_attr.removeprefix('_')\n            msg = f'{cls_name}.{name} may only be set to path-like objects'\n            raise TypeError(msg) from err\n", "type": "function"}, {"name": "_Descriptor", "docstring": "", "methods": ["__init__", "__get__"], "attributes": [], "code_location": {"file": "typed_vars.py", "path": "/data3/pwh/swebench-repos/sphinx/tests/roots/test-ext-autodoc/target", "start_line": 9, "end_line": 14}, "type": "class"}, {"name": "path", "is_method": true, "class_name": "Math", "parameters": ["self"], "calls": ["pathlib.PurePosixPath"], "code_location": {"file": "typehints.py", "path": "/data3/pwh/swebench-repos/sphinx/tests/roots/test-ext-autodoc/target", "start_line": 59, "end_line": 60}, "code_snippet": "    def path(self) -> pathlib.PurePosixPath:\n        return pathlib.PurePosixPath('/a/b/c')\n", "type": "function"}, {"name": "test_isattributedescriptor", "is_method": false, "class_name": null, "parameters": [], "calls": ["inspect.isattributedescriptor", "inspect.isattributedescriptor", "inspect.isattributedescriptor", "inspect.isattributedescriptor", "inspect.isattributedescriptor", "inspect.isattributedescriptor", "inspect.isattributedescriptor", "inspect.isattributedescriptor", "inspect.isattributedescriptor", "inspect.isattributedescriptor", "_testcapi.instancemethod", "inspect.isattributedescriptor"], "code_location": {"file": "test_util_inspect.py", "path": "/data3/pwh/swebench-repos/sphinx/tests/test_util", "start_line": 876, "end_line": 899}, "code_snippet": "def test_isattributedescriptor() -> None:\n    # fmt: off\n    assert inspect.isattributedescriptor(Base.prop)                      # property\n    assert not inspect.isattributedescriptor(Base.meth)                  # method\n    assert not inspect.isattributedescriptor(Base.staticmeth)            # staticmethod\n    assert not inspect.isattributedescriptor(Base.classmeth)             # classmetho\n    assert not inspect.isattributedescriptor(Descriptor)                 # custom descriptor class\n    assert not inspect.isattributedescriptor(str.join)                   # MethodDescriptorType\n    assert not inspect.isattributedescriptor(object.__init__)            # WrapperDescriptorType\n    assert not inspect.isattributedescriptor(dict.__dict__['fromkeys'])  # ClassMethodDescriptorType\n    assert inspect.isattributedescriptor(types.FrameType.f_locals)       # GetSetDescriptorType\n    assert inspect.isattributedescriptor(datetime.timedelta.days)        # MemberDescriptorType\n    # fmt: on\n\n    try:\n        # _testcapi module cannot be importable in some distro\n        # See: https://github.com/sphinx-doc/sphinx/issues/9868\n        import _testcapi  # type: ignore[import-not-found]\n\n        # instancemethod (C-API)\n        testinstancemethod = _testcapi.instancemethod(str.__repr__)\n        assert not inspect.isattributedescriptor(testinstancemethod)\n    except ImportError:\n        pass\n", "type": "function"}, {"name": "test_isdescriptor", "is_method": false, "class_name": null, "parameters": [], "calls": ["inspect.isdescriptor", "inspect.isdescriptor", "inspect.isdescriptor", "inspect.isdescriptor", "inspect.isdescriptor", "Base", "Base"], "code_location": {"file": "test_util_inspect.py", "path": "/data3/pwh/swebench-repos/sphinx/tests/test_util", "start_line": 866, "end_line": 872}, "code_snippet": "def test_isdescriptor() -> None:\n    # fmt: off\n    assert inspect.isdescriptor(Base.prop)        # property of class\n    assert not inspect.isdescriptor(Base().prop)  # property of instance\n    assert inspect.isdescriptor(Base.meth)        # method of class\n    assert inspect.isdescriptor(Base().meth)      # method of instance\n    assert inspect.isdescriptor(func)             # function\n", "type": "function"}], "retrieved_count": 10, "cost_time": 0.34201979637145996}
{"question": "How does the formatter-returning method in the highlighting bridge class select which formatter class to instantiate based on the destination format?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"name": "ColorizeFormatter", "docstring": "", "methods": ["format"], "attributes": [], "code_location": {"file": "logging.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/util", "start_line": 565, "end_line": 576}, "type": "class"}, {"name": "PygmentsBridge", "docstring": "", "methods": ["__init__", "get_style", "get_formatter", "get_lexer", "highlight_block", "get_stylesheet"], "attributes": ["html_formatter", "latex_formatter"], "code_location": {"file": "highlighting.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx", "start_line": 98, "end_line": 237}, "type": "class"}, {"name": "get_stylesheet", "is_method": true, "class_name": "PygmentsBridge", "parameters": ["self"], "calls": ["self.get_formatter", "formatter.get_style_defs", "formatter.get_style_defs"], "code_location": {"file": "highlighting.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx", "start_line": 232, "end_line": 237}, "code_snippet": "    def get_stylesheet(self) -> str:\n        formatter = self.get_formatter()\n        if self.dest == 'html':\n            return formatter.get_style_defs('.highlight')\n        else:\n            return formatter.get_style_defs() + _LATEX_ADD_STYLES\n", "type": "function"}, {"name": "HighlightLanguageVisitor", "docstring": "", "methods": ["__init__", "unknown_visit", "unknown_departure", "visit_document", "depart_document", "visit_start_of_file", "depart_start_of_file", "visit_highlightlang", "visit_literal_block"], "attributes": [], "code_location": {"file": "code.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/transforms/post_transforms", "start_line": 50, "end_line": 86}, "type": "class"}, {"name": "init_highlighter", "is_method": true, "class_name": "StandaloneHTMLBuilder", "parameters": ["self"], "calls": ["PygmentsBridge", "PygmentsBridge"], "code_location": {"file": "__init__.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/builders/html", "start_line": 238, "end_line": 259}, "code_snippet": "    def init_highlighter(self) -> None:\n        # determine Pygments style and create the highlighter\n        if self.config.pygments_style is not None:\n            style = self.config.pygments_style\n        elif self.theme:\n            # From the ``pygments_style`` theme setting\n            style = self.theme.pygments_style_default or 'none'\n        else:\n            style = 'sphinx'\n        self.highlighter = PygmentsBridge('html', style)\n\n        if self.theme:\n            # From the ``pygments_dark_style`` theme setting\n            dark_style = self.theme.pygments_style_dark\n        else:\n            dark_style = None\n\n        self.dark_highlighter: PygmentsBridge | None\n        if dark_style is not None:\n            self.dark_highlighter = PygmentsBridge('html', dark_style)\n        else:\n            self.dark_highlighter = None\n", "type": "function"}, {"name": "Highlight", "docstring": "Directive to set the highlighting language for code blocks, as well\nas the threshold for line numbers.", "methods": ["run"], "attributes": ["has_content", "required_arguments", "optional_arguments", "final_argument_whitespace"], "code_location": {"file": "code.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/directives", "start_line": 32, "end_line": 56}, "type": "class"}, {"name": "highlight_block", "is_method": true, "class_name": "PygmentsBridge", "parameters": ["self", "source", "lang", "opts", "force", "location"], "calls": ["self.get_lexer", "self.get_formatter", "isinstance", "source.decode", "highlight", "texescape.hlescape", "self.get_lexer", "highlight", "logger.warning", "__", "str"], "code_location": {"file": "highlighting.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx", "start_line": 183, "end_line": 230}, "code_snippet": "    def highlight_block(\n        self,\n        source: str,\n        lang: str,\n        opts: dict[str, Any] | None = None,\n        force: bool = False,\n        location: Any = None,\n        **kwargs: Any,\n    ) -> str:\n        if not isinstance(source, str):\n            source = source.decode()\n\n        lexer = self.get_lexer(source, lang, opts, force, location)\n\n        # highlight via Pygments\n        formatter = self.get_formatter(**kwargs)\n        try:\n            hlsource = highlight(source, lexer, formatter)\n        except ErrorToken as err:\n            # this is most probably not the selected language,\n            # so let it pass un highlighted\n            if lang == 'default':\n                lang = 'none'  # automatic highlighting failed.\n            else:\n                logger.warning(\n                    __(\n                        'Lexing literal_block %r as \"%s\" resulted in an error at token: %r. '\n                        'Retrying in relaxed mode.'\n                    ),\n                    source,\n                    lang,\n                    str(err),\n                    type='misc',\n                    subtype='highlighting_failure',\n                    location=location,\n                )\n                if force:\n                    lang = 'none'\n                else:\n                    force = True\n            lexer = self.get_lexer(source, lang, opts, force, location)\n            hlsource = highlight(source, lexer, formatter)\n\n        if self.dest == 'html':\n            return hlsource\n        else:\n            # MEMO: this is done to escape Unicode chars with non-Unicode engines\n            return texescape.hlescape(hlsource, self.latex_engine)\n", "type": "function"}, {"name": "highlightlang", "docstring": "Inserted to set the highlight language and line number options for\nsubsequent code blocks.", "methods": [], "attributes": [], "code_location": {"file": "addnodes.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx", "start_line": 480, "end_line": 483}, "type": "class"}, {"name": "hl", "is_method": true, "class_name": "ChangesBuilder", "parameters": ["self", "text", "version"], "calls": ["html.escape", "text.replace"], "code_location": {"file": "changes.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/builders", "start_line": 167, "end_line": 178}, "code_snippet": "    def hl(self, text: str, version: str) -> str:\n        text = html.escape(text)\n        for directive in (\n            'versionchanged',\n            'versionadded',\n            'deprecated',\n            'versionremoved',\n        ):\n            text = text.replace(\n                f'.. {directive}:: {version}', f'<b>.. {directive}:: {version}</b>'\n            )\n        return text\n", "type": "function"}, {"name": "write_stylesheet", "is_method": true, "class_name": "LaTeXBuilder", "parameters": ["self"], "calls": ["highlighting.PygmentsBridge", "open", "f.write", "f.write", "f.write", "f.write", "highlighter.get_stylesheet"], "code_location": {"file": "__init__.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/builders/latex", "start_line": 275, "end_line": 287}, "code_snippet": "    def write_stylesheet(self) -> None:\n        highlighter = highlighting.PygmentsBridge('latex', self.config.pygments_style)\n        stylesheet = self.outdir / 'sphinxhighlight.sty'\n        with open(stylesheet, 'w', encoding='utf-8') as f:\n            f.write('\\\\NeedsTeXFormat{LaTeX2e}[1995/12/01]\\n')\n            f.write(\n                '\\\\ProvidesPackage{sphinxhighlight}'\n                '[2022/06/30 stylesheet for highlighting with pygments]\\n'\n            )\n            f.write(\n                '% Its contents depend on pygments_style configuration variable.\\n\\n'\n            )\n            f.write(highlighter.get_stylesheet())\n", "type": "function"}], "retrieved_count": 10, "cost_time": 0.3485560417175293}
{"question": "Where does the C/C++ declaration parser handle and recover from parsing failures when distinguishing cast expressions from unary expressions?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"name": "_parse_cast_expression", "is_method": true, "class_name": "DefinitionParser", "parameters": ["self"], "calls": ["self.skip_ws", "self.skip_string", "self._parse_unary_expression", "self._parse_type", "self._parse_cast_expression", "ASTCastExpr", "self.skip_string", "self.fail", "self._parse_unary_expression", "self._make_multi_error"], "code_location": {"file": "_parser.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/domains/c", "start_line": 332, "end_line": 356}, "code_snippet": "    def _parse_cast_expression(self) -> ASTExpression:\n        # -> unary  | \"(\" type-id \")\" cast\n        pos = self.pos\n        self.skip_ws()\n        if self.skip_string('('):\n            try:\n                typ = self._parse_type(False)\n                if not self.skip_string(')'):\n                    self.fail(\"Expected ')' in cast expression.\")\n                expr = self._parse_cast_expression()\n                return ASTCastExpr(typ, expr)\n            except DefinitionError as ex_cast:\n                self.pos = pos\n                try:\n                    return self._parse_unary_expression()\n                except DefinitionError as ex_unary:\n                    errs = [\n                        (ex_cast, 'If type cast expression'),\n                        (ex_unary, 'If unary expression'),\n                    ]\n                    raise self._make_multi_error(\n                        errs, 'Error in cast expression.'\n                    ) from ex_unary\n        else:\n            return self._parse_unary_expression()\n", "type": "function"}, {"name": "_parse_cast_expression", "is_method": true, "class_name": "DefinitionParser", "parameters": ["self"], "calls": ["self.skip_ws", "self.skip_string", "self._parse_unary_expression", "self._parse_type", "self._parse_cast_expression", "ASTCastExpr", "self.skip_string", "self.fail", "self._parse_unary_expression", "self._make_multi_error"], "code_location": {"file": "_parser.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/domains/cpp", "start_line": 646, "end_line": 670}, "code_snippet": "    def _parse_cast_expression(self) -> ASTExpression:\n        # -> unary  | \"(\" type-id \")\" cast\n        pos = self.pos\n        self.skip_ws()\n        if self.skip_string('('):\n            try:\n                typ = self._parse_type(False)\n                if not self.skip_string(')'):\n                    self.fail(\"Expected ')' in cast expression.\")\n                expr = self._parse_cast_expression()\n                return ASTCastExpr(typ, expr)\n            except DefinitionError as ex_cast:\n                self.pos = pos\n                try:\n                    return self._parse_unary_expression()\n                except DefinitionError as ex_unary:\n                    errs = [\n                        (ex_cast, 'If type cast expression'),\n                        (ex_unary, 'If unary expression'),\n                    ]\n                    raise self._make_multi_error(\n                        errs, 'Error in cast expression.'\n                    ) from ex_unary\n        else:\n            return self._parse_unary_expression()\n", "type": "function"}, {"name": "_parse_unary_expression", "is_method": true, "class_name": "DefinitionParser", "parameters": ["self"], "calls": ["self.skip_ws", "self.skip_word_and_ws", "self.skip_word_and_ws", "self._parse_postfix_expression", "self.skip_string_and_ws", "self._parse_unary_expression", "ASTSizeofExpr", "self._parse_type", "self.skip_ws", "ASTAlignofExpr", "self.skip_word", "self.skip_string", "self._parse_cast_expression", "ASTUnaryOpExpr", "self._parse_type", "self.skip_ws", "ASTSizeofType", "self.skip_string_and_ws", "self.fail", "self.skip_string", "self.fail", "self.skip_string", "self.fail"], "code_location": {"file": "_parser.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/domains/c", "start_line": 294, "end_line": 330}, "code_snippet": "    def _parse_unary_expression(self) -> ASTExpression:\n        # -> postfix\n        #  | \"++\" cast\n        #  | \"--\" cast\n        #  | unary-operator cast -> (* | & | + | - | ! | ~) cast\n        # The rest:\n        #  | \"sizeof\" unary\n        #  | \"sizeof\" \"(\" type-id \")\"\n        #  | \"alignof\" \"(\" type-id \")\"\n        self.skip_ws()\n        for op in _expression_unary_ops:\n            # TODO: hmm, should we be able to backtrack here?\n            if op[0] in 'cn':\n                res = self.skip_word(op)\n            else:\n                res = self.skip_string(op)\n            if res:\n                expr = self._parse_cast_expression()\n                return ASTUnaryOpExpr(op, expr)\n        if self.skip_word_and_ws('sizeof'):\n            if self.skip_string_and_ws('('):\n                typ = self._parse_type(named=False)\n                self.skip_ws()\n                if not self.skip_string(')'):\n                    self.fail(\"Expecting ')' to end 'sizeof'.\")\n                return ASTSizeofType(typ)\n            expr = self._parse_unary_expression()\n            return ASTSizeofExpr(expr)\n        if self.skip_word_and_ws('alignof'):\n            if not self.skip_string_and_ws('('):\n                self.fail(\"Expecting '(' after 'alignof'.\")\n            typ = self._parse_type(named=False)\n            self.skip_ws()\n            if not self.skip_string(')'):\n                self.fail(\"Expecting ')' to end 'alignof'.\")\n            return ASTAlignofExpr(typ)\n        return self._parse_postfix_expression()\n", "type": "function"}, {"name": "_parse_unary_expression", "is_method": true, "class_name": "DefinitionParser", "parameters": ["self"], "calls": ["self.skip_ws", "self.skip_word_and_ws", "self.skip_word_and_ws", "self.skip_word_and_ws", "self.skip_string", "self.skip_ws", "self.skip_string", "self.skip_ws", "self._parse_postfix_expression", "self.skip_string_and_ws", "self.skip_string_and_ws", "self._parse_unary_expression", "ASTSizeofExpr", "self._parse_type", "self.skip_ws", "ASTAlignofExpr", "self._parse_expression", "self.skip_ws", "ASTNoexceptExpr", "self.skip_word_and_ws", "self.skip_string_and_ws", "self._parse_expression_list_or_braced_init_list", "ASTNewExpr", "self.skip_word_and_ws", "self.skip_string_and_ws", "self._parse_cast_expression", "ASTDeleteExpr", "self.skip_word", "self.skip_string", "self._parse_cast_expression", "ASTUnaryOpExpr", "ASTIdentifier", "self.skip_ws", "ASTSizeofParamPack", "self._parse_type", "self.skip_ws", "ASTSizeofType", "self.skip_string_and_ws", "self.fail", "self.skip_string", "self.fail", "self.skip_string_and_ws", "self.fail", "self.skip_string", "self.fail", "self.fail", "self._parse_decl_specs", "self._parse_declarator", "self.fail", "ASTType", "self.fail", "self.skip_string_and_ws", "self.fail", "self.match", "self.fail", "self.skip_string", "self.fail", "self.skip_string", "self.fail", "self.skip_string_and_ws"], "code_location": {"file": "_parser.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/domains/cpp", "start_line": 547, "end_line": 644}, "code_snippet": "    def _parse_unary_expression(self) -> ASTExpression:\n        # -> postfix\n        #  | \"++\" cast\n        #  | \"--\" cast\n        #  | unary-operator cast -> (* | & | + | - | ! | ~) cast\n        # The rest:\n        #  | \"sizeof\" unary\n        #  | \"sizeof\" \"(\" type-id \")\"\n        #  | \"sizeof\" \"...\" \"(\" identifier \")\"\n        #  | \"alignof\" \"(\" type-id \")\"\n        #  | noexcept-expression -> noexcept \"(\" expression \")\"\n        #  | new-expression\n        #  | delete-expression\n        self.skip_ws()\n        for op in _expression_unary_ops:\n            # TODO: hmm, should we be able to backtrack here?\n            if op[0] in 'cn':\n                res = self.skip_word(op)\n            else:\n                res = self.skip_string(op)\n            if res:\n                expr = self._parse_cast_expression()\n                return ASTUnaryOpExpr(op, expr)\n        if self.skip_word_and_ws('sizeof'):\n            if self.skip_string_and_ws('...'):\n                if not self.skip_string_and_ws('('):\n                    self.fail(\"Expecting '(' after 'sizeof...'.\")\n                if not self.match(identifier_re):\n                    self.fail(\"Expecting identifier for 'sizeof...'.\")\n                ident = ASTIdentifier(self.matched_text)\n                self.skip_ws()\n                if not self.skip_string(')'):\n                    self.fail(\"Expecting ')' to end 'sizeof...'.\")\n                return ASTSizeofParamPack(ident)\n            if self.skip_string_and_ws('('):\n                typ = self._parse_type(named=False)\n                self.skip_ws()\n                if not self.skip_string(')'):\n                    self.fail(\"Expecting ')' to end 'sizeof'.\")\n                return ASTSizeofType(typ)\n            expr = self._parse_unary_expression()\n            return ASTSizeofExpr(expr)\n        if self.skip_word_and_ws('alignof'):\n            if not self.skip_string_and_ws('('):\n                self.fail(\"Expecting '(' after 'alignof'.\")\n            typ = self._parse_type(named=False)\n            self.skip_ws()\n            if not self.skip_string(')'):\n                self.fail(\"Expecting ')' to end 'alignof'.\")\n            return ASTAlignofExpr(typ)\n        if self.skip_word_and_ws('noexcept'):\n            if not self.skip_string_and_ws('('):\n                self.fail(\"Expecting '(' after 'noexcept'.\")\n            expr = self._parse_expression()\n            self.skip_ws()\n            if not self.skip_string(')'):\n                self.fail(\"Expecting ')' to end 'noexcept'.\")\n            return ASTNoexceptExpr(expr)\n        # new-expression\n        pos = self.pos\n        rooted = self.skip_string('::')\n        self.skip_ws()\n        if not self.skip_word_and_ws('new'):\n            self.pos = pos\n        else:\n            # new-placement[opt] new-type-id new-initializer[opt]\n            # new-placement[opt] ( type-id ) new-initializer[opt]\n            is_new_type_id = True\n            if self.skip_string_and_ws('('):\n                # either this is a new-placement or it's the second production\n                # without placement, and it's actually the ( type-id ) part\n                self.fail(\n                    'Sorry, neither new-placement nor parenthesised type-id '\n                    'in new-epression is supported yet.'\n                )\n                # set is_new_type_id = False if it's (type-id)\n            if is_new_type_id:\n                decl_specs = self._parse_decl_specs(outer=None)\n                decl = self._parse_declarator(named=False, param_mode='new')\n            else:\n                self.fail(\n                    'Sorry, parenthesised type-id in new expression not yet supported.'\n                )\n            lst = self._parse_expression_list_or_braced_init_list()\n            return ASTNewExpr(rooted, is_new_type_id, ASTType(decl_specs, decl), lst)\n        # delete-expression\n        pos = self.pos\n        rooted = self.skip_string('::')\n        self.skip_ws()\n        if not self.skip_word_and_ws('delete'):\n            self.pos = pos\n        else:\n            array = self.skip_string_and_ws('[')\n            if array and not self.skip_string_and_ws(']'):\n                self.fail(\"Expected ']' in array delete-expression.\")\n            expr = self._parse_cast_expression()\n            return ASTDeleteExpr(rooted, array, expr)\n        return self._parse_postfix_expression()\n", "type": "function"}, {"name": "_parse_declarator", "is_method": true, "class_name": "DefinitionParser", "parameters": ["self", "named", "param_mode", "typed"], "calls": ["self.skip_ws", "Exception", "self.skip_string", "self.skip_ws", "self._parse_declarator", "ASTDeclaratorPtr", "self.skip_string", "self._parse_attribute_list", "self._parse_declarator", "ASTDeclaratorRef", "self.skip_string", "self._parse_declarator", "ASTDeclaratorParamPack", "self._parse_declarator_name_suffix", "self._parse_attribute", "ASTDeclaratorNameParamQual", "self._parse_declarator_name_suffix", "self._parse_nested_name", "self.skip_ws", "self.skip_ws", "self._parse_declarator", "ASTDeclaratorMemPtr", "self.otherErrors.append", "prev_errors.append", "self._make_multi_error", "self.skip_word_and_ws", "self.skip_word_and_ws", "attr_list.append", "ASTAttributeList", "prev_errors.append", "self.skip_string", "self.fail", "prev_errors.append", "self._make_multi_error", "self.skip_string", "self._parse_declarator", "self._parse_declarator", "ASTDeclaratorParen", "self.skip_word_and_ws", "self.skip_word_and_ws", "self.skip_string", "self.fail", "prev_errors.append", "self._make_multi_error"], "code_location": {"file": "_parser.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/domains/cpp", "start_line": 1440, "end_line": 1563}, "code_snippet": "    def _parse_declarator(\n        self, named: bool | str, param_mode: str, typed: bool = True\n    ) -> ASTDeclarator:\n        # 'typed' here means 'parse return type stuff'\n        if param_mode not in {'type', 'function', 'operatorCast', 'new'}:\n            raise Exception(\"Internal error, unknown param_mode '%s'.\" % param_mode)\n        prev_errors = []\n        self.skip_ws()\n        if typed and self.skip_string('*'):\n            self.skip_ws()\n            volatile = False\n            const = False\n            attr_list = []\n            while 1:\n                if not volatile:\n                    volatile = self.skip_word_and_ws('volatile')\n                    if volatile:\n                        continue\n                if not const:\n                    const = self.skip_word_and_ws('const')\n                    if const:\n                        continue\n                attr = self._parse_attribute()\n                if attr is not None:\n                    attr_list.append(attr)\n                    continue\n                break\n            next = self._parse_declarator(named, param_mode, typed)\n            return ASTDeclaratorPtr(\n                next=next,\n                volatile=volatile,\n                const=const,\n                attrs=ASTAttributeList(attr_list),\n            )\n        # TODO: shouldn't we parse an R-value ref here first?\n        if typed and self.skip_string('&'):\n            attrs = self._parse_attribute_list()\n            next = self._parse_declarator(named, param_mode, typed)\n            return ASTDeclaratorRef(next=next, attrs=attrs)\n        if typed and self.skip_string('...'):\n            next = self._parse_declarator(named, param_mode, False)\n            return ASTDeclaratorParamPack(next=next)\n        if typed and self.current_char == '(':  # note: peeking, not skipping\n            if param_mode == 'operatorCast':\n                # TODO: we should be able to parse cast operators which return\n                # function pointers. For now, just hax it and ignore.\n                return ASTDeclaratorNameParamQual(\n                    declId=None, arrayOps=[], paramQual=None\n                )\n            # maybe this is the beginning of params and quals,try that first,\n            # otherwise assume it's noptr->declarator > ( ptr-declarator )\n            pos = self.pos\n            try:\n                # assume this is params and quals\n                res = self._parse_declarator_name_suffix(named, param_mode, typed)\n                return res\n            except DefinitionError as ex_param_qual:\n                prev_errors.append((\n                    ex_param_qual,\n                    'If declarator-id with parameters-and-qualifiers',\n                ))\n                self.pos = pos\n                try:\n                    assert self.current_char == '('\n                    self.skip_string('(')\n                    # TODO: hmm, if there is a name, it must be in inner, right?\n                    # TODO: hmm, if there must be parameters, they must be\n                    #       inside, right?\n                    inner = self._parse_declarator(named, param_mode, typed)\n                    if not self.skip_string(')'):\n                        self.fail('Expected \\')\\' in \"( ptr-declarator )\"')\n                    next = self._parse_declarator(\n                        named=False, param_mode='type', typed=typed\n                    )\n                    return ASTDeclaratorParen(inner=inner, next=next)\n                except DefinitionError as ex_no_ptr_paren:\n                    self.pos = pos\n                    prev_errors.append((\n                        ex_no_ptr_paren,\n                        'If parenthesis in noptr-declarator',\n                    ))\n                    header = 'Error in declarator'\n                    raise self._make_multi_error(\n                        prev_errors, header\n                    ) from ex_no_ptr_paren\n        if typed:  # pointer to member\n            pos = self.pos\n            try:\n                name = self._parse_nested_name(member_pointer=True)\n                self.skip_ws()\n                if not self.skip_string('*'):\n                    self.fail(\"Expected '*' in pointer to member declarator.\")\n                self.skip_ws()\n            except DefinitionError as e:\n                self.pos = pos\n                prev_errors.append((e, 'If pointer to member declarator'))\n            else:\n                volatile = False\n                const = False\n                while 1:\n                    if not volatile:\n                        volatile = self.skip_word_and_ws('volatile')\n                        if volatile:\n                            continue\n                    if not const:\n                        const = self.skip_word_and_ws('const')\n                        if const:\n                            continue\n                    break\n                next = self._parse_declarator(named, param_mode, typed)\n                return ASTDeclaratorMemPtr(name, const, volatile, next=next)\n        pos = self.pos\n        try:\n            res = self._parse_declarator_name_suffix(named, param_mode, typed)\n            # this is a heuristic for error messages, for when there is a < after a\n            # nested name, but it was not a successful template argument list\n            if self.current_char == '<':\n                self.otherErrors.append(self._make_multi_error(prev_errors, ''))\n            return res\n        except DefinitionError as e:\n            self.pos = pos\n            prev_errors.append((e, 'If declarator-id'))\n            header = 'Error in declarator or parameters-and-qualifiers'\n            raise self._make_multi_error(prev_errors, header) from e\n", "type": "function"}, {"name": "_parse_fold_or_paren_expression", "is_method": true, "class_name": "DefinitionParser", "parameters": ["self"], "calls": ["self.skip_ws", "self.skip_string_and_ws", "self.skip_string", "self._parse_cast_expression", "self.skip_ws", "ASTFoldExpr", "self._parse_cast_expression", "ASTFoldExpr", "self.skip_ws", "self._parse_cast_expression", "self.skip_ws", "self.skip_ws", "ASTFoldExpr", "self.match", "self.fail", "self.fail", "self.skip_string", "self.fail", "self.match", "self.fail", "self.skip_string", "self.fail", "self.match", "self.fail", "self.skip_string_and_ws", "self.fail", "ASTParenExpr", "self._parse_expression", "self.skip_ws", "self.skip_string", "self.fail", "self._make_multi_error"], "code_location": {"file": "_parser.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/domains/cpp", "start_line": 239, "end_line": 303}, "code_snippet": "    def _parse_fold_or_paren_expression(self) -> ASTExpression | None:\n        # \"(\" expression \")\"\n        # fold-expression\n        # -> ( cast-expression fold-operator ... )\n        #  | ( ... fold-operator cast-expression )\n        #  | ( cast-expression fold-operator ... fold-operator cast-expression\n        if self.current_char != '(':\n            return None\n        self.pos += 1\n        self.skip_ws()\n        if self.skip_string_and_ws('...'):\n            # ( ... fold-operator cast-expression )\n            if not self.match(_fold_operator_re):\n                self.fail(\"Expected fold operator after '...' in fold expression.\")\n            op = self.matched_text\n            right_expr = self._parse_cast_expression()\n            if not self.skip_string(')'):\n                self.fail(\"Expected ')' in end of fold expression.\")\n            return ASTFoldExpr(None, op, right_expr)\n        # try first parsing a unary right fold, or a binary fold\n        pos = self.pos\n        try:\n            self.skip_ws()\n            left_expr = self._parse_cast_expression()\n            self.skip_ws()\n            if not self.match(_fold_operator_re):\n                self.fail(\n                    'Expected fold operator after left expression in fold expression.'\n                )\n            op = self.matched_text\n            self.skip_ws()\n            if not self.skip_string_and_ws('...'):\n                self.fail(\"Expected '...' after fold operator in fold expression.\")\n        except DefinitionError as e_fold:\n            self.pos = pos\n            # fall back to a paren expression\n            try:\n                res = self._parse_expression()\n                self.skip_ws()\n                if not self.skip_string(')'):\n                    self.fail(\"Expected ')' in end of parenthesized expression.\")\n            except DefinitionError as e_expr:\n                raise self._make_multi_error(\n                    [\n                        (e_fold, 'If fold expression'),\n                        (e_expr, 'If parenthesized expression'),\n                    ],\n                    'Error in fold expression or parenthesized expression.',\n                ) from e_expr\n            return ASTParenExpr(res)\n        # now it definitely is a fold expression\n        if self.skip_string(')'):\n            return ASTFoldExpr(left_expr, op, None)\n        if not self.match(_fold_operator_re):\n            self.fail(\"Expected fold operator or ')' after '...' in fold expression.\")\n        if op != self.matched_text:\n            self.fail(\n                \"Operators are different in binary fold: '%s' and '%s'.\"\n                % (op, self.matched_text)\n            )\n        right_expr = self._parse_cast_expression()\n        self.skip_ws()\n        if not self.skip_string(')'):\n            self.fail(\"Expected ')' to end binary fold expression.\")\n        return ASTFoldExpr(left_expr, op, right_expr)\n", "type": "function"}, {"name": "_parse_postfix_expression", "is_method": true, "class_name": "DefinitionParser", "parameters": ["self"], "calls": ["self.skip_ws", "ASTPostfixExpr", "self.skip_word_and_ws", "self._parse_type", "self.skip_ws", "self._parse_expression_fallback", "self.skip_ws", "ASTExplicitCast", "self.skip_word_and_ws", "self.skip_ws", "self._parse_expression_list_or_braced_init_list", "self.skip_string", "self.fail", "self.skip_string_and_ws", "self.fail", "self.skip_string", "self.fail", "self.skip_string", "self.fail", "self.skip_string_and_ws", "self.skip_string", "self.skip_string", "self.skip_string", "self.skip_string", "post_fixes.append", "self.skip_string_and_ws", "self.fail", "self._parse_type", "ASTTypeId", "self._parse_primary_expression", "self._parse_expression", "self.skip_ws", "post_fixes.append", "self.skip_string", "self.skip_string", "post_fixes.append", "post_fixes.append", "ASTPostfixCallExpr", "self.skip_string", "self.fail", "self.skip_string", "self.fail", "ASTPostfixArray", "self.skip_string", "self._parse_nested_name", "post_fixes.append", "ASTPostfixInc", "ASTPostfixDec", "self._parse_expression_fallback", "ASTTypeId", "self._parse_type", "self.skip_ws", "self._parse_nested_name", "post_fixes.append", "ASTPostfixMemberOfPointer", "self.skip_string", "self.fail", "self._make_multi_error", "self.fail", "self._make_multi_error", "ASTPostfixMember"], "code_location": {"file": "_parser.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/domains/cpp", "start_line": 399, "end_line": 545}, "code_snippet": "    def _parse_postfix_expression(self) -> ASTPostfixExpr:\n        # -> primary\n        #  | postfix \"[\" expression \"]\"\n        #  | postfix \"[\" braced-init-list [opt] \"]\"\n        #  | postfix \"(\" expression-list [opt] \")\"\n        #  | postfix \".\" \"template\" [opt] id-expression\n        #  | postfix \"->\" \"template\" [opt] id-expression\n        #  | postfix \".\" pseudo-destructor-name\n        #  | postfix \"->\" pseudo-destructor-name\n        #  | postfix \"++\"\n        #  | postfix \"--\"\n        #  | simple-type-specifier \"(\" expression-list [opt] \")\"\n        #  | simple-type-specifier braced-init-list\n        #  | typename-specifier \"(\" expression-list [opt] \")\"\n        #  | typename-specifier braced-init-list\n        #  | \"dynamic_cast\" \"<\" type-id \">\" \"(\" expression \")\"\n        #  | \"static_cast\" \"<\" type-id \">\" \"(\" expression \")\"\n        #  | \"reinterpret_cast\" \"<\" type-id \">\" \"(\" expression \")\"\n        #  | \"const_cast\" \"<\" type-id \">\" \"(\" expression \")\"\n        #  | \"typeid\" \"(\" expression \")\"\n        #  | \"typeid\" \"(\" type-id \")\"\n\n        prefix_type = None\n        prefix: Any = None\n        self.skip_ws()\n\n        cast = None\n        for c in _id_explicit_cast:\n            if self.skip_word_and_ws(c):\n                cast = c\n                break\n        if cast is not None:\n            prefix_type = 'cast'\n            if not self.skip_string('<'):\n                self.fail(\"Expected '<' after '%s'.\" % cast)\n            typ = self._parse_type(False)\n            self.skip_ws()\n            if not self.skip_string_and_ws('>'):\n                self.fail(\"Expected '>' after type in '%s'.\" % cast)\n            if not self.skip_string('('):\n                self.fail(\"Expected '(' in '%s'.\" % cast)\n\n            parser = self._parse_expression\n            expr = self._parse_expression_fallback([')'], parser)\n            self.skip_ws()\n            if not self.skip_string(')'):\n                self.fail(\"Expected ')' to end '%s'.\" % cast)\n            prefix = ASTExplicitCast(cast, typ, expr)\n        elif self.skip_word_and_ws('typeid'):\n            prefix_type = 'typeid'\n            if not self.skip_string_and_ws('('):\n                self.fail(\"Expected '(' after 'typeid'.\")\n            pos = self.pos\n            try:\n                typ = self._parse_type(False)\n                prefix = ASTTypeId(typ, isType=True)\n                if not self.skip_string(')'):\n                    self.fail(\"Expected ')' to end 'typeid' of type.\")\n            except DefinitionError as e_type:\n                self.pos = pos\n                try:\n                    parser = self._parse_expression\n                    expr = self._parse_expression_fallback([')'], parser)\n                    prefix = ASTTypeId(expr, isType=False)\n                    if not self.skip_string(')'):\n                        self.fail(\"Expected ')' to end 'typeid' of expression.\")\n                except DefinitionError as e_expr:\n                    self.pos = pos\n                    header = \"Error in 'typeid(...)'.\"\n                    header += ' Expected type or expression.'\n                    errors = [\n                        (e_type, 'If type'),\n                        (e_expr, 'If expression'),\n                    ]\n                    raise self._make_multi_error(errors, header) from e_expr\n        else:  # a primary expression or a type\n            pos = self.pos\n            try:\n                prefix = self._parse_primary_expression()\n                prefix_type = 'expr'\n            except DefinitionError as e_outer:\n                self.pos = pos\n                try:\n                    # we are potentially casting, so save parens for us\n                    # TODO: hmm, would we need to try both with operatorCast and with None?\n                    prefix = self._parse_type(False, 'operatorCast')\n                    prefix_type = 'typeOperatorCast'\n                    #  | simple-type-specifier \"(\" expression-list [opt] \")\"\n                    #  | simple-type-specifier braced-init-list\n                    #  | typename-specifier \"(\" expression-list [opt] \")\"\n                    #  | typename-specifier braced-init-list\n                    self.skip_ws()\n                    if self.current_char not in {'(', '{'}:\n                        self.fail(\"Expecting '(' or '{' after type in cast expression.\")\n                except DefinitionError as e_inner:\n                    self.pos = pos\n                    header = 'Error in postfix expression,'\n                    header += ' expected primary expression or type.'\n                    errors = [\n                        (e_outer, 'If primary expression'),\n                        (e_inner, 'If type'),\n                    ]\n                    raise self._make_multi_error(errors, header) from e_inner\n\n        # and now parse postfixes\n        post_fixes: list[ASTPostfixOp] = []\n        while True:\n            self.skip_ws()\n            if prefix_type in {'expr', 'cast', 'typeid'}:\n                if self.skip_string_and_ws('['):\n                    expr = self._parse_expression()\n                    self.skip_ws()\n                    if not self.skip_string(']'):\n                        self.fail(\"Expected ']' in end of postfix expression.\")\n                    post_fixes.append(ASTPostfixArray(expr))\n                    continue\n                if self.skip_string('.'):\n                    if self.skip_string('*'):\n                        # don't steal the dot\n                        self.pos -= 2\n                    elif self.skip_string('..'):\n                        # don't steal the dot\n                        self.pos -= 3\n                    else:\n                        name = self._parse_nested_name()\n                        post_fixes.append(ASTPostfixMember(name))\n                        continue\n                if self.skip_string('->'):\n                    if self.skip_string('*'):\n                        # don't steal the arrow\n                        self.pos -= 3\n                    else:\n                        name = self._parse_nested_name()\n                        post_fixes.append(ASTPostfixMemberOfPointer(name))\n                        continue\n                if self.skip_string('++'):\n                    post_fixes.append(ASTPostfixInc())\n                    continue\n                if self.skip_string('--'):\n                    post_fixes.append(ASTPostfixDec())\n                    continue\n            lst = self._parse_expression_list_or_braced_init_list()\n            if lst is not None:\n                post_fixes.append(ASTPostfixCallExpr(lst))\n                continue\n            break\n        return ASTPostfixExpr(prefix, post_fixes)\n", "type": "function"}, {"name": "_parse_declarator_name_suffix", "is_method": true, "class_name": "DefinitionParser", "parameters": ["self", "named", "param_mode", "typed"], "calls": ["self._parse_parameters_and_qualifiers", "ASTDeclaratorNameParamQual", "self.skip_ws", "self._parse_nested_name", "self.match", "self.skip_string", "self.skip_ws", "self.skip_string", "self._parse_expression_fallback", "array_ops.append", "len", "self.skip_ws", "self.skip_string", "ASTIdentifier", "ASTNestedNameElement", "ASTNestedName", "self.skip_ws", "self._parse_nested_name", "array_ops.append", "self.skip_string", "self.fail", "ASTArray", "self._parse_constant_expression", "ASTDeclaratorNameBitField", "self.fail", "ASTArray"], "code_location": {"file": "_parser.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/domains/cpp", "start_line": 1386, "end_line": 1438}, "code_snippet": "    def _parse_declarator_name_suffix(\n        self, named: bool | str, param_mode: str, typed: bool\n    ) -> ASTDeclaratorNameParamQual | ASTDeclaratorNameBitField:\n        # now we should parse the name, and then suffixes\n        if named == 'maybe':\n            pos = self.pos\n            try:\n                decl_id = self._parse_nested_name()\n            except DefinitionError:\n                self.pos = pos\n                decl_id = None\n        elif named == 'single':\n            if self.match(identifier_re):\n                identifier = ASTIdentifier(self.matched_text)\n                nne = ASTNestedNameElement(identifier, None)\n                decl_id = ASTNestedName([nne], [False], rooted=False)\n                # if it's a member pointer, we may have '::', which should be an error\n                self.skip_ws()\n                if self.current_char == ':':\n                    self.fail(\"Unexpected ':' after identifier.\")\n            else:\n                decl_id = None\n        elif named:\n            decl_id = self._parse_nested_name()\n        else:\n            decl_id = None\n        array_ops = []\n        while 1:\n            self.skip_ws()\n            if typed and self.skip_string('['):\n                self.skip_ws()\n                if self.skip_string(']'):\n                    array_ops.append(ASTArray(None))\n                    continue\n\n                parser = self._parse_expression\n                value = self._parse_expression_fallback([']'], parser)\n                if not self.skip_string(']'):\n                    self.fail(\"Expected ']' in end of array operator.\")\n                array_ops.append(ASTArray(value))\n                continue\n            break\n        param_qual = self._parse_parameters_and_qualifiers(param_mode)\n        if param_qual is None and len(array_ops) == 0:\n            # perhaps a bit-field\n            if named and param_mode == 'type' and typed:\n                self.skip_ws()\n                if self.skip_string(':'):\n                    size = self._parse_constant_expression(in_template=False)\n                    return ASTDeclaratorNameBitField(declId=decl_id, size=size)\n        return ASTDeclaratorNameParamQual(\n            declId=decl_id, arrayOps=array_ops, paramQual=param_qual\n        )\n", "type": "function"}, {"name": "_parse_operator", "is_method": true, "class_name": "DefinitionParser", "parameters": ["self"], "calls": ["self.skip_ws", "self.match", "self.skip_string", "self._parse_type", "ASTOperatorType", "ASTOperatorBuildIn", "self.skip_ws", "self.skip_string", "ASTOperatorBuildIn", "self.skip_ws", "ASTIdentifier", "ASTOperatorLiteral", "self.skip_word", "self.skip_ws", "self.match", "self.fail", "self.skip_string", "self.fail"], "code_location": {"file": "_parser.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/domains/cpp", "start_line": 850, "end_line": 880}, "code_snippet": "    def _parse_operator(self) -> ASTOperator:\n        self.skip_ws()\n        # adapted from the old code\n        # yay, a regular operator definition\n        if self.match(_operator_re):\n            return ASTOperatorBuildIn(self.matched_text)\n\n        # new/delete operator?\n        for op in 'new', 'delete':\n            if not self.skip_word(op):\n                continue\n            self.skip_ws()\n            if self.skip_string('['):\n                self.skip_ws()\n                if not self.skip_string(']'):\n                    self.fail('Expected \"]\" after  \"operator ' + op + '[\"')\n                op += '[]'\n            return ASTOperatorBuildIn(op)\n\n        # user-defined literal?\n        if self.skip_string('\"\"'):\n            self.skip_ws()\n            if not self.match(identifier_re):\n                self.fail('Expected user-defined literal suffix.')\n            identifier = ASTIdentifier(self.matched_text)\n            return ASTOperatorLiteral(identifier)\n\n        # oh well, looks like a cast operator definition.\n        # In that case, eat another type.\n        type = self._parse_type(named=False, outer='operatorCast')\n        return ASTOperatorType(type)\n", "type": "function"}, {"name": "_parse_declarator", "is_method": true, "class_name": "DefinitionParser", "parameters": ["self", "named", "param_mode", "typed"], "calls": ["self.skip_ws", "Exception", "self.skip_string", "self.skip_ws", "self._parse_declarator", "ASTDeclaratorPtr", "self._parse_declarator_name_suffix", "self._parse_attribute", "self._parse_declarator_name_suffix", "prev_errors.append", "self._make_multi_error", "self.skip_word_and_ws", "self.skip_word_and_ws", "self.skip_word_and_ws", "attrs.append", "ASTAttributeList", "prev_errors.append", "self.skip_string", "self._parse_declarator", "self._parse_declarator", "ASTDeclaratorParen", "self.skip_string", "self.fail", "prev_errors.append", "self._make_multi_error"], "code_location": {"file": "_parser.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/domains/c", "start_line": 778, "end_line": 862}, "code_snippet": "    def _parse_declarator(\n        self, named: bool | str, param_mode: str, typed: bool = True\n    ) -> ASTDeclarator:\n        # 'typed' here means 'parse return type stuff'\n        if param_mode not in {'type', 'function'}:\n            raise Exception(\"Internal error, unknown param_mode '%s'.\" % param_mode)\n        prev_errors = []\n        self.skip_ws()\n        if typed and self.skip_string('*'):\n            self.skip_ws()\n            restrict = False\n            volatile = False\n            const = False\n            attrs = []\n            while 1:\n                if not restrict:\n                    restrict = self.skip_word_and_ws('restrict')\n                    if restrict:\n                        continue\n                if not volatile:\n                    volatile = self.skip_word_and_ws('volatile')\n                    if volatile:\n                        continue\n                if not const:\n                    const = self.skip_word_and_ws('const')\n                    if const:\n                        continue\n                attr = self._parse_attribute()\n                if attr is not None:\n                    attrs.append(attr)\n                    continue\n                break\n            next = self._parse_declarator(named, param_mode, typed)\n            return ASTDeclaratorPtr(\n                next=next,\n                restrict=restrict,\n                volatile=volatile,\n                const=const,\n                attrs=ASTAttributeList(attrs),\n            )\n        if typed and self.current_char == '(':  # note: peeking, not skipping\n            # maybe this is the beginning of params, try that first,\n            # otherwise assume it's noptr->declarator > ( ptr-declarator )\n            pos = self.pos\n            try:\n                # assume this is params\n                res = self._parse_declarator_name_suffix(named, param_mode, typed)\n                return res\n            except DefinitionError as ex_param_qual:\n                msg = 'If declarator-id with parameters'\n                if param_mode == 'function':\n                    msg += \" (e.g., 'void f(int arg)')\"\n                prev_errors.append((ex_param_qual, msg))\n                self.pos = pos\n                try:\n                    assert self.current_char == '('\n                    self.skip_string('(')\n                    # TODO: hmm, if there is a name, it must be in inner, right?\n                    # TODO: hmm, if there must be parameters, they must b\n                    # inside, right?\n                    inner = self._parse_declarator(named, param_mode, typed)\n                    if not self.skip_string(')'):\n                        self.fail('Expected \\')\\' in \"( ptr-declarator )\"')\n                    next = self._parse_declarator(\n                        named=False, param_mode='type', typed=typed\n                    )\n                    return ASTDeclaratorParen(inner=inner, next=next)\n                except DefinitionError as ex_no_ptr_paren:\n                    self.pos = pos\n                    msg = 'If parenthesis in noptr-declarator'\n                    if param_mode == 'function':\n                        msg += \" (e.g., 'void (*f(int arg))(double)')\"\n                    prev_errors.append((ex_no_ptr_paren, msg))\n                    header = 'Error in declarator'\n                    raise self._make_multi_error(\n                        prev_errors, header\n                    ) from ex_no_ptr_paren\n        pos = self.pos\n        try:\n            return self._parse_declarator_name_suffix(named, param_mode, typed)\n        except DefinitionError as e:\n            self.pos = pos\n            prev_errors.append((e, 'If declarator-id'))\n            header = 'Error in declarator or parameters'\n            raise self._make_multi_error(prev_errors, header) from e\n", "type": "function"}], "retrieved_count": 10, "cost_time": 0.3559141159057617}
{"question": "What architectural separation does the initialization method in the builder class that generates Texinfo output establish between loading document configuration and early setup that prepares empty data structures within sequential processing phases?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"name": "init", "is_method": true, "class_name": "StandaloneHTMLBuilder", "parameters": ["self"], "calls": ["self.create_build_info", "self.init_templates", "self.init_highlighter", "self.init_css_files", "self.init_js_files", "self.get_builder_config", "self.get_builder_config", "self.get_builder_config"], "code_location": {"file": "__init__.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/builders/html", "start_line": 163, "end_line": 187}, "code_snippet": "    def init(self) -> None:\n        self.build_info = self.create_build_info()\n        # basename of images directory\n        self.imagedir = '_images'\n        # section numbers for headings in the currently visited document\n        self.secnumbers: dict[str, tuple[int, ...]] = {}\n        # currently written docname\n        self.current_docname: str = ''\n\n        self.init_templates()\n        self.init_highlighter()\n        self.init_css_files()\n        self.init_js_files()\n\n        html_file_suffix = self.get_builder_config('file_suffix', 'html')\n        if html_file_suffix is not None:\n            self.out_suffix = html_file_suffix\n\n        html_link_suffix = self.get_builder_config('link_suffix', 'html')\n        if html_link_suffix is not None:\n            self.link_suffix = html_link_suffix\n        else:\n            self.link_suffix = self.out_suffix\n\n        self.use_index = self.get_builder_config('use_index', 'html')\n", "type": "function"}, {"name": "prepare_writing", "is_method": true, "class_name": "TexinfoBuilder", "parameters": ["self", "_docnames"], "calls": ["list", "logger.warning", "self.document_data.append", "docname.removesuffix", "self.titles.append", "__", "logger.warning", "__"], "code_location": {"file": "texinfo.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/builders", "start_line": 68, "end_line": 93}, "code_snippet": "    def prepare_writing(self, _docnames: Set[str]) -> None:\n        preliminary_document_data = [list(x) for x in self.config.texinfo_documents]\n        if not preliminary_document_data:\n            logger.warning(\n                __(\n                    'no \"texinfo_documents\" config value found; no documents '\n                    'will be written'\n                )\n            )\n            return\n        # assign subdirs to titles\n        self.titles: list[tuple[str, str]] = []\n        for entry in preliminary_document_data:\n            docname = entry[0]\n            if docname not in self.env.all_docs:\n                logger.warning(\n                    __(\n                        '\"texinfo_documents\" config value references unknown '\n                        'document %s'\n                    ),\n                    docname,\n                )\n                continue\n            self.document_data.append(entry)  # type: ignore[arg-type]\n            docname = docname.removesuffix(SEP + 'index')\n            self.titles.append((docname, entry[2]))\n", "type": "function"}, {"name": "init", "is_method": true, "class_name": "LaTeXBuilder", "parameters": ["self"], "calls": ["ThemeFactory", "texescape.init", "self.init_context", "self.init_babel", "self.init_multilingual"], "code_location": {"file": "__init__.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/builders/latex", "start_line": 127, "end_line": 137}, "code_snippet": "    def init(self) -> None:\n        self.babel: ExtBabel\n        self.context: dict[str, Any] = {}\n        self.docnames: Iterable[str] = {}\n        self.document_data: list[tuple[str, str, str, str, str, bool]] = []\n        self.themes = ThemeFactory(srcdir=self.srcdir, config=self.config)\n        texescape.init()\n\n        self.init_context()\n        self.init_babel()\n        self.init_multilingual()\n", "type": "function"}, {"name": "__init__", "is_method": true, "class_name": "TexinfoWriter", "parameters": ["self", "builder"], "calls": ["__init__", "super"], "code_location": {"file": "texinfo.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/writers", "start_line": 130, "end_line": 132}, "code_snippet": "    def __init__(self, builder: TexinfoBuilder) -> None:\n        super().__init__()\n        self.builder = builder\n", "type": "function"}, {"name": "init_document_data", "is_method": true, "class_name": "LaTeXBuilder", "parameters": ["self"], "calls": ["list", "logger.warning", "self.document_data.append", "docname.removesuffix", "self.titles.append", "__", "logger.warning", "__"], "code_location": {"file": "__init__.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/builders/latex", "start_line": 151, "end_line": 173}, "code_snippet": "    def init_document_data(self) -> None:\n        preliminary_document_data = [list(x) for x in self.config.latex_documents]\n        if not preliminary_document_data:\n            logger.warning(\n                __(\n                    'no \"latex_documents\" config value found; no documents '\n                    'will be written'\n                )\n            )\n            return\n        # assign subdirs to titles\n        self.titles: list[tuple[str, str]] = []\n        for entry in preliminary_document_data:\n            docname = entry[0]\n            if docname not in self.env.all_docs:\n                logger.warning(\n                    __('\"latex_documents\" config value references unknown document %s'),\n                    docname,\n                )\n                continue\n            self.document_data.append(entry)  # type: ignore[arg-type]\n            docname = docname.removesuffix(SEP + 'index')\n            self.titles.append((docname, entry[2]))\n", "type": "function"}, {"name": "init_settings", "is_method": true, "class_name": "TexinfoTranslator", "parameters": ["self"], "calls": ["self.default_elements.copy", "elements.update", "elements.update", "_", "format_date", "self.document.next_node", "self.escape_id", "self.format_menu_entry", "self.escape", "self.escape", "self.escape", "self.escape", "title_node.astext", "self.document.get", "self.escape_menu", "self.escape_arg", "self.escape_id"], "code_location": {"file": "texinfo.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/writers", "start_line": 219, "end_line": 261}, "code_snippet": "    def init_settings(self) -> None:\n        today_fmt = self.config.today_fmt or _('%b %d, %Y')\n        today = self.config.today or format_date(\n            today_fmt, language=self.config.language\n        )\n        elements = self.elements = self.default_elements.copy()\n        elements.update({\n            # if empty, the title is set to the first section title\n            'title': self.settings.title,\n            'author': self.settings.author,\n            # if empty, use basename of input file\n            'filename': self.settings.texinfo_filename,\n            'release': self.escape(self.config.release),\n            'project': self.escape(self.config.project),\n            'copyright': self.escape(self.config.copyright),\n            'date': self.escape(today),\n        })\n        # title\n        title: str = self.settings.title\n        if not title:\n            title_node = self.document.next_node(nodes.title)\n            title = title_node.astext() if title_node else '<untitled>'\n        elements['title'] = self.escape_id(title) or '<untitled>'\n        # filename\n        if not elements['filename']:\n            elements['filename'] = self.document.get('source') or 'untitled'\n            if elements['filename'][-4:] in {'.txt', '.rst'}:  # type: ignore[index]\n                elements['filename'] = elements['filename'][:-4]  # type: ignore[index]\n            elements['filename'] += '.info'  # type: ignore[operator]\n        # direntry\n        if self.settings.texinfo_dir_entry:\n            entry = self.format_menu_entry(\n                self.escape_menu(self.settings.texinfo_dir_entry),\n                '(%s)' % elements['filename'],\n                self.escape_arg(self.settings.texinfo_dir_description),\n            )\n            elements['direntry'] = '@dircategory %s\\n@direntry\\n%s@end direntry\\n' % (\n                self.escape_id(self.settings.texinfo_dir_category),\n                entry,\n            )\n        elements['copying'] = COPYING % elements\n        # allow the user to override them all\n        elements.update(self.settings.texinfo_elements)\n", "type": "function"}, {"name": "init", "is_method": true, "class_name": "EpubBuilder", "parameters": ["self"], "calls": ["init", "self.get_builder_config", "super"], "code_location": {"file": "_epub_base.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/builders", "start_line": 165, "end_line": 174}, "code_snippet": "    def init(self) -> None:\n        super().init()\n        # the output files for epub must be .html only\n        self.out_suffix = '.xhtml'\n        self.link_suffix = '.xhtml'\n        self.playorder = 0\n        self.tocid = 0\n        self.id_cache: dict[str, str] = {}\n        self.use_index = self.get_builder_config('use_index', 'epub')\n        self.refnodes: list[dict[str, Any]] = []\n", "type": "function"}, {"name": "init", "is_method": true, "class_name": "TexinfoBuilder", "parameters": ["self"], "calls": [], "code_location": {"file": "texinfo.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/builders", "start_line": 52, "end_line": 54}, "code_snippet": "    def init(self) -> None:\n        self.docnames: Iterable[str] = []\n        self.document_data: list[tuple[str, str, str, str, str, str, str, bool]] = []\n", "type": "function"}, {"name": "__init__", "is_method": true, "class_name": "TexinfoTranslator", "parameters": ["self", "document", "builder"], "calls": ["__init__", "self.init_settings", "set", "set", "self.collect_indices", "self.collect_node_names", "self.collect_node_menus", "self.collect_rellinks", "set", "set", "super"], "code_location": {"file": "texinfo.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/writers", "start_line": 163, "end_line": 196}, "code_snippet": "    def __init__(self, document: nodes.document, builder: TexinfoBuilder) -> None:\n        super().__init__(document, builder)\n        self.init_settings()\n\n        self.written_ids: set[str] = set()  # node names and anchors in output\n        # node names and anchors that should be in output\n        self.referenced_ids: set[str] = set()\n        self.indices: list[tuple[str, str]] = []  # (node name, content)\n        self.short_ids: dict[str, str] = {}  # anchors --> short ids\n        self.node_names: dict[str, str] = {}  # node name --> node's name to display\n        self.node_menus: dict[str, list[str]] = {}  # node name --> node's menu entries\n        self.rellinks: dict[str, list[str]] = {}  # node name --> (next, previous, up)\n\n        self.collect_indices()\n        self.collect_node_names()\n        self.collect_node_menus()\n        self.collect_rellinks()\n\n        self.body: list[str] = []\n        self.context: list[str] = []\n        self.descs: list[addnodes.desc] = []\n        self.previous_section: nodes.section | None = None\n        self.section_level = 0\n        self.seen_title = False\n        self.next_section_ids: set[str] = set()\n        self.escape_newlines = 0\n        self.escape_hyphens = 0\n        self.curfilestack: list[str] = []\n        self.footnotestack: list[dict[str, list[collected_footnote | bool]]] = []\n        self.in_production_list = False\n        self.in_footnote = 0\n        self.in_samp = 0\n        self.handled_abbrs: set[str] = set()\n        self.colwidths: list[int] = []\n", "type": "function"}, {"name": "init", "is_method": true, "class_name": "TextBuilder", "parameters": ["self"], "calls": [], "code_location": {"file": "text.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/builders", "start_line": 35, "end_line": 37}, "code_snippet": "    def init(self) -> None:\n        # section numbers for headings in the currently visited document\n        self.secnumbers: dict[str, tuple[int, ...]] = {}\n", "type": "function"}], "retrieved_count": 10, "cost_time": 0.33797144889831543}
{"question": "Where does invoking the line termination method before the parent class footnote visitor affect the manual page translator output buffer state?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"name": "visit_footnote", "is_method": true, "class_name": "ManualPageTranslator", "parameters": ["self", "node"], "calls": ["self.ensure_eol", "visit_footnote", "super"], "code_location": {"file": "manpage.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/writers", "start_line": 251, "end_line": 253}, "code_snippet": "    def visit_footnote(self, node: nodes.footnote) -> None:\n        self.ensure_eol()\n        super().visit_footnote(node)\n", "type": "function"}, {"name": "depart_footnote", "is_method": true, "class_name": "LaTeXTranslator", "parameters": ["self", "node"], "calls": ["self.body.append", "self.body.append", "self.body.append"], "code_location": {"file": "latex.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/writers", "start_line": 1154, "end_line": 1160}, "code_snippet": "    def depart_footnote(self, node: Element) -> None:\n        if self.in_parsed_literal:\n            self.body.append(r'\\end{footnote}')\n        else:\n            self.body.append('%' + CR)\n            self.body.append(r'\\end{footnote}')\n        self.in_footnote -= 1\n", "type": "function"}, {"name": "depart_footnotetext", "is_method": true, "class_name": "LaTeXTranslator", "parameters": ["self", "node"], "calls": ["self.body.append", "self.body.append"], "code_location": {"file": "latex.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/writers", "start_line": 2195, "end_line": 2198}, "code_snippet": "    def depart_footnotetext(self, node: Element) -> None:\n        # the \\ignorespaces in particular for after table header use\n        self.body.append('%' + CR)\n        self.body.append(r'\\end{footnotetext}\\ignorespaces ')\n", "type": "function"}, {"name": "visit_footnote", "is_method": true, "class_name": "TextTranslator", "parameters": ["self", "node"], "calls": ["cast", "strip", "self.new_state", "label.astext", "len"], "code_location": {"file": "text.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/writers", "start_line": 803, "end_line": 806}, "code_snippet": "    def visit_footnote(self, node: Element) -> None:\n        label = cast('nodes.label', node[0])\n        self._footnote = label.astext().strip()\n        self.new_state(len(self._footnote) + 3)\n", "type": "function"}, {"name": "depart_footnote", "is_method": true, "class_name": "TextTranslator", "parameters": ["self", "node"], "calls": ["self.end_state"], "code_location": {"file": "text.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/writers", "start_line": 808, "end_line": 809}, "code_snippet": "    def depart_footnote(self, node: Element) -> None:\n        self.end_state(first='[%s] ' % self._footnote)\n", "type": "function"}, {"name": "visit_footnotetext", "is_method": true, "class_name": "LaTeXTranslator", "parameters": ["self", "node"], "calls": ["cast", "self.body.append", "self.body.append", "self.body.append", "label.astext"], "code_location": {"file": "latex.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/writers", "start_line": 2189, "end_line": 2193}, "code_snippet": "    def visit_footnotetext(self, node: Element) -> None:\n        label = cast('nodes.label', node[0])\n        self.body.append('%' + CR)\n        self.body.append(r'\\begin{footnotetext}[%s]' % label.astext())\n        self.body.append(r'\\sphinxAtStartFootnote' + CR)\n", "type": "function"}, {"name": "visit_collected_footnote", "is_method": true, "class_name": "TexinfoTranslator", "parameters": ["self", "node"], "calls": ["self.body.append"], "code_location": {"file": "texinfo.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/writers", "start_line": 878, "end_line": 880}, "code_snippet": "    def visit_collected_footnote(self, node: Element) -> None:\n        self.in_footnote += 1\n        self.body.append('@footnote{')\n", "type": "function"}, {"name": "visit_footnote", "is_method": true, "class_name": "LaTeXTranslator", "parameters": ["self", "node"], "calls": ["cast", "self.body.append", "self.body.append", "self.body.append", "self.body.append", "label.astext", "label.astext"], "code_location": {"file": "latex.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/writers", "start_line": 1141, "end_line": 1152}, "code_snippet": "    def visit_footnote(self, node: Element) -> None:\n        self.in_footnote += 1\n        label = cast('nodes.label', node[0])\n        if self.in_parsed_literal:\n            self.body.append(r'\\begin{footnote}[%s]' % label.astext())\n        else:\n            self.body.append('%' + CR)\n            self.body.append(r'\\begin{footnote}[%s]' % label.astext())\n        if 'referred' in node:\n            # TODO: in future maybe output a latex macro with backrefs here\n            pass\n        self.body.append(r'\\sphinxAtStartFootnote' + CR)\n", "type": "function"}, {"name": "visit_footnote", "is_method": true, "class_name": "LaTeXFootnoteVisitor", "parameters": ["self", "node"], "calls": ["self.restrict"], "code_location": {"file": "transforms.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/builders/latex", "start_line": 450, "end_line": 451}, "code_snippet": "    def visit_footnote(self, node: nodes.footnote) -> None:\n        self.restrict(node)\n", "type": "function"}, {"name": "depart_footnote", "is_method": true, "class_name": "LaTeXFootnoteVisitor", "parameters": ["self", "node"], "calls": ["self.unrestrict"], "code_location": {"file": "transforms.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/builders/latex", "start_line": 453, "end_line": 454}, "code_snippet": "    def depart_footnote(self, node: nodes.footnote) -> None:\n        self.unrestrict(node)\n", "type": "function"}], "retrieved_count": 10, "cost_time": 0.3611574172973633}
{"question": "What is the propagation mechanism of the return value of the boolean method that determines spacing requirements after type specification sequences through the abstract syntax tree node hierarchy of declarator wrappers that influences whitespace insertion decisions in type declaration formatting?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"name": "require_space_after_declSpecs", "is_method": true, "class_name": "ASTDeclaratorRef", "parameters": ["self"], "calls": ["self.next.require_space_after_declSpecs"], "code_location": {"file": "_ast.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/domains/cpp", "start_line": 2945, "end_line": 2946}, "code_snippet": "    def require_space_after_declSpecs(self) -> bool:\n        return self.next.require_space_after_declSpecs()\n", "type": "function"}, {"name": "require_space_after_declSpecs", "is_method": true, "class_name": "ASTDeclaratorPtr", "parameters": ["self"], "calls": ["self.next.require_space_after_declSpecs"], "code_location": {"file": "_ast.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/domains/cpp", "start_line": 2832, "end_line": 2833}, "code_snippet": "    def require_space_after_declSpecs(self) -> bool:\n        return self.next.require_space_after_declSpecs()\n", "type": "function"}, {"name": "require_space_after_declSpecs", "is_method": true, "class_name": "ASTDeclaratorPtr", "parameters": ["self"], "calls": ["self.next.require_space_after_declSpecs", "len"], "code_location": {"file": "_ast.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/domains/c", "start_line": 1337, "end_line": 1344}, "code_snippet": "    def require_space_after_declSpecs(self) -> bool:\n        return (\n            self.const\n            or self.volatile\n            or self.restrict\n            or len(self.attrs) > 0\n            or self.next.require_space_after_declSpecs()\n        )\n", "type": "function"}, {"name": "require_space_after_declSpecs", "is_method": true, "class_name": "ASTDeclaratorNameParam", "parameters": ["self"], "calls": [], "code_location": {"file": "_ast.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/domains/c", "start_line": 1234, "end_line": 1235}, "code_snippet": "    def require_space_after_declSpecs(self) -> bool:\n        return self.declId is not None\n", "type": "function"}, {"name": "require_space_after_declSpecs", "is_method": true, "class_name": "ASTDeclaratorNameBitField", "parameters": ["self"], "calls": [], "code_location": {"file": "_ast.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/domains/cpp", "start_line": 2764, "end_line": 2765}, "code_snippet": "    def require_space_after_declSpecs(self) -> bool:\n        return self.declId is not None\n", "type": "function"}, {"name": "require_space_after_declSpecs", "is_method": true, "class_name": "ASTDeclaratorNameParamQual", "parameters": ["self"], "calls": [], "code_location": {"file": "_ast.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/domains/cpp", "start_line": 2708, "end_line": 2709}, "code_snippet": "    def require_space_after_declSpecs(self) -> bool:\n        return self.declId is not None\n", "type": "function"}, {"name": "require_space_after_declSpecs", "is_method": true, "class_name": "ASTDeclaratorNameBitField", "parameters": ["self"], "calls": [], "code_location": {"file": "_ast.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/domains/c", "start_line": 1277, "end_line": 1278}, "code_snippet": "    def require_space_after_declSpecs(self) -> bool:\n        return self.declId is not None\n", "type": "function"}, {"name": "require_space_after_declSpecs", "is_method": true, "class_name": "ASTDeclaratorParen", "parameters": ["self"], "calls": [], "code_location": {"file": "_ast.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/domains/c", "start_line": 1418, "end_line": 1419}, "code_snippet": "    def require_space_after_declSpecs(self) -> bool:\n        return True\n", "type": "function"}, {"name": "require_space_after_declSpecs", "is_method": true, "class_name": "ASTDeclaratorParen", "parameters": ["self"], "calls": [], "code_location": {"file": "_ast.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/domains/cpp", "start_line": 3209, "end_line": 3210}, "code_snippet": "    def require_space_after_declSpecs(self) -> bool:\n        return True\n", "type": "function"}, {"name": "require_space_after_declSpecs", "is_method": true, "class_name": "ASTDeclaratorMemPtr", "parameters": ["self"], "calls": [], "code_location": {"file": "_ast.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/domains/cpp", "start_line": 3102, "end_line": 3103}, "code_snippet": "    def require_space_after_declSpecs(self) -> bool:\n        return True\n", "type": "function"}], "retrieved_count": 10, "cost_time": 0.37169313430786133}
{"question": "What is the semantic significance of the processing order where the declarator following parentheses is processed before the declarator inside parentheses in the type identifier generation method for parenthesized C++ declarators?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"name": "get_type_id", "is_method": true, "class_name": "ASTDeclaratorPtr", "parameters": ["self", "version", "returnTypeId"], "calls": ["res.append", "self.next.get_type_id", "res.append", "res.append", "join"], "code_location": {"file": "_ast.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/domains/cpp", "start_line": 2874, "end_line": 2882}, "code_snippet": "    def get_type_id(self, version: int, returnTypeId: str) -> str:\n        # ReturnType *next, so we are part of the return type of 'next\n        res = ['P']\n        if self.volatile:\n            res.append('V')\n        if self.const:\n            res.append('C')\n        res.append(returnTypeId)\n        return self.next.get_type_id(version, returnTypeId=''.join(res))\n", "type": "function"}, {"name": "__init__", "is_method": true, "class_name": "ASTDeclaratorParen", "parameters": ["self", "inner", "next"], "calls": [], "code_location": {"file": "_ast.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/domains/cpp", "start_line": 3174, "end_line": 3178}, "code_snippet": "    def __init__(self, inner: ASTDeclarator, next: ASTDeclarator) -> None:\n        assert inner\n        assert next\n        self.inner = inner\n        self.next = next\n", "type": "function"}, {"name": "__init__", "is_method": true, "class_name": "ASTDeclaratorParen", "parameters": ["self", "inner", "next"], "calls": [], "code_location": {"file": "_ast.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/domains/c", "start_line": 1395, "end_line": 1399}, "code_snippet": "    def __init__(self, inner: ASTDeclarator, next: ASTDeclarator) -> None:\n        assert inner\n        assert next\n        self.inner = inner\n        self.next = next\n", "type": "function"}, {"name": "paren_attributes", "is_method": true, "class_name": "DefinitionParser", "parameters": ["self"], "calls": [], "code_location": {"file": "_parser.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/domains/cpp", "start_line": 149, "end_line": 150}, "code_snippet": "    def paren_attributes(self) -> Sequence[str]:\n        return self.config.cpp_paren_attributes\n", "type": "function"}, {"name": "get_type_declaration_prefix", "is_method": true, "class_name": "ASTType", "parameters": ["self"], "calls": [], "code_location": {"file": "_ast.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/domains/cpp", "start_line": 3458, "end_line": 3462}, "code_snippet": "    def get_type_declaration_prefix(self) -> str:\n        if self.declSpecs.trailingTypeSpec:\n            return 'typedef'\n        else:\n            return 'type'\n", "type": "function"}, {"name": "get_type_declaration_prefix", "is_method": true, "class_name": "ASTType", "parameters": ["self"], "calls": [], "code_location": {"file": "_ast.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/domains/c", "start_line": 1580, "end_line": 1584}, "code_snippet": "    def get_type_declaration_prefix(self) -> str:\n        if self.declSpecs.trailingTypeSpec:\n            return 'typedef'\n        else:\n            return 'type'\n", "type": "function"}, {"name": "_parse_declarator", "is_method": true, "class_name": "DefinitionParser", "parameters": ["self", "named", "param_mode", "typed"], "calls": ["self.skip_ws", "Exception", "self.skip_string", "self.skip_ws", "self._parse_declarator", "ASTDeclaratorPtr", "self.skip_string", "self._parse_attribute_list", "self._parse_declarator", "ASTDeclaratorRef", "self.skip_string", "self._parse_declarator", "ASTDeclaratorParamPack", "self._parse_declarator_name_suffix", "self._parse_attribute", "ASTDeclaratorNameParamQual", "self._parse_declarator_name_suffix", "self._parse_nested_name", "self.skip_ws", "self.skip_ws", "self._parse_declarator", "ASTDeclaratorMemPtr", "self.otherErrors.append", "prev_errors.append", "self._make_multi_error", "self.skip_word_and_ws", "self.skip_word_and_ws", "attr_list.append", "ASTAttributeList", "prev_errors.append", "self.skip_string", "self.fail", "prev_errors.append", "self._make_multi_error", "self.skip_string", "self._parse_declarator", "self._parse_declarator", "ASTDeclaratorParen", "self.skip_word_and_ws", "self.skip_word_and_ws", "self.skip_string", "self.fail", "prev_errors.append", "self._make_multi_error"], "code_location": {"file": "_parser.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/domains/cpp", "start_line": 1440, "end_line": 1563}, "code_snippet": "    def _parse_declarator(\n        self, named: bool | str, param_mode: str, typed: bool = True\n    ) -> ASTDeclarator:\n        # 'typed' here means 'parse return type stuff'\n        if param_mode not in {'type', 'function', 'operatorCast', 'new'}:\n            raise Exception(\"Internal error, unknown param_mode '%s'.\" % param_mode)\n        prev_errors = []\n        self.skip_ws()\n        if typed and self.skip_string('*'):\n            self.skip_ws()\n            volatile = False\n            const = False\n            attr_list = []\n            while 1:\n                if not volatile:\n                    volatile = self.skip_word_and_ws('volatile')\n                    if volatile:\n                        continue\n                if not const:\n                    const = self.skip_word_and_ws('const')\n                    if const:\n                        continue\n                attr = self._parse_attribute()\n                if attr is not None:\n                    attr_list.append(attr)\n                    continue\n                break\n            next = self._parse_declarator(named, param_mode, typed)\n            return ASTDeclaratorPtr(\n                next=next,\n                volatile=volatile,\n                const=const,\n                attrs=ASTAttributeList(attr_list),\n            )\n        # TODO: shouldn't we parse an R-value ref here first?\n        if typed and self.skip_string('&'):\n            attrs = self._parse_attribute_list()\n            next = self._parse_declarator(named, param_mode, typed)\n            return ASTDeclaratorRef(next=next, attrs=attrs)\n        if typed and self.skip_string('...'):\n            next = self._parse_declarator(named, param_mode, False)\n            return ASTDeclaratorParamPack(next=next)\n        if typed and self.current_char == '(':  # note: peeking, not skipping\n            if param_mode == 'operatorCast':\n                # TODO: we should be able to parse cast operators which return\n                # function pointers. For now, just hax it and ignore.\n                return ASTDeclaratorNameParamQual(\n                    declId=None, arrayOps=[], paramQual=None\n                )\n            # maybe this is the beginning of params and quals,try that first,\n            # otherwise assume it's noptr->declarator > ( ptr-declarator )\n            pos = self.pos\n            try:\n                # assume this is params and quals\n                res = self._parse_declarator_name_suffix(named, param_mode, typed)\n                return res\n            except DefinitionError as ex_param_qual:\n                prev_errors.append((\n                    ex_param_qual,\n                    'If declarator-id with parameters-and-qualifiers',\n                ))\n                self.pos = pos\n                try:\n                    assert self.current_char == '('\n                    self.skip_string('(')\n                    # TODO: hmm, if there is a name, it must be in inner, right?\n                    # TODO: hmm, if there must be parameters, they must be\n                    #       inside, right?\n                    inner = self._parse_declarator(named, param_mode, typed)\n                    if not self.skip_string(')'):\n                        self.fail('Expected \\')\\' in \"( ptr-declarator )\"')\n                    next = self._parse_declarator(\n                        named=False, param_mode='type', typed=typed\n                    )\n                    return ASTDeclaratorParen(inner=inner, next=next)\n                except DefinitionError as ex_no_ptr_paren:\n                    self.pos = pos\n                    prev_errors.append((\n                        ex_no_ptr_paren,\n                        'If parenthesis in noptr-declarator',\n                    ))\n                    header = 'Error in declarator'\n                    raise self._make_multi_error(\n                        prev_errors, header\n                    ) from ex_no_ptr_paren\n        if typed:  # pointer to member\n            pos = self.pos\n            try:\n                name = self._parse_nested_name(member_pointer=True)\n                self.skip_ws()\n                if not self.skip_string('*'):\n                    self.fail(\"Expected '*' in pointer to member declarator.\")\n                self.skip_ws()\n            except DefinitionError as e:\n                self.pos = pos\n                prev_errors.append((e, 'If pointer to member declarator'))\n            else:\n                volatile = False\n                const = False\n                while 1:\n                    if not volatile:\n                        volatile = self.skip_word_and_ws('volatile')\n                        if volatile:\n                            continue\n                    if not const:\n                        const = self.skip_word_and_ws('const')\n                        if const:\n                            continue\n                    break\n                next = self._parse_declarator(named, param_mode, typed)\n                return ASTDeclaratorMemPtr(name, const, volatile, next=next)\n        pos = self.pos\n        try:\n            res = self._parse_declarator_name_suffix(named, param_mode, typed)\n            # this is a heuristic for error messages, for when there is a < after a\n            # nested name, but it was not a successful template argument list\n            if self.current_char == '<':\n                self.otherErrors.append(self._make_multi_error(prev_errors, ''))\n            return res\n        except DefinitionError as e:\n            self.pos = pos\n            prev_errors.append((e, 'If declarator-id'))\n            header = 'Error in declarator or parameters-and-qualifiers'\n            raise self._make_multi_error(prev_errors, header) from e\n", "type": "function"}, {"name": "__init__", "is_method": true, "class_name": "ASTDeclaratorParamPack", "parameters": ["self", "next"], "calls": [], "code_location": {"file": "_ast.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/domains/cpp", "start_line": 2987, "end_line": 2989}, "code_snippet": "    def __init__(self, next: ASTDeclarator) -> None:\n        assert next\n        self.next = next\n", "type": "function"}, {"name": "_parse_declarator_name_suffix", "is_method": true, "class_name": "DefinitionParser", "parameters": ["self", "named", "param_mode", "typed"], "calls": ["self._parse_parameters", "ASTDeclaratorNameParam", "self.match", "self.skip_ws", "ASTIdentifier", "ASTNestedName", "self._parse_nested_name", "self.skip_string", "self.skip_ws", "array_ops.append", "len", "self.skip_ws", "self.skip_string", "self.fail", "self.fail", "self.skip_string_and_ws", "self.skip_string", "ASTArray", "self._parse_constant_expression", "ASTDeclaratorNameBitField", "self.skip_word_and_ws", "self.skip_word_and_ws", "self.skip_word_and_ws", "self.skip_word_and_ws", "self.skip_string", "self.fail", "self._parse_expression_fallback", "self.skip_ws", "self.skip_string", "self.fail", "str"], "code_location": {"file": "_parser.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/domains/c", "start_line": 696, "end_line": 776}, "code_snippet": "    def _parse_declarator_name_suffix(\n        self, named: bool | str, param_mode: str, typed: bool\n    ) -> ASTDeclarator:\n        assert named in {True, False, 'single'}\n        # now we should parse the name, and then suffixes\n        if named == 'single':\n            if self.match(identifier_re):\n                if self.matched_text in _keywords:\n                    self.fail(\n                        'Expected identifier, got keyword: %s' % self.matched_text\n                    )\n                if self.matched_text in self.config.c_extra_keywords:\n                    msg = (\n                        'Expected identifier, got user-defined keyword: %s. '\n                        'Remove it from c_extra_keywords to allow it as identifier.\\n'\n                        'Currently c_extra_keywords is %s.'\n                    )\n                    self.fail(\n                        msg % (self.matched_text, str(self.config.c_extra_keywords))\n                    )\n                identifier = ASTIdentifier(self.matched_text)\n                decl_id = ASTNestedName([identifier], rooted=False)\n            else:\n                decl_id = None\n        elif named:\n            decl_id = self._parse_nested_name()\n        else:\n            decl_id = None\n        array_ops = []\n        while 1:\n            self.skip_ws()\n            if typed and self.skip_string('['):\n                self.skip_ws()\n                static = False\n                const = False\n                volatile = False\n                restrict = False\n                while True:\n                    if not static:\n                        if self.skip_word_and_ws('static'):\n                            static = True\n                            continue\n                    if not const:\n                        if self.skip_word_and_ws('const'):\n                            const = True\n                            continue\n                    if not volatile:\n                        if self.skip_word_and_ws('volatile'):\n                            volatile = True\n                            continue\n                    if not restrict:\n                        if self.skip_word_and_ws('restrict'):\n                            restrict = True\n                            continue\n                    break\n                vla = False if static else self.skip_string_and_ws('*')\n                if vla:\n                    if not self.skip_string(']'):\n                        self.fail(\"Expected ']' in end of array operator.\")\n                    size = None\n                else:\n                    if self.skip_string(']'):\n                        size = None\n                    else:\n                        parser = self._parse_expression\n                        size = self._parse_expression_fallback([']'], parser)\n                        self.skip_ws()\n                        if not self.skip_string(']'):\n                            self.fail(\"Expected ']' in end of array operator.\")\n                array_ops.append(ASTArray(static, const, volatile, restrict, vla, size))\n            else:\n                break\n        param = self._parse_parameters(param_mode)\n        if param is None and len(array_ops) == 0:\n            # perhaps a bit-field\n            if named and param_mode == 'type' and typed:\n                self.skip_ws()\n                if self.skip_string(':'):\n                    size = self._parse_constant_expression()\n                    return ASTDeclaratorNameBitField(declId=decl_id, size=size)\n        return ASTDeclaratorNameParam(declId=decl_id, arrayOps=array_ops, param=param)\n", "type": "function"}, {"name": "__init__", "is_method": true, "class_name": "ASTDeclSpecs", "parameters": ["self", "outer", "leftSpecs", "rightSpecs", "trailing"], "calls": ["self.leftSpecs.mergeWith"], "code_location": {"file": "_ast.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/domains/cpp", "start_line": 2454, "end_line": 2467}, "code_snippet": "    def __init__(\n        self,\n        outer: str,\n        leftSpecs: ASTDeclSpecsSimple,\n        rightSpecs: ASTDeclSpecsSimple,\n        trailing: ASTTrailingTypeSpec,\n    ) -> None:\n        # leftSpecs and rightSpecs are used for output\n        # allSpecs are used for id generation\n        self.outer = outer\n        self.leftSpecs = leftSpecs\n        self.rightSpecs = rightSpecs\n        self.allSpecs = self.leftSpecs.mergeWith(self.rightSpecs)\n        self.trailingTypeSpec = trailing\n", "type": "function"}], "retrieved_count": 10, "cost_time": 0.376018762588501}
{"question": "What is the integration mechanism between the macro declaration node class and the abstract syntax tree hierarchy that maintains consistency between identifier resolution via the versioned identifier method and symbol table management in the C domain?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"name": "run", "is_method": true, "class_name": "CObject", "parameters": ["self"], "calls": ["run", "root.get_lookup_key", "super"], "code_location": {"file": "__init__.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/domains/c", "start_line": 221, "end_line": 232}, "code_snippet": "    def run(self) -> list[Node]:\n        env = self.env\n        if env.current_document.c_parent_symbol is None:\n            root = env.domaindata['c']['root_symbol']\n            env.current_document.c_parent_symbol = root\n            env.ref_context['c:parent_key'] = root.get_lookup_key()\n\n        # When multiple declarations are made in the same directive\n        # they need to know about each other to provide symbol lookup for function parameters.\n        # We use last_symbol to store the latest added declaration in a directive.\n        env.current_document.c_last_symbol = None\n        return super().run()\n", "type": "function"}, {"name": "ASTMacro", "docstring": "", "methods": ["__init__", "__eq__", "__hash__", "name", "get_id", "_stringify", "describe_signature"], "attributes": [], "code_location": {"file": "_ast.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/domains/c", "start_line": 1676, "end_line": 1723}, "type": "class"}, {"name": "test_domain_c_ast_macro_definitions", "is_method": false, "class_name": null, "parameters": [], "calls": ["check", "check", "check", "check", "check", "check", "check", "check", "check", "check", "pytest.raises", "check"], "code_location": {"file": "test_domain_c.py", "path": "/data3/pwh/swebench-repos/sphinx/tests/test_domains", "start_line": 432, "end_line": 445}, "code_snippet": "def test_domain_c_ast_macro_definitions() -> None:\n    check('macro', 'M', {1: 'M'})\n    check('macro', 'M()', {1: 'M'})\n    check('macro', 'M(arg)', {1: 'M'})\n    check('macro', 'M(arg1, arg2)', {1: 'M'})\n    check('macro', 'M(arg1, arg2, arg3)', {1: 'M'})\n    check('macro', 'M(...)', {1: 'M'})\n    check('macro', 'M(arg, ...)', {1: 'M'})\n    check('macro', 'M(arg1, arg2, ...)', {1: 'M'})\n    check('macro', 'M(arg1, arg2, arg3, ...)', {1: 'M'})\n    # GNU extension\n    check('macro', 'M(arg1, arg2, arg3...)', {1: 'M'})\n    with pytest.raises(DefinitionError):\n        check('macro', 'M(arg1, arg2..., arg3)', {1: 'M'})\n", "type": "function"}, {"name": "__init__", "is_method": true, "class_name": "ASTMacro", "parameters": ["self", "ident", "args"], "calls": [], "code_location": {"file": "_ast.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/domains/c", "start_line": 1677, "end_line": 1681}, "code_snippet": "    def __init__(\n        self, ident: ASTNestedName, args: list[ASTMacroParameter] | None\n    ) -> None:\n        self.ident = ident\n        self.args = args\n", "type": "function"}, {"name": "get_id", "is_method": true, "class_name": "ASTFunctionParameter", "parameters": ["self", "version", "objectType", "symbol"], "calls": ["symbol.parent.declaration.get_id", "self.arg.get_id"], "code_location": {"file": "_ast.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/domains/cpp", "start_line": 2035, "end_line": 2046}, "code_snippet": "    def get_id(\n        self, version: int, objectType: str | None = None, symbol: Symbol | None = None\n    ) -> str:\n        # this is not part of the normal name mangling in C++\n        if symbol:\n            # the anchor will be our parent\n            return symbol.parent.declaration.get_id(version, prefixed=False)\n        # else, do the usual\n        if self.ellipsis:\n            return 'z'\n        else:\n            return self.arg.get_id(version)\n", "type": "function"}, {"name": "__init__", "is_method": true, "class_name": "Symbol", "parameters": ["self", "parent", "identOrOp", "templateParams", "templateArgs", "declaration", "docname", "line"], "calls": ["self._assert_invariants", "self._add_template_and_function_params", "self.parent._children.append", "_is_specialization"], "code_location": {"file": "_symbol.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/domains/cpp", "start_line": 187, "end_line": 231}, "code_snippet": "    def __init__(\n        self,\n        parent: Symbol | None,\n        identOrOp: ASTIdentifier | ASTOperator | None,\n        templateParams: ASTTemplateParams | ASTTemplateIntroduction | None,\n        templateArgs: Any,\n        declaration: ASTDeclaration | None,\n        docname: str | None,\n        line: int | None,\n    ) -> None:\n        self.parent = parent\n        # declarations in a single directive are linked together\n        self.siblingAbove: Symbol | None = None\n        self.siblingBelow: Symbol | None = None\n        self.identOrOp = identOrOp\n        # Ensure the same symbol for `A` is created for:\n        #\n        #     .. cpp:class:: template <typename T> class A\n        #\n        # and\n        #\n        #     .. cpp:function:: template <typename T> int A<T>::foo()\n        if templateArgs is not None and not _is_specialization(\n            templateParams, templateArgs\n        ):\n            templateArgs = None\n        self.templateParams = templateParams  # template<templateParams>\n        self.templateArgs = templateArgs  # identifier<templateArgs>\n        self.declaration = declaration\n        self.docname = docname\n        self.line = line\n        self.isRedeclaration = False\n        self._assert_invariants()\n\n        # Remember to modify Symbol.remove if modifications to the parent change.\n        self._children: list[Symbol] = []\n        self._anon_children: list[Symbol] = []\n        # note: _children includes _anon_children\n        if self.parent:\n            self.parent._children.append(self)\n        if self.declaration:\n            self.declaration.symbol = self\n\n        # Do symbol addition after self._children has been initialised.\n        self._add_template_and_function_params()\n", "type": "function"}, {"name": "get_id", "is_method": true, "class_name": "ASTTemplateIntroductionParameter", "parameters": ["self", "version", "objectType", "symbol"], "calls": ["symbol.parent.declaration.get_id"], "code_location": {"file": "_ast.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/domains/cpp", "start_line": 4308, "end_line": 4320}, "code_snippet": "    def get_id(\n        self, version: int, objectType: str | None = None, symbol: Symbol | None = None\n    ) -> str:\n        assert version >= 2\n        # this is not part of the normal name mangling in C++\n        if symbol:\n            # the anchor will be our parent\n            return symbol.parent.declaration.get_id(version, prefixed=None)\n        else:\n            if self.parameterPack:\n                return 'Dp'\n            else:\n                return '0'  # we need to put something\n", "type": "function"}, {"name": "get_id", "is_method": true, "class_name": "ASTTemplateParamNonType", "parameters": ["self", "version", "objectType", "symbol"], "calls": ["symbol.parent.declaration.get_id", "self.param.get_id"], "code_location": {"file": "_ast.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/domains/cpp", "start_line": 4157, "end_line": 4169}, "code_snippet": "    def get_id(\n        self, version: int, objectType: str | None = None, symbol: Symbol | None = None\n    ) -> str:\n        assert version >= 2\n        # this is not part of the normal name mangling in C++\n        if symbol:\n            # the anchor will be our parent\n            return symbol.parent.declaration.get_id(version, prefixed=None)\n        else:\n            res = '_'\n            if self.parameterPack:\n                res += 'Dp'\n            return res + self.param.get_id(version)\n", "type": "function"}, {"name": "ASTMacroParameter", "docstring": "", "methods": ["__init__", "__eq__", "__hash__", "_stringify", "describe_signature"], "attributes": [], "code_location": {"file": "_ast.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/domains/c", "start_line": 1635, "end_line": 1673}, "type": "class"}, {"name": "get_id", "is_method": true, "class_name": "ASTTemplateParamType", "parameters": ["self", "version", "objectType", "symbol"], "calls": ["symbol.parent.declaration.get_id", "self.data.get_id"], "code_location": {"file": "_ast.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/domains/cpp", "start_line": 4047, "end_line": 4056}, "code_snippet": "    def get_id(\n        self, version: int, objectType: str | None = None, symbol: Symbol | None = None\n    ) -> str:\n        # this is not part of the normal name mangling in C++\n        assert version >= 2\n        if symbol:\n            # the anchor will be our parent\n            return symbol.parent.declaration.get_id(version, prefixed=False)\n        else:\n            return self.data.get_id(version)\n", "type": "function"}], "retrieved_count": 10, "cost_time": 0.47431302070617676}
