{"question": "What is Sphinx's approach to handling large documentation projects?", "answer": null, "relative_code_list": null, "ground_truth": "Sphinx employs several strategies to efficiently handle large documentation projects:\n\n1. **Incremental Build System**: Sphinx uses an incremental build approach where only new or changed source files are processed. The system tracks which files have been modified since the last build and only rebuilds those files, significantly reducing build times for large projects.\n\n2. **Environment Caching**: Sphinx caches the build environment (containing cross-references, metadata, and other build state) as a pickle file. This allows the system to skip the expensive parsing and analysis phase for unchanged files.\n\n3. **Parallel Processing**: Sphinx supports parallel document processing using the `--jobs` or `-j` option. This distributes the build across multiple processes, making it more effective on multiprocessor machines. The system can automatically detect the number of CPU cores and use them optimally.\n\n4. **Document Tree Serialization**: Sphinx implements document tree serialization for distributed builds, allowing the parsed document trees to be shared between parallel processes and merged efficiently.\n\n5. **Doctree Caching**: Parsed source files are cached as \"doctree pickles\" in a `.doctrees` directory. These cached files can be shared between different builders and significantly speed up subsequent builds.\n\n6. **Memory Management**: The parallel processing system is designed to reduce memory usage and CPU utilization by distributing the workload across multiple processes, preventing any single process from consuming excessive resources.\n\n7. **Selective Rebuilding**: Users can specify individual files to rebuild using the `--write-all` option or by providing specific filenames, allowing for targeted rebuilding of only the necessary components.\n\n8. **Fresh Environment Option**: For cases where the cached environment might be corrupted or when a complete rebuild is needed, Sphinx provides the `--fresh-env` option to rebuild the environment completely.\n\nThese approaches work together to make Sphinx capable of handling documentation projects with thousands of files while maintaining reasonable build times and resource usage.", "score": null, "retrieved_content": [{"name": "Sphinx", "docstring": "The main application class and extensibility interface.\n\n:ivar srcdir: Directory containing source.\n:ivar confdir: Directory containing ``conf.py``.\n:ivar doctreedir: Directory for storing pickled doctrees.\n:ivar outdir: Directory for storing build documents.", "methods": ["__init__", "fresh_env_used", "phase", "_init_i18n", "_init_env", "_create_fresh_env", "_load_existing_env", "_post_init_env", "preload_builder", "create_builder", "_init_builder", "build", "setup_extension", "require_sphinx", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "disconnect", "emit", "emit_firstresult", "add_builder", "add_config_value", "add_event", "set_translator", "add_node", "add_enumerable_node", "add_directive", "add_role", "add_generic_role", "add_domain", "add_directive_to_domain", "add_role_to_domain", "add_index_to_domain", "add_object_type", "add_crossref_type", "add_transform", "add_post_transform", "add_js_file", "add_css_file", "add_latex_package", "add_lexer", "add_autodocumenter", "add_autodoc_attrgetter", "add_search_language", "add_source_suffix", "add_source_parser", "add_env_collector", "add_html_theme", "add_html_math_renderer", "add_message_catalog", "is_parallel_allowed", "set_html_assets_policy"], "attributes": ["srcdir", "confdir", "outdir", "doctreedir"], "code_location": {"file": "application.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx", "start_line": 142, "end_line": 1822}, "type": "class"}, {"name": "Project", "docstring": "A project is the source code set of the Sphinx document(s).", "methods": ["__init__", "restore", "discover", "path2doc", "doc2path"], "attributes": [], "code_location": {"file": "project.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx", "start_line": 23, "end_line": 128}, "type": "class"}, {"name": "SphinxFileOutput", "docstring": "Better FileOutput class for Sphinx.", "methods": ["__init__", "write"], "attributes": [], "code_location": {"file": "docutils.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/util", "start_line": 447, "end_line": 469}, "type": "class"}, {"name": "__init__", "is_method": true, "class_name": "BuildEnvironment", "parameters": ["self", "app"], "calls": ["_get_env_version", "default_settings.copy", "defaultdict", "defaultdict", "set", "defaultdict", "set", "set", "FilenameUniqDict", "DownloadFiles", "_CurrentDocument", "_DomainsContainer._from_environment", "self.setup"], "code_location": {"file": "__init__.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/environment", "start_line": 114, "end_line": 239}, "code_snippet": "    def __init__(self, app: Sphinx) -> None:\n        self._app: Sphinx = app\n        self.doctreedir = app.doctreedir\n        self.srcdir = app.srcdir\n        self.config: Config = None  # type: ignore[assignment]\n        self.config_status: int = CONFIG_UNSET\n        self.config_status_extra: str = ''\n        self.events: EventManager = app.events\n        self.project: Project = app.project\n        self.version: Mapping[str, int] = _get_env_version(app.extensions)\n\n        # the method of doctree versioning; see set_versioning_method\n        self.versioning_condition: Literal[False] | Callable[[Node], bool] | None = None\n        self.versioning_compare: bool | None = None\n\n        # the docutils settings for building\n        self.settings: dict[str, Any] = default_settings.copy()\n        self.settings['env'] = self\n\n        # All \"docnames\" here are /-separated and relative and exclude\n        # the source suffix.\n\n        # docname -> time of reading (in integer microseconds)\n        # contains all read docnames\n        self.all_docs: dict[str, int] = {}\n        # docname -> set of dependent file\n        # names, relative to documentation root\n        self.dependencies: dict[str, set[_StrPath]] = defaultdict(set)\n        # docname -> set of included file\n        # docnames included from other documents\n        self.included: dict[str, set[str]] = defaultdict(set)\n        # docnames to re-read unconditionally on next build\n        self.reread_always: set[str] = set()\n\n        self._pickled_doctree_cache: dict[str, bytes] = {}\n        \"\"\"In-memory cache for reading pickled doctrees from disk.\n        docname -> pickled doctree\n\n        This cache is used in the ``get_doctree`` method to avoid reading the\n        doctree from disk multiple times.\n        \"\"\"\n\n        self._write_doc_doctree_cache: dict[str, nodes.document] = {}\n        \"\"\"In-memory cache for unpickling doctrees from disk.\n        docname -> doctree\n\n        Items are added in ``Builder.write_doctree``, during the read phase,\n        then used only in the ``get_and_resolve_doctree`` method.\n        \"\"\"\n\n        # File metadata\n        # docname -> dict of metadata items\n        self.metadata: dict[str, dict[str, Any]] = defaultdict(dict)\n\n        # TOC inventory\n        # docname -> title node\n        self.titles: dict[str, nodes.title] = {}\n        # docname -> title node; only different if\n        # set differently with title directive\n        self.longtitles: dict[str, nodes.title] = {}\n        # docname -> table of contents nodetree\n        self.tocs: dict[str, nodes.bullet_list] = {}\n        # docname -> number of real entries\n        self.toc_num_entries: dict[str, int] = {}\n\n        # used to determine when to show the TOC\n        # in a sidebar (don't show if it's only one item)\n        # docname -> dict of sectionid -> number\n        self.toc_secnumbers: dict[str, dict[str, tuple[int, ...]]] = {}\n        # docname -> dict of figtype -> dict of figureid -> number\n        self.toc_fignumbers: dict[str, dict[str, dict[str, tuple[int, ...]]]] = {}\n\n        # docname -> list of toctree includefiles\n        self.toctree_includes: dict[str, list[str]] = {}\n        # docname -> set of files (containing its TOCs) to rebuild too\n        self.files_to_rebuild: dict[str, set[str]] = {}\n        # docnames that have :glob: toctrees\n        self.glob_toctrees: set[str] = set()\n        # docnames that have :numbered: toctrees\n        self.numbered_toctrees: set[str] = set()\n\n        # domain-specific inventories, here to be pickled\n        # domainname -> domain-specific dict\n        self.domaindata: dict[str, dict[str, Any]] = {}\n\n        # these map absolute path -> (docnames, unique filename)\n        self.images: FilenameUniqDict = FilenameUniqDict()\n        # filename -> (set of docnames, destination)\n        self.dlfiles: DownloadFiles = DownloadFiles()\n\n        # the original URI for images\n        self.original_image_uri: dict[_StrPath, str] = {}\n\n        # temporary data storage while reading a document\n        self.current_document: _CurrentDocument = _CurrentDocument()\n        # context for cross-references (e.g. current module or class)\n        # this is similar to ``self.current_document``,\n        # but will for example be copied to attributes of \"any\" cross references\n        self.ref_context: dict[str, Any] = {}\n\n        # search index data\n\n        # docname -> title\n        self._search_index_titles: dict[str, str | None] = {}\n        # docname -> filename\n        self._search_index_filenames: dict[str, str] = {}\n        # stemmed words -> set(docname)\n        self._search_index_mapping: dict[str, set[str]] = {}\n        # stemmed words in titles -> set(docname)\n        self._search_index_title_mapping: dict[str, set[str]] = {}\n        # docname -> all titles in document\n        self._search_index_all_titles: dict[str, list[tuple[str, str | None]]] = {}\n        # docname -> list(index entry)\n        self._search_index_index_entries: dict[str, list[tuple[str, str, str]]] = {}\n        # objtype -> index\n        self._search_index_objtypes: dict[tuple[str, str], int] = {}\n        # objtype index -> (domain, type, objname (localized))\n        self._search_index_objnames: dict[int, tuple[str, str, str]] = {}\n\n        # all the registered domains, set by the application\n        self.domains: _DomainsContainer = _DomainsContainer._from_environment(\n            self, registry=app.registry\n        )\n\n        # set up environment\n        self.setup(app)\n", "type": "function"}, {"name": "__init__", "is_method": true, "class_name": "Sphinx", "parameters": ["self", "srcdir", "confdir", "outdir", "doctreedir", "buildername", "confoverrides", "status", "warning", "freshenv", "warningiserror", "tags", "verbosity", "parallel", "keep_going", "pdb", "exception_on_warning"], "calls": ["SphinxComponentRegistry", "resolve", "resolve", "resolve", "bool", "bool", "logging.setup", "EventManager", "deque", "logger.info", "Tags", "self._init_i18n", "self.preload_builder", "self.config._report_override_warnings", "self.events.emit", "Project", "self._init_env", "self.create_builder", "self._post_init_env", "self._init_builder", "self.srcdir.is_dir", "ApplicationError", "self.outdir.exists", "ApplicationError", "ApplicationError", "StringIO", "StringIO", "bold", "Config", "resolve", "Config.read", "VersionRequirementError", "self.setup_extension", "self.setup_extension", "self.outdir.is_dir", "_StrPath", "_StrPath", "_StrPath", "self.outdir.is_dir", "__", "__", "progress_message", "ensuredir", "__", "prefixed_warnings", "callable", "__", "__", "_StrPath", "__", "__", "self.config.setup", "ConfigError", "__"], "code_location": {"file": "application.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx", "start_line": 159, "end_line": 334}, "code_snippet": "    def __init__(\n        self,\n        srcdir: str | os.PathLike[str],\n        confdir: str | os.PathLike[str] | None,\n        outdir: str | os.PathLike[str],\n        doctreedir: str | os.PathLike[str],\n        buildername: str,\n        confoverrides: dict[str, Any] | None = None,\n        status: IO[str] | None = sys.stdout,\n        warning: IO[str] | None = sys.stderr,\n        freshenv: bool = False,\n        warningiserror: bool = False,\n        tags: Sequence[str] = (),\n        verbosity: int = 0,\n        parallel: int = 0,\n        keep_going: bool = False,\n        pdb: bool = False,\n        exception_on_warning: bool = False,\n    ) -> None:\n        \"\"\"Initialize the Sphinx application.\n\n        :param srcdir: The path to the source directory.\n        :param confdir: The path to the configuration directory.\n            If not given, it is assumed to be the same as ``srcdir``.\n        :param outdir: Directory for storing build documents.\n        :param doctreedir: Directory for caching pickled doctrees.\n        :param buildername: The name of the builder to use.\n        :param confoverrides: A dictionary of configuration settings that override the\n            settings in the configuration file.\n        :param status: A file-like object to write status messages to.\n        :param warning: A file-like object to write warnings to.\n        :param freshenv: If true, clear the cached environment.\n        :param warningiserror: If true, warnings become errors.\n        :param tags: A list of tags to apply.\n        :param verbosity: The verbosity level.\n        :param parallel: The maximum number of parallel jobs to use\n            when reading/writing documents.\n        :param keep_going: Unused.\n        :param pdb: If true, enable the Python debugger on an exception.\n        :param exception_on_warning: If true, raise an exception on warnings.\n        \"\"\"\n        self.verbosity = verbosity\n        self._fresh_env_used: bool | None = None\n        self.extensions: dict[str, Extension] = {}\n        self.registry = SphinxComponentRegistry()\n\n        # validate provided directories\n        self.srcdir = _StrPath(srcdir).resolve()\n        self.outdir = _StrPath(outdir).resolve()\n        self.doctreedir = _StrPath(doctreedir).resolve()\n\n        if not self.srcdir.is_dir():\n            raise ApplicationError(\n                __('Cannot find source directory (%s)') % self.srcdir\n            )\n\n        if self.outdir.exists() and not self.outdir.is_dir():\n            raise ApplicationError(\n                __('Output directory (%s) is not a directory') % self.outdir\n            )\n\n        if self.srcdir == self.outdir:\n            raise ApplicationError(\n                __('Source directory and destination directory cannot be identical')\n            )\n\n        self.parallel = parallel\n\n        if status is None:\n            self._status: IO[str] = StringIO()\n            self.quiet: bool = True\n        else:\n            self._status = status\n            self.quiet = False\n\n        if warning is None:\n            self._warning: IO[str] = StringIO()\n        else:\n            self._warning = warning\n        self._warncount = 0\n        self.keep_going = bool(warningiserror)  # Unused\n        self._fail_on_warnings = bool(warningiserror)\n        self.pdb = pdb\n        self._exception_on_warning = exception_on_warning\n        logging.setup(self, self._status, self._warning, verbosity=verbosity)\n\n        self.events = EventManager(self)\n\n        # keep last few messages for traceback\n        # This will be filled by sphinx.util.logging.LastMessagesWriter\n        self.messagelog: deque[str] = deque(maxlen=10)\n\n        # say hello to the world\n        logger.info(bold(__('Running Sphinx v%s')), sphinx.__display_version__)\n\n        # status code for command-line application\n        self.statuscode = 0\n\n        # read config\n        overrides = confoverrides or {}\n        self.tags = Tags(tags)\n        if confdir is None:\n            # set confdir to srcdir if -C given (!= no confdir); a few pieces\n            # of code expect a confdir to be set\n            self.confdir = self.srcdir\n            self.config = Config({}, overrides)\n        else:\n            self.confdir = _StrPath(confdir).resolve()\n            self.config = Config.read(self.confdir, overrides=overrides, tags=self.tags)\n        self.config._verbosity = -1 if self.quiet else self.verbosity\n\n        # set up translation infrastructure\n        self._init_i18n()\n\n        # check the Sphinx version if requested\n        if (\n            self.config.needs_sphinx\n            and self.config.needs_sphinx > sphinx.__display_version__\n        ):\n            raise VersionRequirementError(\n                __(\n                    'This project needs at least Sphinx v%s and therefore cannot '\n                    'be built with this version.'\n                )\n                % self.config.needs_sphinx\n            )\n\n        # load all built-in extension modules, first-party extension modules,\n        # and first-party themes\n        for extension in builtin_extensions:\n            self.setup_extension(extension)\n\n        # load all user-given extension modules\n        for extension in self.config.extensions:\n            self.setup_extension(extension)\n\n        # preload builder module (before init config values)\n        self.preload_builder(buildername)\n\n        if not self.outdir.is_dir():\n            with progress_message(__('making output directory')):\n                ensuredir(self.outdir)\n\n        # the config file itself can be an extension\n        if self.config.setup:\n            prefix = __('while setting up extension %s:') % 'conf.py'\n            with prefixed_warnings(prefix):\n                if callable(self.config.setup):\n                    self.config.setup(self)\n                else:\n                    raise ConfigError(\n                        __(\n                            \"'setup' as currently defined in conf.py isn't a Python callable. \"\n                            'Please modify its definition to make it a callable function. '\n                            'This is needed for conf.py to behave as a Sphinx extension.'\n                        ),\n                    )\n\n        # Report any warnings for overrides.\n        self.config._report_override_warnings()\n        self.events.emit('config-inited', self.config)\n\n        # create the project\n        self.project = Project(self.srcdir, self.config.source_suffix)\n\n        # set up the build environment\n        self.env = self._init_env(freshenv)\n\n        # create the builder\n        self.builder = self.create_builder(buildername)\n\n        # build environment post-initialisation, after creating the builder\n        self._post_init_env()\n\n        # set up the builder\n        self._init_builder()\n", "type": "function"}, {"name": "SphinxStandaloneReader", "docstring": "A basic document reader for Sphinx.", "methods": ["__init__", "_setup_transforms", "read", "read_source"], "attributes": [], "code_location": {"file": "io.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx", "start_line": 79, "end_line": 109}, "type": "class"}, {"name": "_full_quickstart", "is_method": false, "class_name": null, "parameters": [], "calls": ["modules.sort", "module.startswith", "str", "str", "extend", "qs.generate", "remove", "extend", "ext.split"], "code_location": {"file": "_cli.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/ext/apidoc", "start_line": 309, "end_line": 356}, "code_snippet": "def _full_quickstart(opts: ApidocOptions, /, *, modules: list[str]) -> None:\n    from sphinx.cmd import quickstart as qs\n\n    modules.sort()\n    prev_module = ''\n    text = ''\n    for module in modules:\n        if module.startswith(prev_module + '.'):\n            continue\n        prev_module = module\n        text += f'   {module}\\n'\n    d: dict[str, Any] = {\n        'path': str(opts.dest_dir),\n        'sep': False,\n        'dot': '_',\n        'project': opts.header,\n        'author': opts.author or 'Author',\n        'version': opts.version or '',\n        'release': opts.release or opts.version or '',\n        'suffix': '.' + opts.suffix,\n        'master': 'index',\n        'epub': True,\n        'extensions': [\n            'sphinx.ext.autodoc',\n            'sphinx.ext.viewcode',\n            'sphinx.ext.todo',\n        ],\n        'makefile': True,\n        'batchfile': True,\n        'make_mode': True,\n        'mastertocmaxdepth': opts.max_depth,\n        'mastertoctree': text,\n        'language': 'en',\n        'module_path': str(opts.module_path),\n        'append_syspath': opts.append_syspath,\n    }\n    if opts.extensions:\n        d['extensions'].extend(opts.extensions)\n    if opts.quiet:\n        d['quiet'] = True\n\n    for ext in d['extensions'][:]:\n        if ',' in ext:\n            d['extensions'].remove(ext)\n            d['extensions'].extend(ext.split(','))\n\n    if not opts.dry_run:\n        qs.generate(d, silent=True, overwrite=opts.force, templatedir=opts.template_dir)\n", "type": "function"}, {"name": "IntersphinxProject", "docstring": "", "methods": ["__init__", "record", "normalise"], "attributes": [], "code_location": {"file": "test_ext_intersphinx_cache.py", "path": "/data3/pwh/swebench-repos/sphinx/tests/test_extensions", "start_line": 79, "end_line": 120}, "type": "class"}, {"name": "_IntersphinxProject", "docstring": "", "methods": ["__init__", "__repr__", "__eq__", "__hash__", "__setattr__", "__delattr__"], "attributes": ["__slots__"], "code_location": {"file": "_shared.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/ext/intersphinx", "start_line": 44, "end_line": 111}, "type": "class"}, {"name": "SingleFileHTMLBuilder", "docstring": "Builds the whole document tree as a single HTML page.", "methods": ["get_outdated_docs", "get_target_uri", "get_relative_uri", "fix_refuris", "_get_local_toctree", "assemble_doctree", "assemble_toc_secnumbers", "assemble_toc_fignumbers", "get_doc_context", "write_documents", "finish", "write_additional_files"], "attributes": ["name", "epilog", "copysource"], "code_location": {"file": "singlehtml.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/builders", "start_line": 31, "end_line": 205}, "type": "class"}], "retrieved_count": 10, "cost_time": 1.102827548980713}
{"question": "What is the purpose of the SphinxComponentRegistry class?", "answer": null, "relative_code_list": null, "ground_truth": "The SphinxComponentRegistry class serves as the central registry and component management system for Sphinx's extensible architecture. Its primary purpose is to maintain and organize all the various components that can be registered and used throughout the Sphinx build process.\n\nKey responsibilities of the SphinxComponentRegistry include:\n\n1. **Component Storage**: The registry maintains dictionaries and collections for storing various types of components including builders, domains, directives, roles, transforms, documenters, and other extensible elements.\n\n2. **Extension Management**: It handles the loading and registration of Sphinx extensions, managing their metadata and ensuring proper initialization. The registry can load extensions from entry points and handle extension setup functions.\n\n3. **Domain Component Management**: The registry manages domain-specific components such as directives, roles, object types, and indices that are associated with specific domains (Python, C++, etc.).\n\n4. **Builder Management**: It maintains a registry of available builder classes and provides methods to create builder instances.\n\n5. **Autodoc Integration**: The registry manages autodoc documenters and attribute getters for automatic documentation generation.\n\n6. **Node Handler Management**: It manages custom node handlers for translators, allowing extensions to customize how specific node types are rendered in different output formats.\n\n7. **Math Renderer Management**: The registry handles math rendering components for different output formats.\n\n8. **Component Creation**: It provides methods to create instances of registered components, such as creating domain instances with all their associated components properly initialized.\n\nThe registry is instantiated as part of the Sphinx application (`self.registry = SphinxComponentRegistry()`) and serves as the foundation for Sphinx's plugin architecture, allowing extensions to register new functionality without modifying the core Sphinx codebase.", "score": null, "retrieved_content": [{"name": "SphinxComponentRegistry", "docstring": "", "methods": ["__init__", "autodoc_attrgettrs", "add_builder", "preload_builder", "create_builder", "add_domain", "has_domain", "create_domains", "add_directive_to_domain", "add_role_to_domain", "add_index_to_domain", "add_object_type", "add_crossref_type", "add_source_suffix", "add_source_parser", "get_source_parser", "get_source_parsers", "create_source_parser", "add_translator", "add_translation_handlers", "get_translator_class", "create_translator", "add_transform", "get_transforms", "add_post_transform", "get_post_transforms", "add_documenter", "add_autodoc_attrgetter", "add_css_files", "add_js_file", "has_latex_package", "add_latex_package", "add_enumerable_node", "add_html_math_renderer", "add_html_theme", "load_extension", "get_envversion"], "attributes": [], "code_location": {"file": "registry.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx", "start_line": 73, "end_line": 592}, "type": "class"}, {"name": "_registry", "is_method": true, "class_name": "BuildEnvironment", "parameters": ["self"], "calls": [], "code_location": {"file": "__init__.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/environment", "start_line": 310, "end_line": 311}, "code_snippet": "    def _registry(self) -> SphinxComponentRegistry:\n        return self._app.registry\n", "type": "function"}, {"name": "__init__", "is_method": true, "class_name": "FakeApplication", "parameters": ["self"], "calls": ["Path", "Path", "Config", "Project", "SphinxComponentRegistry"], "code_location": {"file": "__init__.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/ext/autosummary", "start_line": 163, "end_line": 170}, "code_snippet": "    def __init__(self) -> None:\n        self.doctreedir = Path()\n        self.events = None\n        self.extensions: dict[str, Extension] = {}\n        self.srcdir = Path()\n        self.config = Config()\n        self.project = Project('', {})\n        self.registry = SphinxComponentRegistry()\n", "type": "function"}, {"name": "SphinxRenderer", "docstring": "", "methods": ["__init__", "render_from_file"], "attributes": [], "code_location": {"file": "template.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/util", "start_line": 64, "end_line": 78}, "type": "class"}, {"name": "SphinxTransformer", "docstring": "A transformer for Sphinx.", "methods": ["set_environment", "apply_transforms"], "attributes": [], "code_location": {"file": "__init__.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/transforms", "start_line": 81, "end_line": 108}, "type": "class"}, {"name": "Sphinx", "docstring": "The main application class and extensibility interface.\n\n:ivar srcdir: Directory containing source.\n:ivar confdir: Directory containing ``conf.py``.\n:ivar doctreedir: Directory for storing pickled doctrees.\n:ivar outdir: Directory for storing build documents.", "methods": ["__init__", "fresh_env_used", "phase", "_init_i18n", "_init_env", "_create_fresh_env", "_load_existing_env", "_post_init_env", "preload_builder", "create_builder", "_init_builder", "build", "setup_extension", "require_sphinx", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "disconnect", "emit", "emit_firstresult", "add_builder", "add_config_value", "add_event", "set_translator", "add_node", "add_enumerable_node", "add_directive", "add_role", "add_generic_role", "add_domain", "add_directive_to_domain", "add_role_to_domain", "add_index_to_domain", "add_object_type", "add_crossref_type", "add_transform", "add_post_transform", "add_js_file", "add_css_file", "add_latex_package", "add_lexer", "add_autodocumenter", "add_autodoc_attrgetter", "add_search_language", "add_source_suffix", "add_source_parser", "add_env_collector", "add_html_theme", "add_html_math_renderer", "add_message_catalog", "is_parallel_allowed", "set_html_assets_policy"], "attributes": ["srcdir", "confdir", "outdir", "doctreedir"], "code_location": {"file": "application.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx", "start_line": 142, "end_line": 1822}, "type": "class"}, {"name": "__init__", "is_method": true, "class_name": "Index", "parameters": ["self", "domain"], "calls": ["SphinxError"], "code_location": {"file": "_index.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/domains", "start_line": 81, "end_line": 85}, "code_snippet": "    def __init__(self, domain: Domain) -> None:\n        if not self.name or self.localname is None:\n            msg = f'Index subclass {self.__class__.__name__} has no valid name or localname'\n            raise SphinxError(msg)\n        self.domain = domain\n", "type": "function"}, {"name": "__init__", "is_method": true, "class_name": "DummyApplication", "parameters": ["self", "translator"], "calls": ["Config", "_DummyEvents", "SphinxComponentRegistry", "_StrPath", "self.config.add", "self.config.add", "self.config.add"], "code_location": {"file": "generate.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/ext/autosummary", "start_line": 73, "end_line": 86}, "code_snippet": "    def __init__(self, translator: NullTranslations) -> None:\n        self.config = Config()\n        self.events = _DummyEvents()\n        self.registry = SphinxComponentRegistry()\n        self.messagelog: list[str] = []\n        self.srcdir = _StrPath('/')\n        self.translator = translator\n        self.verbosity = 0\n        self._warncount = 0\n        self._exception_on_warning = False\n\n        self.config.add('autosummary_context', {}, 'env', ())\n        self.config.add('autosummary_filename_map', {}, 'env', ())\n        self.config.add('autosummary_ignore_module_all', True, 'env', bool)\n", "type": "function"}, {"name": "__init__", "is_method": true, "class_name": "ModuleScanner", "parameters": ["self", "obj"], "calls": [], "code_location": {"file": "generate.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/ext/autosummary", "start_line": 208, "end_line": 219}, "code_snippet": "    def __init__(\n        self,\n        obj: Any,\n        *,\n        config: Config,\n        events: EventManager,\n        registry: SphinxComponentRegistry,\n    ) -> None:\n        self.config = config\n        self.events = events\n        self.registry = registry\n        self.object = obj\n", "type": "function"}, {"name": "SphinxDomains", "docstring": "Collect objects to Sphinx domains for cross references.", "methods": ["apply"], "attributes": ["default_priority"], "code_location": {"file": "references.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/transforms", "start_line": 33, "end_line": 41}, "type": "class"}], "retrieved_count": 10, "cost_time": 1.110680103302002}
{"question": "What is the purpose of the SphinxTransformer class?", "answer": null, "relative_code_list": null, "ground_truth": "The SphinxTransformer class serves as a specialized transformer for Sphinx that extends the standard Docutils transformer functionality. Its primary purpose is to provide Sphinx-specific document tree transformations and ensure proper integration with Sphinx's build environment.\n\nKey purposes of the SphinxTransformer class include:\n\n1. **Environment Integration**: The SphinxTransformer maintains a reference to the Sphinx BuildEnvironment (`self.env`), allowing transforms to access Sphinx-specific data and functionality during the transformation process.\n\n2. **Document Wrapping**: The transformer can wrap target nodes in a document node during transformation when needed, ensuring that the transformation process works correctly even with partial document trees.\n\n3. **Settings Management**: The transformer ensures that the document settings include a reference to the Sphinx environment, making it available to transforms that need access to Sphinx-specific information.\n\n4. **Transform Application**: The transformer applies both regular transforms and post-transforms to document trees, handling the transformation pipeline in a way that's compatible with Sphinx's build process.\n\n5. **Node Processing**: It processes document trees by applying registered transforms in the correct order, ensuring that Sphinx-specific transformations (like cross-reference resolution) are applied at the appropriate stage.\n\n6. **Error Handling**: The transformer provides robust error handling for transformation operations, ensuring that the build process can continue even if individual transforms fail.\n\nThe SphinxTransformer is used throughout Sphinx's build process to apply various transformations to document trees, including cross-reference resolution, link processing, and other Sphinx-specific document modifications. It serves as the bridge between Docutils' transformation system and Sphinx's specialized document processing requirements.", "score": null, "retrieved_content": [{"name": "SphinxTransformer", "docstring": "A transformer for Sphinx.", "methods": ["set_environment", "apply_transforms"], "attributes": [], "code_location": {"file": "__init__.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/transforms", "start_line": 81, "end_line": 108}, "type": "class"}, {"name": "SphinxTransform", "docstring": "A base class of Transforms.\n\nCompared with ``docutils.transforms.Transform``, this class improves accessibility to\nSphinx APIs.", "methods": ["app", "env", "config"], "attributes": [], "code_location": {"file": "__init__.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/transforms", "start_line": 55, "end_line": 78}, "type": "class"}, {"name": "SphinxRenderer", "docstring": "", "methods": ["__init__", "render_from_file"], "attributes": [], "code_location": {"file": "template.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/util", "start_line": 64, "end_line": 78}, "type": "class"}, {"name": "get_transforms", "is_method": true, "class_name": "RSTParser", "parameters": ["self"], "calls": ["get_transforms", "transforms.remove", "super", "RSTParser"], "code_location": {"file": "parsers.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx", "start_line": 68, "end_line": 75}, "code_snippet": "    def get_transforms(self) -> list[type[Transform]]:\n        \"\"\"Sphinx's reST parser replaces a transform class for smart-quotes by its own\n\n        refs: sphinx.io.SphinxStandaloneReader\n        \"\"\"\n        transforms = super(RSTParser, RSTParser()).get_transforms()\n        transforms.remove(SmartQuotes)\n        return transforms\n", "type": "function"}, {"name": "SphinxFileOutput", "docstring": "Better FileOutput class for Sphinx.", "methods": ["__init__", "write"], "attributes": [], "code_location": {"file": "docutils.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/util", "start_line": 447, "end_line": 469}, "type": "class"}, {"name": "SphinxStandaloneReader", "docstring": "A basic document reader for Sphinx.", "methods": ["__init__", "_setup_transforms", "read", "read_source"], "attributes": [], "code_location": {"file": "io.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx", "start_line": 79, "end_line": 109}, "type": "class"}, {"name": "SphinxDanglingReferences", "docstring": "DanglingReferences transform which does not output info messages.", "methods": ["apply"], "attributes": [], "code_location": {"file": "references.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/transforms", "start_line": 18, "end_line": 30}, "type": "class"}, {"name": "get_transforms", "is_method": true, "class_name": "SphinxBaseReader", "parameters": ["self"], "calls": ["get_transforms", "transforms.remove", "super"], "code_location": {"file": "io.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx", "start_line": 51, "end_line": 60}, "code_snippet": "    def get_transforms(self) -> list[type[Transform]]:\n        transforms = super().get_transforms() + self.transforms\n\n        # remove transforms which is not needed for Sphinx\n        unused = [DanglingReferences]\n        for transform in unused:\n            if transform in transforms:\n                transforms.remove(transform)\n\n        return transforms\n", "type": "function"}, {"name": "SphinxSmartQuotes", "docstring": "Customized SmartQuotes to avoid transform for some extra node types.\n\nrefs: sphinx.parsers.RSTParser", "methods": ["apply", "is_available", "get_tokens"], "attributes": ["default_priority"], "code_location": {"file": "__init__.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/transforms", "start_line": 360, "end_line": 408}, "type": "class"}, {"name": "setup", "is_method": false, "class_name": null, "parameters": ["app"], "calls": ["app.add_transform", "app.add_transform", "app.add_transform", "app.add_transform", "app.add_transform", "app.add_transform", "app.add_transform", "app.add_transform", "app.add_transform", "app.add_transform", "app.add_transform", "app.add_transform", "app.add_transform", "app.add_transform", "app.add_transform"], "code_location": {"file": "__init__.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/transforms", "start_line": 511, "end_line": 532}, "code_snippet": "def setup(app: Sphinx) -> ExtensionMetadata:\n    app.add_transform(ApplySourceWorkaround)\n    app.add_transform(ExtraTranslatableNodes)\n    app.add_transform(DefaultSubstitutions)\n    app.add_transform(MoveModuleTargets)\n    app.add_transform(HandleCodeBlocks)\n    app.add_transform(SortIds)\n    app.add_transform(DoctestTransform)\n    app.add_transform(AutoNumbering)\n    app.add_transform(AutoIndexUpgrader)\n    app.add_transform(FilterSystemMessages)\n    app.add_transform(UnreferencedFootnotesDetector)\n    app.add_transform(SphinxSmartQuotes)\n    app.add_transform(DoctreeReadEvent)\n    app.add_transform(GlossarySorter)\n    app.add_transform(ReorderConsecutiveTargetAndIndexNodes)\n\n    return {\n        'version': 'builtin',\n        'parallel_read_safe': True,\n        'parallel_write_safe': True,\n    }\n", "type": "function"}], "retrieved_count": 10, "cost_time": 1.1230897903442383}
{"question": "Why does Sphinx implement document tree serialization for distributed builds?", "answer": null, "relative_code_list": null, "ground_truth": "Sphinx implements document tree serialization for distributed builds to enable efficient parallel processing and sharing of parsed document data across multiple processes. This feature is essential for the parallel build system and provides several important benefits.\n\nKey reasons for implementing document tree serialization include:\n\n1. **Parallel Processing Support**: Document tree serialization allows Sphinx to distribute document processing across multiple parallel processes. Each process can work on a subset of documents independently, and the results can be merged back into the main build environment.\n\n2. **Process Communication**: Serialization enables communication between the main Sphinx process and worker processes. Document trees can be passed to worker processes for processing and then returned with the results.\n\n3. **Memory Efficiency**: By serializing document trees, Sphinx can transfer document data between processes without keeping all document trees in memory simultaneously in the main process, which is important for large projects.\n\n4. **Data Sharing**: Serialization allows the build environment and document metadata to be shared between processes, ensuring that all processes have access to the necessary information for cross-reference resolution and other build tasks.\n\n5. **Incremental Build Integration**: Serialized document trees can be cached and reused in subsequent builds, supporting the incremental build system by allowing processed document trees to persist between builds.\n\n6. **Fault Tolerance**: If a worker process fails, the serialized data can be used to restart processing without losing all progress, improving the robustness of the parallel build system.\n\n7. **Scalability**: Document tree serialization enables Sphinx to scale beyond the memory limitations of a single process, allowing for processing of very large documentation projects.\n\n8. **Cross-Platform Compatibility**: Serialization provides a standardized way to transfer complex data structures between processes, ensuring compatibility across different operating systems and Python implementations.\n\nThe serialization system uses Python's pickle module to serialize document trees and build environment data, allowing for efficient transfer and storage of complex document structures while maintaining the integrity of the build process.", "score": null, "retrieved_content": [{"name": "write_doctree", "is_method": true, "class_name": "Builder", "parameters": ["self", "docname", "doctree"], "calls": ["doctree.settings.copy", "doctree_filename.parent.mkdir", "open", "pickle.dump"], "code_location": {"file": "__init__.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/builders", "start_line": 681, "end_line": 709}, "code_snippet": "    def write_doctree(\n        self,\n        docname: str,\n        doctree: nodes.document,\n        *,\n        _cache: bool = True,\n    ) -> None:\n        \"\"\"Write the doctree to a file, to be used as a cache by re-builds.\"\"\"\n        # make it pickleable\n        doctree.reporter = None  # type: ignore[assignment]\n        doctree.transformer = None  # type: ignore[assignment]\n\n        # Create a copy of settings object before modification because it is\n        # shared with other documents.\n        doctree.settings = doctree.settings.copy()\n        doctree.settings.warning_stream = None\n        doctree.settings.env = None\n        doctree.settings.record_dependencies = None\n\n        doctree_filename = self.doctreedir / f'{docname}.doctree'\n        doctree_filename.parent.mkdir(parents=True, exist_ok=True)\n        with open(doctree_filename, 'wb') as f:\n            pickle.dump(doctree, f, pickle.HIGHEST_PROTOCOL)\n\n        # When Sphinx is running in parallel mode, ``write_doctree()`` is invoked\n        # in the context of a process worker, and thus it does not make sense to\n        # pickle the doctree and send it to the main process\n        if _cache:\n            self.env._write_doc_doctree_cache[docname] = doctree\n", "type": "function"}, {"name": "write_documents", "is_method": true, "class_name": "SingleFileHTMLBuilder", "parameters": ["self", "_docnames"], "calls": ["self.prepare_writing", "self.env.all_docs.keys", "progress_message", "self.assemble_doctree", "self.assemble_toc_secnumbers", "self.assemble_toc_fignumbers", "progress_message", "self.write_doc_serialized", "self.write_doc", "__", "__"], "code_location": {"file": "singlehtml.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/builders", "start_line": 168, "end_line": 178}, "code_snippet": "    def write_documents(self, _docnames: Set[str]) -> None:\n        self.prepare_writing(self.env.all_docs.keys())\n\n        with progress_message(__('assembling single document'), nonl=False):\n            doctree = self.assemble_doctree()\n            self.env.toc_secnumbers = self.assemble_toc_secnumbers()\n            self.env.toc_fignumbers = self.assemble_toc_fignumbers()\n\n        with progress_message(__('writing')):\n            self.write_doc_serialized(self.config.root_doc, doctree)\n            self.write_doc(self.config.root_doc, doctree)\n", "type": "function"}, {"name": "write_doc_serialized", "is_method": true, "class_name": "Builder", "parameters": ["self", "docname", "doctree"], "calls": [], "code_location": {"file": "__init__.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/builders", "start_line": 847, "end_line": 851}, "code_snippet": "    def write_doc_serialized(self, docname: str, doctree: nodes.document) -> None:\n        \"\"\"Handle parts of write_doc that must be called in the main process\n        if parallel build is active.\n        \"\"\"\n        pass\n", "type": "function"}, {"name": "write_doc_serialized", "is_method": true, "class_name": "StandaloneHTMLBuilder", "parameters": ["self", "docname", "doctree"], "calls": ["relative_uri", "self.post_process_images", "self.env.longtitles.get", "self.index_page", "self.get_target_uri", "self.render_partial"], "code_location": {"file": "__init__.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/builders/html", "start_line": 681, "end_line": 686}, "code_snippet": "    def write_doc_serialized(self, docname: str, doctree: nodes.document) -> None:\n        self.imgpath = relative_uri(self.get_target_uri(docname), self.imagedir)\n        self.post_process_images(doctree)\n        title_node = self.env.longtitles.get(docname)\n        title = self.render_partial(title_node)['title'] if title_node else ''\n        self.index_page(docname, doctree, title)\n", "type": "function"}, {"name": "SphinxDummyWriter", "docstring": "Dummy writer module used for generating doctree.", "methods": ["__init__", "translate"], "attributes": ["supported"], "code_location": {"file": "io.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx", "start_line": 112, "end_line": 126}, "type": "class"}, {"name": "_write_parallel", "is_method": true, "class_name": "Builder", "parameters": ["self", "docnames", "nproc"], "calls": ["_write_docname", "ParallelTasks", "make_chunks", "status_iterator", "tasks.join", "logger.info", "__", "len", "next", "tasks.add_task", "self.write_doc", "self.env.get_and_resolve_doctree", "self.write_doc_serialized", "arg.append"], "code_location": {"file": "__init__.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/builders", "start_line": 786, "end_line": 825}, "code_snippet": "    def _write_parallel(self, docnames: Sequence[str], nproc: int) -> None:\n        def write_process(docs: list[tuple[str, nodes.document]]) -> None:\n            self.phase = BuildPhase.WRITING\n            for docname, doctree in docs:\n                self.write_doc(docname, doctree)\n\n        # warm up caches/compile templates using the first document\n        firstname, docnames = docnames[0], docnames[1:]\n        _write_docname(firstname, env=self.env, builder=self, tags=self.tags)\n\n        tasks = ParallelTasks(nproc)\n        chunks = make_chunks(docnames, nproc)\n\n        # create a status_iterator to step progressbar after writing a document\n        # (see: ``on_chunk_done()`` function)\n        progress = status_iterator(\n            chunks,\n            __('writing output... '),\n            'darkgreen',\n            len(chunks),\n            self.config.verbosity,\n        )\n\n        def on_chunk_done(args: list[tuple[str, nodes.document]], result: None) -> None:\n            next(progress)\n\n        self.phase = BuildPhase.RESOLVING\n        for chunk in chunks:\n            arg = []\n            for docname in chunk:\n                doctree = self.env.get_and_resolve_doctree(\n                    docname, self, tags=self.tags\n                )\n                self.write_doc_serialized(docname, doctree)\n                arg.append((docname, doctree))\n            tasks.add_task(write_process, arg, on_chunk_done)\n\n        # make sure all threads have finished\n        tasks.join()\n        logger.info('')\n", "type": "function"}, {"name": "on_doctree_resolved", "is_method": false, "class_name": null, "parameters": ["app", "doctree", "docname"], "calls": [], "code_location": {"file": "test_versioning.py", "path": "/data3/pwh/swebench-repos/sphinx/tests", "start_line": 35, "end_line": 36}, "code_snippet": "def on_doctree_resolved(app, doctree, docname):\n    doctrees[docname] = doctree\n", "type": "function"}, {"name": "write_doc", "is_method": true, "class_name": "XMLBuilder", "parameters": ["self", "docname", "doctree"], "calls": ["doctree.deepcopy", "self.env.domains.sorted", "doctree.findall", "self._translate", "out_file_name.parent.mkdir", "node.attributes.items", "out_file_name.write_text", "isinstance", "isinstance", "logger.warning", "list", "enumerate", "__", "isinstance", "list"], "code_location": {"file": "xml.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/builders", "start_line": 60, "end_line": 81}, "code_snippet": "    def write_doc(self, docname: str, doctree: nodes.document) -> None:\n        # work around multiple string % tuple issues in docutils;\n        # replace tuples in attribute values with lists\n        doctree = doctree.deepcopy()\n        for domain in self.env.domains.sorted():\n            doctree[f'xmlns:{domain.name}'] = 'https://www.sphinx-doc.org/'\n        for node in doctree.findall(nodes.Element):\n            for att, value in node.attributes.items():\n                if isinstance(value, tuple):\n                    node.attributes[att] = list(value)\n                value = node.attributes[att]\n                if isinstance(value, list):\n                    for i, val in enumerate(value):\n                        if isinstance(val, tuple):\n                            value[i] = list(val)\n        output = self._translate(doctree)\n        out_file_name = self.outdir / (docname + self.out_suffix)\n        out_file_name.parent.mkdir(parents=True, exist_ok=True)\n        try:\n            out_file_name.write_text(output, encoding='utf-8')\n        except OSError as err:\n            logger.warning(__('error writing file %s: %s'), out_file_name, err)\n", "type": "function"}, {"name": "__init__", "is_method": true, "class_name": "BuildEnvironment", "parameters": ["self", "app"], "calls": ["_get_env_version", "default_settings.copy", "defaultdict", "defaultdict", "set", "defaultdict", "set", "set", "FilenameUniqDict", "DownloadFiles", "_CurrentDocument", "_DomainsContainer._from_environment", "self.setup"], "code_location": {"file": "__init__.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/environment", "start_line": 114, "end_line": 239}, "code_snippet": "    def __init__(self, app: Sphinx) -> None:\n        self._app: Sphinx = app\n        self.doctreedir = app.doctreedir\n        self.srcdir = app.srcdir\n        self.config: Config = None  # type: ignore[assignment]\n        self.config_status: int = CONFIG_UNSET\n        self.config_status_extra: str = ''\n        self.events: EventManager = app.events\n        self.project: Project = app.project\n        self.version: Mapping[str, int] = _get_env_version(app.extensions)\n\n        # the method of doctree versioning; see set_versioning_method\n        self.versioning_condition: Literal[False] | Callable[[Node], bool] | None = None\n        self.versioning_compare: bool | None = None\n\n        # the docutils settings for building\n        self.settings: dict[str, Any] = default_settings.copy()\n        self.settings['env'] = self\n\n        # All \"docnames\" here are /-separated and relative and exclude\n        # the source suffix.\n\n        # docname -> time of reading (in integer microseconds)\n        # contains all read docnames\n        self.all_docs: dict[str, int] = {}\n        # docname -> set of dependent file\n        # names, relative to documentation root\n        self.dependencies: dict[str, set[_StrPath]] = defaultdict(set)\n        # docname -> set of included file\n        # docnames included from other documents\n        self.included: dict[str, set[str]] = defaultdict(set)\n        # docnames to re-read unconditionally on next build\n        self.reread_always: set[str] = set()\n\n        self._pickled_doctree_cache: dict[str, bytes] = {}\n        \"\"\"In-memory cache for reading pickled doctrees from disk.\n        docname -> pickled doctree\n\n        This cache is used in the ``get_doctree`` method to avoid reading the\n        doctree from disk multiple times.\n        \"\"\"\n\n        self._write_doc_doctree_cache: dict[str, nodes.document] = {}\n        \"\"\"In-memory cache for unpickling doctrees from disk.\n        docname -> doctree\n\n        Items are added in ``Builder.write_doctree``, during the read phase,\n        then used only in the ``get_and_resolve_doctree`` method.\n        \"\"\"\n\n        # File metadata\n        # docname -> dict of metadata items\n        self.metadata: dict[str, dict[str, Any]] = defaultdict(dict)\n\n        # TOC inventory\n        # docname -> title node\n        self.titles: dict[str, nodes.title] = {}\n        # docname -> title node; only different if\n        # set differently with title directive\n        self.longtitles: dict[str, nodes.title] = {}\n        # docname -> table of contents nodetree\n        self.tocs: dict[str, nodes.bullet_list] = {}\n        # docname -> number of real entries\n        self.toc_num_entries: dict[str, int] = {}\n\n        # used to determine when to show the TOC\n        # in a sidebar (don't show if it's only one item)\n        # docname -> dict of sectionid -> number\n        self.toc_secnumbers: dict[str, dict[str, tuple[int, ...]]] = {}\n        # docname -> dict of figtype -> dict of figureid -> number\n        self.toc_fignumbers: dict[str, dict[str, dict[str, tuple[int, ...]]]] = {}\n\n        # docname -> list of toctree includefiles\n        self.toctree_includes: dict[str, list[str]] = {}\n        # docname -> set of files (containing its TOCs) to rebuild too\n        self.files_to_rebuild: dict[str, set[str]] = {}\n        # docnames that have :glob: toctrees\n        self.glob_toctrees: set[str] = set()\n        # docnames that have :numbered: toctrees\n        self.numbered_toctrees: set[str] = set()\n\n        # domain-specific inventories, here to be pickled\n        # domainname -> domain-specific dict\n        self.domaindata: dict[str, dict[str, Any]] = {}\n\n        # these map absolute path -> (docnames, unique filename)\n        self.images: FilenameUniqDict = FilenameUniqDict()\n        # filename -> (set of docnames, destination)\n        self.dlfiles: DownloadFiles = DownloadFiles()\n\n        # the original URI for images\n        self.original_image_uri: dict[_StrPath, str] = {}\n\n        # temporary data storage while reading a document\n        self.current_document: _CurrentDocument = _CurrentDocument()\n        # context for cross-references (e.g. current module or class)\n        # this is similar to ``self.current_document``,\n        # but will for example be copied to attributes of \"any\" cross references\n        self.ref_context: dict[str, Any] = {}\n\n        # search index data\n\n        # docname -> title\n        self._search_index_titles: dict[str, str | None] = {}\n        # docname -> filename\n        self._search_index_filenames: dict[str, str] = {}\n        # stemmed words -> set(docname)\n        self._search_index_mapping: dict[str, set[str]] = {}\n        # stemmed words in titles -> set(docname)\n        self._search_index_title_mapping: dict[str, set[str]] = {}\n        # docname -> all titles in document\n        self._search_index_all_titles: dict[str, list[tuple[str, str | None]]] = {}\n        # docname -> list(index entry)\n        self._search_index_index_entries: dict[str, list[tuple[str, str, str]]] = {}\n        # objtype -> index\n        self._search_index_objtypes: dict[tuple[str, str], int] = {}\n        # objtype index -> (domain, type, objname (localized))\n        self._search_index_objnames: dict[int, tuple[str, str, str]] = {}\n\n        # all the registered domains, set by the application\n        self.domains: _DomainsContainer = _DomainsContainer._from_environment(\n            self, registry=app.registry\n        )\n\n        # set up environment\n        self.setup(app)\n", "type": "function"}, {"name": "build", "is_method": true, "class_name": "SphinxTestApp", "parameters": ["self", "force_all", "filenames"], "calls": ["self.env._pickled_doctree_cache.clear", "build", "super"], "code_location": {"file": "util.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/testing", "start_line": 235, "end_line": 237}, "code_snippet": "    def build(self, force_all: bool = False, filenames: Sequence[Path] = ()) -> None:\n        self.env._pickled_doctree_cache.clear()\n        super().build(force_all, filenames)\n", "type": "function"}], "retrieved_count": 10, "cost_time": 1.1228251457214355}
{"question": "What is the structure of Sphinx's configuration system?", "answer": null, "relative_code_list": null, "ground_truth": "Sphinx's configuration system is structured around a centralized Config class that manages all configuration values for a Sphinx project. The system consists of several key components:\n\n1. **Config Class**: The main configuration abstraction that makes all config options available as attributes. It's exposed via `app.config` and `env.config` attributes.\n\n2. **_Opt Class**: Represents individual configuration options with metadata including default values, rebuild requirements, valid types, and descriptions. Each option is defined with a default value, rebuild specification (what needs to be rebuilt if changed), and valid type constraints.\n\n3. **Configuration File (conf.py)**: A Python file that defines project-specific configuration values. The file is executed as Python code at build time, allowing for dynamic configuration based on environment variables or other conditions.\n\n4. **Configuration Values Dictionary**: A comprehensive dictionary (`config_values`) that defines all available configuration options with their metadata. This includes general options (project, author, version), build-specific options, and format-specific options for different output formats.\n\n5. **Override System**: Supports configuration overrides through the `confoverrides` parameter, allowing values to be overridden programmatically without modifying the conf.py file.\n\n6. **Type Validation**: The system validates configuration values against their defined types using the `valid_types` field in _Opt objects.\n\n7. **Rebuild Tracking**: Each configuration option specifies what needs to be rebuilt when the option changes (e.g., 'env', 'html', 'epub').\n\n8. **Extension Integration**: The configuration system integrates with Sphinx's extension system, allowing extensions to add their own configuration options.\n\nThe configuration is loaded during Sphinx initialization and is used throughout the build process to control various aspects of document generation, formatting, and output.", "score": null, "retrieved_content": [{"name": "Sphinx", "docstring": "The main application class and extensibility interface.\n\n:ivar srcdir: Directory containing source.\n:ivar confdir: Directory containing ``conf.py``.\n:ivar doctreedir: Directory for storing pickled doctrees.\n:ivar outdir: Directory for storing build documents.", "methods": ["__init__", "fresh_env_used", "phase", "_init_i18n", "_init_env", "_create_fresh_env", "_load_existing_env", "_post_init_env", "preload_builder", "create_builder", "_init_builder", "build", "setup_extension", "require_sphinx", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "disconnect", "emit", "emit_firstresult", "add_builder", "add_config_value", "add_event", "set_translator", "add_node", "add_enumerable_node", "add_directive", "add_role", "add_generic_role", "add_domain", "add_directive_to_domain", "add_role_to_domain", "add_index_to_domain", "add_object_type", "add_crossref_type", "add_transform", "add_post_transform", "add_js_file", "add_css_file", "add_latex_package", "add_lexer", "add_autodocumenter", "add_autodoc_attrgetter", "add_search_language", "add_source_suffix", "add_source_parser", "add_env_collector", "add_html_theme", "add_html_math_renderer", "add_message_catalog", "is_parallel_allowed", "set_html_assets_policy"], "attributes": ["srcdir", "confdir", "outdir", "doctreedir"], "code_location": {"file": "application.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx", "start_line": 142, "end_line": 1822}, "type": "class"}, {"name": "Config", "docstring": "Configuration file abstraction.\n\nThe Config object makes the values of all config options available as\nattributes.\n\nIt is exposed via the :py:class:`~sphinx.application.Sphinx`\\ ``.config``\nand :py:class:`sphinx.environment.BuildEnvironment`\\ ``.config`` attributes.\nFor example, to get the value of :confval:`language`, use either\n``app.config.language`` or ``env.config.language``.", "methods": ["__init__", "values", "overrides", "verbosity", "read", "convert_overrides", "pre_init_values", "init_values", "_report_override_warnings", "__repr__", "__setattr__", "__getattr__", "__getitem__", "__setitem__", "__delitem__", "__contains__", "__iter__", "add", "filter", "__getstate__", "__setstate__", "__init__"], "attributes": ["c_id_attributes", "c_paren_attributes", "c_extra_keywords"], "code_location": {"file": "config.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx", "start_line": 208, "end_line": 574}, "type": "class"}, {"name": "__init__", "is_method": true, "class_name": "_Opt", "parameters": ["self", "default", "rebuild", "valid_types", "description"], "calls": ["__setattr__", "__setattr__", "__setattr__", "__setattr__", "super", "super", "super", "super"], "code_location": {"file": "config.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx", "start_line": 108, "end_line": 126}, "code_snippet": "    def __init__(\n        self,\n        default: Any,\n        rebuild: _ConfigRebuild,\n        valid_types: _OptValidTypes,\n        description: str = '',\n    ) -> None:\n        \"\"\"Configuration option type for Sphinx.\n\n        The type is intended to be immutable; changing the field values\n        is an unsupported action.\n        No validation is performed on the values, though consumers will\n        likely expect them to be of the types advertised.\n        The old tuple-based interface will be removed in Sphinx 9.\n        \"\"\"\n        super().__setattr__('default', default)\n        super().__setattr__('rebuild', rebuild)\n        super().__setattr__('valid_types', valid_types)\n        super().__setattr__('description', description)\n", "type": "function"}, {"name": "test_core_config", "is_method": false, "class_name": null, "parameters": ["app"], "calls": ["pytest.mark.sphinx", "getattr", "pytest.raises", "pytest.raises", "pytest.raises"], "code_location": {"file": "test_config.py", "path": "/data3/pwh/swebench-repos/sphinx/tests/test_config", "start_line": 91, "end_line": 138}, "code_snippet": "def test_core_config(app: SphinxTestApp) -> None:\n    cfg = app.config\n\n    # simple values\n    assert 'project' in cfg.__dict__\n    assert cfg.project == 'Sphinx <Tests>'\n    assert cfg.templates_path == ['_templates']\n\n    # overrides\n    assert cfg.root_doc == 'root'\n    assert cfg.latex_elements['maketitle'] == 'blah blah blah'\n    assert cfg.modindex_common_prefix == ['path1', 'path2']\n\n    # simple default values\n    assert 'locale_dirs' in cfg.__dict__\n    assert cfg.locale_dirs == ['locales']\n    assert cfg.trim_footnote_reference_space is False\n\n    # complex default values\n    assert 'html_title' not in cfg.__dict__\n    assert cfg.html_title == 'Sphinx <Tests> 0.6alpha1 documentation'\n\n    # complex default values mustn't raise\n    for valuename in cfg.config_values:\n        getattr(cfg, valuename)\n\n    # \"contains\" gives True both for set and unset values\n    assert 'project' in cfg\n    assert 'html_title' in cfg\n    assert 'nonexisting_value' not in cfg\n\n    # invalid values\n    with pytest.raises(AttributeError):\n        _ = cfg._value\n    with pytest.raises(AttributeError):\n        _ = cfg.nonexisting_value\n\n    # non-value attributes are deleted from the namespace\n    with pytest.raises(AttributeError):\n        _ = cfg.sys\n\n    # setting attributes\n    cfg.project = 'Foo'\n    assert cfg.project == 'Foo'\n\n    # alternative access via item interface\n    cfg['project'] = 'Sphinx Tests'\n    assert cfg['project'] == cfg.project == 'Sphinx Tests'\n", "type": "function"}, {"name": "SphinxComponentRegistry", "docstring": "", "methods": ["__init__", "autodoc_attrgettrs", "add_builder", "preload_builder", "create_builder", "add_domain", "has_domain", "create_domains", "add_directive_to_domain", "add_role_to_domain", "add_index_to_domain", "add_object_type", "add_crossref_type", "add_source_suffix", "add_source_parser", "get_source_parser", "get_source_parsers", "create_source_parser", "add_translator", "add_translation_handlers", "get_translator_class", "create_translator", "add_transform", "get_transforms", "add_post_transform", "get_post_transforms", "add_documenter", "add_autodoc_attrgetter", "add_css_files", "add_js_file", "has_latex_package", "add_latex_package", "add_enumerable_node", "add_html_math_renderer", "add_html_theme", "load_extension", "get_envversion"], "attributes": [], "code_location": {"file": "registry.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx", "start_line": 73, "end_line": 592}, "type": "class"}, {"name": "test_sphinx_directive_config", "is_method": false, "class_name": null, "parameters": [], "calls": ["SimpleNamespace", "make_directive_and_state", "hasattr", "object"], "code_location": {"file": "test_util_docutils_sphinx_directive.py", "path": "/data3/pwh/swebench-repos/sphinx/tests/test_util", "start_line": 72, "end_line": 78}, "code_snippet": "def test_sphinx_directive_config() -> None:\n    env = SimpleNamespace(config=object())\n    state, directive = make_directive_and_state(env=env)\n\n    assert hasattr(directive, 'config')\n    assert directive.config is directive.env.config\n    assert directive.config is state.document.settings.env.config\n", "type": "function"}, {"name": "Config", "docstring": "Sphinx napoleon extension settings in `conf.py`.\n\nListed below are all the settings used by napoleon and their default\nvalues. These settings can be changed in the Sphinx `conf.py` file. Make\nsure that \"sphinx.ext.napoleon\" is enabled in `conf.py`::\n\n    # conf.py\n\n    # Add any Sphinx extension module names here, as strings\n    extensions = ['sphinx.ext.napoleon']\n\n    # Napoleon settings\n    napoleon_google_docstring = True\n    napoleon_numpy_docstring = True\n    napoleon_include_init_with_doc = False\n    napoleon_include_private_with_doc = False\n    napoleon_include_special_with_doc = False\n    napoleon_use_admonition_for_examples = False\n    napoleon_use_admonition_for_notes = False\n    napoleon_use_admonition_for_references = False\n    napoleon_use_ivar = False\n    napoleon_use_param = True\n    napoleon_use_rtype = True\n    napoleon_use_keyword = True\n    napoleon_preprocess_types = False\n    napoleon_type_aliases = None\n    napoleon_custom_sections = None\n    napoleon_attr_annotations = True\n\n.. _Google style:\n   https://google.github.io/styleguide/pyguide.html\n.. _NumPy style:\n   https://numpydoc.readthedocs.io/en/latest/format.html#docstring-standard\n\nAttributes\n----------\nnapoleon_google_docstring : :obj:`bool` (Defaults to True)\n    True to parse `Google style`_ docstrings. False to disable support\n    for Google style docstrings.\nnapoleon_numpy_docstring : :obj:`bool` (Defaults to True)\n    True to parse `NumPy style`_ docstrings. False to disable support\n    for NumPy style docstrings.\nnapoleon_include_init_with_doc : :obj:`bool` (Defaults to False)\n    True to list ``__init___`` docstrings separately from the class\n    docstring. False to fall back to Sphinx's default behavior, which\n    considers the ``__init___`` docstring as part of the class\n    documentation.\n\n    **If True**::\n\n        def __init__(self):\n            \"\"\"\n            This will be included in the docs because it has a docstring\n            \"\"\"\n\n        def __init__(self):\n            # This will NOT be included in the docs\n\nnapoleon_include_private_with_doc : :obj:`bool` (Defaults to False)\n    True to include private members (like ``_membername``) with docstrings\n    in the documentation. False to fall back to Sphinx's default behavior.\n\n    **If True**::\n\n        def _included(self):\n            \"\"\"\n            This will be included in the docs because it has a docstring\n            \"\"\"\n            pass\n\n        def _skipped(self):\n            # This will NOT be included in the docs\n            pass\n\nnapoleon_include_special_with_doc : :obj:`bool` (Defaults to False)\n    True to include special members (like ``__membername__``) with\n    docstrings in the documentation. False to fall back to Sphinx's\n    default behavior.\n\n    **If True**::\n\n        def __str__(self):\n            \"\"\"\n            This will be included in the docs because it has a docstring\n            \"\"\"\n            return unicode(self).encode('utf-8')\n\n        def __unicode__(self):\n            # This will NOT be included in the docs\n            return unicode(self.__class__.__name__)\n\nnapoleon_use_admonition_for_examples : :obj:`bool` (Defaults to False)\n    True to use the ``.. admonition::`` directive for the **Example** and\n    **Examples** sections. False to use the ``.. rubric::`` directive\n    instead. One may look better than the other depending on what HTML\n    theme is used.\n\n    This `NumPy style`_ snippet will be converted as follows::\n\n        Example\n        -------\n        This is just a quick example\n\n    **If True**::\n\n        .. admonition:: Example\n\n           This is just a quick example\n\n    **If False**::\n\n        .. rubric:: Example\n\n        This is just a quick example\n\nnapoleon_use_admonition_for_notes : :obj:`bool` (Defaults to False)\n    True to use the ``.. admonition::`` directive for **Notes** sections.\n    False to use the ``.. rubric::`` directive instead.\n\n    Note\n    ----\n    The singular **Note** section will always be converted to a\n    ``.. note::`` directive.\n\n    See Also\n    --------\n    :confval:`napoleon_use_admonition_for_examples`\n\nnapoleon_use_admonition_for_references : :obj:`bool` (Defaults to False)\n    True to use the ``.. admonition::`` directive for **References**\n    sections. False to use the ``.. rubric::`` directive instead.\n\n    See Also\n    --------\n    :confval:`napoleon_use_admonition_for_examples`\n\nnapoleon_use_ivar : :obj:`bool` (Defaults to False)\n    True to use the ``:ivar:`` role for instance variables. False to use\n    the ``.. attribute::`` directive instead.\n\n    This `NumPy style`_ snippet will be converted as follows::\n\n        Attributes\n        ----------\n        attr1 : int\n            Description of `attr1`\n\n    **If True**::\n\n        :ivar attr1: Description of `attr1`\n        :vartype attr1: int\n\n    **If False**::\n\n        .. attribute:: attr1\n\n           Description of `attr1`\n\n           :type: int\n\nnapoleon_use_param : :obj:`bool` (Defaults to True)\n    True to use a ``:param:`` role for each function parameter. False to\n    use a single ``:parameters:`` role for all the parameters.\n\n    This `NumPy style`_ snippet will be converted as follows::\n\n        Parameters\n        ----------\n        arg1 : str\n            Description of `arg1`\n        arg2 : int, optional\n            Description of `arg2`, defaults to 0\n\n    **If True**::\n\n        :param arg1: Description of `arg1`\n        :type arg1: str\n        :param arg2: Description of `arg2`, defaults to 0\n        :type arg2: int, optional\n\n    **If False**::\n\n        :parameters: * **arg1** (*str*) --\n                       Description of `arg1`\n                     * **arg2** (*int, optional*) --\n                       Description of `arg2`, defaults to 0\n\nnapoleon_use_keyword : :obj:`bool` (Defaults to True)\n    True to use a ``:keyword:`` role for each function keyword argument.\n    False to use a single ``:keyword arguments:`` role for all the\n    keywords.\n\n    This behaves similarly to :confval:`napoleon_use_param`. Note unlike\n    docutils, ``:keyword:`` and ``:param:`` will not be treated the same\n    way - there will be a separate \"Keyword Arguments\" section, rendered\n    in the same fashion as \"Parameters\" section (type links created if\n    possible)\n\n    See Also\n    --------\n    :confval:`napoleon_use_param`\n\nnapoleon_use_rtype : :obj:`bool` (Defaults to True)\n    True to use the ``:rtype:`` role for the return type. False to output\n    the return type inline with the description.\n\n    This `NumPy style`_ snippet will be converted as follows::\n\n        Returns\n        -------\n        bool\n            True if successful, False otherwise\n\n    **If True**::\n\n        :returns: True if successful, False otherwise\n        :rtype: bool\n\n    **If False**::\n\n        :returns: *bool* -- True if successful, False otherwise\n\nnapoleon_preprocess_types : :obj:`bool` (Defaults to False)\n    Enable the type preprocessor.\n\nnapoleon_type_aliases : :obj:`dict` (Defaults to None)\n    Add a mapping of strings to string, translating types in numpy\n    style docstrings. Only works if ``napoleon_preprocess_types = True``.\n\nnapoleon_custom_sections : :obj:`list` (Defaults to None)\n    Add a list of custom sections to include, expanding the list of parsed sections.\n\n    The entries can either be strings or tuples, depending on the intention:\n      * To create a custom \"generic\" section, just pass a string.\n      * To create an alias for an existing section, pass a tuple containing the\n        alias name and the original, in that order.\n      * To create a custom section that displays like the parameters or returns\n        section, pass a tuple containing the custom section name and a string\n        value, \"params_style\" or \"returns_style\".\n\n    If an entry is just a string, it is interpreted as a header for a generic\n    section. If the entry is a tuple/list/indexed container, the first entry\n    is the name of the section, the second is the section key to emulate. If the\n    second entry value is \"params_style\" or \"returns_style\", the custom section\n    will be displayed like the parameters section or returns section.\n\nnapoleon_attr_annotations : :obj:`bool` (Defaults to True)\n    Use the type annotations of class attributes that are documented in the docstring\n    but do not have a type in the docstring.", "methods": [], "attributes": [], "code_location": {"file": "__init__.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/ext/napoleon", "start_line": 21, "end_line": 297}, "type": "class"}, {"name": "setup", "is_method": false, "class_name": null, "parameters": ["app"], "calls": ["app.connect", "app.connect", "app.connect", "app.connect", "app.connect", "app.connect", "app.connect", "app.connect", "app.connect"], "code_location": {"file": "config.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx", "start_line": 911, "end_line": 926}, "code_snippet": "def setup(app: Sphinx) -> ExtensionMetadata:\n    app.connect('config-inited', deprecate_source_encoding, priority=790)\n    app.connect('config-inited', convert_source_suffix, priority=800)\n    app.connect('config-inited', convert_highlight_options, priority=800)\n    app.connect('config-inited', init_numfig_format, priority=800)\n    app.connect('config-inited', evaluate_copyright_placeholders, priority=795)\n    app.connect('config-inited', correct_copyright_year, priority=800)\n    app.connect('config-inited', check_confval_types, priority=800)\n    app.connect('config-inited', check_primary_domain, priority=800)\n    app.connect('env-get-outdated', check_master_doc)\n\n    return {\n        'version': 'builtin',\n        'parallel_read_safe': True,\n        'parallel_write_safe': True,\n    }\n", "type": "function"}, {"name": "__init__", "is_method": true, "class_name": "Sphinx", "parameters": ["self", "srcdir", "confdir", "outdir", "doctreedir", "buildername", "confoverrides", "status", "warning", "freshenv", "warningiserror", "tags", "verbosity", "parallel", "keep_going", "pdb", "exception_on_warning"], "calls": ["SphinxComponentRegistry", "resolve", "resolve", "resolve", "bool", "bool", "logging.setup", "EventManager", "deque", "logger.info", "Tags", "self._init_i18n", "self.preload_builder", "self.config._report_override_warnings", "self.events.emit", "Project", "self._init_env", "self.create_builder", "self._post_init_env", "self._init_builder", "self.srcdir.is_dir", "ApplicationError", "self.outdir.exists", "ApplicationError", "ApplicationError", "StringIO", "StringIO", "bold", "Config", "resolve", "Config.read", "VersionRequirementError", "self.setup_extension", "self.setup_extension", "self.outdir.is_dir", "_StrPath", "_StrPath", "_StrPath", "self.outdir.is_dir", "__", "__", "progress_message", "ensuredir", "__", "prefixed_warnings", "callable", "__", "__", "_StrPath", "__", "__", "self.config.setup", "ConfigError", "__"], "code_location": {"file": "application.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx", "start_line": 159, "end_line": 334}, "code_snippet": "    def __init__(\n        self,\n        srcdir: str | os.PathLike[str],\n        confdir: str | os.PathLike[str] | None,\n        outdir: str | os.PathLike[str],\n        doctreedir: str | os.PathLike[str],\n        buildername: str,\n        confoverrides: dict[str, Any] | None = None,\n        status: IO[str] | None = sys.stdout,\n        warning: IO[str] | None = sys.stderr,\n        freshenv: bool = False,\n        warningiserror: bool = False,\n        tags: Sequence[str] = (),\n        verbosity: int = 0,\n        parallel: int = 0,\n        keep_going: bool = False,\n        pdb: bool = False,\n        exception_on_warning: bool = False,\n    ) -> None:\n        \"\"\"Initialize the Sphinx application.\n\n        :param srcdir: The path to the source directory.\n        :param confdir: The path to the configuration directory.\n            If not given, it is assumed to be the same as ``srcdir``.\n        :param outdir: Directory for storing build documents.\n        :param doctreedir: Directory for caching pickled doctrees.\n        :param buildername: The name of the builder to use.\n        :param confoverrides: A dictionary of configuration settings that override the\n            settings in the configuration file.\n        :param status: A file-like object to write status messages to.\n        :param warning: A file-like object to write warnings to.\n        :param freshenv: If true, clear the cached environment.\n        :param warningiserror: If true, warnings become errors.\n        :param tags: A list of tags to apply.\n        :param verbosity: The verbosity level.\n        :param parallel: The maximum number of parallel jobs to use\n            when reading/writing documents.\n        :param keep_going: Unused.\n        :param pdb: If true, enable the Python debugger on an exception.\n        :param exception_on_warning: If true, raise an exception on warnings.\n        \"\"\"\n        self.verbosity = verbosity\n        self._fresh_env_used: bool | None = None\n        self.extensions: dict[str, Extension] = {}\n        self.registry = SphinxComponentRegistry()\n\n        # validate provided directories\n        self.srcdir = _StrPath(srcdir).resolve()\n        self.outdir = _StrPath(outdir).resolve()\n        self.doctreedir = _StrPath(doctreedir).resolve()\n\n        if not self.srcdir.is_dir():\n            raise ApplicationError(\n                __('Cannot find source directory (%s)') % self.srcdir\n            )\n\n        if self.outdir.exists() and not self.outdir.is_dir():\n            raise ApplicationError(\n                __('Output directory (%s) is not a directory') % self.outdir\n            )\n\n        if self.srcdir == self.outdir:\n            raise ApplicationError(\n                __('Source directory and destination directory cannot be identical')\n            )\n\n        self.parallel = parallel\n\n        if status is None:\n            self._status: IO[str] = StringIO()\n            self.quiet: bool = True\n        else:\n            self._status = status\n            self.quiet = False\n\n        if warning is None:\n            self._warning: IO[str] = StringIO()\n        else:\n            self._warning = warning\n        self._warncount = 0\n        self.keep_going = bool(warningiserror)  # Unused\n        self._fail_on_warnings = bool(warningiserror)\n        self.pdb = pdb\n        self._exception_on_warning = exception_on_warning\n        logging.setup(self, self._status, self._warning, verbosity=verbosity)\n\n        self.events = EventManager(self)\n\n        # keep last few messages for traceback\n        # This will be filled by sphinx.util.logging.LastMessagesWriter\n        self.messagelog: deque[str] = deque(maxlen=10)\n\n        # say hello to the world\n        logger.info(bold(__('Running Sphinx v%s')), sphinx.__display_version__)\n\n        # status code for command-line application\n        self.statuscode = 0\n\n        # read config\n        overrides = confoverrides or {}\n        self.tags = Tags(tags)\n        if confdir is None:\n            # set confdir to srcdir if -C given (!= no confdir); a few pieces\n            # of code expect a confdir to be set\n            self.confdir = self.srcdir\n            self.config = Config({}, overrides)\n        else:\n            self.confdir = _StrPath(confdir).resolve()\n            self.config = Config.read(self.confdir, overrides=overrides, tags=self.tags)\n        self.config._verbosity = -1 if self.quiet else self.verbosity\n\n        # set up translation infrastructure\n        self._init_i18n()\n\n        # check the Sphinx version if requested\n        if (\n            self.config.needs_sphinx\n            and self.config.needs_sphinx > sphinx.__display_version__\n        ):\n            raise VersionRequirementError(\n                __(\n                    'This project needs at least Sphinx v%s and therefore cannot '\n                    'be built with this version.'\n                )\n                % self.config.needs_sphinx\n            )\n\n        # load all built-in extension modules, first-party extension modules,\n        # and first-party themes\n        for extension in builtin_extensions:\n            self.setup_extension(extension)\n\n        # load all user-given extension modules\n        for extension in self.config.extensions:\n            self.setup_extension(extension)\n\n        # preload builder module (before init config values)\n        self.preload_builder(buildername)\n\n        if not self.outdir.is_dir():\n            with progress_message(__('making output directory')):\n                ensuredir(self.outdir)\n\n        # the config file itself can be an extension\n        if self.config.setup:\n            prefix = __('while setting up extension %s:') % 'conf.py'\n            with prefixed_warnings(prefix):\n                if callable(self.config.setup):\n                    self.config.setup(self)\n                else:\n                    raise ConfigError(\n                        __(\n                            \"'setup' as currently defined in conf.py isn't a Python callable. \"\n                            'Please modify its definition to make it a callable function. '\n                            'This is needed for conf.py to behave as a Sphinx extension.'\n                        ),\n                    )\n\n        # Report any warnings for overrides.\n        self.config._report_override_warnings()\n        self.events.emit('config-inited', self.config)\n\n        # create the project\n        self.project = Project(self.srcdir, self.config.source_suffix)\n\n        # set up the build environment\n        self.env = self._init_env(freshenv)\n\n        # create the builder\n        self.builder = self.create_builder(buildername)\n\n        # build environment post-initialisation, after creating the builder\n        self._post_init_env()\n\n        # set up the builder\n        self._init_builder()\n", "type": "function"}, {"name": "setup", "is_method": false, "class_name": null, "parameters": ["app"], "calls": ["app.add_builder", "app.add_config_value", "app.add_config_value", "app.add_config_value", "app.add_config_value", "app.add_config_value", "app.add_config_value", "app.add_config_value", "app.add_config_value", "app.add_config_value", "app.add_config_value", "app.add_config_value", "app.add_config_value", "app.add_config_value", "frozenset", "frozenset", "frozenset", "frozenset", "frozenset", "frozenset", "frozenset", "frozenset", "frozenset", "frozenset", "frozenset", "frozenset", "frozenset"], "code_location": {"file": "coverage.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/ext", "start_line": 523, "end_line": 557}, "code_snippet": "def setup(app: Sphinx) -> ExtensionMetadata:\n    app.add_builder(CoverageBuilder)\n    app.add_config_value('coverage_modules', (), '', types=frozenset({list, tuple}))\n    app.add_config_value(\n        'coverage_ignore_modules', [], '', types=frozenset({list, tuple})\n    )\n    app.add_config_value(\n        'coverage_ignore_functions', [], '', types=frozenset({list, tuple})\n    )\n    app.add_config_value(\n        'coverage_ignore_classes', [], '', types=frozenset({list, tuple})\n    )\n    app.add_config_value(\n        'coverage_ignore_pyobjects', [], '', types=frozenset({list, tuple})\n    )\n    app.add_config_value('coverage_c_path', [], '', types=frozenset({list, tuple}))\n    app.add_config_value('coverage_c_regexes', {}, '', types=frozenset({dict}))\n    app.add_config_value('coverage_ignore_c_items', {}, '', types=frozenset({dict}))\n    app.add_config_value('coverage_write_headline', True, '', types=frozenset({bool}))\n    app.add_config_value(\n        'coverage_statistics_to_report', True, '', types=frozenset({bool})\n    )\n    app.add_config_value(\n        'coverage_statistics_to_stdout', True, '', types=frozenset({bool})\n    )\n    app.add_config_value(\n        'coverage_skip_undoc_in_source', False, '', types=frozenset({bool})\n    )\n    app.add_config_value(\n        'coverage_show_missing_items', False, '', types=frozenset({bool})\n    )\n    return {\n        'version': sphinx.__display_version__,\n        'parallel_read_safe': True,\n    }\n", "type": "function"}], "retrieved_count": 10, "cost_time": 1.169609546661377}
{"question": "What is the function of the Domain class in Sphinx's architecture?", "answer": null, "relative_code_list": null, "ground_truth": "The Domain class in Sphinx's architecture serves as a specialized container for organizing and managing documentation elements that belong to a specific domain or language. It provides a structured way to handle object descriptions, cross-references, and domain-specific functionality.\n\nKey functions of the Domain class include:\n\n1. **Object Type Management**: Each domain defines and manages specific object types (e.g., functions, classes, modules for Python domain) through the `object_types` attribute, which maps object type names to `ObjType` instances.\n\n2. **Directive Registration**: Domains register domain-specific directives (e.g., `py:function`, `cpp:class`) that create object descriptions and store information about documented objects.\n\n3. **Role Management**: Domains provide domain-specific roles (e.g., `:py:func:`, `:cpp:class:`) for creating cross-references to objects within that domain.\n\n4. **Data Storage**: Each domain maintains its own data storage in `self.data`, which is stored in the environment's `domaindata` dictionary under the domain's name. This data persists across builds and contains information about all objects in that domain.\n\n5. **Cross-Reference Resolution**: Domains implement methods to resolve cross-references to objects within their domain, providing domain-specific logic for finding and linking to documented objects.\n\n6. **Index Generation**: Domains can provide custom indices for their objects, allowing for specialized indexing and search functionality.\n\n7. **Namespace Isolation**: By organizing functionality into domains, Sphinx avoids naming conflicts when documenting multiple languages or systems in the same project.\n\n8. **Extension Support**: Domains provide a framework for extensions to add new object types, directives, and roles specific to their domain.\n\nThe Domain class is instantiated for each active domain during the build process and is given access to the BuildEnvironment. It serves as the foundation for Sphinx's multi-language documentation capabilities, allowing different domains to coexist and provide specialized functionality for their respective languages or systems.", "score": null, "retrieved_content": [{"name": "Domain", "docstring": "A Domain is meant to be a group of \"object\" description directives for\nobjects of a similar nature, and corresponding roles to create references to\nthem.  Examples would be Python modules, classes, functions etc., elements\nof a templating language, Sphinx roles and directives, etc.\n\nEach domain has a separate storage for information about existing objects\nand how to reference them in `self.data`, which must be a dictionary.  It\nalso must implement several functions that expose the object information in\na uniform way to parts of Sphinx that allow the user to reference or search\nfor objects in a domain-agnostic way.\n\nAbout `self.data`: since all object and cross-referencing information is\nstored on a BuildEnvironment instance, the `domain.data` object is also\nstored in the `env.domaindata` dict under the key `domain.name`.  Before the\nbuild process starts, every active domain is instantiated and given the\nenvironment object; the `domaindata` dict must then either be nonexistent or\na dictionary whose 'version' key is equal to the domain class'\n:attr:`data_version` attribute.  Otherwise, `OSError` is raised and the\npickled environment is discarded.", "methods": ["__init__", "setup", "add_object_type", "role", "directive", "clear_doc", "merge_domaindata", "process_doc", "check_consistency", "process_field_xref", "resolve_xref", "resolve_any_xref", "get_objects", "get_type_name", "get_enumerable_node_type", "get_full_qualified_name"], "attributes": [], "code_location": {"file": "__init__.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/domains", "start_line": 62, "end_line": 331}, "type": "class"}, {"name": "__init__", "is_method": true, "class_name": "Index", "parameters": ["self", "domain"], "calls": ["SphinxError"], "code_location": {"file": "_index.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/domains", "start_line": 81, "end_line": 85}, "code_snippet": "    def __init__(self, domain: Domain) -> None:\n        if not self.name or self.localname is None:\n            msg = f'Index subclass {self.__class__.__name__} has no valid name or localname'\n            raise SphinxError(msg)\n        self.domain = domain\n", "type": "function"}, {"name": "CDomain", "docstring": "C language domain.", "methods": ["clear_doc", "process_doc", "process_field_xref", "merge_domaindata", "_resolve_xref_inner", "resolve_xref", "resolve_any_xref", "get_objects"], "attributes": ["name", "label", "object_types", "directives", "roles"], "code_location": {"file": "__init__.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/domains/c", "start_line": 770, "end_line": 970}, "type": "class"}, {"name": "SphinxDomains", "docstring": "Collect objects to Sphinx domains for cross references.", "methods": ["apply"], "attributes": ["default_priority"], "code_location": {"file": "references.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/transforms", "start_line": 33, "end_line": 41}, "type": "class"}, {"name": "sphinx_domains", "docstring": "Monkey-patch directive and role dispatch, so that domain-specific\nmarkup takes precedence.", "methods": ["__init__", "directive", "role"], "attributes": [], "code_location": {"file": "docutils.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/util", "start_line": 301, "end_line": 380}, "type": "class"}, {"name": "__init__", "is_method": true, "class_name": "Domain", "parameters": ["self", "env"], "calls": ["dict", "dict", "dict", "list", "self.object_types.items", "isinstance", "copy.deepcopy", "OSError", "append", "self._role2type.setdefault"], "code_location": {"file": "__init__.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/domains", "start_line": 107, "end_line": 135}, "code_snippet": "    def __init__(self, env: BuildEnvironment) -> None:\n        domain_data: dict[str, dict[str, Any]] = env.domaindata\n        self.env: BuildEnvironment = env\n        self._role_cache: dict[str, RoleFunction] = {}\n        self._directive_cache: dict[str, type[Directive]] = {}\n        self._role2type: dict[str, list[str]] = {}\n        self._type2role: dict[str, str] = {}\n\n        # convert class variables to instance one (to enhance through API)\n        self.object_types = dict(self.object_types)  # type: ignore[misc]\n        self.directives = dict(self.directives)  # type: ignore[misc]\n        self.roles = dict(self.roles)  # type: ignore[misc]\n        self.indices = list(self.indices)  # type: ignore[misc]\n\n        if self.name not in domain_data:\n            assert isinstance(self.initial_data, dict)\n            new_data = copy.deepcopy(self.initial_data)\n            new_data['version'] = self.data_version\n            self.data = domain_data[self.name] = new_data\n        else:\n            self.data = domain_data[self.name]\n            if self.data['version'] != self.data_version:\n                raise OSError('data of %r domain out of date' % self.label)\n        for name, obj in self.object_types.items():\n            for rolename in obj.roles:\n                self._role2type.setdefault(rolename, []).append(name)\n            self._type2role[name] = obj.roles[0] if obj.roles else ''\n        self.objtypes_for_role = self._role2type.get\n        self.role_for_objtype = self._type2role.get\n", "type": "function"}, {"name": "DurationDomain", "docstring": "A domain for durations of Sphinx processing.", "methods": ["reading_durations", "note_reading_duration", "clear", "clear_doc", "merge_domaindata"], "attributes": ["name"], "code_location": {"file": "duration.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/ext", "start_line": 30, "end_line": 55}, "type": "class"}, {"name": "DefaultDomain", "docstring": "Directive to (re-)set the default domain for this source file.", "methods": ["run"], "attributes": ["has_content", "required_arguments", "optional_arguments", "final_argument_whitespace"], "code_location": {"file": "__init__.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/directives", "start_line": 350, "end_line": 363}, "type": "class"}, {"name": "create_domains", "is_method": true, "class_name": "SphinxComponentRegistry", "parameters": ["self", "env"], "calls": ["self.domains.values", "DomainClass", "domain.directives.update", "domain.roles.update", "domain.indices.extend", "items", "self.domain_directives.get", "self.domain_roles.get", "self.domain_indices.get", "domain.add_object_type", "self.domain_object_types.get"], "code_location": {"file": "registry.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx", "start_line": 205, "end_line": 216}, "code_snippet": "    def create_domains(self, env: BuildEnvironment) -> Iterator[Domain]:\n        for DomainClass in self.domains.values():\n            domain = DomainClass(env)\n\n            # transplant components added by extensions\n            domain.directives.update(self.domain_directives.get(domain.name, {}))\n            domain.roles.update(self.domain_roles.get(domain.name, {}))\n            domain.indices.extend(self.domain_indices.get(domain.name, []))\n            for name, objtype in self.domain_object_types.get(domain.name, {}).items():\n                domain.add_object_type(name, objtype)\n\n            yield domain\n", "type": "function"}, {"name": "ReSTDomain", "docstring": "ReStructuredText domain.", "methods": ["objects", "note_object", "clear_doc", "merge_domaindata", "resolve_xref", "resolve_any_xref", "get_objects"], "attributes": ["name", "label", "object_types", "directives", "roles"], "code_location": {"file": "rst.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/domains", "start_line": 227, "end_line": 338}, "type": "class"}], "retrieved_count": 10, "cost_time": 1.171818494796753}
{"question": "What is Sphinx's role system?", "answer": null, "relative_code_list": null, "ground_truth": "Sphinx's role system is a markup mechanism that allows users to insert semantic markup into documents using interpreted text roles. Roles are written in the format `:rolename:`content`` and provide a way to create cross-references, apply formatting, and add semantic meaning to text.\n\nKey components of Sphinx's role system include:\n\n1. **XRefRole**: The core cross-referencing role class that handles automatic creation of references and content nodes. It supports features like automatic title/target separation with `title <target>` syntax, parentheses normalization, and customizable node classes.\n\n2. **Domain-specific roles**: Different domains (Python, C++, etc.) provide specialized roles for their object types. For example, the Python domain provides `:py:func:`, `:py:class:`, `:py:mod:` roles.\n\n3. **Standard domain roles**: The standard domain provides general-purpose roles like `:ref:`, `:doc:`, `:term:`, `:option:`, `:envvar:`, and `:any:` for cross-referencing various document elements.\n\n4. **Custom role creation**: Sphinx provides base classes like `SphinxRole` and `ReferenceRole` for creating custom roles. The `ReferenceRole` class implements Sphinx's title/target logic and is useful for creating cross-reference roles.\n\n5. **Role registration**: Roles are registered using `app.add_role()` or `app.add_role_to_domain()` methods, allowing extensions to add new roles.\n\n6. **Cross-reference modifiers**: Roles support modifiers like custom link text (`:role:`custom text <target>``) and suppressed links (`:role:`!target``) to prevent link generation.\n\nThe role system integrates with Sphinx's domain system and event system, allowing for flexible cross-reference resolution and extensibility through the extension API.", "score": null, "retrieved_content": [{"name": "SphinxRole", "docstring": "A base class for Sphinx roles.\n\nThis class provides helper methods for Sphinx roles.\n\n.. versionadded:: 2.0\n\n.. note:: The subclasses of this class might not work with docutils.\n          This class is strongly coupled with Sphinx.", "methods": ["__call__", "run", "env", "config", "get_source_info", "set_source_info", "get_location"], "attributes": [], "code_location": {"file": "docutils.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/util", "start_line": 603, "end_line": 699}, "type": "class"}, {"name": "IntersphinxRole", "docstring": "", "methods": ["__init__", "run", "get_inventory_and_name_suffix", "_get_domain_role", "_emit_warning", "_concat_strings", "get_role_name", "is_existent_role", "invoke_role"], "attributes": ["_re_inv_ref"], "code_location": {"file": "_resolve.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/ext/intersphinx", "start_line": 370, "end_line": 596}, "type": "class"}, {"name": "setup", "is_method": false, "class_name": null, "parameters": ["app"], "calls": ["generic_docroles.items", "specific_docroles.items", "roles.register_canonical_role", "roles.GenericRole", "roles.CustomRole", "roles.register_local_role", "roles.register_local_role"], "code_location": {"file": "roles.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx", "start_line": 634, "end_line": 653}, "code_snippet": "def setup(app: Sphinx) -> ExtensionMetadata:\n    from docutils.parsers.rst import roles\n\n    for rolename, nodeclass in generic_docroles.items():\n        generic = roles.GenericRole(rolename, nodeclass)\n        role = roles.CustomRole(rolename, generic, {'classes': [rolename]})  # type: ignore[arg-type]\n        roles.register_local_role(rolename, role)  # type: ignore[arg-type]\n\n    for rolename, func in specific_docroles.items():\n        roles.register_local_role(rolename, func)  # type: ignore[arg-type]\n\n    # Since docutils registers it as a canonical role, override it as a\n    # canonical role as well.\n    roles.register_canonical_role('code', code_role)  # type: ignore[arg-type]\n\n    return {\n        'version': 'builtin',\n        'parallel_read_safe': True,\n        'parallel_write_safe': True,\n    }\n", "type": "function"}, {"name": "sphinx_domains", "docstring": "Monkey-patch directive and role dispatch, so that domain-specific\nmarkup takes precedence.", "methods": ["__init__", "directive", "role"], "attributes": [], "code_location": {"file": "docutils.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/util", "start_line": 301, "end_line": 380}, "type": "class"}, {"name": "setup_link_roles", "is_method": false, "class_name": null, "parameters": ["app"], "calls": ["app.config.extlinks.items", "app.add_role", "make_link_role"], "code_location": {"file": "extlinks.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/ext", "start_line": 123, "end_line": 125}, "code_snippet": "def setup_link_roles(app: Sphinx) -> None:\n    for name, (base_url, caption) in app.config.extlinks.items():\n        app.add_role(name, make_link_role(name, base_url, caption))\n", "type": "function"}, {"name": "DefaultRole", "docstring": "Set the default interpreted text role.  Overridden from docutils.", "methods": ["run"], "attributes": ["optional_arguments", "final_argument_whitespace"], "code_location": {"file": "__init__.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/directives", "start_line": 320, "end_line": 347}, "type": "class"}, {"name": "ReSTRole", "docstring": "Description of a reST role.", "methods": ["handle_signature", "get_index_text"], "attributes": [], "code_location": {"file": "rst.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/domains", "start_line": 214, "end_line": 224}, "type": "class"}, {"name": "role", "is_method": true, "class_name": "CustomReSTDispatcher", "parameters": ["self", "role_name", "language_module", "lineno", "reporter"], "calls": ["self.role_func"], "code_location": {"file": "docutils.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/util", "start_line": 282, "end_line": 294}, "code_snippet": "    def role(\n        self,\n        role_name: str,\n        language_module: ModuleType,\n        lineno: int,\n        reporter: Reporter,\n    ) -> tuple[RoleFunction, list[system_message]]:\n        return self.role_func(\n            role_name,\n            language_module,  # type: ignore[return-value]\n            lineno,\n            reporter,\n        )\n", "type": "function"}, {"name": "test_rst_role", "is_method": false, "class_name": null, "parameters": ["app"], "calls": ["pytest.mark.sphinx", "restructuredtext.parse", "assert_node", "assert_node", "assert_node"], "code_location": {"file": "test_domain_rst.py", "path": "/data3/pwh/swebench-repos/sphinx/tests/test_domains", "start_line": 268, "end_line": 286}, "code_snippet": "def test_rst_role(app: SphinxTestApp) -> None:\n    text = '.. rst:role:: ref'\n    doctree = restructuredtext.parse(app, text)\n    assert_node(\n        doctree,\n        (\n            addnodes.index,\n            [desc, ([desc_signature, desc_name, ':ref:'], [desc_content, ()])],\n        ),\n    )\n    assert_node(doctree[0], entries=[('single', 'ref (role)', 'role-ref', '', None)])\n    assert_node(\n        doctree[1],\n        addnodes.desc,\n        desctype='role',\n        domain='rst',\n        objtype='role',\n        no_index=False,\n    )\n", "type": "function"}, {"name": "IntersphinxDispatcher", "docstring": "Custom dispatcher for external role.\n\nThis enables :external:***:/:external+***: roles on parsing reST document.", "methods": ["role"], "attributes": [], "code_location": {"file": "_resolve.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/ext/intersphinx", "start_line": 351, "end_line": 367}, "type": "class"}], "retrieved_count": 10, "cost_time": 1.2077934741973877}
{"question": "What are the core components of Sphinx's document processing pipeline?", "answer": null, "relative_code_list": null, "ground_truth": "Sphinx's document processing pipeline consists of several core components that work together to transform source documents into output formats. The main components include:\n\n1. **Sphinx Application (Sphinx class)**: The main application class that orchestrates the entire build process, manages extensions, and controls high-level functionality.\n\n2. **BuildEnvironment**: Responsible for parsing source documents, storing metadata about the document collection, and managing cross-references. It maintains the state of the build and is serialized to disk after each build.\n\n3. **Builder Classes**: Convert parsed documents into specific output formats (HTML, LaTeX, etc.). Each builder implements the core build workflow through methods like build(), read(), and write().\n\n4. **Parser System**: Handles different input formats (reStructuredText, Markdown) and converts them into docutils document trees.\n\n5. **Transform System**: Applies transformations to document trees during processing. This includes both regular transforms and post-transforms that handle cross-references and other document modifications.\n\n6. **Domain System**: Provides specialized functionality for different types of documentation (Python, C++, etc.) including cross-reference resolution and object descriptions.\n\n7. **Event System**: Manages the event-driven architecture that allows extensions to hook into various stages of the build process.\n\n8. **Configuration System**: Manages project settings and configuration values from conf.py files.\n\nThe pipeline follows a multi-phase build process: initialization, reading (parsing source files), consistency checks, resolving (cross-references), and writing (output generation).", "score": null, "retrieved_content": [{"name": "SphinxStandaloneReader", "docstring": "A basic document reader for Sphinx.", "methods": ["__init__", "_setup_transforms", "read", "read_source"], "attributes": [], "code_location": {"file": "io.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx", "start_line": 79, "end_line": 109}, "type": "class"}, {"name": "Sphinx", "docstring": "The main application class and extensibility interface.\n\n:ivar srcdir: Directory containing source.\n:ivar confdir: Directory containing ``conf.py``.\n:ivar doctreedir: Directory for storing pickled doctrees.\n:ivar outdir: Directory for storing build documents.", "methods": ["__init__", "fresh_env_used", "phase", "_init_i18n", "_init_env", "_create_fresh_env", "_load_existing_env", "_post_init_env", "preload_builder", "create_builder", "_init_builder", "build", "setup_extension", "require_sphinx", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "disconnect", "emit", "emit_firstresult", "add_builder", "add_config_value", "add_event", "set_translator", "add_node", "add_enumerable_node", "add_directive", "add_role", "add_generic_role", "add_domain", "add_directive_to_domain", "add_role_to_domain", "add_index_to_domain", "add_object_type", "add_crossref_type", "add_transform", "add_post_transform", "add_js_file", "add_css_file", "add_latex_package", "add_lexer", "add_autodocumenter", "add_autodoc_attrgetter", "add_search_language", "add_source_suffix", "add_source_parser", "add_env_collector", "add_html_theme", "add_html_math_renderer", "add_message_catalog", "is_parallel_allowed", "set_html_assets_policy"], "attributes": ["srcdir", "confdir", "outdir", "doctreedir"], "code_location": {"file": "application.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx", "start_line": 142, "end_line": 1822}, "type": "class"}, {"name": "SphinxTransformer", "docstring": "A transformer for Sphinx.", "methods": ["set_environment", "apply_transforms"], "attributes": [], "code_location": {"file": "__init__.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/transforms", "start_line": 81, "end_line": 108}, "type": "class"}, {"name": "setup", "is_method": false, "class_name": null, "parameters": ["app"], "calls": ["app.add_transform", "app.add_transform", "app.add_transform", "app.add_transform", "app.add_transform", "app.add_transform", "app.add_transform", "app.add_transform", "app.add_transform", "app.add_transform", "app.add_transform", "app.add_transform", "app.add_transform", "app.add_transform", "app.add_transform"], "code_location": {"file": "__init__.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/transforms", "start_line": 511, "end_line": 532}, "code_snippet": "def setup(app: Sphinx) -> ExtensionMetadata:\n    app.add_transform(ApplySourceWorkaround)\n    app.add_transform(ExtraTranslatableNodes)\n    app.add_transform(DefaultSubstitutions)\n    app.add_transform(MoveModuleTargets)\n    app.add_transform(HandleCodeBlocks)\n    app.add_transform(SortIds)\n    app.add_transform(DoctestTransform)\n    app.add_transform(AutoNumbering)\n    app.add_transform(AutoIndexUpgrader)\n    app.add_transform(FilterSystemMessages)\n    app.add_transform(UnreferencedFootnotesDetector)\n    app.add_transform(SphinxSmartQuotes)\n    app.add_transform(DoctreeReadEvent)\n    app.add_transform(GlossarySorter)\n    app.add_transform(ReorderConsecutiveTargetAndIndexNodes)\n\n    return {\n        'version': 'builtin',\n        'parallel_read_safe': True,\n        'parallel_write_safe': True,\n    }\n", "type": "function"}, {"name": "SphinxComponentRegistry", "docstring": "", "methods": ["__init__", "autodoc_attrgettrs", "add_builder", "preload_builder", "create_builder", "add_domain", "has_domain", "create_domains", "add_directive_to_domain", "add_role_to_domain", "add_index_to_domain", "add_object_type", "add_crossref_type", "add_source_suffix", "add_source_parser", "get_source_parser", "get_source_parsers", "create_source_parser", "add_translator", "add_translation_handlers", "get_translator_class", "create_translator", "add_transform", "get_transforms", "add_post_transform", "get_post_transforms", "add_documenter", "add_autodoc_attrgetter", "add_css_files", "add_js_file", "has_latex_package", "add_latex_package", "add_enumerable_node", "add_html_math_renderer", "add_html_theme", "load_extension", "get_envversion"], "attributes": [], "code_location": {"file": "registry.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx", "start_line": 73, "end_line": 592}, "type": "class"}, {"name": "SphinxPostTransform", "docstring": "A base class of post-transforms.\n\nPost transforms are invoked to modify the document to restructure it for outputting.\nThey resolve references, convert images, do special transformation for each output\nformats and so on.  This class helps to implement these post transforms.", "methods": ["apply", "is_supported", "run"], "attributes": [], "code_location": {"file": "__init__.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/transforms/post_transforms", "start_line": 33, "end_line": 59}, "type": "class"}, {"name": "setup", "is_method": false, "class_name": null, "parameters": ["app"], "calls": ["app.add_transform", "app.add_post_transform", "app.add_post_transform", "app.add_post_transform", "app.add_post_transform", "app.add_post_transform", "app.add_post_transform", "app.add_post_transform", "app.add_post_transform", "app.add_post_transform"], "code_location": {"file": "transforms.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/builders/latex", "start_line": 645, "end_line": 661}, "code_snippet": "def setup(app: Sphinx) -> ExtensionMetadata:\n    app.add_transform(FootnoteDocnameUpdater)\n    app.add_post_transform(SubstitutionDefinitionsRemover)\n    app.add_post_transform(BibliographyTransform)\n    app.add_post_transform(CitationReferenceTransform)\n    app.add_post_transform(DocumentTargetTransform)\n    app.add_post_transform(IndexInSectionTitleTransform)\n    app.add_post_transform(LaTeXFootnoteTransform)\n    app.add_post_transform(LiteralBlockTransform)\n    app.add_post_transform(MathReferenceTransform)\n    app.add_post_transform(ShowUrlsTransform)\n\n    return {\n        'version': 'builtin',\n        'parallel_read_safe': True,\n        'parallel_write_safe': True,\n    }\n", "type": "function"}, {"name": "SphinxTransform", "docstring": "A base class of Transforms.\n\nCompared with ``docutils.transforms.Transform``, this class improves accessibility to\nSphinx APIs.", "methods": ["app", "env", "config"], "attributes": [], "code_location": {"file": "__init__.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/transforms", "start_line": 55, "end_line": 78}, "type": "class"}, {"name": "SphinxFileInput", "docstring": "A basic FileInput for Sphinx.", "methods": ["__init__"], "attributes": [], "code_location": {"file": "io.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx", "start_line": 139, "end_line": 149}, "type": "class"}, {"name": "setup", "is_method": false, "class_name": null, "parameters": ["app"], "calls": ["app.add_post_transform", "app.add_post_transform", "app.add_post_transform", "app.add_post_transform"], "code_location": {"file": "__init__.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/transforms/post_transforms", "start_line": 393, "end_line": 403}, "code_snippet": "def setup(app: Sphinx) -> ExtensionMetadata:\n    app.add_post_transform(ReferencesResolver)\n    app.add_post_transform(OnlyNodeTransform)\n    app.add_post_transform(SigElementFallbackTransform)\n    app.add_post_transform(PropagateDescDomain)\n\n    return {\n        'version': 'builtin',\n        'parallel_read_safe': True,\n        'parallel_write_safe': True,\n    }\n", "type": "function"}], "retrieved_count": 10, "cost_time": 1.2227756977081299}
{"question": "What is the role of the BuildEnvironment class in Sphinx?", "answer": null, "relative_code_list": null, "ground_truth": "The BuildEnvironment class serves as the central data store and state manager for Sphinx's document processing system. It plays a crucial role in managing the build process and maintaining consistency across builds.\n\nKey responsibilities of the BuildEnvironment class include:\n\n1. **Document State Management**: The environment tracks which documents have been read, their dependencies, and their modification times. It maintains collections like `all_docs`, `dependencies`, and `included` to track document relationships and changes.\n\n2. **Cross-Reference Storage**: The environment stores all metadata about the document collection, including cross-references, labels, headings, described objects, and index entries. This information is used to resolve cross-references during the build process.\n\n3. **Domain Data Management**: The environment manages domain-specific data through the `domaindata` attribute, which stores information for each domain (Python, C++, etc.) about objects, references, and other domain-specific metadata.\n\n4. **Incremental Build Support**: The environment is serialized to disk after each build as a pickle file, allowing Sphinx to skip expensive parsing and analysis phases for unchanged files in subsequent builds.\n\n5. **Configuration Integration**: The environment maintains a reference to the current configuration and tracks configuration changes to determine what needs to be rebuilt.\n\n6. **Document Tree Caching**: The environment provides methods to cache and retrieve parsed document trees, optimizing memory usage and build performance.\n\n7. **Extension Support**: The environment provides an API that extensions can use to cache information that should persist for incremental rebuilds, allowing extensions to store their own metadata.\n\n8. **Reference Resolution**: The environment provides methods for resolving cross-references and managing the relationships between different document elements.\n\nThe BuildEnvironment is instantiated by the Sphinx application and is available as `app.env` or `builder.env`. It serves as the foundation for Sphinx's incremental build system and provides the data persistence mechanism that makes efficient rebuilding possible.", "score": null, "retrieved_content": [{"name": "BuildEnvironment", "docstring": "The environment in which the ReST files are translated.\nStores an inventory of cross-file targets and provides doctree\ntransformations to resolve links to them.", "methods": ["__init__", "__getstate__", "__setstate__", "setup", "app", "app", "app", "_registry", "_tags", "_config_status", "_update_settings", "set_versioning_method", "clear_doc", "merge_info_from", "path2doc", "doc2path", "relfn2path", "found_docs", "find_files", "get_outdated_files", "check_dependents", "prepare_settings", "temp_data", "docname", "parser", "new_serialno", "note_dependency", "note_included", "note_reread", "get_domain", "get_doctree", "master_doctree", "get_and_resolve_doctree", "resolve_toctree", "resolve_references", "apply_post_transforms", "collect_relations", "check_consistency"], "attributes": ["srcdir", "doctreedir"], "code_location": {"file": "__init__.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/environment", "start_line": 100, "end_line": 812}, "type": "class"}, {"name": "setup", "is_method": true, "class_name": "BuildEnvironment", "parameters": ["self", "app"], "calls": ["_get_env_version", "self.domains._setup", "self._config_status", "self._update_settings", "BuildEnvironmentError", "BuildEnvironmentError", "app.project.restore", "_DomainsContainer._from_environment", "_get_env_version", "__", "__"], "code_location": {"file": "__init__.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/environment", "start_line": 255, "end_line": 292}, "code_snippet": "    def setup(self, app: Sphinx) -> None:\n        \"\"\"Set up BuildEnvironment object.\"\"\"\n        if self.version and self.version != _get_env_version(app.extensions):\n            raise BuildEnvironmentError(__('build environment version not current'))\n        if self.srcdir and self.srcdir != app.srcdir:\n            raise BuildEnvironmentError(__('source directory has changed'))\n\n        if self.project:\n            app.project.restore(self.project)\n\n        self._app = app\n        self.doctreedir = app.doctreedir\n        self.events = app.events\n        self.srcdir = app.srcdir\n        self.project = app.project\n        self.version = _get_env_version(app.extensions)\n\n        # initialise domains\n        if self.domains is None:\n            # if we are unpickling an environment, we need to recreate the domains\n            self.domains = _DomainsContainer._from_environment(\n                self, registry=app.registry\n            )\n        # setup domains (must do after all initialization)\n        self.domains._setup()\n\n        # Initialise config.\n        # The old config is self.config, restored from the pickled environment.\n        # The new config is app.config, always recreated from ``conf.py``\n        self.config_status, self.config_status_extra = self._config_status(\n            old_config=self.config,\n            new_config=app.config,\n            verbosity=app.config.verbosity,\n        )\n        self.config = app.config\n\n        # initialize settings\n        self._update_settings(app.config)\n", "type": "function"}, {"name": "_init_env", "is_method": true, "class_name": "Sphinx", "parameters": ["self", "freshenv"], "calls": ["self._create_fresh_env", "self._load_existing_env", "filename.exists"], "code_location": {"file": "application.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx", "start_line": 382, "end_line": 387}, "code_snippet": "    def _init_env(self, freshenv: bool) -> BuildEnvironment:\n        filename = self.doctreedir / ENV_PICKLE_FILENAME\n        if freshenv or not filename.exists():\n            return self._create_fresh_env()\n        else:\n            return self._load_existing_env(filename)\n", "type": "function"}, {"name": "env", "is_method": true, "class_name": "SphinxDirective", "parameters": ["self"], "calls": [], "code_location": {"file": "docutils.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/util", "start_line": 484, "end_line": 489}, "code_snippet": "    def env(self) -> BuildEnvironment:\n        \"\"\"Reference to the :class:`.BuildEnvironment` object.\n\n        .. versionadded:: 1.8\n        \"\"\"\n        return self.state.document.settings.env\n", "type": "function"}, {"name": "env", "is_method": true, "class_name": "SphinxRole", "parameters": ["self"], "calls": [], "code_location": {"file": "docutils.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/util", "start_line": 662, "end_line": 667}, "code_snippet": "    def env(self) -> BuildEnvironment:\n        \"\"\"Reference to the :class:`.BuildEnvironment` object.\n\n        .. versionadded:: 2.0\n        \"\"\"\n        return self.inliner.document.settings.env\n", "type": "function"}, {"name": "env", "is_method": true, "class_name": "SphinxTransform", "parameters": ["self"], "calls": [], "code_location": {"file": "__init__.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/transforms", "start_line": 71, "end_line": 73}, "code_snippet": "    def env(self) -> BuildEnvironment:\n        \"\"\"Reference to the :class:`.BuildEnvironment` object.\"\"\"\n        return self.document.settings.env\n", "type": "function"}, {"name": "BuildPhase", "docstring": "Build phase of Sphinx application.", "methods": [], "attributes": ["INITIALIZATION", "READING", "CONSISTENCY_CHECK", "RESOLVING", "WRITING"], "code_location": {"file": "build_phase.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/util", "start_line": 8, "end_line": 15}, "type": "class"}, {"name": "EnvironmentCollector", "docstring": "An EnvironmentCollector is a specific data collector from each document.\n\nIt gathers data and stores :py:class:`BuildEnvironment\n<sphinx.environment.BuildEnvironment>` as a database.\nExamples of specific data would be images, download files, section titles, metadatas, index\nentries and toctrees, etc.\n\n.. note::\n\n    This class essentially wraps a sub-set of :ref:`Sphinx event callbacks <events>`.", "methods": ["enable", "disable", "clear_doc", "merge_other", "process_doc", "get_updated_docs", "get_outdated_docs"], "attributes": [], "code_location": {"file": "__init__.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/environment/collectors", "start_line": 16, "end_line": 102}, "type": "class"}, {"name": "BuildInfo", "docstring": "buildinfo file manipulator.\n\nHTMLBuilder and its family are storing their own envdata to ``.buildinfo``.\nThis class is a manipulator for the file.", "methods": ["load", "__init__", "__eq__", "__hash__", "dump"], "attributes": [], "code_location": {"file": "_build_info.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/builders/html", "start_line": 18, "end_line": 79}, "type": "class"}, {"name": "__init__", "is_method": true, "class_name": "BuildEnvironment", "parameters": ["self", "app"], "calls": ["_get_env_version", "default_settings.copy", "defaultdict", "defaultdict", "set", "defaultdict", "set", "set", "FilenameUniqDict", "DownloadFiles", "_CurrentDocument", "_DomainsContainer._from_environment", "self.setup"], "code_location": {"file": "__init__.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/environment", "start_line": 114, "end_line": 239}, "code_snippet": "    def __init__(self, app: Sphinx) -> None:\n        self._app: Sphinx = app\n        self.doctreedir = app.doctreedir\n        self.srcdir = app.srcdir\n        self.config: Config = None  # type: ignore[assignment]\n        self.config_status: int = CONFIG_UNSET\n        self.config_status_extra: str = ''\n        self.events: EventManager = app.events\n        self.project: Project = app.project\n        self.version: Mapping[str, int] = _get_env_version(app.extensions)\n\n        # the method of doctree versioning; see set_versioning_method\n        self.versioning_condition: Literal[False] | Callable[[Node], bool] | None = None\n        self.versioning_compare: bool | None = None\n\n        # the docutils settings for building\n        self.settings: dict[str, Any] = default_settings.copy()\n        self.settings['env'] = self\n\n        # All \"docnames\" here are /-separated and relative and exclude\n        # the source suffix.\n\n        # docname -> time of reading (in integer microseconds)\n        # contains all read docnames\n        self.all_docs: dict[str, int] = {}\n        # docname -> set of dependent file\n        # names, relative to documentation root\n        self.dependencies: dict[str, set[_StrPath]] = defaultdict(set)\n        # docname -> set of included file\n        # docnames included from other documents\n        self.included: dict[str, set[str]] = defaultdict(set)\n        # docnames to re-read unconditionally on next build\n        self.reread_always: set[str] = set()\n\n        self._pickled_doctree_cache: dict[str, bytes] = {}\n        \"\"\"In-memory cache for reading pickled doctrees from disk.\n        docname -> pickled doctree\n\n        This cache is used in the ``get_doctree`` method to avoid reading the\n        doctree from disk multiple times.\n        \"\"\"\n\n        self._write_doc_doctree_cache: dict[str, nodes.document] = {}\n        \"\"\"In-memory cache for unpickling doctrees from disk.\n        docname -> doctree\n\n        Items are added in ``Builder.write_doctree``, during the read phase,\n        then used only in the ``get_and_resolve_doctree`` method.\n        \"\"\"\n\n        # File metadata\n        # docname -> dict of metadata items\n        self.metadata: dict[str, dict[str, Any]] = defaultdict(dict)\n\n        # TOC inventory\n        # docname -> title node\n        self.titles: dict[str, nodes.title] = {}\n        # docname -> title node; only different if\n        # set differently with title directive\n        self.longtitles: dict[str, nodes.title] = {}\n        # docname -> table of contents nodetree\n        self.tocs: dict[str, nodes.bullet_list] = {}\n        # docname -> number of real entries\n        self.toc_num_entries: dict[str, int] = {}\n\n        # used to determine when to show the TOC\n        # in a sidebar (don't show if it's only one item)\n        # docname -> dict of sectionid -> number\n        self.toc_secnumbers: dict[str, dict[str, tuple[int, ...]]] = {}\n        # docname -> dict of figtype -> dict of figureid -> number\n        self.toc_fignumbers: dict[str, dict[str, dict[str, tuple[int, ...]]]] = {}\n\n        # docname -> list of toctree includefiles\n        self.toctree_includes: dict[str, list[str]] = {}\n        # docname -> set of files (containing its TOCs) to rebuild too\n        self.files_to_rebuild: dict[str, set[str]] = {}\n        # docnames that have :glob: toctrees\n        self.glob_toctrees: set[str] = set()\n        # docnames that have :numbered: toctrees\n        self.numbered_toctrees: set[str] = set()\n\n        # domain-specific inventories, here to be pickled\n        # domainname -> domain-specific dict\n        self.domaindata: dict[str, dict[str, Any]] = {}\n\n        # these map absolute path -> (docnames, unique filename)\n        self.images: FilenameUniqDict = FilenameUniqDict()\n        # filename -> (set of docnames, destination)\n        self.dlfiles: DownloadFiles = DownloadFiles()\n\n        # the original URI for images\n        self.original_image_uri: dict[_StrPath, str] = {}\n\n        # temporary data storage while reading a document\n        self.current_document: _CurrentDocument = _CurrentDocument()\n        # context for cross-references (e.g. current module or class)\n        # this is similar to ``self.current_document``,\n        # but will for example be copied to attributes of \"any\" cross references\n        self.ref_context: dict[str, Any] = {}\n\n        # search index data\n\n        # docname -> title\n        self._search_index_titles: dict[str, str | None] = {}\n        # docname -> filename\n        self._search_index_filenames: dict[str, str] = {}\n        # stemmed words -> set(docname)\n        self._search_index_mapping: dict[str, set[str]] = {}\n        # stemmed words in titles -> set(docname)\n        self._search_index_title_mapping: dict[str, set[str]] = {}\n        # docname -> all titles in document\n        self._search_index_all_titles: dict[str, list[tuple[str, str | None]]] = {}\n        # docname -> list(index entry)\n        self._search_index_index_entries: dict[str, list[tuple[str, str, str]]] = {}\n        # objtype -> index\n        self._search_index_objtypes: dict[tuple[str, str], int] = {}\n        # objtype index -> (domain, type, objname (localized))\n        self._search_index_objnames: dict[int, tuple[str, str, str]] = {}\n\n        # all the registered domains, set by the application\n        self.domains: _DomainsContainer = _DomainsContainer._from_environment(\n            self, registry=app.registry\n        )\n\n        # set up environment\n        self.setup(app)\n", "type": "function"}], "retrieved_count": 10, "cost_time": 1.2197308540344238}
{"question": "What dependencies exist between Sphinx's Builder classes and their corresponding Writer classes?", "answer": null, "relative_code_list": null, "ground_truth": "Sphinx's Builder classes and their corresponding Writer classes have a well-defined dependency relationship that follows a separation of concerns principle. The Builder classes are responsible for orchestrating the build process and managing the overall workflow, while Writer classes handle the actual output generation for specific formats.\n\nKey dependencies and relationships include:\n\n1. **Builder Orchestration**: Builder classes coordinate the entire build process, including reading source files, applying transforms, and calling the appropriate writer to generate output. They manage the build workflow and delegate the actual output generation to writers.\n\n2. **Writer Selection**: Builders select and instantiate the appropriate writer class based on the output format they need to generate. For example, an HTML builder would use an HTML writer, while a LaTeX builder would use a LaTeX writer.\n\n3. **Document Tree Processing**: Builders prepare the document trees and apply necessary transformations before passing them to writers. Writers receive fully processed document trees and focus solely on converting them to the target output format.\n\n4. **Configuration Integration**: Builders pass configuration settings and build context to writers, ensuring that writers have access to the necessary information to generate appropriate output.\n\n5. **Output Management**: Builders manage the output directory structure and file organization, while writers handle the actual content generation for individual files.\n\n6. **Error Handling**: Builders provide error handling and logging context for the overall build process, while writers handle format-specific errors during output generation.\n\nThis separation allows Sphinx to maintain a clean architecture where builders focus on build process management and writers focus on format-specific output generation, making the system more modular and extensible.", "score": null, "retrieved_content": [{"name": "Builder", "docstring": "Builds target formats from the reST sources.", "methods": ["__init__", "app", "_translator", "get_translator_class", "create_translator", "init", "create_template_bridge", "get_target_uri", "get_relative_uri", "get_outdated_docs", "get_asset_paths", "post_process_images", "compile_catalogs", "compile_all_catalogs", "compile_specific_catalogs", "compile_update_catalogs", "build_all", "build_specific", "build_update", "build", "read", "_read_serial", "_read_parallel", "read_doc", "write_doctree", "write", "write_documents", "_write_serial", "_write_parallel", "prepare_writing", "copy_assets", "write_doc", "write_doc_serialized", "finish", "cleanup", "get_builder_config"], "attributes": ["srcdir", "confdir", "outdir", "doctreedir"], "code_location": {"file": "__init__.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/builders", "start_line": 64, "end_line": 881}, "type": "class"}, {"name": "LaTeXBuilder", "docstring": "Builds LaTeX output to create PDF.", "methods": ["init", "get_outdated_docs", "get_target_uri", "get_relative_uri", "init_document_data", "init_context", "update_context", "init_babel", "init_multilingual", "write_stylesheet", "prepare_writing", "copy_assets", "write_documents", "get_contentsname", "update_doc_context", "assemble_doctree", "finish", "copy_support_files", "copy_latex_additional_files", "copy_image_files", "write_message_catalog"], "attributes": ["name", "format", "epilog", "supported_image_types", "supported_remote_images", "default_translator_class"], "code_location": {"file": "__init__.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/builders/latex", "start_line": 110, "end_line": 523}, "type": "class"}, {"name": "EpubBuilder", "docstring": "Builder that outputs epub files.\n\nIt creates the metainfo files container.opf, toc.ncx, mimetype, and\nMETA-INF/container.xml.  Afterwards, all necessary files are zipped to an\nepub file.", "methods": ["init", "create_build_info", "get_theme_config", "make_id", "get_refnodes", "check_refnodes", "get_toc", "toc_add_files", "fix_fragment", "fix_ids", "_update_node_id", "_make_footnote_ref", "_make_footnote", "_footnote_spot", "add_visible_links", "write_doc", "fix_genindex", "is_vector_graphics", "copy_image_files_pil", "copy_image_files", "copy_download_files", "handle_page", "build_mimetype", "build_container", "content_metadata", "build_content", "new_navpoint", "build_navpoints", "toc_metadata", "build_toc", "build_epub"], "attributes": ["copysource", "supported_image_types", "supported_remote_images", "add_permalinks", "allow_sharp_as_current_path", "embedded", "download_support", "html_scaled_image_link", "search", "coverpage_name", "toctree_template", "link_target_template", "css_link_target_class", "guide_titles", "media_types", "refuri_re", "doctype"], "code_location": {"file": "_epub_base.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/builders", "start_line": 129, "end_line": 808}, "type": "class"}, {"name": "SphinxDummyWriter", "docstring": "Dummy writer module used for generating doctree.", "methods": ["__init__", "translate"], "attributes": ["supported"], "code_location": {"file": "io.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx", "start_line": 112, "end_line": 126}, "type": "class"}, {"name": "is_supported_builder", "is_method": false, "class_name": null, "parameters": ["builder", "viewcode_enable_epub"], "calls": ["builder.name.startswith"], "code_location": {"file": "viewcode.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/ext", "start_line": 106, "end_line": 111}, "code_snippet": "def is_supported_builder(builder: type[Builder], viewcode_enable_epub: bool) -> bool:\n    return (\n        builder.format == 'html'\n        and builder.name != 'singlehtml'\n        and (not builder.name.startswith('epub') or viewcode_enable_epub)\n    )\n", "type": "function"}, {"name": "create_builder", "is_method": true, "class_name": "SphinxComponentRegistry", "parameters": ["self", "app", "name", "env"], "calls": ["SphinxError", "__"], "code_location": {"file": "registry.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx", "start_line": 190, "end_line": 194}, "code_snippet": "    def create_builder(self, app: Sphinx, name: str, env: BuildEnvironment) -> Builder:\n        if name not in self.builders:\n            raise SphinxError(__('Builder name %s not registered') % name)\n\n        return self.builders[name](app, env)\n", "type": "function"}, {"name": "TexinfoBuilder", "docstring": "Builds Texinfo output to create Info documentation.", "methods": ["init", "get_outdated_docs", "get_target_uri", "get_relative_uri", "prepare_writing", "write_documents", "assemble_doctree", "copy_assets", "copy_image_files", "copy_support_files"], "attributes": ["name", "format", "epilog", "supported_image_types", "default_translator_class"], "code_location": {"file": "texinfo.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/builders", "start_line": 36, "end_line": 218}, "type": "class"}, {"name": "XMLBuilder", "docstring": "Builds Docutils-native XML.", "methods": ["init", "get_outdated_docs", "get_target_uri", "write_doc", "_translate", "finish"], "attributes": ["name", "format", "epilog", "out_suffix", "allow_parallel", "default_translator_class"], "code_location": {"file": "xml.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/builders", "start_line": 24, "end_line": 95}, "type": "class"}, {"name": "preload_builder", "is_method": true, "class_name": "SphinxComponentRegistry", "parameters": ["self", "app", "name"], "calls": ["entry_points", "self.load_extension", "SphinxError", "__"], "code_location": {"file": "registry.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx", "start_line": 171, "end_line": 188}, "code_snippet": "    def preload_builder(self, app: Sphinx, name: str) -> None:\n        if name is None:\n            return\n\n        if name not in self.builders:\n            builder_entry_points = entry_points(group='sphinx.builders')\n            try:\n                entry_point = builder_entry_points[name]\n            except KeyError as exc:\n                raise SphinxError(\n                    __(\n                        'Builder name %s not registered or available'\n                        ' through entry point'\n                    )\n                    % name\n                ) from exc\n\n            self.load_extension(app, entry_point.module)\n", "type": "function"}, {"name": "Epub3Builder", "docstring": "Builder that outputs epub3 files.\n\nIt creates the metainfo files content.opf, nav.xhtml, toc.ncx, mimetype,\nand META-INF/container.xml. Afterwards, all necessary files are zipped to\nan epub file.", "methods": ["handle_finish", "content_metadata", "prepare_writing", "build_navlist", "navigation_doc_metadata", "build_navigation_doc"], "attributes": ["name", "epilog", "supported_remote_images", "template_dir", "doctype", "html_tag", "use_meta_charset"], "code_location": {"file": "epub3.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/builders", "start_line": 75, "end_line": 214}, "type": "class"}], "retrieved_count": 10, "cost_time": 1.2287344932556152}
{"question": "Why does Sphinx provide parallel processing capabilities for build performance optimization?", "answer": null, "relative_code_list": null, "ground_truth": "Sphinx provides parallel processing capabilities for build performance optimization to leverage modern multi-core systems and significantly reduce build times for large documentation projects. This feature addresses the computational demands of processing extensive documentation sets.\n\nKey reasons for implementing parallel processing include:\n\n1. **Multi-Core Utilization**: Modern systems typically have multiple CPU cores, and parallel processing allows Sphinx to utilize all available cores simultaneously, dramatically improving build performance compared to single-threaded processing.\n\n2. **Document Independence**: During the reading phase, many documents can be processed independently since they don't depend on each other for parsing and initial processing. This makes them ideal candidates for parallel execution.\n\n3. **Scalability**: As documentation projects grow in size, the benefits of parallel processing become more pronounced. The system can scale with the number of available CPU cores, providing better performance on high-end systems.\n\n4. **Build Time Reduction**: Parallel processing can significantly reduce build times, especially for large projects with hundreds or thousands of documents. This improves developer productivity and reduces waiting times during documentation development.\n\n5. **Resource Efficiency**: By distributing the workload across multiple processes, parallel processing can make better use of system resources and reduce the overall time the system is occupied with build tasks.\n\n6. **CI/CD Performance**: In continuous integration environments, faster builds mean quicker feedback and more efficient development workflows. Parallel processing helps maintain fast build times even as projects grow.\n\n7. **Memory Management**: The parallel processing system is designed to manage memory usage effectively across multiple processes, preventing memory exhaustion on large projects.\n\n8. **Flexibility**: Users can control the level of parallelism through the `--jobs` option, allowing them to balance build performance with system resource usage based on their specific needs.\n\nParallel processing is particularly effective during the document reading phase where documents can be processed independently, and the system includes mechanisms to merge the results from parallel processes back into the main build environment.", "score": null, "retrieved_content": [{"name": "test_html_parallel", "is_method": false, "class_name": null, "parameters": ["app"], "calls": ["pytest.mark.sphinx", "app.build"], "code_location": {"file": "test_build_html.py", "path": "/data3/pwh/swebench-repos/sphinx/tests/test_builders", "start_line": 152, "end_line": 153}, "code_snippet": "def test_html_parallel(app: SphinxTestApp) -> None:\n    app.build()\n", "type": "function"}, {"name": "_write_parallel", "is_method": true, "class_name": "Builder", "parameters": ["self", "docnames", "nproc"], "calls": ["_write_docname", "ParallelTasks", "make_chunks", "status_iterator", "tasks.join", "logger.info", "__", "len", "next", "tasks.add_task", "self.write_doc", "self.env.get_and_resolve_doctree", "self.write_doc_serialized", "arg.append"], "code_location": {"file": "__init__.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/builders", "start_line": 786, "end_line": 825}, "code_snippet": "    def _write_parallel(self, docnames: Sequence[str], nproc: int) -> None:\n        def write_process(docs: list[tuple[str, nodes.document]]) -> None:\n            self.phase = BuildPhase.WRITING\n            for docname, doctree in docs:\n                self.write_doc(docname, doctree)\n\n        # warm up caches/compile templates using the first document\n        firstname, docnames = docnames[0], docnames[1:]\n        _write_docname(firstname, env=self.env, builder=self, tags=self.tags)\n\n        tasks = ParallelTasks(nproc)\n        chunks = make_chunks(docnames, nproc)\n\n        # create a status_iterator to step progressbar after writing a document\n        # (see: ``on_chunk_done()`` function)\n        progress = status_iterator(\n            chunks,\n            __('writing output... '),\n            'darkgreen',\n            len(chunks),\n            self.config.verbosity,\n        )\n\n        def on_chunk_done(args: list[tuple[str, nodes.document]], result: None) -> None:\n            next(progress)\n\n        self.phase = BuildPhase.RESOLVING\n        for chunk in chunks:\n            arg = []\n            for docname in chunk:\n                doctree = self.env.get_and_resolve_doctree(\n                    docname, self, tags=self.tags\n                )\n                self.write_doc_serialized(docname, doctree)\n                arg.append((docname, doctree))\n            tasks.add_task(write_process, arg, on_chunk_done)\n\n        # make sure all threads have finished\n        tasks.join()\n        logger.info('')\n", "type": "function"}, {"name": "_read_parallel", "is_method": true, "class_name": "Builder", "parameters": ["self", "docnames", "nproc"], "calls": ["make_chunks", "status_iterator", "ParallelTasks", "tasks.join", "logger.info", "__", "len", "self.events.emit", "self.env.clear_doc", "pickle.dumps", "pickle.loads", "self.env.merge_info_from", "next", "tasks.add_task", "self.read_doc"], "code_location": {"file": "__init__.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/builders", "start_line": 592, "end_line": 629}, "code_snippet": "    def _read_parallel(self, docnames: list[str], nproc: int) -> None:\n        chunks = make_chunks(docnames, nproc)\n\n        # create a status_iterator to step progressbar after reading a document\n        # (see: ``merge()`` function)\n        progress = status_iterator(\n            chunks,\n            __('reading sources... '),\n            'purple',\n            len(chunks),\n            self.config.verbosity,\n        )\n\n        # clear all outdated docs at once\n        for docname in docnames:\n            self.events.emit('env-purge-doc', self.env, docname)\n            self.env.clear_doc(docname)\n\n        def read_process(docs: list[str]) -> bytes:\n            self.env._app = self._app\n            for docname in docs:\n                self.read_doc(docname, _cache=False)\n            # allow pickling self to send it back\n            return pickle.dumps(self.env, pickle.HIGHEST_PROTOCOL)\n\n        def merge(docs: list[str], otherenv: bytes) -> None:\n            env = pickle.loads(otherenv)\n            self.env.merge_info_from(docs, env, self._app)\n\n            next(progress)\n\n        tasks = ParallelTasks(nproc)\n        for chunk in chunks:\n            tasks.add_task(read_process, chunk, merge)\n\n        # make sure all threads have finished\n        tasks.join()\n        logger.info('')\n", "type": "function"}, {"name": "build_main", "is_method": false, "class_name": null, "parameters": ["argv"], "calls": ["get_parser", "_parse_arguments", "_parse_confdir", "_parse_doctreedir", "_validate_filenames", "_validate_colour_support", "_parse_logging", "_parse_confoverrides", "patch_docutils", "docutils_namespace", "Sphinx", "app.build", "sphinx._cli.util.errors.handle_exception", "warnfp.close", "app.extensions.values"], "code_location": {"file": "build.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/cmd", "start_line": 395, "end_line": 452}, "code_snippet": "def build_main(argv: Sequence[str]) -> int:\n    \"\"\"Sphinx build \"main\" command-line entry.\"\"\"\n    parser = get_parser()\n    args = _parse_arguments(parser, argv)\n    args.confdir = _parse_confdir(args.noconfig, args.confdir, args.sourcedir)\n    args.doctreedir = _parse_doctreedir(args.doctreedir, args.outputdir)\n    _validate_filenames(parser, args.force_all, args.filenames)\n    _validate_colour_support(args.color)\n    args.status, args.warning, args.error, warnfp = _parse_logging(\n        parser, args.quiet, args.really_quiet, args.warnfile\n    )\n    args.confoverrides = _parse_confoverrides(\n        parser, args.define, args.htmldefine, args.nitpicky\n    )\n\n    app = None\n    try:\n        confdir = args.confdir or args.sourcedir\n        with patch_docutils(confdir), docutils_namespace():\n            app = Sphinx(\n                srcdir=args.sourcedir,\n                confdir=args.confdir,\n                outdir=args.outputdir,\n                doctreedir=args.doctreedir,\n                buildername=args.builder,\n                confoverrides=args.confoverrides,\n                status=args.status,\n                warning=args.warning,\n                freshenv=args.freshenv,\n                warningiserror=args.warningiserror,\n                tags=args.tags,\n                verbosity=args.verbosity,\n                parallel=args.jobs,\n                keep_going=False,\n                pdb=args.pdb,\n                exception_on_warning=args.exception_on_warning,\n            )\n            app.build(args.force_all, args.filenames)\n            return app.statuscode\n    except (Exception, KeyboardInterrupt) as exc:\n        if app is not None:\n            message_log: Sequence[str] = app.messagelog\n            extensions: Collection[Extension] = app.extensions.values()\n        else:\n            message_log = extensions = ()\n        sphinx._cli.util.errors.handle_exception(\n            exc,\n            stderr=args.error,\n            use_pdb=args.pdb,\n            print_traceback=args.verbosity or args.traceback,\n            message_log=message_log,\n            extensions=extensions,\n        )\n        return 2\n    finally:\n        if warnfp is not None:\n            # close the file descriptor for the warnings file opened by Sphinx\n            warnfp.close()\n", "type": "function"}, {"name": "write_doc_serialized", "is_method": true, "class_name": "Builder", "parameters": ["self", "docname", "doctree"], "calls": [], "code_location": {"file": "__init__.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/builders", "start_line": 847, "end_line": 851}, "code_snippet": "    def write_doc_serialized(self, docname: str, doctree: nodes.document) -> None:\n        \"\"\"Handle parts of write_doc that must be called in the main process\n        if parallel build is active.\n        \"\"\"\n        pass\n", "type": "function"}, {"name": "make_main", "is_method": false, "class_name": null, "parameters": ["argv"], "calls": ["make_mode.run_make_mode"], "code_location": {"file": "build.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/cmd", "start_line": 291, "end_line": 295}, "code_snippet": "def make_main(argv: Sequence[str]) -> int:\n    \"\"\"Sphinx build \"make mode\" entry.\"\"\"\n    from sphinx.cmd import make_mode\n\n    return make_mode.run_make_mode(argv[1:])\n", "type": "function"}, {"name": "__init__", "is_method": true, "class_name": "Sphinx", "parameters": ["self", "srcdir", "confdir", "outdir", "doctreedir", "buildername", "confoverrides", "status", "warning", "freshenv", "warningiserror", "tags", "verbosity", "parallel", "keep_going", "pdb", "exception_on_warning"], "calls": ["SphinxComponentRegistry", "resolve", "resolve", "resolve", "bool", "bool", "logging.setup", "EventManager", "deque", "logger.info", "Tags", "self._init_i18n", "self.preload_builder", "self.config._report_override_warnings", "self.events.emit", "Project", "self._init_env", "self.create_builder", "self._post_init_env", "self._init_builder", "self.srcdir.is_dir", "ApplicationError", "self.outdir.exists", "ApplicationError", "ApplicationError", "StringIO", "StringIO", "bold", "Config", "resolve", "Config.read", "VersionRequirementError", "self.setup_extension", "self.setup_extension", "self.outdir.is_dir", "_StrPath", "_StrPath", "_StrPath", "self.outdir.is_dir", "__", "__", "progress_message", "ensuredir", "__", "prefixed_warnings", "callable", "__", "__", "_StrPath", "__", "__", "self.config.setup", "ConfigError", "__"], "code_location": {"file": "application.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx", "start_line": 159, "end_line": 334}, "code_snippet": "    def __init__(\n        self,\n        srcdir: str | os.PathLike[str],\n        confdir: str | os.PathLike[str] | None,\n        outdir: str | os.PathLike[str],\n        doctreedir: str | os.PathLike[str],\n        buildername: str,\n        confoverrides: dict[str, Any] | None = None,\n        status: IO[str] | None = sys.stdout,\n        warning: IO[str] | None = sys.stderr,\n        freshenv: bool = False,\n        warningiserror: bool = False,\n        tags: Sequence[str] = (),\n        verbosity: int = 0,\n        parallel: int = 0,\n        keep_going: bool = False,\n        pdb: bool = False,\n        exception_on_warning: bool = False,\n    ) -> None:\n        \"\"\"Initialize the Sphinx application.\n\n        :param srcdir: The path to the source directory.\n        :param confdir: The path to the configuration directory.\n            If not given, it is assumed to be the same as ``srcdir``.\n        :param outdir: Directory for storing build documents.\n        :param doctreedir: Directory for caching pickled doctrees.\n        :param buildername: The name of the builder to use.\n        :param confoverrides: A dictionary of configuration settings that override the\n            settings in the configuration file.\n        :param status: A file-like object to write status messages to.\n        :param warning: A file-like object to write warnings to.\n        :param freshenv: If true, clear the cached environment.\n        :param warningiserror: If true, warnings become errors.\n        :param tags: A list of tags to apply.\n        :param verbosity: The verbosity level.\n        :param parallel: The maximum number of parallel jobs to use\n            when reading/writing documents.\n        :param keep_going: Unused.\n        :param pdb: If true, enable the Python debugger on an exception.\n        :param exception_on_warning: If true, raise an exception on warnings.\n        \"\"\"\n        self.verbosity = verbosity\n        self._fresh_env_used: bool | None = None\n        self.extensions: dict[str, Extension] = {}\n        self.registry = SphinxComponentRegistry()\n\n        # validate provided directories\n        self.srcdir = _StrPath(srcdir).resolve()\n        self.outdir = _StrPath(outdir).resolve()\n        self.doctreedir = _StrPath(doctreedir).resolve()\n\n        if not self.srcdir.is_dir():\n            raise ApplicationError(\n                __('Cannot find source directory (%s)') % self.srcdir\n            )\n\n        if self.outdir.exists() and not self.outdir.is_dir():\n            raise ApplicationError(\n                __('Output directory (%s) is not a directory') % self.outdir\n            )\n\n        if self.srcdir == self.outdir:\n            raise ApplicationError(\n                __('Source directory and destination directory cannot be identical')\n            )\n\n        self.parallel = parallel\n\n        if status is None:\n            self._status: IO[str] = StringIO()\n            self.quiet: bool = True\n        else:\n            self._status = status\n            self.quiet = False\n\n        if warning is None:\n            self._warning: IO[str] = StringIO()\n        else:\n            self._warning = warning\n        self._warncount = 0\n        self.keep_going = bool(warningiserror)  # Unused\n        self._fail_on_warnings = bool(warningiserror)\n        self.pdb = pdb\n        self._exception_on_warning = exception_on_warning\n        logging.setup(self, self._status, self._warning, verbosity=verbosity)\n\n        self.events = EventManager(self)\n\n        # keep last few messages for traceback\n        # This will be filled by sphinx.util.logging.LastMessagesWriter\n        self.messagelog: deque[str] = deque(maxlen=10)\n\n        # say hello to the world\n        logger.info(bold(__('Running Sphinx v%s')), sphinx.__display_version__)\n\n        # status code for command-line application\n        self.statuscode = 0\n\n        # read config\n        overrides = confoverrides or {}\n        self.tags = Tags(tags)\n        if confdir is None:\n            # set confdir to srcdir if -C given (!= no confdir); a few pieces\n            # of code expect a confdir to be set\n            self.confdir = self.srcdir\n            self.config = Config({}, overrides)\n        else:\n            self.confdir = _StrPath(confdir).resolve()\n            self.config = Config.read(self.confdir, overrides=overrides, tags=self.tags)\n        self.config._verbosity = -1 if self.quiet else self.verbosity\n\n        # set up translation infrastructure\n        self._init_i18n()\n\n        # check the Sphinx version if requested\n        if (\n            self.config.needs_sphinx\n            and self.config.needs_sphinx > sphinx.__display_version__\n        ):\n            raise VersionRequirementError(\n                __(\n                    'This project needs at least Sphinx v%s and therefore cannot '\n                    'be built with this version.'\n                )\n                % self.config.needs_sphinx\n            )\n\n        # load all built-in extension modules, first-party extension modules,\n        # and first-party themes\n        for extension in builtin_extensions:\n            self.setup_extension(extension)\n\n        # load all user-given extension modules\n        for extension in self.config.extensions:\n            self.setup_extension(extension)\n\n        # preload builder module (before init config values)\n        self.preload_builder(buildername)\n\n        if not self.outdir.is_dir():\n            with progress_message(__('making output directory')):\n                ensuredir(self.outdir)\n\n        # the config file itself can be an extension\n        if self.config.setup:\n            prefix = __('while setting up extension %s:') % 'conf.py'\n            with prefixed_warnings(prefix):\n                if callable(self.config.setup):\n                    self.config.setup(self)\n                else:\n                    raise ConfigError(\n                        __(\n                            \"'setup' as currently defined in conf.py isn't a Python callable. \"\n                            'Please modify its definition to make it a callable function. '\n                            'This is needed for conf.py to behave as a Sphinx extension.'\n                        ),\n                    )\n\n        # Report any warnings for overrides.\n        self.config._report_override_warnings()\n        self.events.emit('config-inited', self.config)\n\n        # create the project\n        self.project = Project(self.srcdir, self.config.source_suffix)\n\n        # set up the build environment\n        self.env = self._init_env(freshenv)\n\n        # create the builder\n        self.builder = self.create_builder(buildername)\n\n        # build environment post-initialisation, after creating the builder\n        self._post_init_env()\n\n        # set up the builder\n        self._init_builder()\n", "type": "function"}, {"name": "build", "is_method": false, "class_name": null, "parameters": ["srcdir"], "calls": ["subprocess.run"], "code_location": {"file": "generate_js_fixtures.py", "path": "/data3/pwh/swebench-repos/sphinx/utils", "start_line": 17, "end_line": 26}, "code_snippet": "def build(srcdir: Path) -> None:\n    cmd = (\n        'sphinx-build',\n        '--fresh-env',\n        '--quiet',\n        *('--builder', 'html'),\n        f'{srcdir}',\n        f'{srcdir}/_build',\n    )\n    subprocess.run(cmd, check=True, capture_output=True)\n", "type": "function"}, {"name": "build", "is_method": true, "class_name": "SphinxTestApp", "parameters": ["self", "force_all", "filenames"], "calls": ["self.env._pickled_doctree_cache.clear", "build", "super"], "code_location": {"file": "util.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/testing", "start_line": 235, "end_line": 237}, "code_snippet": "    def build(self, force_all: bool = False, filenames: Sequence[Path] = ()) -> None:\n        self.env._pickled_doctree_cache.clear()\n        super().build(force_all, filenames)\n", "type": "function"}, {"name": "test_add_is_parallel_allowed", "is_method": false, "class_name": null, "parameters": ["app"], "calls": ["pytest.mark.sphinx", "logging.setup", "app.setup_extension", "app.extensions.pop", "app.setup_extension", "app.extensions.pop", "app.warning.truncate", "app.setup_extension", "app.warning.truncate", "app.extensions.pop", "app.setup_extension", "app.extensions.pop", "app.warning.truncate", "app.is_parallel_allowed", "app.is_parallel_allowed", "app.warning.getvalue", "app.is_parallel_allowed", "app.is_parallel_allowed", "app.warning.getvalue", "app.is_parallel_allowed", "app.is_parallel_allowed", "app.warning.getvalue", "app.is_parallel_allowed", "app.warning.getvalue", "app.is_parallel_allowed", "app.warning.getvalue", "app.is_parallel_allowed", "app.is_parallel_allowed", "app.warning.getvalue"], "code_location": {"file": "test_application.py", "path": "/data3/pwh/swebench-repos/sphinx/tests", "start_line": 114, "end_line": 155}, "code_snippet": "def test_add_is_parallel_allowed(app: SphinxTestApp) -> None:\n    logging.setup(app, app.status, app.warning)\n\n    assert app.is_parallel_allowed('read') is True\n    assert app.is_parallel_allowed('write') is True\n    assert app.warning.getvalue() == ''\n\n    app.setup_extension('read_parallel')\n    assert app.is_parallel_allowed('read') is True\n    assert app.is_parallel_allowed('write') is True\n    assert app.warning.getvalue() == ''\n    app.extensions.pop('read_parallel')\n\n    app.setup_extension('write_parallel')\n    assert app.is_parallel_allowed('read') is False\n    assert app.is_parallel_allowed('write') is True\n    assert (\n        'the write_parallel extension does not declare if it is safe '\n        \"for parallel reading, assuming it isn't - please \"\n    ) in app.warning.getvalue()\n    app.extensions.pop('write_parallel')\n    app.warning.truncate(0)  # reset warnings\n\n    app.setup_extension('read_serial')\n    assert app.is_parallel_allowed('read') is False\n    assert (\n        'the read_serial extension is not safe for parallel reading'\n    ) in app.warning.getvalue()\n    app.warning.truncate(0)  # reset warnings\n    assert app.is_parallel_allowed('write') is True\n    assert app.warning.getvalue() == ''\n    app.extensions.pop('read_serial')\n\n    app.setup_extension('write_serial')\n    assert app.is_parallel_allowed('read') is False\n    assert app.is_parallel_allowed('write') is False\n    assert (\n        'the write_serial extension does not declare if it is safe '\n        \"for parallel reading, assuming it isn't - please \"\n    ) in app.warning.getvalue()\n    app.extensions.pop('write_serial')\n    app.warning.truncate(0)  # reset warnings\n", "type": "function"}], "retrieved_count": 10, "cost_time": 1.2172234058380127}
{"question": "What is the relationship between Sphinx's Domain system and the Role system in cross-reference resolution?", "answer": null, "relative_code_list": null, "ground_truth": "Sphinx's Domain system and Role system work together in a tightly integrated manner to provide comprehensive cross-reference resolution capabilities. The relationship between these systems is fundamental to Sphinx's ability to handle cross-references across different types of documentation objects.\n\nKey aspects of this relationship include:\n\n1. **Domain-Specific Roles**: Each domain provides its own set of roles for creating cross-references to objects within that domain. For example, the Python domain provides roles like `:py:func:`, `:py:class:`, and `:py:mod:` for referencing Python functions, classes, and modules respectively.\n\n2. **Role Registration**: Domains register their domain-specific roles in the `roles` attribute, which maps role names to role functions. These roles are then available for use in documents and are processed during the cross-reference resolution phase.\n\n3. **Object Type Mapping**: Domains define object types through the `object_types` attribute, which maps object type names to `ObjType` instances. Each object type specifies which roles can be used to reference objects of that type.\n\n4. **Cross-Reference Resolution**: When a role is used in a document, the domain system provides the logic to resolve the reference to the appropriate object. The domain's `resolve_xref` method is called to find the target object and create the appropriate reference node.\n\n5. **Data Storage**: Domains store information about documented objects in their `data` attribute, which is used during cross-reference resolution to find the target objects and their locations.\n\n6. **Namespace Isolation**: The domain system ensures that cross-references are resolved within the correct context, preventing conflicts between different types of objects (e.g., Python functions vs. C++ functions).\n\n7. **Extension Integration**: Both systems work together to support extensions that can add new object types, roles, and cross-reference resolution logic to existing domains or create entirely new domains.\n\nThis integration allows Sphinx to provide rich cross-referencing capabilities while maintaining clear separation between different types of documentation objects and ensuring that references are resolved correctly within their appropriate contexts.", "score": null, "retrieved_content": [{"name": "sphinx_domains", "docstring": "Monkey-patch directive and role dispatch, so that domain-specific\nmarkup takes precedence.", "methods": ["__init__", "directive", "role"], "attributes": [], "code_location": {"file": "docutils.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/util", "start_line": 301, "end_line": 380}, "type": "class"}, {"name": "SphinxDomains", "docstring": "Collect objects to Sphinx domains for cross references.", "methods": ["apply"], "attributes": ["default_priority"], "code_location": {"file": "references.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/transforms", "start_line": 33, "end_line": 41}, "type": "class"}, {"name": "make_xref", "is_method": true, "class_name": "Field", "parameters": ["self", "rolename", "domain", "target", "innernode", "contnode", "env", "inliner", "location"], "calls": ["role", "role", "nodes.inline", "addnodes.pending_xref", "process_field_xref", "innernode", "env.get_domain", "__", "logger.warning", "innernode", "contextlib.suppress", "get_node_line", "__", "env.get_domain"], "code_location": {"file": "docfields.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/util", "start_line": 81, "end_line": 122}, "code_snippet": "    def make_xref(\n        self,\n        rolename: str,\n        domain: str,\n        target: str,\n        innernode: type[TextlikeNode] = addnodes.literal_emphasis,\n        contnode: Node | None = None,\n        env: BuildEnvironment | None = None,\n        inliner: Inliner | None = None,\n        location: Element | None = None,\n    ) -> Node:\n        # note: for backwards compatibility env is last, but not optional\n        assert env is not None\n        assert (inliner is None) == (location is None), (inliner, location)\n        if not rolename:\n            return contnode or innernode(target, target)  # type: ignore[call-arg]\n        # The domain is passed from DocFieldTransformer. So it surely exists.\n        # So we don't need to take care the env.get_domain() raises an exception.\n        role = env.get_domain(domain).role(rolename)\n        if role is None or inliner is None:\n            if role is None and inliner is not None:\n                msg = __(\n                    'Problem in %s domain: field is supposed '\n                    \"to use role '%s', but that role is not in the domain.\"\n                )\n                logger.warning(__(msg), domain, rolename, location=location)\n            refnode = addnodes.pending_xref(\n                '',\n                refdomain=domain,\n                refexplicit=False,\n                reftype=rolename,\n                reftarget=target,\n            )\n            refnode += contnode or innernode(target, target)  # type: ignore[call-arg]\n            env.get_domain(domain).process_field_xref(refnode)\n            return refnode\n        lineno = -1\n        if location is not None:\n            with contextlib.suppress(ValueError):\n                lineno = get_node_line(location)\n        ns, _messages = role(rolename, target, target, lineno, inliner, {}, [])\n        return nodes.inline(target, '', *ns)\n", "type": "function"}, {"name": "role", "is_method": true, "class_name": "sphinx_domains", "parameters": ["self", "role_name", "language_module", "lineno", "reporter"], "calls": ["role_name.lower", "self.domains.standard_domain.role", "role", "role_name.partition", "domain.role", "default_domain.role", "super", "logger.warning", "__"], "code_location": {"file": "docutils.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/util", "start_line": 346, "end_line": 380}, "code_snippet": "    def role(\n        self,\n        role_name: str,\n        language_module: ModuleType,\n        lineno: int,\n        reporter: Reporter,\n    ) -> tuple[RoleFunction, list[system_message]]:\n        \"\"\"Lookup a role, given its name which can include a domain.\"\"\"\n        role_name = role_name.lower()\n        # explicit domain given?\n        if ':' in role_name:\n            domain_name, _, name = role_name.partition(':')\n            try:\n                domain = self.domains[domain_name]\n            except KeyError:\n                logger.warning(__('unknown role name: %s'), role_name)\n            else:\n                element = domain.role(name)\n                if element is not None:\n                    return element, []\n        # else look in the default domain\n        else:\n            name = role_name\n            default_domain = self.current_document.default_domain\n            if default_domain is not None:\n                element = default_domain.role(name)\n                if element is not None:\n                    return element, []\n\n        # always look in the std domain\n        element = self.domains.standard_domain.role(name)\n        if element is not None:\n            return element, []\n\n        return super().role(role_name, language_module, lineno, reporter)\n", "type": "function"}, {"name": "_resolve_pending_any_xref", "is_method": true, "class_name": "ReferencesResolver", "parameters": ["self"], "calls": ["domains.standard_domain.resolve_xref", "domains.standard_domain.resolve_any_xref", "domains.sorted", "results.append", "len", "join", "__", "logger.warning", "res_role.partition", "isinstance", "get", "extend", "domain.resolve_any_xref", "starmap", "len", "res_role.replace", "domain.resolve_xref", "isinstance", "results.append", "len"], "code_location": {"file": "__init__.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/transforms/post_transforms", "start_line": 187, "end_line": 248}, "code_snippet": "    def _resolve_pending_any_xref(\n        self,\n        *,\n        node: addnodes.pending_xref,\n        contnode: Element,\n        ref_doc: str,\n        target: str,\n    ) -> nodes.reference | None:\n        \"\"\"Resolve reference generated by the \"any\" role.\"\"\"\n        env = self.env\n        builder = self.env._app.builder\n        domains = env.domains\n\n        results: list[tuple[str, nodes.reference]] = []\n        # first, try resolving as :doc:\n        doc_ref = domains.standard_domain.resolve_xref(\n            env, ref_doc, builder, 'doc', target, node, contnode\n        )\n        if doc_ref:\n            results.append(('doc', doc_ref))\n        # next, do the standard domain (makes this a priority)\n        results += domains.standard_domain.resolve_any_xref(\n            env, ref_doc, builder, target, node, contnode\n        )\n        for domain in domains.sorted():\n            if domain.name == 'std':\n                continue  # we did this one already\n            try:\n                results += domain.resolve_any_xref(\n                    env, ref_doc, builder, target, node, contnode\n                )\n            except NotImplementedError:\n                # the domain doesn't yet support the new interface\n                # we have to manually collect possible references (SLOW)\n                for role in domain.roles:\n                    res = domain.resolve_xref(\n                        env, ref_doc, builder, role, target, node, contnode\n                    )\n                    if res and len(res) > 0 and isinstance(res[0], nodes.Element):\n                        results.append((f'{domain.name}:{role}', res))\n        # now, see how many matches we got...\n        if not results:\n            return None\n        if len(results) > 1:\n            candidates = ' or '.join(starmap(self._stringify, results))\n            msg = __(\n                \"more than one target found for 'any' cross-reference %r: could be %s\"\n            )\n            logger.warning(\n                msg, target, candidates, location=node, type='ref', subtype='any'\n            )\n        res_role, new_node = results[0]\n        # Override \"any\" class with the actual role type to get the styling\n        # approximately correct.\n        res_domain = res_role.partition(':')[0]\n        if (\n            len(new_node) > 0\n            and isinstance(new_node[0], nodes.Element)\n            and new_node[0].get('classes')\n        ):\n            new_node[0]['classes'].extend((res_domain, res_role.replace(':', '-')))\n        return new_node\n", "type": "function"}, {"name": "add_role_to_domain", "is_method": true, "class_name": "SphinxComponentRegistry", "parameters": ["self", "domain", "name", "role", "override"], "calls": ["logger.debug", "self.domain_roles.setdefault", "ExtensionError", "ExtensionError", "__", "__"], "code_location": {"file": "registry.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx", "start_line": 235, "end_line": 250}, "code_snippet": "    def add_role_to_domain(\n        self,\n        domain: str,\n        name: str,\n        role: RoleFunction | XRefRole,\n        override: bool = False,\n    ) -> None:\n        logger.debug('[app] adding role to domain: %r', (domain, name, role))\n        if domain not in self.domains:\n            raise ExtensionError(__('domain %s not yet registered') % domain)\n        roles = self.domain_roles.setdefault(domain, {})\n        if name in roles and not override:\n            raise ExtensionError(\n                __('The %r role is already registered to domain %s') % (name, domain)\n            )\n        roles[name] = role\n", "type": "function"}, {"name": "Domain", "docstring": "A Domain is meant to be a group of \"object\" description directives for\nobjects of a similar nature, and corresponding roles to create references to\nthem.  Examples would be Python modules, classes, functions etc., elements\nof a templating language, Sphinx roles and directives, etc.\n\nEach domain has a separate storage for information about existing objects\nand how to reference them in `self.data`, which must be a dictionary.  It\nalso must implement several functions that expose the object information in\na uniform way to parts of Sphinx that allow the user to reference or search\nfor objects in a domain-agnostic way.\n\nAbout `self.data`: since all object and cross-referencing information is\nstored on a BuildEnvironment instance, the `domain.data` object is also\nstored in the `env.domaindata` dict under the key `domain.name`.  Before the\nbuild process starts, every active domain is instantiated and given the\nenvironment object; the `domaindata` dict must then either be nonexistent or\na dictionary whose 'version' key is equal to the domain class'\n:attr:`data_version` attribute.  Otherwise, `OSError` is raised and the\npickled environment is discarded.", "methods": ["__init__", "setup", "add_object_type", "role", "directive", "clear_doc", "merge_domaindata", "process_doc", "check_consistency", "process_field_xref", "resolve_xref", "resolve_any_xref", "get_objects", "get_type_name", "get_enumerable_node_type", "get_full_qualified_name"], "attributes": [], "code_location": {"file": "__init__.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/domains", "start_line": 62, "end_line": 331}, "type": "class"}, {"name": "role", "is_method": true, "class_name": "IntersphinxDispatcher", "parameters": ["self", "role_name", "language_module", "lineno", "reporter"], "calls": ["role_name.startswith", "role", "len", "IntersphinxRole", "super"], "code_location": {"file": "_resolve.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/ext/intersphinx", "start_line": 357, "end_line": 367}, "code_snippet": "    def role(\n        self,\n        role_name: str,\n        language_module: ModuleType,\n        lineno: int,\n        reporter: Reporter,\n    ) -> tuple[RoleFunction, list[system_message]]:\n        if len(role_name) > 9 and role_name.startswith(('external:', 'external+')):\n            return IntersphinxRole(role_name), []\n        else:\n            return super().role(role_name, language_module, lineno, reporter)\n", "type": "function"}, {"name": "get_role_name", "is_method": true, "class_name": "IntersphinxRole", "parameters": ["self", "name"], "calls": ["_deprecation_warning", "name.split", "len", "self.is_existent_role", "self.is_existent_role", "len"], "code_location": {"file": "_resolve.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/ext/intersphinx", "start_line": 538, "end_line": 561}, "code_snippet": "    def get_role_name(self, name: str) -> tuple[str, str] | None:\n        _deprecation_warning(\n            __name__, f'{self.__class__.__name__}.get_role_name', '', remove=(9, 0)\n        )\n        names = name.split(':')\n        if len(names) == 1:\n            # role\n            if (domain := self.env.current_document.default_domain) is not None:\n                domain_name = domain.name\n            else:\n                domain_name = None\n            role = names[0]\n        elif len(names) == 2:\n            # domain:role:\n            domain_name, role = names\n        else:\n            return None\n\n        if domain_name and self.is_existent_role(domain_name, role):\n            return domain_name, role\n        elif self.is_existent_role('std', role):\n            return 'std', role\n        else:\n            return None\n", "type": "function"}, {"name": "add_role_to_domain", "is_method": true, "class_name": "Sphinx", "parameters": ["self", "domain", "name", "role", "override"], "calls": ["self.registry.add_role_to_domain"], "code_location": {"file": "application.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx", "start_line": 1226, "end_line": 1249}, "code_snippet": "    def add_role_to_domain(\n        self,\n        domain: str,\n        name: str,\n        role: RoleFunction | XRefRole,\n        override: bool = False,\n    ) -> None:\n        \"\"\"Register a Docutils role in a domain.\n\n        Like :meth:`add_role`, but the role is added to the domain named\n        *domain*.\n\n        :param domain: The name of the target domain\n        :param name: The name of the role\n        :param role: The role function\n        :param override: If false, do not install it if another role\n                         is already installed as the same name\n                         If true, unconditionally install the role.\n\n        .. versionadded:: 1.0\n        .. versionchanged:: 1.8\n           Add *override* keyword.\n        \"\"\"\n        self.registry.add_role_to_domain(domain, name, role, override=override)\n", "type": "function"}], "retrieved_count": 10, "cost_time": 1.242950439453125}
{"question": "Why does Sphinx separate the Builder concept from the Writer concept in its output generation pipeline?", "answer": null, "relative_code_list": null, "ground_truth": "Sphinx separates the Builder concept from the Writer concept in its output generation pipeline to achieve better separation of concerns, modularity, and extensibility. This separation provides several important architectural benefits.\n\nKey reasons for this separation include:\n\n1. **Separation of Concerns**: Builders focus on orchestrating the overall build process, managing file dependencies, and coordinating the build workflow, while Writers focus specifically on converting document trees to the target output format. This separation makes the codebase more maintainable and easier to understand.\n\n2. **Reusability**: Writers can be reused across different builders. For example, the same HTML writer can be used by both the HTML builder and the singlehtml builder, reducing code duplication and ensuring consistent output formatting.\n\n3. **Modularity**: The separation allows for independent development and testing of build logic and output generation logic. Builders can be modified without affecting writers, and vice versa.\n\n4. **Extensibility**: New output formats can be added by creating new writers without modifying existing builders. Similarly, new build strategies can be implemented by creating new builders that use existing writers.\n\n5. **Complexity Management**: Builders handle complex build-specific logic such as incremental builds, parallel processing, and dependency management, while writers focus on the simpler task of format conversion. This reduces the complexity of each component.\n\n6. **Testing**: The separation makes it easier to test builders and writers independently. Writers can be tested with sample document trees without needing to set up a full build environment.\n\n7. **Flexibility**: Different builders can use different strategies for managing the build process while still using the same writers for output generation. This allows for specialized builders (like linkcheck builders) that don't generate traditional documentation output.\n\n8. **Maintenance**: Changes to output formatting only require modifications to writers, while changes to build process logic only require modifications to builders. This reduces the risk of introducing bugs when making changes.\n\nThis architectural separation follows the single responsibility principle and makes Sphinx's output generation system more flexible and maintainable.", "score": null, "retrieved_content": [{"name": "write", "is_method": true, "class_name": "Builder", "parameters": ["self", "build_docnames", "updated_docnames", "method"], "calls": ["self.events.emit", "dict", "set", "logger.debug", "logger.debug", "sorted", "progress_message", "self.prepare_writing", "progress_message", "self.copy_assets", "self.write_documents", "set", "set", "__", "join", "__", "env.files_to_rebuild.get", "env.toctree_includes.items", "__", "__", "sorted"], "code_location": {"file": "__init__.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/builders", "start_line": 712, "end_line": 755}, "code_snippet": "    def write(\n        self,\n        build_docnames: Iterable[str] | None,\n        updated_docnames: Iterable[str],\n        method: Literal['all', 'specific', 'update'] = 'update',\n    ) -> None:\n        \"\"\"Write builder specific output files.\"\"\"\n        env = self.env\n\n        # Allow any extensions to perform setup for writing\n        self.events.emit('write-started', self)\n\n        if build_docnames is None or build_docnames == ['__all__']:\n            # build_all\n            build_docnames = env.found_docs\n        if method == 'update':\n            # build updated ones as well\n            docnames = set(build_docnames) | set(updated_docnames)\n        else:\n            docnames = set(build_docnames)\n        if docnames:\n            logger.debug(__('docnames to write: %s'), ', '.join(sorted(docnames)))\n        else:\n            logger.debug(__('no docnames to write!'))\n\n        # add all toctree-containing files that may have changed\n        docnames |= {\n            toc_docname\n            for docname in docnames\n            for toc_docname in env.files_to_rebuild.get(docname, ())\n            if toc_docname in env.found_docs\n        }\n\n        # sort to ensure deterministic toctree generation\n        env.toctree_includes = dict(sorted(env.toctree_includes.items()))\n\n        with progress_message(__('preparing documents')):\n            self.prepare_writing(docnames)\n\n        with progress_message(__('copying assets'), nonl=False):\n            self.copy_assets()\n\n        if docnames:\n            self.write_documents(docnames)\n", "type": "function"}, {"name": "Builder", "docstring": "Builds target formats from the reST sources.", "methods": ["__init__", "app", "_translator", "get_translator_class", "create_translator", "init", "create_template_bridge", "get_target_uri", "get_relative_uri", "get_outdated_docs", "get_asset_paths", "post_process_images", "compile_catalogs", "compile_all_catalogs", "compile_specific_catalogs", "compile_update_catalogs", "build_all", "build_specific", "build_update", "build", "read", "_read_serial", "_read_parallel", "read_doc", "write_doctree", "write", "write_documents", "_write_serial", "_write_parallel", "prepare_writing", "copy_assets", "write_doc", "write_doc_serialized", "finish", "cleanup", "get_builder_config"], "attributes": ["srcdir", "confdir", "outdir", "doctreedir"], "code_location": {"file": "__init__.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/builders", "start_line": 64, "end_line": 881}, "type": "class"}, {"name": "SphinxFileOutput", "docstring": "Better FileOutput class for Sphinx.", "methods": ["__init__", "write"], "attributes": [], "code_location": {"file": "docutils.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/util", "start_line": 447, "end_line": 469}, "type": "class"}, {"name": "XMLBuilder", "docstring": "Builds Docutils-native XML.", "methods": ["init", "get_outdated_docs", "get_target_uri", "write_doc", "_translate", "finish"], "attributes": ["name", "format", "epilog", "out_suffix", "allow_parallel", "default_translator_class"], "code_location": {"file": "xml.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/builders", "start_line": 24, "end_line": 95}, "type": "class"}, {"name": "SphinxDummyWriter", "docstring": "Dummy writer module used for generating doctree.", "methods": ["__init__", "translate"], "attributes": ["supported"], "code_location": {"file": "io.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx", "start_line": 112, "end_line": 126}, "type": "class"}, {"name": "TexinfoBuilder", "docstring": "Builds Texinfo output to create Info documentation.", "methods": ["init", "get_outdated_docs", "get_target_uri", "get_relative_uri", "prepare_writing", "write_documents", "assemble_doctree", "copy_assets", "copy_image_files", "copy_support_files"], "attributes": ["name", "format", "epilog", "supported_image_types", "default_translator_class"], "code_location": {"file": "texinfo.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/builders", "start_line": 36, "end_line": 218}, "type": "class"}, {"name": "StandaloneHTMLBuilder", "docstring": "Builds standalone HTML docs.", "methods": ["__init__", "init", "create_build_info", "_get_translations_js", "_get_style_filenames", "get_theme_config", "init_templates", "init_highlighter", "css_files", "init_css_files", "add_css_file", "script_files", "init_js_files", "add_js_file", "math_renderer_name", "get_outdated_docs", "get_asset_paths", "render_partial", "prepare_writing", "get_doc_context", "copy_assets", "write_doc", "write_doc_serialized", "finish", "gen_indices", "gen_pages_from_extensions", "gen_additional_pages", "write_genindex", "write_domain_indices", "copy_image_files", "copy_download_files", "create_pygments_style_file", "copy_translation_js", "copy_stemmer_js", "copy_theme_static_files", "copy_html_static_files", "copy_html_logo", "copy_html_favicon", "copy_static_files", "copy_extra_files", "write_buildinfo", "cleanup", "post_process_images", "load_indexer", "index_page", "_get_local_toctree", "get_output_path", "get_outfilename", "add_sidebars", "get_target_uri", "handle_page", "update_page_context", "handle_finish", "dump_inventory", "dump_search_index"], "attributes": ["name", "format", "epilog", "default_translator_class", "copysource", "allow_parallel", "out_suffix", "link_suffix", "indexer_dumps_unicode", "html_scaled_image_link", "supported_image_types", "supported_remote_images", "supported_data_uri_images", "searchindex_filename", "add_permalinks", "allow_sharp_as_current_path", "embedded", "search", "use_index", "download_support"], "code_location": {"file": "__init__.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/builders/html", "start_line": 110, "end_line": 1292}, "type": "class"}, {"name": "Sphinx", "docstring": "The main application class and extensibility interface.\n\n:ivar srcdir: Directory containing source.\n:ivar confdir: Directory containing ``conf.py``.\n:ivar doctreedir: Directory for storing pickled doctrees.\n:ivar outdir: Directory for storing build documents.", "methods": ["__init__", "fresh_env_used", "phase", "_init_i18n", "_init_env", "_create_fresh_env", "_load_existing_env", "_post_init_env", "preload_builder", "create_builder", "_init_builder", "build", "setup_extension", "require_sphinx", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "disconnect", "emit", "emit_firstresult", "add_builder", "add_config_value", "add_event", "set_translator", "add_node", "add_enumerable_node", "add_directive", "add_role", "add_generic_role", "add_domain", "add_directive_to_domain", "add_role_to_domain", "add_index_to_domain", "add_object_type", "add_crossref_type", "add_transform", "add_post_transform", "add_js_file", "add_css_file", "add_latex_package", "add_lexer", "add_autodocumenter", "add_autodoc_attrgetter", "add_search_language", "add_source_suffix", "add_source_parser", "add_env_collector", "add_html_theme", "add_html_math_renderer", "add_message_catalog", "is_parallel_allowed", "set_html_assets_policy"], "attributes": ["srcdir", "confdir", "outdir", "doctreedir"], "code_location": {"file": "application.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx", "start_line": 142, "end_line": 1822}, "type": "class"}, {"name": "EpubBuilder", "docstring": "Builder that outputs epub files.\n\nIt creates the metainfo files container.opf, toc.ncx, mimetype, and\nMETA-INF/container.xml.  Afterwards, all necessary files are zipped to an\nepub file.", "methods": ["init", "create_build_info", "get_theme_config", "make_id", "get_refnodes", "check_refnodes", "get_toc", "toc_add_files", "fix_fragment", "fix_ids", "_update_node_id", "_make_footnote_ref", "_make_footnote", "_footnote_spot", "add_visible_links", "write_doc", "fix_genindex", "is_vector_graphics", "copy_image_files_pil", "copy_image_files", "copy_download_files", "handle_page", "build_mimetype", "build_container", "content_metadata", "build_content", "new_navpoint", "build_navpoints", "toc_metadata", "build_toc", "build_epub"], "attributes": ["copysource", "supported_image_types", "supported_remote_images", "add_permalinks", "allow_sharp_as_current_path", "embedded", "download_support", "html_scaled_image_link", "search", "coverpage_name", "toctree_template", "link_target_template", "css_link_target_class", "guide_titles", "media_types", "refuri_re", "doctype"], "code_location": {"file": "_epub_base.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/builders", "start_line": 129, "end_line": 808}, "type": "class"}, {"name": "SingleFileHTMLBuilder", "docstring": "Builds the whole document tree as a single HTML page.", "methods": ["get_outdated_docs", "get_target_uri", "get_relative_uri", "fix_refuris", "_get_local_toctree", "assemble_doctree", "assemble_toc_secnumbers", "assemble_toc_fignumbers", "get_doc_context", "write_documents", "finish", "write_additional_files"], "attributes": ["name", "epilog", "copysource"], "code_location": {"file": "singlehtml.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/builders", "start_line": 31, "end_line": 205}, "type": "class"}], "retrieved_count": 10, "cost_time": 1.2352533340454102}
{"question": "Why does Sphinx use a multi-phase build process instead of a single-pass document generation?", "answer": null, "relative_code_list": null, "ground_truth": "Sphinx uses a multi-phase build process instead of single-pass document generation for several important reasons related to cross-reference resolution, extensibility, and build efficiency.\n\nKey reasons for the multi-phase approach include:\n\n1. **Cross-Reference Resolution**: Many cross-references in Sphinx documentation can only be resolved after all documents have been read and their metadata has been collected. For example, a reference to a function in another document requires that the target document has been processed to know where that function is defined.\n\n2. **Incremental Builds**: The multi-phase approach allows Sphinx to implement efficient incremental builds. By separating reading from writing, Sphinx can determine which documents have changed and only rebuild the necessary parts of the documentation.\n\n3. **Extension Integration**: The multi-phase process provides multiple hook points for extensions to modify the document processing. Extensions can add functionality at different stages (reading, resolving, writing) without interfering with each other.\n\n4. **Memory Management**: Processing all documents in a single pass would require keeping all document trees in memory simultaneously, which could be problematic for large documentation projects. The multi-phase approach allows for more efficient memory usage.\n\n5. **Parallel Processing**: The separation of phases enables parallel processing of documents during the reading phase, as documents can be processed independently before cross-references are resolved.\n\n6. **Error Handling**: The multi-phase approach allows for better error handling and recovery. If errors occur during one phase, they can be handled appropriately without affecting other phases.\n\n7. **Consistency Checking**: The multi-phase process includes a consistency checking phase where Sphinx can verify that all cross-references are valid and that the documentation is internally consistent.\n\nThe phases typically include: initialization, reading (parsing source files), consistency checks, resolving (cross-references), and writing (output generation). This approach provides the flexibility and robustness needed for complex documentation projects.", "score": null, "retrieved_content": [{"name": "build", "is_method": true, "class_name": "Sphinx", "parameters": ["self", "force_all", "filenames"], "calls": ["self.builder.cleanup", "self.events.emit", "logger.info", "logger.info", "self.builder.build_all", "envfile.is_file", "self.events.emit", "logger.info", "logger.info", "logger.info", "logger.info", "self.builder.build_specific", "self.builder.build_update", "envfile.unlink", "bold", "bold", "__", "bold", "__", "bold", "relpath", "__", "__", "__", "__", "__", "__"], "code_location": {"file": "application.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx", "start_line": 428, "end_line": 487}, "code_snippet": "    def build(self, force_all: bool = False, filenames: Sequence[Path] = ()) -> None:\n        self.builder.phase = BuildPhase.READING\n        try:\n            if force_all:\n                self.builder.build_all()\n            elif filenames:\n                self.builder.build_specific(filenames)\n            else:\n                self.builder.build_update()\n\n            self.events.emit('build-finished', None)\n        except Exception as err:\n            # delete the saved env to force a fresh build next time\n            envfile = self.doctreedir / ENV_PICKLE_FILENAME\n            if envfile.is_file():\n                envfile.unlink()\n            self.events.emit('build-finished', err)\n            raise\n\n        if self._warncount == 0:\n            if self.statuscode != 0:\n                logger.info(bold(__('build finished with problems.')))\n            else:\n                logger.info(bold(__('build succeeded.')))\n        elif self._warncount == 1:\n            if self._fail_on_warnings:\n                self.statuscode = 1\n                msg = __(\n                    'build finished with problems, 1 warning '\n                    '(with warnings treated as errors).'\n                )\n            elif self.statuscode != 0:\n                msg = __('build finished with problems, 1 warning.')\n            else:\n                msg = __('build succeeded, 1 warning.')\n            logger.info(bold(msg))\n        else:\n            if self._fail_on_warnings:\n                self.statuscode = 1\n                msg = __(\n                    'build finished with problems, %s warnings '\n                    '(with warnings treated as errors).'\n                )\n            elif self.statuscode != 0:\n                msg = __('build finished with problems, %s warnings.')\n            else:\n                msg = __('build succeeded, %s warnings.')\n            logger.info(bold(msg), self._warncount)\n\n        if self.statuscode == 0 and self.builder.epilog:\n            logger.info('')\n            logger.info(\n                self.builder.epilog,\n                {\n                    'outdir': relpath(self.outdir),\n                    'project': self.config.project,\n                },\n            )\n\n        self.builder.cleanup()\n", "type": "function"}, {"name": "build_main", "is_method": false, "class_name": null, "parameters": ["argv"], "calls": ["get_parser", "_parse_arguments", "_parse_confdir", "_parse_doctreedir", "_validate_filenames", "_validate_colour_support", "_parse_logging", "_parse_confoverrides", "patch_docutils", "docutils_namespace", "Sphinx", "app.build", "sphinx._cli.util.errors.handle_exception", "warnfp.close", "app.extensions.values"], "code_location": {"file": "build.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/cmd", "start_line": 395, "end_line": 452}, "code_snippet": "def build_main(argv: Sequence[str]) -> int:\n    \"\"\"Sphinx build \"main\" command-line entry.\"\"\"\n    parser = get_parser()\n    args = _parse_arguments(parser, argv)\n    args.confdir = _parse_confdir(args.noconfig, args.confdir, args.sourcedir)\n    args.doctreedir = _parse_doctreedir(args.doctreedir, args.outputdir)\n    _validate_filenames(parser, args.force_all, args.filenames)\n    _validate_colour_support(args.color)\n    args.status, args.warning, args.error, warnfp = _parse_logging(\n        parser, args.quiet, args.really_quiet, args.warnfile\n    )\n    args.confoverrides = _parse_confoverrides(\n        parser, args.define, args.htmldefine, args.nitpicky\n    )\n\n    app = None\n    try:\n        confdir = args.confdir or args.sourcedir\n        with patch_docutils(confdir), docutils_namespace():\n            app = Sphinx(\n                srcdir=args.sourcedir,\n                confdir=args.confdir,\n                outdir=args.outputdir,\n                doctreedir=args.doctreedir,\n                buildername=args.builder,\n                confoverrides=args.confoverrides,\n                status=args.status,\n                warning=args.warning,\n                freshenv=args.freshenv,\n                warningiserror=args.warningiserror,\n                tags=args.tags,\n                verbosity=args.verbosity,\n                parallel=args.jobs,\n                keep_going=False,\n                pdb=args.pdb,\n                exception_on_warning=args.exception_on_warning,\n            )\n            app.build(args.force_all, args.filenames)\n            return app.statuscode\n    except (Exception, KeyboardInterrupt) as exc:\n        if app is not None:\n            message_log: Sequence[str] = app.messagelog\n            extensions: Collection[Extension] = app.extensions.values()\n        else:\n            message_log = extensions = ()\n        sphinx._cli.util.errors.handle_exception(\n            exc,\n            stderr=args.error,\n            use_pdb=args.pdb,\n            print_traceback=args.verbosity or args.traceback,\n            message_log=message_log,\n            extensions=extensions,\n        )\n        return 2\n    finally:\n        if warnfp is not None:\n            # close the file descriptor for the warnings file opened by Sphinx\n            warnfp.close()\n", "type": "function"}, {"name": "build", "is_method": true, "class_name": "SphinxTestApp", "parameters": ["self", "force_all", "filenames"], "calls": ["self.env._pickled_doctree_cache.clear", "build", "super"], "code_location": {"file": "util.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/testing", "start_line": 235, "end_line": 237}, "code_snippet": "    def build(self, force_all: bool = False, filenames: Sequence[Path] = ()) -> None:\n        self.env._pickled_doctree_cache.clear()\n        super().build(force_all, filenames)\n", "type": "function"}, {"name": "build", "is_method": false, "class_name": null, "parameters": ["srcdir"], "calls": ["subprocess.run"], "code_location": {"file": "generate_js_fixtures.py", "path": "/data3/pwh/swebench-repos/sphinx/utils", "start_line": 17, "end_line": 26}, "code_snippet": "def build(srcdir: Path) -> None:\n    cmd = (\n        'sphinx-build',\n        '--fresh-env',\n        '--quiet',\n        *('--builder', 'html'),\n        f'{srcdir}',\n        f'{srcdir}/_build',\n    )\n    subprocess.run(cmd, check=True, capture_output=True)\n", "type": "function"}, {"name": "test_build", "is_method": false, "class_name": null, "parameters": ["app"], "calls": ["pytest.mark.sphinx", "app.build", "read_text", "py_undoc.startswith", "read_text", "c_undoc.startswith", "pickle.loads", "app.status.getvalue", "read_bytes", "len", "next", "app.status.getvalue", "iter", "undoc_c.values"], "code_location": {"file": "test_ext_coverage.py", "path": "/data3/pwh/swebench-repos/sphinx/tests/test_extensions", "start_line": 15, "end_line": 55}, "code_snippet": "def test_build(app: SphinxTestApp) -> None:\n    app.build(force_all=True)\n\n    py_undoc = (app.outdir / 'python.txt').read_text(encoding='utf8')\n    assert py_undoc.startswith(\n        'Undocumented Python objects\\n===========================\\n',\n    )\n    assert 'autodoc_target\\n--------------\\n' in py_undoc\n    assert ' * Class -- missing methods:\\n' in py_undoc\n    assert ' * raises\\n' in py_undoc\n    # these two are documented in autodoc.txt\n    assert ' * function\\n' not in py_undoc\n    assert ' * Class\\n' not in py_undoc\n\n    # in the \"failed import\" section\n    assert \" * mod -- No module named 'mod'\" in py_undoc\n\n    assert 'undocumented  py' not in app.status.getvalue()\n\n    c_undoc = (app.outdir / 'c.txt').read_text(encoding='utf8')\n    assert c_undoc.startswith(\n        'Undocumented C API elements\\n===========================\\n',\n    )\n    assert 'api.h' in c_undoc\n    assert ' * Py_SphinxTest' in c_undoc\n\n    undoc_py, undoc_c, _py_undocumented, _py_documented = pickle.loads(\n        (app.outdir / 'undoc.pickle').read_bytes()\n    )\n    assert len(undoc_c) == 1\n    # the key is the full path to the header file, which isn't testable\n    assert next(iter(undoc_c.values())) == {('function', 'Py_SphinxTest')}\n\n    assert 'autodoc_target' in undoc_py\n    assert 'funcs' in undoc_py['autodoc_target']\n    assert 'raises' in undoc_py['autodoc_target']['funcs']\n    assert 'classes' in undoc_py['autodoc_target']\n    assert 'Class' in undoc_py['autodoc_target']['classes']\n    assert 'undocmeth' in undoc_py['autodoc_target']['classes']['Class']\n\n    assert 'undocumented  c' not in app.status.getvalue()\n", "type": "function"}, {"name": "write_documents", "is_method": true, "class_name": "SingleFileHTMLBuilder", "parameters": ["self", "_docnames"], "calls": ["self.prepare_writing", "self.env.all_docs.keys", "progress_message", "self.assemble_doctree", "self.assemble_toc_secnumbers", "self.assemble_toc_fignumbers", "progress_message", "self.write_doc_serialized", "self.write_doc", "__", "__"], "code_location": {"file": "singlehtml.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/builders", "start_line": 168, "end_line": 178}, "code_snippet": "    def write_documents(self, _docnames: Set[str]) -> None:\n        self.prepare_writing(self.env.all_docs.keys())\n\n        with progress_message(__('assembling single document'), nonl=False):\n            doctree = self.assemble_doctree()\n            self.env.toc_secnumbers = self.assemble_toc_secnumbers()\n            self.env.toc_fignumbers = self.assemble_toc_fignumbers()\n\n        with progress_message(__('writing')):\n            self.write_doc_serialized(self.config.root_doc, doctree)\n            self.write_doc(self.config.root_doc, doctree)\n", "type": "function"}, {"name": "_write_parallel", "is_method": true, "class_name": "Builder", "parameters": ["self", "docnames", "nproc"], "calls": ["_write_docname", "ParallelTasks", "make_chunks", "status_iterator", "tasks.join", "logger.info", "__", "len", "next", "tasks.add_task", "self.write_doc", "self.env.get_and_resolve_doctree", "self.write_doc_serialized", "arg.append"], "code_location": {"file": "__init__.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/builders", "start_line": 786, "end_line": 825}, "code_snippet": "    def _write_parallel(self, docnames: Sequence[str], nproc: int) -> None:\n        def write_process(docs: list[tuple[str, nodes.document]]) -> None:\n            self.phase = BuildPhase.WRITING\n            for docname, doctree in docs:\n                self.write_doc(docname, doctree)\n\n        # warm up caches/compile templates using the first document\n        firstname, docnames = docnames[0], docnames[1:]\n        _write_docname(firstname, env=self.env, builder=self, tags=self.tags)\n\n        tasks = ParallelTasks(nproc)\n        chunks = make_chunks(docnames, nproc)\n\n        # create a status_iterator to step progressbar after writing a document\n        # (see: ``on_chunk_done()`` function)\n        progress = status_iterator(\n            chunks,\n            __('writing output... '),\n            'darkgreen',\n            len(chunks),\n            self.config.verbosity,\n        )\n\n        def on_chunk_done(args: list[tuple[str, nodes.document]], result: None) -> None:\n            next(progress)\n\n        self.phase = BuildPhase.RESOLVING\n        for chunk in chunks:\n            arg = []\n            for docname in chunk:\n                doctree = self.env.get_and_resolve_doctree(\n                    docname, self, tags=self.tags\n                )\n                self.write_doc_serialized(docname, doctree)\n                arg.append((docname, doctree))\n            tasks.add_task(write_process, arg, on_chunk_done)\n\n        # make sure all threads have finished\n        tasks.join()\n        logger.info('')\n", "type": "function"}, {"name": "BuildEnvironment", "docstring": "The environment in which the ReST files are translated.\nStores an inventory of cross-file targets and provides doctree\ntransformations to resolve links to them.", "methods": ["__init__", "__getstate__", "__setstate__", "setup", "app", "app", "app", "_registry", "_tags", "_config_status", "_update_settings", "set_versioning_method", "clear_doc", "merge_info_from", "path2doc", "doc2path", "relfn2path", "found_docs", "find_files", "get_outdated_files", "check_dependents", "prepare_settings", "temp_data", "docname", "parser", "new_serialno", "note_dependency", "note_included", "note_reread", "get_domain", "get_doctree", "master_doctree", "get_and_resolve_doctree", "resolve_toctree", "resolve_references", "apply_post_transforms", "collect_relations", "check_consistency"], "attributes": ["srcdir", "doctreedir"], "code_location": {"file": "__init__.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/environment", "start_line": 100, "end_line": 812}, "type": "class"}, {"name": "assemble_doctree", "is_method": true, "class_name": "LaTeXBuilder", "parameters": ["self", "indexfile", "toctree_only", "appendices"], "calls": ["logger.info", "self.env.get_doctree", "inline_all_toctrees", "logger.info", "logger.info", "self.env.resolve_references", "largetree.findall", "darkgreen", "new_document", "nodes.section", "nodes.title", "tree.findall", "self.env.get_doctree", "largetree.append", "__", "pendingnode.replace_self", "nodes.emphasis", "docname.startswith", "newnodes.extend", "nodes.Text", "nodes.emphasis", "nodes.Text", "_"], "code_location": {"file": "__init__.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/builders/latex", "start_line": 369, "end_line": 415}, "code_snippet": "    def assemble_doctree(\n        self,\n        indexfile: str,\n        toctree_only: bool,\n        appendices: list[str],\n    ) -> nodes.document:\n        self.docnames = {indexfile, *appendices}\n        logger.info(darkgreen(indexfile))\n        tree = self.env.get_doctree(indexfile)\n        tree['docname'] = indexfile\n        if toctree_only:\n            # extract toctree nodes from the tree and put them in a\n            # fresh document\n            new_tree = new_document('<latex output>')\n            new_sect = nodes.section()\n            new_sect += nodes.title('<Set title in conf.py>', '<Set title in conf.py>')\n            new_tree += new_sect\n            for node in tree.findall(addnodes.toctree):\n                new_sect += node\n            tree = new_tree\n        largetree = inline_all_toctrees(\n            self, self.docnames, indexfile, tree, darkgreen, [indexfile]\n        )\n        largetree['docname'] = indexfile\n        for docname in appendices:\n            appendix = self.env.get_doctree(docname)\n            appendix['docname'] = docname\n            largetree.append(appendix)\n        logger.info('')\n        logger.info(__('resolving references...'))\n        self.env.resolve_references(largetree, indexfile, self)\n        # resolve :ref:s to distant tex files -- we can't add a cross-reference,\n        # but append the document name\n        for pendingnode in largetree.findall(addnodes.pending_xref):\n            docname = pendingnode['refdocname']\n            sectname = pendingnode['refsectname']\n            newnodes: list[Node] = [nodes.emphasis(sectname, sectname)]\n            for subdir, title in self.titles:\n                if docname.startswith(subdir):\n                    newnodes.extend((\n                        nodes.Text(_(' (in ')),\n                        nodes.emphasis(title, title),\n                        nodes.Text(')'),\n                    ))\n                    break\n            pendingnode.replace_self(newnodes)\n        return largetree\n", "type": "function"}, {"name": "_build_inventory", "is_method": false, "class_name": null, "parameters": ["srcdir"], "calls": ["SphinxTestApp", "app.build", "sphinx.locale.translators.clear"], "code_location": {"file": "test_util_inventory.py", "path": "/data3/pwh/swebench-repos/sphinx/tests/test_util", "start_line": 103, "end_line": 107}, "code_snippet": "def _build_inventory(srcdir: Path) -> Path:\n    app = SphinxTestApp(srcdir=srcdir)\n    app.build()\n    sphinx.locale.translators.clear()\n    return app.outdir / 'objects.inv'\n", "type": "function"}], "retrieved_count": 10, "cost_time": 1.2574493885040283}
{"question": "Why does Sphinx use an event-driven architecture for its extension system instead of direct method calls?", "answer": null, "relative_code_list": null, "ground_truth": "Sphinx uses an event-driven architecture for its extension system instead of direct method calls for several important reasons related to extensibility, decoupling, and maintainability.\n\nKey reasons for the event-driven approach include:\n\n1. **Loose Coupling**: The event-driven architecture decouples the core Sphinx system from extensions, allowing extensions to be added or removed without modifying the core codebase. This makes the system more modular and maintainable.\n\n2. **Multiple Extension Support**: Multiple extensions can listen to the same events without interfering with each other. This allows for rich extension ecosystems where different extensions can add functionality to the same build phases.\n\n3. **Flexible Hook Points**: The event system provides numerous hook points throughout the build process (e.g., 'config-inited', 'builder-inited', 'doctree-read', 'doctree-resolved'), allowing extensions to integrate at the most appropriate stage.\n\n4. **Non-Intrusive Integration**: Extensions can add functionality without requiring changes to the core Sphinx code. This makes it easier to maintain backward compatibility and reduces the risk of introducing bugs when adding new features.\n\n5. **Dynamic Extension Loading**: The event system allows extensions to be loaded dynamically and to register their event handlers at runtime, providing flexibility in how extensions are integrated.\n\n6. **Error Isolation**: If one extension fails during event processing, it doesn't necessarily affect other extensions or the core build process, providing better error isolation and robustness.\n\n7. **Build Phase Integration**: The event system aligns well with Sphinx's multi-phase build process, allowing extensions to hook into specific phases (reading, resolving, writing) as needed.\n\n8. **Extensibility**: The event-driven approach makes it easy to add new extension points in the future without breaking existing extensions, as new events can be added without changing the existing event system.\n\nThis architecture provides the flexibility and robustness needed for a complex documentation system that needs to support a wide variety of extensions and use cases.", "score": null, "retrieved_content": [{"name": "emit", "is_method": true, "class_name": "EventManager", "parameters": ["self", "name"], "calls": ["sorted", "repr", "logger.debug", "attrgetter", "results.append", "listener.handler", "safe_getattr", "ExtensionError", "__"], "code_location": {"file": "events.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx", "start_line": 393, "end_line": 429}, "code_snippet": "    def emit(\n        self,\n        name: str,\n        *args: Any,\n        allowed_exceptions: tuple[type[Exception], ...] = (),\n    ) -> list[Any]:\n        \"\"\"Emit a Sphinx event.\"\"\"\n        # not every object likes to be repr()'d (think\n        # random stuff coming via autodoc)\n        try:\n            repr_args = repr(args)\n        except Exception:\n            pass\n        else:\n            logger.debug('[app] emitting event: %r%s', name, repr_args)\n\n        results = []\n        listeners = sorted(self.listeners[name], key=attrgetter('priority'))\n        for listener in listeners:\n            try:\n                results.append(listener.handler(self._app, *args))\n            except allowed_exceptions:\n                # pass through the errors specified as *allowed_exceptions*\n                raise\n            except SphinxError:\n                raise\n            except Exception as exc:\n                if self._reraise_errors:\n                    raise\n                modname = safe_getattr(listener.handler, '__module__', None)\n                raise ExtensionError(\n                    __('Handler %r for event %r threw an exception')\n                    % (listener.handler, name),\n                    exc,\n                    modname=modname,\n                ) from exc\n        return results\n", "type": "function"}, {"name": "__init__", "is_method": true, "class_name": "EventManager", "parameters": ["self", "app"], "calls": ["core_events.copy", "defaultdict"], "code_location": {"file": "events.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx", "start_line": 69, "end_line": 76}, "code_snippet": "    def __init__(self, app: Sphinx) -> None:\n        self._app = app\n        self.events = core_events.copy()\n        self.listeners: dict[str, list[EventListener]] = defaultdict(list)\n        self.next_listener_id = 0\n\n        # pass through errors for debugging.\n        self._reraise_errors: bool = app.pdb\n", "type": "function"}, {"name": "add", "is_method": true, "class_name": "EventManager", "parameters": ["self", "name"], "calls": ["ExtensionError", "__"], "code_location": {"file": "events.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx", "start_line": 78, "end_line": 82}, "code_snippet": "    def add(self, name: str) -> None:\n        \"\"\"Register a custom Sphinx event.\"\"\"\n        if name in self.events:\n            raise ExtensionError(__('Event %r already present') % name)\n        self.events[name] = ''\n", "type": "function"}, {"name": "connect", "is_method": true, "class_name": "Sphinx", "parameters": ["self", "event", "callback", "priority"], "calls": [], "code_location": {"file": "application.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx", "start_line": 661, "end_line": 666}, "code_snippet": "    def connect(\n        self,\n        event: Literal['build-finished'],\n        callback: Callable[[Sphinx, Exception | None], None],\n        priority: int = 500,\n    ) -> int: ...\n", "type": "function"}, {"name": "EventManager", "docstring": "Event manager for Sphinx.", "methods": ["__init__", "add", "app", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "disconnect", "emit", "emit_firstresult"], "attributes": [], "code_location": {"file": "events.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx", "start_line": 66, "end_line": 444}, "type": "class"}, {"name": "connect", "is_method": true, "class_name": "Sphinx", "parameters": ["self", "event", "callback", "priority"], "calls": [], "code_location": {"file": "application.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx", "start_line": 534, "end_line": 539}, "code_snippet": "    def connect(\n        self,\n        event: Literal['builder-inited'],\n        callback: Callable[[Sphinx], None],\n        priority: int = 500,\n    ) -> int: ...\n", "type": "function"}, {"name": "connect", "is_method": true, "class_name": "EventManager", "parameters": ["self", "name", "callback", "priority"], "calls": [], "code_location": {"file": "events.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx", "start_line": 100, "end_line": 105}, "code_snippet": "    def connect(\n        self,\n        name: Literal['builder-inited'],\n        callback: Callable[[Sphinx], None],\n        priority: int,\n    ) -> int: ...\n", "type": "function"}, {"name": "connect", "is_method": true, "class_name": "Sphinx", "parameters": ["self", "event", "callback", "priority"], "calls": [], "code_location": {"file": "application.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx", "start_line": 746, "end_line": 751}, "code_snippet": "    def connect(\n        self,\n        event: Literal['autodoc-process-bases'],\n        callback: Callable[[Sphinx, str, Any, dict[str, bool], list[str]], None],\n        priority: int = 500,\n    ) -> int: ...\n", "type": "function"}, {"name": "setup", "is_method": false, "class_name": null, "parameters": ["app"], "calls": ["app.connect", "app.connect", "GroupedField", "app.add_object_type"], "code_location": {"file": "conf.py", "path": "/data3/pwh/swebench-repos/sphinx/doc", "start_line": 350, "end_line": 364}, "code_snippet": "def setup(app: Sphinx) -> None:\n    from sphinx.util.docfields import GroupedField\n\n    app.connect('include-read', linkify_issues_in_changelog)\n    app.connect('build-finished', build_redirects)\n    fdesc = GroupedField(\n        'parameter', label='Parameters', names=('param',), can_collapse=True\n    )\n    app.add_object_type(\n        'event',\n        'event',\n        'pair: %s; event',\n        parse_event,\n        doc_field_types=[fdesc],\n    )\n", "type": "function"}, {"name": "connect", "is_method": true, "class_name": "EventManager", "parameters": ["self", "name", "callback", "priority"], "calls": [], "code_location": {"file": "events.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx", "start_line": 227, "end_line": 232}, "code_snippet": "    def connect(\n        self,\n        name: Literal['build-finished'],\n        callback: Callable[[Sphinx, Exception | None], None],\n        priority: int,\n    ) -> int: ...\n", "type": "function"}], "retrieved_count": 10, "cost_time": 1.2766015529632568}
{"question": "Why does Sphinx use a caching mechanism for build time optimization?", "answer": null, "relative_code_list": null, "ground_truth": "Sphinx uses a caching mechanism for build time optimization to avoid redundant processing and significantly improve build performance, especially for large documentation projects and incremental builds. This caching system provides several important performance benefits.\n\nKey reasons for implementing caching include:\n\n1. **Avoid Redundant Processing**: Caching allows Sphinx to skip expensive operations like parsing source files, resolving cross-references, and generating document trees for files that haven't changed since the last build.\n\n2. **Incremental Build Support**: The caching system is fundamental to Sphinx's incremental build functionality. By caching the build environment and document trees, Sphinx can determine which files have changed and only rebuild the necessary components.\n\n3. **Cross-Reference Persistence**: Cross-reference data and metadata about documented objects are cached between builds, allowing Sphinx to maintain consistency and avoid recalculating complex relationships.\n\n4. **Memory Efficiency**: Caching reduces memory usage by allowing Sphinx to load only the necessary data from disk rather than keeping all document trees in memory simultaneously.\n\n5. **Build Time Reduction**: For large projects, caching can dramatically reduce build times by avoiding the expensive parsing and analysis phases for unchanged files.\n\n6. **Resource Conservation**: Caching reduces CPU usage and disk I/O by avoiding unnecessary file processing, making builds more efficient and less resource-intensive.\n\n7. **Development Workflow**: Caching improves the development experience by providing fast feedback during documentation development, allowing developers to see changes quickly without waiting for full rebuilds.\n\n8. **Scalability**: As documentation projects grow in size, the benefits of caching become more pronounced, making it possible to handle projects with thousands of files efficiently.\n\nThe caching system includes multiple levels of caching, including the build environment cache (stored as a pickle file), document tree caching, and various metadata caches that work together to optimize the build process.", "score": null, "retrieved_content": [{"name": "write_doctree", "is_method": true, "class_name": "Builder", "parameters": ["self", "docname", "doctree"], "calls": ["doctree.settings.copy", "doctree_filename.parent.mkdir", "open", "pickle.dump"], "code_location": {"file": "__init__.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/builders", "start_line": 681, "end_line": 709}, "code_snippet": "    def write_doctree(\n        self,\n        docname: str,\n        doctree: nodes.document,\n        *,\n        _cache: bool = True,\n    ) -> None:\n        \"\"\"Write the doctree to a file, to be used as a cache by re-builds.\"\"\"\n        # make it pickleable\n        doctree.reporter = None  # type: ignore[assignment]\n        doctree.transformer = None  # type: ignore[assignment]\n\n        # Create a copy of settings object before modification because it is\n        # shared with other documents.\n        doctree.settings = doctree.settings.copy()\n        doctree.settings.warning_stream = None\n        doctree.settings.env = None\n        doctree.settings.record_dependencies = None\n\n        doctree_filename = self.doctreedir / f'{docname}.doctree'\n        doctree_filename.parent.mkdir(parents=True, exist_ok=True)\n        with open(doctree_filename, 'wb') as f:\n            pickle.dump(doctree, f, pickle.HIGHEST_PROTOCOL)\n\n        # When Sphinx is running in parallel mode, ``write_doctree()`` is invoked\n        # in the context of a process worker, and thus it does not make sense to\n        # pickle the doctree and send it to the main process\n        if _cache:\n            self.env._write_doc_doctree_cache[docname] = doctree\n", "type": "function"}, {"name": "BuildPhase", "docstring": "Build phase of Sphinx application.", "methods": [], "attributes": ["INITIALIZATION", "READING", "CONSISTENCY_CHECK", "RESOLVING", "WRITING"], "code_location": {"file": "build_phase.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/util", "start_line": 8, "end_line": 15}, "type": "class"}, {"name": "SphinxTestAppWrapperForSkipBuilding", "docstring": "A wrapper for SphinxTestApp.\n\nThis class is used to speed up the test by skipping ``app.build()``\nif it has already been built and there are any output files.", "methods": ["build"], "attributes": [], "code_location": {"file": "util.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/testing", "start_line": 240, "end_line": 250}, "type": "class"}, {"name": "__init__", "is_method": true, "class_name": "BuildEnvironment", "parameters": ["self", "app"], "calls": ["_get_env_version", "default_settings.copy", "defaultdict", "defaultdict", "set", "defaultdict", "set", "set", "FilenameUniqDict", "DownloadFiles", "_CurrentDocument", "_DomainsContainer._from_environment", "self.setup"], "code_location": {"file": "__init__.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/environment", "start_line": 114, "end_line": 239}, "code_snippet": "    def __init__(self, app: Sphinx) -> None:\n        self._app: Sphinx = app\n        self.doctreedir = app.doctreedir\n        self.srcdir = app.srcdir\n        self.config: Config = None  # type: ignore[assignment]\n        self.config_status: int = CONFIG_UNSET\n        self.config_status_extra: str = ''\n        self.events: EventManager = app.events\n        self.project: Project = app.project\n        self.version: Mapping[str, int] = _get_env_version(app.extensions)\n\n        # the method of doctree versioning; see set_versioning_method\n        self.versioning_condition: Literal[False] | Callable[[Node], bool] | None = None\n        self.versioning_compare: bool | None = None\n\n        # the docutils settings for building\n        self.settings: dict[str, Any] = default_settings.copy()\n        self.settings['env'] = self\n\n        # All \"docnames\" here are /-separated and relative and exclude\n        # the source suffix.\n\n        # docname -> time of reading (in integer microseconds)\n        # contains all read docnames\n        self.all_docs: dict[str, int] = {}\n        # docname -> set of dependent file\n        # names, relative to documentation root\n        self.dependencies: dict[str, set[_StrPath]] = defaultdict(set)\n        # docname -> set of included file\n        # docnames included from other documents\n        self.included: dict[str, set[str]] = defaultdict(set)\n        # docnames to re-read unconditionally on next build\n        self.reread_always: set[str] = set()\n\n        self._pickled_doctree_cache: dict[str, bytes] = {}\n        \"\"\"In-memory cache for reading pickled doctrees from disk.\n        docname -> pickled doctree\n\n        This cache is used in the ``get_doctree`` method to avoid reading the\n        doctree from disk multiple times.\n        \"\"\"\n\n        self._write_doc_doctree_cache: dict[str, nodes.document] = {}\n        \"\"\"In-memory cache for unpickling doctrees from disk.\n        docname -> doctree\n\n        Items are added in ``Builder.write_doctree``, during the read phase,\n        then used only in the ``get_and_resolve_doctree`` method.\n        \"\"\"\n\n        # File metadata\n        # docname -> dict of metadata items\n        self.metadata: dict[str, dict[str, Any]] = defaultdict(dict)\n\n        # TOC inventory\n        # docname -> title node\n        self.titles: dict[str, nodes.title] = {}\n        # docname -> title node; only different if\n        # set differently with title directive\n        self.longtitles: dict[str, nodes.title] = {}\n        # docname -> table of contents nodetree\n        self.tocs: dict[str, nodes.bullet_list] = {}\n        # docname -> number of real entries\n        self.toc_num_entries: dict[str, int] = {}\n\n        # used to determine when to show the TOC\n        # in a sidebar (don't show if it's only one item)\n        # docname -> dict of sectionid -> number\n        self.toc_secnumbers: dict[str, dict[str, tuple[int, ...]]] = {}\n        # docname -> dict of figtype -> dict of figureid -> number\n        self.toc_fignumbers: dict[str, dict[str, dict[str, tuple[int, ...]]]] = {}\n\n        # docname -> list of toctree includefiles\n        self.toctree_includes: dict[str, list[str]] = {}\n        # docname -> set of files (containing its TOCs) to rebuild too\n        self.files_to_rebuild: dict[str, set[str]] = {}\n        # docnames that have :glob: toctrees\n        self.glob_toctrees: set[str] = set()\n        # docnames that have :numbered: toctrees\n        self.numbered_toctrees: set[str] = set()\n\n        # domain-specific inventories, here to be pickled\n        # domainname -> domain-specific dict\n        self.domaindata: dict[str, dict[str, Any]] = {}\n\n        # these map absolute path -> (docnames, unique filename)\n        self.images: FilenameUniqDict = FilenameUniqDict()\n        # filename -> (set of docnames, destination)\n        self.dlfiles: DownloadFiles = DownloadFiles()\n\n        # the original URI for images\n        self.original_image_uri: dict[_StrPath, str] = {}\n\n        # temporary data storage while reading a document\n        self.current_document: _CurrentDocument = _CurrentDocument()\n        # context for cross-references (e.g. current module or class)\n        # this is similar to ``self.current_document``,\n        # but will for example be copied to attributes of \"any\" cross references\n        self.ref_context: dict[str, Any] = {}\n\n        # search index data\n\n        # docname -> title\n        self._search_index_titles: dict[str, str | None] = {}\n        # docname -> filename\n        self._search_index_filenames: dict[str, str] = {}\n        # stemmed words -> set(docname)\n        self._search_index_mapping: dict[str, set[str]] = {}\n        # stemmed words in titles -> set(docname)\n        self._search_index_title_mapping: dict[str, set[str]] = {}\n        # docname -> all titles in document\n        self._search_index_all_titles: dict[str, list[tuple[str, str | None]]] = {}\n        # docname -> list(index entry)\n        self._search_index_index_entries: dict[str, list[tuple[str, str, str]]] = {}\n        # objtype -> index\n        self._search_index_objtypes: dict[tuple[str, str], int] = {}\n        # objtype index -> (domain, type, objname (localized))\n        self._search_index_objnames: dict[int, tuple[str, str, str]] = {}\n\n        # all the registered domains, set by the application\n        self.domains: _DomainsContainer = _DomainsContainer._from_environment(\n            self, registry=app.registry\n        )\n\n        # set up environment\n        self.setup(app)\n", "type": "function"}, {"name": "build", "is_method": true, "class_name": "SphinxTestApp", "parameters": ["self", "force_all", "filenames"], "calls": ["self.env._pickled_doctree_cache.clear", "build", "super"], "code_location": {"file": "util.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/testing", "start_line": 235, "end_line": 237}, "code_snippet": "    def build(self, force_all: bool = False, filenames: Sequence[Path] = ()) -> None:\n        self.env._pickled_doctree_cache.clear()\n        super().build(force_all, filenames)\n", "type": "function"}, {"name": "Sphinx", "docstring": "The main application class and extensibility interface.\n\n:ivar srcdir: Directory containing source.\n:ivar confdir: Directory containing ``conf.py``.\n:ivar doctreedir: Directory for storing pickled doctrees.\n:ivar outdir: Directory for storing build documents.", "methods": ["__init__", "fresh_env_used", "phase", "_init_i18n", "_init_env", "_create_fresh_env", "_load_existing_env", "_post_init_env", "preload_builder", "create_builder", "_init_builder", "build", "setup_extension", "require_sphinx", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "disconnect", "emit", "emit_firstresult", "add_builder", "add_config_value", "add_event", "set_translator", "add_node", "add_enumerable_node", "add_directive", "add_role", "add_generic_role", "add_domain", "add_directive_to_domain", "add_role_to_domain", "add_index_to_domain", "add_object_type", "add_crossref_type", "add_transform", "add_post_transform", "add_js_file", "add_css_file", "add_latex_package", "add_lexer", "add_autodocumenter", "add_autodoc_attrgetter", "add_search_language", "add_source_suffix", "add_source_parser", "add_env_collector", "add_html_theme", "add_html_math_renderer", "add_message_catalog", "is_parallel_allowed", "set_html_assets_policy"], "attributes": ["srcdir", "confdir", "outdir", "doctreedir"], "code_location": {"file": "application.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx", "start_line": 142, "end_line": 1822}, "type": "class"}, {"name": "build_main", "is_method": false, "class_name": null, "parameters": ["argv"], "calls": ["get_parser", "_parse_arguments", "_parse_confdir", "_parse_doctreedir", "_validate_filenames", "_validate_colour_support", "_parse_logging", "_parse_confoverrides", "patch_docutils", "docutils_namespace", "Sphinx", "app.build", "sphinx._cli.util.errors.handle_exception", "warnfp.close", "app.extensions.values"], "code_location": {"file": "build.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/cmd", "start_line": 395, "end_line": 452}, "code_snippet": "def build_main(argv: Sequence[str]) -> int:\n    \"\"\"Sphinx build \"main\" command-line entry.\"\"\"\n    parser = get_parser()\n    args = _parse_arguments(parser, argv)\n    args.confdir = _parse_confdir(args.noconfig, args.confdir, args.sourcedir)\n    args.doctreedir = _parse_doctreedir(args.doctreedir, args.outputdir)\n    _validate_filenames(parser, args.force_all, args.filenames)\n    _validate_colour_support(args.color)\n    args.status, args.warning, args.error, warnfp = _parse_logging(\n        parser, args.quiet, args.really_quiet, args.warnfile\n    )\n    args.confoverrides = _parse_confoverrides(\n        parser, args.define, args.htmldefine, args.nitpicky\n    )\n\n    app = None\n    try:\n        confdir = args.confdir or args.sourcedir\n        with patch_docutils(confdir), docutils_namespace():\n            app = Sphinx(\n                srcdir=args.sourcedir,\n                confdir=args.confdir,\n                outdir=args.outputdir,\n                doctreedir=args.doctreedir,\n                buildername=args.builder,\n                confoverrides=args.confoverrides,\n                status=args.status,\n                warning=args.warning,\n                freshenv=args.freshenv,\n                warningiserror=args.warningiserror,\n                tags=args.tags,\n                verbosity=args.verbosity,\n                parallel=args.jobs,\n                keep_going=False,\n                pdb=args.pdb,\n                exception_on_warning=args.exception_on_warning,\n            )\n            app.build(args.force_all, args.filenames)\n            return app.statuscode\n    except (Exception, KeyboardInterrupt) as exc:\n        if app is not None:\n            message_log: Sequence[str] = app.messagelog\n            extensions: Collection[Extension] = app.extensions.values()\n        else:\n            message_log = extensions = ()\n        sphinx._cli.util.errors.handle_exception(\n            exc,\n            stderr=args.error,\n            use_pdb=args.pdb,\n            print_traceback=args.verbosity or args.traceback,\n            message_log=message_log,\n            extensions=extensions,\n        )\n        return 2\n    finally:\n        if warnfp is not None:\n            # close the file descriptor for the warnings file opened by Sphinx\n            warnfp.close()\n", "type": "function"}, {"name": "test_load_mappings_cache", "is_method": false, "class_name": null, "parameters": ["tmp_path"], "calls": ["touch", "touch", "SingleEntryProject", "make_inventory_handler", "project.make_entry", "dict", "InventoryAdapter", "http_server", "SphinxTestApp", "app.build", "app.cleanup", "list", "tmp_path.joinpath", "tmp_path.joinpath", "project.normalise"], "code_location": {"file": "test_ext_intersphinx_cache.py", "path": "/data3/pwh/swebench-repos/sphinx/tests/test_extensions", "start_line": 228, "end_line": 249}, "code_snippet": "def test_load_mappings_cache(tmp_path):\n    tmp_path.joinpath('conf.py').touch()\n    tmp_path.joinpath('index.rst').touch()\n    project = SingleEntryProject(1, 'a')\n\n    InventoryHandler = make_inventory_handler(project)\n    with http_server(InventoryHandler, port=project.port):\n        # clean build\n        confoverrides = BASE_CONFIG | {'intersphinx_mapping': project.record}\n        app = SphinxTestApp('dummy', srcdir=tmp_path, confoverrides=confoverrides)\n        app.build()\n        app.cleanup()\n\n    # the inventory when querying the 'old' URL\n    entry = project.make_entry()\n    item = dict((project.normalise(entry),))\n    inventories = InventoryAdapter(app.env)\n    assert list(inventories.cache) == ['http://localhost:9341/a']\n    e_name, _e_time, e_inv = inventories.cache['http://localhost:9341/a']\n    assert e_name == 'spam'\n    assert e_inv == {'py:module': item}\n    assert inventories.named_inventory == {'spam': {'py:module': item}}\n", "type": "function"}, {"name": "_has_doc_changed", "is_method": false, "class_name": null, "parameters": ["docname"], "calls": ["_last_modified_time", "logger.debug", "doctree_path.is_file", "logger.debug", "logger.debug", "_format_rfc3339_microseconds", "_format_rfc3339_microseconds", "dep_path.is_file", "logger.debug", "_last_modified_time", "logger.debug", "_format_rfc3339_microseconds", "_format_rfc3339_microseconds"], "code_location": {"file": "__init__.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/environment", "start_line": 838, "end_line": 900}, "code_snippet": "def _has_doc_changed(\n    docname: str,\n    *,\n    filename: Path,\n    reread_always: Set[str],\n    doctreedir: Path,\n    all_docs: Mapping[str, int],\n    dependencies: Mapping[str, Set[Path]],\n) -> bool:\n    # check the \"reread always\" list\n    if docname in reread_always:\n        logger.debug('[build target] changed %r: re-read forced', docname)\n        return True\n\n    # if the doctree file is not there, rebuild\n    doctree_path = doctreedir / f'{docname}.doctree'\n    if not doctree_path.is_file():\n        logger.debug('[build target] changed %r: doctree file does not exist', docname)\n        return True\n\n    # check the mtime of the document\n    mtime = all_docs[docname]\n    new_mtime = _last_modified_time(filename)\n    if new_mtime > mtime:\n        logger.debug(\n            '[build target] changed: %r is outdated (%s -> %s)',\n            docname,\n            _format_rfc3339_microseconds(mtime),\n            _format_rfc3339_microseconds(new_mtime),\n        )\n        return True\n\n    # finally, check the mtime of dependencies\n    if docname not in dependencies:\n        return False\n    for dep_path in dependencies[docname]:\n        try:\n            dep_path_is_file = dep_path.is_file()\n        except OSError:\n            return True  # give it another chance\n        if not dep_path_is_file:\n            logger.debug(\n                '[build target] changed: %r is missing dependency %r',\n                docname,\n                dep_path,\n            )\n            return True\n\n        try:\n            dep_mtime = _last_modified_time(dep_path)\n        except OSError:\n            return True  # give it another chance\n        if dep_mtime > mtime:\n            logger.debug(\n                '[build target] changed: %r is outdated due to dependency %r (%s -> %s)',\n                docname,\n                dep_path,\n                _format_rfc3339_microseconds(mtime),\n                _format_rfc3339_microseconds(dep_mtime),\n            )\n            return True\n\n    return False\n", "type": "function"}, {"name": "test_load_mappings_cache_revert_update", "is_method": false, "class_name": null, "parameters": ["tmp_path"], "calls": ["touch", "touch", "SingleEntryProject", "SingleEntryProject", "make_inventory_handler", "old_project.make_entry", "dict", "InventoryAdapter", "http_server", "SphinxTestApp", "app1.build", "app1.cleanup", "SphinxTestApp", "app2.build", "app2.cleanup", "SphinxTestApp", "app3.build", "app3.cleanup", "list", "tmp_path.joinpath", "tmp_path.joinpath", "old_project.normalise"], "code_location": {"file": "test_ext_intersphinx_cache.py", "path": "/data3/pwh/swebench-repos/sphinx/tests/test_extensions", "start_line": 285, "end_line": 319}, "code_snippet": "def test_load_mappings_cache_revert_update(tmp_path):\n    tmp_path.joinpath('conf.py').touch()\n    tmp_path.joinpath('index.rst').touch()\n    old_project = SingleEntryProject(1337, 'old')\n    new_project = SingleEntryProject(1701, 'new')\n\n    InventoryHandler = make_inventory_handler(old_project, new_project)\n    with http_server(InventoryHandler, port=SingleEntryProject.port):\n        # build normally to create an initial cache\n        confoverrides1 = BASE_CONFIG | {'intersphinx_mapping': old_project.record}\n        app1 = SphinxTestApp('dummy', srcdir=tmp_path, confoverrides=confoverrides1)\n        app1.build()\n        app1.cleanup()\n\n        # switch to new url and build\n        confoverrides2 = BASE_CONFIG | {'intersphinx_mapping': new_project.record}\n        app2 = SphinxTestApp('dummy', srcdir=tmp_path, confoverrides=confoverrides2)\n        app2.build()\n        app2.cleanup()\n\n        # switch back to old url (reuse 'old_item')\n        confoverrides3 = BASE_CONFIG | {'intersphinx_mapping': old_project.record}\n        app3 = SphinxTestApp('dummy', srcdir=tmp_path, confoverrides=confoverrides3)\n        app3.build()\n        app3.cleanup()\n\n    entry = old_project.make_entry()\n    item = dict((old_project.normalise(entry),))\n    inventories = InventoryAdapter(app3.env)\n    # check that the URLs were changed accordingly\n    assert list(inventories.cache) == ['http://localhost:9341/old']\n    e_name, _e_time, e_inv = inventories.cache['http://localhost:9341/old']\n    assert e_name == 'spam'\n    assert e_inv == {'py:module': item}\n    assert inventories.named_inventory == {'spam': {'py:module': item}}\n", "type": "function"}], "retrieved_count": 10, "cost_time": 1.2661468982696533}
{"question": "What is the relationship between Sphinx's Config class and the Project class in configuration inheritance?", "answer": null, "relative_code_list": null, "ground_truth": "The relationship between Sphinx's Config class and Project class in configuration inheritance is primarily one of data sharing and coordination rather than direct inheritance. Both classes work together to manage different aspects of the project's configuration and metadata.\n\nKey aspects of this relationship include:\n\n1. **Configuration Access**: The Project class has access to the Config object through the environment (`env.config`), allowing it to read configuration values that affect project behavior, such as source file suffixes and other project-specific settings.\n\n2. **Source File Management**: The Project class uses configuration information from the Config class to determine which files should be considered as source files for the documentation project. It relies on the `source_suffix` configuration to identify valid source file extensions.\n\n3. **Project Metadata**: While the Config class manages most configuration values, the Project class handles project-specific metadata such as the list of source files, their relationships, and project structure information.\n\n4. **Environment Integration**: Both classes are integrated through the BuildEnvironment, where the environment maintains references to both the config (`env.config`) and the project (`env.project`), allowing them to work together seamlessly.\n\n5. **Initialization Coordination**: During Sphinx initialization, the Config class is created first from the conf.py file, and then the Project class is created using configuration values from the Config class to set up the project structure.\n\n6. **Data Persistence**: The Project class can be serialized and restored as part of the environment, allowing project information to persist across builds, while the Config class is recreated from the conf.py file on each build.\n\nThis relationship ensures that project-specific information and general configuration settings work together to provide a complete picture of the documentation project's setup and requirements.", "score": null, "retrieved_content": [{"name": "Project", "docstring": "A project is the source code set of the Sphinx document(s).", "methods": ["__init__", "restore", "discover", "path2doc", "doc2path"], "attributes": [], "code_location": {"file": "project.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx", "start_line": 23, "end_line": 128}, "type": "class"}, {"name": "Config", "docstring": "Configuration file abstraction.\n\nThe Config object makes the values of all config options available as\nattributes.\n\nIt is exposed via the :py:class:`~sphinx.application.Sphinx`\\ ``.config``\nand :py:class:`sphinx.environment.BuildEnvironment`\\ ``.config`` attributes.\nFor example, to get the value of :confval:`language`, use either\n``app.config.language`` or ``env.config.language``.", "methods": ["__init__", "values", "overrides", "verbosity", "read", "convert_overrides", "pre_init_values", "init_values", "_report_override_warnings", "__repr__", "__setattr__", "__getattr__", "__getitem__", "__setitem__", "__delitem__", "__contains__", "__iter__", "add", "filter", "__getstate__", "__setstate__", "__init__"], "attributes": ["c_id_attributes", "c_paren_attributes", "c_extra_keywords"], "code_location": {"file": "config.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx", "start_line": 208, "end_line": 574}, "type": "class"}, {"name": "IntersphinxProject", "docstring": "", "methods": ["__init__", "record", "normalise"], "attributes": [], "code_location": {"file": "test_ext_intersphinx_cache.py", "path": "/data3/pwh/swebench-repos/sphinx/tests/test_extensions", "start_line": 79, "end_line": 120}, "type": "class"}, {"name": "_IntersphinxProject", "docstring": "", "methods": ["__init__", "__repr__", "__eq__", "__hash__", "__setattr__", "__delattr__"], "attributes": ["__slots__"], "code_location": {"file": "_shared.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/ext/intersphinx", "start_line": 44, "end_line": 111}, "type": "class"}, {"name": "__init__", "is_method": true, "class_name": "Config", "parameters": ["self", "config", "overrides"], "calls": ["Config.config_values.copy", "list", "raw_config.get", "raw_config.get", "dict", "self._overrides.keys", "self._overrides.pop", "isinstance", "name.partition", "self._overrides.pop", "extensions.split", "raw_config.setdefault"], "code_location": {"file": "config.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx", "start_line": 311, "end_line": 336}, "code_snippet": "    def __init__(\n        self,\n        config: dict[str, Any] | None = None,\n        overrides: dict[str, Any] | None = None,\n    ) -> None:\n        raw_config: dict[str, Any] = config or {}\n        self._overrides = dict(overrides) if overrides is not None else {}\n        self._options = Config.config_values.copy()\n        self._raw_config = raw_config\n\n        for name in list(self._overrides.keys()):\n            if '.' in name:\n                real_name, _, key = name.partition('.')\n                raw_config.setdefault(real_name, {})[key] = self._overrides.pop(name)\n\n        self.setup: _ExtensionSetupFunc | None = raw_config.get('setup')\n\n        if 'extensions' in self._overrides:\n            extensions = self._overrides.pop('extensions')\n            if isinstance(extensions, str):\n                raw_config['extensions'] = extensions.split(',')\n            else:\n                raw_config['extensions'] = extensions\n        self.extensions: list[str] = raw_config.get('extensions', [])\n\n        self._verbosity: int = 0  # updated in Sphinx.__init__()\n", "type": "function"}, {"name": "__init__", "is_method": true, "class_name": "IntersphinxProject", "parameters": ["self"], "calls": ["re.sub", "str", "re.sub", "posixpath.join"], "code_location": {"file": "test_ext_intersphinx_cache.py", "path": "/data3/pwh/swebench-repos/sphinx/tests/test_extensions", "start_line": 80, "end_line": 106}, "code_snippet": "    def __init__(\n        self,\n        *,\n        name: str = 'spam',\n        version: str | int = 1,\n        baseurl: str = '',\n        baseuri: str = '',\n        file: str | None = None,\n    ) -> None:\n        #: The project name.\n        self.name = name\n        #: The escaped project name.\n        self.safe_name = re.sub(r'\\\\s+', ' ', name)\n\n        #: The project version as a string.\n        self.version = version = str(version)\n        #: The escaped project version.\n        self.safe_version = re.sub(r'\\\\s+', ' ', version)\n\n        #: The project base URL (e.g., http://localhost:9341).\n        self.baseurl = baseurl\n        #: The project base URI, relative to *baseurl* (e.g., 'spam').\n        self.uri = baseuri\n        #: The project URL, as specified in :confval:`intersphinx_mapping`.\n        self.url = posixpath.join(baseurl, baseuri)\n        #: The project local file, if any.\n        self.file = file\n", "type": "function"}, {"name": "__init__", "is_method": true, "class_name": "FakeApplication", "parameters": ["self"], "calls": ["Path", "Path", "Config", "Project", "SphinxComponentRegistry"], "code_location": {"file": "__init__.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/ext/autosummary", "start_line": 163, "end_line": 170}, "code_snippet": "    def __init__(self) -> None:\n        self.doctreedir = Path()\n        self.events = None\n        self.extensions: dict[str, Extension] = {}\n        self.srcdir = Path()\n        self.config = Config()\n        self.project = Project('', {})\n        self.registry = SphinxComponentRegistry()\n", "type": "function"}, {"name": "Sphinx", "docstring": "The main application class and extensibility interface.\n\n:ivar srcdir: Directory containing source.\n:ivar confdir: Directory containing ``conf.py``.\n:ivar doctreedir: Directory for storing pickled doctrees.\n:ivar outdir: Directory for storing build documents.", "methods": ["__init__", "fresh_env_used", "phase", "_init_i18n", "_init_env", "_create_fresh_env", "_load_existing_env", "_post_init_env", "preload_builder", "create_builder", "_init_builder", "build", "setup_extension", "require_sphinx", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "disconnect", "emit", "emit_firstresult", "add_builder", "add_config_value", "add_event", "set_translator", "add_node", "add_enumerable_node", "add_directive", "add_role", "add_generic_role", "add_domain", "add_directive_to_domain", "add_role_to_domain", "add_index_to_domain", "add_object_type", "add_crossref_type", "add_transform", "add_post_transform", "add_js_file", "add_css_file", "add_latex_package", "add_lexer", "add_autodocumenter", "add_autodoc_attrgetter", "add_search_language", "add_source_suffix", "add_source_parser", "add_env_collector", "add_html_theme", "add_html_math_renderer", "add_message_catalog", "is_parallel_allowed", "set_html_assets_policy"], "attributes": ["srcdir", "confdir", "outdir", "doctreedir"], "code_location": {"file": "application.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx", "start_line": 142, "end_line": 1822}, "type": "class"}, {"name": "__init__", "is_method": true, "class_name": "_Opt", "parameters": ["self", "default", "rebuild", "valid_types", "description"], "calls": ["__setattr__", "__setattr__", "__setattr__", "__setattr__", "super", "super", "super", "super"], "code_location": {"file": "config.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx", "start_line": 108, "end_line": 126}, "code_snippet": "    def __init__(\n        self,\n        default: Any,\n        rebuild: _ConfigRebuild,\n        valid_types: _OptValidTypes,\n        description: str = '',\n    ) -> None:\n        \"\"\"Configuration option type for Sphinx.\n\n        The type is intended to be immutable; changing the field values\n        is an unsupported action.\n        No validation is performed on the values, though consumers will\n        likely expect them to be of the types advertised.\n        The old tuple-based interface will be removed in Sphinx 9.\n        \"\"\"\n        super().__setattr__('default', default)\n        super().__setattr__('rebuild', rebuild)\n        super().__setattr__('valid_types', valid_types)\n        super().__setattr__('description', description)\n", "type": "function"}, {"name": "__init__", "is_method": true, "class_name": "BuiltInTheme", "parameters": ["self", "name", "config"], "calls": ["__init__", "config.latex_docclass.get", "config.latex_docclass.get", "super", "self.docclass.startswith"], "code_location": {"file": "theming.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/builders/latex", "start_line": 50, "end_line": 68}, "code_snippet": "    def __init__(self, name: str, config: Config) -> None:\n        super().__init__(name)\n\n        if name == 'howto':\n            self.docclass = config.latex_docclass.get('howto', 'article')\n        else:\n            self.docclass = config.latex_docclass.get('manual', 'report')\n\n        if name in {'manual', 'howto'}:\n            self.wrapperclass = 'sphinx' + name\n        else:\n            self.wrapperclass = name\n\n        # we assume LaTeX class provides \\chapter command except in case\n        # of non-Japanese 'howto' case\n        if name == 'howto' and not self.docclass.startswith('j'):\n            self.toplevel_sectioning = 'section'\n        else:\n            self.toplevel_sectioning = 'chapter'\n", "type": "function"}], "retrieved_count": 10, "cost_time": 1.2990045547485352}
{"question": "Where does the data flow when Sphinx processes cross-references from role resolution through target lookup to link generation?", "answer": null, "relative_code_list": null, "ground_truth": "The data flow when Sphinx processes cross-references follows a structured sequence from role resolution through target lookup to link generation: 1) Role resolution phase begins when the parser encounters cross-reference roles (like `:py:func:`, `:ref:`, `:doc:`) in the markup, which are processed by the role system to create reference nodes in the document tree, 2) Reference node creation occurs where the role system creates docutils reference nodes containing the reference target, role type, and other metadata, storing this information in the document tree during the parsing phase, 3) Environment data collection happens during the reading phase where domains collect information about all documented objects and store it in the BuildEnvironment's domaindata, including object names, locations, and cross-reference metadata, 4) Target lookup phase occurs during the resolving phase where the cross-reference system searches the environment data to find matching target objects based on the reference information stored in the reference nodes, 5) Domain-specific resolution happens through each domain's resolve_xref method, which implements domain-specific logic for finding and validating target objects within that domain, 6) Cross-reference validation occurs where the system verifies that the target object exists and is accessible, handling cases where targets are missing or ambiguous, 7) Link generation phase begins where the resolved cross-reference information is used to generate appropriate links in the output format, with the builder determining the target URI and link format, 8) Output-specific processing happens where the writer generates the actual link markup (HTML, LaTeX, etc.) based on the resolved cross-reference data and the target format, 9) Error handling occurs throughout the process where broken references are handled gracefully with appropriate error messages and fallback behavior, 10) The entire data flow is coordinated through Sphinx's event system, with events like 'doctree-resolved' marking the completion of cross-reference resolution, 11) Caching mechanisms store resolved cross-reference data in the environment to support incremental builds and improve performance, 12) The data flow ensures that cross-references are accurately resolved and properly linked while maintaining the flexibility and extensibility of the cross-reference system.", "score": null, "retrieved_content": [{"name": "_resolve_xref_inner", "is_method": true, "class_name": "CDomain", "parameters": ["self", "env", "fromdocname", "builder", "typ", "target", "node", "contnode"], "calls": ["DefinitionParser", "node.get", "parent_symbol.find_declaration", "name.get_display_string", "parser.parse_xref_object", "root_symbol.direct_lookup", "make_refnode", "logger.warning", "logger.debug", "logger.debug", "logger.debug", "declaration.get_newest_id", "root_symbol.dump"], "code_location": {"file": "__init__.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/domains/c", "start_line": 876, "end_line": 925}, "code_snippet": "    def _resolve_xref_inner(\n        self,\n        env: BuildEnvironment,\n        fromdocname: str,\n        builder: Builder,\n        typ: str,\n        target: str,\n        node: pending_xref,\n        contnode: Element,\n    ) -> tuple[nodes.reference, str] | tuple[None, None]:\n        parser = DefinitionParser(target, location=node, config=env.config)\n        try:\n            name = parser.parse_xref_object()\n        except DefinitionError as e:\n            logger.warning(\n                'Unparseable C cross-reference: %r\\n%s', target, e, location=node\n            )\n            return None, None\n        parent_key: LookupKey | None = node.get('c:parent_key', None)\n        root_symbol = self.data['root_symbol']\n        if parent_key:\n            parent_symbol: Symbol = root_symbol.direct_lookup(parent_key)\n            if not parent_symbol:\n                logger.debug('Target: %s', target)\n                logger.debug('ParentKey: %s', parent_key)\n                logger.debug(root_symbol.dump(1))\n            assert parent_symbol  # should be there\n        else:\n            parent_symbol = root_symbol\n        s = parent_symbol.find_declaration(\n            name, typ, matchSelf=True, recurseInAnon=True\n        )\n        if s is None or s.declaration is None:\n            return None, None\n\n        # TODO: check role type vs. object type\n\n        declaration = s.declaration\n        display_name = name.get_display_string()\n        docname = s.docname\n        assert docname\n\n        return make_refnode(\n            builder,\n            fromdocname,\n            docname,\n            declaration.get_newest_id(),\n            contnode,\n            display_name,\n        ), declaration.objectType\n", "type": "function"}, {"name": "resolve_xref", "is_method": true, "class_name": "ReSTDomain", "parameters": ["self", "env", "fromdocname", "builder", "typ", "target", "node", "contnode"], "calls": ["self.objtypes_for_role", "self.objects.get", "make_refnode"], "code_location": {"file": "rst.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/domains", "start_line": 282, "end_line": 307}, "code_snippet": "    def resolve_xref(\n        self,\n        env: BuildEnvironment,\n        fromdocname: str,\n        builder: Builder,\n        typ: str,\n        target: str,\n        node: pending_xref,\n        contnode: Element,\n    ) -> nodes.reference | None:\n        objtypes = self.objtypes_for_role(typ)\n        if not objtypes:\n            return None\n        for objtype in objtypes:\n            result = self.objects.get((objtype, target))\n            if result:\n                todocname, node_id = result\n                return make_refnode(\n                    builder,\n                    fromdocname,\n                    todocname,\n                    node_id,\n                    contnode,\n                    f'{target} {objtype}',\n                )\n        return None\n", "type": "function"}, {"name": "_resolve_pending_any_xref", "is_method": true, "class_name": "ReferencesResolver", "parameters": ["self"], "calls": ["domains.standard_domain.resolve_xref", "domains.standard_domain.resolve_any_xref", "domains.sorted", "results.append", "len", "join", "__", "logger.warning", "res_role.partition", "isinstance", "get", "extend", "domain.resolve_any_xref", "starmap", "len", "res_role.replace", "domain.resolve_xref", "isinstance", "results.append", "len"], "code_location": {"file": "__init__.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/transforms/post_transforms", "start_line": 187, "end_line": 248}, "code_snippet": "    def _resolve_pending_any_xref(\n        self,\n        *,\n        node: addnodes.pending_xref,\n        contnode: Element,\n        ref_doc: str,\n        target: str,\n    ) -> nodes.reference | None:\n        \"\"\"Resolve reference generated by the \"any\" role.\"\"\"\n        env = self.env\n        builder = self.env._app.builder\n        domains = env.domains\n\n        results: list[tuple[str, nodes.reference]] = []\n        # first, try resolving as :doc:\n        doc_ref = domains.standard_domain.resolve_xref(\n            env, ref_doc, builder, 'doc', target, node, contnode\n        )\n        if doc_ref:\n            results.append(('doc', doc_ref))\n        # next, do the standard domain (makes this a priority)\n        results += domains.standard_domain.resolve_any_xref(\n            env, ref_doc, builder, target, node, contnode\n        )\n        for domain in domains.sorted():\n            if domain.name == 'std':\n                continue  # we did this one already\n            try:\n                results += domain.resolve_any_xref(\n                    env, ref_doc, builder, target, node, contnode\n                )\n            except NotImplementedError:\n                # the domain doesn't yet support the new interface\n                # we have to manually collect possible references (SLOW)\n                for role in domain.roles:\n                    res = domain.resolve_xref(\n                        env, ref_doc, builder, role, target, node, contnode\n                    )\n                    if res and len(res) > 0 and isinstance(res[0], nodes.Element):\n                        results.append((f'{domain.name}:{role}', res))\n        # now, see how many matches we got...\n        if not results:\n            return None\n        if len(results) > 1:\n            candidates = ' or '.join(starmap(self._stringify, results))\n            msg = __(\n                \"more than one target found for 'any' cross-reference %r: could be %s\"\n            )\n            logger.warning(\n                msg, target, candidates, location=node, type='ref', subtype='any'\n            )\n        res_role, new_node = results[0]\n        # Override \"any\" class with the actual role type to get the styling\n        # approximately correct.\n        res_domain = res_role.partition(':')[0]\n        if (\n            len(new_node) > 0\n            and isinstance(new_node[0], nodes.Element)\n            and new_node[0].get('classes')\n        ):\n            new_node[0]['classes'].extend((res_domain, res_role.replace(':', '-')))\n        return new_node\n", "type": "function"}, {"name": "XRefRole", "docstring": "A generic cross-referencing role.  To create a callable that can be used as\na role function, create an instance of this class.\n\nThe general features of this role are:\n\n* Automatic creation of a reference and a content node.\n* Optional separation of title and target with `title <target>`.\n* The implementation is a class rather than a function to make\n  customization easier.\n\nCustomization can be done in two ways:\n\n* Supplying constructor parameters:\n  * `fix_parens` to normalize parentheses (strip from target, and add to\n    title if configured)\n  * `lowercase` to lowercase the target\n  * `nodeclass` and `innernodeclass` select the node classes for\n    the reference and the content node\n\n* Subclassing and overwriting `process_link()` and/or `result_nodes()`.", "methods": ["__init__", "update_title_and_target", "run", "create_non_xref_node", "create_xref_node", "process_link", "result_nodes"], "attributes": [], "code_location": {"file": "roles.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx", "start_line": 44, "end_line": 180}, "type": "class"}, {"name": "make_xref", "is_method": true, "class_name": "Field", "parameters": ["self", "rolename", "domain", "target", "innernode", "contnode", "env", "inliner", "location"], "calls": ["role", "role", "nodes.inline", "addnodes.pending_xref", "process_field_xref", "innernode", "env.get_domain", "__", "logger.warning", "innernode", "contextlib.suppress", "get_node_line", "__", "env.get_domain"], "code_location": {"file": "docfields.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/util", "start_line": 81, "end_line": 122}, "code_snippet": "    def make_xref(\n        self,\n        rolename: str,\n        domain: str,\n        target: str,\n        innernode: type[TextlikeNode] = addnodes.literal_emphasis,\n        contnode: Node | None = None,\n        env: BuildEnvironment | None = None,\n        inliner: Inliner | None = None,\n        location: Element | None = None,\n    ) -> Node:\n        # note: for backwards compatibility env is last, but not optional\n        assert env is not None\n        assert (inliner is None) == (location is None), (inliner, location)\n        if not rolename:\n            return contnode or innernode(target, target)  # type: ignore[call-arg]\n        # The domain is passed from DocFieldTransformer. So it surely exists.\n        # So we don't need to take care the env.get_domain() raises an exception.\n        role = env.get_domain(domain).role(rolename)\n        if role is None or inliner is None:\n            if role is None and inliner is not None:\n                msg = __(\n                    'Problem in %s domain: field is supposed '\n                    \"to use role '%s', but that role is not in the domain.\"\n                )\n                logger.warning(__(msg), domain, rolename, location=location)\n            refnode = addnodes.pending_xref(\n                '',\n                refdomain=domain,\n                refexplicit=False,\n                reftype=rolename,\n                reftarget=target,\n            )\n            refnode += contnode or innernode(target, target)  # type: ignore[call-arg]\n            env.get_domain(domain).process_field_xref(refnode)\n            return refnode\n        lineno = -1\n        if location is not None:\n            with contextlib.suppress(ValueError):\n                lineno = get_node_line(location)\n        ns, _messages = role(rolename, target, target, lineno, inliner, {}, [])\n        return nodes.inline(target, '', *ns)\n", "type": "function"}, {"name": "process_link", "is_method": true, "class_name": "JSXRefRole", "parameters": ["self", "env", "refnode", "has_explicit_title", "title", "target"], "calls": ["env.ref_context.get", "env.ref_context.get", "title.lstrip", "target.lstrip", "title.rfind"], "code_location": {"file": "javascript.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/domains", "start_line": 387, "end_line": 409}, "code_snippet": "    def process_link(\n        self,\n        env: BuildEnvironment,\n        refnode: Element,\n        has_explicit_title: bool,\n        title: str,\n        target: str,\n    ) -> tuple[str, str]:\n        # basically what sphinx.domains.python.PyXRefRole does\n        refnode['js:object'] = env.ref_context.get('js:object')\n        refnode['js:module'] = env.ref_context.get('js:module')\n        if not has_explicit_title:\n            title = title.lstrip('.')\n            target = target.lstrip('~')\n            if title[0:1] == '~':\n                title = title[1:]\n                dot = title.rfind('.')\n                if dot != -1:\n                    title = title[dot + 1 :]\n        if target[0:1] == '.':\n            target = target[1:]\n            refnode['refspecific'] = True\n        return title, target\n", "type": "function"}, {"name": "make_xrefs", "is_method": true, "class_name": "Field", "parameters": ["self", "rolename", "domain", "target", "innernode", "contnode", "env", "inliner", "location"], "calls": ["self.make_xref"], "code_location": {"file": "docfields.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/util", "start_line": 124, "end_line": 139}, "code_snippet": "    def make_xrefs(\n        self,\n        rolename: str,\n        domain: str,\n        target: str,\n        innernode: type[TextlikeNode] = addnodes.literal_emphasis,\n        contnode: Node | None = None,\n        env: BuildEnvironment | None = None,\n        inliner: Inliner | None = None,\n        location: Element | None = None,\n    ) -> list[Node]:\n        return [\n            self.make_xref(\n                rolename, domain, target, innernode, contnode, env, inliner, location\n            )\n        ]\n", "type": "function"}, {"name": "_resolve_xref_inner", "is_method": true, "class_name": "CPPDomain", "parameters": ["self", "env", "fromdocname", "builder", "typ", "target", "node", "contnode"], "calls": ["DefinitionParser", "node.get", "typ.removeprefix", "parser.parse_xref_object", "root_symbol.direct_lookup", "isinstance", "parent_symbol.find_name", "isinstance", "parent_symbol.find_declaration", "str", "self._check_type", "logger.warning", "s.get_full_nested_name", "lstrip", "decl.get_display_string", "astext", "nodes.Text", "make_refnode", "logger.warning", "logger.debug", "logger.debug", "logger.debug", "txt_name.startswith", "NoUri", "s.get_full_nested_name", "declaration.get_newest_id", "DefinitionParser", "root_symbol.dump", "len", "full_nested_name.get_display_string", "contnode.pop", "node.get", "parser2.parse_xref_object", "NoUri", "title.endswith", "title.endswith", "display_name.endswith", "display_name.endswith", "str", "display_name.endswith", "display_name.endswith", "title.removesuffix"], "code_location": {"file": "__init__.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/domains/cpp", "start_line": 1070, "end_line": 1240}, "code_snippet": "    def _resolve_xref_inner(\n        self,\n        env: BuildEnvironment,\n        fromdocname: str,\n        builder: Builder,\n        typ: str,\n        target: str,\n        node: pending_xref,\n        contnode: Element,\n    ) -> tuple[nodes.reference, str] | tuple[None, None]:\n        # add parens again for those that could be functions\n        if typ in {'any', 'func'}:\n            target += '()'\n        parser = DefinitionParser(target, location=node, config=env.config)\n        try:\n            ast, is_shorthand = parser.parse_xref_object()\n        except DefinitionError as e:\n            if typ in {'any', 'func'}:\n                # hax on top of the paren hax to try to get correct errors\n                parser2 = DefinitionParser(\n                    target[:-2], location=node, config=env.config\n                )\n                try:\n                    parser2.parse_xref_object()\n                except DefinitionError as e2:\n                    target = target[:-2]\n                    ex = e2\n                else:\n                    # strange, that we don't get the error now, use the original\n                    ex = e\n            else:\n                ex = e\n\n            logger.warning(\n                'Unparseable C++ cross-reference: %r\\n%s', target, ex, location=node\n            )\n            return None, None\n        parent_key: LookupKey | None = node.get('cpp:parent_key', None)\n        root_symbol = self.data['root_symbol']\n        if parent_key:\n            parent_symbol: Symbol = root_symbol.direct_lookup(parent_key)\n            if not parent_symbol:\n                logger.debug('Target: %s', target)\n                logger.debug('ParentKey: %s', parent_key.data)\n                logger.debug(root_symbol.dump(1))\n            assert parent_symbol  # should be there\n        else:\n            parent_symbol = root_symbol\n\n        if is_shorthand:\n            assert isinstance(ast, ASTNamespace)\n            ns = ast\n            name = ns.nestedName\n            if ns.templatePrefix:\n                template_decls = ns.templatePrefix.templates\n            else:\n                template_decls = []\n            # let's be conservative with the sibling lookup for now\n            search_in_siblings = (not name.rooted) and len(name.names) == 1\n            symbols, fail_reason = parent_symbol.find_name(\n                name,\n                template_decls,\n                typ,\n                templateShorthand=True,\n                matchSelf=True,\n                recurseInAnon=True,\n                searchInSiblings=search_in_siblings,\n            )\n            if symbols is None:\n                if typ == 'identifier':\n                    if fail_reason == 'templateParamInQualified':\n                        # this is an xref we created as part of a signature,\n                        # so don't warn for names nested in template parameters\n                        raise NoUri(str(name), typ)\n                s = None\n            else:\n                # just refer to the arbitrarily first symbol\n                s = symbols[0]\n        else:\n            assert isinstance(ast, ASTDeclaration)\n            decl = ast\n            name = decl.name\n            s = parent_symbol.find_declaration(\n                decl, typ, templateShorthand=True, matchSelf=True, recurseInAnon=True\n            )\n        if s is None or s.declaration is None:\n            txt_name = str(name)\n            if txt_name.startswith('std::') or txt_name == 'std':\n                raise NoUri(txt_name, typ)\n            return None, None\n\n        typ = typ.removeprefix('cpp:')\n        decl_typ = s.declaration.objectType\n\n        if not self._check_type(typ, decl_typ):\n            logger.warning(\n                'cpp:%s targets a %s (%s).',\n                typ,\n                s.declaration.objectType,\n                s.get_full_nested_name(),\n                location=node,\n            )\n\n        declaration = s.declaration\n        if is_shorthand:\n            full_nested_name = s.get_full_nested_name()\n            display_name = full_nested_name.get_display_string().lstrip(':')\n        else:\n            display_name = decl.get_display_string()\n        docname = s.docname\n        assert docname\n\n        # the non-identifier refs are cross-references, which should be processed:\n        # - fix parenthesis due to operator() and add_function_parentheses\n        if typ != 'identifier':\n            title = contnode.pop(0).astext()\n            # If it's operator(), we need to add '()' if explicit function parens\n            # are requested. Then the Sphinx machinery will add another pair.\n            # Also, if it's an 'any' ref that resolves to a function, we need to add\n            # parens as well.\n            # However, if it's a non-shorthand function ref, for a function that\n            # takes no arguments, then we may need to add parens again as well.\n            add_paren = 0\n            if (\n                not node.get('refexplicit', False)\n                and declaration.objectType == 'function'\n            ):\n                if is_shorthand:\n                    # this is just the normal haxing for 'any' roles\n                    if env.config.add_function_parentheses and typ == 'any':\n                        add_paren += 1\n                    # and now this stuff for operator()\n                    if (\n                        env.config.add_function_parentheses\n                        and typ == 'func'\n                        and title.endswith('operator()')\n                    ):\n                        add_paren += 1\n                    if (\n                        typ in {'any', 'func'}\n                        and title.endswith('operator')\n                        and display_name.endswith('operator()')\n                    ):\n                        add_paren += 1\n                else:\n                    # our job here is to essentially nullify add_function_parentheses\n                    if env.config.add_function_parentheses:\n                        if typ == 'any' and display_name.endswith('()'):\n                            add_paren += 1\n                        elif typ == 'func':\n                            if not display_name.endswith('()'):\n                                title = title.removesuffix('()')\n                    else:\n                        if display_name.endswith('()'):\n                            add_paren += 1\n            if add_paren > 0:\n                title += '()' * add_paren\n            # and reconstruct the title again\n            contnode += nodes.Text(title)\n        res = (\n            make_refnode(\n                builder,\n                fromdocname,\n                docname,\n                declaration.get_newest_id(),\n                contnode,\n                display_name,\n            ),\n            declaration.objectType,\n        )\n        return res\n", "type": "function"}, {"name": "resolve_xref", "is_method": true, "class_name": "StandardDomain", "parameters": ["self", "env", "fromdocname", "builder", "typ", "target", "node", "contnode"], "calls": ["resolver"], "code_location": {"file": "__init__.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/domains/std", "start_line": 1033, "end_line": 1058}, "code_snippet": "    def resolve_xref(\n        self,\n        env: BuildEnvironment,\n        fromdocname: str,\n        builder: Builder,\n        typ: str,\n        target: str,\n        node: pending_xref,\n        contnode: Element,\n    ) -> nodes.reference | None:\n        if typ == 'ref':\n            resolver = self._resolve_ref_xref\n        elif typ == 'numref':\n            resolver = self._resolve_numref_xref  # type: ignore[assignment]\n        elif typ == 'keyword':\n            resolver = self._resolve_keyword_xref\n        elif typ == 'doc':\n            resolver = self._resolve_doc_xref\n        elif typ == 'option':\n            resolver = self._resolve_option_xref\n        elif typ == 'term':\n            resolver = self._resolve_term_xref\n        else:\n            resolver = self._resolve_obj_xref\n\n        return resolver(env, fromdocname, builder, typ, target, node, contnode)\n", "type": "function"}, {"name": "test_xml_role_xref", "is_method": false, "class_name": null, "parameters": ["app"], "calls": ["pytest.mark.sphinx", "pytest.mark.test_params", "app.build", "etree_parse", "et.findall", "sec1.findall", "assert_elem", "sec1.findall", "sec1_1.findall", "assert_elem", "sec2.findall", "assert_elem", "assert_elem", "assert_elem", "assert_elem", "assert_elem", "assert_elem", "assert_elem"], "code_location": {"file": "test_intl.py", "path": "/data3/pwh/swebench-repos/sphinx/tests/test_intl", "start_line": 1336, "end_line": 1407}, "code_snippet": "def test_xml_role_xref(app):\n    app.build()\n    # --- role xref: regression test for\n    # https://github.com/sphinx-doc/sphinx/issues/1090,\n    # https://github.com/sphinx-doc/sphinx/issues/1193\n    et = etree_parse(app.outdir / 'role_xref.xml')\n    sec1, sec2 = et.findall('section')\n\n    (para1,) = sec1.findall('paragraph')\n    assert_elem(\n        para1,\n        [\n            'LINK TO',\n            \"I18N ROCK'N ROLE XREF\",\n            ',',\n            'CONTENTS',\n            ',',\n            'SOME NEW TERM',\n            '.',\n        ],\n        ['i18n-role-xref', 'index', 'glossary_terms#term-Some-term'],\n    )\n\n    (sec1_1,) = sec1.findall('section')\n    (title,) = sec1_1.findall('title')\n    assert_elem(\n        title,\n        [\n            'LINK TO',\n            \"I18N ROCK'N ROLE XREF\",\n            ',',\n            'CONTENTS',\n            ',',\n            'SOME NEW TERM',\n            '.',\n        ],\n        ['i18n-role-xref', 'index', 'glossary_terms#term-Some-term'],\n    )\n\n    para2 = sec2.findall('paragraph')\n    assert_elem(\n        para2[0],\n        ['LINK TO', 'SOME OTHER NEW TERM', 'AND', 'SOME NEW TERM', '.'],\n        ['glossary_terms#term-Some-other-term', 'glossary_terms#term-Some-term'],\n    )\n    assert_elem(\n        para2[1],\n        ['LINK TO', 'LABEL', 'AND', 'SAME TYPE LINKS', 'AND', 'SAME TYPE LINKS', '.'],\n        ['i18n-role-xref', 'same-type-links', 'same-type-links'],\n    )\n    assert_elem(\n        para2[2],\n        ['LINK TO', 'I18N WITH GLOSSARY TERMS', 'AND', 'CONTENTS', '.'],\n        ['glossary_terms', 'index'],\n    )\n    assert_elem(\n        para2[3],\n        ['LINK TO', '--module', 'AND', '-m', '.'],\n        ['cmdoption-module', 'cmdoption-m'],\n    )\n    assert_elem(\n        para2[4],\n        ['LINK TO', 'env2', 'AND', 'env1', '.'],\n        ['envvar-env2', 'envvar-env1'],\n    )\n    # TODO: how do I link token role to productionlist?\n    assert_elem(para2[5], ['LINK TO', 'token2', 'AND', 'token1', '.'], [])\n    assert_elem(\n        para2[6],\n        ['LINK TO', 'same-type-links', 'AND', 'i18n-role-xref', '.'],\n        ['same-type-links', 'i18n-role-xref'],\n    )\n", "type": "function"}], "retrieved_count": 10, "cost_time": 1.2739911079406738}
{"question": "Why does Sphinx implement an incremental build system for large documentation projects?", "answer": null, "relative_code_list": null, "ground_truth": "Sphinx implements an incremental build system for large documentation projects to address the performance and efficiency challenges that arise when dealing with extensive documentation sets. This approach provides significant benefits for both development workflow and build performance.\n\nKey reasons for implementing incremental builds include:\n\n1. **Build Time Optimization**: Large documentation projects can contain thousands of files, and rebuilding everything from scratch would be prohibitively time-consuming. Incremental builds only process files that have changed since the last build, dramatically reducing build times.\n\n2. **Development Efficiency**: During active documentation development, developers often make small changes to individual files. Incremental builds allow for rapid feedback by only rebuilding the affected parts, enabling faster iteration cycles.\n\n3. **Resource Conservation**: Full rebuilds of large projects consume significant computational resources (CPU, memory, disk I/O). Incremental builds minimize resource usage by avoiding unnecessary processing of unchanged files.\n\n4. **Dependency Tracking**: The incremental build system tracks dependencies between documents, ensuring that when one document changes, all documents that depend on it are also rebuilt. This maintains consistency while still avoiding unnecessary work.\n\n5. **Environment Persistence**: Sphinx caches the build environment (including cross-references, metadata, and document relationships) between builds, allowing the system to skip expensive parsing and analysis phases for unchanged files.\n\n6. **Scalability**: As documentation projects grow in size, the benefits of incremental builds become more pronounced. The system scales better with project size compared to full rebuilds.\n\n7. **User Experience**: Faster build times improve the overall user experience for documentation maintainers, making the development process more efficient and less frustrating.\n\n8. **CI/CD Integration**: Incremental builds are particularly valuable in continuous integration environments where builds need to be fast and efficient to provide timely feedback.\n\nThe incremental build system is a key feature that makes Sphinx practical for large-scale documentation projects and contributes to its widespread adoption in the documentation community.", "score": null, "retrieved_content": [{"name": "build", "is_method": true, "class_name": "SphinxTestApp", "parameters": ["self", "force_all", "filenames"], "calls": ["self.env._pickled_doctree_cache.clear", "build", "super"], "code_location": {"file": "util.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/testing", "start_line": 235, "end_line": 237}, "code_snippet": "    def build(self, force_all: bool = False, filenames: Sequence[Path] = ()) -> None:\n        self.env._pickled_doctree_cache.clear()\n        super().build(force_all, filenames)\n", "type": "function"}, {"name": "_has_doc_changed", "is_method": false, "class_name": null, "parameters": ["docname"], "calls": ["_last_modified_time", "logger.debug", "doctree_path.is_file", "logger.debug", "logger.debug", "_format_rfc3339_microseconds", "_format_rfc3339_microseconds", "dep_path.is_file", "logger.debug", "_last_modified_time", "logger.debug", "_format_rfc3339_microseconds", "_format_rfc3339_microseconds"], "code_location": {"file": "__init__.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/environment", "start_line": 838, "end_line": 900}, "code_snippet": "def _has_doc_changed(\n    docname: str,\n    *,\n    filename: Path,\n    reread_always: Set[str],\n    doctreedir: Path,\n    all_docs: Mapping[str, int],\n    dependencies: Mapping[str, Set[Path]],\n) -> bool:\n    # check the \"reread always\" list\n    if docname in reread_always:\n        logger.debug('[build target] changed %r: re-read forced', docname)\n        return True\n\n    # if the doctree file is not there, rebuild\n    doctree_path = doctreedir / f'{docname}.doctree'\n    if not doctree_path.is_file():\n        logger.debug('[build target] changed %r: doctree file does not exist', docname)\n        return True\n\n    # check the mtime of the document\n    mtime = all_docs[docname]\n    new_mtime = _last_modified_time(filename)\n    if new_mtime > mtime:\n        logger.debug(\n            '[build target] changed: %r is outdated (%s -> %s)',\n            docname,\n            _format_rfc3339_microseconds(mtime),\n            _format_rfc3339_microseconds(new_mtime),\n        )\n        return True\n\n    # finally, check the mtime of dependencies\n    if docname not in dependencies:\n        return False\n    for dep_path in dependencies[docname]:\n        try:\n            dep_path_is_file = dep_path.is_file()\n        except OSError:\n            return True  # give it another chance\n        if not dep_path_is_file:\n            logger.debug(\n                '[build target] changed: %r is missing dependency %r',\n                docname,\n                dep_path,\n            )\n            return True\n\n        try:\n            dep_mtime = _last_modified_time(dep_path)\n        except OSError:\n            return True  # give it another chance\n        if dep_mtime > mtime:\n            logger.debug(\n                '[build target] changed: %r is outdated due to dependency %r (%s -> %s)',\n                docname,\n                dep_path,\n                _format_rfc3339_microseconds(mtime),\n                _format_rfc3339_microseconds(dep_mtime),\n            )\n            return True\n\n    return False\n", "type": "function"}, {"name": "test_incremental_reading", "is_method": false, "class_name": null, "parameters": ["app"], "calls": ["pytest.mark.sphinx", "app.builder.read", "write_text", "unlink", "app.builder.read", "set", "set", "sorted", "set"], "code_location": {"file": "test_incremental_reading.py", "path": "/data3/pwh/swebench-repos/sphinx/tests/test_builders", "start_line": 20, "end_line": 39}, "code_snippet": "def test_incremental_reading(app: SphinxTestApp) -> None:\n    # first reading\n    updated = app.builder.read()\n    assert set(updated) == app.env.found_docs == set(app.env.all_docs)\n    assert updated == sorted(updated)  # sorted by alphanumeric\n\n    # test if exclude_patterns works ok\n    assert 'subdir/excluded' not in app.env.found_docs\n\n    # before second reading, add, modify and remove source files\n    (app.srcdir / 'new.txt').write_text('New file\\n========\\n', encoding='utf8')\n    app.env.all_docs['index'] = 0  # mark as modified\n    (app.srcdir / 'autodoc.txt').unlink()\n\n    # second reading\n    updated = app.builder.read()\n\n    assert set(updated) == {'index', 'new'}\n    assert 'autodoc' not in app.env.all_docs\n    assert 'autodoc' not in app.env.found_docs\n", "type": "function"}, {"name": "test_incremental_reading_for_missing_files", "is_method": false, "class_name": null, "parameters": ["app"], "calls": ["pytest.mark.sphinx", "app.builder.read", "app.builder.read", "sys.modules.pop", "set", "set", "set"], "code_location": {"file": "test_incremental_reading.py", "path": "/data3/pwh/swebench-repos/sphinx/tests/test_builders", "start_line": 47, "end_line": 59}, "code_snippet": "def test_incremental_reading_for_missing_files(app: SphinxTestApp) -> None:\n    # first reading\n    updated = app.builder.read()\n    assert set(updated) == app.env.found_docs == set(app.env.all_docs)\n\n    # second reading\n    updated = app.builder.read()\n\n    # \"index\" is listed up to updated because it contains references\n    # to nonexisting downloadable or image files\n    assert set(updated) == {'index'}\n\n    sys.modules.pop('autodoc_fodder', None)\n", "type": "function"}, {"name": "build", "is_method": true, "class_name": "Sphinx", "parameters": ["self", "force_all", "filenames"], "calls": ["self.builder.cleanup", "self.events.emit", "logger.info", "logger.info", "self.builder.build_all", "envfile.is_file", "self.events.emit", "logger.info", "logger.info", "logger.info", "logger.info", "self.builder.build_specific", "self.builder.build_update", "envfile.unlink", "bold", "bold", "__", "bold", "__", "bold", "relpath", "__", "__", "__", "__", "__", "__"], "code_location": {"file": "application.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx", "start_line": 428, "end_line": 487}, "code_snippet": "    def build(self, force_all: bool = False, filenames: Sequence[Path] = ()) -> None:\n        self.builder.phase = BuildPhase.READING\n        try:\n            if force_all:\n                self.builder.build_all()\n            elif filenames:\n                self.builder.build_specific(filenames)\n            else:\n                self.builder.build_update()\n\n            self.events.emit('build-finished', None)\n        except Exception as err:\n            # delete the saved env to force a fresh build next time\n            envfile = self.doctreedir / ENV_PICKLE_FILENAME\n            if envfile.is_file():\n                envfile.unlink()\n            self.events.emit('build-finished', err)\n            raise\n\n        if self._warncount == 0:\n            if self.statuscode != 0:\n                logger.info(bold(__('build finished with problems.')))\n            else:\n                logger.info(bold(__('build succeeded.')))\n        elif self._warncount == 1:\n            if self._fail_on_warnings:\n                self.statuscode = 1\n                msg = __(\n                    'build finished with problems, 1 warning '\n                    '(with warnings treated as errors).'\n                )\n            elif self.statuscode != 0:\n                msg = __('build finished with problems, 1 warning.')\n            else:\n                msg = __('build succeeded, 1 warning.')\n            logger.info(bold(msg))\n        else:\n            if self._fail_on_warnings:\n                self.statuscode = 1\n                msg = __(\n                    'build finished with problems, %s warnings '\n                    '(with warnings treated as errors).'\n                )\n            elif self.statuscode != 0:\n                msg = __('build finished with problems, %s warnings.')\n            else:\n                msg = __('build succeeded, %s warnings.')\n            logger.info(bold(msg), self._warncount)\n\n        if self.statuscode == 0 and self.builder.epilog:\n            logger.info('')\n            logger.info(\n                self.builder.epilog,\n                {\n                    'outdir': relpath(self.outdir),\n                    'project': self.config.project,\n                },\n            )\n\n        self.builder.cleanup()\n", "type": "function"}, {"name": "SphinxTestAppWrapperForSkipBuilding", "docstring": "A wrapper for SphinxTestApp.\n\nThis class is used to speed up the test by skipping ``app.build()``\nif it has already been built and there are any output files.", "methods": ["build"], "attributes": [], "code_location": {"file": "util.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/testing", "start_line": 240, "end_line": 250}, "type": "class"}, {"name": "Sphinx", "docstring": "The main application class and extensibility interface.\n\n:ivar srcdir: Directory containing source.\n:ivar confdir: Directory containing ``conf.py``.\n:ivar doctreedir: Directory for storing pickled doctrees.\n:ivar outdir: Directory for storing build documents.", "methods": ["__init__", "fresh_env_used", "phase", "_init_i18n", "_init_env", "_create_fresh_env", "_load_existing_env", "_post_init_env", "preload_builder", "create_builder", "_init_builder", "build", "setup_extension", "require_sphinx", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "disconnect", "emit", "emit_firstresult", "add_builder", "add_config_value", "add_event", "set_translator", "add_node", "add_enumerable_node", "add_directive", "add_role", "add_generic_role", "add_domain", "add_directive_to_domain", "add_role_to_domain", "add_index_to_domain", "add_object_type", "add_crossref_type", "add_transform", "add_post_transform", "add_js_file", "add_css_file", "add_latex_package", "add_lexer", "add_autodocumenter", "add_autodoc_attrgetter", "add_search_language", "add_source_suffix", "add_source_parser", "add_env_collector", "add_html_theme", "add_html_math_renderer", "add_message_catalog", "is_parallel_allowed", "set_html_assets_policy"], "attributes": ["srcdir", "confdir", "outdir", "doctreedir"], "code_location": {"file": "application.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx", "start_line": 142, "end_line": 1822}, "type": "class"}, {"name": "build_update", "is_method": true, "class_name": "Builder", "parameters": ["self"], "calls": ["self.compile_update_catalogs", "self.get_outdated_docs", "isinstance", "self.build", "set", "self.build", "__", "len"], "code_location": {"file": "__init__.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/builders", "start_line": 372, "end_line": 386}, "code_snippet": "    def build_update(self) -> None:\n        \"\"\"Only rebuild what was changed or added since last build.\"\"\"\n        self.compile_update_catalogs()\n\n        to_build = self.get_outdated_docs()\n        if isinstance(to_build, str):\n            self.build(['__all__'], summary=to_build, method='update')\n        else:\n            to_build = set(to_build)\n            self.build(\n                to_build,\n                summary=__('targets for %d source files that are out of date')\n                % len(to_build),\n                method='update',\n            )\n", "type": "function"}, {"name": "__init__", "is_method": true, "class_name": "BuildEnvironment", "parameters": ["self", "app"], "calls": ["_get_env_version", "default_settings.copy", "defaultdict", "defaultdict", "set", "defaultdict", "set", "set", "FilenameUniqDict", "DownloadFiles", "_CurrentDocument", "_DomainsContainer._from_environment", "self.setup"], "code_location": {"file": "__init__.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/environment", "start_line": 114, "end_line": 239}, "code_snippet": "    def __init__(self, app: Sphinx) -> None:\n        self._app: Sphinx = app\n        self.doctreedir = app.doctreedir\n        self.srcdir = app.srcdir\n        self.config: Config = None  # type: ignore[assignment]\n        self.config_status: int = CONFIG_UNSET\n        self.config_status_extra: str = ''\n        self.events: EventManager = app.events\n        self.project: Project = app.project\n        self.version: Mapping[str, int] = _get_env_version(app.extensions)\n\n        # the method of doctree versioning; see set_versioning_method\n        self.versioning_condition: Literal[False] | Callable[[Node], bool] | None = None\n        self.versioning_compare: bool | None = None\n\n        # the docutils settings for building\n        self.settings: dict[str, Any] = default_settings.copy()\n        self.settings['env'] = self\n\n        # All \"docnames\" here are /-separated and relative and exclude\n        # the source suffix.\n\n        # docname -> time of reading (in integer microseconds)\n        # contains all read docnames\n        self.all_docs: dict[str, int] = {}\n        # docname -> set of dependent file\n        # names, relative to documentation root\n        self.dependencies: dict[str, set[_StrPath]] = defaultdict(set)\n        # docname -> set of included file\n        # docnames included from other documents\n        self.included: dict[str, set[str]] = defaultdict(set)\n        # docnames to re-read unconditionally on next build\n        self.reread_always: set[str] = set()\n\n        self._pickled_doctree_cache: dict[str, bytes] = {}\n        \"\"\"In-memory cache for reading pickled doctrees from disk.\n        docname -> pickled doctree\n\n        This cache is used in the ``get_doctree`` method to avoid reading the\n        doctree from disk multiple times.\n        \"\"\"\n\n        self._write_doc_doctree_cache: dict[str, nodes.document] = {}\n        \"\"\"In-memory cache for unpickling doctrees from disk.\n        docname -> doctree\n\n        Items are added in ``Builder.write_doctree``, during the read phase,\n        then used only in the ``get_and_resolve_doctree`` method.\n        \"\"\"\n\n        # File metadata\n        # docname -> dict of metadata items\n        self.metadata: dict[str, dict[str, Any]] = defaultdict(dict)\n\n        # TOC inventory\n        # docname -> title node\n        self.titles: dict[str, nodes.title] = {}\n        # docname -> title node; only different if\n        # set differently with title directive\n        self.longtitles: dict[str, nodes.title] = {}\n        # docname -> table of contents nodetree\n        self.tocs: dict[str, nodes.bullet_list] = {}\n        # docname -> number of real entries\n        self.toc_num_entries: dict[str, int] = {}\n\n        # used to determine when to show the TOC\n        # in a sidebar (don't show if it's only one item)\n        # docname -> dict of sectionid -> number\n        self.toc_secnumbers: dict[str, dict[str, tuple[int, ...]]] = {}\n        # docname -> dict of figtype -> dict of figureid -> number\n        self.toc_fignumbers: dict[str, dict[str, dict[str, tuple[int, ...]]]] = {}\n\n        # docname -> list of toctree includefiles\n        self.toctree_includes: dict[str, list[str]] = {}\n        # docname -> set of files (containing its TOCs) to rebuild too\n        self.files_to_rebuild: dict[str, set[str]] = {}\n        # docnames that have :glob: toctrees\n        self.glob_toctrees: set[str] = set()\n        # docnames that have :numbered: toctrees\n        self.numbered_toctrees: set[str] = set()\n\n        # domain-specific inventories, here to be pickled\n        # domainname -> domain-specific dict\n        self.domaindata: dict[str, dict[str, Any]] = {}\n\n        # these map absolute path -> (docnames, unique filename)\n        self.images: FilenameUniqDict = FilenameUniqDict()\n        # filename -> (set of docnames, destination)\n        self.dlfiles: DownloadFiles = DownloadFiles()\n\n        # the original URI for images\n        self.original_image_uri: dict[_StrPath, str] = {}\n\n        # temporary data storage while reading a document\n        self.current_document: _CurrentDocument = _CurrentDocument()\n        # context for cross-references (e.g. current module or class)\n        # this is similar to ``self.current_document``,\n        # but will for example be copied to attributes of \"any\" cross references\n        self.ref_context: dict[str, Any] = {}\n\n        # search index data\n\n        # docname -> title\n        self._search_index_titles: dict[str, str | None] = {}\n        # docname -> filename\n        self._search_index_filenames: dict[str, str] = {}\n        # stemmed words -> set(docname)\n        self._search_index_mapping: dict[str, set[str]] = {}\n        # stemmed words in titles -> set(docname)\n        self._search_index_title_mapping: dict[str, set[str]] = {}\n        # docname -> all titles in document\n        self._search_index_all_titles: dict[str, list[tuple[str, str | None]]] = {}\n        # docname -> list(index entry)\n        self._search_index_index_entries: dict[str, list[tuple[str, str, str]]] = {}\n        # objtype -> index\n        self._search_index_objtypes: dict[tuple[str, str], int] = {}\n        # objtype index -> (domain, type, objname (localized))\n        self._search_index_objnames: dict[int, tuple[str, str, str]] = {}\n\n        # all the registered domains, set by the application\n        self.domains: _DomainsContainer = _DomainsContainer._from_environment(\n            self, registry=app.registry\n        )\n\n        # set up environment\n        self.setup(app)\n", "type": "function"}, {"name": "build_main", "is_method": false, "class_name": null, "parameters": ["argv"], "calls": ["get_parser", "_parse_arguments", "_parse_confdir", "_parse_doctreedir", "_validate_filenames", "_validate_colour_support", "_parse_logging", "_parse_confoverrides", "patch_docutils", "docutils_namespace", "Sphinx", "app.build", "sphinx._cli.util.errors.handle_exception", "warnfp.close", "app.extensions.values"], "code_location": {"file": "build.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/cmd", "start_line": 395, "end_line": 452}, "code_snippet": "def build_main(argv: Sequence[str]) -> int:\n    \"\"\"Sphinx build \"main\" command-line entry.\"\"\"\n    parser = get_parser()\n    args = _parse_arguments(parser, argv)\n    args.confdir = _parse_confdir(args.noconfig, args.confdir, args.sourcedir)\n    args.doctreedir = _parse_doctreedir(args.doctreedir, args.outputdir)\n    _validate_filenames(parser, args.force_all, args.filenames)\n    _validate_colour_support(args.color)\n    args.status, args.warning, args.error, warnfp = _parse_logging(\n        parser, args.quiet, args.really_quiet, args.warnfile\n    )\n    args.confoverrides = _parse_confoverrides(\n        parser, args.define, args.htmldefine, args.nitpicky\n    )\n\n    app = None\n    try:\n        confdir = args.confdir or args.sourcedir\n        with patch_docutils(confdir), docutils_namespace():\n            app = Sphinx(\n                srcdir=args.sourcedir,\n                confdir=args.confdir,\n                outdir=args.outputdir,\n                doctreedir=args.doctreedir,\n                buildername=args.builder,\n                confoverrides=args.confoverrides,\n                status=args.status,\n                warning=args.warning,\n                freshenv=args.freshenv,\n                warningiserror=args.warningiserror,\n                tags=args.tags,\n                verbosity=args.verbosity,\n                parallel=args.jobs,\n                keep_going=False,\n                pdb=args.pdb,\n                exception_on_warning=args.exception_on_warning,\n            )\n            app.build(args.force_all, args.filenames)\n            return app.statuscode\n    except (Exception, KeyboardInterrupt) as exc:\n        if app is not None:\n            message_log: Sequence[str] = app.messagelog\n            extensions: Collection[Extension] = app.extensions.values()\n        else:\n            message_log = extensions = ()\n        sphinx._cli.util.errors.handle_exception(\n            exc,\n            stderr=args.error,\n            use_pdb=args.pdb,\n            print_traceback=args.verbosity or args.traceback,\n            message_log=message_log,\n            extensions=extensions,\n        )\n        return 2\n    finally:\n        if warnfp is not None:\n            # close the file descriptor for the warnings file opened by Sphinx\n            warnfp.close()\n", "type": "function"}], "retrieved_count": 10, "cost_time": 1.3192980289459229}
{"question": "What dependencies does Sphinx's extension system have on the core BuildEnvironment and Application classes?", "answer": null, "relative_code_list": null, "ground_truth": "Sphinx's extension system has significant dependencies on both the BuildEnvironment and Application (Sphinx) classes, as these provide the core infrastructure and APIs that extensions rely on to function properly.\n\nKey dependencies on the Application class include:\n\n1. **Event System Access**: Extensions depend on the application's event system to register callbacks for various build phases. The application provides the `events` attribute that extensions use to connect to events like 'config-inited', 'builder-inited', 'doctree-read', etc.\n\n2. **Configuration Access**: Extensions need access to the application's configuration through `app.config` to read project settings and extension-specific configuration values.\n\n3. **Component Registration**: Extensions use the application's registry (`app.registry`) to register new components like directives, roles, builders, and domains.\n\n4. **Extension Management**: The application manages the loading and initialization of extensions, providing the extension setup function with the application instance.\n\nKey dependencies on the BuildEnvironment class include:\n\n1. **Document State Access**: Extensions need access to the environment's document state information, including which documents have been read, their dependencies, and modification times.\n\n2. **Cross-Reference Data**: Extensions often need to access the environment's cross-reference data and metadata about documented objects to implement custom functionality.\n\n3. **Domain Data Access**: Extensions that work with domains need access to the environment's `domaindata` to store and retrieve domain-specific information.\n\n4. **Document Tree Access**: Extensions may need to access and modify document trees through the environment's document tree management methods.\n\n5. **Caching and Persistence**: Extensions can use the environment's caching mechanisms to store data that should persist across builds.\n\nThese dependencies ensure that extensions can integrate seamlessly with Sphinx's build process and access all the necessary information and functionality to implement their features.", "score": null, "retrieved_content": [{"name": "setup", "is_method": false, "class_name": null, "parameters": ["app"], "calls": ["app.add_env_collector"], "code_location": {"file": "dependencies.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/environment/collectors", "start_line": 53, "end_line": 60}, "code_snippet": "def setup(app: Sphinx) -> ExtensionMetadata:\n    app.add_env_collector(DependenciesCollector)\n\n    return {\n        'version': 'builtin',\n        'parallel_read_safe': True,\n        'parallel_write_safe': True,\n    }\n", "type": "function"}, {"name": "get_envversion", "is_method": true, "class_name": "SphinxComponentRegistry", "parameters": ["self", "app"], "calls": ["_get_env_version"], "code_location": {"file": "registry.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx", "start_line": 589, "end_line": 592}, "code_snippet": "    def get_envversion(self, app: Sphinx) -> Mapping[str, int]:\n        from sphinx.environment import _get_env_version\n\n        return _get_env_version(app.extensions)\n", "type": "function"}, {"name": "Sphinx", "docstring": "The main application class and extensibility interface.\n\n:ivar srcdir: Directory containing source.\n:ivar confdir: Directory containing ``conf.py``.\n:ivar doctreedir: Directory for storing pickled doctrees.\n:ivar outdir: Directory for storing build documents.", "methods": ["__init__", "fresh_env_used", "phase", "_init_i18n", "_init_env", "_create_fresh_env", "_load_existing_env", "_post_init_env", "preload_builder", "create_builder", "_init_builder", "build", "setup_extension", "require_sphinx", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "disconnect", "emit", "emit_firstresult", "add_builder", "add_config_value", "add_event", "set_translator", "add_node", "add_enumerable_node", "add_directive", "add_role", "add_generic_role", "add_domain", "add_directive_to_domain", "add_role_to_domain", "add_index_to_domain", "add_object_type", "add_crossref_type", "add_transform", "add_post_transform", "add_js_file", "add_css_file", "add_latex_package", "add_lexer", "add_autodocumenter", "add_autodoc_attrgetter", "add_search_language", "add_source_suffix", "add_source_parser", "add_env_collector", "add_html_theme", "add_html_math_renderer", "add_message_catalog", "is_parallel_allowed", "set_html_assets_policy"], "attributes": ["srcdir", "confdir", "outdir", "doctreedir"], "code_location": {"file": "application.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx", "start_line": 142, "end_line": 1822}, "type": "class"}, {"name": "DependenciesCollector", "docstring": "dependencies collector for sphinx.environment.", "methods": ["clear_doc", "merge_other", "process_doc"], "attributes": [], "code_location": {"file": "dependencies.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/environment/collectors", "start_line": 21, "end_line": 50}, "type": "class"}, {"name": "BuildEnvironment", "docstring": "The environment in which the ReST files are translated.\nStores an inventory of cross-file targets and provides doctree\ntransformations to resolve links to them.", "methods": ["__init__", "__getstate__", "__setstate__", "setup", "app", "app", "app", "_registry", "_tags", "_config_status", "_update_settings", "set_versioning_method", "clear_doc", "merge_info_from", "path2doc", "doc2path", "relfn2path", "found_docs", "find_files", "get_outdated_files", "check_dependents", "prepare_settings", "temp_data", "docname", "parser", "new_serialno", "note_dependency", "note_included", "note_reread", "get_domain", "get_doctree", "master_doctree", "get_and_resolve_doctree", "resolve_toctree", "resolve_references", "apply_post_transforms", "collect_relations", "check_consistency"], "attributes": ["srcdir", "doctreedir"], "code_location": {"file": "__init__.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/environment", "start_line": 100, "end_line": 812}, "type": "class"}, {"name": "setup", "is_method": false, "class_name": null, "parameters": ["app"], "calls": ["app.connect"], "code_location": {"file": "extension.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx", "start_line": 87, "end_line": 94}, "code_snippet": "def setup(app: Sphinx) -> ExtensionMetadata:\n    app.connect('config-inited', verify_needs_extensions, priority=800)\n\n    return {\n        'version': 'builtin',\n        'parallel_read_safe': True,\n        'parallel_write_safe': True,\n    }\n", "type": "function"}, {"name": "setup", "is_method": false, "class_name": null, "parameters": ["app"], "calls": ["app.add_env_collector", "app.add_env_collector"], "code_location": {"file": "asset.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/environment/collectors", "start_line": 177, "end_line": 185}, "code_snippet": "def setup(app: Sphinx) -> ExtensionMetadata:\n    app.add_env_collector(ImageCollector)\n    app.add_env_collector(DownloadFileCollector)\n\n    return {\n        'version': 'builtin',\n        'parallel_read_safe': True,\n        'parallel_write_safe': True,\n    }\n", "type": "function"}, {"name": "load_extension", "is_method": true, "class_name": "SphinxComponentRegistry", "parameters": ["self", "app", "extname"], "calls": ["logger.warning", "__", "prefixed_warnings", "getattr", "Extension", "__", "import_module", "logger.warning", "logger.verbose", "ExtensionError", "__", "setup", "isinstance", "logger.warning", "VersionRequirementError", "__", "__", "traceback.format_exc", "__", "__"], "code_location": {"file": "registry.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx", "start_line": 524, "end_line": 587}, "code_snippet": "    def load_extension(self, app: Sphinx, extname: str) -> None:\n        \"\"\"Load a Sphinx extension.\"\"\"\n        if extname in app.extensions:  # already loaded\n            return\n        if extname in EXTENSION_BLACKLIST:\n            logger.warning(\n                __(\n                    'the extension %r was already merged with Sphinx since '\n                    'version %s; this extension is ignored.'\n                ),\n                extname,\n                EXTENSION_BLACKLIST[extname],\n            )\n            return\n\n        # update loading context\n        prefix = __('while setting up extension %s:') % extname\n        with prefixed_warnings(prefix):\n            try:\n                mod = import_module(extname)\n            except ImportError as err:\n                logger.verbose(__('Original exception:\\n') + traceback.format_exc())\n                raise ExtensionError(\n                    __('Could not import extension %s') % extname, err\n                ) from err\n\n            setup: _ExtensionSetupFunc | None = getattr(mod, 'setup', None)\n            if setup is None:\n                logger.warning(\n                    __(\n                        'extension %r has no setup() function; is it really '\n                        'a Sphinx extension module?'\n                    ),\n                    extname,\n                )\n                metadata: ExtensionMetadata = {}\n            else:\n                try:\n                    metadata = setup(app)\n                except VersionRequirementError as err:\n                    # add the extension name to the version required\n                    raise VersionRequirementError(\n                        __(\n                            'The %s extension used by this project needs at least '\n                            'Sphinx v%s; it therefore cannot be built with this '\n                            'version.'\n                        )\n                        % (extname, err),\n                    ) from err\n\n            if metadata is None:\n                metadata = {}\n            elif not isinstance(metadata, dict):\n                logger.warning(\n                    __(\n                        'extension %r returned an unsupported object from '\n                        'its setup() function; it should return None or a '\n                        'metadata dictionary'\n                    ),\n                    extname,\n                )\n                metadata = {}\n\n            app.extensions[extname] = Extension(extname, mod, **metadata)\n", "type": "function"}, {"name": "EnvironmentCollector", "docstring": "An EnvironmentCollector is a specific data collector from each document.\n\nIt gathers data and stores :py:class:`BuildEnvironment\n<sphinx.environment.BuildEnvironment>` as a database.\nExamples of specific data would be images, download files, section titles, metadatas, index\nentries and toctrees, etc.\n\n.. note::\n\n    This class essentially wraps a sub-set of :ref:`Sphinx event callbacks <events>`.", "methods": ["enable", "disable", "clear_doc", "merge_other", "process_doc", "get_updated_docs", "get_outdated_docs"], "attributes": [], "code_location": {"file": "__init__.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/environment/collectors", "start_line": 16, "end_line": 102}, "type": "class"}, {"name": "_get_env_version", "is_method": false, "class_name": null, "parameters": ["extensions"], "calls": ["extensions.values", "ext.metadata.get"], "code_location": {"file": "__init__.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/environment", "start_line": 815, "end_line": 822}, "code_snippet": "def _get_env_version(extensions: Mapping[str, Extension]) -> Mapping[str, int]:\n    env_version = {\n        ext.name: ext_env_version\n        for ext in extensions.values()\n        if (ext_env_version := ext.metadata.get('env_version'))\n    }\n    env_version['sphinx'] = ENV_VERSION\n    return env_version\n", "type": "function"}], "retrieved_count": 10, "cost_time": 1.3403685092926025}
{"question": "Why does Sphinx's parallel document processing reduce memory usage and CPU utilization?", "answer": null, "relative_code_list": null, "ground_truth": "Sphinx's parallel document processing reduces memory usage and CPU utilization through several mechanisms that distribute the workload more efficiently across system resources. This approach provides better resource management compared to single-threaded processing.\n\nKey ways parallel processing reduces resource usage include:\n\n1. **Distributed Memory Load**: By distributing document processing across multiple processes, the memory load is spread out rather than concentrated in a single process. Each worker process handles a subset of documents, reducing peak memory usage in any single process.\n\n2. **Process Isolation**: Each worker process has its own memory space, allowing the operating system to manage memory more efficiently. When a process completes its work, its memory can be freed immediately.\n\n3. **CPU Load Balancing**: Parallel processing distributes CPU-intensive tasks across multiple cores, preventing any single core from becoming a bottleneck. This results in more efficient CPU utilization and better overall system performance.\n\n4. **Reduced Memory Fragmentation**: By processing documents in smaller chunks across multiple processes, memory fragmentation is reduced compared to processing all documents in a single large process.\n\n5. **Fault Tolerance**: If one worker process encounters memory issues or crashes, only that process is affected. The main process and other workers can continue processing, improving overall system stability.\n\n6. **Garbage Collection Efficiency**: Smaller processes have more efficient garbage collection, as the garbage collector can work on smaller memory spaces more effectively.\n\n7. **I/O Parallelization**: Multiple processes can perform I/O operations in parallel, reducing the time spent waiting for disk operations and improving overall throughput.\n\n8. **Scalable Resource Usage**: The system can scale resource usage based on the number of available CPU cores, making better use of modern multi-core systems without overwhelming any single resource.\n\nParallel processing is particularly effective at reducing resource usage for large projects where the overhead of process management is outweighed by the benefits of distributed processing.", "score": null, "retrieved_content": [{"name": "_read_parallel", "is_method": true, "class_name": "Builder", "parameters": ["self", "docnames", "nproc"], "calls": ["make_chunks", "status_iterator", "ParallelTasks", "tasks.join", "logger.info", "__", "len", "self.events.emit", "self.env.clear_doc", "pickle.dumps", "pickle.loads", "self.env.merge_info_from", "next", "tasks.add_task", "self.read_doc"], "code_location": {"file": "__init__.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/builders", "start_line": 592, "end_line": 629}, "code_snippet": "    def _read_parallel(self, docnames: list[str], nproc: int) -> None:\n        chunks = make_chunks(docnames, nproc)\n\n        # create a status_iterator to step progressbar after reading a document\n        # (see: ``merge()`` function)\n        progress = status_iterator(\n            chunks,\n            __('reading sources... '),\n            'purple',\n            len(chunks),\n            self.config.verbosity,\n        )\n\n        # clear all outdated docs at once\n        for docname in docnames:\n            self.events.emit('env-purge-doc', self.env, docname)\n            self.env.clear_doc(docname)\n\n        def read_process(docs: list[str]) -> bytes:\n            self.env._app = self._app\n            for docname in docs:\n                self.read_doc(docname, _cache=False)\n            # allow pickling self to send it back\n            return pickle.dumps(self.env, pickle.HIGHEST_PROTOCOL)\n\n        def merge(docs: list[str], otherenv: bytes) -> None:\n            env = pickle.loads(otherenv)\n            self.env.merge_info_from(docs, env, self._app)\n\n            next(progress)\n\n        tasks = ParallelTasks(nproc)\n        for chunk in chunks:\n            tasks.add_task(read_process, chunk, merge)\n\n        # make sure all threads have finished\n        tasks.join()\n        logger.info('')\n", "type": "function"}, {"name": "_write_parallel", "is_method": true, "class_name": "Builder", "parameters": ["self", "docnames", "nproc"], "calls": ["_write_docname", "ParallelTasks", "make_chunks", "status_iterator", "tasks.join", "logger.info", "__", "len", "next", "tasks.add_task", "self.write_doc", "self.env.get_and_resolve_doctree", "self.write_doc_serialized", "arg.append"], "code_location": {"file": "__init__.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/builders", "start_line": 786, "end_line": 825}, "code_snippet": "    def _write_parallel(self, docnames: Sequence[str], nproc: int) -> None:\n        def write_process(docs: list[tuple[str, nodes.document]]) -> None:\n            self.phase = BuildPhase.WRITING\n            for docname, doctree in docs:\n                self.write_doc(docname, doctree)\n\n        # warm up caches/compile templates using the first document\n        firstname, docnames = docnames[0], docnames[1:]\n        _write_docname(firstname, env=self.env, builder=self, tags=self.tags)\n\n        tasks = ParallelTasks(nproc)\n        chunks = make_chunks(docnames, nproc)\n\n        # create a status_iterator to step progressbar after writing a document\n        # (see: ``on_chunk_done()`` function)\n        progress = status_iterator(\n            chunks,\n            __('writing output... '),\n            'darkgreen',\n            len(chunks),\n            self.config.verbosity,\n        )\n\n        def on_chunk_done(args: list[tuple[str, nodes.document]], result: None) -> None:\n            next(progress)\n\n        self.phase = BuildPhase.RESOLVING\n        for chunk in chunks:\n            arg = []\n            for docname in chunk:\n                doctree = self.env.get_and_resolve_doctree(\n                    docname, self, tags=self.tags\n                )\n                self.write_doc_serialized(docname, doctree)\n                arg.append((docname, doctree))\n            tasks.add_task(write_process, arg, on_chunk_done)\n\n        # make sure all threads have finished\n        tasks.join()\n        logger.info('')\n", "type": "function"}, {"name": "write_doc_serialized", "is_method": true, "class_name": "Builder", "parameters": ["self", "docname", "doctree"], "calls": [], "code_location": {"file": "__init__.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/builders", "start_line": 847, "end_line": 851}, "code_snippet": "    def write_doc_serialized(self, docname: str, doctree: nodes.document) -> None:\n        \"\"\"Handle parts of write_doc that must be called in the main process\n        if parallel build is active.\n        \"\"\"\n        pass\n", "type": "function"}, {"name": "_read_serial", "is_method": true, "class_name": "Builder", "parameters": ["self", "docnames"], "calls": ["status_iterator", "__", "len", "self.events.emit", "self.env.clear_doc", "self.read_doc"], "code_location": {"file": "__init__.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/builders", "start_line": 579, "end_line": 590}, "code_snippet": "    def _read_serial(self, docnames: list[str]) -> None:\n        for docname in status_iterator(\n            docnames,\n            __('reading sources... '),\n            'purple',\n            len(docnames),\n            self.config.verbosity,\n        ):\n            # remove all inventory entries for that file\n            self.events.emit('env-purge-doc', self.env, docname)\n            self.env.clear_doc(docname)\n            self.read_doc(docname)\n", "type": "function"}, {"name": "_write_serial", "is_method": true, "class_name": "Builder", "parameters": ["self", "docnames"], "calls": ["status_iterator", "nullcontext", "logging.pending_warnings", "__", "len", "_write_docname"], "code_location": {"file": "__init__.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/builders", "start_line": 771, "end_line": 784}, "code_snippet": "    def _write_serial(self, docnames: Sequence[str]) -> None:\n        with (\n            nullcontext()\n            if self._app._exception_on_warning\n            else logging.pending_warnings()\n        ):\n            for docname in status_iterator(\n                docnames,\n                __('writing output... '),\n                'darkgreen',\n                len(docnames),\n                self.config.verbosity,\n            ):\n                _write_docname(docname, env=self.env, builder=self, tags=self.tags)\n", "type": "function"}, {"name": "merge_info_from", "is_method": true, "class_name": "BuildEnvironment", "parameters": ["self", "docnames", "other", "app"], "calls": ["frozenset", "self.domains._merge_domain_data", "self.events.emit", "self.reread_always.add"], "code_location": {"file": "__init__.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/environment", "start_line": 418, "end_line": 434}, "code_snippet": "    def merge_info_from(\n        self, docnames: Iterable[str], other: BuildEnvironment, app: Sphinx\n    ) -> None:\n        \"\"\"Merge global information gathered about *docnames* while reading them\n        from the *other* environment.\n\n        This possibly comes from a parallel build process.\n        \"\"\"\n        docnames = frozenset(docnames)\n        for docname in docnames:\n            self.all_docs[docname] = other.all_docs[docname]\n            self.included[docname] = other.included[docname]\n            if docname in other.reread_always:\n                self.reread_always.add(docname)\n\n        self.domains._merge_domain_data(docnames, other.domaindata)\n        self.events.emit('env-merge-info', self, docnames, other)\n", "type": "function"}, {"name": "write_documents", "is_method": true, "class_name": "Builder", "parameters": ["self", "docnames"], "calls": ["sorted", "self._write_parallel", "self._write_serial"], "code_location": {"file": "__init__.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/builders", "start_line": 757, "end_line": 769}, "code_snippet": "    def write_documents(self, docnames: Set[str]) -> None:\n        \"\"\"Write all documents in *docnames*.\n\n        This method can be overridden if a builder does not create\n        output files for each document.\n        \"\"\"\n        sorted_docnames = sorted(docnames)\n        if self.parallel_ok:\n            # number of subprocesses is parallel-1 because the main process\n            # is busy loading doctrees and doing write_doc_serialized()\n            self._write_parallel(sorted_docnames, nproc=self._app.parallel - 1)\n        else:\n            self._write_serial(sorted_docnames)\n", "type": "function"}, {"name": "write_documents", "is_method": true, "class_name": "SingleFileHTMLBuilder", "parameters": ["self", "_docnames"], "calls": ["self.prepare_writing", "self.env.all_docs.keys", "progress_message", "self.assemble_doctree", "self.assemble_toc_secnumbers", "self.assemble_toc_fignumbers", "progress_message", "self.write_doc_serialized", "self.write_doc", "__", "__"], "code_location": {"file": "singlehtml.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/builders", "start_line": 168, "end_line": 178}, "code_snippet": "    def write_documents(self, _docnames: Set[str]) -> None:\n        self.prepare_writing(self.env.all_docs.keys())\n\n        with progress_message(__('assembling single document'), nonl=False):\n            doctree = self.assemble_doctree()\n            self.env.toc_secnumbers = self.assemble_toc_secnumbers()\n            self.env.toc_fignumbers = self.assemble_toc_fignumbers()\n\n        with progress_message(__('writing')):\n            self.write_doc_serialized(self.config.root_doc, doctree)\n            self.write_doc(self.config.root_doc, doctree)\n", "type": "function"}, {"name": "is_parallel_allowed", "is_method": true, "class_name": "Sphinx", "parameters": ["self", "typ"], "calls": ["self.extensions.values", "__", "__", "getattr", "__", "__", "ValueError", "logger.warning", "logger.warning", "__", "logger.warning", "logger.warning", "__"], "code_location": {"file": "application.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx", "start_line": 1773, "end_line": 1810}, "code_snippet": "    def is_parallel_allowed(self, typ: str) -> bool:\n        \"\"\"Check whether parallel processing is allowed or not.\n\n        :param typ: A type of processing; ``'read'`` or ``'write'``.\n        \"\"\"\n        if typ == 'read':\n            attrname = 'parallel_read_safe'\n            message_not_declared = __(\n                'the %s extension does not declare if it '\n                'is safe for parallel reading, assuming '\n                \"it isn't - please ask the extension author \"\n                'to check and make it explicit'\n            )\n            message_not_safe = __('the %s extension is not safe for parallel reading')\n        elif typ == 'write':\n            attrname = 'parallel_write_safe'\n            message_not_declared = __(\n                'the %s extension does not declare if it '\n                'is safe for parallel writing, assuming '\n                \"it isn't - please ask the extension author \"\n                'to check and make it explicit'\n            )\n            message_not_safe = __('the %s extension is not safe for parallel writing')\n        else:\n            raise ValueError('parallel type %s is not supported' % typ)\n\n        for ext in self.extensions.values():\n            allowed = getattr(ext, attrname, None)\n            if allowed is None:\n                logger.warning(message_not_declared, ext.name)\n                logger.warning(__('doing serial %s'), typ)\n                return False\n            elif not allowed:\n                logger.warning(message_not_safe, ext.name)\n                logger.warning(__('doing serial %s'), typ)\n                return False\n\n        return True\n", "type": "function"}, {"name": "__init__", "is_method": true, "class_name": "BuildEnvironment", "parameters": ["self", "app"], "calls": ["_get_env_version", "default_settings.copy", "defaultdict", "defaultdict", "set", "defaultdict", "set", "set", "FilenameUniqDict", "DownloadFiles", "_CurrentDocument", "_DomainsContainer._from_environment", "self.setup"], "code_location": {"file": "__init__.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/environment", "start_line": 114, "end_line": 239}, "code_snippet": "    def __init__(self, app: Sphinx) -> None:\n        self._app: Sphinx = app\n        self.doctreedir = app.doctreedir\n        self.srcdir = app.srcdir\n        self.config: Config = None  # type: ignore[assignment]\n        self.config_status: int = CONFIG_UNSET\n        self.config_status_extra: str = ''\n        self.events: EventManager = app.events\n        self.project: Project = app.project\n        self.version: Mapping[str, int] = _get_env_version(app.extensions)\n\n        # the method of doctree versioning; see set_versioning_method\n        self.versioning_condition: Literal[False] | Callable[[Node], bool] | None = None\n        self.versioning_compare: bool | None = None\n\n        # the docutils settings for building\n        self.settings: dict[str, Any] = default_settings.copy()\n        self.settings['env'] = self\n\n        # All \"docnames\" here are /-separated and relative and exclude\n        # the source suffix.\n\n        # docname -> time of reading (in integer microseconds)\n        # contains all read docnames\n        self.all_docs: dict[str, int] = {}\n        # docname -> set of dependent file\n        # names, relative to documentation root\n        self.dependencies: dict[str, set[_StrPath]] = defaultdict(set)\n        # docname -> set of included file\n        # docnames included from other documents\n        self.included: dict[str, set[str]] = defaultdict(set)\n        # docnames to re-read unconditionally on next build\n        self.reread_always: set[str] = set()\n\n        self._pickled_doctree_cache: dict[str, bytes] = {}\n        \"\"\"In-memory cache for reading pickled doctrees from disk.\n        docname -> pickled doctree\n\n        This cache is used in the ``get_doctree`` method to avoid reading the\n        doctree from disk multiple times.\n        \"\"\"\n\n        self._write_doc_doctree_cache: dict[str, nodes.document] = {}\n        \"\"\"In-memory cache for unpickling doctrees from disk.\n        docname -> doctree\n\n        Items are added in ``Builder.write_doctree``, during the read phase,\n        then used only in the ``get_and_resolve_doctree`` method.\n        \"\"\"\n\n        # File metadata\n        # docname -> dict of metadata items\n        self.metadata: dict[str, dict[str, Any]] = defaultdict(dict)\n\n        # TOC inventory\n        # docname -> title node\n        self.titles: dict[str, nodes.title] = {}\n        # docname -> title node; only different if\n        # set differently with title directive\n        self.longtitles: dict[str, nodes.title] = {}\n        # docname -> table of contents nodetree\n        self.tocs: dict[str, nodes.bullet_list] = {}\n        # docname -> number of real entries\n        self.toc_num_entries: dict[str, int] = {}\n\n        # used to determine when to show the TOC\n        # in a sidebar (don't show if it's only one item)\n        # docname -> dict of sectionid -> number\n        self.toc_secnumbers: dict[str, dict[str, tuple[int, ...]]] = {}\n        # docname -> dict of figtype -> dict of figureid -> number\n        self.toc_fignumbers: dict[str, dict[str, dict[str, tuple[int, ...]]]] = {}\n\n        # docname -> list of toctree includefiles\n        self.toctree_includes: dict[str, list[str]] = {}\n        # docname -> set of files (containing its TOCs) to rebuild too\n        self.files_to_rebuild: dict[str, set[str]] = {}\n        # docnames that have :glob: toctrees\n        self.glob_toctrees: set[str] = set()\n        # docnames that have :numbered: toctrees\n        self.numbered_toctrees: set[str] = set()\n\n        # domain-specific inventories, here to be pickled\n        # domainname -> domain-specific dict\n        self.domaindata: dict[str, dict[str, Any]] = {}\n\n        # these map absolute path -> (docnames, unique filename)\n        self.images: FilenameUniqDict = FilenameUniqDict()\n        # filename -> (set of docnames, destination)\n        self.dlfiles: DownloadFiles = DownloadFiles()\n\n        # the original URI for images\n        self.original_image_uri: dict[_StrPath, str] = {}\n\n        # temporary data storage while reading a document\n        self.current_document: _CurrentDocument = _CurrentDocument()\n        # context for cross-references (e.g. current module or class)\n        # this is similar to ``self.current_document``,\n        # but will for example be copied to attributes of \"any\" cross references\n        self.ref_context: dict[str, Any] = {}\n\n        # search index data\n\n        # docname -> title\n        self._search_index_titles: dict[str, str | None] = {}\n        # docname -> filename\n        self._search_index_filenames: dict[str, str] = {}\n        # stemmed words -> set(docname)\n        self._search_index_mapping: dict[str, set[str]] = {}\n        # stemmed words in titles -> set(docname)\n        self._search_index_title_mapping: dict[str, set[str]] = {}\n        # docname -> all titles in document\n        self._search_index_all_titles: dict[str, list[tuple[str, str | None]]] = {}\n        # docname -> list(index entry)\n        self._search_index_index_entries: dict[str, list[tuple[str, str, str]]] = {}\n        # objtype -> index\n        self._search_index_objtypes: dict[tuple[str, str], int] = {}\n        # objtype index -> (domain, type, objname (localized))\n        self._search_index_objnames: dict[int, tuple[str, str, str]] = {}\n\n        # all the registered domains, set by the application\n        self.domains: _DomainsContainer = _DomainsContainer._from_environment(\n            self, registry=app.registry\n        )\n\n        # set up environment\n        self.setup(app)\n", "type": "function"}], "retrieved_count": 10, "cost_time": 1.3320951461791992}
{"question": "Where does Sphinx's extension system flow from extension loading through hook execution to document modification?", "answer": null, "relative_code_list": null, "ground_truth": "Sphinx's extension system flow follows a structured path from extension loading through hook execution to document modification, with multiple components working together to provide extensibility throughout the build process.\n\nThe extension system flow includes the following key stages:\n\n1. **Extension Discovery and Loading**: The process begins in the SphinxComponentRegistry, which discovers extensions through various mechanisms including the extensions list in conf.py, entry points, and direct module imports. The registry loads each extension module and calls its setup function.\n\n2. **Component Registration**: During extension setup, extensions register their components (directives, roles, builders, domains, etc.) with the SphinxComponentRegistry. This registration process makes the components available for use throughout the build process.\n\n3. **Event System Integration**: Extensions connect to Sphinx's event system by registering event handlers with the EventManager. These handlers are called at specific points during the build process, such as 'config-inited', 'builder-inited', 'doctree-read', and 'doctree-resolved'.\n\n4. **Build Phase Integration**: The extension system integrates with Sphinx's multi-phase build process. Extensions can hook into different phases (initialization, reading, resolving, writing) by connecting to appropriate events and implementing the necessary callback functions.\n\n5. **Document Processing Hooks**: During document processing, extensions can modify document trees, add custom nodes, process cross-references, and perform other document modifications through event handlers and custom transforms.\n\n6. **Configuration Integration**: Extensions can add configuration options to the Config system, allowing users to customize extension behavior through conf.py settings.\n\n7. **Output Generation Integration**: Extensions can modify the output generation process by registering custom builders, writers, or by modifying the output through post-processing hooks.\n\n8. **Environment Integration**: Extensions can store and retrieve data from the BuildEnvironment, allowing them to maintain state across the build process and implement features like caching and incremental builds.\n\nThis flow is managed by the main Sphinx application, which coordinates the extension system with the core build process, ensuring that extensions are properly initialized and their hooks are executed at the appropriate times during the build.", "score": null, "retrieved_content": [{"name": "setup", "is_method": false, "class_name": null, "parameters": ["app"], "calls": ["app.add_transform", "app.add_transform", "app.add_transform", "app.add_transform", "app.add_transform", "app.add_transform", "app.add_transform", "app.add_transform", "app.add_transform", "app.add_transform", "app.add_transform", "app.add_transform", "app.add_transform", "app.add_transform", "app.add_transform"], "code_location": {"file": "__init__.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/transforms", "start_line": 511, "end_line": 532}, "code_snippet": "def setup(app: Sphinx) -> ExtensionMetadata:\n    app.add_transform(ApplySourceWorkaround)\n    app.add_transform(ExtraTranslatableNodes)\n    app.add_transform(DefaultSubstitutions)\n    app.add_transform(MoveModuleTargets)\n    app.add_transform(HandleCodeBlocks)\n    app.add_transform(SortIds)\n    app.add_transform(DoctestTransform)\n    app.add_transform(AutoNumbering)\n    app.add_transform(AutoIndexUpgrader)\n    app.add_transform(FilterSystemMessages)\n    app.add_transform(UnreferencedFootnotesDetector)\n    app.add_transform(SphinxSmartQuotes)\n    app.add_transform(DoctreeReadEvent)\n    app.add_transform(GlossarySorter)\n    app.add_transform(ReorderConsecutiveTargetAndIndexNodes)\n\n    return {\n        'version': 'builtin',\n        'parallel_read_safe': True,\n        'parallel_write_safe': True,\n    }\n", "type": "function"}, {"name": "load_extension", "is_method": true, "class_name": "SphinxComponentRegistry", "parameters": ["self", "app", "extname"], "calls": ["logger.warning", "__", "prefixed_warnings", "getattr", "Extension", "__", "import_module", "logger.warning", "logger.verbose", "ExtensionError", "__", "setup", "isinstance", "logger.warning", "VersionRequirementError", "__", "__", "traceback.format_exc", "__", "__"], "code_location": {"file": "registry.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx", "start_line": 524, "end_line": 587}, "code_snippet": "    def load_extension(self, app: Sphinx, extname: str) -> None:\n        \"\"\"Load a Sphinx extension.\"\"\"\n        if extname in app.extensions:  # already loaded\n            return\n        if extname in EXTENSION_BLACKLIST:\n            logger.warning(\n                __(\n                    'the extension %r was already merged with Sphinx since '\n                    'version %s; this extension is ignored.'\n                ),\n                extname,\n                EXTENSION_BLACKLIST[extname],\n            )\n            return\n\n        # update loading context\n        prefix = __('while setting up extension %s:') % extname\n        with prefixed_warnings(prefix):\n            try:\n                mod = import_module(extname)\n            except ImportError as err:\n                logger.verbose(__('Original exception:\\n') + traceback.format_exc())\n                raise ExtensionError(\n                    __('Could not import extension %s') % extname, err\n                ) from err\n\n            setup: _ExtensionSetupFunc | None = getattr(mod, 'setup', None)\n            if setup is None:\n                logger.warning(\n                    __(\n                        'extension %r has no setup() function; is it really '\n                        'a Sphinx extension module?'\n                    ),\n                    extname,\n                )\n                metadata: ExtensionMetadata = {}\n            else:\n                try:\n                    metadata = setup(app)\n                except VersionRequirementError as err:\n                    # add the extension name to the version required\n                    raise VersionRequirementError(\n                        __(\n                            'The %s extension used by this project needs at least '\n                            'Sphinx v%s; it therefore cannot be built with this '\n                            'version.'\n                        )\n                        % (extname, err),\n                    ) from err\n\n            if metadata is None:\n                metadata = {}\n            elif not isinstance(metadata, dict):\n                logger.warning(\n                    __(\n                        'extension %r returned an unsupported object from '\n                        'its setup() function; it should return None or a '\n                        'metadata dictionary'\n                    ),\n                    extname,\n                )\n                metadata = {}\n\n            app.extensions[extname] = Extension(extname, mod, **metadata)\n", "type": "function"}, {"name": "setup", "is_method": false, "class_name": null, "parameters": ["app"], "calls": ["app.add_transform", "app.add_post_transform", "app.add_post_transform", "app.add_post_transform", "app.add_post_transform", "app.add_post_transform", "app.add_post_transform", "app.add_post_transform", "app.add_post_transform", "app.add_post_transform"], "code_location": {"file": "transforms.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/builders/latex", "start_line": 645, "end_line": 661}, "code_snippet": "def setup(app: Sphinx) -> ExtensionMetadata:\n    app.add_transform(FootnoteDocnameUpdater)\n    app.add_post_transform(SubstitutionDefinitionsRemover)\n    app.add_post_transform(BibliographyTransform)\n    app.add_post_transform(CitationReferenceTransform)\n    app.add_post_transform(DocumentTargetTransform)\n    app.add_post_transform(IndexInSectionTitleTransform)\n    app.add_post_transform(LaTeXFootnoteTransform)\n    app.add_post_transform(LiteralBlockTransform)\n    app.add_post_transform(MathReferenceTransform)\n    app.add_post_transform(ShowUrlsTransform)\n\n    return {\n        'version': 'builtin',\n        'parallel_read_safe': True,\n        'parallel_write_safe': True,\n    }\n", "type": "function"}, {"name": "setup", "is_method": false, "class_name": null, "parameters": ["app"], "calls": ["app.add_post_transform", "app.add_post_transform", "app.add_post_transform", "app.add_post_transform"], "code_location": {"file": "__init__.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/transforms/post_transforms", "start_line": 393, "end_line": 403}, "code_snippet": "def setup(app: Sphinx) -> ExtensionMetadata:\n    app.add_post_transform(ReferencesResolver)\n    app.add_post_transform(OnlyNodeTransform)\n    app.add_post_transform(SigElementFallbackTransform)\n    app.add_post_transform(PropagateDescDomain)\n\n    return {\n        'version': 'builtin',\n        'parallel_read_safe': True,\n        'parallel_write_safe': True,\n    }\n", "type": "function"}, {"name": "run_apidoc", "is_method": false, "class_name": null, "parameters": ["app"], "calls": ["ApidocDefaults.from_config", "LOGGER.info", "enumerate", "bold", "_run_apidoc_module", "__"], "code_location": {"file": "_extension.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/ext/apidoc", "start_line": 43, "end_line": 60}, "code_snippet": "def run_apidoc(app: Sphinx) -> None:\n    \"\"\"Run the apidoc extension.\"\"\"\n    defaults = ApidocDefaults.from_config(app.config)\n    apidoc_modules: Sequence[dict[str, Any]] = app.config.apidoc_modules\n    srcdir: Path = app.srcdir\n    confdir: Path = app.confdir\n\n    LOGGER.info(bold(__('Running apidoc')))\n\n    module_options: dict[str, Any]\n    for i, module_options in enumerate(apidoc_modules):\n        _run_apidoc_module(\n            i,\n            options=module_options,\n            defaults=defaults,\n            srcdir=srcdir,\n            confdir=confdir,\n        )\n", "type": "function"}, {"name": "setup", "is_method": false, "class_name": null, "parameters": ["app"], "calls": ["app.add_post_transform", "app.add_post_transform"], "code_location": {"file": "images.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/transforms/post_transforms", "start_line": 294, "end_line": 302}, "code_snippet": "def setup(app: Sphinx) -> ExtensionMetadata:\n    app.add_post_transform(ImageDownloader)\n    app.add_post_transform(DataURIExtractor)\n\n    return {\n        'version': 'builtin',\n        'parallel_read_safe': True,\n        'parallel_write_safe': True,\n    }\n", "type": "function"}, {"name": "setup", "is_method": false, "class_name": null, "parameters": ["app"], "calls": ["_patch_python_domain", "app.setup_extension", "app.connect", "app.connect", "isinstance", "app.add_config_value"], "code_location": {"file": "__init__.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/ext/napoleon", "start_line": 300, "end_line": 341}, "code_snippet": "def setup(app: Sphinx) -> ExtensionMetadata:\n    \"\"\"Sphinx extension setup function.\n\n    When the extension is loaded, Sphinx imports this module and executes\n    the ``setup()`` function, which in turn notifies Sphinx of everything\n    the extension offers.\n\n    Parameters\n    ----------\n    app : sphinx.application.Sphinx\n        Application object representing the Sphinx process\n\n    See Also\n    --------\n    `The Sphinx documentation on Extensions\n    <https://www.sphinx-doc.org/extensions.html>`_\n\n    `The Extension Tutorial <https://www.sphinx-doc.org/extdev/tutorial.html>`_\n\n    `The Extension API <https://www.sphinx-doc.org/extdev/appapi.html>`_\n\n    \"\"\"\n    if not isinstance(app, Sphinx):\n        # probably called by tests\n        return {\n            'version': sphinx.__display_version__,\n            'parallel_read_safe': True,\n        }\n\n    _patch_python_domain()\n\n    app.setup_extension('sphinx.ext.autodoc')\n    app.connect('autodoc-process-docstring', _process_docstring)\n    app.connect('autodoc-skip-member', _skip_member)\n\n    for name, default, rebuild, types in Config._config_values:\n        app.add_config_value(name, default, rebuild, types=types)\n\n    return {\n        'version': sphinx.__display_version__,\n        'parallel_read_safe': True,\n    }\n", "type": "function"}, {"name": "setup", "is_method": false, "class_name": null, "parameters": ["app"], "calls": ["app.add_post_transform", "app.add_post_transform"], "code_location": {"file": "code.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/transforms/post_transforms", "start_line": 135, "end_line": 143}, "code_snippet": "def setup(app: Sphinx) -> ExtensionMetadata:\n    app.add_post_transform(HighlightLanguageTransform)\n    app.add_post_transform(TrimDoctestFlagsTransform)\n\n    return {\n        'version': 'builtin',\n        'parallel_read_safe': True,\n        'parallel_write_safe': True,\n    }\n", "type": "function"}, {"name": "setup", "is_method": false, "class_name": null, "parameters": ["app"], "calls": ["app.add_transform", "app.add_transform", "app.add_transform", "app.add_transform", "app.add_transform"], "code_location": {"file": "i18n.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/transforms", "start_line": 694, "end_line": 705}, "code_snippet": "def setup(app: Sphinx) -> ExtensionMetadata:\n    app.add_transform(PreserveTranslatableMessages)\n    app.add_transform(Locale)\n    app.add_transform(TranslationProgressTotaliser)\n    app.add_transform(AddTranslationClasses)\n    app.add_transform(RemoveTranslatableInline)\n\n    return {\n        'version': 'builtin',\n        'parallel_read_safe': True,\n        'parallel_write_safe': True,\n    }\n", "type": "function"}, {"name": "setup", "is_method": false, "class_name": null, "parameters": ["app"], "calls": ["app.add_post_transform"], "code_location": {"file": "mocksvgconverter.py", "path": "/data3/pwh/swebench-repos/sphinx/tests/roots/test-ext-imgmockconverter", "start_line": 33, "end_line": 40}, "code_snippet": "def setup(app: Sphinx) -> ExtensionMetadata:\n    app.add_post_transform(MyConverter)\n\n    return {\n        'version': 'builtin',\n        'parallel_read_safe': True,\n        'parallel_write_safe': True,\n    }\n", "type": "function"}], "retrieved_count": 10, "cost_time": 1.3280761241912842}
{"question": "Why does Sphinx's incremental build system improve build performance for large documentation sets?", "answer": null, "relative_code_list": null, "ground_truth": "Sphinx's incremental build system improves build performance for large documentation sets by intelligently tracking changes and only rebuilding the components that have actually been modified. This approach provides significant performance benefits that scale with project size.\n\nKey ways the incremental build system improves performance include:\n\n1. **Selective Processing**: The system tracks which files have changed since the last build and only processes those files, avoiding the expensive parsing and analysis of unchanged documents.\n\n2. **Dependency Tracking**: Sphinx maintains a dependency graph that tracks relationships between documents. When one document changes, only documents that depend on it are rebuilt, minimizing unnecessary work.\n\n3. **Environment Persistence**: The build environment, including cross-references, metadata, and document relationships, is cached between builds. This allows Sphinx to skip the expensive initial setup phase for unchanged components.\n\n4. **Cross-Reference Optimization**: Cross-reference data is preserved across builds, allowing Sphinx to avoid recalculating complex relationships between documents that haven't changed.\n\n5. **Memory Efficiency**: By processing only changed files, the incremental system reduces peak memory usage, making it possible to handle larger projects on systems with limited memory.\n\n6. **Scalable Performance**: The performance benefits of incremental builds increase with project size. For very large projects with thousands of files, the time savings can be dramatic compared to full rebuilds.\n\n7. **Development Workflow**: Incremental builds enable faster feedback during development, allowing developers to see changes quickly without waiting for complete rebuilds.\n\n8. **Resource Conservation**: By avoiding unnecessary processing, incremental builds reduce CPU usage, disk I/O, and overall system resource consumption.\n\nThe incremental build system is particularly effective for large documentation sets because the overhead of tracking changes is minimal compared to the time saved by avoiding redundant processing of unchanged files.", "score": null, "retrieved_content": [{"name": "build", "is_method": true, "class_name": "SphinxTestApp", "parameters": ["self", "force_all", "filenames"], "calls": ["self.env._pickled_doctree_cache.clear", "build", "super"], "code_location": {"file": "util.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/testing", "start_line": 235, "end_line": 237}, "code_snippet": "    def build(self, force_all: bool = False, filenames: Sequence[Path] = ()) -> None:\n        self.env._pickled_doctree_cache.clear()\n        super().build(force_all, filenames)\n", "type": "function"}, {"name": "test_incremental_reading", "is_method": false, "class_name": null, "parameters": ["app"], "calls": ["pytest.mark.sphinx", "app.builder.read", "write_text", "unlink", "app.builder.read", "set", "set", "sorted", "set"], "code_location": {"file": "test_incremental_reading.py", "path": "/data3/pwh/swebench-repos/sphinx/tests/test_builders", "start_line": 20, "end_line": 39}, "code_snippet": "def test_incremental_reading(app: SphinxTestApp) -> None:\n    # first reading\n    updated = app.builder.read()\n    assert set(updated) == app.env.found_docs == set(app.env.all_docs)\n    assert updated == sorted(updated)  # sorted by alphanumeric\n\n    # test if exclude_patterns works ok\n    assert 'subdir/excluded' not in app.env.found_docs\n\n    # before second reading, add, modify and remove source files\n    (app.srcdir / 'new.txt').write_text('New file\\n========\\n', encoding='utf8')\n    app.env.all_docs['index'] = 0  # mark as modified\n    (app.srcdir / 'autodoc.txt').unlink()\n\n    # second reading\n    updated = app.builder.read()\n\n    assert set(updated) == {'index', 'new'}\n    assert 'autodoc' not in app.env.all_docs\n    assert 'autodoc' not in app.env.found_docs\n", "type": "function"}, {"name": "test_incremental_reading_for_missing_files", "is_method": false, "class_name": null, "parameters": ["app"], "calls": ["pytest.mark.sphinx", "app.builder.read", "app.builder.read", "sys.modules.pop", "set", "set", "set"], "code_location": {"file": "test_incremental_reading.py", "path": "/data3/pwh/swebench-repos/sphinx/tests/test_builders", "start_line": 47, "end_line": 59}, "code_snippet": "def test_incremental_reading_for_missing_files(app: SphinxTestApp) -> None:\n    # first reading\n    updated = app.builder.read()\n    assert set(updated) == app.env.found_docs == set(app.env.all_docs)\n\n    # second reading\n    updated = app.builder.read()\n\n    # \"index\" is listed up to updated because it contains references\n    # to nonexisting downloadable or image files\n    assert set(updated) == {'index'}\n\n    sys.modules.pop('autodoc_fodder', None)\n", "type": "function"}, {"name": "build", "is_method": true, "class_name": "Sphinx", "parameters": ["self", "force_all", "filenames"], "calls": ["self.builder.cleanup", "self.events.emit", "logger.info", "logger.info", "self.builder.build_all", "envfile.is_file", "self.events.emit", "logger.info", "logger.info", "logger.info", "logger.info", "self.builder.build_specific", "self.builder.build_update", "envfile.unlink", "bold", "bold", "__", "bold", "__", "bold", "relpath", "__", "__", "__", "__", "__", "__"], "code_location": {"file": "application.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx", "start_line": 428, "end_line": 487}, "code_snippet": "    def build(self, force_all: bool = False, filenames: Sequence[Path] = ()) -> None:\n        self.builder.phase = BuildPhase.READING\n        try:\n            if force_all:\n                self.builder.build_all()\n            elif filenames:\n                self.builder.build_specific(filenames)\n            else:\n                self.builder.build_update()\n\n            self.events.emit('build-finished', None)\n        except Exception as err:\n            # delete the saved env to force a fresh build next time\n            envfile = self.doctreedir / ENV_PICKLE_FILENAME\n            if envfile.is_file():\n                envfile.unlink()\n            self.events.emit('build-finished', err)\n            raise\n\n        if self._warncount == 0:\n            if self.statuscode != 0:\n                logger.info(bold(__('build finished with problems.')))\n            else:\n                logger.info(bold(__('build succeeded.')))\n        elif self._warncount == 1:\n            if self._fail_on_warnings:\n                self.statuscode = 1\n                msg = __(\n                    'build finished with problems, 1 warning '\n                    '(with warnings treated as errors).'\n                )\n            elif self.statuscode != 0:\n                msg = __('build finished with problems, 1 warning.')\n            else:\n                msg = __('build succeeded, 1 warning.')\n            logger.info(bold(msg))\n        else:\n            if self._fail_on_warnings:\n                self.statuscode = 1\n                msg = __(\n                    'build finished with problems, %s warnings '\n                    '(with warnings treated as errors).'\n                )\n            elif self.statuscode != 0:\n                msg = __('build finished with problems, %s warnings.')\n            else:\n                msg = __('build succeeded, %s warnings.')\n            logger.info(bold(msg), self._warncount)\n\n        if self.statuscode == 0 and self.builder.epilog:\n            logger.info('')\n            logger.info(\n                self.builder.epilog,\n                {\n                    'outdir': relpath(self.outdir),\n                    'project': self.config.project,\n                },\n            )\n\n        self.builder.cleanup()\n", "type": "function"}, {"name": "build_main", "is_method": false, "class_name": null, "parameters": ["argv"], "calls": ["get_parser", "_parse_arguments", "_parse_confdir", "_parse_doctreedir", "_validate_filenames", "_validate_colour_support", "_parse_logging", "_parse_confoverrides", "patch_docutils", "docutils_namespace", "Sphinx", "app.build", "sphinx._cli.util.errors.handle_exception", "warnfp.close", "app.extensions.values"], "code_location": {"file": "build.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/cmd", "start_line": 395, "end_line": 452}, "code_snippet": "def build_main(argv: Sequence[str]) -> int:\n    \"\"\"Sphinx build \"main\" command-line entry.\"\"\"\n    parser = get_parser()\n    args = _parse_arguments(parser, argv)\n    args.confdir = _parse_confdir(args.noconfig, args.confdir, args.sourcedir)\n    args.doctreedir = _parse_doctreedir(args.doctreedir, args.outputdir)\n    _validate_filenames(parser, args.force_all, args.filenames)\n    _validate_colour_support(args.color)\n    args.status, args.warning, args.error, warnfp = _parse_logging(\n        parser, args.quiet, args.really_quiet, args.warnfile\n    )\n    args.confoverrides = _parse_confoverrides(\n        parser, args.define, args.htmldefine, args.nitpicky\n    )\n\n    app = None\n    try:\n        confdir = args.confdir or args.sourcedir\n        with patch_docutils(confdir), docutils_namespace():\n            app = Sphinx(\n                srcdir=args.sourcedir,\n                confdir=args.confdir,\n                outdir=args.outputdir,\n                doctreedir=args.doctreedir,\n                buildername=args.builder,\n                confoverrides=args.confoverrides,\n                status=args.status,\n                warning=args.warning,\n                freshenv=args.freshenv,\n                warningiserror=args.warningiserror,\n                tags=args.tags,\n                verbosity=args.verbosity,\n                parallel=args.jobs,\n                keep_going=False,\n                pdb=args.pdb,\n                exception_on_warning=args.exception_on_warning,\n            )\n            app.build(args.force_all, args.filenames)\n            return app.statuscode\n    except (Exception, KeyboardInterrupt) as exc:\n        if app is not None:\n            message_log: Sequence[str] = app.messagelog\n            extensions: Collection[Extension] = app.extensions.values()\n        else:\n            message_log = extensions = ()\n        sphinx._cli.util.errors.handle_exception(\n            exc,\n            stderr=args.error,\n            use_pdb=args.pdb,\n            print_traceback=args.verbosity or args.traceback,\n            message_log=message_log,\n            extensions=extensions,\n        )\n        return 2\n    finally:\n        if warnfp is not None:\n            # close the file descriptor for the warnings file opened by Sphinx\n            warnfp.close()\n", "type": "function"}, {"name": "_has_doc_changed", "is_method": false, "class_name": null, "parameters": ["docname"], "calls": ["_last_modified_time", "logger.debug", "doctree_path.is_file", "logger.debug", "logger.debug", "_format_rfc3339_microseconds", "_format_rfc3339_microseconds", "dep_path.is_file", "logger.debug", "_last_modified_time", "logger.debug", "_format_rfc3339_microseconds", "_format_rfc3339_microseconds"], "code_location": {"file": "__init__.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/environment", "start_line": 838, "end_line": 900}, "code_snippet": "def _has_doc_changed(\n    docname: str,\n    *,\n    filename: Path,\n    reread_always: Set[str],\n    doctreedir: Path,\n    all_docs: Mapping[str, int],\n    dependencies: Mapping[str, Set[Path]],\n) -> bool:\n    # check the \"reread always\" list\n    if docname in reread_always:\n        logger.debug('[build target] changed %r: re-read forced', docname)\n        return True\n\n    # if the doctree file is not there, rebuild\n    doctree_path = doctreedir / f'{docname}.doctree'\n    if not doctree_path.is_file():\n        logger.debug('[build target] changed %r: doctree file does not exist', docname)\n        return True\n\n    # check the mtime of the document\n    mtime = all_docs[docname]\n    new_mtime = _last_modified_time(filename)\n    if new_mtime > mtime:\n        logger.debug(\n            '[build target] changed: %r is outdated (%s -> %s)',\n            docname,\n            _format_rfc3339_microseconds(mtime),\n            _format_rfc3339_microseconds(new_mtime),\n        )\n        return True\n\n    # finally, check the mtime of dependencies\n    if docname not in dependencies:\n        return False\n    for dep_path in dependencies[docname]:\n        try:\n            dep_path_is_file = dep_path.is_file()\n        except OSError:\n            return True  # give it another chance\n        if not dep_path_is_file:\n            logger.debug(\n                '[build target] changed: %r is missing dependency %r',\n                docname,\n                dep_path,\n            )\n            return True\n\n        try:\n            dep_mtime = _last_modified_time(dep_path)\n        except OSError:\n            return True  # give it another chance\n        if dep_mtime > mtime:\n            logger.debug(\n                '[build target] changed: %r is outdated due to dependency %r (%s -> %s)',\n                docname,\n                dep_path,\n                _format_rfc3339_microseconds(mtime),\n                _format_rfc3339_microseconds(dep_mtime),\n            )\n            return True\n\n    return False\n", "type": "function"}, {"name": "build_update", "is_method": true, "class_name": "Builder", "parameters": ["self"], "calls": ["self.compile_update_catalogs", "self.get_outdated_docs", "isinstance", "self.build", "set", "self.build", "__", "len"], "code_location": {"file": "__init__.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/builders", "start_line": 372, "end_line": 386}, "code_snippet": "    def build_update(self) -> None:\n        \"\"\"Only rebuild what was changed or added since last build.\"\"\"\n        self.compile_update_catalogs()\n\n        to_build = self.get_outdated_docs()\n        if isinstance(to_build, str):\n            self.build(['__all__'], summary=to_build, method='update')\n        else:\n            to_build = set(to_build)\n            self.build(\n                to_build,\n                summary=__('targets for %d source files that are out of date')\n                % len(to_build),\n                method='update',\n            )\n", "type": "function"}, {"name": "__init__", "is_method": true, "class_name": "BuildEnvironment", "parameters": ["self", "app"], "calls": ["_get_env_version", "default_settings.copy", "defaultdict", "defaultdict", "set", "defaultdict", "set", "set", "FilenameUniqDict", "DownloadFiles", "_CurrentDocument", "_DomainsContainer._from_environment", "self.setup"], "code_location": {"file": "__init__.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/environment", "start_line": 114, "end_line": 239}, "code_snippet": "    def __init__(self, app: Sphinx) -> None:\n        self._app: Sphinx = app\n        self.doctreedir = app.doctreedir\n        self.srcdir = app.srcdir\n        self.config: Config = None  # type: ignore[assignment]\n        self.config_status: int = CONFIG_UNSET\n        self.config_status_extra: str = ''\n        self.events: EventManager = app.events\n        self.project: Project = app.project\n        self.version: Mapping[str, int] = _get_env_version(app.extensions)\n\n        # the method of doctree versioning; see set_versioning_method\n        self.versioning_condition: Literal[False] | Callable[[Node], bool] | None = None\n        self.versioning_compare: bool | None = None\n\n        # the docutils settings for building\n        self.settings: dict[str, Any] = default_settings.copy()\n        self.settings['env'] = self\n\n        # All \"docnames\" here are /-separated and relative and exclude\n        # the source suffix.\n\n        # docname -> time of reading (in integer microseconds)\n        # contains all read docnames\n        self.all_docs: dict[str, int] = {}\n        # docname -> set of dependent file\n        # names, relative to documentation root\n        self.dependencies: dict[str, set[_StrPath]] = defaultdict(set)\n        # docname -> set of included file\n        # docnames included from other documents\n        self.included: dict[str, set[str]] = defaultdict(set)\n        # docnames to re-read unconditionally on next build\n        self.reread_always: set[str] = set()\n\n        self._pickled_doctree_cache: dict[str, bytes] = {}\n        \"\"\"In-memory cache for reading pickled doctrees from disk.\n        docname -> pickled doctree\n\n        This cache is used in the ``get_doctree`` method to avoid reading the\n        doctree from disk multiple times.\n        \"\"\"\n\n        self._write_doc_doctree_cache: dict[str, nodes.document] = {}\n        \"\"\"In-memory cache for unpickling doctrees from disk.\n        docname -> doctree\n\n        Items are added in ``Builder.write_doctree``, during the read phase,\n        then used only in the ``get_and_resolve_doctree`` method.\n        \"\"\"\n\n        # File metadata\n        # docname -> dict of metadata items\n        self.metadata: dict[str, dict[str, Any]] = defaultdict(dict)\n\n        # TOC inventory\n        # docname -> title node\n        self.titles: dict[str, nodes.title] = {}\n        # docname -> title node; only different if\n        # set differently with title directive\n        self.longtitles: dict[str, nodes.title] = {}\n        # docname -> table of contents nodetree\n        self.tocs: dict[str, nodes.bullet_list] = {}\n        # docname -> number of real entries\n        self.toc_num_entries: dict[str, int] = {}\n\n        # used to determine when to show the TOC\n        # in a sidebar (don't show if it's only one item)\n        # docname -> dict of sectionid -> number\n        self.toc_secnumbers: dict[str, dict[str, tuple[int, ...]]] = {}\n        # docname -> dict of figtype -> dict of figureid -> number\n        self.toc_fignumbers: dict[str, dict[str, dict[str, tuple[int, ...]]]] = {}\n\n        # docname -> list of toctree includefiles\n        self.toctree_includes: dict[str, list[str]] = {}\n        # docname -> set of files (containing its TOCs) to rebuild too\n        self.files_to_rebuild: dict[str, set[str]] = {}\n        # docnames that have :glob: toctrees\n        self.glob_toctrees: set[str] = set()\n        # docnames that have :numbered: toctrees\n        self.numbered_toctrees: set[str] = set()\n\n        # domain-specific inventories, here to be pickled\n        # domainname -> domain-specific dict\n        self.domaindata: dict[str, dict[str, Any]] = {}\n\n        # these map absolute path -> (docnames, unique filename)\n        self.images: FilenameUniqDict = FilenameUniqDict()\n        # filename -> (set of docnames, destination)\n        self.dlfiles: DownloadFiles = DownloadFiles()\n\n        # the original URI for images\n        self.original_image_uri: dict[_StrPath, str] = {}\n\n        # temporary data storage while reading a document\n        self.current_document: _CurrentDocument = _CurrentDocument()\n        # context for cross-references (e.g. current module or class)\n        # this is similar to ``self.current_document``,\n        # but will for example be copied to attributes of \"any\" cross references\n        self.ref_context: dict[str, Any] = {}\n\n        # search index data\n\n        # docname -> title\n        self._search_index_titles: dict[str, str | None] = {}\n        # docname -> filename\n        self._search_index_filenames: dict[str, str] = {}\n        # stemmed words -> set(docname)\n        self._search_index_mapping: dict[str, set[str]] = {}\n        # stemmed words in titles -> set(docname)\n        self._search_index_title_mapping: dict[str, set[str]] = {}\n        # docname -> all titles in document\n        self._search_index_all_titles: dict[str, list[tuple[str, str | None]]] = {}\n        # docname -> list(index entry)\n        self._search_index_index_entries: dict[str, list[tuple[str, str, str]]] = {}\n        # objtype -> index\n        self._search_index_objtypes: dict[tuple[str, str], int] = {}\n        # objtype index -> (domain, type, objname (localized))\n        self._search_index_objnames: dict[int, tuple[str, str, str]] = {}\n\n        # all the registered domains, set by the application\n        self.domains: _DomainsContainer = _DomainsContainer._from_environment(\n            self, registry=app.registry\n        )\n\n        # set up environment\n        self.setup(app)\n", "type": "function"}, {"name": "test_githubpages", "is_method": false, "class_name": null, "parameters": ["app"], "calls": ["pytest.mark.sphinx", "app.build", "re.search", "app.status.getvalue", "app.status.getvalue"], "code_location": {"file": "test_ext_duration.py", "path": "/data3/pwh/swebench-repos/sphinx/tests/test_extensions", "start_line": 19, "end_line": 23}, "code_snippet": "def test_githubpages(app: SphinxTestApp) -> None:\n    app.build()\n\n    assert 'slowest reading durations' in app.status.getvalue()\n    assert re.search('\\\\d+\\\\.\\\\d{3} index\\n', app.status.getvalue())\n", "type": "function"}, {"name": "test_build", "is_method": false, "class_name": null, "parameters": ["app"], "calls": ["pytest.mark.sphinx", "app.build", "read_text", "py_undoc.startswith", "read_text", "c_undoc.startswith", "pickle.loads", "app.status.getvalue", "read_bytes", "len", "next", "app.status.getvalue", "iter", "undoc_c.values"], "code_location": {"file": "test_ext_coverage.py", "path": "/data3/pwh/swebench-repos/sphinx/tests/test_extensions", "start_line": 15, "end_line": 55}, "code_snippet": "def test_build(app: SphinxTestApp) -> None:\n    app.build(force_all=True)\n\n    py_undoc = (app.outdir / 'python.txt').read_text(encoding='utf8')\n    assert py_undoc.startswith(\n        'Undocumented Python objects\\n===========================\\n',\n    )\n    assert 'autodoc_target\\n--------------\\n' in py_undoc\n    assert ' * Class -- missing methods:\\n' in py_undoc\n    assert ' * raises\\n' in py_undoc\n    # these two are documented in autodoc.txt\n    assert ' * function\\n' not in py_undoc\n    assert ' * Class\\n' not in py_undoc\n\n    # in the \"failed import\" section\n    assert \" * mod -- No module named 'mod'\" in py_undoc\n\n    assert 'undocumented  py' not in app.status.getvalue()\n\n    c_undoc = (app.outdir / 'c.txt').read_text(encoding='utf8')\n    assert c_undoc.startswith(\n        'Undocumented C API elements\\n===========================\\n',\n    )\n    assert 'api.h' in c_undoc\n    assert ' * Py_SphinxTest' in c_undoc\n\n    undoc_py, undoc_c, _py_undocumented, _py_documented = pickle.loads(\n        (app.outdir / 'undoc.pickle').read_bytes()\n    )\n    assert len(undoc_c) == 1\n    # the key is the full path to the header file, which isn't testable\n    assert next(iter(undoc_c.values())) == {('function', 'Py_SphinxTest')}\n\n    assert 'autodoc_target' in undoc_py\n    assert 'funcs' in undoc_py['autodoc_target']\n    assert 'raises' in undoc_py['autodoc_target']['funcs']\n    assert 'classes' in undoc_py['autodoc_target']\n    assert 'Class' in undoc_py['autodoc_target']['classes']\n    assert 'undocmeth' in undoc_py['autodoc_target']['classes']['Class']\n\n    assert 'undocumented  c' not in app.status.getvalue()\n", "type": "function"}], "retrieved_count": 10, "cost_time": 1.3501391410827637}
{"question": "Where does Sphinx store its extension implementations?", "answer": null, "relative_code_list": null, "ground_truth": "Sphinx stores its extension implementations in several locations within the codebase, organized by functionality and type. The extension system is designed to be modular and extensible, with built-in extensions distributed throughout the codebase.\n\nKey locations where Sphinx stores extension implementations include:\n\n1. **sphinx/ext/**: This directory contains many of Sphinx's built-in extensions, including autodoc, autosummary, doctest, intersphinx, and others. Each extension is typically implemented as a separate module or package within this directory.\n\n2. **sphinx/domains/**: Domain-specific extensions are stored in this directory, including implementations for Python (py), C++ (cpp), C (c), JavaScript (js), and other programming language domains. Each domain provides specialized functionality for documenting code in that language.\n\n3. **sphinx/directives/**: Built-in directive implementations are stored here, including general-purpose directives like admonitions, code blocks, and other document structure elements.\n\n4. **sphinx/roles.py**: Built-in role implementations are stored in this file, including cross-reference roles, formatting roles, and other inline markup elements.\n\n5. **sphinx/builders/**: Builder implementations for different output formats (HTML, LaTeX, PDF, etc.) are stored in this directory, with each builder providing functionality for generating documentation in a specific format.\n\n6. **sphinx/transforms/**: Transform implementations that modify document trees during processing are stored here, including transforms for cross-reference resolution, indexing, and other document modifications.\n\n7. **sphinx/themes/**: Theme implementations for customizing the appearance of generated documentation are stored in this directory.\n\n8. **sphinx/writers/**: Writer implementations for different output formats are stored here, providing the actual output generation logic for each format.\n\nThe extension system also supports external extensions that can be installed separately and loaded through the extensions configuration in conf.py. These external extensions are typically distributed as separate Python packages and can be installed via pip or other package managers.", "score": null, "retrieved_content": [{"name": "setup", "is_method": false, "class_name": null, "parameters": ["app"], "calls": ["app.add_env_collector", "app.add_env_collector"], "code_location": {"file": "asset.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/environment/collectors", "start_line": 177, "end_line": 185}, "code_snippet": "def setup(app: Sphinx) -> ExtensionMetadata:\n    app.add_env_collector(ImageCollector)\n    app.add_env_collector(DownloadFileCollector)\n\n    return {\n        'version': 'builtin',\n        'parallel_read_safe': True,\n        'parallel_write_safe': True,\n    }\n", "type": "function"}, {"name": "setup", "is_method": false, "class_name": null, "parameters": ["app"], "calls": ["app.setup_extension", "app.add_builder"], "code_location": {"file": "dirhtml.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/builders", "start_line": 41, "end_line": 50}, "code_snippet": "def setup(app: Sphinx) -> ExtensionMetadata:\n    app.setup_extension('sphinx.builders.html')\n\n    app.add_builder(DirectoryHTMLBuilder)\n\n    return {\n        'version': 'builtin',\n        'parallel_read_safe': True,\n        'parallel_write_safe': True,\n    }\n", "type": "function"}, {"name": "setup", "is_method": false, "class_name": null, "parameters": ["app"], "calls": ["app.add_transform", "app.add_transform"], "code_location": {"file": "references.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/transforms", "start_line": 44, "end_line": 52}, "code_snippet": "def setup(app: Sphinx) -> ExtensionMetadata:\n    app.add_transform(SphinxDanglingReferences)\n    app.add_transform(SphinxDomains)\n\n    return {\n        'version': 'builtin',\n        'parallel_read_safe': True,\n        'parallel_write_safe': True,\n    }\n", "type": "function"}, {"name": "setup", "is_method": false, "class_name": null, "parameters": ["app"], "calls": ["app.add_post_transform", "app.add_post_transform"], "code_location": {"file": "images.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/transforms/post_transforms", "start_line": 294, "end_line": 302}, "code_snippet": "def setup(app: Sphinx) -> ExtensionMetadata:\n    app.add_post_transform(ImageDownloader)\n    app.add_post_transform(DataURIExtractor)\n\n    return {\n        'version': 'builtin',\n        'parallel_read_safe': True,\n        'parallel_write_safe': True,\n    }\n", "type": "function"}, {"name": "setup", "is_method": false, "class_name": null, "parameters": ["app"], "calls": ["app.add_domain", "app.add_directive", "app.add_role", "IndexRole"], "code_location": {"file": "index.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/domains", "start_line": 120, "end_line": 130}, "code_snippet": "def setup(app: Sphinx) -> ExtensionMetadata:\n    app.add_domain(IndexDomain)\n    app.add_directive('index', IndexDirective)\n    app.add_role('index', IndexRole())\n\n    return {\n        'version': 'builtin',\n        'env_version': 1,\n        'parallel_read_safe': True,\n        'parallel_write_safe': True,\n    }\n", "type": "function"}, {"name": "setup", "is_method": false, "class_name": null, "parameters": ["app"], "calls": ["app.add_transform", "app.add_transform", "app.add_transform", "app.add_transform", "app.add_transform", "app.add_transform", "app.add_transform", "app.add_transform", "app.add_transform", "app.add_transform", "app.add_transform", "app.add_transform", "app.add_transform", "app.add_transform", "app.add_transform"], "code_location": {"file": "__init__.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/transforms", "start_line": 511, "end_line": 532}, "code_snippet": "def setup(app: Sphinx) -> ExtensionMetadata:\n    app.add_transform(ApplySourceWorkaround)\n    app.add_transform(ExtraTranslatableNodes)\n    app.add_transform(DefaultSubstitutions)\n    app.add_transform(MoveModuleTargets)\n    app.add_transform(HandleCodeBlocks)\n    app.add_transform(SortIds)\n    app.add_transform(DoctestTransform)\n    app.add_transform(AutoNumbering)\n    app.add_transform(AutoIndexUpgrader)\n    app.add_transform(FilterSystemMessages)\n    app.add_transform(UnreferencedFootnotesDetector)\n    app.add_transform(SphinxSmartQuotes)\n    app.add_transform(DoctreeReadEvent)\n    app.add_transform(GlossarySorter)\n    app.add_transform(ReorderConsecutiveTargetAndIndexNodes)\n\n    return {\n        'version': 'builtin',\n        'parallel_read_safe': True,\n        'parallel_write_safe': True,\n    }\n", "type": "function"}, {"name": "load_extension", "is_method": true, "class_name": "SphinxComponentRegistry", "parameters": ["self", "app", "extname"], "calls": ["logger.warning", "__", "prefixed_warnings", "getattr", "Extension", "__", "import_module", "logger.warning", "logger.verbose", "ExtensionError", "__", "setup", "isinstance", "logger.warning", "VersionRequirementError", "__", "__", "traceback.format_exc", "__", "__"], "code_location": {"file": "registry.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx", "start_line": 524, "end_line": 587}, "code_snippet": "    def load_extension(self, app: Sphinx, extname: str) -> None:\n        \"\"\"Load a Sphinx extension.\"\"\"\n        if extname in app.extensions:  # already loaded\n            return\n        if extname in EXTENSION_BLACKLIST:\n            logger.warning(\n                __(\n                    'the extension %r was already merged with Sphinx since '\n                    'version %s; this extension is ignored.'\n                ),\n                extname,\n                EXTENSION_BLACKLIST[extname],\n            )\n            return\n\n        # update loading context\n        prefix = __('while setting up extension %s:') % extname\n        with prefixed_warnings(prefix):\n            try:\n                mod = import_module(extname)\n            except ImportError as err:\n                logger.verbose(__('Original exception:\\n') + traceback.format_exc())\n                raise ExtensionError(\n                    __('Could not import extension %s') % extname, err\n                ) from err\n\n            setup: _ExtensionSetupFunc | None = getattr(mod, 'setup', None)\n            if setup is None:\n                logger.warning(\n                    __(\n                        'extension %r has no setup() function; is it really '\n                        'a Sphinx extension module?'\n                    ),\n                    extname,\n                )\n                metadata: ExtensionMetadata = {}\n            else:\n                try:\n                    metadata = setup(app)\n                except VersionRequirementError as err:\n                    # add the extension name to the version required\n                    raise VersionRequirementError(\n                        __(\n                            'The %s extension used by this project needs at least '\n                            'Sphinx v%s; it therefore cannot be built with this '\n                            'version.'\n                        )\n                        % (extname, err),\n                    ) from err\n\n            if metadata is None:\n                metadata = {}\n            elif not isinstance(metadata, dict):\n                logger.warning(\n                    __(\n                        'extension %r returned an unsupported object from '\n                        'its setup() function; it should return None or a '\n                        'metadata dictionary'\n                    ),\n                    extname,\n                )\n                metadata = {}\n\n            app.extensions[extname] = Extension(extname, mod, **metadata)\n", "type": "function"}, {"name": "setup", "is_method": false, "class_name": null, "parameters": ["app"], "calls": ["app.add_builder"], "code_location": {"file": "dummy.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/builders", "start_line": 39, "end_line": 46}, "code_snippet": "def setup(app: Sphinx) -> ExtensionMetadata:\n    app.add_builder(DummyBuilder)\n\n    return {\n        'version': 'builtin',\n        'parallel_read_safe': True,\n        'parallel_write_safe': True,\n    }\n", "type": "function"}, {"name": "Sphinx", "docstring": "The main application class and extensibility interface.\n\n:ivar srcdir: Directory containing source.\n:ivar confdir: Directory containing ``conf.py``.\n:ivar doctreedir: Directory for storing pickled doctrees.\n:ivar outdir: Directory for storing build documents.", "methods": ["__init__", "fresh_env_used", "phase", "_init_i18n", "_init_env", "_create_fresh_env", "_load_existing_env", "_post_init_env", "preload_builder", "create_builder", "_init_builder", "build", "setup_extension", "require_sphinx", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "disconnect", "emit", "emit_firstresult", "add_builder", "add_config_value", "add_event", "set_translator", "add_node", "add_enumerable_node", "add_directive", "add_role", "add_generic_role", "add_domain", "add_directive_to_domain", "add_role_to_domain", "add_index_to_domain", "add_object_type", "add_crossref_type", "add_transform", "add_post_transform", "add_js_file", "add_css_file", "add_latex_package", "add_lexer", "add_autodocumenter", "add_autodoc_attrgetter", "add_search_language", "add_source_suffix", "add_source_parser", "add_env_collector", "add_html_theme", "add_html_math_renderer", "add_message_catalog", "is_parallel_allowed", "set_html_assets_policy"], "attributes": ["srcdir", "confdir", "outdir", "doctreedir"], "code_location": {"file": "application.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx", "start_line": 142, "end_line": 1822}, "type": "class"}, {"name": "setup", "is_method": false, "class_name": null, "parameters": ["app"], "calls": ["app.add_env_collector"], "code_location": {"file": "dependencies.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/environment/collectors", "start_line": 53, "end_line": 60}, "code_snippet": "def setup(app: Sphinx) -> ExtensionMetadata:\n    app.add_env_collector(DependenciesCollector)\n\n    return {\n        'version': 'builtin',\n        'parallel_read_safe': True,\n        'parallel_write_safe': True,\n    }\n", "type": "function"}], "retrieved_count": 10, "cost_time": 1.3533639907836914}
{"question": "Where in Sphinx is the cross-reference system implemented?", "answer": null, "relative_code_list": null, "ground_truth": "Sphinx's cross-reference system is implemented across multiple components and modules throughout the codebase, with different parts handling various aspects of cross-reference functionality. The system is designed to be extensible and domain-specific.\n\nKey locations where the cross-reference system is implemented include:\n\n1. **sphinx/roles.py**: Contains the XRefRole class and other cross-reference role implementations that handle the creation of cross-reference nodes in documents. This includes the core logic for processing cross-reference markup.\n\n2. **sphinx/domains/__init__.py**: The Domain base class provides the framework for domain-specific cross-reference resolution. Each domain (Python, C++, etc.) implements its own cross-reference logic through the `resolve_xref` method.\n\n3. **sphinx/domains/python.py**: Contains the Python domain implementation with specific cross-reference resolution logic for Python objects like functions, classes, modules, etc.\n\n4. **sphinx/domains/cpp.py**: Contains the C++ domain implementation with cross-reference resolution for C++ objects like classes, functions, namespaces, etc.\n\n5. **sphinx/transforms/__init__.py**: Contains transform implementations that handle cross-reference resolution during the document processing pipeline, including the SphinxTransformer class.\n\n6. **sphinx/transforms/references.py**: Contains specific transforms for handling cross-reference resolution, including the ReferenceResolver transform that processes pending cross-reference nodes.\n\n7. **sphinx/environment/__init__.py**: The BuildEnvironment class manages cross-reference data and metadata, storing information about documented objects that can be referenced across documents.\n\n8. **sphinx/environment/collectors/**: Contains collector implementations that gather cross-reference information during document processing, including the TitleCollector and other metadata collectors.\n\n9. **sphinx/ext/intersphinx/**: Contains the intersphinx extension that enables cross-references between different Sphinx projects.\n\n10. **sphinx/util/docutils.py**: Contains utility functions for cross-reference processing, including the ReferenceRole base class that provides common functionality for cross-reference roles.\n\nThe cross-reference system integrates with Sphinx's event system, allowing extensions to hook into the cross-reference resolution process and add custom cross-reference types or modify existing resolution logic.", "score": null, "retrieved_content": [{"name": "ReferencesResolver", "docstring": "Resolves cross-references on doctrees.", "methods": ["run", "_resolve_pending_xref", "_resolve_pending_xref_in_domain", "_resolve_pending_any_xref", "_stringify", "warn_missing_reference", "find_pending_xref_condition"], "attributes": ["default_priority"], "code_location": {"file": "__init__.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/transforms/post_transforms", "start_line": 62, "end_line": 309}, "type": "class"}, {"name": "resolve_xref", "is_method": true, "class_name": "StandardDomain", "parameters": ["self", "env", "fromdocname", "builder", "typ", "target", "node", "contnode"], "calls": ["resolver"], "code_location": {"file": "__init__.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/domains/std", "start_line": 1033, "end_line": 1058}, "code_snippet": "    def resolve_xref(\n        self,\n        env: BuildEnvironment,\n        fromdocname: str,\n        builder: Builder,\n        typ: str,\n        target: str,\n        node: pending_xref,\n        contnode: Element,\n    ) -> nodes.reference | None:\n        if typ == 'ref':\n            resolver = self._resolve_ref_xref\n        elif typ == 'numref':\n            resolver = self._resolve_numref_xref  # type: ignore[assignment]\n        elif typ == 'keyword':\n            resolver = self._resolve_keyword_xref\n        elif typ == 'doc':\n            resolver = self._resolve_doc_xref\n        elif typ == 'option':\n            resolver = self._resolve_option_xref\n        elif typ == 'term':\n            resolver = self._resolve_term_xref\n        else:\n            resolver = self._resolve_obj_xref\n\n        return resolver(env, fromdocname, builder, typ, target, node, contnode)\n", "type": "function"}, {"name": "PyXRefRole", "docstring": "", "methods": ["process_link"], "attributes": [], "code_location": {"file": "__init__.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/domains/python", "start_line": 569, "end_line": 595}, "type": "class"}, {"name": "SphinxDomains", "docstring": "Collect objects to Sphinx domains for cross references.", "methods": ["apply"], "attributes": ["default_priority"], "code_location": {"file": "references.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/transforms", "start_line": 33, "end_line": 41}, "type": "class"}, {"name": "pending_xref", "docstring": "Node for cross-references that cannot be resolved without complete\ninformation about all documents.\n\nThese nodes are resolved before writing output, in\nBuildEnvironment.resolve_references.", "methods": [], "attributes": ["child_text_separator"], "code_location": {"file": "addnodes.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx", "start_line": 493, "end_line": 501}, "type": "class"}, {"name": "CXRefRole", "docstring": "", "methods": ["process_link"], "attributes": [], "code_location": {"file": "__init__.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/domains/c", "start_line": 704, "end_line": 729}, "type": "class"}, {"name": "resolve_xref", "is_method": true, "class_name": "CitationDomain", "parameters": ["self", "env", "fromdocname", "builder", "typ", "target", "node", "contnode"], "calls": ["self.citations.get", "make_refnode"], "code_location": {"file": "citation.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/domains", "start_line": 99, "end_line": 113}, "code_snippet": "    def resolve_xref(\n        self,\n        env: BuildEnvironment,\n        fromdocname: str,\n        builder: Builder,\n        typ: str,\n        target: str,\n        node: pending_xref,\n        contnode: Element,\n    ) -> nodes.reference | None:\n        docname, labelid, _lineno = self.citations.get(target, ('', '', 0))\n        if not docname:\n            return None\n\n        return make_refnode(builder, fromdocname, docname, labelid, contnode)\n", "type": "function"}, {"name": "resolve_xref", "is_method": true, "class_name": "CDomain", "parameters": ["self", "env", "fromdocname", "builder", "typ", "target", "node", "contnode"], "calls": ["self._resolve_xref_inner"], "code_location": {"file": "__init__.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/domains/c", "start_line": 927, "end_line": 939}, "code_snippet": "    def resolve_xref(\n        self,\n        env: BuildEnvironment,\n        fromdocname: str,\n        builder: Builder,\n        typ: str,\n        target: str,\n        node: pending_xref,\n        contnode: Element,\n    ) -> nodes.reference | None:\n        return self._resolve_xref_inner(\n            env, fromdocname, builder, typ, target, node, contnode\n        )[0]\n", "type": "function"}, {"name": "resolve_xref", "is_method": true, "class_name": "CPPDomain", "parameters": ["self", "env", "fromdocname", "builder", "typ", "target", "node", "contnode"], "calls": ["self._resolve_xref_inner"], "code_location": {"file": "__init__.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/domains/cpp", "start_line": 1242, "end_line": 1254}, "code_snippet": "    def resolve_xref(\n        self,\n        env: BuildEnvironment,\n        fromdocname: str,\n        builder: Builder,\n        typ: str,\n        target: str,\n        node: pending_xref,\n        contnode: Element,\n    ) -> nodes.reference | None:\n        return self._resolve_xref_inner(\n            env, fromdocname, builder, typ, target, node, contnode\n        )[0]\n", "type": "function"}, {"name": "_resolve_xref_inner", "is_method": true, "class_name": "CDomain", "parameters": ["self", "env", "fromdocname", "builder", "typ", "target", "node", "contnode"], "calls": ["DefinitionParser", "node.get", "parent_symbol.find_declaration", "name.get_display_string", "parser.parse_xref_object", "root_symbol.direct_lookup", "make_refnode", "logger.warning", "logger.debug", "logger.debug", "logger.debug", "declaration.get_newest_id", "root_symbol.dump"], "code_location": {"file": "__init__.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/domains/c", "start_line": 876, "end_line": 925}, "code_snippet": "    def _resolve_xref_inner(\n        self,\n        env: BuildEnvironment,\n        fromdocname: str,\n        builder: Builder,\n        typ: str,\n        target: str,\n        node: pending_xref,\n        contnode: Element,\n    ) -> tuple[nodes.reference, str] | tuple[None, None]:\n        parser = DefinitionParser(target, location=node, config=env.config)\n        try:\n            name = parser.parse_xref_object()\n        except DefinitionError as e:\n            logger.warning(\n                'Unparseable C cross-reference: %r\\n%s', target, e, location=node\n            )\n            return None, None\n        parent_key: LookupKey | None = node.get('c:parent_key', None)\n        root_symbol = self.data['root_symbol']\n        if parent_key:\n            parent_symbol: Symbol = root_symbol.direct_lookup(parent_key)\n            if not parent_symbol:\n                logger.debug('Target: %s', target)\n                logger.debug('ParentKey: %s', parent_key)\n                logger.debug(root_symbol.dump(1))\n            assert parent_symbol  # should be there\n        else:\n            parent_symbol = root_symbol\n        s = parent_symbol.find_declaration(\n            name, typ, matchSelf=True, recurseInAnon=True\n        )\n        if s is None or s.declaration is None:\n            return None, None\n\n        # TODO: check role type vs. object type\n\n        declaration = s.declaration\n        display_name = name.get_display_string()\n        docname = s.docname\n        assert docname\n\n        return make_refnode(\n            builder,\n            fromdocname,\n            docname,\n            declaration.get_newest_id(),\n            contnode,\n            display_name,\n        ), declaration.objectType\n", "type": "function"}], "retrieved_count": 10, "cost_time": 1.358612298965454}
{"question": "Why does Sphinx's caching strategy optimize build time versus memory consumption trade-offs?", "answer": null, "relative_code_list": null, "ground_truth": "Sphinx's caching strategy optimizes build time versus memory consumption trade-offs through a sophisticated multi-level caching system that balances performance benefits with resource constraints. This approach provides optimal performance while managing memory usage effectively.\n\nKey aspects of Sphinx's caching strategy include:\n\n1. **Selective Caching**: Sphinx caches the most expensive-to-compute data (like parsed document trees and cross-reference metadata) while avoiding caching of easily regenerated information, optimizing the memory-to-performance ratio.\n\n2. **Environment Persistence**: The build environment, which contains cross-references, metadata, and document relationships, is cached as a pickle file. This provides significant build time savings while using a reasonable amount of disk space.\n\n3. **Document Tree Caching**: Parsed document trees are cached to avoid expensive re-parsing of unchanged files. The system uses disk-based caching to avoid keeping all document trees in memory simultaneously.\n\n4. **Memory Management**: Sphinx clears in-memory caches when serializing the environment to disk, reducing memory consumption while preserving the performance benefits of caching.\n\n5. **Incremental Cache Updates**: The caching system only updates cached data for files that have actually changed, minimizing both cache update time and memory usage.\n\n6. **Configurable Cache Levels**: Different types of data are cached at different levels (memory vs. disk) based on their access patterns and regeneration costs, optimizing the trade-off between speed and memory usage.\n\n7. **Cache Invalidation**: The system intelligently invalidates cached data when dependencies change, ensuring consistency while avoiding unnecessary cache rebuilds.\n\n8. **Resource-Aware Caching**: The caching strategy takes into account available system resources, allowing it to adapt to different system configurations and project sizes.\n\nThis multi-level approach allows Sphinx to provide significant build time improvements while keeping memory usage within reasonable bounds, making it suitable for both small and large documentation projects.", "score": null, "retrieved_content": [{"name": "__init__", "is_method": true, "class_name": "BuildEnvironment", "parameters": ["self", "app"], "calls": ["_get_env_version", "default_settings.copy", "defaultdict", "defaultdict", "set", "defaultdict", "set", "set", "FilenameUniqDict", "DownloadFiles", "_CurrentDocument", "_DomainsContainer._from_environment", "self.setup"], "code_location": {"file": "__init__.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/environment", "start_line": 114, "end_line": 239}, "code_snippet": "    def __init__(self, app: Sphinx) -> None:\n        self._app: Sphinx = app\n        self.doctreedir = app.doctreedir\n        self.srcdir = app.srcdir\n        self.config: Config = None  # type: ignore[assignment]\n        self.config_status: int = CONFIG_UNSET\n        self.config_status_extra: str = ''\n        self.events: EventManager = app.events\n        self.project: Project = app.project\n        self.version: Mapping[str, int] = _get_env_version(app.extensions)\n\n        # the method of doctree versioning; see set_versioning_method\n        self.versioning_condition: Literal[False] | Callable[[Node], bool] | None = None\n        self.versioning_compare: bool | None = None\n\n        # the docutils settings for building\n        self.settings: dict[str, Any] = default_settings.copy()\n        self.settings['env'] = self\n\n        # All \"docnames\" here are /-separated and relative and exclude\n        # the source suffix.\n\n        # docname -> time of reading (in integer microseconds)\n        # contains all read docnames\n        self.all_docs: dict[str, int] = {}\n        # docname -> set of dependent file\n        # names, relative to documentation root\n        self.dependencies: dict[str, set[_StrPath]] = defaultdict(set)\n        # docname -> set of included file\n        # docnames included from other documents\n        self.included: dict[str, set[str]] = defaultdict(set)\n        # docnames to re-read unconditionally on next build\n        self.reread_always: set[str] = set()\n\n        self._pickled_doctree_cache: dict[str, bytes] = {}\n        \"\"\"In-memory cache for reading pickled doctrees from disk.\n        docname -> pickled doctree\n\n        This cache is used in the ``get_doctree`` method to avoid reading the\n        doctree from disk multiple times.\n        \"\"\"\n\n        self._write_doc_doctree_cache: dict[str, nodes.document] = {}\n        \"\"\"In-memory cache for unpickling doctrees from disk.\n        docname -> doctree\n\n        Items are added in ``Builder.write_doctree``, during the read phase,\n        then used only in the ``get_and_resolve_doctree`` method.\n        \"\"\"\n\n        # File metadata\n        # docname -> dict of metadata items\n        self.metadata: dict[str, dict[str, Any]] = defaultdict(dict)\n\n        # TOC inventory\n        # docname -> title node\n        self.titles: dict[str, nodes.title] = {}\n        # docname -> title node; only different if\n        # set differently with title directive\n        self.longtitles: dict[str, nodes.title] = {}\n        # docname -> table of contents nodetree\n        self.tocs: dict[str, nodes.bullet_list] = {}\n        # docname -> number of real entries\n        self.toc_num_entries: dict[str, int] = {}\n\n        # used to determine when to show the TOC\n        # in a sidebar (don't show if it's only one item)\n        # docname -> dict of sectionid -> number\n        self.toc_secnumbers: dict[str, dict[str, tuple[int, ...]]] = {}\n        # docname -> dict of figtype -> dict of figureid -> number\n        self.toc_fignumbers: dict[str, dict[str, dict[str, tuple[int, ...]]]] = {}\n\n        # docname -> list of toctree includefiles\n        self.toctree_includes: dict[str, list[str]] = {}\n        # docname -> set of files (containing its TOCs) to rebuild too\n        self.files_to_rebuild: dict[str, set[str]] = {}\n        # docnames that have :glob: toctrees\n        self.glob_toctrees: set[str] = set()\n        # docnames that have :numbered: toctrees\n        self.numbered_toctrees: set[str] = set()\n\n        # domain-specific inventories, here to be pickled\n        # domainname -> domain-specific dict\n        self.domaindata: dict[str, dict[str, Any]] = {}\n\n        # these map absolute path -> (docnames, unique filename)\n        self.images: FilenameUniqDict = FilenameUniqDict()\n        # filename -> (set of docnames, destination)\n        self.dlfiles: DownloadFiles = DownloadFiles()\n\n        # the original URI for images\n        self.original_image_uri: dict[_StrPath, str] = {}\n\n        # temporary data storage while reading a document\n        self.current_document: _CurrentDocument = _CurrentDocument()\n        # context for cross-references (e.g. current module or class)\n        # this is similar to ``self.current_document``,\n        # but will for example be copied to attributes of \"any\" cross references\n        self.ref_context: dict[str, Any] = {}\n\n        # search index data\n\n        # docname -> title\n        self._search_index_titles: dict[str, str | None] = {}\n        # docname -> filename\n        self._search_index_filenames: dict[str, str] = {}\n        # stemmed words -> set(docname)\n        self._search_index_mapping: dict[str, set[str]] = {}\n        # stemmed words in titles -> set(docname)\n        self._search_index_title_mapping: dict[str, set[str]] = {}\n        # docname -> all titles in document\n        self._search_index_all_titles: dict[str, list[tuple[str, str | None]]] = {}\n        # docname -> list(index entry)\n        self._search_index_index_entries: dict[str, list[tuple[str, str, str]]] = {}\n        # objtype -> index\n        self._search_index_objtypes: dict[tuple[str, str], int] = {}\n        # objtype index -> (domain, type, objname (localized))\n        self._search_index_objnames: dict[int, tuple[str, str, str]] = {}\n\n        # all the registered domains, set by the application\n        self.domains: _DomainsContainer = _DomainsContainer._from_environment(\n            self, registry=app.registry\n        )\n\n        # set up environment\n        self.setup(app)\n", "type": "function"}, {"name": "write_doctree", "is_method": true, "class_name": "Builder", "parameters": ["self", "docname", "doctree"], "calls": ["doctree.settings.copy", "doctree_filename.parent.mkdir", "open", "pickle.dump"], "code_location": {"file": "__init__.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/builders", "start_line": 681, "end_line": 709}, "code_snippet": "    def write_doctree(\n        self,\n        docname: str,\n        doctree: nodes.document,\n        *,\n        _cache: bool = True,\n    ) -> None:\n        \"\"\"Write the doctree to a file, to be used as a cache by re-builds.\"\"\"\n        # make it pickleable\n        doctree.reporter = None  # type: ignore[assignment]\n        doctree.transformer = None  # type: ignore[assignment]\n\n        # Create a copy of settings object before modification because it is\n        # shared with other documents.\n        doctree.settings = doctree.settings.copy()\n        doctree.settings.warning_stream = None\n        doctree.settings.env = None\n        doctree.settings.record_dependencies = None\n\n        doctree_filename = self.doctreedir / f'{docname}.doctree'\n        doctree_filename.parent.mkdir(parents=True, exist_ok=True)\n        with open(doctree_filename, 'wb') as f:\n            pickle.dump(doctree, f, pickle.HIGHEST_PROTOCOL)\n\n        # When Sphinx is running in parallel mode, ``write_doctree()`` is invoked\n        # in the context of a process worker, and thus it does not make sense to\n        # pickle the doctree and send it to the main process\n        if _cache:\n            self.env._write_doc_doctree_cache[docname] = doctree\n", "type": "function"}, {"name": "BuildPhase", "docstring": "Build phase of Sphinx application.", "methods": [], "attributes": ["INITIALIZATION", "READING", "CONSISTENCY_CHECK", "RESOLVING", "WRITING"], "code_location": {"file": "build_phase.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/util", "start_line": 8, "end_line": 15}, "type": "class"}, {"name": "SphinxTestAppWrapperForSkipBuilding", "docstring": "A wrapper for SphinxTestApp.\n\nThis class is used to speed up the test by skipping ``app.build()``\nif it has already been built and there are any output files.", "methods": ["build"], "attributes": [], "code_location": {"file": "util.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/testing", "start_line": 240, "end_line": 250}, "type": "class"}, {"name": "Sphinx", "docstring": "The main application class and extensibility interface.\n\n:ivar srcdir: Directory containing source.\n:ivar confdir: Directory containing ``conf.py``.\n:ivar doctreedir: Directory for storing pickled doctrees.\n:ivar outdir: Directory for storing build documents.", "methods": ["__init__", "fresh_env_used", "phase", "_init_i18n", "_init_env", "_create_fresh_env", "_load_existing_env", "_post_init_env", "preload_builder", "create_builder", "_init_builder", "build", "setup_extension", "require_sphinx", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "disconnect", "emit", "emit_firstresult", "add_builder", "add_config_value", "add_event", "set_translator", "add_node", "add_enumerable_node", "add_directive", "add_role", "add_generic_role", "add_domain", "add_directive_to_domain", "add_role_to_domain", "add_index_to_domain", "add_object_type", "add_crossref_type", "add_transform", "add_post_transform", "add_js_file", "add_css_file", "add_latex_package", "add_lexer", "add_autodocumenter", "add_autodoc_attrgetter", "add_search_language", "add_source_suffix", "add_source_parser", "add_env_collector", "add_html_theme", "add_html_math_renderer", "add_message_catalog", "is_parallel_allowed", "set_html_assets_policy"], "attributes": ["srcdir", "confdir", "outdir", "doctreedir"], "code_location": {"file": "application.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx", "start_line": 142, "end_line": 1822}, "type": "class"}, {"name": "cache", "is_method": true, "class_name": "InventoryAdapter", "parameters": ["self"], "calls": [], "code_location": {"file": "_shared.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/ext/intersphinx", "start_line": 128, "end_line": 136}, "code_snippet": "    def cache(self) -> dict[InventoryURI, InventoryCacheEntry]:\n        \"\"\"Intersphinx cache.\n\n        - Key is the URI of the remote inventory.\n        - Element one is the key given in the Sphinx :confval:`intersphinx_mapping`.\n        - Element two is a time value for cache invalidation, an integer.\n        - Element three is the loaded remote inventory of type :class:`!Inventory`.\n        \"\"\"\n        return self.env.intersphinx_cache  # type: ignore[attr-defined]\n", "type": "function"}, {"name": "build", "is_method": true, "class_name": "SphinxTestApp", "parameters": ["self", "force_all", "filenames"], "calls": ["self.env._pickled_doctree_cache.clear", "build", "super"], "code_location": {"file": "util.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/testing", "start_line": 235, "end_line": 237}, "code_snippet": "    def build(self, force_all: bool = False, filenames: Sequence[Path] = ()) -> None:\n        self.env._pickled_doctree_cache.clear()\n        super().build(force_all, filenames)\n", "type": "function"}, {"name": "test_load_mappings_cache", "is_method": false, "class_name": null, "parameters": ["tmp_path"], "calls": ["touch", "touch", "SingleEntryProject", "make_inventory_handler", "project.make_entry", "dict", "InventoryAdapter", "http_server", "SphinxTestApp", "app.build", "app.cleanup", "list", "tmp_path.joinpath", "tmp_path.joinpath", "project.normalise"], "code_location": {"file": "test_ext_intersphinx_cache.py", "path": "/data3/pwh/swebench-repos/sphinx/tests/test_extensions", "start_line": 228, "end_line": 249}, "code_snippet": "def test_load_mappings_cache(tmp_path):\n    tmp_path.joinpath('conf.py').touch()\n    tmp_path.joinpath('index.rst').touch()\n    project = SingleEntryProject(1, 'a')\n\n    InventoryHandler = make_inventory_handler(project)\n    with http_server(InventoryHandler, port=project.port):\n        # clean build\n        confoverrides = BASE_CONFIG | {'intersphinx_mapping': project.record}\n        app = SphinxTestApp('dummy', srcdir=tmp_path, confoverrides=confoverrides)\n        app.build()\n        app.cleanup()\n\n    # the inventory when querying the 'old' URL\n    entry = project.make_entry()\n    item = dict((project.normalise(entry),))\n    inventories = InventoryAdapter(app.env)\n    assert list(inventories.cache) == ['http://localhost:9341/a']\n    e_name, _e_time, e_inv = inventories.cache['http://localhost:9341/a']\n    assert e_name == 'spam'\n    assert e_inv == {'py:module': item}\n    assert inventories.named_inventory == {'spam': {'py:module': item}}\n", "type": "function"}, {"name": "build_main", "is_method": false, "class_name": null, "parameters": ["argv"], "calls": ["get_parser", "_parse_arguments", "_parse_confdir", "_parse_doctreedir", "_validate_filenames", "_validate_colour_support", "_parse_logging", "_parse_confoverrides", "patch_docutils", "docutils_namespace", "Sphinx", "app.build", "sphinx._cli.util.errors.handle_exception", "warnfp.close", "app.extensions.values"], "code_location": {"file": "build.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/cmd", "start_line": 395, "end_line": 452}, "code_snippet": "def build_main(argv: Sequence[str]) -> int:\n    \"\"\"Sphinx build \"main\" command-line entry.\"\"\"\n    parser = get_parser()\n    args = _parse_arguments(parser, argv)\n    args.confdir = _parse_confdir(args.noconfig, args.confdir, args.sourcedir)\n    args.doctreedir = _parse_doctreedir(args.doctreedir, args.outputdir)\n    _validate_filenames(parser, args.force_all, args.filenames)\n    _validate_colour_support(args.color)\n    args.status, args.warning, args.error, warnfp = _parse_logging(\n        parser, args.quiet, args.really_quiet, args.warnfile\n    )\n    args.confoverrides = _parse_confoverrides(\n        parser, args.define, args.htmldefine, args.nitpicky\n    )\n\n    app = None\n    try:\n        confdir = args.confdir or args.sourcedir\n        with patch_docutils(confdir), docutils_namespace():\n            app = Sphinx(\n                srcdir=args.sourcedir,\n                confdir=args.confdir,\n                outdir=args.outputdir,\n                doctreedir=args.doctreedir,\n                buildername=args.builder,\n                confoverrides=args.confoverrides,\n                status=args.status,\n                warning=args.warning,\n                freshenv=args.freshenv,\n                warningiserror=args.warningiserror,\n                tags=args.tags,\n                verbosity=args.verbosity,\n                parallel=args.jobs,\n                keep_going=False,\n                pdb=args.pdb,\n                exception_on_warning=args.exception_on_warning,\n            )\n            app.build(args.force_all, args.filenames)\n            return app.statuscode\n    except (Exception, KeyboardInterrupt) as exc:\n        if app is not None:\n            message_log: Sequence[str] = app.messagelog\n            extensions: Collection[Extension] = app.extensions.values()\n        else:\n            message_log = extensions = ()\n        sphinx._cli.util.errors.handle_exception(\n            exc,\n            stderr=args.error,\n            use_pdb=args.pdb,\n            print_traceback=args.verbosity or args.traceback,\n            message_log=message_log,\n            extensions=extensions,\n        )\n        return 2\n    finally:\n        if warnfp is not None:\n            # close the file descriptor for the warnings file opened by Sphinx\n            warnfp.close()\n", "type": "function"}, {"name": "SphinxFileOutput", "docstring": "Better FileOutput class for Sphinx.", "methods": ["__init__", "write"], "attributes": [], "code_location": {"file": "docutils.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/util", "start_line": 447, "end_line": 469}, "type": "class"}], "retrieved_count": 10, "cost_time": 1.3910882472991943}
{"question": "Where does Sphinx's document processing flow from source files through parsing to final output generation?", "answer": null, "relative_code_list": null, "ground_truth": "Sphinx's document processing flow follows a well-defined pipeline from source files through parsing to final output generation, with multiple stages and components working together to transform raw documentation into finished output.\n\nThe document processing flow includes the following key stages:\n\n1. **Source File Discovery**: The process begins in the Project class, which scans the source directory to identify all source files based on configured file extensions (typically .rst files). The Project class maintains a list of all source files and their relationships.\n\n2. **Configuration Loading**: The Config class loads project configuration from conf.py, setting up all the parameters that control the build process, including extensions, theme settings, and output format options.\n\n3. **Extension Initialization**: The SphinxComponentRegistry loads and initializes all configured extensions, registering their components (directives, roles, builders, etc.) with the system.\n\n4. **Document Reading Phase**: The Builder class orchestrates the reading of source files. For each document, the system uses appropriate parsers (typically reStructuredText parsers) to convert source text into docutils document trees.\n\n5. **Transform Application**: The SphinxTransformer applies various transforms to document trees, including Sphinx-specific transforms for cross-references, indexing, and other document modifications.\n\n6. **Cross-Reference Resolution**: The BuildEnvironment manages cross-reference resolution, using domain-specific logic to resolve references to documented objects and create appropriate links.\n\n7. **Output Generation**: The Builder class coordinates with appropriate Writer classes to convert the processed document trees into the target output format (HTML, LaTeX, etc.).\n\n8. **File Writing**: The final output files are written to the output directory, with the Builder managing the overall file structure and the Writer handling format-specific content generation.\n\nThis flow is managed by the main Sphinx application class, which coordinates all components and ensures that each stage is completed before moving to the next, while providing extension points throughout the process for customization and enhancement.", "score": null, "retrieved_content": [{"name": "Sphinx", "docstring": "The main application class and extensibility interface.\n\n:ivar srcdir: Directory containing source.\n:ivar confdir: Directory containing ``conf.py``.\n:ivar doctreedir: Directory for storing pickled doctrees.\n:ivar outdir: Directory for storing build documents.", "methods": ["__init__", "fresh_env_used", "phase", "_init_i18n", "_init_env", "_create_fresh_env", "_load_existing_env", "_post_init_env", "preload_builder", "create_builder", "_init_builder", "build", "setup_extension", "require_sphinx", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "disconnect", "emit", "emit_firstresult", "add_builder", "add_config_value", "add_event", "set_translator", "add_node", "add_enumerable_node", "add_directive", "add_role", "add_generic_role", "add_domain", "add_directive_to_domain", "add_role_to_domain", "add_index_to_domain", "add_object_type", "add_crossref_type", "add_transform", "add_post_transform", "add_js_file", "add_css_file", "add_latex_package", "add_lexer", "add_autodocumenter", "add_autodoc_attrgetter", "add_search_language", "add_source_suffix", "add_source_parser", "add_env_collector", "add_html_theme", "add_html_math_renderer", "add_message_catalog", "is_parallel_allowed", "set_html_assets_policy"], "attributes": ["srcdir", "confdir", "outdir", "doctreedir"], "code_location": {"file": "application.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx", "start_line": 142, "end_line": 1822}, "type": "class"}, {"name": "Parser", "docstring": "A base class for source parsers.\n\nAdditional parsers should inherit from this class instead of\n``docutils.parsers.Parser``.\nThis class provides access to core Sphinx objects; *config* and *env*.", "methods": ["config", "env", "set_application", "__init__", "parse", "parse_comments", "parse_definition", "parse", "get_transforms"], "attributes": ["supported"], "code_location": {"file": "parsers.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx", "start_line": 26, "end_line": 62}, "type": "class"}, {"name": "SphinxStandaloneReader", "docstring": "A basic document reader for Sphinx.", "methods": ["__init__", "_setup_transforms", "read", "read_source"], "attributes": [], "code_location": {"file": "io.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx", "start_line": 79, "end_line": 109}, "type": "class"}, {"name": "create_source_parser", "is_method": true, "class_name": "SphinxComponentRegistry", "parameters": ["self", "filename"], "calls": ["self.get_source_parser", "parser_class", "isinstance"], "code_location": {"file": "registry.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx", "start_line": 373, "end_line": 381}, "code_snippet": "    def create_source_parser(\n        self, filename: str, *, config: Config, env: BuildEnvironment\n    ) -> Parser:\n        parser_class = self.get_source_parser(filename)\n        parser = parser_class()\n        if isinstance(parser, SphinxParser):\n            parser._config = config\n            parser._env = env\n        return parser\n", "type": "function"}, {"name": "_doctree_for_test", "is_method": false, "class_name": null, "parameters": ["app", "env", "docname"], "calls": ["env.doc2path", "filename.read_text", "env.prepare_settings", "registry.create_source_parser", "_parse_str_to_doctree", "registry.get_transforms"], "code_location": {"file": "test_directive_object_description.py", "path": "/data3/pwh/swebench-repos/sphinx/tests/test_directives", "start_line": 21, "end_line": 39}, "code_snippet": "def _doctree_for_test(\n    app: Sphinx, env: BuildEnvironment, docname: str\n) -> nodes.document:\n    config = app.config\n    registry = app.registry\n\n    filename = env.doc2path(docname)\n    content = filename.read_text(encoding='utf-8')\n\n    env.prepare_settings(docname)\n    parser = registry.create_source_parser('restructuredtext', config=config, env=env)\n    return _parse_str_to_doctree(\n        content,\n        filename=filename,\n        default_settings={'env': env},\n        env=env,\n        parser=parser,\n        transforms=registry.get_transforms(),\n    )\n", "type": "function"}, {"name": "parse", "is_method": true, "class_name": "RSTParser", "parameters": ["self", "inputstring", "document"], "calls": ["self.setup_parse", "states.RSTStateMachine", "isinstance", "self.decorate", "self.statemachine.run", "self.finish_parse", "docutils.statemachine.string2lines", "StringList"], "code_location": {"file": "parsers.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx", "start_line": 77, "end_line": 100}, "code_snippet": "    def parse(self, inputstring: str | StringList, document: nodes.document) -> None:\n        \"\"\"Parse text and generate a document tree.\"\"\"\n        self.setup_parse(inputstring, document)  # type: ignore[arg-type]\n        self.statemachine = states.RSTStateMachine(\n            state_classes=self.state_classes,\n            initial_state=self.initial_state,\n            debug=document.reporter.debug_flag,\n        )\n\n        # preprocess inputstring\n        if isinstance(inputstring, str):\n            lines = docutils.statemachine.string2lines(\n                inputstring,\n                tab_width=document.settings.tab_width,\n                convert_whitespace=True,\n            )\n\n            inputlines = StringList(lines, document.current_source)\n        else:\n            inputlines = inputstring\n\n        self.decorate(inputlines)\n        self.statemachine.run(inputlines, document, inliner=self.inliner)\n        self.finish_parse()\n", "type": "function"}, {"name": "_parse_str_to_doctree", "is_method": false, "class_name": null, "parameters": ["content"], "calls": ["_get_settings", "str", "LoggingReporter", "nodes.document", "document.note_source", "SphinxTransformer", "transformer.add_transforms", "transformer.add_transforms", "transformer.add_transforms", "str", "parser.get_transforms", "rst.default_role", "nullcontext", "sphinx_domains", "parser.parse", "transformer.apply_transforms", "str", "str", "events.emit"], "code_location": {"file": "docutils.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/util", "start_line": 837, "end_line": 896}, "code_snippet": "def _parse_str_to_doctree(\n    content: str,\n    *,\n    filename: Path,\n    default_role: str = '',\n    default_settings: Mapping[str, Any],\n    env: BuildEnvironment,\n    events: EventManager | None = None,\n    parser: Parser,\n    transforms: Sequence[type[Transform]] = (),\n) -> nodes.document:\n    env.current_document._parser = parser\n\n    # Propagate exceptions by default when used programmatically:\n    defaults = {'traceback': True, **default_settings}\n    settings = _get_settings(\n        standalone.Reader, parser, defaults=defaults, read_config_files=True\n    )\n    settings._source = str(filename)\n\n    # Create root document node\n    reporter = LoggingReporter(\n        source=str(filename),\n        report_level=settings.report_level,\n        halt_level=settings.halt_level,\n        debug=settings.debug,\n        error_handler=settings.error_encoding_error_handler,\n    )\n    document = nodes.document(settings, reporter, source=str(filename))\n    document.note_source(str(filename), -1)\n\n    # substitute transformer\n    document.transformer = transformer = SphinxTransformer(document)\n    transformer.add_transforms(_READER_TRANSFORMS)\n    transformer.add_transforms(transforms)\n    transformer.add_transforms(parser.get_transforms())\n\n    if default_role:\n        default_role_cm = rst.default_role(env.current_document.docname, default_role)\n    else:\n        default_role_cm = nullcontext()  # type: ignore[assignment]\n    with sphinx_domains(env), default_role_cm:\n        # TODO: Move the stanza below to Builder.read_doc(), within\n        #       a sphinx_domains() context manager.\n        #       This will require changes to IntersphinxDispatcher and/or\n        #       CustomReSTDispatcher.\n        if events is not None:\n            # emit \"source-read\" event\n            arg = [content]\n            events.emit('source-read', env.current_document.docname, arg)\n            content = arg[0]\n\n        # parse content to abstract syntax tree\n        parser.parse(content, document)\n        document.current_source = document.current_line = None\n\n        # run transforms\n        transformer.apply_transforms()\n\n    return document\n", "type": "function"}, {"name": "process_doc", "is_method": true, "class_name": "CPPDomain", "parameters": ["self", "env", "docname", "document"], "calls": ["logger.debug", "logger.debug", "logger.debug", "dump"], "code_location": {"file": "__init__.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/domains/cpp", "start_line": 1025, "end_line": 1031}, "code_snippet": "    def process_doc(\n        self, env: BuildEnvironment, docname: str, document: nodes.document\n    ) -> None:\n        if Symbol.debug_show_tree:\n            logger.debug('process_doc: %s', docname)\n            logger.debug(self.data['root_symbol'].dump(0))\n            logger.debug('process_doc end: %s', docname)\n", "type": "function"}, {"name": "_read_serial", "is_method": true, "class_name": "Builder", "parameters": ["self", "docnames"], "calls": ["status_iterator", "__", "len", "self.events.emit", "self.env.clear_doc", "self.read_doc"], "code_location": {"file": "__init__.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/builders", "start_line": 579, "end_line": 590}, "code_snippet": "    def _read_serial(self, docnames: list[str]) -> None:\n        for docname in status_iterator(\n            docnames,\n            __('reading sources... '),\n            'purple',\n            len(docnames),\n            self.config.verbosity,\n        ):\n            # remove all inventory entries for that file\n            self.events.emit('env-purge-doc', self.env, docname)\n            self.env.clear_doc(docname)\n            self.read_doc(docname)\n", "type": "function"}, {"name": "process_doc", "is_method": true, "class_name": "CDomain", "parameters": ["self", "env", "docname", "document"], "calls": ["logger.debug", "logger.debug", "logger.debug", "dump"], "code_location": {"file": "__init__.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/domains/c", "start_line": 844, "end_line": 850}, "code_snippet": "    def process_doc(\n        self, env: BuildEnvironment, docname: str, document: nodes.document\n    ) -> None:\n        if Symbol.debug_show_tree:\n            logger.debug('process_doc: %s', docname)\n            logger.debug(self.data['root_symbol'].dump(0))\n            logger.debug('process_doc end: %s', docname)\n", "type": "function"}], "retrieved_count": 10, "cost_time": 1.400001049041748}
{"question": "Where does the control flow when Sphinx's incremental build system determines which documents need to be rebuilt?", "answer": null, "relative_code_list": null, "ground_truth": "The control flow when Sphinx's incremental build system determines which documents need to be rebuilt follows a structured decision-making process: 1) Environment loading phase begins where Sphinx attempts to load the cached BuildEnvironment from the previous build, checking for the existence and validity of the environment pickle file, 2) Change detection phase occurs where the system compares file modification times of source files against the cached environment data to identify which files have been modified since the last build, 3) Configuration change analysis happens where Sphinx checks if the configuration file (conf.py) has been modified and determines what needs to be rebuilt based on which configuration options have changed, 4) Dependency analysis phase begins where the system analyzes the dependency graph stored in the environment to determine which documents are affected by changes to other documents, including both direct and transitive dependencies, 5) Document status evaluation occurs where each document is evaluated to determine if it needs to be rebuilt based on its own changes, dependency changes, or configuration changes, 6) Outdated document identification happens where the get_outdated_docs() method identifies which documents are outdated and need to be rebuilt, considering factors like file modification times, dependency changes, and configuration changes, 7) Build strategy determination occurs where the system decides whether to perform a full rebuild or selective rebuilding based on the scope of changes and the --fresh-env option, 8) Parallel processing coordination happens where the system determines how to distribute the rebuilding work across multiple processes if parallel processing is enabled, 9) Cache validation phase occurs where the system validates the integrity of cached doctree files and determines which cached files can be reused, 10) Error handling and fallback mechanisms are triggered if the incremental build system encounters corrupted cache files or other issues, potentially falling back to a full rebuild, 11) The control flow is coordinated through the builder's build() method which orchestrates the entire incremental build process, 12) The system provides feedback to the user about what is being rebuilt and why, helping users understand the incremental build decisions and optimize their documentation structure.", "score": null, "retrieved_content": [{"name": "_has_doc_changed", "is_method": false, "class_name": null, "parameters": ["docname"], "calls": ["_last_modified_time", "logger.debug", "doctree_path.is_file", "logger.debug", "logger.debug", "_format_rfc3339_microseconds", "_format_rfc3339_microseconds", "dep_path.is_file", "logger.debug", "_last_modified_time", "logger.debug", "_format_rfc3339_microseconds", "_format_rfc3339_microseconds"], "code_location": {"file": "__init__.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/environment", "start_line": 838, "end_line": 900}, "code_snippet": "def _has_doc_changed(\n    docname: str,\n    *,\n    filename: Path,\n    reread_always: Set[str],\n    doctreedir: Path,\n    all_docs: Mapping[str, int],\n    dependencies: Mapping[str, Set[Path]],\n) -> bool:\n    # check the \"reread always\" list\n    if docname in reread_always:\n        logger.debug('[build target] changed %r: re-read forced', docname)\n        return True\n\n    # if the doctree file is not there, rebuild\n    doctree_path = doctreedir / f'{docname}.doctree'\n    if not doctree_path.is_file():\n        logger.debug('[build target] changed %r: doctree file does not exist', docname)\n        return True\n\n    # check the mtime of the document\n    mtime = all_docs[docname]\n    new_mtime = _last_modified_time(filename)\n    if new_mtime > mtime:\n        logger.debug(\n            '[build target] changed: %r is outdated (%s -> %s)',\n            docname,\n            _format_rfc3339_microseconds(mtime),\n            _format_rfc3339_microseconds(new_mtime),\n        )\n        return True\n\n    # finally, check the mtime of dependencies\n    if docname not in dependencies:\n        return False\n    for dep_path in dependencies[docname]:\n        try:\n            dep_path_is_file = dep_path.is_file()\n        except OSError:\n            return True  # give it another chance\n        if not dep_path_is_file:\n            logger.debug(\n                '[build target] changed: %r is missing dependency %r',\n                docname,\n                dep_path,\n            )\n            return True\n\n        try:\n            dep_mtime = _last_modified_time(dep_path)\n        except OSError:\n            return True  # give it another chance\n        if dep_mtime > mtime:\n            logger.debug(\n                '[build target] changed: %r is outdated due to dependency %r (%s -> %s)',\n                docname,\n                dep_path,\n                _format_rfc3339_microseconds(mtime),\n                _format_rfc3339_microseconds(dep_mtime),\n            )\n            return True\n\n    return False\n", "type": "function"}, {"name": "get_outdated_docs", "is_method": true, "class_name": "StandaloneHTMLBuilder", "parameters": ["self"], "calls": ["BuildInfo.load", "int", "self.get_output_path", "logger.warning", "build_info_path.with_name", "_last_modified_time", "logger.debug", "_last_modified_time", "_last_modified_time", "max", "__", "shutil.move", "self.build_info.dump", "__", "logger.info", "self.templates.newest_template_mtime", "logger.info", "self.env.doc2path", "logger.debug", "self.templates.newest_template_name", "_format_rfc3339_microseconds", "_format_rfc3339_microseconds", "_format_rfc3339_microseconds", "bold", "bold", "__", "__"], "code_location": {"file": "__init__.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/builders/html", "start_line": 346, "end_line": 418}, "code_snippet": "    def get_outdated_docs(self) -> Iterator[str]:\n        build_info_path = self.outdir / '.buildinfo'\n        try:\n            build_info = BuildInfo.load(build_info_path)\n        except ValueError as exc:\n            logger.warning(__('Failed to read build info file: %r'), exc)\n        except OSError:\n            # ignore errors on reading\n            pass\n        else:\n            if self.build_info != build_info:\n                # log the mismatch and backup the old build info\n                build_info_backup = build_info_path.with_name('.buildinfo.bak')\n                try:\n                    shutil.move(build_info_path, build_info_backup)\n                    self.build_info.dump(build_info_path)\n                except OSError:\n                    pass  # ignore errors\n                else:\n                    # only log on success\n                    msg = __(\n                        'build_info mismatch, copying .buildinfo to .buildinfo.bak'\n                    )\n                    logger.info(bold(__('building [html]: ')) + msg)  # NoQA: G003\n\n                yield from self.env.found_docs\n                return\n\n        if self.templates:\n            template_mtime = int(self.templates.newest_template_mtime() * 10**6)\n            try:\n                old_mtime = _last_modified_time(build_info_path)\n            except Exception:\n                pass\n            else:\n                # Let users know they have a newer template\n                if template_mtime > old_mtime:\n                    logger.info(\n                        bold('building [html]: ')  # NoQA: G003\n                        + __(\n                            'template %s has been changed since the previous build, '\n                            'all docs will be rebuilt'\n                        ),\n                        self.templates.newest_template_name(),\n                    )\n        else:\n            template_mtime = 0\n        for docname in self.env.found_docs:\n            if docname not in self.env.all_docs:\n                logger.debug('[build target] did not in env: %r', docname)\n                yield docname\n                continue\n            target_name = self.get_output_path(docname)\n            try:\n                target_mtime = _last_modified_time(target_name)\n            except OSError:\n                target_mtime = 0\n            try:\n                doc_mtime = _last_modified_time(self.env.doc2path(docname))\n                srcmtime = max(doc_mtime, template_mtime)\n                if srcmtime > target_mtime:\n                    logger.debug(\n                        '[build target] target_name %r(%s), template(%s), docname %r(%s)',\n                        target_name,\n                        _format_rfc3339_microseconds(target_mtime),\n                        _format_rfc3339_microseconds(template_mtime),\n                        docname,\n                        _format_rfc3339_microseconds(doc_mtime),\n                    )\n                    yield docname\n            except OSError:\n                # source doesn't exist anymore\n                pass\n", "type": "function"}, {"name": "check_dependents", "is_method": true, "class_name": "BuildEnvironment", "parameters": ["self", "app", "already"], "calls": ["self.events.emit", "set", "to_rewrite.extend"], "code_location": {"file": "__init__.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/environment", "start_line": 553, "end_line": 559}, "code_snippet": "    def check_dependents(self, app: Sphinx, already: set[str]) -> Iterator[str]:\n        to_rewrite: list[str] = []\n        for docnames in self.events.emit('env-get-updated', self):\n            to_rewrite.extend(docnames)\n        for docname in set(to_rewrite):\n            if docname not in already:\n                yield docname\n", "type": "function"}, {"name": "build", "is_method": true, "class_name": "SphinxTestApp", "parameters": ["self", "force_all", "filenames"], "calls": ["self.env._pickled_doctree_cache.clear", "build", "super"], "code_location": {"file": "util.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/testing", "start_line": 235, "end_line": 237}, "code_snippet": "    def build(self, force_all: bool = False, filenames: Sequence[Path] = ()) -> None:\n        self.env._pickled_doctree_cache.clear()\n        super().build(force_all, filenames)\n", "type": "function"}, {"name": "get_outdated_docs", "is_method": true, "class_name": "XMLBuilder", "parameters": ["self"], "calls": ["_last_modified_time", "_last_modified_time", "self.env.doc2path"], "code_location": {"file": "xml.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/builders", "start_line": 39, "end_line": 55}, "code_snippet": "    def get_outdated_docs(self) -> Iterator[str]:\n        for docname in self.env.found_docs:\n            if docname not in self.env.all_docs:\n                yield docname\n                continue\n            targetname = self.outdir / (docname + self.out_suffix)\n            try:\n                targetmtime = _last_modified_time(targetname)\n            except Exception:\n                targetmtime = 0\n            try:\n                srcmtime = _last_modified_time(self.env.doc2path(docname))\n                if srcmtime > targetmtime:\n                    yield docname\n            except OSError:\n                # source doesn't exist anymore\n                pass\n", "type": "function"}, {"name": "get_outdated_docs", "is_method": true, "class_name": "TextBuilder", "parameters": ["self"], "calls": ["_last_modified_time", "_last_modified_time", "self.env.doc2path"], "code_location": {"file": "text.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/builders", "start_line": 39, "end_line": 55}, "code_snippet": "    def get_outdated_docs(self) -> Iterator[str]:\n        for docname in self.env.found_docs:\n            if docname not in self.env.all_docs:\n                yield docname\n                continue\n            targetname = self.outdir / (docname + self.out_suffix)\n            try:\n                targetmtime = _last_modified_time(targetname)\n            except Exception:\n                targetmtime = 0\n            try:\n                srcmtime = _last_modified_time(self.env.doc2path(docname))\n                if srcmtime > targetmtime:\n                    yield docname\n            except OSError:\n                # source doesn't exist anymore\n                pass\n", "type": "function"}, {"name": "test_incremental_reading", "is_method": false, "class_name": null, "parameters": ["app"], "calls": ["pytest.mark.sphinx", "app.builder.read", "write_text", "unlink", "app.builder.read", "set", "set", "sorted", "set"], "code_location": {"file": "test_incremental_reading.py", "path": "/data3/pwh/swebench-repos/sphinx/tests/test_builders", "start_line": 20, "end_line": 39}, "code_snippet": "def test_incremental_reading(app: SphinxTestApp) -> None:\n    # first reading\n    updated = app.builder.read()\n    assert set(updated) == app.env.found_docs == set(app.env.all_docs)\n    assert updated == sorted(updated)  # sorted by alphanumeric\n\n    # test if exclude_patterns works ok\n    assert 'subdir/excluded' not in app.env.found_docs\n\n    # before second reading, add, modify and remove source files\n    (app.srcdir / 'new.txt').write_text('New file\\n========\\n', encoding='utf8')\n    app.env.all_docs['index'] = 0  # mark as modified\n    (app.srcdir / 'autodoc.txt').unlink()\n\n    # second reading\n    updated = app.builder.read()\n\n    assert set(updated) == {'index', 'new'}\n    assert 'autodoc' not in app.env.all_docs\n    assert 'autodoc' not in app.env.found_docs\n", "type": "function"}, {"name": "build_update", "is_method": true, "class_name": "Builder", "parameters": ["self"], "calls": ["self.compile_update_catalogs", "self.get_outdated_docs", "isinstance", "self.build", "set", "self.build", "__", "len"], "code_location": {"file": "__init__.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/builders", "start_line": 372, "end_line": 386}, "code_snippet": "    def build_update(self) -> None:\n        \"\"\"Only rebuild what was changed or added since last build.\"\"\"\n        self.compile_update_catalogs()\n\n        to_build = self.get_outdated_docs()\n        if isinstance(to_build, str):\n            self.build(['__all__'], summary=to_build, method='update')\n        else:\n            to_build = set(to_build)\n            self.build(\n                to_build,\n                summary=__('targets for %d source files that are out of date')\n                % len(to_build),\n                method='update',\n            )\n", "type": "function"}, {"name": "test_incremental_reading_for_missing_files", "is_method": false, "class_name": null, "parameters": ["app"], "calls": ["pytest.mark.sphinx", "app.builder.read", "app.builder.read", "sys.modules.pop", "set", "set", "set"], "code_location": {"file": "test_incremental_reading.py", "path": "/data3/pwh/swebench-repos/sphinx/tests/test_builders", "start_line": 47, "end_line": 59}, "code_snippet": "def test_incremental_reading_for_missing_files(app: SphinxTestApp) -> None:\n    # first reading\n    updated = app.builder.read()\n    assert set(updated) == app.env.found_docs == set(app.env.all_docs)\n\n    # second reading\n    updated = app.builder.read()\n\n    # \"index\" is listed up to updated because it contains references\n    # to nonexisting downloadable or image files\n    assert set(updated) == {'index'}\n\n    sys.modules.pop('autodoc_fodder', None)\n", "type": "function"}, {"name": "build", "is_method": true, "class_name": "Sphinx", "parameters": ["self", "force_all", "filenames"], "calls": ["self.builder.cleanup", "self.events.emit", "logger.info", "logger.info", "self.builder.build_all", "envfile.is_file", "self.events.emit", "logger.info", "logger.info", "logger.info", "logger.info", "self.builder.build_specific", "self.builder.build_update", "envfile.unlink", "bold", "bold", "__", "bold", "__", "bold", "relpath", "__", "__", "__", "__", "__", "__"], "code_location": {"file": "application.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx", "start_line": 428, "end_line": 487}, "code_snippet": "    def build(self, force_all: bool = False, filenames: Sequence[Path] = ()) -> None:\n        self.builder.phase = BuildPhase.READING\n        try:\n            if force_all:\n                self.builder.build_all()\n            elif filenames:\n                self.builder.build_specific(filenames)\n            else:\n                self.builder.build_update()\n\n            self.events.emit('build-finished', None)\n        except Exception as err:\n            # delete the saved env to force a fresh build next time\n            envfile = self.doctreedir / ENV_PICKLE_FILENAME\n            if envfile.is_file():\n                envfile.unlink()\n            self.events.emit('build-finished', err)\n            raise\n\n        if self._warncount == 0:\n            if self.statuscode != 0:\n                logger.info(bold(__('build finished with problems.')))\n            else:\n                logger.info(bold(__('build succeeded.')))\n        elif self._warncount == 1:\n            if self._fail_on_warnings:\n                self.statuscode = 1\n                msg = __(\n                    'build finished with problems, 1 warning '\n                    '(with warnings treated as errors).'\n                )\n            elif self.statuscode != 0:\n                msg = __('build finished with problems, 1 warning.')\n            else:\n                msg = __('build succeeded, 1 warning.')\n            logger.info(bold(msg))\n        else:\n            if self._fail_on_warnings:\n                self.statuscode = 1\n                msg = __(\n                    'build finished with problems, %s warnings '\n                    '(with warnings treated as errors).'\n                )\n            elif self.statuscode != 0:\n                msg = __('build finished with problems, %s warnings.')\n            else:\n                msg = __('build succeeded, %s warnings.')\n            logger.info(bold(msg), self._warncount)\n\n        if self.statuscode == 0 and self.builder.epilog:\n            logger.info('')\n            logger.info(\n                self.builder.epilog,\n                {\n                    'outdir': relpath(self.outdir),\n                    'project': self.config.project,\n                },\n            )\n\n        self.builder.cleanup()\n", "type": "function"}], "retrieved_count": 10, "cost_time": 1.3995084762573242}
{"question": "Where does Sphinx implement its theme system?", "answer": null, "relative_code_list": null, "ground_truth": "Sphinx implements its theme system across several modules and directories within the codebase, providing a flexible and extensible system for customizing the appearance of generated documentation. The theme system is designed to support both built-in and custom themes.\n\nKey locations where Sphinx's theme system is implemented include:\n\n1. **sphinx/theming.py**: Contains the core theme system implementation, including the Theme class that manages theme loading, configuration, and template resolution. This module provides the foundation for the entire theme system.\n\n2. **sphinx/themes/**: This directory contains built-in theme implementations, including themes like 'alabaster' (the default theme), 'classic', 'sphinxdoc', and others. Each theme is typically implemented as a separate directory with its own templates and static files.\n\n3. **sphinx/themes/basic/**: Contains the basic theme that serves as a foundation for other themes, providing core templates and styling that can be extended or overridden by specific themes.\n\n4. **sphinx/themes/alabaster/**: Contains the default Alabaster theme implementation, including HTML templates, CSS stylesheets, and other static assets.\n\n5. **sphinx/themes/classic/**: Contains the classic theme implementation, providing an alternative styling option for Sphinx documentation.\n\n6. **sphinx/themes/sphinxdoc/**: Contains the sphinxdoc theme implementation, which was the original Sphinx theme.\n\n7. **sphinx/builders/html.py**: The HTML builder integrates with the theme system to apply themes during HTML generation, using theme templates and static files to create the final output.\n\n8. **sphinx/builders/html/**: Contains HTML-specific builder implementations that work with the theme system to generate themed HTML output.\n\n9. **sphinx/util/template.py**: Contains utility functions for template processing, including Jinja2 template engine integration that the theme system uses for template rendering.\n\n10. **sphinx/config.py**: Contains configuration options for theme settings, allowing users to specify themes and theme-specific options in their conf.py files.\n\nThe theme system supports both built-in themes that are distributed with Sphinx and external themes that can be installed separately as Python packages. Themes can customize HTML templates, CSS styles, JavaScript, and other static assets to create unique documentation appearances.", "score": null, "retrieved_content": [{"name": "__init__", "is_method": true, "class_name": "HTMLThemeFactory", "parameters": ["self"], "calls": ["self._load_builtin_themes", "self._load_entry_point_themes", "getattr", "self._load_additional_themes"], "code_location": {"file": "theming.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx", "start_line": 153, "end_line": 168}, "code_snippet": "    def __init__(\n        self,\n        *,\n        confdir: Path,\n        app: Sphinx,\n        config: Config,\n        registry: SphinxComponentRegistry,\n    ) -> None:\n        self._app = app\n        self._confdir = confdir\n        self._themes = registry.html_themes\n        self._entry_point_themes: dict[str, Callable[[], None]] = {}\n        self._load_builtin_themes()\n        if html_theme_path := getattr(config, 'html_theme_path', None):\n            self._load_additional_themes(html_theme_path)\n        self._load_entry_point_themes()\n", "type": "function"}, {"name": "test_theme_api", "is_method": false, "class_name": null, "parameters": ["app"], "calls": ["pytest.mark.sphinx", "isinstance", "theme.get_options", "theme.get_options", "theme._cleanup", "set", "set", "len", "theme.get_config", "theme.get_config", "theme.get_config", "pytest.raises", "theme.get_config", "pytest.raises", "theme.get_config", "any", "app.registry.html_themes.keys", "theme.get_theme_dirs", "p.exists"], "code_location": {"file": "test_theming.py", "path": "/data3/pwh/swebench-repos/sphinx/tests/test_theming", "start_line": 36, "end_line": 98}, "code_snippet": "def test_theme_api(app: SphinxTestApp) -> None:\n    assert isinstance(app.builder, StandaloneHTMLBuilder)  # type-checking\n    themes = [\n        'basic',\n        'default',\n        'scrolls',\n        'agogo',\n        'sphinxdoc',\n        'haiku',\n        'traditional',\n        'epub',\n        'nature',\n        'pyramid',\n        'bizstyle',\n        'classic',\n        'nonav',\n        'test-theme',\n        'ziptheme',\n        'staticfiles',\n        'parent',\n        'child',\n        'alabaster',\n    ]\n\n    # test Theme class API\n    assert set(app.registry.html_themes.keys()) == set(themes)\n    assert app.registry.html_themes['test-theme'] == (\n        app.srcdir / 'test_theme' / 'test-theme'\n    )\n    assert app.registry.html_themes['ziptheme'] == (app.srcdir / 'ziptheme.zip')\n    assert app.registry.html_themes['staticfiles'] == (\n        app.srcdir / 'test_theme' / 'staticfiles'\n    )\n\n    # test Theme instance API\n    theme = app.builder.theme\n    assert theme.name == 'ziptheme'\n    assert len(theme.get_theme_dirs()) == 2\n\n    # direct setting\n    assert theme.get_config('theme', 'stylesheet') == 'custom.css'\n    # inherited setting\n    assert theme.get_config('options', 'nosidebar') == 'false'\n    # nonexisting setting\n    assert theme.get_config('theme', 'foobar', 'def') == 'def'\n    with pytest.raises(ThemeError):\n        theme.get_config('theme', 'foobar')\n    # nonexisting section\n    with pytest.raises(ThemeError):\n        theme.get_config('foobar', 'foobar')\n\n    # options API\n\n    options = theme.get_options({'nonexisting': 'foo'})\n    assert 'nonexisting' not in options\n\n    options = theme.get_options(app.config.html_theme_options)\n    assert options['testopt'] == 'foo'\n    assert options['nosidebar'] == 'false'\n\n    # cleanup temp directories\n    theme._cleanup()\n    assert not any(p.exists() for p in theme._tmp_dirs)\n", "type": "function"}, {"name": "init", "is_method": true, "class_name": "BuiltinTemplateLoader", "parameters": ["self", "builder", "theme", "dirs"], "calls": ["len", "SandboxedEnvironment", "pass_context", "pass_context", "theme.get_theme_dirs", "SphinxFileSystemLoader", "self.environment.install_gettext_translations", "list", "list", "map", "map"], "code_location": {"file": "jinja2glue.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx", "start_line": 167, "end_line": 214}, "code_snippet": "    def init(\n        self,\n        builder: Builder,\n        theme: Theme | None = None,\n        dirs: list[str] | None = None,\n    ) -> None:\n        # create a chain of paths to search\n        if theme:\n            # the theme's own dir and its bases' dirs\n            pathchain = theme.get_theme_dirs()\n            # the loader dirs: pathchain + the parent directories for all themes\n            loaderchain = pathchain + [p.parent for p in pathchain]\n        elif dirs:\n            pathchain = list(map(_StrPath, dirs))\n            loaderchain = list(map(_StrPath, dirs))\n        else:\n            pathchain = []\n            loaderchain = []\n\n        # prepend explicit template paths\n        self.templatepathlen = len(builder.config.templates_path)\n        if builder.config.templates_path:\n            cfg_templates_path = [\n                builder.confdir / tp for tp in builder.config.templates_path\n            ]\n            pathchain[0:0] = cfg_templates_path\n            loaderchain[0:0] = cfg_templates_path\n\n        # store it for use in newest_template_mtime\n        self.pathchain = pathchain\n\n        # make the paths into loaders\n        self.loaders = [SphinxFileSystemLoader(x) for x in loaderchain]\n\n        use_i18n = builder._translator is not None\n        extensions = ['jinja2.ext.i18n'] if use_i18n else []\n        self.environment = SandboxedEnvironment(loader=self, extensions=extensions)\n        self.environment.filters['tobool'] = _tobool\n        self.environment.filters['toint'] = _toint\n        self.environment.filters['todim'] = _todim\n        self.environment.filters['slice_index'] = _slice_index\n        self.environment.globals['debug'] = pass_context(pformat)\n        self.environment.globals['warning'] = warning\n        self.environment.globals['accesskey'] = pass_context(accesskey)\n        self.environment.globals['idgen'] = idgen\n        if use_i18n:\n            # ``install_gettext_translations`` is injected by the ``jinja2.ext.i18n`` extension\n            self.environment.install_gettext_translations(builder._translator)  # type: ignore[attr-defined]\n", "type": "function"}, {"name": "init", "is_method": true, "class_name": "TemplateBridge", "parameters": ["self", "builder", "theme", "dirs"], "calls": ["NotImplementedError"], "code_location": {"file": "application.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx", "start_line": 1830, "end_line": 1845}, "code_snippet": "    def init(\n        self,\n        builder: Builder,\n        theme: Theme | None = None,\n        dirs: list[str] | None = None,\n    ) -> None:\n        \"\"\"Called by the builder to initialize the template system.\n\n        *builder* is the builder object; you'll probably want to look at the\n        value of ``builder.config.templates_path``.\n\n        *theme* is a :class:`sphinx.theming.Theme` object or None; in the latter\n        case, *dirs* can be list of fixed directories to look for templates.\n        \"\"\"\n        msg = 'must be implemented in subclasses'\n        raise NotImplementedError(msg)\n", "type": "function"}, {"name": "Theme", "docstring": "A Theme is a set of HTML templates and configurations.\n\nThis class supports both theme directory and theme archive (zipped theme).", "methods": ["__init__", "get_theme_dirs", "get_config", "get_options", "_cleanup", "__init__", "update"], "attributes": ["LATEX_ELEMENTS_KEYS", "UPDATABLE_KEYS"], "code_location": {"file": "theming.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx", "start_line": 56, "end_line": 147}, "type": "class"}, {"name": "__init__", "is_method": true, "class_name": "SphinxTemplateLoader", "parameters": ["self", "confdir", "templates_paths", "system_templates_paths"], "calls": ["Path", "SphinxFileSystemLoader", "self.loaders.append", "SphinxFileSystemLoader", "self.loaders.append", "self.sysloaders.append"], "code_location": {"file": "template.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/util", "start_line": 127, "end_line": 144}, "code_snippet": "    def __init__(\n        self,\n        confdir: str | os.PathLike[str],\n        templates_paths: Sequence[str | os.PathLike[str]],\n        system_templates_paths: Sequence[str | os.PathLike[str]],\n    ) -> None:\n        self.loaders = []\n        self.sysloaders = []\n\n        conf_dir = Path(confdir)\n        for templates_path in templates_paths:\n            loader = SphinxFileSystemLoader(conf_dir / templates_path)\n            self.loaders.append(loader)\n\n        for templates_path in system_templates_paths:\n            loader = SphinxFileSystemLoader(templates_path)\n            self.loaders.append(loader)\n            self.sysloaders.append(loader)\n", "type": "function"}, {"name": "__init__", "is_method": true, "class_name": "ThemeFactory", "parameters": ["self"], "calls": ["self.load_builtin_themes"], "code_location": {"file": "theming.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/builders/latex", "start_line": 104, "end_line": 108}, "code_snippet": "    def __init__(self, *, srcdir: Path, config: Config) -> None:\n        self.themes: dict[str, Theme] = {}\n        self.theme_paths = [srcdir / p for p in config.latex_theme_path]\n        self.config = config\n        self.load_builtin_themes(config)\n", "type": "function"}, {"name": "test_theme_having_multiple_stylesheets", "is_method": false, "class_name": null, "parameters": ["app"], "calls": ["pytest.mark.sphinx", "app.build", "read_text"], "code_location": {"file": "test_html_theme.py", "path": "/data3/pwh/swebench-repos/sphinx/tests/test_theming", "start_line": 41, "end_line": 50}, "code_snippet": "def test_theme_having_multiple_stylesheets(app: SphinxTestApp) -> None:\n    app.build()\n    content = (app.outdir / 'index.html').read_text(encoding='utf-8')\n\n    assert (\n        '<link rel=\"stylesheet\" type=\"text/css\" href=\"_static/mytheme.css\" />'\n    ) in content\n    assert (\n        '<link rel=\"stylesheet\" type=\"text/css\" href=\"_static/extra.css\" />'\n    ) in content\n", "type": "function"}, {"name": "HTMLThemeFactory", "docstring": "A factory class for HTML Themes.", "methods": ["__init__", "_load_builtin_themes", "_load_additional_themes", "_load_entry_point_themes", "_find_themes", "create"], "attributes": [], "code_location": {"file": "theming.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx", "start_line": 150, "end_line": 245}, "type": "class"}, {"name": "test_nested_zipped_theme", "is_method": false, "class_name": null, "parameters": ["app"], "calls": ["pytest.mark.sphinx", "isinstance", "app.build"], "code_location": {"file": "test_theming.py", "path": "/data3/pwh/swebench-repos/sphinx/tests/test_theming", "start_line": 120, "end_line": 123}, "code_snippet": "def test_nested_zipped_theme(app: SphinxTestApp) -> None:\n    assert isinstance(app.builder, StandaloneHTMLBuilder)  # type-checking\n    assert app.builder.theme.name == 'child'\n    app.build()  # => not raises TemplateNotFound\n", "type": "function"}], "retrieved_count": 10, "cost_time": 1.4210455417633057}
{"question": "Where in the Sphinx codebase is the core document processor implemented?", "answer": null, "relative_code_list": null, "ground_truth": "The core document processor in Sphinx is implemented across several key modules and classes that work together to handle document parsing, transformation, and processing. The main components are distributed throughout the codebase to provide modularity and extensibility.\n\nKey locations where the core document processor is implemented include:\n\n1. **sphinx/application.py**: The main Sphinx application class orchestrates the overall document processing workflow, coordinating between different components and managing the build process phases.\n\n2. **sphinx/builders/__init__.py**: The Builder base class implements the core document reading and writing logic, including methods like `read_doc()`, `write_doc()`, and the overall build workflow.\n\n3. **sphinx/environment/__init__.py**: The BuildEnvironment class manages document state, cross-references, and metadata throughout the build process, providing the data store for document processing.\n\n4. **sphinx/transforms/__init__.py**: The SphinxTransformer class and various transform implementations handle document tree modifications, including cross-reference resolution and other document transformations.\n\n5. **sphinx/parsers.py**: Contains parser implementations for different input formats, including reStructuredText and Markdown parsers that convert source text into docutils document trees.\n\n6. **sphinx/domains/__init__.py**: The Domain class and domain implementations provide specialized document processing for different types of documentation (Python, C++, etc.).\n\n7. **sphinx/registry.py**: The SphinxComponentRegistry manages all the components involved in document processing, including parsers, transforms, and other extensible elements.\n\n8. **sphinx/util/docutils.py**: Contains utility functions and classes that integrate with Docutils for document processing, including the SphinxRole and SphinxDirective base classes.\n\nThe document processor is designed as a modular system where different components handle specific aspects of document processing, allowing for extensibility and customization while maintaining a consistent overall architecture.", "score": null, "retrieved_content": [{"name": "SphinxStandaloneReader", "docstring": "A basic document reader for Sphinx.", "methods": ["__init__", "_setup_transforms", "read", "read_source"], "attributes": [], "code_location": {"file": "io.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx", "start_line": 79, "end_line": 109}, "type": "class"}, {"name": "_process_doc", "is_method": true, "class_name": "_DomainsContainer", "parameters": ["self", "env", "docname", "document"], "calls": ["self._domain_instances.values", "domain.process_doc"], "code_location": {"file": "_domains_container.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/domains", "start_line": 165, "end_line": 169}, "code_snippet": "    def _process_doc(\n        self, env: BuildEnvironment, docname: str, document: nodes.document\n    ) -> None:\n        for domain in self._domain_instances.values():\n            domain.process_doc(env, docname, document)\n", "type": "function"}, {"name": "process_doc", "is_method": true, "class_name": "CPPDomain", "parameters": ["self", "env", "docname", "document"], "calls": ["logger.debug", "logger.debug", "logger.debug", "dump"], "code_location": {"file": "__init__.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/domains/cpp", "start_line": 1025, "end_line": 1031}, "code_snippet": "    def process_doc(\n        self, env: BuildEnvironment, docname: str, document: nodes.document\n    ) -> None:\n        if Symbol.debug_show_tree:\n            logger.debug('process_doc: %s', docname)\n            logger.debug(self.data['root_symbol'].dump(0))\n            logger.debug('process_doc end: %s', docname)\n", "type": "function"}, {"name": "process_doc", "is_method": true, "class_name": "CDomain", "parameters": ["self", "env", "docname", "document"], "calls": ["logger.debug", "logger.debug", "logger.debug", "dump"], "code_location": {"file": "__init__.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/domains/c", "start_line": 844, "end_line": 850}, "code_snippet": "    def process_doc(\n        self, env: BuildEnvironment, docname: str, document: nodes.document\n    ) -> None:\n        if Symbol.debug_show_tree:\n            logger.debug('process_doc: %s', docname)\n            logger.debug(self.data['root_symbol'].dump(0))\n            logger.debug('process_doc end: %s', docname)\n", "type": "function"}, {"name": "Sphinx", "docstring": "The main application class and extensibility interface.\n\n:ivar srcdir: Directory containing source.\n:ivar confdir: Directory containing ``conf.py``.\n:ivar doctreedir: Directory for storing pickled doctrees.\n:ivar outdir: Directory for storing build documents.", "methods": ["__init__", "fresh_env_used", "phase", "_init_i18n", "_init_env", "_create_fresh_env", "_load_existing_env", "_post_init_env", "preload_builder", "create_builder", "_init_builder", "build", "setup_extension", "require_sphinx", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "disconnect", "emit", "emit_firstresult", "add_builder", "add_config_value", "add_event", "set_translator", "add_node", "add_enumerable_node", "add_directive", "add_role", "add_generic_role", "add_domain", "add_directive_to_domain", "add_role_to_domain", "add_index_to_domain", "add_object_type", "add_crossref_type", "add_transform", "add_post_transform", "add_js_file", "add_css_file", "add_latex_package", "add_lexer", "add_autodocumenter", "add_autodoc_attrgetter", "add_search_language", "add_source_suffix", "add_source_parser", "add_env_collector", "add_html_theme", "add_html_math_renderer", "add_message_catalog", "is_parallel_allowed", "set_html_assets_policy"], "attributes": ["srcdir", "confdir", "outdir", "doctreedir"], "code_location": {"file": "application.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx", "start_line": 142, "end_line": 1822}, "type": "class"}, {"name": "process_doc", "is_method": true, "class_name": "ChangeSetDomain", "parameters": ["self", "env", "docname", "document"], "calls": [], "code_location": {"file": "changeset.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/domains", "start_line": 160, "end_line": 163}, "code_snippet": "    def process_doc(\n        self, env: BuildEnvironment, docname: str, document: nodes.document\n    ) -> None:\n        pass  # nothing to do here. All changesets are registered on calling directive.\n", "type": "function"}, {"name": "Parser", "docstring": "A base class for source parsers.\n\nAdditional parsers should inherit from this class instead of\n``docutils.parsers.Parser``.\nThis class provides access to core Sphinx objects; *config* and *env*.", "methods": ["config", "env", "set_application", "__init__", "parse", "parse_comments", "parse_definition", "parse", "get_transforms"], "attributes": ["supported"], "code_location": {"file": "parsers.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx", "start_line": 26, "end_line": 62}, "type": "class"}, {"name": "IndexBuilder", "docstring": "Helper class that creates a search index based on the doctrees\npassed to the `feed` method.", "methods": ["__init__", "load", "dump", "get_objects", "get_terms", "freeze", "label", "prune", "feed", "_word_collector", "context_for_searchtool", "get_js_stemmer_rawcodes", "get_js_stemmer_rawcode", "get_js_stemmer_code"], "attributes": ["formats"], "code_location": {"file": "__init__.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/search", "start_line": 263, "end_line": 592}, "type": "class"}, {"name": "SphinxTransformer", "docstring": "A transformer for Sphinx.", "methods": ["set_environment", "apply_transforms"], "attributes": [], "code_location": {"file": "__init__.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/transforms", "start_line": 81, "end_line": 108}, "type": "class"}, {"name": "SphinxFileOutput", "docstring": "Better FileOutput class for Sphinx.", "methods": ["__init__", "write"], "attributes": [], "code_location": {"file": "docutils.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/util", "start_line": 447, "end_line": 469}, "type": "class"}], "retrieved_count": 10, "cost_time": 1.4348094463348389}
{"question": "Why does Sphinx's extension system design impact build performance when multiple extensions are loaded?", "answer": null, "relative_code_list": null, "ground_truth": "Sphinx's extension system design impacts build performance when multiple extensions are loaded due to the cumulative overhead of extension processing and the way extensions integrate with the build process. This impact becomes more significant as the number of loaded extensions increases.\n\nKey factors that affect build performance include:\n\n1. **Event Processing Overhead**: Each extension that connects to Sphinx events adds processing time during the build. Multiple extensions listening to the same events can create a cascade of processing that accumulates across the entire build process.\n\n2. **Document Tree Modifications**: Extensions that modify document trees during processing (e.g., adding nodes, transforming content) can significantly impact performance, especially when multiple extensions perform similar operations on the same documents.\n\n3. **Cross-Reference Processing**: Extensions that add custom cross-reference types or modify cross-reference resolution can increase the complexity and time required for the reference resolution phase.\n\n4. **Memory Usage**: Each extension adds to the memory footprint of the build process. Multiple extensions can collectively consume significant memory, especially if they cache data or maintain large data structures.\n\n5. **Initialization Overhead**: Extensions require initialization time during the build setup phase. With many extensions, this initialization time can become noticeable.\n\n6. **Dependency Conflicts**: Some extensions may have conflicting requirements or may perform redundant operations, leading to inefficient processing and potential performance degradation.\n\n7. **Extension Ordering**: The order in which extensions are loaded and their event handler priorities can affect performance, as some extensions may need to process documents multiple times or in specific sequences.\n\n8. **Resource Competition**: Multiple extensions competing for the same system resources (CPU, memory, I/O) can lead to performance bottlenecks, especially on systems with limited resources.\n\nThe extension system's event-driven architecture, while providing flexibility and extensibility, introduces these performance considerations that need to be balanced against the functionality benefits that extensions provide.", "score": null, "retrieved_content": [{"name": "load_extension", "is_method": true, "class_name": "SphinxComponentRegistry", "parameters": ["self", "app", "extname"], "calls": ["logger.warning", "__", "prefixed_warnings", "getattr", "Extension", "__", "import_module", "logger.warning", "logger.verbose", "ExtensionError", "__", "setup", "isinstance", "logger.warning", "VersionRequirementError", "__", "__", "traceback.format_exc", "__", "__"], "code_location": {"file": "registry.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx", "start_line": 524, "end_line": 587}, "code_snippet": "    def load_extension(self, app: Sphinx, extname: str) -> None:\n        \"\"\"Load a Sphinx extension.\"\"\"\n        if extname in app.extensions:  # already loaded\n            return\n        if extname in EXTENSION_BLACKLIST:\n            logger.warning(\n                __(\n                    'the extension %r was already merged with Sphinx since '\n                    'version %s; this extension is ignored.'\n                ),\n                extname,\n                EXTENSION_BLACKLIST[extname],\n            )\n            return\n\n        # update loading context\n        prefix = __('while setting up extension %s:') % extname\n        with prefixed_warnings(prefix):\n            try:\n                mod = import_module(extname)\n            except ImportError as err:\n                logger.verbose(__('Original exception:\\n') + traceback.format_exc())\n                raise ExtensionError(\n                    __('Could not import extension %s') % extname, err\n                ) from err\n\n            setup: _ExtensionSetupFunc | None = getattr(mod, 'setup', None)\n            if setup is None:\n                logger.warning(\n                    __(\n                        'extension %r has no setup() function; is it really '\n                        'a Sphinx extension module?'\n                    ),\n                    extname,\n                )\n                metadata: ExtensionMetadata = {}\n            else:\n                try:\n                    metadata = setup(app)\n                except VersionRequirementError as err:\n                    # add the extension name to the version required\n                    raise VersionRequirementError(\n                        __(\n                            'The %s extension used by this project needs at least '\n                            'Sphinx v%s; it therefore cannot be built with this '\n                            'version.'\n                        )\n                        % (extname, err),\n                    ) from err\n\n            if metadata is None:\n                metadata = {}\n            elif not isinstance(metadata, dict):\n                logger.warning(\n                    __(\n                        'extension %r returned an unsupported object from '\n                        'its setup() function; it should return None or a '\n                        'metadata dictionary'\n                    ),\n                    extname,\n                )\n                metadata = {}\n\n            app.extensions[extname] = Extension(extname, mod, **metadata)\n", "type": "function"}, {"name": "setup", "is_method": false, "class_name": null, "parameters": ["app"], "calls": ["app.add_transform", "app.add_transform", "app.add_transform", "app.add_transform", "app.add_transform", "app.add_transform", "app.add_transform", "app.add_transform", "app.add_transform", "app.add_transform", "app.add_transform", "app.add_transform", "app.add_transform", "app.add_transform", "app.add_transform"], "code_location": {"file": "__init__.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/transforms", "start_line": 511, "end_line": 532}, "code_snippet": "def setup(app: Sphinx) -> ExtensionMetadata:\n    app.add_transform(ApplySourceWorkaround)\n    app.add_transform(ExtraTranslatableNodes)\n    app.add_transform(DefaultSubstitutions)\n    app.add_transform(MoveModuleTargets)\n    app.add_transform(HandleCodeBlocks)\n    app.add_transform(SortIds)\n    app.add_transform(DoctestTransform)\n    app.add_transform(AutoNumbering)\n    app.add_transform(AutoIndexUpgrader)\n    app.add_transform(FilterSystemMessages)\n    app.add_transform(UnreferencedFootnotesDetector)\n    app.add_transform(SphinxSmartQuotes)\n    app.add_transform(DoctreeReadEvent)\n    app.add_transform(GlossarySorter)\n    app.add_transform(ReorderConsecutiveTargetAndIndexNodes)\n\n    return {\n        'version': 'builtin',\n        'parallel_read_safe': True,\n        'parallel_write_safe': True,\n    }\n", "type": "function"}, {"name": "setup", "is_method": false, "class_name": null, "parameters": ["app"], "calls": ["app.setup_extension", "app.add_builder", "app.add_config_value", "frozenset"], "code_location": {"file": "singlehtml.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/builders", "start_line": 208, "end_line": 223}, "code_snippet": "def setup(app: Sphinx) -> ExtensionMetadata:\n    app.setup_extension('sphinx.builders.html')\n\n    app.add_builder(SingleFileHTMLBuilder)\n    app.add_config_value(\n        'singlehtml_sidebars',\n        lambda self: self.html_sidebars,\n        'html',\n        types=frozenset({dict}),\n    )\n\n    return {\n        'version': 'builtin',\n        'parallel_read_safe': True,\n        'parallel_write_safe': True,\n    }\n", "type": "function"}, {"name": "setup", "is_method": false, "class_name": null, "parameters": ["app"], "calls": ["app.connect"], "code_location": {"file": "extension.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx", "start_line": 87, "end_line": 94}, "code_snippet": "def setup(app: Sphinx) -> ExtensionMetadata:\n    app.connect('config-inited', verify_needs_extensions, priority=800)\n\n    return {\n        'version': 'builtin',\n        'parallel_read_safe': True,\n        'parallel_write_safe': True,\n    }\n", "type": "function"}, {"name": "setup", "is_method": false, "class_name": null, "parameters": ["app"], "calls": ["app.add_builder"], "code_location": {"file": "dummy.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/builders", "start_line": 39, "end_line": 46}, "code_snippet": "def setup(app: Sphinx) -> ExtensionMetadata:\n    app.add_builder(DummyBuilder)\n\n    return {\n        'version': 'builtin',\n        'parallel_read_safe': True,\n        'parallel_write_safe': True,\n    }\n", "type": "function"}, {"name": "setup", "is_method": false, "class_name": null, "parameters": ["app"], "calls": ["app.setup_extension", "app.add_builder"], "code_location": {"file": "dirhtml.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/builders", "start_line": 41, "end_line": 50}, "code_snippet": "def setup(app: Sphinx) -> ExtensionMetadata:\n    app.setup_extension('sphinx.builders.html')\n\n    app.add_builder(DirectoryHTMLBuilder)\n\n    return {\n        'version': 'builtin',\n        'parallel_read_safe': True,\n        'parallel_write_safe': True,\n    }\n", "type": "function"}, {"name": "setup", "is_method": false, "class_name": null, "parameters": ["app"], "calls": ["app.add_builder"], "code_location": {"file": "changes.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/builders", "start_line": 184, "end_line": 191}, "code_snippet": "def setup(app: Sphinx) -> ExtensionMetadata:\n    app.add_builder(ChangesBuilder)\n\n    return {\n        'version': 'builtin',\n        'parallel_read_safe': True,\n        'parallel_write_safe': True,\n    }\n", "type": "function"}, {"name": "setup", "is_method": false, "class_name": null, "parameters": ["app"], "calls": ["app.add_env_collector"], "code_location": {"file": "dependencies.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/environment/collectors", "start_line": 53, "end_line": 60}, "code_snippet": "def setup(app: Sphinx) -> ExtensionMetadata:\n    app.add_env_collector(DependenciesCollector)\n\n    return {\n        'version': 'builtin',\n        'parallel_read_safe': True,\n        'parallel_write_safe': True,\n    }\n", "type": "function"}, {"name": "test_extensions", "is_method": false, "class_name": null, "parameters": ["app"], "calls": ["pytest.mark.sphinx", "app.setup_extension", "strip_escape_sequences", "app.warning.getvalue"], "code_location": {"file": "test_application.py", "path": "/data3/pwh/swebench-repos/sphinx/tests", "start_line": 86, "end_line": 89}, "code_snippet": "def test_extensions(app: SphinxTestApp) -> None:\n    app.setup_extension('shutil')\n    warning = strip_escape_sequences(app.warning.getvalue())\n    assert \"extension 'shutil' has no setup() function\" in warning\n", "type": "function"}, {"name": "setup", "is_method": false, "class_name": null, "parameters": ["app"], "calls": ["app.connect", "app.connect", "app.connect", "app.connect", "app.connect", "app.connect", "app.connect", "app.connect", "app.connect"], "code_location": {"file": "config.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx", "start_line": 911, "end_line": 926}, "code_snippet": "def setup(app: Sphinx) -> ExtensionMetadata:\n    app.connect('config-inited', deprecate_source_encoding, priority=790)\n    app.connect('config-inited', convert_source_suffix, priority=800)\n    app.connect('config-inited', convert_highlight_options, priority=800)\n    app.connect('config-inited', init_numfig_format, priority=800)\n    app.connect('config-inited', evaluate_copyright_placeholders, priority=795)\n    app.connect('config-inited', correct_copyright_year, priority=800)\n    app.connect('config-inited', check_confval_types, priority=800)\n    app.connect('config-inited', check_primary_domain, priority=800)\n    app.connect('env-get-outdated', check_master_doc)\n\n    return {\n        'version': 'builtin',\n        'parallel_read_safe': True,\n        'parallel_write_safe': True,\n    }\n", "type": "function"}], "retrieved_count": 10, "cost_time": 1.4421591758728027}
{"question": "Why does Sphinx implement its own Domain system rather than relying solely on Docutils' built-in roles?", "answer": null, "relative_code_list": null, "ground_truth": "Sphinx implements its own Domain system rather than relying solely on Docutils' built-in roles for several important reasons related to functionality, extensibility, and the specific needs of documentation generation.\n\nKey reasons for implementing a custom Domain system include:\n\n1. **Language-Specific Functionality**: Different programming languages and documentation domains have unique requirements for object descriptions, cross-references, and indexing. The Domain system allows Sphinx to provide specialized functionality for Python, C++, JavaScript, and other languages that goes beyond what Docutils' generic roles can provide.\n\n2. **Cross-Reference Resolution**: Sphinx's Domain system provides sophisticated cross-reference resolution capabilities that can handle complex relationships between objects, such as method inheritance, module imports, and namespace resolution. This requires domain-specific logic that Docutils' built-in roles cannot provide.\n\n3. **Object Type Management**: The Domain system allows Sphinx to define and manage specific object types (functions, classes, modules, etc.) with their own attributes, relationships, and documentation requirements. This provides much richer functionality than generic Docutils roles.\n\n4. **Namespace Isolation**: By organizing functionality into domains, Sphinx can avoid naming conflicts when documenting multiple languages or systems in the same project. For example, Python functions and C++ functions can coexist without conflicts.\n\n5. **Extensibility**: The Domain system provides a framework for extensions to add new object types, directives, and roles specific to their domain, making it much easier to extend Sphinx for new languages or documentation needs.\n\n6. **Data Persistence**: Domains can store complex metadata about documented objects that persists across builds, enabling features like automatic index generation, search functionality, and advanced cross-referencing.\n\n7. **Integration with Build Process**: The Domain system integrates deeply with Sphinx's build process, allowing for features like automatic object discovery, dependency tracking, and incremental builds that are specific to documentation generation.\n\nThe Domain system builds on top of Docutils' role system but provides the additional functionality needed for sophisticated documentation generation that goes beyond simple text markup.", "score": null, "retrieved_content": [{"name": "sphinx_domains", "docstring": "Monkey-patch directive and role dispatch, so that domain-specific\nmarkup takes precedence.", "methods": ["__init__", "directive", "role"], "attributes": [], "code_location": {"file": "docutils.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/util", "start_line": 301, "end_line": 380}, "type": "class"}, {"name": "add_role_to_domain", "is_method": true, "class_name": "Sphinx", "parameters": ["self", "domain", "name", "role", "override"], "calls": ["self.registry.add_role_to_domain"], "code_location": {"file": "application.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx", "start_line": 1226, "end_line": 1249}, "code_snippet": "    def add_role_to_domain(\n        self,\n        domain: str,\n        name: str,\n        role: RoleFunction | XRefRole,\n        override: bool = False,\n    ) -> None:\n        \"\"\"Register a Docutils role in a domain.\n\n        Like :meth:`add_role`, but the role is added to the domain named\n        *domain*.\n\n        :param domain: The name of the target domain\n        :param name: The name of the role\n        :param role: The role function\n        :param override: If false, do not install it if another role\n                         is already installed as the same name\n                         If true, unconditionally install the role.\n\n        .. versionadded:: 1.0\n        .. versionchanged:: 1.8\n           Add *override* keyword.\n        \"\"\"\n        self.registry.add_role_to_domain(domain, name, role, override=override)\n", "type": "function"}, {"name": "Domain", "docstring": "A Domain is meant to be a group of \"object\" description directives for\nobjects of a similar nature, and corresponding roles to create references to\nthem.  Examples would be Python modules, classes, functions etc., elements\nof a templating language, Sphinx roles and directives, etc.\n\nEach domain has a separate storage for information about existing objects\nand how to reference them in `self.data`, which must be a dictionary.  It\nalso must implement several functions that expose the object information in\na uniform way to parts of Sphinx that allow the user to reference or search\nfor objects in a domain-agnostic way.\n\nAbout `self.data`: since all object and cross-referencing information is\nstored on a BuildEnvironment instance, the `domain.data` object is also\nstored in the `env.domaindata` dict under the key `domain.name`.  Before the\nbuild process starts, every active domain is instantiated and given the\nenvironment object; the `domaindata` dict must then either be nonexistent or\na dictionary whose 'version' key is equal to the domain class'\n:attr:`data_version` attribute.  Otherwise, `OSError` is raised and the\npickled environment is discarded.", "methods": ["__init__", "setup", "add_object_type", "role", "directive", "clear_doc", "merge_domaindata", "process_doc", "check_consistency", "process_field_xref", "resolve_xref", "resolve_any_xref", "get_objects", "get_type_name", "get_enumerable_node_type", "get_full_qualified_name"], "attributes": [], "code_location": {"file": "__init__.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/domains", "start_line": 62, "end_line": 331}, "type": "class"}, {"name": "role", "is_method": true, "class_name": "sphinx_domains", "parameters": ["self", "role_name", "language_module", "lineno", "reporter"], "calls": ["role_name.lower", "self.domains.standard_domain.role", "role", "role_name.partition", "domain.role", "default_domain.role", "super", "logger.warning", "__"], "code_location": {"file": "docutils.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/util", "start_line": 346, "end_line": 380}, "code_snippet": "    def role(\n        self,\n        role_name: str,\n        language_module: ModuleType,\n        lineno: int,\n        reporter: Reporter,\n    ) -> tuple[RoleFunction, list[system_message]]:\n        \"\"\"Lookup a role, given its name which can include a domain.\"\"\"\n        role_name = role_name.lower()\n        # explicit domain given?\n        if ':' in role_name:\n            domain_name, _, name = role_name.partition(':')\n            try:\n                domain = self.domains[domain_name]\n            except KeyError:\n                logger.warning(__('unknown role name: %s'), role_name)\n            else:\n                element = domain.role(name)\n                if element is not None:\n                    return element, []\n        # else look in the default domain\n        else:\n            name = role_name\n            default_domain = self.current_document.default_domain\n            if default_domain is not None:\n                element = default_domain.role(name)\n                if element is not None:\n                    return element, []\n\n        # always look in the std domain\n        element = self.domains.standard_domain.role(name)\n        if element is not None:\n            return element, []\n\n        return super().role(role_name, language_module, lineno, reporter)\n", "type": "function"}, {"name": "SphinxDomains", "docstring": "Collect objects to Sphinx domains for cross references.", "methods": ["apply"], "attributes": ["default_priority"], "code_location": {"file": "references.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/transforms", "start_line": 33, "end_line": 41}, "type": "class"}, {"name": "add_role_to_domain", "is_method": true, "class_name": "SphinxComponentRegistry", "parameters": ["self", "domain", "name", "role", "override"], "calls": ["logger.debug", "self.domain_roles.setdefault", "ExtensionError", "ExtensionError", "__", "__"], "code_location": {"file": "registry.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx", "start_line": 235, "end_line": 250}, "code_snippet": "    def add_role_to_domain(\n        self,\n        domain: str,\n        name: str,\n        role: RoleFunction | XRefRole,\n        override: bool = False,\n    ) -> None:\n        logger.debug('[app] adding role to domain: %r', (domain, name, role))\n        if domain not in self.domains:\n            raise ExtensionError(__('domain %s not yet registered') % domain)\n        roles = self.domain_roles.setdefault(domain, {})\n        if name in roles and not override:\n            raise ExtensionError(\n                __('The %r role is already registered to domain %s') % (name, domain)\n            )\n        roles[name] = role\n", "type": "function"}, {"name": "role", "is_method": true, "class_name": "IntersphinxDispatcher", "parameters": ["self", "role_name", "language_module", "lineno", "reporter"], "calls": ["role_name.startswith", "role", "len", "IntersphinxRole", "super"], "code_location": {"file": "_resolve.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/ext/intersphinx", "start_line": 357, "end_line": 367}, "code_snippet": "    def role(\n        self,\n        role_name: str,\n        language_module: ModuleType,\n        lineno: int,\n        reporter: Reporter,\n    ) -> tuple[RoleFunction, list[system_message]]:\n        if len(role_name) > 9 and role_name.startswith(('external:', 'external+')):\n            return IntersphinxRole(role_name), []\n        else:\n            return super().role(role_name, language_module, lineno, reporter)\n", "type": "function"}, {"name": "create_domains", "is_method": true, "class_name": "SphinxComponentRegistry", "parameters": ["self", "env"], "calls": ["self.domains.values", "DomainClass", "domain.directives.update", "domain.roles.update", "domain.indices.extend", "items", "self.domain_directives.get", "self.domain_roles.get", "self.domain_indices.get", "domain.add_object_type", "self.domain_object_types.get"], "code_location": {"file": "registry.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx", "start_line": 205, "end_line": 216}, "code_snippet": "    def create_domains(self, env: BuildEnvironment) -> Iterator[Domain]:\n        for DomainClass in self.domains.values():\n            domain = DomainClass(env)\n\n            # transplant components added by extensions\n            domain.directives.update(self.domain_directives.get(domain.name, {}))\n            domain.roles.update(self.domain_roles.get(domain.name, {}))\n            domain.indices.extend(self.domain_indices.get(domain.name, []))\n            for name, objtype in self.domain_object_types.get(domain.name, {}).items():\n                domain.add_object_type(name, objtype)\n\n            yield domain\n", "type": "function"}, {"name": "SphinxRole", "docstring": "A base class for Sphinx roles.\n\nThis class provides helper methods for Sphinx roles.\n\n.. versionadded:: 2.0\n\n.. note:: The subclasses of this class might not work with docutils.\n          This class is strongly coupled with Sphinx.", "methods": ["__call__", "run", "env", "config", "get_source_info", "set_source_info", "get_location"], "attributes": [], "code_location": {"file": "docutils.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/util", "start_line": 603, "end_line": 699}, "type": "class"}, {"name": "get_role_name", "is_method": true, "class_name": "IntersphinxRole", "parameters": ["self", "name"], "calls": ["_deprecation_warning", "name.split", "len", "self.is_existent_role", "self.is_existent_role", "len"], "code_location": {"file": "_resolve.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/ext/intersphinx", "start_line": 538, "end_line": 561}, "code_snippet": "    def get_role_name(self, name: str) -> tuple[str, str] | None:\n        _deprecation_warning(\n            __name__, f'{self.__class__.__name__}.get_role_name', '', remove=(9, 0)\n        )\n        names = name.split(':')\n        if len(names) == 1:\n            # role\n            if (domain := self.env.current_document.default_domain) is not None:\n                domain_name = domain.name\n            else:\n                domain_name = None\n            role = names[0]\n        elif len(names) == 2:\n            # domain:role:\n            domain_name, role = names\n        else:\n            return None\n\n        if domain_name and self.is_existent_role(domain_name, role):\n            return domain_name, role\n        elif self.is_existent_role('std', role):\n            return 'std', role\n        else:\n            return None\n", "type": "function"}], "retrieved_count": 10, "cost_time": 1.48445725440979}
{"question": "Where in the Sphinx codebase are the core Builder class definitions located?", "answer": null, "relative_code_list": null, "ground_truth": "The core Builder class definitions in Sphinx are located in the sphinx/builders/ directory, with the main Builder base class and various specific builder implementations distributed across multiple files and subdirectories.\n\nKey locations where Builder class definitions are located include:\n\n1. **sphinx/builders/__init__.py**: Contains the main Builder base class that defines the core interface and common functionality for all builders. This includes the abstract methods that must be implemented by specific builders and the overall build workflow.\n\n2. **sphinx/builders/html.py**: Contains the HTML builder implementation, which is one of the most commonly used builders for generating HTML documentation.\n\n3. **sphinx/builders/latex.py**: Contains the LaTeX builder implementation for generating LaTeX output that can be compiled to PDF.\n\n4. **sphinx/builders/manpage.py**: Contains the manpage builder for generating Unix manual pages.\n\n5. **sphinx/builders/texinfo.py**: Contains the Texinfo builder for generating Texinfo documentation.\n\n6. **sphinx/builders/text.py**: Contains the text builder for generating plain text documentation.\n\n7. **sphinx/builders/xml.py**: Contains the XML builder for generating XML output.\n\n8. **sphinx/builders/epub3.py**: Contains the EPUB3 builder for generating electronic book format documentation.\n\n9. **sphinx/builders/gettext.py**: Contains the gettext builder for generating message catalogs for internationalization.\n\n10. **sphinx/builders/linkcheck.py**: Contains the linkcheck builder for checking external links in documentation.\n\n11. **sphinx/builders/dummy.py**: Contains a dummy builder for testing purposes.\n\n12. **sphinx/builders/changes.py**: Contains the changes builder for generating change logs.\n\n13. **sphinx/builders/dirhtml.py**: Contains the directory HTML builder for generating HTML with directory-based URLs.\n\n14. **sphinx/builders/singlehtml.py**: Contains the single HTML builder for generating a single HTML file containing all documentation.\n\nEach builder implementation extends the base Builder class and provides specific functionality for its target output format. The builders are registered with the SphinxComponentRegistry and can be selected through the buildername parameter when creating a Sphinx application.", "score": null, "retrieved_content": [{"name": "Builder", "docstring": "Builds target formats from the reST sources.", "methods": ["__init__", "app", "_translator", "get_translator_class", "create_translator", "init", "create_template_bridge", "get_target_uri", "get_relative_uri", "get_outdated_docs", "get_asset_paths", "post_process_images", "compile_catalogs", "compile_all_catalogs", "compile_specific_catalogs", "compile_update_catalogs", "build_all", "build_specific", "build_update", "build", "read", "_read_serial", "_read_parallel", "read_doc", "write_doctree", "write", "write_documents", "_write_serial", "_write_parallel", "prepare_writing", "copy_assets", "write_doc", "write_doc_serialized", "finish", "cleanup", "get_builder_config"], "attributes": ["srcdir", "confdir", "outdir", "doctreedir"], "code_location": {"file": "__init__.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/builders", "start_line": 64, "end_line": 881}, "type": "class"}, {"name": "BuildPhase", "docstring": "Build phase of Sphinx application.", "methods": [], "attributes": ["INITIALIZATION", "READING", "CONSISTENCY_CHECK", "RESOLVING", "WRITING"], "code_location": {"file": "build_phase.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/util", "start_line": 8, "end_line": 15}, "type": "class"}, {"name": "Sphinx", "docstring": "The main application class and extensibility interface.\n\n:ivar srcdir: Directory containing source.\n:ivar confdir: Directory containing ``conf.py``.\n:ivar doctreedir: Directory for storing pickled doctrees.\n:ivar outdir: Directory for storing build documents.", "methods": ["__init__", "fresh_env_used", "phase", "_init_i18n", "_init_env", "_create_fresh_env", "_load_existing_env", "_post_init_env", "preload_builder", "create_builder", "_init_builder", "build", "setup_extension", "require_sphinx", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "disconnect", "emit", "emit_firstresult", "add_builder", "add_config_value", "add_event", "set_translator", "add_node", "add_enumerable_node", "add_directive", "add_role", "add_generic_role", "add_domain", "add_directive_to_domain", "add_role_to_domain", "add_index_to_domain", "add_object_type", "add_crossref_type", "add_transform", "add_post_transform", "add_js_file", "add_css_file", "add_latex_package", "add_lexer", "add_autodocumenter", "add_autodoc_attrgetter", "add_search_language", "add_source_suffix", "add_source_parser", "add_env_collector", "add_html_theme", "add_html_math_renderer", "add_message_catalog", "is_parallel_allowed", "set_html_assets_policy"], "attributes": ["srcdir", "confdir", "outdir", "doctreedir"], "code_location": {"file": "application.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx", "start_line": 142, "end_line": 1822}, "type": "class"}, {"name": "StandaloneHTMLBuilder", "docstring": "Builds standalone HTML docs.", "methods": ["__init__", "init", "create_build_info", "_get_translations_js", "_get_style_filenames", "get_theme_config", "init_templates", "init_highlighter", "css_files", "init_css_files", "add_css_file", "script_files", "init_js_files", "add_js_file", "math_renderer_name", "get_outdated_docs", "get_asset_paths", "render_partial", "prepare_writing", "get_doc_context", "copy_assets", "write_doc", "write_doc_serialized", "finish", "gen_indices", "gen_pages_from_extensions", "gen_additional_pages", "write_genindex", "write_domain_indices", "copy_image_files", "copy_download_files", "create_pygments_style_file", "copy_translation_js", "copy_stemmer_js", "copy_theme_static_files", "copy_html_static_files", "copy_html_logo", "copy_html_favicon", "copy_static_files", "copy_extra_files", "write_buildinfo", "cleanup", "post_process_images", "load_indexer", "index_page", "_get_local_toctree", "get_output_path", "get_outfilename", "add_sidebars", "get_target_uri", "handle_page", "update_page_context", "handle_finish", "dump_inventory", "dump_search_index"], "attributes": ["name", "format", "epilog", "default_translator_class", "copysource", "allow_parallel", "out_suffix", "link_suffix", "indexer_dumps_unicode", "html_scaled_image_link", "supported_image_types", "supported_remote_images", "supported_data_uri_images", "searchindex_filename", "add_permalinks", "allow_sharp_as_current_path", "embedded", "search", "use_index", "download_support"], "code_location": {"file": "__init__.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/builders/html", "start_line": 110, "end_line": 1292}, "type": "class"}, {"name": "LaTeXBuilder", "docstring": "Builds LaTeX output to create PDF.", "methods": ["init", "get_outdated_docs", "get_target_uri", "get_relative_uri", "init_document_data", "init_context", "update_context", "init_babel", "init_multilingual", "write_stylesheet", "prepare_writing", "copy_assets", "write_documents", "get_contentsname", "update_doc_context", "assemble_doctree", "finish", "copy_support_files", "copy_latex_additional_files", "copy_image_files", "write_message_catalog"], "attributes": ["name", "format", "epilog", "supported_image_types", "supported_remote_images", "default_translator_class"], "code_location": {"file": "__init__.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/builders/latex", "start_line": 110, "end_line": 523}, "type": "class"}, {"name": "EpubBuilder", "docstring": "Builder that outputs epub files.\n\nIt creates the metainfo files container.opf, toc.ncx, mimetype, and\nMETA-INF/container.xml.  Afterwards, all necessary files are zipped to an\nepub file.", "methods": ["init", "create_build_info", "get_theme_config", "make_id", "get_refnodes", "check_refnodes", "get_toc", "toc_add_files", "fix_fragment", "fix_ids", "_update_node_id", "_make_footnote_ref", "_make_footnote", "_footnote_spot", "add_visible_links", "write_doc", "fix_genindex", "is_vector_graphics", "copy_image_files_pil", "copy_image_files", "copy_download_files", "handle_page", "build_mimetype", "build_container", "content_metadata", "build_content", "new_navpoint", "build_navpoints", "toc_metadata", "build_toc", "build_epub"], "attributes": ["copysource", "supported_image_types", "supported_remote_images", "add_permalinks", "allow_sharp_as_current_path", "embedded", "download_support", "html_scaled_image_link", "search", "coverpage_name", "toctree_template", "link_target_template", "css_link_target_class", "guide_titles", "media_types", "refuri_re", "doctype"], "code_location": {"file": "_epub_base.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/builders", "start_line": 129, "end_line": 808}, "type": "class"}, {"name": "XMLBuilder", "docstring": "Builds Docutils-native XML.", "methods": ["init", "get_outdated_docs", "get_target_uri", "write_doc", "_translate", "finish"], "attributes": ["name", "format", "epilog", "out_suffix", "allow_parallel", "default_translator_class"], "code_location": {"file": "xml.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/builders", "start_line": 24, "end_line": 95}, "type": "class"}, {"name": "TexinfoBuilder", "docstring": "Builds Texinfo output to create Info documentation.", "methods": ["init", "get_outdated_docs", "get_target_uri", "get_relative_uri", "prepare_writing", "write_documents", "assemble_doctree", "copy_assets", "copy_image_files", "copy_support_files"], "attributes": ["name", "format", "epilog", "supported_image_types", "default_translator_class"], "code_location": {"file": "texinfo.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/builders", "start_line": 36, "end_line": 218}, "type": "class"}, {"name": "BuildEnvironment", "docstring": "The environment in which the ReST files are translated.\nStores an inventory of cross-file targets and provides doctree\ntransformations to resolve links to them.", "methods": ["__init__", "__getstate__", "__setstate__", "setup", "app", "app", "app", "_registry", "_tags", "_config_status", "_update_settings", "set_versioning_method", "clear_doc", "merge_info_from", "path2doc", "doc2path", "relfn2path", "found_docs", "find_files", "get_outdated_files", "check_dependents", "prepare_settings", "temp_data", "docname", "parser", "new_serialno", "note_dependency", "note_included", "note_reread", "get_domain", "get_doctree", "master_doctree", "get_and_resolve_doctree", "resolve_toctree", "resolve_references", "apply_post_transforms", "collect_relations", "check_consistency"], "attributes": ["srcdir", "doctreedir"], "code_location": {"file": "__init__.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/environment", "start_line": 100, "end_line": 812}, "type": "class"}, {"name": "setup", "is_method": false, "class_name": null, "parameters": ["app"], "calls": ["app.add_builder"], "code_location": {"file": "dummy.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/builders", "start_line": 39, "end_line": 46}, "code_snippet": "def setup(app: Sphinx) -> ExtensionMetadata:\n    app.add_builder(DummyBuilder)\n\n    return {\n        'version': 'builtin',\n        'parallel_read_safe': True,\n        'parallel_write_safe': True,\n    }\n", "type": "function"}], "retrieved_count": 10, "cost_time": 0.415283203125}
{"question": "Where are Sphinx's built-in role definitions registered in the codebase?", "answer": null, "relative_code_list": null, "ground_truth": "Sphinx's built-in role definitions are registered in the codebase through several mechanisms and locations, with the registration process happening during Sphinx initialization and extension setup.\n\nKey locations where built-in role definitions are registered include:\n\n1. **sphinx/roles.py**: This is the main file where built-in roles are defined and registered. The file contains role implementations and a `setup()` function that registers these roles with the Docutils role system. This includes roles like `XRefRole`, `AnyXRefRole`, and various specialized roles for cross-references, formatting, and other functionality.\n\n2. **sphinx/domains/__init__.py**: The Domain base class provides a framework for registering domain-specific roles. Each domain can register its own roles through the `roles` attribute and the domain initialization process.\n\n3. **sphinx/domains/python.py**: Contains Python domain-specific role implementations and registration, including roles like `:py:func:`, `:py:class:`, `:py:mod:`, etc.\n\n4. **sphinx/domains/cpp.py**: Contains C++ domain-specific role implementations and registration, including roles for C++ objects like classes, functions, namespaces, etc.\n\n5. **sphinx/domains/c.py**: Contains C domain-specific role implementations and registration.\n\n6. **sphinx/domains/js.py**: Contains JavaScript domain-specific role implementations and registration.\n\n7. **sphinx/domains/rst.py**: Contains reStructuredText domain-specific role implementations and registration.\n\n8. **sphinx/domains/math.py**: Contains math domain-specific role implementations and registration.\n\n9. **sphinx/domains/std.py**: Contains standard domain role implementations and registration, including general-purpose roles like `:ref:`, `:doc:`, `:term:`, etc.\n\n10. **sphinx/registry.py**: The SphinxComponentRegistry manages the registration of roles across the system, providing methods for extensions to register custom roles.\n\nThe registration process typically involves calling Docutils' `register_local_role()` function or using Sphinx's extension API to register roles with the system. Roles are registered during the extension setup phase, ensuring they are available throughout the build process.", "score": null, "retrieved_content": [{"name": "setup", "is_method": false, "class_name": null, "parameters": ["app"], "calls": ["generic_docroles.items", "specific_docroles.items", "roles.register_canonical_role", "roles.GenericRole", "roles.CustomRole", "roles.register_local_role", "roles.register_local_role"], "code_location": {"file": "roles.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx", "start_line": 634, "end_line": 653}, "code_snippet": "def setup(app: Sphinx) -> ExtensionMetadata:\n    from docutils.parsers.rst import roles\n\n    for rolename, nodeclass in generic_docroles.items():\n        generic = roles.GenericRole(rolename, nodeclass)\n        role = roles.CustomRole(rolename, generic, {'classes': [rolename]})  # type: ignore[arg-type]\n        roles.register_local_role(rolename, role)  # type: ignore[arg-type]\n\n    for rolename, func in specific_docroles.items():\n        roles.register_local_role(rolename, func)  # type: ignore[arg-type]\n\n    # Since docutils registers it as a canonical role, override it as a\n    # canonical role as well.\n    roles.register_canonical_role('code', code_role)  # type: ignore[arg-type]\n\n    return {\n        'version': 'builtin',\n        'parallel_read_safe': True,\n        'parallel_write_safe': True,\n    }\n", "type": "function"}, {"name": "SphinxRole", "docstring": "A base class for Sphinx roles.\n\nThis class provides helper methods for Sphinx roles.\n\n.. versionadded:: 2.0\n\n.. note:: The subclasses of this class might not work with docutils.\n          This class is strongly coupled with Sphinx.", "methods": ["__call__", "run", "env", "config", "get_source_info", "set_source_info", "get_location"], "attributes": [], "code_location": {"file": "docutils.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/util", "start_line": 603, "end_line": 699}, "type": "class"}, {"name": "setup_link_roles", "is_method": false, "class_name": null, "parameters": ["app"], "calls": ["app.config.extlinks.items", "app.add_role", "make_link_role"], "code_location": {"file": "extlinks.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/ext", "start_line": 123, "end_line": 125}, "code_snippet": "def setup_link_roles(app: Sphinx) -> None:\n    for name, (base_url, caption) in app.config.extlinks.items():\n        app.add_role(name, make_link_role(name, base_url, caption))\n", "type": "function"}, {"name": "default_role", "is_method": false, "class_name": null, "parameters": ["docname", "name"], "calls": ["docutils.unregister_role", "Reporter", "roles.role", "docutils.register_role", "logger.warning", "__"], "code_location": {"file": "rst.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/util", "start_line": 66, "end_line": 77}, "code_snippet": "def default_role(docname: str, name: str) -> Iterator[None]:\n    if name:\n        dummy_reporter = Reporter('', 4, 4)\n        role_fn, _ = roles.role(name, english, 0, dummy_reporter)  # type: ignore[arg-type]\n        if role_fn:\n            docutils.register_role('', role_fn)  # type: ignore[arg-type]\n        else:\n            logger.warning(__('default role %s not found'), name, location=docname)\n\n    yield\n\n    docutils.unregister_role('')\n", "type": "function"}, {"name": "role", "is_method": true, "class_name": "CustomReSTDispatcher", "parameters": ["self", "role_name", "language_module", "lineno", "reporter"], "calls": ["self.role_func"], "code_location": {"file": "docutils.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/util", "start_line": 282, "end_line": 294}, "code_snippet": "    def role(\n        self,\n        role_name: str,\n        language_module: ModuleType,\n        lineno: int,\n        reporter: Reporter,\n    ) -> tuple[RoleFunction, list[system_message]]:\n        return self.role_func(\n            role_name,\n            language_module,  # type: ignore[return-value]\n            lineno,\n            reporter,\n        )\n", "type": "function"}, {"name": "role", "is_method": true, "class_name": "IntersphinxDispatcher", "parameters": ["self", "role_name", "language_module", "lineno", "reporter"], "calls": ["role_name.startswith", "role", "len", "IntersphinxRole", "super"], "code_location": {"file": "_resolve.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/ext/intersphinx", "start_line": 357, "end_line": 367}, "code_snippet": "    def role(\n        self,\n        role_name: str,\n        language_module: ModuleType,\n        lineno: int,\n        reporter: Reporter,\n    ) -> tuple[RoleFunction, list[system_message]]:\n        if len(role_name) > 9 and role_name.startswith(('external:', 'external+')):\n            return IntersphinxRole(role_name), []\n        else:\n            return super().role(role_name, language_module, lineno, reporter)\n", "type": "function"}, {"name": "DefaultRole", "docstring": "Set the default interpreted text role.  Overridden from docutils.", "methods": ["run"], "attributes": ["optional_arguments", "final_argument_whitespace"], "code_location": {"file": "__init__.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/directives", "start_line": 320, "end_line": 347}, "type": "class"}, {"name": "IntersphinxRole", "docstring": "", "methods": ["__init__", "run", "get_inventory_and_name_suffix", "_get_domain_role", "_emit_warning", "_concat_strings", "get_role_name", "is_existent_role", "invoke_role"], "attributes": ["_re_inv_ref"], "code_location": {"file": "_resolve.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/ext/intersphinx", "start_line": 370, "end_line": 596}, "type": "class"}, {"name": "ReSTRole", "docstring": "Description of a reST role.", "methods": ["handle_signature", "get_index_text"], "attributes": [], "code_location": {"file": "rst.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/domains", "start_line": 214, "end_line": 224}, "type": "class"}, {"name": "test_rst_role", "is_method": false, "class_name": null, "parameters": ["app"], "calls": ["pytest.mark.sphinx", "restructuredtext.parse", "assert_node", "assert_node", "assert_node"], "code_location": {"file": "test_domain_rst.py", "path": "/data3/pwh/swebench-repos/sphinx/tests/test_domains", "start_line": 268, "end_line": 286}, "code_snippet": "def test_rst_role(app: SphinxTestApp) -> None:\n    text = '.. rst:role:: ref'\n    doctree = restructuredtext.parse(app, text)\n    assert_node(\n        doctree,\n        (\n            addnodes.index,\n            [desc, ([desc_signature, desc_name, ':ref:'], [desc_content, ()])],\n        ),\n    )\n    assert_node(doctree[0], entries=[('single', 'ref (role)', 'role-ref', '', None)])\n    assert_node(\n        doctree[1],\n        addnodes.desc,\n        desctype='role',\n        domain='rst',\n        objtype='role',\n        no_index=False,\n    )\n", "type": "function"}], "retrieved_count": 10, "cost_time": 0.41698312759399414}
{"question": "Where are the default configuration values defined in Sphinx's source code?", "answer": null, "relative_code_list": null, "ground_truth": "The default configuration values in Sphinx's source code are primarily defined in the sphinx/config.py module, specifically in the Config class. This is where the comprehensive configuration system is implemented with all the default values for Sphinx's various settings.\n\nKey locations where default configuration values are defined include:\n\n1. **sphinx/config.py**: The main location where default configuration values are defined. The Config class contains a `config_values` dictionary that defines all available configuration options with their default values, rebuild requirements, and valid types. This includes settings for project information, build options, output formatting, extension settings, and many other configuration parameters.\n\n2. **sphinx/application.py**: Contains some configuration-related defaults, particularly for built-in extensions and their initialization order.\n\n3. **sphinx/builders/__init__.py**: Contains default configuration values specific to builders, such as default builder settings and builder-specific options.\n\n4. **sphinx/theming.py**: Contains default theme-related configuration values and theme system settings.\n\n5. **sphinx/environment/__init__.py**: Contains default environment settings and configuration values related to the build environment.\n\n6. **sphinx/ext/**: Various extension modules contain their own default configuration values, which are typically defined within the extension's setup function or configuration handling code.\n\n7. **sphinx/domains/**: Domain-specific configuration defaults are defined within each domain implementation, particularly for domain-specific settings and object type configurations.\n\nThe configuration system uses a structured approach where each configuration option is defined with metadata including the default value, what needs to be rebuilt if the value changes, valid types for the value, and a description. This system allows for comprehensive configuration management while providing sensible defaults for all Sphinx features.", "score": null, "retrieved_content": [{"name": "test_core_config", "is_method": false, "class_name": null, "parameters": ["app"], "calls": ["pytest.mark.sphinx", "getattr", "pytest.raises", "pytest.raises", "pytest.raises"], "code_location": {"file": "test_config.py", "path": "/data3/pwh/swebench-repos/sphinx/tests/test_config", "start_line": 91, "end_line": 138}, "code_snippet": "def test_core_config(app: SphinxTestApp) -> None:\n    cfg = app.config\n\n    # simple values\n    assert 'project' in cfg.__dict__\n    assert cfg.project == 'Sphinx <Tests>'\n    assert cfg.templates_path == ['_templates']\n\n    # overrides\n    assert cfg.root_doc == 'root'\n    assert cfg.latex_elements['maketitle'] == 'blah blah blah'\n    assert cfg.modindex_common_prefix == ['path1', 'path2']\n\n    # simple default values\n    assert 'locale_dirs' in cfg.__dict__\n    assert cfg.locale_dirs == ['locales']\n    assert cfg.trim_footnote_reference_space is False\n\n    # complex default values\n    assert 'html_title' not in cfg.__dict__\n    assert cfg.html_title == 'Sphinx <Tests> 0.6alpha1 documentation'\n\n    # complex default values mustn't raise\n    for valuename in cfg.config_values:\n        getattr(cfg, valuename)\n\n    # \"contains\" gives True both for set and unset values\n    assert 'project' in cfg\n    assert 'html_title' in cfg\n    assert 'nonexisting_value' not in cfg\n\n    # invalid values\n    with pytest.raises(AttributeError):\n        _ = cfg._value\n    with pytest.raises(AttributeError):\n        _ = cfg.nonexisting_value\n\n    # non-value attributes are deleted from the namespace\n    with pytest.raises(AttributeError):\n        _ = cfg.sys\n\n    # setting attributes\n    cfg.project = 'Foo'\n    assert cfg.project == 'Foo'\n\n    # alternative access via item interface\n    cfg['project'] = 'Sphinx Tests'\n    assert cfg['project'] == cfg.project == 'Sphinx Tests'\n", "type": "function"}, {"name": "Config", "docstring": "Configuration file abstraction.\n\nThe Config object makes the values of all config options available as\nattributes.\n\nIt is exposed via the :py:class:`~sphinx.application.Sphinx`\\ ``.config``\nand :py:class:`sphinx.environment.BuildEnvironment`\\ ``.config`` attributes.\nFor example, to get the value of :confval:`language`, use either\n``app.config.language`` or ``env.config.language``.", "methods": ["__init__", "values", "overrides", "verbosity", "read", "convert_overrides", "pre_init_values", "init_values", "_report_override_warnings", "__repr__", "__setattr__", "__getattr__", "__getitem__", "__setitem__", "__delitem__", "__contains__", "__iter__", "add", "filter", "__getstate__", "__setstate__", "__init__"], "attributes": ["c_id_attributes", "c_paren_attributes", "c_extra_keywords"], "code_location": {"file": "config.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx", "start_line": 208, "end_line": 574}, "type": "class"}, {"name": "setup", "is_method": false, "class_name": null, "parameters": ["app"], "calls": ["app.add_config_value", "app.add_config_value", "app.add_config_value"], "code_location": {"file": "conf.py", "path": "/data3/pwh/swebench-repos/sphinx/tests/roots/test-ext-ifconfig", "start_line": 7, "end_line": 10}, "code_snippet": "def setup(app):\n    app.add_config_value('confval1', False, None)\n    app.add_config_value('confval2', False, None)\n    app.add_config_value('false_config', False, None)\n", "type": "function"}, {"name": "Sphinx", "docstring": "The main application class and extensibility interface.\n\n:ivar srcdir: Directory containing source.\n:ivar confdir: Directory containing ``conf.py``.\n:ivar doctreedir: Directory for storing pickled doctrees.\n:ivar outdir: Directory for storing build documents.", "methods": ["__init__", "fresh_env_used", "phase", "_init_i18n", "_init_env", "_create_fresh_env", "_load_existing_env", "_post_init_env", "preload_builder", "create_builder", "_init_builder", "build", "setup_extension", "require_sphinx", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "disconnect", "emit", "emit_firstresult", "add_builder", "add_config_value", "add_event", "set_translator", "add_node", "add_enumerable_node", "add_directive", "add_role", "add_generic_role", "add_domain", "add_directive_to_domain", "add_role_to_domain", "add_index_to_domain", "add_object_type", "add_crossref_type", "add_transform", "add_post_transform", "add_js_file", "add_css_file", "add_latex_package", "add_lexer", "add_autodocumenter", "add_autodoc_attrgetter", "add_search_language", "add_source_suffix", "add_source_parser", "add_env_collector", "add_html_theme", "add_html_math_renderer", "add_message_catalog", "is_parallel_allowed", "set_html_assets_policy"], "attributes": ["srcdir", "confdir", "outdir", "doctreedir"], "code_location": {"file": "application.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx", "start_line": 142, "end_line": 1822}, "type": "class"}, {"name": "add_config_value", "is_method": true, "class_name": "Sphinx", "parameters": ["self", "name", "default", "rebuild", "types", "description"], "calls": ["logger.debug", "self.config.add"], "code_location": {"file": "application.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx", "start_line": 905, "end_line": 956}, "code_snippet": "    def add_config_value(\n        self,\n        name: str,\n        default: Any,\n        rebuild: _ConfigRebuild,\n        types: type | Collection[type] | ENUM = (),\n        description: str = '',\n    ) -> None:\n        \"\"\"Register a configuration value.\n\n        This is necessary for Sphinx to recognize new values and set default\n        values accordingly.\n\n\n        :param name: The name of the configuration value.  It is recommended to be prefixed\n                     with the extension name (ex. ``html_logo``, ``epub_title``)\n        :param default: The default value of the configuration.\n        :param rebuild: The condition of rebuild.  It must be one of those values:\n\n                        * ``'env'`` if a change in the setting only takes effect when a\n                          document is parsed -- this means that the whole environment must be\n                          rebuilt.\n                        * ``'html'`` if a change in the setting needs a full rebuild of HTML\n                          documents.\n                        * ``''`` if a change in the setting will not need any special rebuild.\n        :param types: The type of configuration value.  A list of types can be specified.  For\n                      example, ``[str]`` is used to describe a configuration that takes string\n                      value.\n        :param description: A short description of the configuration value.\n\n        .. versionchanged:: 0.4\n           If the *default* value is a callable, it will be called with the\n           config object as its argument in order to get the default value.\n           This can be used to implement config values whose default depends on\n           other values.\n\n        .. versionchanged:: 0.6\n           Changed *rebuild* from a simple boolean (equivalent to ``''`` or\n           ``'env'``) to a string.  However, booleans are still accepted and\n           converted internally.\n\n        .. versionadded:: 7.4\n           The *description* parameter.\n        \"\"\"\n        logger.debug('[app] adding config value: %r', (name, default, rebuild, types))\n        self.config.add(\n            name=name,\n            default=default,\n            rebuild=rebuild,\n            types=types,\n            description=description,\n        )\n", "type": "function"}, {"name": "setup", "is_method": false, "class_name": null, "parameters": ["app"], "calls": ["app.connect", "app.connect", "app.connect", "app.connect", "app.connect", "app.connect", "app.connect", "app.connect", "app.connect"], "code_location": {"file": "config.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx", "start_line": 911, "end_line": 926}, "code_snippet": "def setup(app: Sphinx) -> ExtensionMetadata:\n    app.connect('config-inited', deprecate_source_encoding, priority=790)\n    app.connect('config-inited', convert_source_suffix, priority=800)\n    app.connect('config-inited', convert_highlight_options, priority=800)\n    app.connect('config-inited', init_numfig_format, priority=800)\n    app.connect('config-inited', evaluate_copyright_placeholders, priority=795)\n    app.connect('config-inited', correct_copyright_year, priority=800)\n    app.connect('config-inited', check_confval_types, priority=800)\n    app.connect('config-inited', check_primary_domain, priority=800)\n    app.connect('env-get-outdated', check_master_doc)\n\n    return {\n        'version': 'builtin',\n        'parallel_read_safe': True,\n        'parallel_write_safe': True,\n    }\n", "type": "function"}, {"name": "validate_config_values", "is_method": false, "class_name": null, "parameters": ["app"], "calls": ["logger.warning", "_XML_NAME_PATTERN.match", "logger.warning", "logger.warning", "logger.warning", "logger.warning", "logger.warning", "logger.warning", "logger.warning", "logger.warning", "logger.warning", "__", "__", "__", "__", "__", "__", "__", "__", "__", "__"], "code_location": {"file": "epub3.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/builders", "start_line": 217, "end_line": 269}, "code_snippet": "def validate_config_values(app: Sphinx) -> None:\n    if app.builder.name != 'epub':\n        return\n\n    # <package> lang attribute, dc:language\n    if not app.config.epub_language:\n        logger.warning(\n            __(\n                'conf value \"epub_language\" (or \"language\") '\n                'should not be empty for EPUB3'\n            )\n        )\n    # <package> unique-identifier attribute\n    if not _XML_NAME_PATTERN.match(app.config.epub_uid):\n        logger.warning(__('conf value \"epub_uid\" should be XML NAME for EPUB3'))\n    # dc:title\n    if not app.config.epub_title:\n        logger.warning(\n            __(\n                'conf value \"epub_title\" (or \"html_title\") '\n                'should not be empty for EPUB3'\n            )\n        )\n    # dc:creator\n    if not app.config.epub_author:\n        logger.warning(__('conf value \"epub_author\" should not be empty for EPUB3'))\n    # dc:contributor\n    if not app.config.epub_contributor:\n        logger.warning(\n            __('conf value \"epub_contributor\" should not be empty for EPUB3')\n        )\n    # dc:description\n    if not app.config.epub_description:\n        logger.warning(\n            __('conf value \"epub_description\" should not be empty for EPUB3')\n        )\n    # dc:publisher\n    if not app.config.epub_publisher:\n        logger.warning(__('conf value \"epub_publisher\" should not be empty for EPUB3'))\n    # dc:rights\n    if not app.config.epub_copyright:\n        logger.warning(\n            __(\n                'conf value \"epub_copyright\" (or \"copyright\")'\n                'should not be empty for EPUB3'\n            )\n        )\n    # dc:identifier\n    if not app.config.epub_identifier:\n        logger.warning(__('conf value \"epub_identifier\" should not be empty for EPUB3'))\n    # meta ibooks:version\n    if not app.config.version:\n        logger.warning(__('conf value \"version\" should not be empty for EPUB3'))\n", "type": "function"}, {"name": "test_add_config_values", "is_method": true, "class_name": "TestSetup", "parameters": ["self"], "calls": ["mock.Mock", "setup", "pytest.fail", "pytest.fail", "pytest.fail"], "code_location": {"file": "test_ext_napoleon.py", "path": "/data3/pwh/swebench-repos/sphinx/tests/test_extensions", "start_line": 115, "end_line": 140}, "code_snippet": "    def test_add_config_values(self):\n        app = mock.Mock(Sphinx)\n        setup(app)\n        for name, _default, _rebuild, _types in Config._config_values:\n            has_config = False\n            for method_name, args, _kwargs in app.method_calls:\n                if method_name == 'add_config_value' and args[0] == name:\n                    has_config = True\n            if not has_config:\n                pytest.fail('Config value was not added to app %s' % name)\n\n        has_process_docstring = False\n        has_skip_member = False\n        for method_name, args, _kwargs in app.method_calls:\n            if method_name == 'connect':\n                if (\n                    args[0] == 'autodoc-process-docstring'\n                    and args[1] == _process_docstring\n                ):\n                    has_process_docstring = True\n                elif args[0] == 'autodoc-skip-member' and args[1] == _skip_member:\n                    has_skip_member = True\n        if not has_process_docstring:\n            pytest.fail('autodoc-process-docstring never connected')\n        if not has_skip_member:\n            pytest.fail('autodoc-skip-member never connected')\n", "type": "function"}, {"name": "check_confval_types", "is_method": false, "class_name": null, "parameters": ["app", "config"], "calls": ["config._options.items", "getattr", "callable", "isinstance", "type", "type", "common_bases.discard", "default", "frozenset", "set", "__", "sorted", "logger.warning", "__", "logger.warning", "valid_types.match", "__", "logger.warning", "setattr", "len", "join", "msg.format", "msg.format", "msg.format", "frozenset", "setattr", "join", "tuple"], "code_location": {"file": "config.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx", "start_line": 789, "end_line": 863}, "code_snippet": "def check_confval_types(app: Sphinx | None, config: Config) -> None:\n    \"\"\"Check all values for deviation from the default value's type, since\n    that can result in TypeErrors all over the place NB.\n    \"\"\"\n    for name, opt in config._options.items():\n        default = opt.default\n        valid_types = opt.valid_types\n        value = getattr(config, name)\n\n        if callable(default):\n            default = default(config)  # evaluate default value\n        if default is None and not valid_types:\n            continue  # neither inferable nor explicitly annotated types\n\n        if valid_types == frozenset({Any}):  # any type of value is accepted\n            continue\n\n        if isinstance(valid_types, ENUM):\n            if not valid_types.match(value):\n                msg = __(\n                    'The config value `{name}` has to be a one of {candidates}, '\n                    'but `{current}` is given.'\n                )\n                logger.warning(\n                    msg.format(\n                        name=name, current=value, candidates=valid_types._candidates\n                    ),\n                    once=True,\n                )\n            continue\n\n        type_value = type(value)\n        type_default = type(default)\n\n        if type_value is type_default:  # attempt to infer the type\n            continue\n\n        if type_value in valid_types:  # check explicitly listed types\n            if frozenset in valid_types and type_value in {list, tuple, set}:\n                setattr(config, name, frozenset(value))\n            elif tuple in valid_types and type_value is list:\n                setattr(config, name, tuple(value))\n            continue\n\n        common_bases = {*type_value.__bases__, type_value} & set(type_default.__bases__)\n        common_bases.discard(object)\n        if common_bases:\n            continue  # at least we share a non-trivial base class\n\n        if valid_types:\n            msg = __(\n                \"The config value `{name}' has type `{current.__name__}'; \"\n                'expected {permitted}.'\n            )\n            wrapped_valid_types = sorted(f\"`{c.__name__}'\" for c in valid_types)\n            if len(wrapped_valid_types) > 2:\n                permitted = (\n                    ', '.join(wrapped_valid_types[:-1])\n                    + f', or {wrapped_valid_types[-1]}'\n                )\n            else:\n                permitted = ' or '.join(wrapped_valid_types)\n            logger.warning(\n                msg.format(name=name, current=type_value, permitted=permitted),\n                once=True,\n            )\n        else:\n            msg = __(\n                \"The config value `{name}' has type `{current.__name__}', \"\n                \"defaults to `{default.__name__}'.\"\n            )\n            logger.warning(\n                msg.format(name=name, current=type_value, default=type_default),\n                once=True,\n            )\n", "type": "function"}, {"name": "test_builtin_conf", "is_method": false, "class_name": null, "parameters": ["app"], "calls": ["pytest.mark.sphinx", "app.warning.getvalue"], "code_location": {"file": "test_config.py", "path": "/data3/pwh/swebench-repos/sphinx/tests/test_config", "start_line": 454, "end_line": 465}, "code_snippet": "def test_builtin_conf(app: SphinxTestApp) -> None:\n    warnings = app.warning.getvalue()\n    assert 'root_doc' in warnings, (\n        'override on builtin \"root_doc\" should raise a type warning'\n    )\n    assert 'language' not in warnings, (\n        'explicitly permitted override on builtin \"language\" should NOT raise '\n        'a type warning'\n    )\n    assert 'primary_domain' not in warnings, (\n        'override to None on builtin \"primary_domain\" should NOT raise a type warning'\n    )\n", "type": "function"}], "retrieved_count": 10, "cost_time": 0.4069335460662842}
{"question": "Where are Sphinx's built-in directive implementations located in the codebase?", "answer": null, "relative_code_list": null, "ground_truth": "Sphinx's built-in directive implementations are located throughout the codebase, organized by functionality and domain. The directives are distributed across multiple modules and directories to provide modularity and domain-specific functionality.\n\nKey locations where built-in directive implementations are located include:\n\n1. **sphinx/directives/**: This directory contains many of Sphinx's built-in directive implementations, organized into subdirectories and files based on functionality. This includes general-purpose directives for document structure and formatting.\n\n2. **sphinx/directives/admonitions.py**: Contains directive implementations for admonitions like note, warning, tip, etc.\n\n3. **sphinx/directives/code.py**: Contains directive implementations for code blocks, literal includes, and other code-related directives.\n\n4. **sphinx/directives/other.py**: Contains various other directive implementations for general document structure and formatting.\n\n5. **sphinx/directives/patches.py**: Contains directive implementations that patch or extend Docutils functionality.\n\n6. **sphinx/domains/**: Domain-specific directive implementations are stored in domain modules, with each domain providing directives specific to that domain's functionality.\n\n7. **sphinx/domains/python.py**: Contains Python domain-specific directive implementations like `py:function`, `py:class`, `py:module`, etc.\n\n8. **sphinx/domains/cpp.py**: Contains C++ domain-specific directive implementations for C++ objects like classes, functions, namespaces, etc.\n\n9. **sphinx/domains/c.py**: Contains C domain-specific directive implementations.\n\n10. **sphinx/domains/js.py**: Contains JavaScript domain-specific directive implementations.\n\n11. **sphinx/domains/rst.py**: Contains reStructuredText domain-specific directive implementations.\n\n12. **sphinx/domains/math.py**: Contains math domain-specific directive implementations.\n\n13. **sphinx/domains/std.py**: Contains standard domain directive implementations for general-purpose directives like `glossary`, `productionlist`, etc.\n\n14. **sphinx/ext/**: Various extension modules contain their own directive implementations, particularly for extension-specific functionality.\n\n15. **sphinx/util/docutils.py**: Contains base classes and utility functions for directive implementation, including the SphinxDirective base class.\n\nThe directive implementations are registered with the SphinxComponentRegistry during the extension setup process, making them available for use in documentation. Each directive typically extends the appropriate base class and implements the necessary methods for processing the directive content.", "score": null, "retrieved_content": [{"name": "setup", "is_method": false, "class_name": null, "parameters": ["app"], "calls": ["directives.register_directive", "directives.register_directive", "directives.register_directive", "directives.register_directive", "directives.register_directive", "directives.register_directive", "directives.register_directive", "directives.register_directive", "directives.register_directive", "directives.register_directive", "directives.register_directive", "directives.register_directive"], "code_location": {"file": "other.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/directives", "start_line": 420, "end_line": 442}, "code_snippet": "def setup(app: Sphinx) -> ExtensionMetadata:\n    directives.register_directive('toctree', TocTree)\n    directives.register_directive('sectionauthor', Author)\n    directives.register_directive('moduleauthor', Author)\n    directives.register_directive('codeauthor', Author)\n    directives.register_directive('tabularcolumns', TabularColumns)\n    directives.register_directive('centered', Centered)\n    directives.register_directive('acks', Acks)\n    directives.register_directive('hlist', HList)\n    directives.register_directive('only', Only)\n    directives.register_directive('include', Include)\n\n    # register the standard rst class directive under a different name\n    # only for backwards compatibility now\n    directives.register_directive('cssclass', Class)\n    # new standard name when default-domain with \"class\" is in effect\n    directives.register_directive('rst-class', Class)\n\n    return {\n        'version': 'builtin',\n        'parallel_read_safe': True,\n        'parallel_write_safe': True,\n    }\n", "type": "function"}, {"name": "SphinxDirective", "docstring": "A base class for Sphinx directives.\n\nThis class provides helper methods for Sphinx directives.\n\n.. versionadded:: 1.8\n\n.. note:: The subclasses of this class might not work with docutils.\n          This class is strongly coupled with Sphinx.", "methods": ["env", "config", "get_source_info", "set_source_info", "get_location", "parse_content_to_nodes", "parse_text_to_nodes", "parse_inline"], "attributes": [], "code_location": {"file": "docutils.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/util", "start_line": 472, "end_line": 600}, "type": "class"}, {"name": "setup", "is_method": false, "class_name": null, "parameters": ["app"], "calls": ["directives.register_directive", "directives.register_directive", "directives.register_directive", "directives.register_directive", "directives.register_directive", "directives.register_directive"], "code_location": {"file": "patches.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/directives", "start_line": 228, "end_line": 240}, "code_snippet": "def setup(app: Sphinx) -> ExtensionMetadata:\n    directives.register_directive('figure', Figure)\n    directives.register_directive('meta', Meta)\n    directives.register_directive('csv-table', CSVTable)\n    directives.register_directive('code', Code)\n    directives.register_directive('math', MathDirective)\n    directives.register_directive('rubric', Rubric)\n\n    return {\n        'version': 'builtin',\n        'parallel_read_safe': True,\n        'parallel_write_safe': True,\n    }\n", "type": "function"}, {"name": "setup", "is_method": false, "class_name": null, "parameters": ["app"], "calls": ["app.add_directive", "app.add_directive", "app.add_directive", "app.add_directive", "app.add_directive", "app.add_directive", "app.add_directive", "app.add_directive", "app.add_directive", "app.add_directive", "app.add_directive"], "code_location": {"file": "admonitions.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/directives", "start_line": 90, "end_line": 107}, "code_snippet": "def setup(app: Sphinx) -> ExtensionMetadata:\n    app.add_directive('admonition', Admonition, override=True)\n    app.add_directive('attention', Attention, override=True)\n    app.add_directive('caution', Caution, override=True)\n    app.add_directive('danger', Danger, override=True)\n    app.add_directive('error', Error, override=True)\n    app.add_directive('hint', Hint, override=True)\n    app.add_directive('important', Important, override=True)\n    app.add_directive('note', Note, override=True)\n    app.add_directive('tip', Tip, override=True)\n    app.add_directive('warning', Warning, override=True)\n    app.add_directive('seealso', SeeAlso, override=True)\n\n    return {\n        'version': 'builtin',\n        'parallel_read_safe': True,\n        'parallel_write_safe': True,\n    }\n", "type": "function"}, {"name": "setup", "is_method": false, "class_name": null, "parameters": ["app"], "calls": ["directives.register_directive", "directives.register_directive", "directives.register_directive", "directives.register_directive"], "code_location": {"file": "code.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/directives", "start_line": 504, "end_line": 514}, "code_snippet": "def setup(app: Sphinx) -> ExtensionMetadata:\n    directives.register_directive('highlight', Highlight)\n    directives.register_directive('code-block', CodeBlock)\n    directives.register_directive('sourcecode', CodeBlock)\n    directives.register_directive('literalinclude', LiteralInclude)\n\n    return {\n        'version': 'builtin',\n        'parallel_read_safe': True,\n        'parallel_write_safe': True,\n    }\n", "type": "function"}, {"name": "directive", "is_method": true, "class_name": "CustomReSTDispatcher", "parameters": ["self", "directive_name", "language_module", "document"], "calls": ["self.directive_func"], "code_location": {"file": "docutils.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/util", "start_line": 274, "end_line": 280}, "code_snippet": "    def directive(\n        self,\n        directive_name: str,\n        language_module: ModuleType,\n        document: nodes.document,\n    ) -> tuple[type[Directive] | None, list[system_message]]:\n        return self.directive_func(directive_name, language_module, document)\n", "type": "function"}, {"name": "setup", "is_method": false, "class_name": null, "parameters": ["app"], "calls": ["app.add_config_value", "directives.register_directive", "directives.register_directive", "directives.register_directive", "directives.register_directive", "app.add_event", "frozenset"], "code_location": {"file": "__init__.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/directives", "start_line": 366, "end_line": 382}, "code_snippet": "def setup(app: Sphinx) -> ExtensionMetadata:\n    app.add_config_value(\n        'strip_signature_backslash', False, 'env', types=frozenset({bool})\n    )\n    directives.register_directive('default-role', DefaultRole)\n    directives.register_directive('default-domain', DefaultDomain)\n    directives.register_directive('describe', ObjectDescription)\n    # new, more consistent, name\n    directives.register_directive('object', ObjectDescription)\n\n    app.add_event('object-description-transform')\n\n    return {\n        'version': 'builtin',\n        'parallel_read_safe': True,\n        'parallel_write_safe': True,\n    }\n", "type": "function"}, {"name": "test_rst_directive", "is_method": false, "class_name": null, "parameters": ["app"], "calls": ["pytest.mark.sphinx", "restructuredtext.parse", "assert_node", "assert_node", "assert_node", "restructuredtext.parse", "assert_node", "assert_node", "assert_node"], "code_location": {"file": "test_domain_rst.py", "path": "/data3/pwh/swebench-repos/sphinx/tests/test_domains", "start_line": 41, "end_line": 86}, "code_snippet": "def test_rst_directive(app: SphinxTestApp) -> None:\n    # bare\n    text = '.. rst:directive:: toctree'\n    doctree = restructuredtext.parse(app, text)\n    assert_node(\n        doctree,\n        (\n            addnodes.index,\n            [desc, ([desc_signature, desc_name, '.. toctree::'], [desc_content, ()])],\n        ),\n    )\n    assert_node(\n        doctree[0],\n        entries=[('single', 'toctree (directive)', 'directive-toctree', '', None)],\n    )\n    assert_node(\n        doctree[1],\n        addnodes.desc,\n        desctype='directive',\n        domain='rst',\n        objtype='directive',\n        no_index=False,\n    )\n\n    # decorated\n    text = '.. rst:directive:: .. toctree::'\n    doctree = restructuredtext.parse(app, text)\n    assert_node(\n        doctree,\n        (\n            addnodes.index,\n            [desc, ([desc_signature, desc_name, '.. toctree::'], [desc_content, ()])],\n        ),\n    )\n    assert_node(\n        doctree[0],\n        entries=[('single', 'toctree (directive)', 'directive-toctree', '', None)],\n    )\n    assert_node(\n        doctree[1],\n        addnodes.desc,\n        desctype='directive',\n        domain='rst',\n        objtype='directive',\n        no_index=False,\n    )\n", "type": "function"}, {"name": "DoctestDirective", "docstring": "", "methods": [], "attributes": [], "code_location": {"file": "doctest.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/ext", "start_line": 162, "end_line": 170}, "type": "class"}, {"name": "setup", "is_method": false, "class_name": null, "parameters": ["app"], "calls": ["app.add_directive", "app.add_object_type", "app.add_js_file", "app.add_source_suffix", "app.add_source_parser"], "code_location": {"file": "conf.py", "path": "/data3/pwh/swebench-repos/sphinx/tests/roots/test-root", "start_line": 159, "end_line": 168}, "code_snippet": "def setup(app):\n    import parsermod\n\n    app.add_directive('clsdir', ClassDirective)\n    app.add_object_type(\n        'userdesc', 'userdescrole', '%s (userdesc)', userdesc_parse, objname='user desc'\n    )\n    app.add_js_file('file://moo.js')\n    app.add_source_suffix('.foo', 'foo')\n    app.add_source_parser(parsermod.Parser)\n", "type": "function"}], "retrieved_count": 10, "cost_time": 0.4009525775909424}
{"question": "How does Sphinx implement its document building system?", "answer": null, "relative_code_list": null, "ground_truth": "Sphinx implements its document building system through a sophisticated multi-phase architecture that coordinates various components to transform source documents into finished output. The system is designed to be modular, extensible, and efficient.\n\nThe document building system works through the following key mechanisms:\n\n1. **Multi-Phase Build Process**: Sphinx uses a structured build process with distinct phases: initialization, reading, consistency checking, resolving, and writing. Each phase has specific responsibilities and can be extended through the event system.\n\n2. **Builder Pattern**: The system uses a Builder pattern where different builder classes handle specific output formats (HTML, LaTeX, PDF, etc.). Each builder implements the core build workflow while providing format-specific functionality.\n\n3. **Component Registry**: The SphinxComponentRegistry manages all build components including parsers, transforms, builders, domains, and extensions. This provides a centralized system for component discovery and registration.\n\n4. **Event-Driven Architecture**: The build process is orchestrated through an event system that allows extensions to hook into various stages of the build. Events like 'config-inited', 'builder-inited', 'doctree-read', and 'doctree-resolved' provide extension points.\n\n5. **Document Tree Processing**: Source documents are parsed into docutils document trees, which are then processed through various transforms that handle cross-references, indexing, and other modifications.\n\n6. **Environment Management**: The BuildEnvironment class maintains the state of the build, including cross-references, metadata, and document relationships. This environment is serialized between builds for incremental build support.\n\n7. **Domain System**: Specialized domains (Python, C++, etc.) provide domain-specific functionality for object descriptions, cross-references, and indexing.\n\n8. **Transform Pipeline**: Document trees are processed through a series of transforms that handle various aspects of document processing, from cross-reference resolution to output-specific modifications.\n\n9. **Caching and Incremental Builds**: The system implements sophisticated caching mechanisms that allow for efficient incremental builds by only processing changed files.\n\n10. **Parallel Processing**: The system supports parallel document processing to improve build performance on multi-core systems.\n\nThis architecture provides the flexibility and performance needed to handle complex documentation projects while maintaining extensibility through the extension system.", "score": null, "retrieved_content": [{"name": "Sphinx", "docstring": "The main application class and extensibility interface.\n\n:ivar srcdir: Directory containing source.\n:ivar confdir: Directory containing ``conf.py``.\n:ivar doctreedir: Directory for storing pickled doctrees.\n:ivar outdir: Directory for storing build documents.", "methods": ["__init__", "fresh_env_used", "phase", "_init_i18n", "_init_env", "_create_fresh_env", "_load_existing_env", "_post_init_env", "preload_builder", "create_builder", "_init_builder", "build", "setup_extension", "require_sphinx", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "disconnect", "emit", "emit_firstresult", "add_builder", "add_config_value", "add_event", "set_translator", "add_node", "add_enumerable_node", "add_directive", "add_role", "add_generic_role", "add_domain", "add_directive_to_domain", "add_role_to_domain", "add_index_to_domain", "add_object_type", "add_crossref_type", "add_transform", "add_post_transform", "add_js_file", "add_css_file", "add_latex_package", "add_lexer", "add_autodocumenter", "add_autodoc_attrgetter", "add_search_language", "add_source_suffix", "add_source_parser", "add_env_collector", "add_html_theme", "add_html_math_renderer", "add_message_catalog", "is_parallel_allowed", "set_html_assets_policy"], "attributes": ["srcdir", "confdir", "outdir", "doctreedir"], "code_location": {"file": "application.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx", "start_line": 142, "end_line": 1822}, "type": "class"}, {"name": "BuildPhase", "docstring": "Build phase of Sphinx application.", "methods": [], "attributes": ["INITIALIZATION", "READING", "CONSISTENCY_CHECK", "RESOLVING", "WRITING"], "code_location": {"file": "build_phase.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/util", "start_line": 8, "end_line": 15}, "type": "class"}, {"name": "SphinxStandaloneReader", "docstring": "A basic document reader for Sphinx.", "methods": ["__init__", "_setup_transforms", "read", "read_source"], "attributes": [], "code_location": {"file": "io.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx", "start_line": 79, "end_line": 109}, "type": "class"}, {"name": "Builder", "docstring": "Builds target formats from the reST sources.", "methods": ["__init__", "app", "_translator", "get_translator_class", "create_translator", "init", "create_template_bridge", "get_target_uri", "get_relative_uri", "get_outdated_docs", "get_asset_paths", "post_process_images", "compile_catalogs", "compile_all_catalogs", "compile_specific_catalogs", "compile_update_catalogs", "build_all", "build_specific", "build_update", "build", "read", "_read_serial", "_read_parallel", "read_doc", "write_doctree", "write", "write_documents", "_write_serial", "_write_parallel", "prepare_writing", "copy_assets", "write_doc", "write_doc_serialized", "finish", "cleanup", "get_builder_config"], "attributes": ["srcdir", "confdir", "outdir", "doctreedir"], "code_location": {"file": "__init__.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/builders", "start_line": 64, "end_line": 881}, "type": "class"}, {"name": "BuildEnvironment", "docstring": "The environment in which the ReST files are translated.\nStores an inventory of cross-file targets and provides doctree\ntransformations to resolve links to them.", "methods": ["__init__", "__getstate__", "__setstate__", "setup", "app", "app", "app", "_registry", "_tags", "_config_status", "_update_settings", "set_versioning_method", "clear_doc", "merge_info_from", "path2doc", "doc2path", "relfn2path", "found_docs", "find_files", "get_outdated_files", "check_dependents", "prepare_settings", "temp_data", "docname", "parser", "new_serialno", "note_dependency", "note_included", "note_reread", "get_domain", "get_doctree", "master_doctree", "get_and_resolve_doctree", "resolve_toctree", "resolve_references", "apply_post_transforms", "collect_relations", "check_consistency"], "attributes": ["srcdir", "doctreedir"], "code_location": {"file": "__init__.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/environment", "start_line": 100, "end_line": 812}, "type": "class"}, {"name": "IndexBuilder", "docstring": "Helper class that creates a search index based on the doctrees\npassed to the `feed` method.", "methods": ["__init__", "load", "dump", "get_objects", "get_terms", "freeze", "label", "prune", "feed", "_word_collector", "context_for_searchtool", "get_js_stemmer_rawcodes", "get_js_stemmer_rawcode", "get_js_stemmer_code"], "attributes": ["formats"], "code_location": {"file": "__init__.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/search", "start_line": 263, "end_line": 592}, "type": "class"}, {"name": "EnvironmentCollector", "docstring": "An EnvironmentCollector is a specific data collector from each document.\n\nIt gathers data and stores :py:class:`BuildEnvironment\n<sphinx.environment.BuildEnvironment>` as a database.\nExamples of specific data would be images, download files, section titles, metadatas, index\nentries and toctrees, etc.\n\n.. note::\n\n    This class essentially wraps a sub-set of :ref:`Sphinx event callbacks <events>`.", "methods": ["enable", "disable", "clear_doc", "merge_other", "process_doc", "get_updated_docs", "get_outdated_docs"], "attributes": [], "code_location": {"file": "__init__.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/environment/collectors", "start_line": 16, "end_line": 102}, "type": "class"}, {"name": "XMLBuilder", "docstring": "Builds Docutils-native XML.", "methods": ["init", "get_outdated_docs", "get_target_uri", "write_doc", "_translate", "finish"], "attributes": ["name", "format", "epilog", "out_suffix", "allow_parallel", "default_translator_class"], "code_location": {"file": "xml.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/builders", "start_line": 24, "end_line": 95}, "type": "class"}, {"name": "SphinxBaseReader", "docstring": "A base class of readers for Sphinx.\n\nThis replaces reporter by Sphinx's on generating document.", "methods": ["__init__", "get_transforms", "new_document"], "attributes": [], "code_location": {"file": "io.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx", "start_line": 35, "end_line": 76}, "type": "class"}, {"name": "SphinxFileOutput", "docstring": "Better FileOutput class for Sphinx.", "methods": ["__init__", "write"], "attributes": [], "code_location": {"file": "docutils.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/util", "start_line": 447, "end_line": 469}, "type": "class"}], "retrieved_count": 10, "cost_time": 0.3986070156097412}
{"question": "How does Sphinx's extension system work?", "answer": null, "relative_code_list": null, "ground_truth": "Sphinx's extension system works through a sophisticated plugin architecture that allows third-party code to extend and customize Sphinx's functionality without modifying the core codebase. The system is designed to be flexible, extensible, and maintainable.\n\nThe extension system operates through the following key mechanisms:\n\n1. **Extension Discovery and Loading**: Extensions are discovered through multiple mechanisms including the extensions list in conf.py, entry points in Python packages, and direct module imports. The SphinxComponentRegistry manages the loading and initialization of extensions.\n\n2. **Setup Function Protocol**: Each extension must provide a setup function that is called during Sphinx initialization. This function receives the Sphinx application instance and registers the extension's components with the system.\n\n3. **Component Registration**: Extensions can register various types of components including directives, roles, builders, domains, transforms, and event handlers. These components are stored in the SphinxComponentRegistry and made available throughout the build process.\n\n4. **Event System Integration**: Extensions can connect to Sphinx's event system by registering event handlers. These handlers are called at specific points during the build process, allowing extensions to modify documents, add functionality, or respond to build events.\n\n5. **Configuration Integration**: Extensions can add configuration options to Sphinx's configuration system, allowing users to customize extension behavior through conf.py settings.\n\n6. **Build Phase Integration**: Extensions can hook into different phases of the build process (initialization, reading, resolving, writing) by connecting to appropriate events and implementing the necessary callback functions.\n\n7. **Environment Integration**: Extensions can store and retrieve data from the BuildEnvironment, allowing them to maintain state across the build process and implement features like caching and incremental builds.\n\n8. **Namespace Management**: The extension system provides namespace isolation, allowing extensions to add functionality without conflicts with other extensions or the core system.\n\n9. **Error Handling**: The extension system includes robust error handling that isolates extension failures from the core build process, ensuring that one problematic extension doesn't break the entire build.\n\n10. **Version Compatibility**: Extensions can specify version requirements and compatibility information, helping users understand which extensions work with their version of Sphinx.\n\nThis architecture allows Sphinx to support a rich ecosystem of extensions while maintaining stability and performance of the core system.", "score": null, "retrieved_content": [{"name": "load_extension", "is_method": true, "class_name": "SphinxComponentRegistry", "parameters": ["self", "app", "extname"], "calls": ["logger.warning", "__", "prefixed_warnings", "getattr", "Extension", "__", "import_module", "logger.warning", "logger.verbose", "ExtensionError", "__", "setup", "isinstance", "logger.warning", "VersionRequirementError", "__", "__", "traceback.format_exc", "__", "__"], "code_location": {"file": "registry.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx", "start_line": 524, "end_line": 587}, "code_snippet": "    def load_extension(self, app: Sphinx, extname: str) -> None:\n        \"\"\"Load a Sphinx extension.\"\"\"\n        if extname in app.extensions:  # already loaded\n            return\n        if extname in EXTENSION_BLACKLIST:\n            logger.warning(\n                __(\n                    'the extension %r was already merged with Sphinx since '\n                    'version %s; this extension is ignored.'\n                ),\n                extname,\n                EXTENSION_BLACKLIST[extname],\n            )\n            return\n\n        # update loading context\n        prefix = __('while setting up extension %s:') % extname\n        with prefixed_warnings(prefix):\n            try:\n                mod = import_module(extname)\n            except ImportError as err:\n                logger.verbose(__('Original exception:\\n') + traceback.format_exc())\n                raise ExtensionError(\n                    __('Could not import extension %s') % extname, err\n                ) from err\n\n            setup: _ExtensionSetupFunc | None = getattr(mod, 'setup', None)\n            if setup is None:\n                logger.warning(\n                    __(\n                        'extension %r has no setup() function; is it really '\n                        'a Sphinx extension module?'\n                    ),\n                    extname,\n                )\n                metadata: ExtensionMetadata = {}\n            else:\n                try:\n                    metadata = setup(app)\n                except VersionRequirementError as err:\n                    # add the extension name to the version required\n                    raise VersionRequirementError(\n                        __(\n                            'The %s extension used by this project needs at least '\n                            'Sphinx v%s; it therefore cannot be built with this '\n                            'version.'\n                        )\n                        % (extname, err),\n                    ) from err\n\n            if metadata is None:\n                metadata = {}\n            elif not isinstance(metadata, dict):\n                logger.warning(\n                    __(\n                        'extension %r returned an unsupported object from '\n                        'its setup() function; it should return None or a '\n                        'metadata dictionary'\n                    ),\n                    extname,\n                )\n                metadata = {}\n\n            app.extensions[extname] = Extension(extname, mod, **metadata)\n", "type": "function"}, {"name": "setup", "is_method": false, "class_name": null, "parameters": ["app"], "calls": ["_patch_python_domain", "app.setup_extension", "app.connect", "app.connect", "isinstance", "app.add_config_value"], "code_location": {"file": "__init__.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/ext/napoleon", "start_line": 300, "end_line": 341}, "code_snippet": "def setup(app: Sphinx) -> ExtensionMetadata:\n    \"\"\"Sphinx extension setup function.\n\n    When the extension is loaded, Sphinx imports this module and executes\n    the ``setup()`` function, which in turn notifies Sphinx of everything\n    the extension offers.\n\n    Parameters\n    ----------\n    app : sphinx.application.Sphinx\n        Application object representing the Sphinx process\n\n    See Also\n    --------\n    `The Sphinx documentation on Extensions\n    <https://www.sphinx-doc.org/extensions.html>`_\n\n    `The Extension Tutorial <https://www.sphinx-doc.org/extdev/tutorial.html>`_\n\n    `The Extension API <https://www.sphinx-doc.org/extdev/appapi.html>`_\n\n    \"\"\"\n    if not isinstance(app, Sphinx):\n        # probably called by tests\n        return {\n            'version': sphinx.__display_version__,\n            'parallel_read_safe': True,\n        }\n\n    _patch_python_domain()\n\n    app.setup_extension('sphinx.ext.autodoc')\n    app.connect('autodoc-process-docstring', _process_docstring)\n    app.connect('autodoc-skip-member', _skip_member)\n\n    for name, default, rebuild, types in Config._config_values:\n        app.add_config_value(name, default, rebuild, types=types)\n\n    return {\n        'version': sphinx.__display_version__,\n        'parallel_read_safe': True,\n    }\n", "type": "function"}, {"name": "setup", "is_method": false, "class_name": null, "parameters": ["app"], "calls": ["app.add_transform", "app.add_transform", "app.add_transform", "app.add_transform", "app.add_transform", "app.add_transform", "app.add_transform", "app.add_transform", "app.add_transform", "app.add_transform", "app.add_transform", "app.add_transform", "app.add_transform", "app.add_transform", "app.add_transform"], "code_location": {"file": "__init__.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/transforms", "start_line": 511, "end_line": 532}, "code_snippet": "def setup(app: Sphinx) -> ExtensionMetadata:\n    app.add_transform(ApplySourceWorkaround)\n    app.add_transform(ExtraTranslatableNodes)\n    app.add_transform(DefaultSubstitutions)\n    app.add_transform(MoveModuleTargets)\n    app.add_transform(HandleCodeBlocks)\n    app.add_transform(SortIds)\n    app.add_transform(DoctestTransform)\n    app.add_transform(AutoNumbering)\n    app.add_transform(AutoIndexUpgrader)\n    app.add_transform(FilterSystemMessages)\n    app.add_transform(UnreferencedFootnotesDetector)\n    app.add_transform(SphinxSmartQuotes)\n    app.add_transform(DoctreeReadEvent)\n    app.add_transform(GlossarySorter)\n    app.add_transform(ReorderConsecutiveTargetAndIndexNodes)\n\n    return {\n        'version': 'builtin',\n        'parallel_read_safe': True,\n        'parallel_write_safe': True,\n    }\n", "type": "function"}, {"name": "Sphinx", "docstring": "The main application class and extensibility interface.\n\n:ivar srcdir: Directory containing source.\n:ivar confdir: Directory containing ``conf.py``.\n:ivar doctreedir: Directory for storing pickled doctrees.\n:ivar outdir: Directory for storing build documents.", "methods": ["__init__", "fresh_env_used", "phase", "_init_i18n", "_init_env", "_create_fresh_env", "_load_existing_env", "_post_init_env", "preload_builder", "create_builder", "_init_builder", "build", "setup_extension", "require_sphinx", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "disconnect", "emit", "emit_firstresult", "add_builder", "add_config_value", "add_event", "set_translator", "add_node", "add_enumerable_node", "add_directive", "add_role", "add_generic_role", "add_domain", "add_directive_to_domain", "add_role_to_domain", "add_index_to_domain", "add_object_type", "add_crossref_type", "add_transform", "add_post_transform", "add_js_file", "add_css_file", "add_latex_package", "add_lexer", "add_autodocumenter", "add_autodoc_attrgetter", "add_search_language", "add_source_suffix", "add_source_parser", "add_env_collector", "add_html_theme", "add_html_math_renderer", "add_message_catalog", "is_parallel_allowed", "set_html_assets_policy"], "attributes": ["srcdir", "confdir", "outdir", "doctreedir"], "code_location": {"file": "application.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx", "start_line": 142, "end_line": 1822}, "type": "class"}, {"name": "setup", "is_method": false, "class_name": null, "parameters": ["app"], "calls": ["app.add_transform", "app.add_transform"], "code_location": {"file": "references.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/transforms", "start_line": 44, "end_line": 52}, "code_snippet": "def setup(app: Sphinx) -> ExtensionMetadata:\n    app.add_transform(SphinxDanglingReferences)\n    app.add_transform(SphinxDomains)\n\n    return {\n        'version': 'builtin',\n        'parallel_read_safe': True,\n        'parallel_write_safe': True,\n    }\n", "type": "function"}, {"name": "setup", "is_method": false, "class_name": null, "parameters": ["app"], "calls": ["app.add_transform", "app.add_transform", "app.add_transform", "app.add_transform", "app.add_transform"], "code_location": {"file": "i18n.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/transforms", "start_line": 694, "end_line": 705}, "code_snippet": "def setup(app: Sphinx) -> ExtensionMetadata:\n    app.add_transform(PreserveTranslatableMessages)\n    app.add_transform(Locale)\n    app.add_transform(TranslationProgressTotaliser)\n    app.add_transform(AddTranslationClasses)\n    app.add_transform(RemoveTranslatableInline)\n\n    return {\n        'version': 'builtin',\n        'parallel_read_safe': True,\n        'parallel_write_safe': True,\n    }\n", "type": "function"}, {"name": "setup", "is_method": false, "class_name": null, "parameters": ["app"], "calls": ["app.add_post_transform", "app.add_post_transform"], "code_location": {"file": "images.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/transforms/post_transforms", "start_line": 294, "end_line": 302}, "code_snippet": "def setup(app: Sphinx) -> ExtensionMetadata:\n    app.add_post_transform(ImageDownloader)\n    app.add_post_transform(DataURIExtractor)\n\n    return {\n        'version': 'builtin',\n        'parallel_read_safe': True,\n        'parallel_write_safe': True,\n    }\n", "type": "function"}, {"name": "setup", "is_method": false, "class_name": null, "parameters": ["app"], "calls": ["app.add_post_transform", "app.add_post_transform", "app.add_post_transform", "app.add_post_transform"], "code_location": {"file": "__init__.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/transforms/post_transforms", "start_line": 393, "end_line": 403}, "code_snippet": "def setup(app: Sphinx) -> ExtensionMetadata:\n    app.add_post_transform(ReferencesResolver)\n    app.add_post_transform(OnlyNodeTransform)\n    app.add_post_transform(SigElementFallbackTransform)\n    app.add_post_transform(PropagateDescDomain)\n\n    return {\n        'version': 'builtin',\n        'parallel_read_safe': True,\n        'parallel_write_safe': True,\n    }\n", "type": "function"}, {"name": "test_extensions", "is_method": false, "class_name": null, "parameters": ["app"], "calls": ["pytest.mark.sphinx", "app.setup_extension", "strip_escape_sequences", "app.warning.getvalue"], "code_location": {"file": "test_application.py", "path": "/data3/pwh/swebench-repos/sphinx/tests", "start_line": 86, "end_line": 89}, "code_snippet": "def test_extensions(app: SphinxTestApp) -> None:\n    app.setup_extension('shutil')\n    warning = strip_escape_sequences(app.warning.getvalue())\n    assert \"extension 'shutil' has no setup() function\" in warning\n", "type": "function"}, {"name": "setup", "is_method": false, "class_name": null, "parameters": ["app"], "calls": ["app.add_env_collector", "app.add_env_collector"], "code_location": {"file": "asset.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/environment/collectors", "start_line": 177, "end_line": 185}, "code_snippet": "def setup(app: Sphinx) -> ExtensionMetadata:\n    app.add_env_collector(ImageCollector)\n    app.add_env_collector(DownloadFileCollector)\n\n    return {\n        'version': 'builtin',\n        'parallel_read_safe': True,\n        'parallel_write_safe': True,\n    }\n", "type": "function"}], "retrieved_count": 10, "cost_time": 0.38866329193115234}
{"question": "How does Sphinx implement its search functionality?", "answer": null, "relative_code_list": null, "ground_truth": "Sphinx implements its search functionality through a combination of indexing, JavaScript-based client-side search, and server-side search capabilities. The search system is designed to provide fast and accurate search results across the entire documentation.\n\nThe search functionality is implemented through the following key components:\n\n1. **Search Index Generation**: During the build process, Sphinx generates a search index that contains information about all documents, including titles, content, and metadata. This index is typically stored as a JSON file that can be loaded by the search system.\n\n2. **HTML Builder Integration**: The HTML builder includes search functionality by generating the necessary JavaScript files and HTML elements for the search interface. This includes the search box, search results display, and search logic.\n\n3. **JavaScript Search Engine**: Sphinx uses a JavaScript-based search engine that runs in the browser to provide fast, client-side search capabilities. This engine can search through the generated index without requiring server requests.\n\n4. **Search Index Format**: The search index contains structured data about documents including document titles, section headings, content excerpts, and other metadata that can be searched.\n\n5. **Search Result Ranking**: The search system implements ranking algorithms to order search results by relevance, taking into account factors like exact matches, partial matches, and the location of matches within documents.\n\n6. **Cross-Reference Integration**: The search system can include information about cross-references and links, allowing users to search for and find related content across the documentation.\n\n7. **Extension Support**: The search functionality can be extended through Sphinx's extension system, allowing custom search implementations or modifications to the default search behavior.\n\n8. **Multi-language Support**: The search system can handle documentation in multiple languages, with appropriate indexing and search capabilities for each language.\n\n9. **Search Configuration**: Users can configure various aspects of the search functionality through Sphinx's configuration system, including search options and customizations.\n\n10. **Performance Optimization**: The search system is designed for performance, with efficient indexing algorithms and optimized search queries to provide fast results even for large documentation sets.\n\nThe search functionality is primarily implemented in the HTML builder and related modules, with the actual search logic distributed across JavaScript files and Python modules that handle index generation and search configuration.", "score": null, "retrieved_content": [{"name": "IndexBuilder", "docstring": "Helper class that creates a search index based on the doctrees\npassed to the `feed` method.", "methods": ["__init__", "load", "dump", "get_objects", "get_terms", "freeze", "label", "prune", "feed", "_word_collector", "context_for_searchtool", "get_js_stemmer_rawcodes", "get_js_stemmer_rawcode", "get_js_stemmer_code"], "attributes": ["formats"], "code_location": {"file": "__init__.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/search", "start_line": 263, "end_line": 592}, "type": "class"}, {"name": "SearchJapanese", "docstring": "Japanese search implementation: uses no stemmer, but word splitting is quite\ncomplicated.", "methods": ["__init__", "split", "word_filter", "stem"], "attributes": ["lang", "language_name"], "code_location": {"file": "ja.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/search", "start_line": 518, "end_line": 548}, "type": "class"}, {"name": "SearchLanguage", "docstring": "This class is the base class for search natural language preprocessors.  If\nyou want to add support for a new language, you should override the methods\nof this class.\n\nYou should override `lang` class property too (e.g. 'en', 'fr' and so on).\n\n.. attribute:: stopwords\n\n   This is a set of stop words of the target language.  Default `stopwords`\n   is empty.  This word is used for building index and embedded in JS.\n\n.. attribute:: js_splitter_code\n\n   Return splitter function of JavaScript version.  The function should be\n   named as ``splitQuery``.  And it should take a string and return list of\n   strings.\n\n   .. versionadded:: 3.0\n\n.. attribute:: js_stemmer_code\n\n   Return stemmer class of JavaScript version.  This class' name should be\n   ``Stemmer`` and this class must have ``stemWord`` method.  This string is\n   embedded as-is in searchtools.js.\n\n   This class is used to preprocess search word which Sphinx HTML readers\n   type, before searching index. Default implementation does nothing.", "methods": ["__init__", "split", "stem", "word_filter"], "attributes": ["js_stemmer_code", "_word_re"], "code_location": {"file": "__init__.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/search", "start_line": 45, "end_line": 120}, "type": "class"}, {"name": "Sphinx", "docstring": "The main application class and extensibility interface.\n\n:ivar srcdir: Directory containing source.\n:ivar confdir: Directory containing ``conf.py``.\n:ivar doctreedir: Directory for storing pickled doctrees.\n:ivar outdir: Directory for storing build documents.", "methods": ["__init__", "fresh_env_used", "phase", "_init_i18n", "_init_env", "_create_fresh_env", "_load_existing_env", "_post_init_env", "preload_builder", "create_builder", "_init_builder", "build", "setup_extension", "require_sphinx", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "disconnect", "emit", "emit_firstresult", "add_builder", "add_config_value", "add_event", "set_translator", "add_node", "add_enumerable_node", "add_directive", "add_role", "add_generic_role", "add_domain", "add_directive_to_domain", "add_role_to_domain", "add_index_to_domain", "add_object_type", "add_crossref_type", "add_transform", "add_post_transform", "add_js_file", "add_css_file", "add_latex_package", "add_lexer", "add_autodocumenter", "add_autodoc_attrgetter", "add_search_language", "add_source_suffix", "add_source_parser", "add_env_collector", "add_html_theme", "add_html_math_renderer", "add_message_catalog", "is_parallel_allowed", "set_html_assets_policy"], "attributes": ["srcdir", "confdir", "outdir", "doctreedir"], "code_location": {"file": "application.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx", "start_line": 142, "end_line": 1822}, "type": "class"}, {"name": "__init__", "is_method": true, "class_name": "Index", "parameters": ["self", "domain"], "calls": ["SphinxError"], "code_location": {"file": "_index.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/domains", "start_line": 81, "end_line": 85}, "code_snippet": "    def __init__(self, domain: Domain) -> None:\n        if not self.name or self.localname is None:\n            msg = f'Index subclass {self.__class__.__name__} has no valid name or localname'\n            raise SphinxError(msg)\n        self.domain = domain\n", "type": "function"}, {"name": "SphinxTransformer", "docstring": "A transformer for Sphinx.", "methods": ["set_environment", "apply_transforms"], "attributes": [], "code_location": {"file": "__init__.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/transforms", "start_line": 81, "end_line": 108}, "type": "class"}, {"name": "__init__", "is_method": true, "class_name": "IndexBuilder", "parameters": ["self", "env", "lang", "options", "scoring"], "calls": ["languages.get", "languages.get", "SearchEnglish", "isinstance", "lang_class.rsplit", "getattr", "lang_class", "lang_class", "open", "decode", "lang.partition", "import_module", "fp.read"], "code_location": {"file": "__init__.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/search", "start_line": 273, "end_line": 320}, "code_snippet": "    def __init__(\n        self, env: BuildEnvironment, lang: str, options: dict[str, str], scoring: str\n    ) -> None:\n        self._domains = env.domains\n        self._env_version = env.version\n        # docname -> title\n        self._titles: dict[str, str | None] = env._search_index_titles\n        # docname -> filename\n        self._filenames: dict[str, str] = env._search_index_filenames\n        # stemmed words -> set(docname)\n        self._mapping: dict[str, set[str]] = env._search_index_mapping\n        # stemmed words in titles -> set(docname)\n        self._title_mapping: dict[str, set[str]] = env._search_index_title_mapping\n        # docname -> all titles in document\n        self._all_titles: dict[str, list[tuple[str, str | None]]] = (\n            env._search_index_all_titles\n        )\n        # docname -> list(index entry)\n        self._index_entries: dict[str, list[tuple[str, str, str]]] = (\n            env._search_index_index_entries\n        )\n        # objtype -> index\n        self._objtypes: dict[tuple[str, str], int] = env._search_index_objtypes\n        # objtype index -> (domain, type, objname (localized))\n        self._objnames: dict[int, tuple[str, str, str]] = env._search_index_objnames\n        # add language-specific SearchLanguage instance\n        lang_class = languages.get(lang)\n\n        # fallback; try again with language-code\n        if lang_class is None and '_' in lang:\n            lang_class = languages.get(lang.partition('_')[0])\n\n        if lang_class is None:\n            self.lang: SearchLanguage = SearchEnglish(options)\n        elif isinstance(lang_class, str):\n            module, classname = lang_class.rsplit('.', 1)\n            lang_class: type[SearchLanguage] = getattr(import_module(module), classname)  # type: ignore[no-redef]\n            self.lang = lang_class(options)  # type: ignore[operator]\n        else:\n            # it's directly a class (e.g. added by app.add_search_language)\n            self.lang = lang_class(options)\n\n        if scoring:\n            with open(scoring, 'rb') as fp:\n                self.js_scorer_code = fp.read().decode()\n        else:\n            self.js_scorer_code = ''\n        self.js_splitter_code = ''\n", "type": "function"}, {"name": "SphinxFileOutput", "docstring": "Better FileOutput class for Sphinx.", "methods": ["__init__", "write"], "attributes": [], "code_location": {"file": "docutils.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/util", "start_line": 447, "end_line": 469}, "type": "class"}, {"name": "dump_search_index", "is_method": true, "class_name": "StandaloneHTMLBuilder", "parameters": ["self"], "calls": ["progress_message", "self.indexer.prune", "replace", "__", "self.indexer.label", "open", "self.indexer.dump", "open", "self.indexer.dump", "Path"], "code_location": {"file": "__init__.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/builders/html", "start_line": 1276, "end_line": 1292}, "code_snippet": "    def dump_search_index(self) -> None:\n        if self.indexer is None:\n            return\n\n        with progress_message(__('dumping search index in %s') % self.indexer.label()):\n            self.indexer.prune(self.env.all_docs)\n            search_index_path = self.outdir / self.searchindex_filename\n            search_index_tmp = self.outdir / f'{self.searchindex_filename}.tmp'\n            # first write to a temporary file, so that if dumping fails,\n            # the existing index won't be overwritten\n            if self.indexer_dumps_unicode:\n                with open(search_index_tmp, 'w', encoding='utf-8') as ft:\n                    self.indexer.dump(ft, self.indexer_format)\n            else:\n                with open(search_index_tmp, 'wb') as fb:\n                    self.indexer.dump(fb, self.indexer_format)\n            Path(search_index_tmp).replace(search_index_path)\n", "type": "function"}, {"name": "_JavaScriptIndex", "docstring": "The search index as JavaScript file that calls a function\non the documentation search object to register the index.", "methods": ["dumps", "loads", "dump", "load"], "attributes": ["PREFIX", "SUFFIX"], "code_location": {"file": "__init__.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/search", "start_line": 163, "end_line": 186}, "type": "class"}], "retrieved_count": 10, "cost_time": 0.38250732421875}
{"question": "How does Sphinx implement its event system for extensions?", "answer": null, "relative_code_list": null, "ground_truth": "Sphinx implements its event system for extensions through the EventManager class, which provides a robust event-driven architecture that allows extensions to hook into various stages of the build process. The event system is designed to be flexible, efficient, and maintainable.\n\nThe event system works through the following key mechanisms:\n\n1. **EventManager Class**: The core of the event system is the EventManager class, which manages event registration, event emission, and event handling. It maintains a registry of event handlers and provides methods for connecting and disconnecting event listeners.\n\n2. **Event Registration**: Extensions can register event handlers using the `connect` method, specifying the event name and the callback function to be called when the event occurs. The system supports multiple handlers for the same event.\n\n3. **Event Emission**: Events are emitted at specific points during the build process using the `emit` method. This method calls all registered handlers for the event, passing the appropriate arguments to each handler.\n\n4. **Build Phase Events**: The event system provides events for different phases of the build process, including 'config-inited', 'builder-inited', 'doctree-read', 'doctree-resolved', 'env-before-read-docs', 'env-check-consistency', and many others.\n\n5. **Event Arguments**: Events can pass various arguments to handlers, including the Sphinx application instance, document objects, and other relevant data. This allows handlers to access and modify the build context.\n\n6. **Error Handling**: The event system includes robust error handling that isolates failures in individual event handlers from the rest of the build process. If one handler fails, it doesn't prevent other handlers from being called.\n\n7. **Event Ordering**: The system maintains the order in which event handlers are called, ensuring that handlers are executed in the order they were registered.\n\n8. **Extension Integration**: The event system is tightly integrated with Sphinx's extension system, allowing extensions to easily connect to events during their setup process.\n\n9. **Performance Optimization**: The event system is designed for performance, with efficient event dispatch and minimal overhead for event handling.\n\n10. **Documentation and Discovery**: The event system provides documentation and discovery mechanisms that help extension developers understand what events are available and when they are emitted.\n\nThe event system is instantiated as part of the Sphinx application (`self.events = EventManager()`) and is available to extensions through the application instance. It serves as the foundation for Sphinx's extensible architecture, allowing extensions to customize and extend the build process without modifying the core codebase.", "score": null, "retrieved_content": [{"name": "add", "is_method": true, "class_name": "EventManager", "parameters": ["self", "name"], "calls": ["ExtensionError", "__"], "code_location": {"file": "events.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx", "start_line": 78, "end_line": 82}, "code_snippet": "    def add(self, name: str) -> None:\n        \"\"\"Register a custom Sphinx event.\"\"\"\n        if name in self.events:\n            raise ExtensionError(__('Event %r already present') % name)\n        self.events[name] = ''\n", "type": "function"}, {"name": "emit", "is_method": true, "class_name": "EventManager", "parameters": ["self", "name"], "calls": ["sorted", "repr", "logger.debug", "attrgetter", "results.append", "listener.handler", "safe_getattr", "ExtensionError", "__"], "code_location": {"file": "events.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx", "start_line": 393, "end_line": 429}, "code_snippet": "    def emit(\n        self,\n        name: str,\n        *args: Any,\n        allowed_exceptions: tuple[type[Exception], ...] = (),\n    ) -> list[Any]:\n        \"\"\"Emit a Sphinx event.\"\"\"\n        # not every object likes to be repr()'d (think\n        # random stuff coming via autodoc)\n        try:\n            repr_args = repr(args)\n        except Exception:\n            pass\n        else:\n            logger.debug('[app] emitting event: %r%s', name, repr_args)\n\n        results = []\n        listeners = sorted(self.listeners[name], key=attrgetter('priority'))\n        for listener in listeners:\n            try:\n                results.append(listener.handler(self._app, *args))\n            except allowed_exceptions:\n                # pass through the errors specified as *allowed_exceptions*\n                raise\n            except SphinxError:\n                raise\n            except Exception as exc:\n                if self._reraise_errors:\n                    raise\n                modname = safe_getattr(listener.handler, '__module__', None)\n                raise ExtensionError(\n                    __('Handler %r for event %r threw an exception')\n                    % (listener.handler, name),\n                    exc,\n                    modname=modname,\n                ) from exc\n        return results\n", "type": "function"}, {"name": "EventManager", "docstring": "Event manager for Sphinx.", "methods": ["__init__", "add", "app", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "disconnect", "emit", "emit_firstresult"], "attributes": [], "code_location": {"file": "events.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx", "start_line": 66, "end_line": 444}, "type": "class"}, {"name": "test_events", "is_method": false, "class_name": null, "parameters": ["app"], "calls": ["pytest.mark.sphinx", "app.add_event", "app.connect", "app.disconnect", "pytest.raises", "app.connect", "str", "pytest.raises", "app.add_event", "str", "app.emit", "app.emit"], "code_location": {"file": "test_application.py", "path": "/data3/pwh/swebench-repos/sphinx/tests", "start_line": 53, "end_line": 76}, "code_snippet": "def test_events(app: SphinxTestApp) -> None:\n    def empty() -> None:\n        pass\n\n    with pytest.raises(ExtensionError) as excinfo:\n        app.connect('invalid', empty)\n    assert 'Unknown event name: invalid' in str(excinfo.value)\n\n    app.add_event('my_event')\n    with pytest.raises(ExtensionError) as excinfo:\n        app.add_event('my_event')\n    assert \"Event 'my_event' already present\" in str(excinfo.value)\n\n    def mock_callback(a_app: SphinxTestApp, *args: Any) -> str:\n        assert a_app is app\n        assert emit_args == args\n        return 'ret'\n\n    emit_args = (1, 3, 'string')\n    listener_id = app.connect('my_event', mock_callback)\n    assert app.emit('my_event', *emit_args) == ['ret'], 'Callback not called'\n\n    app.disconnect(listener_id)\n    assert app.emit('my_event', *emit_args) == [], 'Callback called when disconnected'\n", "type": "function"}, {"name": "setup", "is_method": false, "class_name": null, "parameters": ["app"], "calls": ["app.connect", "app.connect", "GroupedField", "app.add_object_type"], "code_location": {"file": "conf.py", "path": "/data3/pwh/swebench-repos/sphinx/doc", "start_line": 350, "end_line": 364}, "code_snippet": "def setup(app: Sphinx) -> None:\n    from sphinx.util.docfields import GroupedField\n\n    app.connect('include-read', linkify_issues_in_changelog)\n    app.connect('build-finished', build_redirects)\n    fdesc = GroupedField(\n        'parameter', label='Parameters', names=('param',), can_collapse=True\n    )\n    app.add_object_type(\n        'event',\n        'event',\n        'pair: %s; event',\n        parse_event,\n        doc_field_types=[fdesc],\n    )\n", "type": "function"}, {"name": "connect", "is_method": true, "class_name": "Sphinx", "parameters": ["self", "event", "callback", "priority"], "calls": [], "code_location": {"file": "application.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx", "start_line": 746, "end_line": 751}, "code_snippet": "    def connect(\n        self,\n        event: Literal['autodoc-process-bases'],\n        callback: Callable[[Sphinx, str, Any, dict[str, bool], list[str]], None],\n        priority: int = 500,\n    ) -> int: ...\n", "type": "function"}, {"name": "connect", "is_method": true, "class_name": "Sphinx", "parameters": ["self", "event", "callback", "priority"], "calls": [], "code_location": {"file": "application.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx", "start_line": 661, "end_line": 666}, "code_snippet": "    def connect(\n        self,\n        event: Literal['build-finished'],\n        callback: Callable[[Sphinx, Exception | None], None],\n        priority: int = 500,\n    ) -> int: ...\n", "type": "function"}, {"name": "connect", "is_method": true, "class_name": "Sphinx", "parameters": ["self", "event", "callback", "priority"], "calls": [], "code_location": {"file": "application.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx", "start_line": 534, "end_line": 539}, "code_snippet": "    def connect(\n        self,\n        event: Literal['builder-inited'],\n        callback: Callable[[Sphinx], None],\n        priority: int = 500,\n    ) -> int: ...\n", "type": "function"}, {"name": "connect", "is_method": true, "class_name": "EventManager", "parameters": ["self", "name", "callback", "priority"], "calls": [], "code_location": {"file": "events.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx", "start_line": 100, "end_line": 105}, "code_snippet": "    def connect(\n        self,\n        name: Literal['builder-inited'],\n        callback: Callable[[Sphinx], None],\n        priority: int,\n    ) -> int: ...\n", "type": "function"}, {"name": "connect", "is_method": true, "class_name": "Sphinx", "parameters": ["self", "event", "callback", "priority"], "calls": [], "code_location": {"file": "application.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx", "start_line": 592, "end_line": 599}, "code_snippet": "    def connect(\n        self,\n        event: Literal['env-merge-info'],\n        callback: Callable[\n            [Sphinx, BuildEnvironment, Set[str], BuildEnvironment], None\n        ],\n        priority: int = 500,\n    ) -> int: ...\n", "type": "function"}], "retrieved_count": 10, "cost_time": 0.38156986236572266}
{"question": "How does Sphinx process different input formats (reStructuredText, Markdown)?", "answer": null, "relative_code_list": null, "ground_truth": "Sphinx processes different input formats through a parser system that converts various markup languages into docutils document trees. The system is designed to be extensible, allowing support for multiple input formats while maintaining a unified internal representation.\n\nThe processing of different input formats works through the following key mechanisms:\n\n1. **Parser Registration**: Sphinx registers different parsers for various input formats through the SphinxComponentRegistry. Each parser is responsible for converting a specific input format into docutils document trees.\n\n2. **reStructuredText Processing**: reStructuredText is the default and most fully supported input format. Sphinx uses Docutils' built-in reStructuredText parser, which converts RST markup into docutils document trees. This parser handles all standard RST directives, roles, and markup.\n\n3. **Markdown Processing**: Sphinx can process Markdown files through extensions like `myst-parser` or `recommonmark`. These extensions provide parsers that convert Markdown syntax into docutils document trees, allowing Sphinx to handle Markdown input alongside RST.\n\n4. **Unified Document Tree**: Regardless of the input format, all parsers convert their input into docutils document trees. This provides a unified internal representation that can be processed by Sphinx's transform system, domain system, and output generators.\n\n5. **Format Detection**: Sphinx detects the input format based on file extensions and configuration settings. The `source_suffix` configuration option specifies which file extensions should be processed by which parsers.\n\n6. **Extension Integration**: The parser system integrates with Sphinx's extension system, allowing extensions to add support for new input formats by registering custom parsers.\n\n7. **Directive and Role Support**: Different input formats may have different capabilities for directives and roles. Sphinx's parser system ensures that format-specific features are properly converted to the unified document tree representation.\n\n8. **Cross-Reference Handling**: The parser system handles cross-references and links in a format-appropriate way, converting them to Sphinx's internal cross-reference system.\n\n9. **Error Handling**: The parser system includes robust error handling for malformed input, providing helpful error messages and allowing the build process to continue when possible.\n\n10. **Performance Optimization**: The parser system is designed for performance, with efficient parsing algorithms and caching mechanisms to handle large documentation projects.\n\nThis architecture allows Sphinx to support multiple input formats while maintaining a consistent internal processing pipeline, making it flexible for different documentation workflows and user preferences.", "score": null, "retrieved_content": [{"name": "get_rst_suffix", "is_method": false, "class_name": null, "parameters": ["app"], "calls": ["get", "suffix.removeprefix", "get_supported_format", "app.registry.get_source_parsers"], "code_location": {"file": "__init__.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/ext/autosummary", "start_line": 894, "end_line": 906}, "code_snippet": "def get_rst_suffix(app: Sphinx) -> str | None:\n    def get_supported_format(suffix: str) -> tuple[str, ...]:\n        parser_class = app.registry.get_source_parsers().get(suffix.removeprefix('.'))\n        if parser_class is None:\n            return ('restructuredtext',)\n        return parser_class.supported\n\n    suffix = None\n    for suffix in app.config.source_suffix:\n        if 'restructuredtext' in get_supported_format(suffix):\n            return suffix\n\n    return None\n", "type": "function"}, {"name": "setup", "is_method": false, "class_name": null, "parameters": ["app"], "calls": ["app.add_source_suffix", "app.add_source_parser"], "code_location": {"file": "prolog_markdown_parser.py", "path": "/data3/pwh/swebench-repos/sphinx/tests/roots/test-prolog", "start_line": 11, "end_line": 13}, "code_snippet": "def setup(app):\n    app.add_source_suffix('.md', 'markdown')\n    app.add_source_parser(DummyMarkdownParser)\n", "type": "function"}, {"name": "test_rst_prolog", "is_method": false, "class_name": null, "parameters": ["app"], "calls": ["pytest.mark.sphinx", "app.build", "app.env.get_doctree", "app.env.get_doctree", "assert_node", "assert_node", "assert_node", "assert_node", "assert_node", "assert_node", "assert_node", "md.rawsource.startswith", "md.rawsource.endswith"], "code_location": {"file": "test_markup.py", "path": "/data3/pwh/swebench-repos/sphinx/tests/test_markup", "start_line": 735, "end_line": 755}, "code_snippet": "def test_rst_prolog(app):\n    app.build(force_all=True)\n    rst = app.env.get_doctree('restructuredtext')\n    md = app.env.get_doctree('markdown')\n\n    # rst_prolog\n    assert_node(rst[0], nodes.paragraph)\n    assert_node(rst[0][0], nodes.emphasis)\n    assert_node(rst[0][0][0], nodes.Text)\n    assert rst[0][0][0] == 'Hello world'\n\n    # rst_epilog\n    assert_node(rst[-1], nodes.section)\n    assert_node(rst[-1][-1], nodes.paragraph)\n    assert_node(rst[-1][-1][0], nodes.emphasis)\n    assert_node(rst[-1][-1][0][0], nodes.Text)\n    assert rst[-1][-1][0][0] == 'Good-bye world'\n\n    # rst_prolog & rst_epilog on exlucding reST parser\n    assert not md.rawsource.startswith('*Hello world*.')\n    assert not md.rawsource.endswith('*Good-bye world*.\\n')\n", "type": "function"}, {"name": "RSTParser", "docstring": "A reST parser for Sphinx.", "methods": ["get_transforms", "parse", "decorate"], "attributes": [], "code_location": {"file": "parsers.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx", "start_line": 65, "end_line": 105}, "type": "class"}, {"name": "Builder", "docstring": "Builds target formats from the reST sources.", "methods": ["__init__", "app", "_translator", "get_translator_class", "create_translator", "init", "create_template_bridge", "get_target_uri", "get_relative_uri", "get_outdated_docs", "get_asset_paths", "post_process_images", "compile_catalogs", "compile_all_catalogs", "compile_specific_catalogs", "compile_update_catalogs", "build_all", "build_specific", "build_update", "build", "read", "_read_serial", "_read_parallel", "read_doc", "write_doctree", "write", "write_documents", "_write_serial", "_write_parallel", "prepare_writing", "copy_assets", "write_doc", "write_doc_serialized", "finish", "cleanup", "get_builder_config"], "attributes": ["srcdir", "confdir", "outdir", "doctreedir"], "code_location": {"file": "__init__.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/builders", "start_line": 64, "end_line": 881}, "type": "class"}, {"name": "SphinxFileInput", "docstring": "A basic FileInput for Sphinx.", "methods": ["__init__"], "attributes": [], "code_location": {"file": "io.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx", "start_line": 139, "end_line": 149}, "type": "class"}, {"name": "test_text_builder", "is_method": false, "class_name": null, "parameters": ["app"], "calls": ["pytest.mark.sphinx", "app.build", "read_text"], "code_location": {"file": "test_smartquotes.py", "path": "/data3/pwh/swebench-repos/sphinx/tests/test_markup", "start_line": 52, "end_line": 56}, "code_snippet": "def test_text_builder(app: SphinxTestApp) -> None:\n    app.build()\n\n    content = (app.outdir / 'index.txt').read_text(encoding='utf8')\n    assert '-- \"Sphinx\" is a tool that makes it easy ...' in content\n", "type": "function"}, {"name": "setup", "is_method": false, "class_name": null, "parameters": ["app"], "calls": ["app.add_source_parser"], "code_location": {"file": "parsers.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx", "start_line": 108, "end_line": 115}, "code_snippet": "def setup(app: Sphinx) -> ExtensionMetadata:\n    app.add_source_parser(RSTParser)\n\n    return {\n        'version': 'builtin',\n        'parallel_read_safe': True,\n        'parallel_write_safe': True,\n    }\n", "type": "function"}, {"name": "test_process_doc", "is_method": false, "class_name": null, "parameters": ["app"], "calls": ["pytest.mark.sphinx", "pytest.mark.test_params", "app.build", "assert_node", "assert_node", "assert_node", "assert_node", "assert_node", "assert_node", "assert_node", "assert_node", "assert_node", "assert_node", "assert_node", "assert_node", "assert_node", "assert_node", "assert_node", "set", "len"], "code_location": {"file": "test_environment_toctree.py", "path": "/data3/pwh/swebench-repos/sphinx/tests/test_environment", "start_line": 29, "end_line": 181}, "code_snippet": "def test_process_doc(app):\n    app.build()\n    # tocs\n    toctree = app.env.tocs['index']\n    assert_node(\n        toctree,\n        [\n            bullet_list,\n            (\n                [\n                    list_item,  # [0]\n                    (\n                        compact_paragraph,  # [0][0]\n                        [\n                            bullet_list,  # [0][1]\n                            (\n                                addnodes.toctree,  # [0][1][0]\n                                only,  # [0][1][1]\n                                list_item,  # [0][1][2]\n                            ),\n                        ],\n                    ),\n                ],\n                [\n                    list_item,  # [1]\n                    (\n                        compact_paragraph,  # [1][0]\n                        [\n                            bullet_list,  # [1][1]\n                            (\n                                addnodes.toctree,  # [1][1][0]\n                                addnodes.toctree,  # [1][1][1]\n                            ),\n                        ],\n                    ),\n                ],\n                list_item,  # [2]\n            ),\n        ],\n    )\n\n    assert_node(\n        toctree[0][0],\n        [compact_paragraph, reference, 'Welcome to Sphinx Testss documentation!'],\n    )\n    assert_node(toctree[0][0][0], reference, anchorname='')\n    assert_node(\n        toctree[0][1][0],\n        addnodes.toctree,\n        caption='Table of Contents',\n        glob=False,\n        hidden=False,\n        titlesonly=False,\n        maxdepth=2,\n        numbered=999,\n        entries=[\n            (None, 'foo'),\n            (None, 'bar'),\n            (None, 'https://sphinx-doc.org/'),\n            (None, 'self'),\n        ],\n        includefiles=['foo', 'bar'],\n    )\n\n    # only branch\n    assert_node(toctree[0][1][1], addnodes.only, expr='html')\n    assert_node(\n        toctree[0][1][1],\n        [\n            only,\n            list_item,\n            (\n                [compact_paragraph, reference, 'Section for HTML'],\n                [bullet_list, addnodes.toctree],\n            ),\n        ],\n    )\n    assert_node(toctree[0][1][1][0][0][0], reference, anchorname='#section-for-html')\n    assert_node(\n        toctree[0][1][1][0][1][0],\n        addnodes.toctree,\n        caption=None,\n        glob=False,\n        hidden=False,\n        entries=[(None, 'baz')],\n        includefiles=['baz'],\n        titlesonly=False,\n        maxdepth=-1,\n        numbered=0,\n    )\n    assert_node(\n        toctree[0][1][2],\n        (\n            [compact_paragraph, reference, 'subsection'],\n            [bullet_list, list_item, compact_paragraph, reference, 'subsubsection'],\n        ),\n    )\n\n    assert_node(\n        toctree[1][0],\n        [\n            compact_paragraph,\n            reference,\n            'Test for combination of globaltoc.html and hidden toctree',\n        ],\n    )\n    assert_node(\n        toctree[1][0][0],\n        reference,\n        anchorname='#test-for-combination-of-globaltoc-html-and-hidden-toctree',\n    )\n    assert_node(\n        toctree[1][1][0],\n        addnodes.toctree,\n        caption=None,\n        entries=[],\n        glob=False,\n        hidden=False,\n        titlesonly=False,\n        maxdepth=-1,\n        numbered=0,\n    )\n    assert_node(\n        toctree[1][1][1],\n        addnodes.toctree,\n        caption=None,\n        glob=False,\n        hidden=True,\n        titlesonly=False,\n        maxdepth=-1,\n        numbered=0,\n        entries=[\n            ('Latest reference', 'https://sphinx-doc.org/latest/'),\n            ('Python', 'https://python.org/'),\n        ],\n    )\n\n    assert_node(toctree[2][0], [compact_paragraph, reference, 'Indices and tables'])\n\n    # other collections\n    assert app.env.toc_num_entries['index'] == 6\n    assert app.env.toctree_includes['index'] == ['foo', 'bar', 'baz']\n    assert app.env.files_to_rebuild['foo'] == {'index'}\n    assert app.env.files_to_rebuild['bar'] == {'index'}\n    assert app.env.files_to_rebuild['baz'] == {'index'}\n    assert app.env.glob_toctrees == set()\n    assert app.env.numbered_toctrees == {'index'}\n\n    # qux has no section title\n    assert len(app.env.tocs['qux']) == 0\n    assert_node(app.env.tocs['qux'], nodes.bullet_list)\n    assert app.env.toc_num_entries['qux'] == 0\n    assert 'qux' not in app.env.toctree_includes\n", "type": "function"}, {"name": "_doctree_for_test", "is_method": false, "class_name": null, "parameters": ["app", "env", "docname"], "calls": ["env.doc2path", "filename.read_text", "env.prepare_settings", "registry.create_source_parser", "_parse_str_to_doctree", "registry.get_transforms"], "code_location": {"file": "test_directive_object_description.py", "path": "/data3/pwh/swebench-repos/sphinx/tests/test_directives", "start_line": 21, "end_line": 39}, "code_snippet": "def _doctree_for_test(\n    app: Sphinx, env: BuildEnvironment, docname: str\n) -> nodes.document:\n    config = app.config\n    registry = app.registry\n\n    filename = env.doc2path(docname)\n    content = filename.read_text(encoding='utf-8')\n\n    env.prepare_settings(docname)\n    parser = registry.create_source_parser('restructuredtext', config=config, env=env)\n    return _parse_str_to_doctree(\n        content,\n        filename=filename,\n        default_settings={'env': env},\n        env=env,\n        parser=parser,\n        transforms=registry.get_transforms(),\n    )\n", "type": "function"}], "retrieved_count": 10, "cost_time": 0.373640775680542}
{"question": "How do Sphinx extensions hook into the document building process?", "answer": null, "relative_code_list": null, "ground_truth": "Sphinx extensions hook into the document building process through multiple mechanisms that allow them to integrate with different phases of the build and modify various aspects of document processing. The hooking system is designed to be flexible and non-intrusive.\n\nExtensions can hook into the document building process through the following key mechanisms:\n\n1. **Event System Hooks**: Extensions can connect to Sphinx's event system by registering event handlers for specific events. These events are emitted at various points during the build process, allowing extensions to respond to and modify the build context.\n\n2. **Build Phase Events**: Extensions can hook into different phases of the build process by connecting to phase-specific events such as 'config-inited', 'builder-inited', 'doctree-read', 'doctree-resolved', 'env-before-read-docs', 'env-check-consistency', and 'build-finished'.\n\n3. **Document Processing Hooks**: Extensions can hook into document processing by connecting to events like 'doctree-read' and 'doctree-resolved', which allow them to modify document trees after they have been read or after cross-references have been resolved.\n\n4. **Transform Registration**: Extensions can register custom transforms that are applied to document trees during the transformation phase. These transforms can modify document structure, add content, or perform other document manipulations.\n\n5. **Directive and Role Registration**: Extensions can register custom directives and roles that are processed during the parsing phase. These can add new markup capabilities or modify how existing markup is processed.\n\n6. **Builder Integration**: Extensions can hook into the builder system by registering custom builders or modifying existing builders to add format-specific functionality.\n\n7. **Domain Integration**: Extensions can hook into the domain system by registering custom domains or extending existing domains with new object types, directives, and roles.\n\n8. **Configuration Hooks**: Extensions can hook into the configuration system by adding configuration options and responding to configuration changes through events like 'config-inited'.\n\n9. **Environment Integration**: Extensions can hook into the BuildEnvironment by storing and retrieving data, allowing them to maintain state across the build process and implement features like caching.\n\n10. **Output Generation Hooks**: Extensions can hook into output generation by registering custom writers or modifying the output generation process through events and transforms.\n\n11. **Setup Function Protocol**: Each extension provides a setup function that is called during Sphinx initialization. This function receives the Sphinx application instance and registers all the extension's hooks and components.\n\n12. **Error Handling Integration**: Extensions can hook into Sphinx's error handling system to provide custom error reporting or recovery mechanisms.\n\nThis comprehensive hooking system allows extensions to integrate deeply with Sphinx's build process while maintaining the stability and performance of the core system. Extensions can modify documents, add functionality, and respond to build events without requiring changes to the core Sphinx codebase.", "score": null, "retrieved_content": [{"name": "enable", "is_method": true, "class_name": "EnvironmentCollector", "parameters": ["self", "app"], "calls": ["app.connect", "app.connect", "app.connect", "app.connect", "app.connect"], "code_location": {"file": "__init__.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/environment/collectors", "start_line": 31, "end_line": 39}, "code_snippet": "    def enable(self, app: Sphinx) -> None:\n        assert self.listener_ids is None\n        self.listener_ids = {\n            'doctree-read': app.connect('doctree-read', self.process_doc),\n            'env-merge-info': app.connect('env-merge-info', self.merge_other),\n            'env-purge-doc': app.connect('env-purge-doc', self.clear_doc),\n            'env-get-updated': app.connect('env-get-updated', self.get_updated_docs),\n            'env-get-outdated': app.connect('env-get-outdated', self.get_outdated_docs),\n        }\n", "type": "function"}, {"name": "setup", "is_method": false, "class_name": null, "parameters": ["app"], "calls": ["app.connect", "app.connect", "GroupedField", "app.add_object_type"], "code_location": {"file": "conf.py", "path": "/data3/pwh/swebench-repos/sphinx/doc", "start_line": 350, "end_line": 364}, "code_snippet": "def setup(app: Sphinx) -> None:\n    from sphinx.util.docfields import GroupedField\n\n    app.connect('include-read', linkify_issues_in_changelog)\n    app.connect('build-finished', build_redirects)\n    fdesc = GroupedField(\n        'parameter', label='Parameters', names=('param',), can_collapse=True\n    )\n    app.add_object_type(\n        'event',\n        'event',\n        'pair: %s; event',\n        parse_event,\n        doc_field_types=[fdesc],\n    )\n", "type": "function"}, {"name": "setup", "is_method": false, "class_name": null, "parameters": ["app"], "calls": ["app.add_transform", "app.add_transform", "app.add_transform", "app.add_transform", "app.add_transform", "app.add_transform", "app.add_transform", "app.add_transform", "app.add_transform", "app.add_transform", "app.add_transform", "app.add_transform", "app.add_transform", "app.add_transform", "app.add_transform"], "code_location": {"file": "__init__.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/transforms", "start_line": 511, "end_line": 532}, "code_snippet": "def setup(app: Sphinx) -> ExtensionMetadata:\n    app.add_transform(ApplySourceWorkaround)\n    app.add_transform(ExtraTranslatableNodes)\n    app.add_transform(DefaultSubstitutions)\n    app.add_transform(MoveModuleTargets)\n    app.add_transform(HandleCodeBlocks)\n    app.add_transform(SortIds)\n    app.add_transform(DoctestTransform)\n    app.add_transform(AutoNumbering)\n    app.add_transform(AutoIndexUpgrader)\n    app.add_transform(FilterSystemMessages)\n    app.add_transform(UnreferencedFootnotesDetector)\n    app.add_transform(SphinxSmartQuotes)\n    app.add_transform(DoctreeReadEvent)\n    app.add_transform(GlossarySorter)\n    app.add_transform(ReorderConsecutiveTargetAndIndexNodes)\n\n    return {\n        'version': 'builtin',\n        'parallel_read_safe': True,\n        'parallel_write_safe': True,\n    }\n", "type": "function"}, {"name": "setup", "is_method": false, "class_name": null, "parameters": ["app"], "calls": ["app.add_post_transform", "app.add_post_transform", "app.add_post_transform", "app.add_post_transform"], "code_location": {"file": "__init__.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/transforms/post_transforms", "start_line": 393, "end_line": 403}, "code_snippet": "def setup(app: Sphinx) -> ExtensionMetadata:\n    app.add_post_transform(ReferencesResolver)\n    app.add_post_transform(OnlyNodeTransform)\n    app.add_post_transform(SigElementFallbackTransform)\n    app.add_post_transform(PropagateDescDomain)\n\n    return {\n        'version': 'builtin',\n        'parallel_read_safe': True,\n        'parallel_write_safe': True,\n    }\n", "type": "function"}, {"name": "setup", "is_method": false, "class_name": null, "parameters": ["app"], "calls": ["app.connect", "app.connect", "app.connect", "app.connect", "app.connect", "app.connect", "app.connect", "app.connect", "app.connect"], "code_location": {"file": "config.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx", "start_line": 911, "end_line": 926}, "code_snippet": "def setup(app: Sphinx) -> ExtensionMetadata:\n    app.connect('config-inited', deprecate_source_encoding, priority=790)\n    app.connect('config-inited', convert_source_suffix, priority=800)\n    app.connect('config-inited', convert_highlight_options, priority=800)\n    app.connect('config-inited', init_numfig_format, priority=800)\n    app.connect('config-inited', evaluate_copyright_placeholders, priority=795)\n    app.connect('config-inited', correct_copyright_year, priority=800)\n    app.connect('config-inited', check_confval_types, priority=800)\n    app.connect('config-inited', check_primary_domain, priority=800)\n    app.connect('env-get-outdated', check_master_doc)\n\n    return {\n        'version': 'builtin',\n        'parallel_read_safe': True,\n        'parallel_write_safe': True,\n    }\n", "type": "function"}, {"name": "setup", "is_method": false, "class_name": null, "parameters": ["app"], "calls": ["app.connect"], "code_location": {"file": "extension.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx", "start_line": 87, "end_line": 94}, "code_snippet": "def setup(app: Sphinx) -> ExtensionMetadata:\n    app.connect('config-inited', verify_needs_extensions, priority=800)\n\n    return {\n        'version': 'builtin',\n        'parallel_read_safe': True,\n        'parallel_write_safe': True,\n    }\n", "type": "function"}, {"name": "setup", "is_method": false, "class_name": null, "parameters": ["app"], "calls": ["app.add_transform", "app.add_post_transform", "app.add_post_transform", "app.add_post_transform", "app.add_post_transform", "app.add_post_transform", "app.add_post_transform", "app.add_post_transform", "app.add_post_transform", "app.add_post_transform"], "code_location": {"file": "transforms.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/builders/latex", "start_line": 645, "end_line": 661}, "code_snippet": "def setup(app: Sphinx) -> ExtensionMetadata:\n    app.add_transform(FootnoteDocnameUpdater)\n    app.add_post_transform(SubstitutionDefinitionsRemover)\n    app.add_post_transform(BibliographyTransform)\n    app.add_post_transform(CitationReferenceTransform)\n    app.add_post_transform(DocumentTargetTransform)\n    app.add_post_transform(IndexInSectionTitleTransform)\n    app.add_post_transform(LaTeXFootnoteTransform)\n    app.add_post_transform(LiteralBlockTransform)\n    app.add_post_transform(MathReferenceTransform)\n    app.add_post_transform(ShowUrlsTransform)\n\n    return {\n        'version': 'builtin',\n        'parallel_read_safe': True,\n        'parallel_write_safe': True,\n    }\n", "type": "function"}, {"name": "setup", "is_method": false, "class_name": null, "parameters": ["app"], "calls": ["app.add_transform", "app.add_transform"], "code_location": {"file": "references.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/transforms", "start_line": 44, "end_line": 52}, "code_snippet": "def setup(app: Sphinx) -> ExtensionMetadata:\n    app.add_transform(SphinxDanglingReferences)\n    app.add_transform(SphinxDomains)\n\n    return {\n        'version': 'builtin',\n        'parallel_read_safe': True,\n        'parallel_write_safe': True,\n    }\n", "type": "function"}, {"name": "setup", "is_method": false, "class_name": null, "parameters": ["app"], "calls": ["app.add_post_transform", "app.add_post_transform"], "code_location": {"file": "images.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/transforms/post_transforms", "start_line": 294, "end_line": 302}, "code_snippet": "def setup(app: Sphinx) -> ExtensionMetadata:\n    app.add_post_transform(ImageDownloader)\n    app.add_post_transform(DataURIExtractor)\n\n    return {\n        'version': 'builtin',\n        'parallel_read_safe': True,\n        'parallel_write_safe': True,\n    }\n", "type": "function"}, {"name": "setup", "is_method": false, "class_name": null, "parameters": ["app"], "calls": ["app.add_env_collector", "app.add_env_collector"], "code_location": {"file": "asset.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/environment/collectors", "start_line": 177, "end_line": 185}, "code_snippet": "def setup(app: Sphinx) -> ExtensionMetadata:\n    app.add_env_collector(ImageCollector)\n    app.add_env_collector(DownloadFileCollector)\n\n    return {\n        'version': 'builtin',\n        'parallel_read_safe': True,\n        'parallel_write_safe': True,\n    }\n", "type": "function"}], "retrieved_count": 10, "cost_time": 0.37988805770874023}
{"question": "How does Sphinx handle incremental builds?", "answer": null, "relative_code_list": null, "ground_truth": "Sphinx handles incremental builds through a sophisticated caching and state management system that tracks changes and only rebuilds what is necessary. The incremental build system is designed to significantly reduce build times for large documentation projects.\n\nThe incremental build system works through the following key mechanisms:\n\n1. **Environment Serialization**: The BuildEnvironment is serialized to disk after each build as a pickle file. This environment contains all the metadata, cross-references, and build state needed to determine what has changed.\n\n2. **Change Detection**: Sphinx tracks which source files have been modified since the last build by comparing file modification times with the cached environment data. Only files that have changed or are affected by changes are processed.\n\n3. **Dependency Tracking**: The environment maintains dependency information between documents, allowing Sphinx to determine which documents need to be rebuilt when a particular file changes. This includes both direct dependencies and transitive dependencies.\n\n4. **Doctree Caching**: Parsed source files are cached as \"doctree pickles\" in a `.doctrees` directory. These cached files can be shared between different builders and significantly speed up subsequent builds.\n\n5. **Configuration Change Detection**: Sphinx tracks changes to the configuration file (conf.py) and determines what needs to be rebuilt based on which configuration options have changed. Different configuration options specify different rebuild requirements.\n\n6. **Selective Rebuilding**: Users can specify individual files to rebuild using the `--write-all` option or by providing specific filenames, allowing for targeted rebuilding of only the necessary components.\n\n7. **Fresh Environment Option**: For cases where the cached environment might be corrupted or when a complete rebuild is needed, Sphinx provides the `--fresh-env` option to rebuild the environment completely.\n\n8. **Parallel Processing Integration**: The incremental build system works with Sphinx's parallel processing capabilities, allowing for efficient parallel rebuilding of changed files.\n\n9. **Extension State Persistence**: Extensions can store their own state in the environment, allowing them to participate in incremental builds and only process what has changed.\n\n10. **Error Recovery**: If the incremental build system encounters errors or corrupted cache files, it can fall back to a full rebuild to ensure consistency.\n\n11. **Memory Management**: The incremental build system is designed to manage memory efficiently, loading only the necessary cached data and cleaning up unused resources.\n\n12. **Build Performance Monitoring**: Sphinx provides information about what is being rebuilt and why, helping users understand the incremental build process and optimize their documentation structure.\n\nThis incremental build system allows Sphinx to handle large documentation projects efficiently by minimizing the amount of work needed for subsequent builds, while maintaining the accuracy and consistency of the generated documentation.", "score": null, "retrieved_content": [{"name": "test_incremental_reading", "is_method": false, "class_name": null, "parameters": ["app"], "calls": ["pytest.mark.sphinx", "app.builder.read", "write_text", "unlink", "app.builder.read", "set", "set", "sorted", "set"], "code_location": {"file": "test_incremental_reading.py", "path": "/data3/pwh/swebench-repos/sphinx/tests/test_builders", "start_line": 20, "end_line": 39}, "code_snippet": "def test_incremental_reading(app: SphinxTestApp) -> None:\n    # first reading\n    updated = app.builder.read()\n    assert set(updated) == app.env.found_docs == set(app.env.all_docs)\n    assert updated == sorted(updated)  # sorted by alphanumeric\n\n    # test if exclude_patterns works ok\n    assert 'subdir/excluded' not in app.env.found_docs\n\n    # before second reading, add, modify and remove source files\n    (app.srcdir / 'new.txt').write_text('New file\\n========\\n', encoding='utf8')\n    app.env.all_docs['index'] = 0  # mark as modified\n    (app.srcdir / 'autodoc.txt').unlink()\n\n    # second reading\n    updated = app.builder.read()\n\n    assert set(updated) == {'index', 'new'}\n    assert 'autodoc' not in app.env.all_docs\n    assert 'autodoc' not in app.env.found_docs\n", "type": "function"}, {"name": "build", "is_method": true, "class_name": "SphinxTestApp", "parameters": ["self", "force_all", "filenames"], "calls": ["self.env._pickled_doctree_cache.clear", "build", "super"], "code_location": {"file": "util.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/testing", "start_line": 235, "end_line": 237}, "code_snippet": "    def build(self, force_all: bool = False, filenames: Sequence[Path] = ()) -> None:\n        self.env._pickled_doctree_cache.clear()\n        super().build(force_all, filenames)\n", "type": "function"}, {"name": "test_incremental_reading_for_missing_files", "is_method": false, "class_name": null, "parameters": ["app"], "calls": ["pytest.mark.sphinx", "app.builder.read", "app.builder.read", "sys.modules.pop", "set", "set", "set"], "code_location": {"file": "test_incremental_reading.py", "path": "/data3/pwh/swebench-repos/sphinx/tests/test_builders", "start_line": 47, "end_line": 59}, "code_snippet": "def test_incremental_reading_for_missing_files(app: SphinxTestApp) -> None:\n    # first reading\n    updated = app.builder.read()\n    assert set(updated) == app.env.found_docs == set(app.env.all_docs)\n\n    # second reading\n    updated = app.builder.read()\n\n    # \"index\" is listed up to updated because it contains references\n    # to nonexisting downloadable or image files\n    assert set(updated) == {'index'}\n\n    sys.modules.pop('autodoc_fodder', None)\n", "type": "function"}, {"name": "build_update", "is_method": true, "class_name": "Builder", "parameters": ["self"], "calls": ["self.compile_update_catalogs", "self.get_outdated_docs", "isinstance", "self.build", "set", "self.build", "__", "len"], "code_location": {"file": "__init__.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/builders", "start_line": 372, "end_line": 386}, "code_snippet": "    def build_update(self) -> None:\n        \"\"\"Only rebuild what was changed or added since last build.\"\"\"\n        self.compile_update_catalogs()\n\n        to_build = self.get_outdated_docs()\n        if isinstance(to_build, str):\n            self.build(['__all__'], summary=to_build, method='update')\n        else:\n            to_build = set(to_build)\n            self.build(\n                to_build,\n                summary=__('targets for %d source files that are out of date')\n                % len(to_build),\n                method='update',\n            )\n", "type": "function"}, {"name": "_has_doc_changed", "is_method": false, "class_name": null, "parameters": ["docname"], "calls": ["_last_modified_time", "logger.debug", "doctree_path.is_file", "logger.debug", "logger.debug", "_format_rfc3339_microseconds", "_format_rfc3339_microseconds", "dep_path.is_file", "logger.debug", "_last_modified_time", "logger.debug", "_format_rfc3339_microseconds", "_format_rfc3339_microseconds"], "code_location": {"file": "__init__.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/environment", "start_line": 838, "end_line": 900}, "code_snippet": "def _has_doc_changed(\n    docname: str,\n    *,\n    filename: Path,\n    reread_always: Set[str],\n    doctreedir: Path,\n    all_docs: Mapping[str, int],\n    dependencies: Mapping[str, Set[Path]],\n) -> bool:\n    # check the \"reread always\" list\n    if docname in reread_always:\n        logger.debug('[build target] changed %r: re-read forced', docname)\n        return True\n\n    # if the doctree file is not there, rebuild\n    doctree_path = doctreedir / f'{docname}.doctree'\n    if not doctree_path.is_file():\n        logger.debug('[build target] changed %r: doctree file does not exist', docname)\n        return True\n\n    # check the mtime of the document\n    mtime = all_docs[docname]\n    new_mtime = _last_modified_time(filename)\n    if new_mtime > mtime:\n        logger.debug(\n            '[build target] changed: %r is outdated (%s -> %s)',\n            docname,\n            _format_rfc3339_microseconds(mtime),\n            _format_rfc3339_microseconds(new_mtime),\n        )\n        return True\n\n    # finally, check the mtime of dependencies\n    if docname not in dependencies:\n        return False\n    for dep_path in dependencies[docname]:\n        try:\n            dep_path_is_file = dep_path.is_file()\n        except OSError:\n            return True  # give it another chance\n        if not dep_path_is_file:\n            logger.debug(\n                '[build target] changed: %r is missing dependency %r',\n                docname,\n                dep_path,\n            )\n            return True\n\n        try:\n            dep_mtime = _last_modified_time(dep_path)\n        except OSError:\n            return True  # give it another chance\n        if dep_mtime > mtime:\n            logger.debug(\n                '[build target] changed: %r is outdated due to dependency %r (%s -> %s)',\n                docname,\n                dep_path,\n                _format_rfc3339_microseconds(mtime),\n                _format_rfc3339_microseconds(dep_mtime),\n            )\n            return True\n\n    return False\n", "type": "function"}, {"name": "build", "is_method": true, "class_name": "Sphinx", "parameters": ["self", "force_all", "filenames"], "calls": ["self.builder.cleanup", "self.events.emit", "logger.info", "logger.info", "self.builder.build_all", "envfile.is_file", "self.events.emit", "logger.info", "logger.info", "logger.info", "logger.info", "self.builder.build_specific", "self.builder.build_update", "envfile.unlink", "bold", "bold", "__", "bold", "__", "bold", "relpath", "__", "__", "__", "__", "__", "__"], "code_location": {"file": "application.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx", "start_line": 428, "end_line": 487}, "code_snippet": "    def build(self, force_all: bool = False, filenames: Sequence[Path] = ()) -> None:\n        self.builder.phase = BuildPhase.READING\n        try:\n            if force_all:\n                self.builder.build_all()\n            elif filenames:\n                self.builder.build_specific(filenames)\n            else:\n                self.builder.build_update()\n\n            self.events.emit('build-finished', None)\n        except Exception as err:\n            # delete the saved env to force a fresh build next time\n            envfile = self.doctreedir / ENV_PICKLE_FILENAME\n            if envfile.is_file():\n                envfile.unlink()\n            self.events.emit('build-finished', err)\n            raise\n\n        if self._warncount == 0:\n            if self.statuscode != 0:\n                logger.info(bold(__('build finished with problems.')))\n            else:\n                logger.info(bold(__('build succeeded.')))\n        elif self._warncount == 1:\n            if self._fail_on_warnings:\n                self.statuscode = 1\n                msg = __(\n                    'build finished with problems, 1 warning '\n                    '(with warnings treated as errors).'\n                )\n            elif self.statuscode != 0:\n                msg = __('build finished with problems, 1 warning.')\n            else:\n                msg = __('build succeeded, 1 warning.')\n            logger.info(bold(msg))\n        else:\n            if self._fail_on_warnings:\n                self.statuscode = 1\n                msg = __(\n                    'build finished with problems, %s warnings '\n                    '(with warnings treated as errors).'\n                )\n            elif self.statuscode != 0:\n                msg = __('build finished with problems, %s warnings.')\n            else:\n                msg = __('build succeeded, %s warnings.')\n            logger.info(bold(msg), self._warncount)\n\n        if self.statuscode == 0 and self.builder.epilog:\n            logger.info('')\n            logger.info(\n                self.builder.epilog,\n                {\n                    'outdir': relpath(self.outdir),\n                    'project': self.config.project,\n                },\n            )\n\n        self.builder.cleanup()\n", "type": "function"}, {"name": "get_outdated_docs", "is_method": true, "class_name": "StandaloneHTMLBuilder", "parameters": ["self"], "calls": ["BuildInfo.load", "int", "self.get_output_path", "logger.warning", "build_info_path.with_name", "_last_modified_time", "logger.debug", "_last_modified_time", "_last_modified_time", "max", "__", "shutil.move", "self.build_info.dump", "__", "logger.info", "self.templates.newest_template_mtime", "logger.info", "self.env.doc2path", "logger.debug", "self.templates.newest_template_name", "_format_rfc3339_microseconds", "_format_rfc3339_microseconds", "_format_rfc3339_microseconds", "bold", "bold", "__", "__"], "code_location": {"file": "__init__.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/builders/html", "start_line": 346, "end_line": 418}, "code_snippet": "    def get_outdated_docs(self) -> Iterator[str]:\n        build_info_path = self.outdir / '.buildinfo'\n        try:\n            build_info = BuildInfo.load(build_info_path)\n        except ValueError as exc:\n            logger.warning(__('Failed to read build info file: %r'), exc)\n        except OSError:\n            # ignore errors on reading\n            pass\n        else:\n            if self.build_info != build_info:\n                # log the mismatch and backup the old build info\n                build_info_backup = build_info_path.with_name('.buildinfo.bak')\n                try:\n                    shutil.move(build_info_path, build_info_backup)\n                    self.build_info.dump(build_info_path)\n                except OSError:\n                    pass  # ignore errors\n                else:\n                    # only log on success\n                    msg = __(\n                        'build_info mismatch, copying .buildinfo to .buildinfo.bak'\n                    )\n                    logger.info(bold(__('building [html]: ')) + msg)  # NoQA: G003\n\n                yield from self.env.found_docs\n                return\n\n        if self.templates:\n            template_mtime = int(self.templates.newest_template_mtime() * 10**6)\n            try:\n                old_mtime = _last_modified_time(build_info_path)\n            except Exception:\n                pass\n            else:\n                # Let users know they have a newer template\n                if template_mtime > old_mtime:\n                    logger.info(\n                        bold('building [html]: ')  # NoQA: G003\n                        + __(\n                            'template %s has been changed since the previous build, '\n                            'all docs will be rebuilt'\n                        ),\n                        self.templates.newest_template_name(),\n                    )\n        else:\n            template_mtime = 0\n        for docname in self.env.found_docs:\n            if docname not in self.env.all_docs:\n                logger.debug('[build target] did not in env: %r', docname)\n                yield docname\n                continue\n            target_name = self.get_output_path(docname)\n            try:\n                target_mtime = _last_modified_time(target_name)\n            except OSError:\n                target_mtime = 0\n            try:\n                doc_mtime = _last_modified_time(self.env.doc2path(docname))\n                srcmtime = max(doc_mtime, template_mtime)\n                if srcmtime > target_mtime:\n                    logger.debug(\n                        '[build target] target_name %r(%s), template(%s), docname %r(%s)',\n                        target_name,\n                        _format_rfc3339_microseconds(target_mtime),\n                        _format_rfc3339_microseconds(template_mtime),\n                        docname,\n                        _format_rfc3339_microseconds(doc_mtime),\n                    )\n                    yield docname\n            except OSError:\n                # source doesn't exist anymore\n                pass\n", "type": "function"}, {"name": "get_outdated_docs", "is_method": true, "class_name": "XMLBuilder", "parameters": ["self"], "calls": ["_last_modified_time", "_last_modified_time", "self.env.doc2path"], "code_location": {"file": "xml.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/builders", "start_line": 39, "end_line": 55}, "code_snippet": "    def get_outdated_docs(self) -> Iterator[str]:\n        for docname in self.env.found_docs:\n            if docname not in self.env.all_docs:\n                yield docname\n                continue\n            targetname = self.outdir / (docname + self.out_suffix)\n            try:\n                targetmtime = _last_modified_time(targetname)\n            except Exception:\n                targetmtime = 0\n            try:\n                srcmtime = _last_modified_time(self.env.doc2path(docname))\n                if srcmtime > targetmtime:\n                    yield docname\n            except OSError:\n                # source doesn't exist anymore\n                pass\n", "type": "function"}, {"name": "get_outdated_docs", "is_method": true, "class_name": "TextBuilder", "parameters": ["self"], "calls": ["_last_modified_time", "_last_modified_time", "self.env.doc2path"], "code_location": {"file": "text.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/builders", "start_line": 39, "end_line": 55}, "code_snippet": "    def get_outdated_docs(self) -> Iterator[str]:\n        for docname in self.env.found_docs:\n            if docname not in self.env.all_docs:\n                yield docname\n                continue\n            targetname = self.outdir / (docname + self.out_suffix)\n            try:\n                targetmtime = _last_modified_time(targetname)\n            except Exception:\n                targetmtime = 0\n            try:\n                srcmtime = _last_modified_time(self.env.doc2path(docname))\n                if srcmtime > targetmtime:\n                    yield docname\n            except OSError:\n                # source doesn't exist anymore\n                pass\n", "type": "function"}, {"name": "_get_update_targets", "is_method": false, "class_name": null, "parameters": ["app"], "calls": ["app.env.find_files", "app.env.get_outdated_files"], "code_location": {"file": "test_intl.py", "path": "/data3/pwh/swebench-repos/sphinx/tests/test_intl", "start_line": 62, "end_line": 65}, "code_snippet": "def _get_update_targets(app):\n    app.env.find_files(app.config, app.builder)\n    added, changed, removed = app.env.get_outdated_files(config_changed=False)\n    return added, changed, removed\n", "type": "function"}], "retrieved_count": 10, "cost_time": 0.37749242782592773}
{"question": "How does Sphinx handle cross-references?", "answer": null, "relative_code_list": null, "ground_truth": "Sphinx handles cross-references through a sophisticated system that integrates the Domain system, Role system, and BuildEnvironment to provide comprehensive cross-reference resolution capabilities. The cross-reference system is designed to be flexible, accurate, and extensible.\n\nThe cross-reference handling works through the following key mechanisms:\n\n1. **Role-Based Cross-References**: Cross-references are created using roles in the markup (e.g., `:py:func:`, `:ref:`, `:doc:`). These roles are processed during the parsing phase and create reference nodes in the document tree.\n\n2. **Domain-Specific Resolution**: Each domain provides its own cross-reference resolution logic through the `resolve_xref` method. This allows domains to implement domain-specific logic for finding and linking to objects within their domain.\n\n3. **Environment Data Storage**: The BuildEnvironment stores metadata about all documented objects, including their locations, relationships, and cross-reference information. This data is used during the resolution phase to find target objects.\n\n4. **Multi-Phase Resolution**: Cross-references are resolved in multiple phases. During the reading phase, reference nodes are created but not yet resolved. During the resolving phase, all references are resolved to their target objects.\n\n5. **Cross-Domain References**: The system supports cross-references between different domains, allowing references from one domain to objects in another domain when appropriate.\n\n6. **Standard Domain References**: The standard domain provides general-purpose cross-reference roles like `:ref:` for section references, `:doc:` for document references, and `:any:` for automatic reference resolution.\n\n7. **Reference Data Collection**: During the reading phase, all domains collect information about their objects and store it in the environment's `domaindata`. This information includes object names, locations, and other metadata needed for resolution.\n\n8. **Automatic Reference Resolution**: The system can automatically resolve references based on object names, allowing for flexible reference creation without requiring exact target specification.\n\n9. **Error Handling**: The cross-reference system includes robust error handling for broken references, providing helpful error messages and allowing the build process to continue when possible.\n\n10. **Extension Integration**: The cross-reference system integrates with Sphinx's extension system, allowing extensions to add new cross-reference types or modify existing resolution logic.\n\n11. **Performance Optimization**: The system is designed for performance, with efficient data structures and algorithms for storing and retrieving cross-reference information.\n\n12. **Incremental Build Support**: Cross-reference information is cached in the environment, allowing for efficient incremental builds that only resolve references for changed documents.\n\nThis comprehensive cross-reference system allows Sphinx to provide rich linking capabilities across documentation while maintaining accuracy and performance for large documentation projects.", "score": null, "retrieved_content": [{"name": "ReferencesResolver", "docstring": "Resolves cross-references on doctrees.", "methods": ["run", "_resolve_pending_xref", "_resolve_pending_xref_in_domain", "_resolve_pending_any_xref", "_stringify", "warn_missing_reference", "find_pending_xref_condition"], "attributes": ["default_priority"], "code_location": {"file": "__init__.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/transforms/post_transforms", "start_line": 62, "end_line": 309}, "type": "class"}, {"name": "resolve_xref", "is_method": true, "class_name": "StandardDomain", "parameters": ["self", "env", "fromdocname", "builder", "typ", "target", "node", "contnode"], "calls": ["resolver"], "code_location": {"file": "__init__.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/domains/std", "start_line": 1033, "end_line": 1058}, "code_snippet": "    def resolve_xref(\n        self,\n        env: BuildEnvironment,\n        fromdocname: str,\n        builder: Builder,\n        typ: str,\n        target: str,\n        node: pending_xref,\n        contnode: Element,\n    ) -> nodes.reference | None:\n        if typ == 'ref':\n            resolver = self._resolve_ref_xref\n        elif typ == 'numref':\n            resolver = self._resolve_numref_xref  # type: ignore[assignment]\n        elif typ == 'keyword':\n            resolver = self._resolve_keyword_xref\n        elif typ == 'doc':\n            resolver = self._resolve_doc_xref\n        elif typ == 'option':\n            resolver = self._resolve_option_xref\n        elif typ == 'term':\n            resolver = self._resolve_term_xref\n        else:\n            resolver = self._resolve_obj_xref\n\n        return resolver(env, fromdocname, builder, typ, target, node, contnode)\n", "type": "function"}, {"name": "resolve_xref", "is_method": true, "class_name": "PythonDomain", "parameters": ["self", "env", "fromdocname", "builder", "type", "target", "node", "contnode"], "calls": ["node.get", "node.get", "self.find_obj", "node.hasattr", "self.find_obj", "self.find_obj", "self.find_obj", "self._make_module_refnode", "find_pending_xref_condition", "make_refnode", "self.find_obj", "len", "len", "logger.warning", "__", "join"], "code_location": {"file": "__init__.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/domains/python", "start_line": 940, "end_line": 1004}, "code_snippet": "    def resolve_xref(\n        self,\n        env: BuildEnvironment,\n        fromdocname: str,\n        builder: Builder,\n        type: str,\n        target: str,\n        node: pending_xref,\n        contnode: Element,\n    ) -> nodes.reference | None:\n        modname = node.get('py:module')\n        clsname = node.get('py:class')\n        searchmode = 1 if node.hasattr('refspecific') else 0\n        matches = self.find_obj(env, modname, clsname, target, type, searchmode)\n\n        if not matches and type == 'class':\n            # fallback to data/attr (for type aliases)\n            # type aliases are documented as data/attr but referenced as class\n            matches = self.find_obj(env, modname, clsname, target, 'data', searchmode)\n            if not matches:\n                matches = self.find_obj(\n                    env, modname, clsname, target, 'attr', searchmode\n                )\n        if not matches and type == 'attr':\n            # fallback to meth (for property; Sphinx 2.4.x)\n            # this ensures that `:attr:` role continues to refer to the old property entry\n            # that defined by ``method`` directive in old reST files.\n            matches = self.find_obj(env, modname, clsname, target, 'meth', searchmode)\n        if not matches and type == 'meth':\n            # fallback to attr (for property)\n            # this ensures that `:meth:` in the old reST files can refer to the property\n            # entry that defined by ``property`` directive.\n            #\n            # Note: _prop is a secret role only for internal look-up.\n            matches = self.find_obj(env, modname, clsname, target, '_prop', searchmode)\n\n        if not matches:\n            return None\n        elif len(matches) > 1:\n            canonicals = [m for m in matches if not m[1].aliased]\n            if len(canonicals) == 1:\n                matches = canonicals\n            else:\n                logger.warning(\n                    __('more than one target found for cross-reference %r: %s'),\n                    target,\n                    ', '.join(match[0] for match in matches),\n                    type='ref',\n                    subtype='python',\n                    location=node,\n                )\n        name, obj = matches[0]\n\n        if obj[2] == 'module':\n            return self._make_module_refnode(builder, fromdocname, name, contnode)\n        else:\n            # determine the content of the reference by conditions\n            content = find_pending_xref_condition(node, 'resolved')\n            if content:\n                children = content.children\n            else:\n                # if not found, use contnode\n                children = [contnode]\n\n            return make_refnode(builder, fromdocname, obj[0], obj[1], children, name)\n", "type": "function"}, {"name": "pending_xref", "docstring": "Node for cross-references that cannot be resolved without complete\ninformation about all documents.\n\nThese nodes are resolved before writing output, in\nBuildEnvironment.resolve_references.", "methods": [], "attributes": ["child_text_separator"], "code_location": {"file": "addnodes.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx", "start_line": 493, "end_line": 501}, "type": "class"}, {"name": "test_texinfo_xrefs", "is_method": false, "class_name": null, "parameters": ["app"], "calls": ["pytest.mark.sphinx", "app.build", "read_text", "re.search", "app.build", "read_text", "re.search"], "code_location": {"file": "test_build_texinfo.py", "path": "/data3/pwh/swebench-repos/sphinx/tests/test_builders", "start_line": 115, "end_line": 127}, "code_snippet": "def test_texinfo_xrefs(app: SphinxTestApp) -> None:\n    app.build(force_all=True)\n    output = (app.outdir / 'sphinxtests.texi').read_text(encoding='utf8')\n    assert re.search(r'@ref{\\w+,,--plugin\\.option}', output)\n\n    # Now rebuild it without xrefs\n    app.config.texinfo_cross_references = False\n    app.build(force_all=True)\n    output = (app.outdir / 'sphinxtests.texi').read_text(encoding='utf8')\n    assert not re.search(r'@ref{\\w+,,--plugin\\.option}', output)\n    assert (\n        'Link to perl +p, --ObjC++, --plugin.option, create-auth-token, arg and -j'\n    ) in output\n", "type": "function"}, {"name": "resolve_any_xref", "is_method": true, "class_name": "CitationDomain", "parameters": ["self", "env", "fromdocname", "builder", "target", "node", "contnode"], "calls": ["self.resolve_xref"], "code_location": {"file": "citation.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/domains", "start_line": 115, "end_line": 130}, "code_snippet": "    def resolve_any_xref(\n        self,\n        env: BuildEnvironment,\n        fromdocname: str,\n        builder: Builder,\n        target: str,\n        node: pending_xref,\n        contnode: Element,\n    ) -> list[tuple[str, nodes.reference]]:\n        refnode = self.resolve_xref(\n            env, fromdocname, builder, 'ref', target, node, contnode\n        )\n        if refnode is None:\n            return []\n        else:\n            return [('ref', refnode)]\n", "type": "function"}, {"name": "resolve_xref", "is_method": true, "class_name": "CitationDomain", "parameters": ["self", "env", "fromdocname", "builder", "typ", "target", "node", "contnode"], "calls": ["self.citations.get", "make_refnode"], "code_location": {"file": "citation.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/domains", "start_line": 99, "end_line": 113}, "code_snippet": "    def resolve_xref(\n        self,\n        env: BuildEnvironment,\n        fromdocname: str,\n        builder: Builder,\n        typ: str,\n        target: str,\n        node: pending_xref,\n        contnode: Element,\n    ) -> nodes.reference | None:\n        docname, labelid, _lineno = self.citations.get(target, ('', '', 0))\n        if not docname:\n            return None\n\n        return make_refnode(builder, fromdocname, docname, labelid, contnode)\n", "type": "function"}, {"name": "SphinxDomains", "docstring": "Collect objects to Sphinx domains for cross references.", "methods": ["apply"], "attributes": ["default_priority"], "code_location": {"file": "references.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/transforms", "start_line": 33, "end_line": 41}, "type": "class"}, {"name": "resolve_xref", "is_method": true, "class_name": "ReSTDomain", "parameters": ["self", "env", "fromdocname", "builder", "typ", "target", "node", "contnode"], "calls": ["self.objtypes_for_role", "self.objects.get", "make_refnode"], "code_location": {"file": "rst.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/domains", "start_line": 282, "end_line": 307}, "code_snippet": "    def resolve_xref(\n        self,\n        env: BuildEnvironment,\n        fromdocname: str,\n        builder: Builder,\n        typ: str,\n        target: str,\n        node: pending_xref,\n        contnode: Element,\n    ) -> nodes.reference | None:\n        objtypes = self.objtypes_for_role(typ)\n        if not objtypes:\n            return None\n        for objtype in objtypes:\n            result = self.objects.get((objtype, target))\n            if result:\n                todocname, node_id = result\n                return make_refnode(\n                    builder,\n                    fromdocname,\n                    todocname,\n                    node_id,\n                    contnode,\n                    f'{target} {objtype}',\n                )\n        return None\n", "type": "function"}, {"name": "PyXRefRole", "docstring": "", "methods": ["process_link"], "attributes": [], "code_location": {"file": "__init__.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/domains/python", "start_line": 569, "end_line": 595}, "type": "class"}], "retrieved_count": 10, "cost_time": 0.38240909576416016}
{"question": "How can Sphinx's Builder API be extended to support new output formats?", "answer": null, "relative_code_list": null, "ground_truth": "Sphinx's Builder API can be extended to support new output formats by creating custom builder classes that inherit from the appropriate base classes and implement the necessary methods for the new format. The Builder API provides a comprehensive framework for adding new output formats.\n\nNew output formats can be supported by extending the Builder API through the following key mechanisms:\n\n1. **Builder Class Inheritance**: Custom builders should inherit from the appropriate base builder class (typically `Builder` or a specific builder like `StandaloneHTMLBuilder`). This provides access to the core build workflow and common functionality.\n\n2. **Core Method Implementation**: Custom builders must implement the core build methods including `build()`, `read()`, `write()`, and `get_outdated_docs()`. These methods define the build workflow for the new format.\n\n3. **Format-Specific Configuration**: Custom builders can define format-specific configuration options by adding configuration values to the `config_values` dictionary. These options can control various aspects of the output format.\n\n4. **Writer Integration**: Custom builders typically work with custom writer classes that handle the actual output generation. The builder orchestrates the build process while the writer handles format-specific output generation.\n\n5. **Document Tree Processing**: Custom builders can implement format-specific document tree processing by overriding methods like `get_target_uri()` and `get_relative_uri()` to define how documents are linked and organized in the output.\n\n6. **Asset Management**: Custom builders can implement asset management for format-specific resources like images, stylesheets, or other media files that need to be included in the output.\n\n7. **Index Generation**: Custom builders can implement format-specific index generation by overriding methods like `write_genindex()` and `write_searchindex()` to create indexes appropriate for the new format.\n\n8. **Cross-Reference Handling**: Custom builders can implement format-specific cross-reference handling by overriding methods that process cross-references and generate appropriate links for the new format.\n\n9. **Extension Integration**: Custom builders can integrate with Sphinx's extension system by providing extension points and events specific to the new format.\n\n10. **Configuration Integration**: Custom builders can add configuration options that control various aspects of the output format, allowing users to customize the generated output.\n\n11. **Error Handling**: Custom builders should implement appropriate error handling for format-specific issues, providing helpful error messages and graceful degradation when possible.\n\n12. **Performance Optimization**: Custom builders should be designed for performance, with efficient algorithms for processing documents and generating output.\n\n13. **Registration**: Custom builders are registered with Sphinx's component registry using `app.add_builder()`, making them available for use in Sphinx projects.\n\n14. **Documentation**: Custom builders should provide documentation and examples showing how to use the new output format effectively.\n\nThis comprehensive extension mechanism allows developers to add support for new output formats while maintaining compatibility with Sphinx's core architecture and providing a consistent user experience.", "score": null, "retrieved_content": [{"name": "Builder", "docstring": "Builds target formats from the reST sources.", "methods": ["__init__", "app", "_translator", "get_translator_class", "create_translator", "init", "create_template_bridge", "get_target_uri", "get_relative_uri", "get_outdated_docs", "get_asset_paths", "post_process_images", "compile_catalogs", "compile_all_catalogs", "compile_specific_catalogs", "compile_update_catalogs", "build_all", "build_specific", "build_update", "build", "read", "_read_serial", "_read_parallel", "read_doc", "write_doctree", "write", "write_documents", "_write_serial", "_write_parallel", "prepare_writing", "copy_assets", "write_doc", "write_doc_serialized", "finish", "cleanup", "get_builder_config"], "attributes": ["srcdir", "confdir", "outdir", "doctreedir"], "code_location": {"file": "__init__.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/builders", "start_line": 64, "end_line": 881}, "type": "class"}, {"name": "add_builder", "is_method": true, "class_name": "SphinxComponentRegistry", "parameters": ["self", "builder", "override"], "calls": ["logger.debug", "hasattr", "ExtensionError", "ExtensionError", "__", "__"], "code_location": {"file": "registry.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx", "start_line": 158, "end_line": 169}, "code_snippet": "    def add_builder(self, builder: type[Builder], override: bool = False) -> None:\n        logger.debug('[app] adding builder: %r', builder)\n        if not hasattr(builder, 'name'):\n            raise ExtensionError(\n                __('Builder class %s has no \"name\" attribute') % builder\n            )\n        if builder.name in self.builders and not override:\n            raise ExtensionError(\n                __('Builder %r already exists (in module %s)')\n                % (builder.name, self.builders[builder.name].__module__)\n            )\n        self.builders[builder.name] = builder\n", "type": "function"}, {"name": "create_builder", "is_method": true, "class_name": "SphinxComponentRegistry", "parameters": ["self", "app", "name", "env"], "calls": ["SphinxError", "__"], "code_location": {"file": "registry.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx", "start_line": 190, "end_line": 194}, "code_snippet": "    def create_builder(self, app: Sphinx, name: str, env: BuildEnvironment) -> Builder:\n        if name not in self.builders:\n            raise SphinxError(__('Builder name %s not registered') % name)\n\n        return self.builders[name](app, env)\n", "type": "function"}, {"name": "preload_builder", "is_method": true, "class_name": "SphinxComponentRegistry", "parameters": ["self", "app", "name"], "calls": ["entry_points", "self.load_extension", "SphinxError", "__"], "code_location": {"file": "registry.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx", "start_line": 171, "end_line": 188}, "code_snippet": "    def preload_builder(self, app: Sphinx, name: str) -> None:\n        if name is None:\n            return\n\n        if name not in self.builders:\n            builder_entry_points = entry_points(group='sphinx.builders')\n            try:\n                entry_point = builder_entry_points[name]\n            except KeyError as exc:\n                raise SphinxError(\n                    __(\n                        'Builder name %s not registered or available'\n                        ' through entry point'\n                    )\n                    % name\n                ) from exc\n\n            self.load_extension(app, entry_point.module)\n", "type": "function"}, {"name": "setup", "is_method": false, "class_name": null, "parameters": ["app"], "calls": ["app.add_builder"], "code_location": {"file": "dummy.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/builders", "start_line": 39, "end_line": 46}, "code_snippet": "def setup(app: Sphinx) -> ExtensionMetadata:\n    app.add_builder(DummyBuilder)\n\n    return {\n        'version': 'builtin',\n        'parallel_read_safe': True,\n        'parallel_write_safe': True,\n    }\n", "type": "function"}, {"name": "setup", "is_method": false, "class_name": null, "parameters": ["app"], "calls": ["app.add_builder", "app.add_config_value", "app.add_config_value", "app.add_config_value", "app.add_config_value", "frozenset", "frozenset", "frozenset", "frozenset"], "code_location": {"file": "text.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/builders", "start_line": 77, "end_line": 89}, "code_snippet": "def setup(app: Sphinx) -> ExtensionMetadata:\n    app.add_builder(TextBuilder)\n\n    app.add_config_value('text_sectionchars', '*=-~\"+`', 'env', types=frozenset({str}))\n    app.add_config_value('text_newlines', 'unix', 'env', types=frozenset({str}))\n    app.add_config_value('text_add_secnumbers', True, 'env', types=frozenset({bool}))\n    app.add_config_value('text_secnumber_suffix', '. ', 'env', types=frozenset({str}))\n\n    return {\n        'version': 'builtin',\n        'parallel_read_safe': True,\n        'parallel_write_safe': True,\n    }\n", "type": "function"}, {"name": "setup", "is_method": false, "class_name": null, "parameters": ["app"], "calls": ["app.add_builder", "app.add_builder", "app.add_config_value", "frozenset"], "code_location": {"file": "xml.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/builders", "start_line": 111, "end_line": 121}, "code_snippet": "def setup(app: Sphinx) -> ExtensionMetadata:\n    app.add_builder(XMLBuilder)\n    app.add_builder(PseudoXMLBuilder)\n\n    app.add_config_value('xml_pretty', True, 'env', types=frozenset({bool}))\n\n    return {\n        'version': 'builtin',\n        'parallel_read_safe': True,\n        'parallel_write_safe': True,\n    }\n", "type": "function"}, {"name": "setup", "is_method": false, "class_name": null, "parameters": ["app"], "calls": ["app.add_builder"], "code_location": {"file": "changes.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/builders", "start_line": 184, "end_line": 191}, "code_snippet": "def setup(app: Sphinx) -> ExtensionMetadata:\n    app.add_builder(ChangesBuilder)\n\n    return {\n        'version': 'builtin',\n        'parallel_read_safe': True,\n        'parallel_write_safe': True,\n    }\n", "type": "function"}, {"name": "setup", "is_method": false, "class_name": null, "parameters": ["app"], "calls": ["app.setup_extension", "app.add_builder"], "code_location": {"file": "dirhtml.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/builders", "start_line": 41, "end_line": 50}, "code_snippet": "def setup(app: Sphinx) -> ExtensionMetadata:\n    app.setup_extension('sphinx.builders.html')\n\n    app.add_builder(DirectoryHTMLBuilder)\n\n    return {\n        'version': 'builtin',\n        'parallel_read_safe': True,\n        'parallel_write_safe': True,\n    }\n", "type": "function"}, {"name": "add_builder", "is_method": true, "class_name": "Sphinx", "parameters": ["self", "builder", "override"], "calls": ["self.registry.add_builder"], "code_location": {"file": "application.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx", "start_line": 893, "end_line": 903}, "code_snippet": "    def add_builder(self, builder: type[Builder], override: bool = False) -> None:\n        \"\"\"Register a new builder.\n\n        :param builder: A builder class\n        :param override: If true, install the builder forcedly even if another builder\n                         is already installed as the same name\n\n        .. versionchanged:: 1.8\n           Add *override* keyword.\n        \"\"\"\n        self.registry.add_builder(builder, override=override)\n", "type": "function"}], "retrieved_count": 10, "cost_time": 0.3639223575592041}
{"question": "How can Sphinx's extension API be used to create custom document processors?", "answer": null, "relative_code_list": null, "ground_truth": "Sphinx's extension API can be used to create custom document processors through multiple mechanisms that allow extensions to modify and process documents at various stages of the build process. The extension API provides a comprehensive set of tools for document processing.\n\nCustom document processors can be created using the following key mechanisms:\n\n1. **Transform Registration**: Extensions can register custom transforms that are applied to document trees during the transformation phase. These transforms can modify document structure, add content, or perform other document manipulations. Transforms are registered using `app.add_transform()`.\n\n2. **Event-Based Processing**: Extensions can connect to document processing events like 'doctree-read' and 'doctree-resolved' to process documents at specific stages of the build. These events provide access to the document tree and allow for modifications.\n\n3. **Directive Implementation**: Extensions can create custom directives that process specific markup and generate document content. Directives are registered using `app.add_directive()` and can create complex document structures.\n\n4. **Role Implementation**: Extensions can create custom roles that process inline markup and generate reference nodes or other document elements. Roles are registered using `app.add_role()`.\n\n5. **Domain Extension**: Extensions can extend existing domains or create new domains to provide domain-specific document processing capabilities. This includes custom object types, directives, and roles for specific documentation domains.\n\n6. **Builder Integration**: Extensions can integrate with the builder system to add custom processing during the build phase. This can include custom output generation or document modification specific to certain output formats.\n\n7. **Environment Integration**: Extensions can store and retrieve data from the BuildEnvironment, allowing them to maintain state across the build process and implement features like caching and incremental processing.\n\n8. **Configuration Integration**: Extensions can add configuration options that control document processing behavior, allowing users to customize how documents are processed.\n\n9. **Parser Integration**: Extensions can register custom parsers for new input formats, allowing them to process documents written in custom markup languages.\n\n10. **Node Handler Registration**: Extensions can register custom node handlers for translators, allowing them to customize how specific node types are rendered in different output formats.\n\n11. **Cross-Reference Processing**: Extensions can implement custom cross-reference resolution logic, allowing them to handle special types of references or modify how existing references are processed.\n\n12. **Content Generation**: Extensions can generate content programmatically, such as automatic tables of contents, indexes, or other document elements.\n\nThe extension API provides a flexible and powerful framework for creating custom document processors that can integrate seamlessly with Sphinx's build process while maintaining the stability and performance of the core system.", "score": null, "retrieved_content": [{"name": "setup", "is_method": false, "class_name": null, "parameters": ["app"], "calls": ["app.add_post_transform"], "code_location": {"file": "mocksvgconverter.py", "path": "/data3/pwh/swebench-repos/sphinx/tests/roots/test-ext-imgmockconverter", "start_line": 33, "end_line": 40}, "code_snippet": "def setup(app: Sphinx) -> ExtensionMetadata:\n    app.add_post_transform(MyConverter)\n\n    return {\n        'version': 'builtin',\n        'parallel_read_safe': True,\n        'parallel_write_safe': True,\n    }\n", "type": "function"}, {"name": "setup", "is_method": false, "class_name": null, "parameters": ["app"], "calls": ["app.add_transform", "app.add_transform", "app.add_transform", "app.add_transform", "app.add_transform", "app.add_transform", "app.add_transform", "app.add_transform", "app.add_transform", "app.add_transform", "app.add_transform", "app.add_transform", "app.add_transform", "app.add_transform", "app.add_transform"], "code_location": {"file": "__init__.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/transforms", "start_line": 511, "end_line": 532}, "code_snippet": "def setup(app: Sphinx) -> ExtensionMetadata:\n    app.add_transform(ApplySourceWorkaround)\n    app.add_transform(ExtraTranslatableNodes)\n    app.add_transform(DefaultSubstitutions)\n    app.add_transform(MoveModuleTargets)\n    app.add_transform(HandleCodeBlocks)\n    app.add_transform(SortIds)\n    app.add_transform(DoctestTransform)\n    app.add_transform(AutoNumbering)\n    app.add_transform(AutoIndexUpgrader)\n    app.add_transform(FilterSystemMessages)\n    app.add_transform(UnreferencedFootnotesDetector)\n    app.add_transform(SphinxSmartQuotes)\n    app.add_transform(DoctreeReadEvent)\n    app.add_transform(GlossarySorter)\n    app.add_transform(ReorderConsecutiveTargetAndIndexNodes)\n\n    return {\n        'version': 'builtin',\n        'parallel_read_safe': True,\n        'parallel_write_safe': True,\n    }\n", "type": "function"}, {"name": "run_apidoc", "is_method": false, "class_name": null, "parameters": ["app"], "calls": ["ApidocDefaults.from_config", "LOGGER.info", "enumerate", "bold", "_run_apidoc_module", "__"], "code_location": {"file": "_extension.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/ext/apidoc", "start_line": 43, "end_line": 60}, "code_snippet": "def run_apidoc(app: Sphinx) -> None:\n    \"\"\"Run the apidoc extension.\"\"\"\n    defaults = ApidocDefaults.from_config(app.config)\n    apidoc_modules: Sequence[dict[str, Any]] = app.config.apidoc_modules\n    srcdir: Path = app.srcdir\n    confdir: Path = app.confdir\n\n    LOGGER.info(bold(__('Running apidoc')))\n\n    module_options: dict[str, Any]\n    for i, module_options in enumerate(apidoc_modules):\n        _run_apidoc_module(\n            i,\n            options=module_options,\n            defaults=defaults,\n            srcdir=srcdir,\n            confdir=confdir,\n        )\n", "type": "function"}, {"name": "setup", "is_method": false, "class_name": null, "parameters": ["app"], "calls": ["app.add_transform", "app.add_post_transform", "app.add_post_transform", "app.add_post_transform", "app.add_post_transform", "app.add_post_transform", "app.add_post_transform", "app.add_post_transform", "app.add_post_transform", "app.add_post_transform"], "code_location": {"file": "transforms.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/builders/latex", "start_line": 645, "end_line": 661}, "code_snippet": "def setup(app: Sphinx) -> ExtensionMetadata:\n    app.add_transform(FootnoteDocnameUpdater)\n    app.add_post_transform(SubstitutionDefinitionsRemover)\n    app.add_post_transform(BibliographyTransform)\n    app.add_post_transform(CitationReferenceTransform)\n    app.add_post_transform(DocumentTargetTransform)\n    app.add_post_transform(IndexInSectionTitleTransform)\n    app.add_post_transform(LaTeXFootnoteTransform)\n    app.add_post_transform(LiteralBlockTransform)\n    app.add_post_transform(MathReferenceTransform)\n    app.add_post_transform(ShowUrlsTransform)\n\n    return {\n        'version': 'builtin',\n        'parallel_read_safe': True,\n        'parallel_write_safe': True,\n    }\n", "type": "function"}, {"name": "setup_documenters", "is_method": false, "class_name": null, "parameters": ["app"], "calls": ["app.registry.add_documenter"], "code_location": {"file": "generate.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/ext/autosummary", "start_line": 99, "end_line": 124}, "code_snippet": "def setup_documenters(app: Sphinx) -> None:\n    from sphinx.ext.autodoc import (\n        AttributeDocumenter,\n        ClassDocumenter,\n        DataDocumenter,\n        DecoratorDocumenter,\n        ExceptionDocumenter,\n        FunctionDocumenter,\n        MethodDocumenter,\n        ModuleDocumenter,\n        PropertyDocumenter,\n    )\n\n    documenters: list[type[Documenter]] = [\n        ModuleDocumenter,\n        ClassDocumenter,\n        ExceptionDocumenter,\n        DataDocumenter,\n        FunctionDocumenter,\n        MethodDocumenter,\n        AttributeDocumenter,\n        DecoratorDocumenter,\n        PropertyDocumenter,\n    ]\n    for documenter in documenters:\n        app.registry.add_documenter(documenter.objtype, documenter)\n", "type": "function"}, {"name": "SphinxTransformer", "docstring": "A transformer for Sphinx.", "methods": ["set_environment", "apply_transforms"], "attributes": [], "code_location": {"file": "__init__.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/transforms", "start_line": 81, "end_line": 108}, "type": "class"}, {"name": "setup", "is_method": false, "class_name": null, "parameters": ["app"], "calls": ["app.add_post_transform", "app.add_post_transform"], "code_location": {"file": "code.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/transforms/post_transforms", "start_line": 135, "end_line": 143}, "code_snippet": "def setup(app: Sphinx) -> ExtensionMetadata:\n    app.add_post_transform(HighlightLanguageTransform)\n    app.add_post_transform(TrimDoctestFlagsTransform)\n\n    return {\n        'version': 'builtin',\n        'parallel_read_safe': True,\n        'parallel_write_safe': True,\n    }\n", "type": "function"}, {"name": "setup", "is_method": false, "class_name": null, "parameters": ["app"], "calls": ["app.add_post_transform", "app.add_post_transform"], "code_location": {"file": "images.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/transforms/post_transforms", "start_line": 294, "end_line": 302}, "code_snippet": "def setup(app: Sphinx) -> ExtensionMetadata:\n    app.add_post_transform(ImageDownloader)\n    app.add_post_transform(DataURIExtractor)\n\n    return {\n        'version': 'builtin',\n        'parallel_read_safe': True,\n        'parallel_write_safe': True,\n    }\n", "type": "function"}, {"name": "SphinxStandaloneReader", "docstring": "A basic document reader for Sphinx.", "methods": ["__init__", "_setup_transforms", "read", "read_source"], "attributes": [], "code_location": {"file": "io.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx", "start_line": 79, "end_line": 109}, "type": "class"}, {"name": "setup", "is_method": false, "class_name": null, "parameters": ["app"], "calls": ["app.add_post_transform", "app.add_post_transform", "app.add_post_transform", "app.add_post_transform"], "code_location": {"file": "__init__.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/transforms/post_transforms", "start_line": 393, "end_line": 403}, "code_snippet": "def setup(app: Sphinx) -> ExtensionMetadata:\n    app.add_post_transform(ReferencesResolver)\n    app.add_post_transform(OnlyNodeTransform)\n    app.add_post_transform(SigElementFallbackTransform)\n    app.add_post_transform(PropagateDescDomain)\n\n    return {\n        'version': 'builtin',\n        'parallel_read_safe': True,\n        'parallel_write_safe': True,\n    }\n", "type": "function"}], "retrieved_count": 10, "cost_time": 0.37666773796081543}
{"question": "How can Sphinx's Domain API be used to implement custom cross-reference systems?", "answer": null, "relative_code_list": null, "ground_truth": "Sphinx's Domain API can be used to implement custom cross-reference systems by creating domain classes that provide specialized cross-reference resolution logic for specific types of documentation objects. The Domain API provides a comprehensive framework for implementing domain-specific cross-reference functionality.\n\nCustom cross-reference systems can be implemented using the Domain API through the following key mechanisms:\n\n1. **Domain Class Creation**: Custom domains should inherit from the base `Domain` class and implement the necessary methods for cross-reference resolution. This includes the `resolve_xref()` method which is the core of cross-reference resolution.\n\n2. **Object Type Definition**: Custom domains define object types through the `object_types` attribute, which maps object type names to `ObjType` instances. Each object type specifies which roles can be used to reference objects of that type.\n\n3. **Role Registration**: Custom domains register domain-specific roles that create cross-references to objects within the domain. These roles are registered in the `roles` attribute and are processed during the parsing phase.\n\n4. **Data Storage**: Custom domains store information about documented objects in their `data` attribute, which is stored in the environment's `domaindata`. This data includes object names, locations, and other metadata needed for cross-reference resolution.\n\n5. **Cross-Reference Resolution**: The `resolve_xref()` method implements the core logic for resolving cross-references. This method receives the reference information and returns the appropriate target object or reference node.\n\n6. **Object Description Collection**: Custom domains collect information about documented objects during the reading phase by processing directives and storing object metadata. This information is used during cross-reference resolution.\n\n7. **Index Generation**: Custom domains can provide custom indices for their objects by implementing the `get_objects()` method. This allows for specialized indexing and search functionality.\n\n8. **Cross-Domain References**: Custom domains can implement logic for handling cross-references to objects in other domains, allowing for flexible reference resolution across different documentation domains.\n\n9. **Reference Data Management**: Custom domains manage reference data including object relationships, inheritance hierarchies, and other domain-specific metadata that affects cross-reference resolution.\n\n10. **Error Handling**: Custom domains implement domain-specific error handling for cross-reference resolution, providing helpful error messages for broken references.\n\n11. **Extension Integration**: Custom domains integrate with Sphinx's extension system, allowing extensions to extend existing domains or create new domains with custom cross-reference functionality.\n\n12. **Configuration Integration**: Custom domains can add configuration options that control cross-reference behavior, allowing users to customize how references are resolved.\n\n13. **Performance Optimization**: Custom domains should implement efficient data structures and algorithms for storing and retrieving cross-reference information.\n\n14. **Documentation**: Custom domains should provide documentation and examples showing how to use the custom cross-reference system effectively.\n\nThis comprehensive framework allows developers to implement sophisticated cross-reference systems that are tailored to specific documentation domains while maintaining compatibility with Sphinx's core cross-reference architecture.", "score": null, "retrieved_content": [{"name": "SphinxDomains", "docstring": "Collect objects to Sphinx domains for cross references.", "methods": ["apply"], "attributes": ["default_priority"], "code_location": {"file": "references.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/transforms", "start_line": 33, "end_line": 41}, "type": "class"}, {"name": "Domain", "docstring": "A Domain is meant to be a group of \"object\" description directives for\nobjects of a similar nature, and corresponding roles to create references to\nthem.  Examples would be Python modules, classes, functions etc., elements\nof a templating language, Sphinx roles and directives, etc.\n\nEach domain has a separate storage for information about existing objects\nand how to reference them in `self.data`, which must be a dictionary.  It\nalso must implement several functions that expose the object information in\na uniform way to parts of Sphinx that allow the user to reference or search\nfor objects in a domain-agnostic way.\n\nAbout `self.data`: since all object and cross-referencing information is\nstored on a BuildEnvironment instance, the `domain.data` object is also\nstored in the `env.domaindata` dict under the key `domain.name`.  Before the\nbuild process starts, every active domain is instantiated and given the\nenvironment object; the `domaindata` dict must then either be nonexistent or\na dictionary whose 'version' key is equal to the domain class'\n:attr:`data_version` attribute.  Otherwise, `OSError` is raised and the\npickled environment is discarded.", "methods": ["__init__", "setup", "add_object_type", "role", "directive", "clear_doc", "merge_domaindata", "process_doc", "check_consistency", "process_field_xref", "resolve_xref", "resolve_any_xref", "get_objects", "get_type_name", "get_enumerable_node_type", "get_full_qualified_name"], "attributes": [], "code_location": {"file": "__init__.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/domains", "start_line": 62, "end_line": 331}, "type": "class"}, {"name": "sphinx_domains", "docstring": "Monkey-patch directive and role dispatch, so that domain-specific\nmarkup takes precedence.", "methods": ["__init__", "directive", "role"], "attributes": [], "code_location": {"file": "docutils.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/util", "start_line": 301, "end_line": 380}, "type": "class"}, {"name": "test_domain_py_xrefs", "is_method": false, "class_name": null, "parameters": ["app"], "calls": ["pytest.mark.sphinx", "app.build", "app.env.get_doctree", "list", "assert_refnode", "assert_refnode", "assert_refnode", "assert_refnode", "assert_refnode", "assert_refnode", "assert_refnode", "assert_refnode", "assert_refnode", "assert_refnode", "assert_refnode", "assert_refnode", "assert_refnode", "assert_refnode", "assert_refnode", "app.env.get_doctree", "list", "assert_refnode", "assert_refnode", "assert_refnode", "assert_refnode", "assert_refnode", "assert_refnode", "assert_refnode", "assert_refnode", "assert_refnode", "assert_refnode", "assert_refnode", "assert_refnode", "assert_refnode", "assert_refnode", "assert_refnode", "assert_refnode", "assert_refnode", "assert_refnode", "assert_refnode", "assert_refnode", "assert_refnode", "app.env.get_doctree", "list", "print", "print", "print", "assert_refnode", "assert_refnode", "assert_node", "doctree.findall", "len", "doctree.findall", "len", "doctree.findall", "len"], "code_location": {"file": "test_domain_py.py", "path": "/data3/pwh/swebench-repos/sphinx/tests/test_domains", "start_line": 83, "end_line": 179}, "code_snippet": "def test_domain_py_xrefs(app):\n    \"\"\"Domain objects have correct prefixes when looking up xrefs\"\"\"\n    app.build(force_all=True)\n\n    def assert_refnode(\n        node, module_name, class_name, target, reftype=None, domain='py'\n    ):\n        attributes = {\n            'refdomain': domain,\n            'reftarget': target,\n        }\n        if reftype is not None:\n            attributes['reftype'] = reftype\n        if module_name is not False:\n            attributes['py:module'] = module_name\n        if class_name is not False:\n            attributes['py:class'] = class_name\n        assert_node(node, **attributes)\n\n    doctree = app.env.get_doctree('roles')\n    refnodes = list(doctree.findall(pending_xref))\n    assert_refnode(refnodes[0], None, None, 'TopLevel', 'class')\n    assert_refnode(refnodes[1], None, None, 'top_level', 'meth')\n    assert_refnode(refnodes[2], None, None, 'TopLevelType', 'type')\n    assert_refnode(refnodes[3], None, 'NestedParentA', 'child_1', 'meth')\n    assert_refnode(\n        refnodes[4], None, 'NestedParentA', 'NestedChildA.subchild_2', 'meth'\n    )\n    assert_refnode(refnodes[5], None, 'NestedParentA', 'child_2', 'meth')\n    assert_refnode(refnodes[6], False, 'NestedParentA', 'any_child', domain='')\n    assert_refnode(refnodes[7], None, 'NestedParentA', 'NestedChildA', 'class')\n    assert_refnode(\n        refnodes[8], None, 'NestedParentA.NestedChildA', 'subchild_2', 'meth'\n    )\n    assert_refnode(\n        refnodes[9], None, 'NestedParentA.NestedChildA', 'NestedParentA.child_1', 'meth'\n    )\n    assert_refnode(\n        refnodes[10], None, 'NestedParentA', 'NestedChildA.subchild_1', 'meth'\n    )\n    assert_refnode(refnodes[11], None, 'NestedParentB', 'child_1', 'meth')\n    assert_refnode(refnodes[12], None, 'NestedParentB', 'NestedParentB', 'class')\n    assert_refnode(refnodes[13], None, None, 'NestedParentA.NestedChildA', 'class')\n    assert_refnode(refnodes[14], None, None, 'NestedParentA.NestedTypeA', 'type')\n    assert len(refnodes) == 15\n\n    doctree = app.env.get_doctree('module')\n    refnodes = list(doctree.findall(pending_xref))\n    assert_refnode(refnodes[0], 'module_a.submodule', None, 'ModTopLevel', 'class')\n    assert_refnode(\n        refnodes[1], 'module_a.submodule', 'ModTopLevel', 'mod_child_1', 'meth'\n    )\n    assert_refnode(\n        refnodes[2],\n        'module_a.submodule',\n        'ModTopLevel',\n        'ModTopLevel.mod_child_1',\n        'meth',\n    )\n    assert_refnode(\n        refnodes[3], 'module_a.submodule', 'ModTopLevel', 'mod_child_2', 'meth'\n    )\n    assert_refnode(\n        refnodes[4],\n        'module_a.submodule',\n        'ModTopLevel',\n        'module_a.submodule.ModTopLevel.mod_child_1',\n        'meth',\n    )\n    assert_refnode(refnodes[5], 'module_a.submodule', 'ModTopLevel', 'prop', 'attr')\n    assert_refnode(refnodes[6], 'module_a.submodule', 'ModTopLevel', 'prop', 'meth')\n    assert_refnode(refnodes[7], 'module_b.submodule', None, 'ModTopLevel', 'class')\n    assert_refnode(\n        refnodes[8], 'module_b.submodule', 'ModTopLevel', 'ModNoModule', 'class'\n    )\n    assert_refnode(refnodes[9], False, False, 'int', 'class')\n    assert_refnode(refnodes[10], False, False, 'tuple', 'class')\n    assert_refnode(refnodes[11], False, False, 'str', 'class')\n    assert_refnode(refnodes[12], False, False, 'float', 'class')\n    assert_refnode(refnodes[13], False, False, 'list', 'class')\n    assert_refnode(refnodes[14], False, False, 'ModTopLevel', 'class')\n    assert_refnode(refnodes[15], False, False, 'index', 'doc', domain='std')\n    assert_refnode(refnodes[16], False, False, 'typing.Literal', 'obj', domain='py')\n    assert_refnode(refnodes[17], False, False, 'typing.Literal', 'obj', domain='py')\n    assert_refnode(refnodes[18], False, False, 'list', 'class', domain='py')\n    assert_refnode(refnodes[19], False, False, 'int', 'class', domain='py')\n    assert_refnode(refnodes[20], False, False, 'str', 'class', domain='py')\n    assert len(refnodes) == 21\n\n    doctree = app.env.get_doctree('module_option')\n    refnodes = list(doctree.findall(pending_xref))\n    print(refnodes)\n    print(refnodes[0])\n    print(refnodes[1])\n    assert_refnode(refnodes[0], 'test.extra', 'B', 'foo', 'meth')\n    assert_refnode(refnodes[1], 'test.extra', 'B', 'foo', 'meth')\n    assert len(refnodes) == 2\n", "type": "function"}, {"name": "make_xref", "is_method": true, "class_name": "Field", "parameters": ["self", "rolename", "domain", "target", "innernode", "contnode", "env", "inliner", "location"], "calls": ["role", "role", "nodes.inline", "addnodes.pending_xref", "process_field_xref", "innernode", "env.get_domain", "__", "logger.warning", "innernode", "contextlib.suppress", "get_node_line", "__", "env.get_domain"], "code_location": {"file": "docfields.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/util", "start_line": 81, "end_line": 122}, "code_snippet": "    def make_xref(\n        self,\n        rolename: str,\n        domain: str,\n        target: str,\n        innernode: type[TextlikeNode] = addnodes.literal_emphasis,\n        contnode: Node | None = None,\n        env: BuildEnvironment | None = None,\n        inliner: Inliner | None = None,\n        location: Element | None = None,\n    ) -> Node:\n        # note: for backwards compatibility env is last, but not optional\n        assert env is not None\n        assert (inliner is None) == (location is None), (inliner, location)\n        if not rolename:\n            return contnode or innernode(target, target)  # type: ignore[call-arg]\n        # The domain is passed from DocFieldTransformer. So it surely exists.\n        # So we don't need to take care the env.get_domain() raises an exception.\n        role = env.get_domain(domain).role(rolename)\n        if role is None or inliner is None:\n            if role is None and inliner is not None:\n                msg = __(\n                    'Problem in %s domain: field is supposed '\n                    \"to use role '%s', but that role is not in the domain.\"\n                )\n                logger.warning(__(msg), domain, rolename, location=location)\n            refnode = addnodes.pending_xref(\n                '',\n                refdomain=domain,\n                refexplicit=False,\n                reftype=rolename,\n                reftarget=target,\n            )\n            refnode += contnode or innernode(target, target)  # type: ignore[call-arg]\n            env.get_domain(domain).process_field_xref(refnode)\n            return refnode\n        lineno = -1\n        if location is not None:\n            with contextlib.suppress(ValueError):\n                lineno = get_node_line(location)\n        ns, _messages = role(rolename, target, target, lineno, inliner, {}, [])\n        return nodes.inline(target, '', *ns)\n", "type": "function"}, {"name": "add_crossref_type", "is_method": true, "class_name": "SphinxComponentRegistry", "parameters": ["self", "directivename", "rolename", "indextemplate", "ref_nodeclass", "objname", "override"], "calls": ["logger.debug", "type", "self.add_directive_to_domain", "self.add_role_to_domain", "self.domain_object_types.setdefault", "ObjType", "XRefRole", "ExtensionError", "__"], "code_location": {"file": "registry.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx", "start_line": 312, "end_line": 341}, "code_snippet": "    def add_crossref_type(\n        self,\n        directivename: str,\n        rolename: str,\n        indextemplate: str = '',\n        ref_nodeclass: type[TextElement] | None = None,\n        objname: str = '',\n        override: bool = False,\n    ) -> None:\n        logger.debug(\n            '[app] adding crossref type: %r',\n            (directivename, rolename, indextemplate, ref_nodeclass, objname),\n        )\n\n        # create a subclass of Target as the new directive\n        directive = type(\n            directivename,\n            (Target, object),\n            {'indextemplate': indextemplate},\n        )\n\n        self.add_directive_to_domain('std', directivename, directive)\n        self.add_role_to_domain('std', rolename, XRefRole(innernodeclass=ref_nodeclass))\n\n        object_types = self.domain_object_types.setdefault('std', {})\n        if directivename in object_types and not override:\n            raise ExtensionError(\n                __('The %r crossref_type is already registered') % directivename\n            )\n        object_types[directivename] = ObjType(objname or directivename, rolename)\n", "type": "function"}, {"name": "_resolve_pending_xref_in_domain", "is_method": true, "class_name": "ReferencesResolver", "parameters": ["self"], "calls": ["domain.resolve_xref", "self._resolve_pending_any_xref"], "code_location": {"file": "__init__.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/transforms/post_transforms", "start_line": 162, "end_line": 185}, "code_snippet": "    def _resolve_pending_xref_in_domain(\n        self,\n        *,\n        domain: Domain | None,\n        node: addnodes.pending_xref,\n        contnode: Element,\n        ref_doc: str,\n        typ: str,\n        target: str,\n    ) -> nodes.reference | None:\n        builder = self.env._app.builder\n        # let the domain try to resolve the reference\n        if domain is not None:\n            return domain.resolve_xref(\n                self.env, ref_doc, builder, typ, target, node, contnode\n            )\n\n        # really hardwired reference types\n        if typ == 'any':\n            return self._resolve_pending_any_xref(\n                node=node, contnode=contnode, ref_doc=ref_doc, target=target\n            )\n\n        return None\n", "type": "function"}, {"name": "Index", "docstring": "An Index is the description for a domain-specific index.  To add an index to\na domain, subclass Index, overriding the three name attributes:\n\n* `name` is an identifier used for generating file names.\n  It is also used for a hyperlink target for the index. Therefore, users can\n  refer the index page using ``ref`` role and a string which is combined\n  domain name and ``name`` attribute (ex. ``:ref:`py-modindex```).\n* `localname` is the section title for the index.\n* `shortname` is a short name for the index, for use in the relation bar in\n  HTML output.  Can be empty to disable entries in the relation bar.\n\nand providing a :meth:`generate` method.  Then, add the index class to\nyour domain's `indices` list.  Extensions can add indices to existing\ndomains using :meth:`~sphinx.application.Sphinx.add_index_to_domain`.\n\n.. versionchanged:: 3.0\n\n   Index pages can be referred by domain name and index name via\n   :rst:role:`ref` role.", "methods": ["__init__", "generate"], "attributes": [], "code_location": {"file": "_index.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/domains", "start_line": 55, "end_line": 108}, "type": "class"}, {"name": "resolve_xref", "is_method": true, "class_name": "RecipeDomain", "parameters": ["self", "env", "fromdocname", "builder", "typ", "target", "node", "contnode"], "calls": ["len", "make_refnode", "print", "self.get_objects"], "code_location": {"file": "recipe.py", "path": "/data3/pwh/swebench-repos/sphinx/doc/development/tutorials/examples", "start_line": 141, "end_line": 155}, "code_snippet": "    def resolve_xref(self, env, fromdocname, builder, typ, target, node, contnode):\n        match = [\n            (docname, anchor)\n            for name, sig, typ, docname, anchor, prio in self.get_objects()\n            if sig == target\n        ]\n\n        if len(match) > 0:\n            todocname = match[0][0]\n            targ = match[0][1]\n\n            return make_refnode(builder, fromdocname, todocname, targ, contnode, targ)\n        else:\n            print('Awww, found nothing')\n            return None\n", "type": "function"}, {"name": "make_xrefs", "is_method": true, "class_name": "Field", "parameters": ["self", "rolename", "domain", "target", "innernode", "contnode", "env", "inliner", "location"], "calls": ["self.make_xref"], "code_location": {"file": "docfields.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/util", "start_line": 124, "end_line": 139}, "code_snippet": "    def make_xrefs(\n        self,\n        rolename: str,\n        domain: str,\n        target: str,\n        innernode: type[TextlikeNode] = addnodes.literal_emphasis,\n        contnode: Node | None = None,\n        env: BuildEnvironment | None = None,\n        inliner: Inliner | None = None,\n        location: Element | None = None,\n    ) -> list[Node]:\n        return [\n            self.make_xref(\n                rolename, domain, target, innernode, contnode, env, inliner, location\n            )\n        ]\n", "type": "function"}], "retrieved_count": 10, "cost_time": 0.3503248691558838}
{"question": "How can Sphinx's event system API be leveraged for custom document transformations?", "answer": null, "relative_code_list": null, "ground_truth": "Sphinx's event system API can be leveraged for custom document transformations by connecting event handlers to specific events that are emitted during the document processing phases. The event system provides a powerful and flexible mechanism for implementing custom document transformations.\n\nCustom document transformations can be implemented using the event system API through the following key mechanisms:\n\n1. **Event Connection**: Extensions can connect to document processing events using the `app.events.connect()` method. Key events for document transformations include 'doctree-read', 'doctree-resolved', and 'env-before-read-docs'.\n\n2. **Document Tree Access**: Event handlers receive the document tree as an argument, allowing them to traverse and modify the document structure. The document tree is a docutils document object that can be manipulated programmatically.\n\n3. **Node Traversal**: Custom transformations can traverse the document tree using docutils node traversal methods, allowing them to find and modify specific types of nodes or content.\n\n4. **Node Modification**: Event handlers can modify document nodes by adding, removing, or replacing nodes in the document tree. This allows for complex transformations like adding content, restructuring sections, or modifying formatting.\n\n5. **Cross-Reference Processing**: Event handlers can process and modify cross-references by working with reference nodes and the environment's cross-reference data.\n\n6. **Content Generation**: Custom transformations can generate new content programmatically, such as automatic tables of contents, indexes, or other document elements.\n\n7. **Conditional Transformations**: Event handlers can implement conditional logic to apply transformations only under certain conditions, such as specific document types or configuration settings.\n\n8. **Environment Integration**: Event handlers have access to the BuildEnvironment, allowing them to store and retrieve data that persists across the build process.\n\n9. **Configuration Integration**: Custom transformations can be controlled through configuration options, allowing users to enable, disable, or customize transformation behavior.\n\n10. **Error Handling**: Event handlers should implement appropriate error handling to ensure that transformation failures don't break the build process.\n\n11. **Performance Optimization**: Custom transformations should be designed for performance, with efficient algorithms and minimal impact on build times.\n\n12. **Extension Integration**: Custom transformations can integrate with other extension components like directives, roles, and domains to provide comprehensive document processing capabilities.\n\n13. **Documentation**: Custom transformations should provide documentation and examples showing how to use the transformation effectively.\n\n14. **Testing**: Custom transformations should be thoroughly tested to ensure they work correctly with different document types and configurations.\n\nThis comprehensive framework allows developers to implement sophisticated document transformations that integrate seamlessly with Sphinx's build process while maintaining the stability and performance of the core system.", "score": null, "retrieved_content": [{"name": "SphinxTransform", "docstring": "A base class of Transforms.\n\nCompared with ``docutils.transforms.Transform``, this class improves accessibility to\nSphinx APIs.", "methods": ["app", "env", "config"], "attributes": [], "code_location": {"file": "__init__.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/transforms", "start_line": 55, "end_line": 78}, "type": "class"}, {"name": "SphinxTransformer", "docstring": "A transformer for Sphinx.", "methods": ["set_environment", "apply_transforms"], "attributes": [], "code_location": {"file": "__init__.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/transforms", "start_line": 81, "end_line": 108}, "type": "class"}, {"name": "apply_transforms", "is_method": true, "class_name": "SphinxTransformer", "parameters": ["self"], "calls": ["isinstance", "apply_transforms", "new_document", "apply_transforms", "hasattr", "super", "super"], "code_location": {"file": "__init__.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/transforms", "start_line": 90, "end_line": 108}, "code_snippet": "    def apply_transforms(self) -> None:\n        if isinstance(self.document, nodes.document):\n            if not hasattr(self.document.settings, 'env') and self.env:\n                self.document.settings.env = self.env\n\n            super().apply_transforms()  # type: ignore[misc]\n        else:\n            # wrap the target node by document node during transforming\n            try:\n                from sphinx.util.docutils import new_document\n\n                document = new_document('')\n                if self.env:\n                    document.settings.env = self.env\n                document += self.document\n                self.document = document\n                super().apply_transforms()\n            finally:\n                self.document = self.document[0]\n", "type": "function"}, {"name": "_transform", "is_method": false, "class_name": null, "parameters": ["doctree"], "calls": ["apply", "ApplySourceWorkaround"], "code_location": {"file": "test_util_nodes.py", "path": "/data3/pwh/swebench-repos/sphinx/tests/test_util", "start_line": 29, "end_line": 30}, "code_snippet": "def _transform(doctree: nodes.document) -> None:\n    ApplySourceWorkaround(doctree).apply()\n", "type": "function"}, {"name": "SphinxPostTransform", "docstring": "A base class of post-transforms.\n\nPost transforms are invoked to modify the document to restructure it for outputting.\nThey resolve references, convert images, do special transformation for each output\nformats and so on.  This class helps to implement these post transforms.", "methods": ["apply", "is_supported", "run"], "attributes": [], "code_location": {"file": "__init__.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/transforms/post_transforms", "start_line": 33, "end_line": 59}, "type": "class"}, {"name": "apply", "is_method": true, "class_name": "DoctreeReadEvent", "parameters": ["self"], "calls": ["self.env.events.emit"], "code_location": {"file": "__init__.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/transforms", "start_line": 416, "end_line": 417}, "code_snippet": "    def apply(self, **kwargs: Any) -> None:\n        self.env.events.emit('doctree-read', self.document)\n", "type": "function"}, {"name": "EventManager", "docstring": "Event manager for Sphinx.", "methods": ["__init__", "add", "app", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "connect", "disconnect", "emit", "emit_firstresult"], "attributes": [], "code_location": {"file": "events.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx", "start_line": 66, "end_line": 444}, "type": "class"}, {"name": "setup", "is_method": false, "class_name": null, "parameters": ["app"], "calls": ["app.add_transform", "app.add_transform", "app.add_transform", "app.add_transform", "app.add_transform", "app.add_transform", "app.add_transform", "app.add_transform", "app.add_transform", "app.add_transform", "app.add_transform", "app.add_transform", "app.add_transform", "app.add_transform", "app.add_transform"], "code_location": {"file": "__init__.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/transforms", "start_line": 511, "end_line": 532}, "code_snippet": "def setup(app: Sphinx) -> ExtensionMetadata:\n    app.add_transform(ApplySourceWorkaround)\n    app.add_transform(ExtraTranslatableNodes)\n    app.add_transform(DefaultSubstitutions)\n    app.add_transform(MoveModuleTargets)\n    app.add_transform(HandleCodeBlocks)\n    app.add_transform(SortIds)\n    app.add_transform(DoctestTransform)\n    app.add_transform(AutoNumbering)\n    app.add_transform(AutoIndexUpgrader)\n    app.add_transform(FilterSystemMessages)\n    app.add_transform(UnreferencedFootnotesDetector)\n    app.add_transform(SphinxSmartQuotes)\n    app.add_transform(DoctreeReadEvent)\n    app.add_transform(GlossarySorter)\n    app.add_transform(ReorderConsecutiveTargetAndIndexNodes)\n\n    return {\n        'version': 'builtin',\n        'parallel_read_safe': True,\n        'parallel_write_safe': True,\n    }\n", "type": "function"}, {"name": "setup", "is_method": false, "class_name": null, "parameters": ["app"], "calls": ["app.connect", "app.connect", "GroupedField", "app.add_object_type"], "code_location": {"file": "conf.py", "path": "/data3/pwh/swebench-repos/sphinx/doc", "start_line": 350, "end_line": 364}, "code_snippet": "def setup(app: Sphinx) -> None:\n    from sphinx.util.docfields import GroupedField\n\n    app.connect('include-read', linkify_issues_in_changelog)\n    app.connect('build-finished', build_redirects)\n    fdesc = GroupedField(\n        'parameter', label='Parameters', names=('param',), can_collapse=True\n    )\n    app.add_object_type(\n        'event',\n        'event',\n        'pair: %s; event',\n        parse_event,\n        doc_field_types=[fdesc],\n    )\n", "type": "function"}, {"name": "DoctreeReadEvent", "docstring": "Emit :event:`doctree-read` event.", "methods": ["apply"], "attributes": ["default_priority"], "code_location": {"file": "__init__.py", "path": "/data3/pwh/swebench-repos/sphinx/sphinx/transforms", "start_line": 411, "end_line": 417}, "type": "class"}], "retrieved_count": 10, "cost_time": 0.3472766876220703}
