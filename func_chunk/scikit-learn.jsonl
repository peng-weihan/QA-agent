{"question": "What is the architectural responsibility of the _local_reachability_density() method within LocalOutlierFactor's computational pipeline, and how does its encapsulation enable the separation between training-time and inference-time density calculations?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"name": "_local_reachability_density", "is_method": true, "class_name": "LocalOutlierFactor", "parameters": ["self", "distances_X", "neighbors_indices"], "calls": ["np.maximum", "np.mean"], "code_location": {"file": "_lof.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/neighbors", "start_line": 493, "end_line": 518}, "code_snippet": "    def _local_reachability_density(self, distances_X, neighbors_indices):\n        \"\"\"The local reachability density (LRD)\n\n        The LRD of a sample is the inverse of the average reachability\n        distance of its k-nearest neighbors.\n\n        Parameters\n        ----------\n        distances_X : ndarray of shape (n_queries, self.n_neighbors)\n            Distances to the neighbors (in the training samples `self._fit_X`)\n            of each query point to compute the LRD.\n\n        neighbors_indices : ndarray of shape (n_queries, self.n_neighbors)\n            Neighbors indices (of each query point) among training samples\n            self._fit_X.\n\n        Returns\n        -------\n        local_reachability_density : ndarray of shape (n_queries,)\n            The local reachability density of each sample.\n        \"\"\"\n        dist_k = self._distances_fit_X_[neighbors_indices, self.n_neighbors_ - 1]\n        reach_dist_array = np.maximum(distances_X, dist_k)\n\n        # 1e-10 to avoid `nan' when nb of duplicates > n_neighbors_:\n        return 1.0 / (np.mean(reach_dist_array, axis=1) + 1e-10)\n", "type": "function"}, {"name": "fit", "is_method": true, "class_name": "LocalOutlierFactor", "parameters": ["self", "X", "y"], "calls": ["_fit_context", "self._fit", "max", "self.kneighbors", "self._local_reachability_density", "warnings.warn", "min", "self._distances_fit_X_.astype", "np.mean", "np.percentile", "warnings.warn", "np.min"], "code_location": {"file": "_lof.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/neighbors", "start_line": 261, "end_line": 327}, "code_snippet": "    def fit(self, X, y=None):\n        \"\"\"Fit the local outlier factor detector from the training dataset.\n\n        Parameters\n        ----------\n        X : {array-like, sparse matrix} of shape (n_samples, n_features) or \\\n                (n_samples, n_samples) if metric='precomputed'\n            Training data.\n\n        y : Ignored\n            Not used, present for API consistency by convention.\n\n        Returns\n        -------\n        self : LocalOutlierFactor\n            The fitted local outlier factor detector.\n        \"\"\"\n        self._fit(X)\n\n        n_samples = self.n_samples_fit_\n        if self.n_neighbors > n_samples:\n            warnings.warn(\n                \"n_neighbors (%s) is greater than the \"\n                \"total number of samples (%s). n_neighbors \"\n                \"will be set to (n_samples - 1) for estimation.\"\n                % (self.n_neighbors, n_samples)\n            )\n        self.n_neighbors_ = max(1, min(self.n_neighbors, n_samples - 1))\n\n        self._distances_fit_X_, _neighbors_indices_fit_X_ = self.kneighbors(\n            n_neighbors=self.n_neighbors_\n        )\n\n        if self._fit_X.dtype == np.float32:\n            self._distances_fit_X_ = self._distances_fit_X_.astype(\n                self._fit_X.dtype,\n                copy=False,\n            )\n\n        self._lrd = self._local_reachability_density(\n            self._distances_fit_X_, _neighbors_indices_fit_X_\n        )\n\n        # Compute lof score over training samples to define offset_:\n        lrd_ratios_array = (\n            self._lrd[_neighbors_indices_fit_X_] / self._lrd[:, np.newaxis]\n        )\n\n        self.negative_outlier_factor_ = -np.mean(lrd_ratios_array, axis=1)\n\n        if self.contamination == \"auto\":\n            # inliers score around -1 (the higher, the less abnormal).\n            self.offset_ = -1.5\n        else:\n            self.offset_ = np.percentile(\n                self.negative_outlier_factor_, 100.0 * self.contamination\n            )\n\n        # Verify if negative_outlier_factor_ values are within acceptable range.\n        # Novelty must also be false to detect outliers\n        if np.min(self.negative_outlier_factor_) < -1e7 and not self.novelty:\n            warnings.warn(\n                \"Duplicate values are leading to incorrect results. \"\n                \"Increase the number of neighbors for more accurate results.\"\n            )\n\n        return self\n", "type": "function"}, {"name": "score_samples", "is_method": true, "class_name": "LocalOutlierFactor", "parameters": ["self", "X"], "calls": ["available_if", "check_is_fitted", "check_array", "self.kneighbors", "self._local_reachability_density", "distances_X.astype", "np.mean"], "code_location": {"file": "_lof.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/neighbors", "start_line": 446, "end_line": 491}, "code_snippet": "    def score_samples(self, X):\n        \"\"\"Opposite of the Local Outlier Factor of X.\n\n        It is the opposite as bigger is better, i.e. large values correspond\n        to inliers.\n\n        **Only available for novelty detection (when novelty is set to True).**\n        The argument X is supposed to contain *new data*: if X contains a\n        point from training, it considers the later in its own neighborhood.\n        Also, the samples in X are not considered in the neighborhood of any\n        point. Because of this, the scores obtained via ``score_samples`` may\n        differ from the standard LOF scores.\n        The standard LOF scores for the training data is available via the\n        ``negative_outlier_factor_`` attribute.\n\n        Parameters\n        ----------\n        X : {array-like, sparse matrix} of shape (n_samples, n_features)\n            The query sample or samples to compute the Local Outlier Factor\n            w.r.t. the training samples.\n\n        Returns\n        -------\n        opposite_lof_scores : ndarray of shape (n_samples,)\n            The opposite of the Local Outlier Factor of each input samples.\n            The lower, the more abnormal.\n        \"\"\"\n        check_is_fitted(self)\n        X = check_array(X, accept_sparse=\"csr\")\n\n        distances_X, neighbors_indices_X = self.kneighbors(\n            X, n_neighbors=self.n_neighbors_\n        )\n\n        if X.dtype == np.float32:\n            distances_X = distances_X.astype(X.dtype, copy=False)\n\n        X_lrd = self._local_reachability_density(\n            distances_X,\n            neighbors_indices_X,\n        )\n\n        lrd_ratios_array = self._lrd[neighbors_indices_X] / X_lrd[:, np.newaxis]\n\n        # as bigger is better:\n        return -np.mean(lrd_ratios_array, axis=1)\n", "type": "function"}, {"name": "test_novelty_training_scores", "is_method": false, "class_name": null, "parameters": ["global_dtype"], "calls": ["iris.data.astype", "neighbors.LocalOutlierFactor", "clf_1.fit", "neighbors.LocalOutlierFactor", "clf_2.fit", "assert_allclose"], "code_location": {"file": "test_lof.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/neighbors/tests", "start_line": 186, "end_line": 201}, "code_snippet": "def test_novelty_training_scores(global_dtype):\n    # check that the scores of the training samples are still accessible\n    # when novelty=True through the negative_outlier_factor_ attribute\n    X = iris.data.astype(global_dtype)\n\n    # fit with novelty=False\n    clf_1 = neighbors.LocalOutlierFactor()\n    clf_1.fit(X)\n    scores_1 = clf_1.negative_outlier_factor_\n\n    # fit with novelty=True\n    clf_2 = neighbors.LocalOutlierFactor(novelty=True)\n    clf_2.fit(X)\n    scores_2 = clf_2.negative_outlier_factor_\n\n    assert_allclose(scores_1, scores_2)\n", "type": "function"}, {"name": "test_lof_values", "is_method": false, "class_name": null, "parameters": ["global_dtype"], "calls": ["np.asarray", "fit", "fit", "assert_allclose", "assert_allclose", "assert_allclose", "assert_allclose", "assert_allclose", "assert_allclose", "neighbors.LocalOutlierFactor", "neighbors.LocalOutlierFactor", "sqrt", "sqrt", "sqrt", "clf1.score_samples", "clf2.score_samples", "clf1.score_samples", "clf2.score_samples", "sqrt", "sqrt"], "code_location": {"file": "test_lof.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/neighbors/tests", "start_line": 75, "end_line": 92}, "code_snippet": "def test_lof_values(global_dtype):\n    # toy samples:\n    X_train = np.asarray([[1, 1], [1, 2], [2, 1]], dtype=global_dtype)\n    clf1 = neighbors.LocalOutlierFactor(\n        n_neighbors=2, contamination=0.1, novelty=True\n    ).fit(X_train)\n    clf2 = neighbors.LocalOutlierFactor(n_neighbors=2, novelty=True).fit(X_train)\n    s_0 = 2.0 * sqrt(2.0) / (1.0 + sqrt(2.0))\n    s_1 = (1.0 + sqrt(2)) * (1.0 / (4.0 * sqrt(2.0)) + 1.0 / (2.0 + 2.0 * sqrt(2)))\n    # check predict()\n    assert_allclose(-clf1.negative_outlier_factor_, [s_0, s_1, s_1])\n    assert_allclose(-clf2.negative_outlier_factor_, [s_0, s_1, s_1])\n    # check predict(one sample not in train)\n    assert_allclose(-clf1.score_samples([[2.0, 2.0]]), [s_0])\n    assert_allclose(-clf2.score_samples([[2.0, 2.0]]), [s_0])\n    # check predict(one sample already in train)\n    assert_allclose(-clf1.score_samples([[1.0, 1.0]]), [s_1])\n    assert_allclose(-clf2.score_samples([[1.0, 1.0]]), [s_1])\n", "type": "function"}, {"name": "test_score_samples", "is_method": false, "class_name": null, "parameters": ["global_dtype"], "calls": ["np.asarray", "np.asarray", "fit", "fit", "clf1.score_samples", "clf1.decision_function", "clf2.score_samples", "clf2.decision_function", "assert_allclose", "assert_allclose", "assert_allclose", "neighbors.LocalOutlierFactor", "neighbors.LocalOutlierFactor"], "code_location": {"file": "test_lof.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/neighbors/tests", "start_line": 133, "end_line": 155}, "code_snippet": "def test_score_samples(global_dtype):\n    X_train = np.asarray([[1, 1], [1, 2], [2, 1]], dtype=global_dtype)\n    X_test = np.asarray([[2.0, 2.0]], dtype=global_dtype)\n    clf1 = neighbors.LocalOutlierFactor(\n        n_neighbors=2, contamination=0.1, novelty=True\n    ).fit(X_train)\n    clf2 = neighbors.LocalOutlierFactor(n_neighbors=2, novelty=True).fit(X_train)\n\n    clf1_scores = clf1.score_samples(X_test)\n    clf1_decisions = clf1.decision_function(X_test)\n\n    clf2_scores = clf2.score_samples(X_test)\n    clf2_decisions = clf2.decision_function(X_test)\n\n    assert_allclose(\n        clf1_scores,\n        clf1_decisions + clf1.offset_,\n    )\n    assert_allclose(\n        clf2_scores,\n        clf2_decisions + clf2.offset_,\n    )\n    assert_allclose(clf1_scores, clf2_scores)\n", "type": "function"}, {"name": "test_lof_performance", "is_method": false, "class_name": null, "parameters": ["global_dtype"], "calls": ["check_random_state", "astype", "np.array", "fit", "astype", "clf.decision_function", "roc_auc_score", "rng.uniform", "neighbors.LocalOutlierFactor", "rng.randn"], "code_location": {"file": "test_lof.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/neighbors/tests", "start_line": 52, "end_line": 72}, "code_snippet": "def test_lof_performance(global_dtype):\n    # Generate train/test data\n    rng = check_random_state(2)\n    X = 0.3 * rng.randn(120, 2).astype(global_dtype, copy=False)\n    X_train = X[:100]\n\n    # Generate some abnormal novel observations\n    X_outliers = rng.uniform(low=-4, high=4, size=(20, 2)).astype(\n        global_dtype, copy=False\n    )\n    X_test = np.r_[X[100:], X_outliers]\n    y_test = np.array([0] * 20 + [1] * 20)\n\n    # fit the model for novelty detection\n    clf = neighbors.LocalOutlierFactor(novelty=True).fit(X_train)\n\n    # predict scores (the lower, the more normal)\n    y_pred = -clf.decision_function(X_test)\n\n    # check that roc_auc is good\n    assert roc_auc_score(y_test, y_pred) > 0.99\n", "type": "function"}, {"name": "test_lof", "is_method": false, "class_name": null, "parameters": ["global_dtype"], "calls": ["np.asarray", "neighbors.LocalOutlierFactor", "assert_array_equal", "fit", "assert_array_equal", "assert_array_equal", "clf.fit", "np.min", "np.max", "clf._predict", "clf.fit_predict", "neighbors.LocalOutlierFactor"], "code_location": {"file": "test_lof.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/neighbors/tests", "start_line": 30, "end_line": 49}, "code_snippet": "def test_lof(global_dtype):\n    # Toy sample (the last two samples are outliers):\n    X = np.asarray(\n        [[-2, -1], [-1, -1], [-1, -2], [1, 1], [1, 2], [2, 1], [5, 3], [-4, 2]],\n        dtype=global_dtype,\n    )\n\n    # Test LocalOutlierFactor:\n    clf = neighbors.LocalOutlierFactor(n_neighbors=5)\n    score = clf.fit(X).negative_outlier_factor_\n    assert_array_equal(clf._fit_X, X)\n\n    # Assert largest outlier score is smaller than smallest inlier score:\n    assert np.min(score[:-2]) > np.max(score[-2:])\n\n    # Assert predict() works:\n    clf = neighbors.LocalOutlierFactor(contamination=0.25, n_neighbors=5).fit(X)\n    expected_predictions = 6 * [1] + 2 * [-1]\n    assert_array_equal(clf._predict(), expected_predictions)\n    assert_array_equal(clf.fit_predict(X), expected_predictions)\n", "type": "function"}, {"name": "_set_reach_dist", "is_method": false, "class_name": null, "parameters": ["core_distances_", "reachability_", "predecessor_", "point_index", "processed", "X", "nbrs", "metric", "metric_params", "p", "max_eps"], "calls": ["np.compress", "np.maximum", "np.around", "np.where", "nbrs.radius_neighbors", "isinstance", "dists.ravel", "ravel", "np.take", "np.asarray", "dict", "metric_params.copy", "np.take", "pairwise_distances", "np.finfo"], "code_location": {"file": "_optics.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/cluster", "start_line": 672, "end_line": 715}, "code_snippet": "def _set_reach_dist(\n    core_distances_,\n    reachability_,\n    predecessor_,\n    point_index,\n    processed,\n    X,\n    nbrs,\n    metric,\n    metric_params,\n    p,\n    max_eps,\n):\n    P = X[point_index : point_index + 1]\n    # Assume that radius_neighbors is faster without distances\n    # and we don't need all distances, nevertheless, this means\n    # we may be doing some work twice.\n    indices = nbrs.radius_neighbors(P, radius=max_eps, return_distance=False)[0]\n\n    # Getting indices of neighbors that have not been processed\n    unproc = np.compress(~np.take(processed, indices), indices)\n    # Neighbors of current point are already processed.\n    if not unproc.size:\n        return\n\n    # Only compute distances to unprocessed neighbors:\n    if metric == \"precomputed\":\n        dists = X[[point_index], unproc]\n        if isinstance(dists, np.matrix):\n            dists = np.asarray(dists)\n        dists = dists.ravel()\n    else:\n        _params = dict() if metric_params is None else metric_params.copy()\n        if metric == \"minkowski\" and \"p\" not in _params:\n            # the same logic as neighbors, p is ignored if explicitly set\n            # in the dict params\n            _params[\"p\"] = p\n        dists = pairwise_distances(P, X[unproc], metric, n_jobs=None, **_params).ravel()\n\n    rdists = np.maximum(dists, core_distances_[point_index])\n    np.around(rdists, decimals=np.finfo(rdists.dtype).precision, out=rdists)\n    improved = np.where(rdists < np.take(reachability_, unproc))\n    reachability_[unproc[improved]] = rdists[improved]\n    predecessor_[unproc[improved]] = point_index\n", "type": "function"}, {"name": "test_lof_novelty_false", "is_method": false, "class_name": null, "parameters": [], "calls": ["np.random.RandomState", "rng.randn", "make_pipeline", "LocalOutlierFactor", "est_chain.fit_predict", "est_compact.fit_predict", "assert_array_almost_equal", "KNeighborsTransformer", "LocalOutlierFactor"], "code_location": {"file": "test_neighbors_pipeline.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/neighbors/tests", "start_line": 160, "end_line": 183}, "code_snippet": "def test_lof_novelty_false():\n    # Test chaining KNeighborsTransformer and LocalOutlierFactor\n    n_neighbors = 4\n\n    rng = np.random.RandomState(0)\n    X = rng.randn(40, 2)\n\n    # compare the chained version and the compact version\n    est_chain = make_pipeline(\n        KNeighborsTransformer(n_neighbors=n_neighbors, mode=\"distance\"),\n        LocalOutlierFactor(\n            metric=\"precomputed\",\n            n_neighbors=n_neighbors,\n            novelty=False,\n            contamination=\"auto\",\n        ),\n    )\n    est_compact = LocalOutlierFactor(\n        n_neighbors=n_neighbors, novelty=False, contamination=\"auto\"\n    )\n\n    pred_chain = est_chain.fit_predict(X)\n    pred_compact = est_compact.fit_predict(X)\n    assert_array_almost_equal(pred_chain, pred_compact)\n", "type": "function"}], "retrieved_count": 10, "cost_time": 1.042191982269287}
{"question": "What is the semantic significance of SelectFromModel's partial_fit method enforcing max_features validation constraints differently compared to its fit method, and why does it raise validation errors during partial_fit rather than deferring validation to subsequent fit calls?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"name": "test_partial_fit", "is_method": false, "class_name": null, "parameters": [], "calls": ["PassiveAggressiveClassifier", "SelectFromModel", "transformer.partial_fit", "transformer.partial_fit", "transformer.transform", "transformer.fit", "assert_array_almost_equal", "SelectFromModel", "np.vstack", "np.concatenate", "transformer.transform", "hasattr", "np.unique", "np.unique", "RandomForestClassifier"], "code_location": {"file": "test_from_model.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/feature_selection/tests", "start_line": 395, "end_line": 412}, "code_snippet": "def test_partial_fit():\n    est = PassiveAggressiveClassifier(\n        random_state=0, shuffle=False, max_iter=5, tol=None\n    )\n    transformer = SelectFromModel(estimator=est)\n    transformer.partial_fit(data, y, classes=np.unique(y))\n    old_model = transformer.estimator_\n    transformer.partial_fit(data, y, classes=np.unique(y))\n    new_model = transformer.estimator_\n    assert old_model is new_model\n\n    X_transform = transformer.transform(data)\n    transformer.fit(np.vstack((data, data)), np.concatenate((y, y)))\n    assert_array_almost_equal(X_transform, transformer.transform(data))\n\n    # check that if est doesn't have partial_fit, neither does SelectFromModel\n    transformer = SelectFromModel(estimator=RandomForestClassifier())\n    assert not hasattr(transformer, \"partial_fit\")\n", "type": "function"}, {"name": "test_max_features_error", "is_method": false, "class_name": null, "parameters": ["max_features", "err_type", "err_msg"], "calls": ["pytest.mark.parametrize", "re.escape", "RandomForestClassifier", "SelectFromModel", "pytest.raises", "transformer.fit"], "code_location": {"file": "test_from_model.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/feature_selection/tests", "start_line": 106, "end_line": 114}, "code_snippet": "def test_max_features_error(max_features, err_type, err_msg):\n    err_msg = re.escape(err_msg)\n    clf = RandomForestClassifier(n_estimators=5, random_state=0)\n\n    transformer = SelectFromModel(\n        estimator=clf, max_features=max_features, threshold=-np.inf\n    )\n    with pytest.raises(err_type, match=err_msg):\n        transformer.fit(data, y)\n", "type": "function"}, {"name": "test_max_features", "is_method": false, "class_name": null, "parameters": [], "calls": ["datasets.make_classification", "RandomForestClassifier", "SelectFromModel", "SelectFromModel", "transformer1.fit_transform", "transformer2.fit_transform", "assert_allclose", "SelectFromModel", "transformer1.fit_transform", "np.abs", "np.argsort", "range", "assert_allclose", "SelectFromModel", "transformer2.fit_transform", "np.abs", "np.argsort", "assert_allclose", "Lasso", "Lasso"], "code_location": {"file": "test_from_model.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/feature_selection/tests", "start_line": 187, "end_line": 227}, "code_snippet": "def test_max_features():\n    # Test max_features parameter using various values\n    X, y = datasets.make_classification(\n        n_samples=1000,\n        n_features=10,\n        n_informative=3,\n        n_redundant=0,\n        n_repeated=0,\n        shuffle=False,\n        random_state=0,\n    )\n    max_features = X.shape[1]\n    est = RandomForestClassifier(n_estimators=50, random_state=0)\n\n    transformer1 = SelectFromModel(estimator=est, threshold=-np.inf)\n    transformer2 = SelectFromModel(\n        estimator=est, max_features=max_features, threshold=-np.inf\n    )\n    X_new1 = transformer1.fit_transform(X, y)\n    X_new2 = transformer2.fit_transform(X, y)\n    assert_allclose(X_new1, X_new2)\n\n    # Test max_features against actual model.\n    transformer1 = SelectFromModel(estimator=Lasso(alpha=0.025, random_state=42))\n    X_new1 = transformer1.fit_transform(X, y)\n    scores1 = np.abs(transformer1.estimator_.coef_)\n    candidate_indices1 = np.argsort(-scores1, kind=\"mergesort\")\n\n    for n_features in range(1, X_new1.shape[1] + 1):\n        transformer2 = SelectFromModel(\n            estimator=Lasso(alpha=0.025, random_state=42),\n            max_features=n_features,\n            threshold=-np.inf,\n        )\n        X_new2 = transformer2.fit_transform(X, y)\n        scores2 = np.abs(transformer2.estimator_.coef_)\n        candidate_indices2 = np.argsort(-scores2, kind=\"mergesort\")\n        assert_allclose(\n            X[:, candidate_indices1[:n_features]], X[:, candidate_indices2[:n_features]]\n        )\n    assert_allclose(transformer1.estimator_.coef_, transformer2.estimator_.coef_)\n", "type": "function"}, {"name": "test_max_features_array_like", "is_method": false, "class_name": null, "parameters": ["max_features"], "calls": ["pytest.mark.parametrize", "RandomForestClassifier", "SelectFromModel", "transformer.fit_transform", "round", "len"], "code_location": {"file": "test_from_model.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/feature_selection/tests", "start_line": 149, "end_line": 163}, "code_snippet": "def test_max_features_array_like(max_features):\n    X = [\n        [0.87, -1.34, 0.31],\n        [-2.79, -0.02, -0.85],\n        [-1.34, -0.48, -2.55],\n        [1.92, 1.48, 0.65],\n    ]\n    y = [0, 1, 0, 1]\n\n    clf = RandomForestClassifier(n_estimators=5, random_state=0)\n    transformer = SelectFromModel(\n        estimator=clf, max_features=max_features, threshold=-np.inf\n    )\n    X_trans = transformer.fit_transform(X, y)\n    assert X_trans.shape[1] == transformer.max_features_\n", "type": "function"}, {"name": "check_estimators_partial_fit_n_features", "is_method": false, "class_name": null, "parameters": ["name", "estimator_orig"], "calls": ["ignore_warnings", "clone", "make_blobs", "_enforce_estimator_tags_X", "_enforce_estimator_tags_y", "hasattr", "is_classifier", "raises", "estimator.partial_fit", "np.unique", "estimator.partial_fit", "estimator.partial_fit"], "code_location": {"file": "estimator_checks.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/utils", "start_line": 2444, "end_line": 2469}, "code_snippet": "def check_estimators_partial_fit_n_features(name, estimator_orig):\n    # check if number of features changes between calls to partial_fit.\n    if not hasattr(estimator_orig, \"partial_fit\"):\n        return\n    estimator = clone(estimator_orig)\n    X, y = make_blobs(n_samples=50, random_state=1)\n    X = _enforce_estimator_tags_X(estimator_orig, X)\n    y = _enforce_estimator_tags_y(estimator_orig, y)\n\n    try:\n        if is_classifier(estimator):\n            classes = np.unique(y)\n            estimator.partial_fit(X, y, classes=classes)\n        else:\n            estimator.partial_fit(X, y)\n    except NotImplementedError:\n        return\n\n    with raises(\n        ValueError,\n        err_msg=(\n            f\"The estimator {name} does not raise an error when the \"\n            \"number of features changes between calls to partial_fit.\"\n        ),\n    ):\n        estimator.partial_fit(X[:, :-1], y)\n", "type": "function"}, {"name": "test_partial_fit_second_call_error_checks", "is_method": false, "class_name": null, "parameters": [], "calls": ["make_blobs", "Birch", "brc.partial_fit", "pytest.raises", "brc.partial_fit"], "code_location": {"file": "test_birch.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/cluster/tests", "start_line": 115, "end_line": 124}, "code_snippet": "def test_partial_fit_second_call_error_checks():\n    # second partial fit calls will error when n_features is not consistent\n    # with the first call\n    X, y = make_blobs(n_samples=100)\n    brc = Birch(n_clusters=3)\n    brc.partial_fit(X, y)\n\n    msg = \"X has 1 features, but Birch is expecting 2 features\"\n    with pytest.raises(ValueError, match=msg):\n        brc.partial_fit(X[:, [0]], y)\n", "type": "function"}, {"name": "test_threshold_and_max_features", "is_method": false, "class_name": null, "parameters": [], "calls": ["datasets.make_classification", "RandomForestClassifier", "SelectFromModel", "transformer1.fit_transform", "SelectFromModel", "transformer2.fit_transform", "SelectFromModel", "transformer3.fit_transform", "transformer3.transform", "assert_allclose", "min", "np.arange"], "code_location": {"file": "test_from_model.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/feature_selection/tests", "start_line": 256, "end_line": 278}, "code_snippet": "def test_threshold_and_max_features():\n    X, y = datasets.make_classification(\n        n_samples=1000,\n        n_features=10,\n        n_informative=3,\n        n_redundant=0,\n        n_repeated=0,\n        shuffle=False,\n        random_state=0,\n    )\n    est = RandomForestClassifier(n_estimators=50, random_state=0)\n\n    transformer1 = SelectFromModel(estimator=est, max_features=3, threshold=-np.inf)\n    X_new1 = transformer1.fit_transform(X, y)\n\n    transformer2 = SelectFromModel(estimator=est, threshold=0.04)\n    X_new2 = transformer2.fit_transform(X, y)\n\n    transformer3 = SelectFromModel(estimator=est, max_features=3, threshold=0.04)\n    X_new3 = transformer3.fit_transform(X, y)\n    assert X_new3.shape[1] == min(X_new1.shape[1], X_new2.shape[1])\n    selected_indices = transformer3.transform(np.arange(X.shape[1])[np.newaxis, :])\n    assert_allclose(X_new3, X[:, selected_indices[0]])\n", "type": "function"}, {"name": "test_unsupervised_model_fit", "is_method": false, "class_name": null, "parameters": ["n_features_to_select"], "calls": ["pytest.mark.parametrize", "make_blobs", "SequentialFeatureSelector", "sfs.fit", "KMeans", "sfs.transform"], "code_location": {"file": "test_sequential.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/feature_selection/tests", "start_line": 244, "end_line": 254}, "code_snippet": "def test_unsupervised_model_fit(n_features_to_select):\n    # Make sure that models without classification labels are not being\n    # validated\n\n    X, y = make_blobs(n_features=4)\n    sfs = SequentialFeatureSelector(\n        KMeans(n_init=1),\n        n_features_to_select=n_features_to_select,\n    )\n    sfs.fit(X)\n    assert sfs.transform(X).shape[1] == n_features_to_select\n", "type": "function"}, {"name": "_check_max_features", "is_method": true, "class_name": "SelectFromModel", "parameters": ["self", "X"], "calls": ["_num_features", "callable", "check_scalar", "self.max_features"], "code_location": {"file": "_from_model.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/feature_selection", "start_line": 309, "end_line": 325}, "code_snippet": "    def _check_max_features(self, X):\n        if self.max_features is not None:\n            n_features = _num_features(X)\n\n            if callable(self.max_features):\n                max_features = self.max_features(X)\n            else:  # int\n                max_features = self.max_features\n\n            check_scalar(\n                max_features,\n                \"max_features\",\n                Integral,\n                min_val=0,\n                max_val=n_features,\n            )\n            self.max_features_ = max_features\n", "type": "function"}, {"name": "_partial_fit", "is_method": true, "class_name": "BaseSGDClassifier", "parameters": ["self", "X", "y", "alpha", "C", "loss", "learning_rate", "max_iter", "classes", "sample_weight", "coef_init", "intercept_init"], "calls": ["validate_data", "_check_partial_fit_first_call", "compute_class_weight", "_check_sample_weight", "self._get_loss_function", "hasattr", "self._allocate_parameter_mem", "hasattr", "self._fit_multiclass", "getattr", "ValueError", "self._fit_binary", "ValueError"], "code_location": {"file": "_stochastic_gradient.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/linear_model", "start_line": 591, "end_line": 674}, "code_snippet": "    def _partial_fit(\n        self,\n        X,\n        y,\n        alpha,\n        C,\n        loss,\n        learning_rate,\n        max_iter,\n        classes,\n        sample_weight,\n        coef_init,\n        intercept_init,\n    ):\n        first_call = not hasattr(self, \"classes_\")\n        X, y = validate_data(\n            self,\n            X,\n            y,\n            accept_sparse=\"csr\",\n            dtype=[np.float64, np.float32],\n            order=\"C\",\n            accept_large_sparse=False,\n            reset=first_call,\n        )\n\n        n_samples, n_features = X.shape\n\n        _check_partial_fit_first_call(self, classes)\n\n        n_classes = self.classes_.shape[0]\n\n        # Allocate datastructures from input arguments\n        self._expanded_class_weight = compute_class_weight(\n            self.class_weight, classes=self.classes_, y=y\n        )\n        sample_weight = _check_sample_weight(sample_weight, X, dtype=X.dtype)\n\n        if getattr(self, \"coef_\", None) is None or coef_init is not None:\n            self._allocate_parameter_mem(\n                n_classes=n_classes,\n                n_features=n_features,\n                input_dtype=X.dtype,\n                coef_init=coef_init,\n                intercept_init=intercept_init,\n            )\n        elif n_features != self.coef_.shape[-1]:\n            raise ValueError(\n                \"Number of features %d does not match previous data %d.\"\n                % (n_features, self.coef_.shape[-1])\n            )\n\n        self._loss_function_ = self._get_loss_function(loss)\n        if not hasattr(self, \"t_\"):\n            self.t_ = 1.0\n\n        # delegate to concrete training procedure\n        if n_classes > 2:\n            self._fit_multiclass(\n                X,\n                y,\n                alpha=alpha,\n                C=C,\n                learning_rate=learning_rate,\n                sample_weight=sample_weight,\n                max_iter=max_iter,\n            )\n        elif n_classes == 2:\n            self._fit_binary(\n                X,\n                y,\n                alpha=alpha,\n                C=C,\n                learning_rate=learning_rate,\n                sample_weight=sample_weight,\n                max_iter=max_iter,\n            )\n        else:\n            raise ValueError(\n                \"The number of classes has to be greater than one; got %d class\"\n                % n_classes\n            )\n\n        return self\n", "type": "function"}], "retrieved_count": 10, "cost_time": 1.0524253845214844}
{"question": "What is the architectural pattern established by the DictionaryLearningBenchmark class that integrates the Transformer, Estimator, and Benchmark base classes for performance measurement in the decomposition module?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"name": "DictionaryLearningBenchmark", "docstring": "Benchmarks for DictionaryLearning.", "methods": ["setup_cache", "make_data", "make_estimator", "make_scorers"], "attributes": ["param_names", "params"], "code_location": {"file": "decomposition.py", "path": "/data3/pwh/swebench-repos/scikit-learn/asv_benchmarks/benchmarks", "start_line": 33, "end_line": 64}, "type": "class"}, {"name": "Transformer", "docstring": "Abstract base class for benchmarks of estimators implementing transform", "methods": ["params"], "attributes": [], "code_location": {"file": "common.py", "path": "/data3/pwh/swebench-repos/scikit-learn/asv_benchmarks/benchmarks", "start_line": 230, "end_line": 256}, "type": "class"}, {"name": "MiniBatchDictionaryLearningBenchmark", "docstring": "Benchmarks for MiniBatchDictionaryLearning", "methods": ["setup_cache", "make_data", "make_estimator", "make_scorers"], "attributes": ["param_names", "params"], "code_location": {"file": "decomposition.py", "path": "/data3/pwh/swebench-repos/scikit-learn/asv_benchmarks/benchmarks", "start_line": 67, "end_line": 96}, "type": "class"}, {"name": "Estimator", "docstring": "Abstract base class for all benchmarks of estimators", "methods": ["make_data", "make_estimator", "skip", "setup_cache", "setup", "time_fit", "peakmem_fit", "track_train_score", "track_test_score"], "attributes": [], "code_location": {"file": "common.py", "path": "/data3/pwh/swebench-repos/scikit-learn/asv_benchmarks/benchmarks", "start_line": 120, "end_line": 198}, "type": "class"}, {"name": "make_estimator", "is_method": true, "class_name": "DictionaryLearningBenchmark", "parameters": ["self", "params"], "calls": ["DictionaryLearning"], "code_location": {"file": "decomposition.py", "path": "/data3/pwh/swebench-repos/scikit-learn/asv_benchmarks/benchmarks", "start_line": 47, "end_line": 61}, "code_snippet": "    def make_estimator(self, params):\n        fit_algorithm, n_jobs = params\n\n        estimator = DictionaryLearning(\n            n_components=15,\n            fit_algorithm=fit_algorithm,\n            alpha=0.1,\n            transform_alpha=1,\n            max_iter=20,\n            tol=1e-16,\n            random_state=0,\n            n_jobs=n_jobs,\n        )\n\n        return estimator\n", "type": "function"}, {"name": "benchmark", "is_method": false, "class_name": null, "parameters": ["estimator", "data"], "calls": ["gc.collect", "print", "time", "estimator.fit", "estimator.transform", "estimator.inverse_transform", "np.mean", "time", "np.abs"], "code_location": {"file": "bench_plot_incremental_pca.py", "path": "/data3/pwh/swebench-repos/scikit-learn/benchmarks", "start_line": 25, "end_line": 34}, "code_snippet": "def benchmark(estimator, data):\n    gc.collect()\n    print(\"Benching %s\" % estimator)\n    t0 = time()\n    estimator.fit(data)\n    training_time = time() - t0\n    data_t = estimator.transform(data)\n    data_r = estimator.inverse_transform(data_t)\n    reconstruction_error = np.mean(np.abs(data - data_r))\n    return {\"time\": training_time, \"error\": reconstruction_error}\n", "type": "function"}, {"name": "DictionaryLearning", "docstring": "Dictionary learning.\n\nFinds a dictionary (a set of atoms) that performs well at sparsely\nencoding the fitted data.\n\nSolves the optimization problem::\n\n    (U^*,V^*) = argmin 0.5 || X - U V ||_Fro^2 + alpha * || U ||_1,1\n                (U,V)\n                with || V_k ||_2 <= 1 for all  0 <= k < n_components\n\n||.||_Fro stands for the Frobenius norm and ||.||_1,1 stands for\nthe entry-wise matrix norm which is the sum of the absolute values\nof all the entries in the matrix.\n\nRead more in the :ref:`User Guide <DictionaryLearning>`.\n\nParameters\n----------\nn_components : int, default=None\n    Number of dictionary elements to extract. If None, then ``n_components``\n    is set to ``n_features``.\n\nalpha : float, default=1.0\n    Sparsity controlling parameter.\n\nmax_iter : int, default=1000\n    Maximum number of iterations to perform.\n\ntol : float, default=1e-8\n    Tolerance for numerical error.\n\nfit_algorithm : {'lars', 'cd'}, default='lars'\n    * `'lars'`: uses the least angle regression method to solve the lasso\n      problem (:func:`~sklearn.linear_model.lars_path`);\n    * `'cd'`: uses the coordinate descent method to compute the\n      Lasso solution (:class:`~sklearn.linear_model.Lasso`). Lars will be\n      faster if the estimated components are sparse.\n\n    .. versionadded:: 0.17\n       *cd* coordinate descent method to improve speed.\n\ntransform_algorithm : {'lasso_lars', 'lasso_cd', 'lars', 'omp',             'threshold'}, default='omp'\n    Algorithm used to transform the data:\n\n    - `'lars'`: uses the least angle regression method\n      (:func:`~sklearn.linear_model.lars_path`);\n    - `'lasso_lars'`: uses Lars to compute the Lasso solution.\n    - `'lasso_cd'`: uses the coordinate descent method to compute the\n      Lasso solution (:class:`~sklearn.linear_model.Lasso`). `'lasso_lars'`\n      will be faster if the estimated components are sparse.\n    - `'omp'`: uses orthogonal matching pursuit to estimate the sparse\n      solution.\n    - `'threshold'`: squashes to zero all coefficients less than alpha from\n      the projection ``dictionary * X'``.\n\n    .. versionadded:: 0.17\n       *lasso_cd* coordinate descent method to improve speed.\n\ntransform_n_nonzero_coefs : int, default=None\n    Number of nonzero coefficients to target in each column of the\n    solution. This is only used by `algorithm='lars'` and\n    `algorithm='omp'`. If `None`, then\n    `transform_n_nonzero_coefs=int(n_features / 10)`.\n\ntransform_alpha : float, default=None\n    If `algorithm='lasso_lars'` or `algorithm='lasso_cd'`, `alpha` is the\n    penalty applied to the L1 norm.\n    If `algorithm='threshold'`, `alpha` is the absolute value of the\n    threshold below which coefficients will be squashed to zero.\n    If `None`, defaults to `alpha`.\n\n    .. versionchanged:: 1.2\n        When None, default value changed from 1.0 to `alpha`.\n\nn_jobs : int or None, default=None\n    Number of parallel jobs to run.\n    ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n    ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n    for more details.\n\ncode_init : ndarray of shape (n_samples, n_components), default=None\n    Initial value for the code, for warm restart. Only used if `code_init`\n    and `dict_init` are not None.\n\ndict_init : ndarray of shape (n_components, n_features), default=None\n    Initial values for the dictionary, for warm restart. Only used if\n    `code_init` and `dict_init` are not None.\n\ncallback : callable, default=None\n    Callable that gets invoked every five iterations.\n\n    .. versionadded:: 1.3\n\nverbose : bool, default=False\n    To control the verbosity of the procedure.\n\nsplit_sign : bool, default=False\n    Whether to split the sparse feature vector into the concatenation of\n    its negative part and its positive part. This can improve the\n    performance of downstream classifiers.\n\nrandom_state : int, RandomState instance or None, default=None\n    Used for initializing the dictionary when ``dict_init`` is not\n    specified, randomly shuffling the data when ``shuffle`` is set to\n    ``True``, and updating the dictionary. Pass an int for reproducible\n    results across multiple function calls.\n    See :term:`Glossary <random_state>`.\n\npositive_code : bool, default=False\n    Whether to enforce positivity when finding the code.\n\n    .. versionadded:: 0.20\n\npositive_dict : bool, default=False\n    Whether to enforce positivity when finding the dictionary.\n\n    .. versionadded:: 0.20\n\ntransform_max_iter : int, default=1000\n    Maximum number of iterations to perform if `algorithm='lasso_cd'` or\n    `'lasso_lars'`.\n\n    .. versionadded:: 0.22\n\nAttributes\n----------\ncomponents_ : ndarray of shape (n_components, n_features)\n    dictionary atoms extracted from the data\n\nerror_ : array\n    vector of errors at each iteration\n\nn_features_in_ : int\n    Number of features seen during :term:`fit`.\n\n    .. versionadded:: 0.24\n\nfeature_names_in_ : ndarray of shape (`n_features_in_`,)\n    Names of features seen during :term:`fit`. Defined only when `X`\n    has feature names that are all strings.\n\n    .. versionadded:: 1.0\n\nn_iter_ : int\n    Number of iterations run.\n\nSee Also\n--------\nMiniBatchDictionaryLearning: A faster, less accurate, version of the\n    dictionary learning algorithm.\nMiniBatchSparsePCA : Mini-batch Sparse Principal Components Analysis.\nSparseCoder : Find a sparse representation of data from a fixed,\n    precomputed dictionary.\nSparsePCA : Sparse Principal Components Analysis.\n\nReferences\n----------\n\nJ. Mairal, F. Bach, J. Ponce, G. Sapiro, 2009: Online dictionary learning\nfor sparse coding (https://www.di.ens.fr/~fbach/mairal_icml09.pdf)\n\nExamples\n--------\n>>> import numpy as np\n>>> from sklearn.datasets import make_sparse_coded_signal\n>>> from sklearn.decomposition import DictionaryLearning\n>>> X, dictionary, code = make_sparse_coded_signal(\n...     n_samples=30, n_components=15, n_features=20, n_nonzero_coefs=10,\n...     random_state=42,\n... )\n>>> dict_learner = DictionaryLearning(\n...     n_components=15, transform_algorithm='lasso_lars', transform_alpha=0.1,\n...     random_state=42,\n... )\n>>> X_transformed = dict_learner.fit(X).transform(X)\n\nWe can check the level of sparsity of `X_transformed`:\n\n>>> np.mean(X_transformed == 0)\nnp.float64(0.527)\n\nWe can compare the average squared euclidean norm of the reconstruction\nerror of the sparse coded signal relative to the squared euclidean norm of\nthe original signal:\n\n>>> X_hat = X_transformed @ dict_learner.components_\n>>> np.mean(np.sum((X_hat - X) ** 2, axis=1) / np.sum(X ** 2, axis=1))\nnp.float64(0.056)", "methods": ["__init__", "fit", "fit_transform", "_n_features_out", "__sklearn_tags__"], "attributes": [], "code_location": {"file": "_dict_learning.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/decomposition", "start_line": 1408, "end_line": 1748}, "type": "class"}, {"name": "bench_one", "is_method": false, "class_name": null, "parameters": ["name", "X", "W0", "H0", "X_shape", "clf_type", "clf_params", "init", "n_components", "random_state"], "calls": ["ignore_warnings", "mem.cache", "W0.copy", "H0.copy", "clf_type", "time", "clf.fit_transform", "time", "_beta_divergence"], "code_location": {"file": "bench_plot_nmf.py", "path": "/data3/pwh/swebench-repos/scikit-learn/benchmarks", "start_line": 354, "end_line": 368}, "code_snippet": "def bench_one(\n    name, X, W0, H0, X_shape, clf_type, clf_params, init, n_components, random_state\n):\n    W = W0.copy()\n    H = H0.copy()\n\n    clf = clf_type(**clf_params)\n    st = time()\n    W = clf.fit_transform(X, W=W, H=H)\n    end = time()\n    H = clf.components_\n\n    this_loss = _beta_divergence(X, W, H, 2.0, True)\n    duration = end - st\n    return this_loss, duration\n", "type": "function"}, {"name": "MiniBatchDictionaryLearning", "docstring": "Mini-batch dictionary learning.\n\nFinds a dictionary (a set of atoms) that performs well at sparsely\nencoding the fitted data.\n\nSolves the optimization problem::\n\n   (U^*,V^*) = argmin 0.5 || X - U V ||_Fro^2 + alpha * || U ||_1,1\n                (U,V)\n                with || V_k ||_2 <= 1 for all  0 <= k < n_components\n\n||.||_Fro stands for the Frobenius norm and ||.||_1,1 stands for\nthe entry-wise matrix norm which is the sum of the absolute values\nof all the entries in the matrix.\n\nRead more in the :ref:`User Guide <DictionaryLearning>`.\n\nParameters\n----------\nn_components : int, default=None\n    Number of dictionary elements to extract.\n\nalpha : float, default=1\n    Sparsity controlling parameter.\n\nmax_iter : int, default=1_000\n    Maximum number of iterations over the complete dataset before\n    stopping independently of any early stopping criterion heuristics.\n\n    .. versionadded:: 1.1\n\nfit_algorithm : {'lars', 'cd'}, default='lars'\n    The algorithm used:\n\n    - `'lars'`: uses the least angle regression method to solve the lasso\n      problem (`linear_model.lars_path`)\n    - `'cd'`: uses the coordinate descent method to compute the\n      Lasso solution (`linear_model.Lasso`). Lars will be faster if\n      the estimated components are sparse.\n\nn_jobs : int, default=None\n    Number of parallel jobs to run.\n    ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n    ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n    for more details.\n\nbatch_size : int, default=256\n    Number of samples in each mini-batch.\n\n    .. versionchanged:: 1.3\n       The default value of `batch_size` changed from 3 to 256 in version 1.3.\n\nshuffle : bool, default=True\n    Whether to shuffle the samples before forming batches.\n\ndict_init : ndarray of shape (n_components, n_features), default=None\n    Initial value of the dictionary for warm restart scenarios.\n\ntransform_algorithm : {'lasso_lars', 'lasso_cd', 'lars', 'omp',             'threshold'}, default='omp'\n    Algorithm used to transform the data:\n\n    - `'lars'`: uses the least angle regression method\n      (`linear_model.lars_path`);\n    - `'lasso_lars'`: uses Lars to compute the Lasso solution.\n    - `'lasso_cd'`: uses the coordinate descent method to compute the\n      Lasso solution (`linear_model.Lasso`). `'lasso_lars'` will be faster\n      if the estimated components are sparse.\n    - `'omp'`: uses orthogonal matching pursuit to estimate the sparse\n      solution.\n    - `'threshold'`: squashes to zero all coefficients less than alpha from\n      the projection ``dictionary * X'``.\n\ntransform_n_nonzero_coefs : int, default=None\n    Number of nonzero coefficients to target in each column of the\n    solution. This is only used by `algorithm='lars'` and\n    `algorithm='omp'`. If `None`, then\n    `transform_n_nonzero_coefs=int(n_features / 10)`.\n\ntransform_alpha : float, default=None\n    If `algorithm='lasso_lars'` or `algorithm='lasso_cd'`, `alpha` is the\n    penalty applied to the L1 norm.\n    If `algorithm='threshold'`, `alpha` is the absolute value of the\n    threshold below which coefficients will be squashed to zero.\n    If `None`, defaults to `alpha`.\n\n    .. versionchanged:: 1.2\n        When None, default value changed from 1.0 to `alpha`.\n\nverbose : bool or int, default=False\n    To control the verbosity of the procedure.\n\nsplit_sign : bool, default=False\n    Whether to split the sparse feature vector into the concatenation of\n    its negative part and its positive part. This can improve the\n    performance of downstream classifiers.\n\nrandom_state : int, RandomState instance or None, default=None\n    Used for initializing the dictionary when ``dict_init`` is not\n    specified, randomly shuffling the data when ``shuffle`` is set to\n    ``True``, and updating the dictionary. Pass an int for reproducible\n    results across multiple function calls.\n    See :term:`Glossary <random_state>`.\n\npositive_code : bool, default=False\n    Whether to enforce positivity when finding the code.\n\n    .. versionadded:: 0.20\n\npositive_dict : bool, default=False\n    Whether to enforce positivity when finding the dictionary.\n\n    .. versionadded:: 0.20\n\ntransform_max_iter : int, default=1000\n    Maximum number of iterations to perform if `algorithm='lasso_cd'` or\n    `'lasso_lars'`.\n\n    .. versionadded:: 0.22\n\ncallback : callable, default=None\n    A callable that gets invoked at the end of each iteration.\n\n    .. versionadded:: 1.1\n\ntol : float, default=1e-3\n    Control early stopping based on the norm of the differences in the\n    dictionary between 2 steps.\n\n    To disable early stopping based on changes in the dictionary, set\n    `tol` to 0.0.\n\n    .. versionadded:: 1.1\n\nmax_no_improvement : int, default=10\n    Control early stopping based on the consecutive number of mini batches\n    that does not yield an improvement on the smoothed cost function.\n\n    To disable convergence detection based on cost function, set\n    `max_no_improvement` to None.\n\n    .. versionadded:: 1.1\n\nAttributes\n----------\ncomponents_ : ndarray of shape (n_components, n_features)\n    Components extracted from the data.\n\nn_features_in_ : int\n    Number of features seen during :term:`fit`.\n\n    .. versionadded:: 0.24\n\nfeature_names_in_ : ndarray of shape (`n_features_in_`,)\n    Names of features seen during :term:`fit`. Defined only when `X`\n    has feature names that are all strings.\n\n    .. versionadded:: 1.0\n\nn_iter_ : int\n    Number of iterations over the full dataset.\n\nn_steps_ : int\n    Number of mini-batches processed.\n\n    .. versionadded:: 1.1\n\nSee Also\n--------\nDictionaryLearning : Find a dictionary that sparsely encodes data.\nMiniBatchSparsePCA : Mini-batch Sparse Principal Components Analysis.\nSparseCoder : Find a sparse representation of data from a fixed,\n    precomputed dictionary.\nSparsePCA : Sparse Principal Components Analysis.\n\nReferences\n----------\n\nJ. Mairal, F. Bach, J. Ponce, G. Sapiro, 2009: Online dictionary learning\nfor sparse coding (https://www.di.ens.fr/~fbach/mairal_icml09.pdf)\n\nExamples\n--------\n>>> import numpy as np\n>>> from sklearn.datasets import make_sparse_coded_signal\n>>> from sklearn.decomposition import MiniBatchDictionaryLearning\n>>> X, dictionary, code = make_sparse_coded_signal(\n...     n_samples=30, n_components=15, n_features=20, n_nonzero_coefs=10,\n...     random_state=42)\n>>> dict_learner = MiniBatchDictionaryLearning(\n...     n_components=15, batch_size=3, transform_algorithm='lasso_lars',\n...     transform_alpha=0.1, max_iter=20, random_state=42)\n>>> X_transformed = dict_learner.fit_transform(X)\n\nWe can check the level of sparsity of `X_transformed`:\n\n>>> np.mean(X_transformed == 0) > 0.5\nnp.True_\n\nWe can compare the average squared euclidean norm of the reconstruction\nerror of the sparse coded signal relative to the squared euclidean norm of\nthe original signal:\n\n>>> X_hat = X_transformed @ dict_learner.components_\n>>> np.mean(np.sum((X_hat - X) ** 2, axis=1) / np.sum(X ** 2, axis=1))\nnp.float64(0.052)", "methods": ["__init__", "_check_params", "_initialize_dict", "_update_inner_stats", "_minibatch_step", "_check_convergence", "fit", "partial_fit", "_n_features_out", "__sklearn_tags__"], "attributes": [], "code_location": {"file": "_dict_learning.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/decomposition", "start_line": 1751, "end_line": 2329}, "type": "class"}, {"name": "make_estimator", "is_method": true, "class_name": "MiniBatchDictionaryLearningBenchmark", "parameters": ["self", "params"], "calls": ["MiniBatchDictionaryLearning"], "code_location": {"file": "decomposition.py", "path": "/data3/pwh/swebench-repos/scikit-learn/asv_benchmarks/benchmarks", "start_line": 81, "end_line": 93}, "code_snippet": "    def make_estimator(self, params):\n        fit_algorithm, n_jobs = params\n\n        estimator = MiniBatchDictionaryLearning(\n            n_components=15,\n            fit_algorithm=fit_algorithm,\n            alpha=0.1,\n            batch_size=3,\n            random_state=0,\n            n_jobs=n_jobs,\n        )\n\n        return estimator\n", "type": "function"}], "retrieved_count": 10, "cost_time": 1.0869033336639404}
{"question": "What is the dependency resolution mechanism in _parallel_predict_regression that handles the estimator.predict method across heterogeneous base estimators with different feature selection requirements, and what internal module dependencies enable this polymorphic behavior?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"name": "_estimators_that_predict_in_fit", "is_method": false, "class_name": null, "parameters": [], "calls": ["_tested_estimators", "set", "estimator.get_params", "estimator.set_params", "estimator.set_params", "pytest.param", "estimator.set_params", "pytest.mark.xfail"], "code_location": {"file": "test_common.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/tests", "start_line": 225, "end_line": 240}, "code_snippet": "def _estimators_that_predict_in_fit():\n    for estimator in _tested_estimators():\n        est_params = set(estimator.get_params())\n        if \"oob_score\" in est_params:\n            yield estimator.set_params(oob_score=True, bootstrap=True)\n        elif \"early_stopping\" in est_params:\n            est = estimator.set_params(early_stopping=True, n_iter_no_change=1)\n            if est.__class__.__name__ in {\"MLPClassifier\", \"MLPRegressor\"}:\n                # TODO: FIX MLP to not check validation set during MLP\n                yield pytest.param(\n                    est, marks=pytest.mark.xfail(msg=\"MLP still validates in fit\")\n                )\n            else:\n                yield est\n        elif \"n_iter_no_change\" in est_params:\n            yield estimator.set_params(n_iter_no_change=1)\n", "type": "function"}, {"name": "_get_estimator", "is_method": true, "class_name": "IsolationForest", "parameters": ["self"], "calls": ["ExtraTreeRegressor"], "code_location": {"file": "_iforest.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/ensemble", "start_line": 277, "end_line": 283}, "code_snippet": "    def _get_estimator(self):\n        return ExtraTreeRegressor(\n            # here max_features has no links with self.max_features\n            max_features=1,\n            splitter=\"random\",\n            random_state=self.random_state,\n        )\n", "type": "function"}, {"name": "test_multioutputregressor_ducktypes_fitted_estimator", "is_method": false, "class_name": null, "parameters": [], "calls": ["load_linnerud", "StackingRegressor", "fit", "reg.predict", "Ridge", "MultiOutputRegressor", "SGDRegressor"], "code_location": {"file": "test_multioutput.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/tests", "start_line": 828, "end_line": 841}, "code_snippet": "def test_multioutputregressor_ducktypes_fitted_estimator():\n    \"\"\"Test that MultiOutputRegressor checks the fitted estimator for\n    predict. Non-regression test for #16549.\"\"\"\n    X, y = load_linnerud(return_X_y=True)\n    stacker = StackingRegressor(\n        estimators=[(\"sgd\", SGDRegressor(random_state=1))],\n        final_estimator=Ridge(),\n        cv=2,\n    )\n\n    reg = MultiOutputRegressor(estimator=stacker).fit(X, y)\n\n    # Does not raise\n    reg.predict(X)\n", "type": "function"}, {"name": "test_cross_val_predict_method_checking", "is_method": false, "class_name": null, "parameters": [], "calls": ["load_iris", "shuffle", "SGDClassifier", "check_cross_val_predict_multiclass"], "code_location": {"file": "test_validation.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/model_selection/tests", "start_line": 1880, "end_line": 1888}, "code_snippet": "def test_cross_val_predict_method_checking():\n    # Regression test for issue #9639. Tests that cross_val_predict does not\n    # check estimator methods (e.g. predict_proba) before fitting\n    iris = load_iris()\n    X, y = iris.data, iris.target\n    X, y = shuffle(X, y, random_state=0)\n    for method in [\"decision_function\", \"predict_proba\", \"predict_log_proba\"]:\n        est = SGDClassifier(loss=\"log_loss\", random_state=2)\n        check_cross_val_predict_multiclass(est, X, y, method)\n", "type": "function"}, {"name": "_MultiOutputEstimator", "docstring": "", "methods": ["__init__", "partial_fit", "fit", "predict", "__sklearn_tags__", "get_metadata_routing"], "attributes": [], "code_location": {"file": "multioutput.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn", "start_line": 99, "end_line": 339}, "type": "class"}, {"name": "test_multi_output_classification_partial_fit_parallelism", "is_method": false, "class_name": null, "parameters": [], "calls": ["SGDClassifier", "MultiOutputClassifier", "mor.partial_fit", "mor.partial_fit", "cpu_count"], "code_location": {"file": "test_multioutput.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/tests", "start_line": 199, "end_line": 208}, "code_snippet": "def test_multi_output_classification_partial_fit_parallelism():\n    sgd_linear_clf = SGDClassifier(loss=\"log_loss\", random_state=1, max_iter=5)\n    mor = MultiOutputClassifier(sgd_linear_clf, n_jobs=4)\n    mor.partial_fit(X, y, classes)\n    est1 = mor.estimators_[0]\n    mor.partial_fit(X, y)\n    est2 = mor.estimators_[0]\n    if cpu_count() > 1:\n        # parallelism requires this to be the case for a sane implementation\n        assert est1 is not est2\n", "type": "function"}, {"name": "test_iforest_subsampled_features", "is_method": false, "class_name": null, "parameters": [], "calls": ["check_random_state", "train_test_split", "IsolationForest", "clf.fit", "clf.predict"], "code_location": {"file": "test_iforest.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/ensemble/tests", "start_line": 187, "end_line": 195}, "code_snippet": "def test_iforest_subsampled_features():\n    # It tests non-regression for #5732 which failed at predict.\n    rng = check_random_state(0)\n    X_train, X_test, y_train, y_test = train_test_split(\n        diabetes.data[:50], diabetes.target[:50], random_state=rng\n    )\n    clf = IsolationForest(max_features=0.8)\n    clf.fit(X_train, y_train)\n    clf.predict(X_test)\n", "type": "function"}, {"name": "test_partial_dependence_helpers", "is_method": false, "class_name": null, "parameters": ["est", "method", "target_feature"], "calls": ["pytest.mark.parametrize", "pytest.mark.parametrize", "make_regression", "fit", "np.array", "np.array", "np.allclose", "range", "y.mean", "_partial_dependence_brute", "_partial_dependence_recursion", "X.copy", "mean_predictions.append", "clone", "mean", "LinearRegression", "GradientBoostingRegressor", "GradientBoostingRegressor", "HistGradientBoostingRegressor", "HistGradientBoostingRegressor", "est.predict"], "code_location": {"file": "test_partial_dependence.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/inspection/tests", "start_line": 330, "end_line": 373}, "code_snippet": "def test_partial_dependence_helpers(est, method, target_feature):\n    # Check that what is returned by _partial_dependence_brute or\n    # _partial_dependence_recursion is equivalent to manually setting a target\n    # feature to a given value, and computing the average prediction over all\n    # samples.\n    # This also checks that the brute and recursion methods give the same\n    # output.\n    # Note that even on the trainset, the brute and the recursion methods\n    # aren't always strictly equivalent, in particular when the slow method\n    # generates unrealistic samples that have low mass in the joint\n    # distribution of the input features, and when some of the features are\n    # dependent. Hence the high tolerance on the checks.\n\n    X, y = make_regression(random_state=0, n_features=5, n_informative=5)\n    # The 'init' estimator for GBDT (here the average prediction) isn't taken\n    # into account with the recursion method, for technical reasons. We set\n    # the mean to 0 to that this 'bug' doesn't have any effect.\n    y = y - y.mean()\n\n    # Clone is necessary to make the test thread-safe.\n    est = clone(est).fit(X, y)\n\n    # target feature will be set to .5 and then to 123\n    features = np.array([target_feature], dtype=np.intp)\n    grid = np.array([[0.5], [123]])\n\n    if method == \"brute\":\n        pdp, predictions = _partial_dependence_brute(\n            est, grid, features, X, response_method=\"auto\"\n        )\n    else:\n        pdp = _partial_dependence_recursion(est, grid, features)\n\n    mean_predictions = []\n    for val in (0.5, 123):\n        X_ = X.copy()\n        X_[:, target_feature] = val\n        mean_predictions.append(est.predict(X_).mean())\n\n    pdp = pdp[0]  # (shape is (1, 2) so make it (2,))\n\n    # allow for greater margin for error with recursion method\n    rtol = 1e-1 if method == \"recursion\" else 1e-3\n    assert np.allclose(pdp, mean_predictions, rtol=rtol)\n", "type": "function"}, {"name": "_get_estimator", "is_method": true, "class_name": "MultiTaskElasticNetCV", "parameters": ["self"], "calls": ["MultiTaskElasticNet"], "code_location": {"file": "_coordinate_descent.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/linear_model", "start_line": 3111, "end_line": 3112}, "code_snippet": "    def _get_estimator(self):\n        return MultiTaskElasticNet()\n", "type": "function"}, {"name": "Predictor", "docstring": "Abstract base class for benchmarks of estimators implementing predict", "methods": ["params"], "attributes": [], "code_location": {"file": "common.py", "path": "/data3/pwh/swebench-repos/scikit-learn/asv_benchmarks/benchmarks", "start_line": 201, "end_line": 227}, "type": "class"}], "retrieved_count": 10, "cost_time": 1.0799903869628906}
{"question": "What are the consequences of dtype incompatibility at each transformation stage in the dataflow dependency chain from fetch_20newsgroups through TfidfVectorizer to train_test_split, and how does this chain constrain dtype parameter propagation?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"name": "test_tfidf_vectorizer_type", "is_method": false, "class_name": null, "parameters": ["vectorizer_dtype", "output_dtype", "warning_expected"], "calls": ["pytest.mark.parametrize", "np.array", "TfidfVectorizer", "pytest.warns", "vectorizer.fit_transform", "warnings.catch_warnings", "warnings.simplefilter", "vectorizer.fit_transform"], "code_location": {"file": "test_text.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/feature_extraction/tests", "start_line": 1269, "end_line": 1281}, "code_snippet": "def test_tfidf_vectorizer_type(vectorizer_dtype, output_dtype, warning_expected):\n    X = np.array([\"numpy\", \"scipy\", \"sklearn\"])\n    vectorizer = TfidfVectorizer(dtype=vectorizer_dtype)\n\n    warning_msg_match = \"'dtype' should be used.\"\n    if warning_expected:\n        with pytest.warns(UserWarning, match=warning_msg_match):\n            X_idf = vectorizer.fit_transform(X)\n    else:\n        with warnings.catch_warnings():\n            warnings.simplefilter(\"error\", UserWarning)\n            X_idf = vectorizer.fit_transform(X)\n    assert X_idf.dtype == output_dtype\n", "type": "function"}, {"name": "test_tfidf_transformer_type", "is_method": false, "class_name": null, "parameters": ["X_dtype"], "calls": ["pytest.mark.parametrize", "sparse.rand", "fit_transform", "TfidfTransformer"], "code_location": {"file": "test_text.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/feature_extraction/tests", "start_line": 1240, "end_line": 1243}, "code_snippet": "def test_tfidf_transformer_type(X_dtype):\n    X = sparse.rand(10, 20000, dtype=X_dtype, random_state=42)\n    X_trans = TfidfTransformer().fit_transform(X)\n    assert X_trans.dtype == X.dtype\n", "type": "function"}, {"name": "test_transformer_dtypes_casting", "is_method": false, "class_name": null, "parameters": ["dtype_in", "dtype_out"], "calls": ["pytest.mark.parametrize", "astype", "BernoulliRBM", "rbm.fit_transform", "format"], "code_location": {"file": "test_rbm.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/neural_network/tests", "start_line": 208, "end_line": 216}, "code_snippet": "def test_transformer_dtypes_casting(dtype_in, dtype_out):\n    X = Xdigits[:100].astype(dtype_in)\n    rbm = BernoulliRBM(n_components=16, batch_size=5, n_iter=5, random_state=42)\n    Xt = rbm.fit_transform(X)\n\n    # dtype_in and dtype_out should be consistent\n    assert Xt.dtype == dtype_out, \"transform dtype: {} - original dtype: {}\".format(\n        Xt.dtype, X.dtype\n    )\n", "type": "function"}, {"name": "test_pipeline_with_nearest_neighbors_transformer", "is_method": false, "class_name": null, "parameters": ["global_dtype"], "calls": ["datasets.make_blobs", "datasets.make_blobs", "X.astype", "X2.astype", "pipeline.make_pipeline", "manifold.Isomap", "est_chain.fit_transform", "est_compact.fit_transform", "assert_allclose", "est_chain.transform", "est_compact.transform", "assert_allclose", "neighbors.KNeighborsTransformer", "manifold.Isomap"], "code_location": {"file": "test_isomap.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/manifold/tests", "start_line": 161, "end_line": 190}, "code_snippet": "def test_pipeline_with_nearest_neighbors_transformer(global_dtype):\n    # Test chaining NearestNeighborsTransformer and Isomap with\n    # neighbors_algorithm='precomputed'\n    algorithm = \"auto\"\n    n_neighbors = 10\n\n    X, _ = datasets.make_blobs(random_state=0)\n    X2, _ = datasets.make_blobs(random_state=1)\n\n    X = X.astype(global_dtype, copy=False)\n    X2 = X2.astype(global_dtype, copy=False)\n\n    # compare the chained version and the compact version\n    est_chain = pipeline.make_pipeline(\n        neighbors.KNeighborsTransformer(\n            n_neighbors=n_neighbors, algorithm=algorithm, mode=\"distance\"\n        ),\n        manifold.Isomap(n_neighbors=n_neighbors, metric=\"precomputed\"),\n    )\n    est_compact = manifold.Isomap(\n        n_neighbors=n_neighbors, neighbors_algorithm=algorithm\n    )\n\n    Xt_chain = est_chain.fit_transform(X)\n    Xt_compact = est_compact.fit_transform(X)\n    assert_allclose(Xt_chain, Xt_compact)\n\n    Xt_chain = est_chain.transform(X2)\n    Xt_compact = est_compact.transform(X2)\n    assert_allclose(Xt_chain, Xt_compact)\n", "type": "function"}, {"name": "test_20news_vectorized", "is_method": false, "class_name": null, "parameters": ["fetch_20newsgroups_vectorized_fxt"], "calls": ["fetch_20newsgroups_vectorized_fxt", "bunch.DESCR.startswith", "fetch_20newsgroups_vectorized_fxt", "bunch.DESCR.startswith", "partial", "check_return_X_y", "fetch_20newsgroups_vectorized_fxt", "bunch.DESCR.startswith", "sp.issparse", "sp.issparse", "sp.issparse"], "code_location": {"file": "test_20news.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/datasets/tests", "start_line": 65, "end_line": 92}, "code_snippet": "def test_20news_vectorized(fetch_20newsgroups_vectorized_fxt):\n    # test subset = train\n    bunch = fetch_20newsgroups_vectorized_fxt(subset=\"train\")\n    assert sp.issparse(bunch.data) and bunch.data.format == \"csr\"\n    assert bunch.data.shape == (11314, 130107)\n    assert bunch.target.shape[0] == 11314\n    assert bunch.data.dtype == np.float64\n    assert bunch.DESCR.startswith(\".. _20newsgroups_dataset:\")\n\n    # test subset = test\n    bunch = fetch_20newsgroups_vectorized_fxt(subset=\"test\")\n    assert sp.issparse(bunch.data) and bunch.data.format == \"csr\"\n    assert bunch.data.shape == (7532, 130107)\n    assert bunch.target.shape[0] == 7532\n    assert bunch.data.dtype == np.float64\n    assert bunch.DESCR.startswith(\".. _20newsgroups_dataset:\")\n\n    # test return_X_y option\n    fetch_func = partial(fetch_20newsgroups_vectorized_fxt, subset=\"test\")\n    check_return_X_y(bunch, fetch_func)\n\n    # test subset = all\n    bunch = fetch_20newsgroups_vectorized_fxt(subset=\"all\")\n    assert sp.issparse(bunch.data) and bunch.data.format == \"csr\"\n    assert bunch.data.shape == (11314 + 7532, 130107)\n    assert bunch.target.shape[0] == 11314 + 7532\n    assert bunch.data.dtype == np.float64\n    assert bunch.DESCR.startswith(\".. _20newsgroups_dataset:\")\n", "type": "function"}, {"name": "check_transformer_preserve_dtypes", "is_method": false, "class_name": null, "parameters": ["name", "transformer_orig"], "calls": ["clone", "hasattr", "make_blobs", "fit_transform", "_enforce_estimator_tags_X", "transformer.set_output", "X.astype", "set_random_state", "transformer.fit_transform", "transform", "zip", "StandardScaler", "get_tags", "isinstance", "transformer.fit"], "code_location": {"file": "estimator_checks.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/utils", "start_line": 2266, "end_line": 2297}, "code_snippet": "def check_transformer_preserve_dtypes(name, transformer_orig):\n    # check that dtype are preserved meaning if input X is of some dtype\n    # X_transformed should be from the same dtype.\n    transformer = clone(transformer_orig)\n    if hasattr(transformer, \"set_output\"):\n        transformer.set_output(transform=\"default\")\n    X, y = make_blobs(\n        n_samples=30,\n        centers=[[0, 0, 0], [1, 1, 1]],\n        random_state=0,\n        cluster_std=0.1,\n    )\n    X = StandardScaler().fit_transform(X)\n    X = _enforce_estimator_tags_X(transformer_orig, X)\n\n    for dtype in get_tags(transformer_orig).transformer_tags.preserves_dtype:\n        X_cast = X.astype(dtype)\n        set_random_state(transformer)\n        X_trans1 = transformer.fit_transform(X_cast, y)\n        X_trans2 = transformer.fit(X_cast, y).transform(X_cast)\n\n        for Xt, method in zip([X_trans1, X_trans2], [\"fit_transform\", \"transform\"]):\n            if isinstance(Xt, tuple):\n                # cross-decompostion returns a tuple of (x_scores, y_scores)\n                # when given y with fit_transform; only check the first element\n                Xt = Xt[0]\n\n            # check that the output dtype is preserved\n            assert Xt.dtype == dtype, (\n                f\"{name} (method={method}) does not preserve dtype. \"\n                f\"Original/Expected dtype={dtype}, got dtype={Xt.dtype}.\"\n            )\n", "type": "function"}, {"name": "test_minibatch_dictionary_learning_dtype_match", "is_method": false, "class_name": null, "parameters": ["data_type", "expected_type", "fit_algorithm", "transform_algorithm"], "calls": ["pytest.mark.parametrize", "pytest.mark.parametrize", "pytest.mark.parametrize", "MiniBatchDictionaryLearning", "dict_learner.fit", "X.astype", "dict_learner.transform", "X.astype"], "code_location": {"file": "test_dict_learning.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/decomposition/tests", "start_line": 791, "end_line": 812}, "code_snippet": "def test_minibatch_dictionary_learning_dtype_match(\n    data_type,\n    expected_type,\n    fit_algorithm,\n    transform_algorithm,\n):\n    # Verify preserving dtype for fit and transform in minibatch dictionary learning\n    dict_learner = MiniBatchDictionaryLearning(\n        n_components=8,\n        batch_size=10,\n        fit_algorithm=fit_algorithm,\n        transform_algorithm=transform_algorithm,\n        max_iter=100,\n        tol=1e-1,\n        random_state=0,\n    )\n    dict_learner.fit(X.astype(data_type))\n\n    assert dict_learner.components_.dtype == expected_type\n    assert dict_learner.transform(X.astype(data_type)).dtype == expected_type\n    assert dict_learner._A.dtype == expected_type\n    assert dict_learner._B.dtype == expected_type\n", "type": "function"}, {"name": "test_dtype_preprocess_data", "is_method": false, "class_name": null, "parameters": ["rescale_with_sw", "fit_intercept", "global_random_seed"], "calls": ["pytest.mark.parametrize", "pytest.mark.parametrize", "np.random.RandomState", "rng.rand", "rng.rand", "np.asarray", "np.asarray", "np.asarray", "np.asarray", "np.asarray", "np.asarray", "_preprocess_data", "_preprocess_data", "_preprocess_data", "_preprocess_data", "assert_allclose", "assert_allclose", "assert_allclose", "assert_allclose", "assert_allclose", "np.abs", "assert_allclose", "rng.rand"], "code_location": {"file": "test_base.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/linear_model/tests", "start_line": 564, "end_line": 658}, "code_snippet": "def test_dtype_preprocess_data(rescale_with_sw, fit_intercept, global_random_seed):\n    rng = np.random.RandomState(global_random_seed)\n    n_samples = 200\n    n_features = 2\n    X = rng.rand(n_samples, n_features)\n    y = rng.rand(n_samples)\n    sw = np.abs(rng.rand(n_samples)) + 1\n\n    X_32 = np.asarray(X, dtype=np.float32)\n    y_32 = np.asarray(y, dtype=np.float32)\n    sw_32 = np.asarray(sw, dtype=np.float32)\n    X_64 = np.asarray(X, dtype=np.float64)\n    y_64 = np.asarray(y, dtype=np.float64)\n    sw_64 = np.asarray(sw, dtype=np.float64)\n\n    Xt_32, yt_32, X_mean_32, y_mean_32, X_scale_32, sqrt_sw_32 = _preprocess_data(\n        X_32,\n        y_32,\n        fit_intercept=fit_intercept,\n        sample_weight=sw_32,\n        rescale_with_sw=rescale_with_sw,\n    )\n\n    Xt_64, yt_64, X_mean_64, y_mean_64, X_scale_64, sqrt_sw_64 = _preprocess_data(\n        X_64,\n        y_64,\n        fit_intercept=fit_intercept,\n        sample_weight=sw_64,\n        rescale_with_sw=rescale_with_sw,\n    )\n\n    Xt_3264, yt_3264, X_mean_3264, y_mean_3264, X_scale_3264, sqrt_sw_3264 = (\n        _preprocess_data(\n            X_32,\n            y_64,\n            fit_intercept=fit_intercept,\n            sample_weight=sw_32,  # sample_weight must have same dtype as X\n            rescale_with_sw=rescale_with_sw,\n        )\n    )\n\n    Xt_6432, yt_6432, X_mean_6432, y_mean_6432, X_scale_6432, sqrt_sw_6432 = (\n        _preprocess_data(\n            X_64,\n            y_32,\n            fit_intercept=fit_intercept,\n            sample_weight=sw_64,  # sample_weight must have same dtype as X\n            rescale_with_sw=rescale_with_sw,\n        )\n    )\n\n    assert Xt_32.dtype == np.float32\n    assert yt_32.dtype == np.float32\n    assert X_mean_32.dtype == np.float32\n    assert y_mean_32.dtype == np.float32\n    assert X_scale_32.dtype == np.float32\n    if rescale_with_sw:\n        assert sqrt_sw_32.dtype == np.float32\n\n    assert Xt_64.dtype == np.float64\n    assert yt_64.dtype == np.float64\n    assert X_mean_64.dtype == np.float64\n    assert y_mean_64.dtype == np.float64\n    assert X_scale_64.dtype == np.float64\n    if rescale_with_sw:\n        assert sqrt_sw_64.dtype == np.float64\n\n    assert Xt_3264.dtype == np.float32\n    assert yt_3264.dtype == np.float32\n    assert X_mean_3264.dtype == np.float32\n    assert y_mean_3264.dtype == np.float32\n    assert X_scale_3264.dtype == np.float32\n    if rescale_with_sw:\n        assert sqrt_sw_3264.dtype == np.float32\n\n    assert Xt_6432.dtype == np.float64\n    assert yt_6432.dtype == np.float64\n    assert X_mean_6432.dtype == np.float64\n    assert y_mean_6432.dtype == np.float64\n    assert X_scale_3264.dtype == np.float32\n    if rescale_with_sw:\n        assert sqrt_sw_6432.dtype == np.float64\n\n    assert X_32.dtype == np.float32\n    assert y_32.dtype == np.float32\n    assert X_64.dtype == np.float64\n    assert y_64.dtype == np.float64\n\n    assert_allclose(Xt_32, Xt_64, rtol=1e-3, atol=1e-7)\n    assert_allclose(yt_32, yt_64, rtol=1e-3, atol=1e-7)\n    assert_allclose(X_mean_32, X_mean_64, rtol=1e-6)\n    assert_allclose(y_mean_32, y_mean_64, rtol=1e-6)\n    assert_allclose(X_scale_32, X_scale_64)\n    if rescale_with_sw:\n        assert_allclose(sqrt_sw_32, sqrt_sw_64, rtol=1e-6)\n", "type": "function"}, {"name": "test_tfidf_vectorizer_perserve_dtype_idf", "is_method": false, "class_name": null, "parameters": ["dtype"], "calls": ["pytest.mark.parametrize", "fit", "str", "uuid.uuid4", "range", "TfidfVectorizer"], "code_location": {"file": "test_text.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/feature_extraction/tests", "start_line": 1620, "end_line": 1628}, "code_snippet": "def test_tfidf_vectorizer_perserve_dtype_idf(dtype):\n    \"\"\"Check that `idf_` has the same dtype as the input data.\n\n    Non-regression test for:\n    https://github.com/scikit-learn/scikit-learn/issues/30016\n    \"\"\"\n    X = [str(uuid.uuid4()) for i in range(100_000)]\n    vectorizer = TfidfVectorizer(dtype=dtype).fit(X)\n    assert vectorizer.idf_.dtype == dtype\n", "type": "function"}, {"name": "test_consistent_dtype", "is_method": false, "class_name": null, "parameters": ["in_dtype", "out_dtype", "encode"], "calls": ["pytest.mark.parametrize", "pytest.mark.parametrize", "pytest.mark.parametrize", "np.array", "KBinsDiscretizer", "kbd.fit", "kbd.transform"], "code_location": {"file": "test_discretization.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/preprocessing/tests", "start_line": 494, "end_line": 513}, "code_snippet": "def test_consistent_dtype(in_dtype, out_dtype, encode):\n    X_input = np.array(X, dtype=in_dtype)\n    kbd = KBinsDiscretizer(\n        n_bins=3,\n        encode=encode,\n        quantile_method=\"averaged_inverted_cdf\",\n        dtype=out_dtype,\n    )\n    kbd.fit(X_input)\n\n    # test output dtype\n    if out_dtype is not None:\n        expected_dtype = out_dtype\n    elif out_dtype is None and X_input.dtype == np.float16:\n        # wrong numeric input dtype are cast in np.float64\n        expected_dtype = np.float64\n    else:\n        expected_dtype = X_input.dtype\n    Xt = kbd.transform(X_input)\n    assert Xt.dtype == expected_dtype\n", "type": "function"}], "retrieved_count": 10, "cost_time": 1.084315299987793}
{"question": "What is the semantic mismatch created by the conditional logic in the fit method's type checking mechanism between the declared accept_large_sparse=True parameter and the actual runtime behavior when processing sparse data with 64-bit indices?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"name": "test_check_array_accept_large_sparse_raise_exception", "is_method": false, "class_name": null, "parameters": ["X_64bit"], "calls": ["pytest.raises", "check_array"], "code_location": {"file": "test_validation.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/utils/tests", "start_line": 732, "end_line": 739}, "code_snippet": "def test_check_array_accept_large_sparse_raise_exception(X_64bit):\n    # When large sparse are not allowed\n    msg = (\n        \"Only sparse matrices with 32-bit integer indices \"\n        \"are accepted. Got int64 indices. Please do report\"\n    )\n    with pytest.raises(ValueError, match=msg):\n        check_array(X_64bit, accept_sparse=True, accept_large_sparse=False)\n", "type": "function"}, {"name": "fit", "is_method": true, "class_name": "LargeSparseNotSupportedClassifier", "parameters": ["self", "X", "y"], "calls": ["validate_data", "isinstance", "isinstance", "ValueError"], "code_location": {"file": "test_estimator_checks.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/utils/tests", "start_line": 412, "end_line": 436}, "code_snippet": "    def fit(self, X, y):\n        X, y = validate_data(\n            self,\n            X,\n            y,\n            accept_sparse=(\"csr\", \"csc\", \"coo\"),\n            accept_large_sparse=True,\n            multi_output=True,\n            y_numeric=True,\n        )\n        if self.raise_for_type == \"sparse_array\":\n            correct_type = isinstance(X, sp.sparray)\n        elif self.raise_for_type == \"sparse_matrix\":\n            correct_type = isinstance(X, sp.spmatrix)\n        if correct_type:\n            if X.format == \"coo\":\n                if X.row.dtype == \"int64\" or X.col.dtype == \"int64\":\n                    raise ValueError(\"Estimator doesn't support 64-bit indices\")\n            elif X.format in [\"csc\", \"csr\"]:\n                assert \"int64\" not in (\n                    X.indices.dtype,\n                    X.indptr.dtype,\n                ), \"Estimator doesn't support 64-bit indices\"\n\n        return self\n", "type": "function"}, {"name": "test_check_array_accept_large_sparse_no_exception", "is_method": false, "class_name": null, "parameters": ["X_64bit"], "calls": ["check_array"], "code_location": {"file": "test_validation.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/utils/tests", "start_line": 727, "end_line": 729}, "code_snippet": "def test_check_array_accept_large_sparse_no_exception(X_64bit):\n    # When large sparse are allowed\n    check_array(X_64bit, accept_large_sparse=True, accept_sparse=True)\n", "type": "function"}, {"name": "_check_large_sparse", "is_method": false, "class_name": null, "parameters": ["X", "accept_large_sparse"], "calls": ["getattr", "ValueError"], "code_location": {"file": "validation.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/utils", "start_line": 1194, "end_line": 1213}, "code_snippet": "def _check_large_sparse(X, accept_large_sparse=False):\n    \"\"\"Raise a ValueError if X has 64bit indices and accept_large_sparse=False\"\"\"\n    if not accept_large_sparse:\n        supported_indices = [\"int32\"]\n        if X.format == \"coo\":\n            index_keys = [\"col\", \"row\"]\n        elif X.format in [\"csr\", \"csc\", \"bsr\"]:\n            index_keys = [\"indices\", \"indptr\"]\n        else:\n            return\n        for key in index_keys:\n            indices_datatype = getattr(X, key).dtype\n            if indices_datatype not in supported_indices:\n                raise ValueError(\n                    \"Only sparse matrices with 32-bit integer indices are accepted.\"\n                    f\" Got {indices_datatype} indices. Please do report a minimal\"\n                    \" reproducer on scikit-learn issue tracker so that support for\"\n                    \" your use-case can be studied by maintainers. See:\"\n                    \" https://scikit-learn.org/dev/developers/minimal_reproducer.html\"\n                )\n", "type": "function"}, {"name": "fit", "is_method": true, "class_name": "NoSparseClassifier", "parameters": ["self", "X", "y"], "calls": ["validate_data", "isinstance", "ValueError", "isinstance"], "code_location": {"file": "test_estimator_checks.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/utils/tests", "start_line": 250, "end_line": 258}, "code_snippet": "    def fit(self, X, y):\n        X, y = validate_data(self, X, y, accept_sparse=[\"csr\", \"csc\"])\n        if self.raise_for_type == \"sparse_array\":\n            correct_type = isinstance(X, sp.sparray)\n        elif self.raise_for_type == \"sparse_matrix\":\n            correct_type = isinstance(X, sp.spmatrix)\n        if correct_type:\n            raise ValueError(\"Nonsensical Error\")\n        return self\n", "type": "function"}, {"name": "test_check_array_accept_sparse_type_exception", "is_method": false, "class_name": null, "parameters": [], "calls": ["sp.csr_matrix", "SVR", "pytest.raises", "check_array", "pytest.raises", "check_array", "pytest.raises", "check_array", "pytest.raises", "check_array", "pytest.raises", "check_array"], "code_location": {"file": "test_validation.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/utils/tests", "start_line": 663, "end_line": 691}, "code_snippet": "def test_check_array_accept_sparse_type_exception():\n    X = [[1, 2], [3, 4]]\n    X_csr = sp.csr_matrix(X)\n    invalid_type = SVR()\n\n    msg = (\n        \"Sparse data was passed, but dense data is required. \"\n        r\"Use '.toarray\\(\\)' to convert to a dense numpy array.\"\n    )\n    with pytest.raises(TypeError, match=msg):\n        check_array(X_csr, accept_sparse=False)\n\n    msg = (\n        \"Parameter 'accept_sparse' should be a string, \"\n        \"boolean or list of strings. You provided 'accept_sparse=.*'.\"\n    )\n    with pytest.raises(ValueError, match=msg):\n        check_array(X_csr, accept_sparse=invalid_type)\n\n    msg = (\n        \"When providing 'accept_sparse' as a tuple or list, \"\n        \"it must contain at least one string value.\"\n    )\n    with pytest.raises(ValueError, match=msg):\n        check_array(X_csr, accept_sparse=[])\n    with pytest.raises(ValueError, match=msg):\n        check_array(X_csr, accept_sparse=())\n    with pytest.raises(TypeError, match=\"SVR\"):\n        check_array(X_csr, accept_sparse=[invalid_type])\n", "type": "function"}, {"name": "test_sparse_input_types", "is_method": false, "class_name": null, "parameters": ["accepted_sparse_type", "index_dtype", "dtype", "Estimator", "parameters"], "calls": ["pytest.mark.parametrize", "pytest.mark.parametrize", "pytest.mark.parametrize", "pytest.mark.parametrize", "_convert_container", "X.data.astype", "X.indices.astype", "X.indptr.astype", "fit", "assert_array_equal", "clf.predict", "np.array", "Estimator"], "code_location": {"file": "test_label_propagation.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/semi_supervised/tests", "start_line": 133, "end_line": 143}, "code_snippet": "def test_sparse_input_types(\n    accepted_sparse_type, index_dtype, dtype, Estimator, parameters\n):\n    # This is non-regression test for #17085\n    X = _convert_container([[1.0, 0.0], [0.0, 2.0], [1.0, 3.0]], accepted_sparse_type)\n    X.data = X.data.astype(dtype, copy=False)\n    X.indices = X.indices.astype(index_dtype, copy=False)\n    X.indptr = X.indptr.astype(index_dtype, copy=False)\n    labels = [0, 1, -1]\n    clf = Estimator(**parameters).fit(X, labels)\n    assert_array_equal(clf.predict([[0.5, 2.5]]), np.array([1]))\n", "type": "function"}, {"name": "test_large_sparse_matrix", "is_method": false, "class_name": null, "parameters": ["solver", "global_random_seed", "csr_container"], "calls": ["pytest.mark.parametrize", "pytest.mark.parametrize", "csr_container", "np.random.RandomState", "rng.randint", "sparse.rand", "setattr", "fit", "astype", "pytest.raises", "fit", "LogisticRegression", "getattr", "LogisticRegression"], "code_location": {"file": "test_logistic.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/linear_model/tests", "start_line": 2264, "end_line": 2280}, "code_snippet": "def test_large_sparse_matrix(solver, global_random_seed, csr_container):\n    # Solvers either accept large sparse matrices, or raise helpful error.\n    # Non-regression test for pull-request #21093.\n\n    # generate sparse matrix with int64 indices\n    X = csr_container(sparse.rand(20, 10, random_state=global_random_seed))\n    for attr in [\"indices\", \"indptr\"]:\n        setattr(X, attr, getattr(X, attr).astype(\"int64\"))\n    rng = np.random.RandomState(global_random_seed)\n    y = rng.randint(2, size=X.shape[0])\n\n    if solver in [\"liblinear\", \"sag\", \"saga\"]:\n        msg = \"Only sparse matrices with 32-bit integer indices\"\n        with pytest.raises(ValueError, match=msg):\n            LogisticRegression(solver=solver).fit(X, y)\n    else:\n        LogisticRegression(solver=solver).fit(X, y)\n", "type": "function"}, {"name": "_check_estimator_sparse_container", "is_method": false, "class_name": null, "parameters": ["name", "estimator_orig", "sparse_type"], "calls": ["np.random.RandomState", "rng.uniform", "_enforce_estimator_tags_X", "astype", "_enforce_estimator_tags_y", "get_tags", "_generate_sparse_data", "ignore_warnings", "clone", "sparse_type", "ignore_warnings", "clone", "raises", "hasattr", "hasattr", "rng.uniform", "estimator.set_params", "ignore_warnings", "estimator.fit", "estimator.predict", "estimator.predict_proba"], "code_location": {"file": "estimator_checks.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/utils", "start_line": 1294, "end_line": 1345}, "code_snippet": "def _check_estimator_sparse_container(name, estimator_orig, sparse_type):\n    rng = np.random.RandomState(0)\n    X = rng.uniform(size=(40, 3))\n    X[X < 0.6] = 0\n    X = _enforce_estimator_tags_X(estimator_orig, X)\n    y = (4 * rng.uniform(size=X.shape[0])).astype(np.int32)\n    # catch deprecation warnings\n    with ignore_warnings(category=FutureWarning):\n        estimator = clone(estimator_orig)\n    y = _enforce_estimator_tags_y(estimator, y)\n    tags = get_tags(estimator_orig)\n    for matrix_format, X in _generate_sparse_data(sparse_type(X)):\n        # catch deprecation warnings\n        with ignore_warnings(category=FutureWarning):\n            estimator = clone(estimator_orig)\n            if name in [\"Scaler\", \"StandardScaler\"]:\n                estimator.set_params(with_mean=False)\n        # fit and predict\n        if \"64\" in matrix_format:\n            err_msg = (\n                f\"Estimator {name} doesn't seem to support {matrix_format} \"\n                \"matrix, and is not failing gracefully, e.g. by using \"\n                \"check_array(X, accept_large_sparse=False).\"\n            )\n        else:\n            err_msg = (\n                f\"Estimator {name} doesn't seem to fail gracefully on sparse \"\n                \"data: error message should state explicitly that sparse \"\n                \"input is not supported if this is not the case, e.g. by using \"\n                \"check_array(X, accept_sparse=False).\"\n            )\n        with raises(\n            (TypeError, ValueError),\n            match=[\"sparse\", \"Sparse\"],\n            may_pass=True,\n            err_msg=err_msg,\n        ):\n            with ignore_warnings(category=FutureWarning):\n                estimator.fit(X, y)\n            if hasattr(estimator, \"predict\"):\n                pred = estimator.predict(X)\n                if tags.target_tags.multi_output and not tags.target_tags.single_output:\n                    assert pred.shape == (X.shape[0], 1)\n                else:\n                    assert pred.shape == (X.shape[0],)\n            if hasattr(estimator, \"predict_proba\"):\n                probs = estimator.predict_proba(X)\n                if not tags.classifier_tags.multi_class:\n                    expected_probs_shape = (X.shape[0], 2)\n                else:\n                    expected_probs_shape = (X.shape[0], 4)\n                assert probs.shape == expected_probs_shape\n", "type": "function"}, {"name": "_sparse_fit", "is_method": true, "class_name": "BaseLibSVM", "parameters": ["self", "X", "y", "sample_weight", "solver_type", "kernel", "random_seed"], "calls": ["np.asarray", "X.sort_indices", "self._sparse_kernels.index", "libsvm_sparse.set_verbosity_wrap", "libsvm_sparse.libsvm_sparse_train", "self._warn_from_fit_status", "hasattr", "np.tile", "getattr", "int", "int", "np.arange", "sp.csr_matrix", "np.arange", "sp.csr_matrix", "np.empty", "len"], "code_location": {"file": "_base.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/svm", "start_line": 367, "end_line": 426}, "code_snippet": "    def _sparse_fit(self, X, y, sample_weight, solver_type, kernel, random_seed):\n        X.data = np.asarray(X.data, dtype=np.float64, order=\"C\")\n        X.sort_indices()\n\n        kernel_type = self._sparse_kernels.index(kernel)\n\n        libsvm_sparse.set_verbosity_wrap(self.verbose)\n\n        (\n            self.support_,\n            self.support_vectors_,\n            dual_coef_data,\n            self.intercept_,\n            self._n_support,\n            self._probA,\n            self._probB,\n            self.fit_status_,\n            self._num_iter,\n        ) = libsvm_sparse.libsvm_sparse_train(\n            X.shape[1],\n            X.data,\n            X.indices,\n            X.indptr,\n            y,\n            solver_type,\n            kernel_type,\n            self.degree,\n            self._gamma,\n            self.coef0,\n            self.tol,\n            self.C,\n            getattr(self, \"class_weight_\", np.empty(0)),\n            sample_weight,\n            self.nu,\n            self.cache_size,\n            self.epsilon,\n            int(self.shrinking),\n            int(self.probability),\n            self.max_iter,\n            random_seed,\n        )\n\n        self._warn_from_fit_status()\n\n        if hasattr(self, \"classes_\"):\n            n_class = len(self.classes_) - 1\n        else:  # regression\n            n_class = 1\n        n_SV = self.support_vectors_.shape[0]\n\n        dual_coef_indices = np.tile(np.arange(n_SV), n_class)\n        if not n_SV:\n            self.dual_coef_ = sp.csr_matrix([])\n        else:\n            dual_coef_indptr = np.arange(\n                0, dual_coef_indices.size + 1, dual_coef_indices.size / n_class\n            )\n            self.dual_coef_ = sp.csr_matrix(\n                (dual_coef_data, dual_coef_indices, dual_coef_indptr), (n_class, n_SV)\n            )\n", "type": "function"}], "retrieved_count": 10, "cost_time": 1.077270746231079}
{"question": "What is the mechanism in the test_mean_shift function that ensures dtype consistency across both the MeanShift class instance and the standalone mean_shift function when processing the same input data with different global_dtype parameters?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"name": "test_mean_shift", "is_method": false, "class_name": null, "parameters": ["global_dtype", "bandwidth", "cluster_all", "expected", "first_cluster_label"], "calls": ["pytest.mark.parametrize", "X.astype", "MeanShift", "np.unique", "len", "mean_shift", "np.unique", "len", "ms.fit"], "code_location": {"file": "test_mean_shift.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/cluster/tests", "start_line": 58, "end_line": 78}, "code_snippet": "def test_mean_shift(\n    global_dtype, bandwidth, cluster_all, expected, first_cluster_label\n):\n    # Test MeanShift algorithm\n    X_with_global_dtype = X.astype(global_dtype, copy=False)\n    ms = MeanShift(bandwidth=bandwidth, cluster_all=cluster_all)\n    labels = ms.fit(X_with_global_dtype).labels_\n    labels_unique = np.unique(labels)\n    n_clusters_ = len(labels_unique)\n    assert n_clusters_ == expected\n    assert labels_unique[0] == first_cluster_label\n    assert ms.cluster_centers_.dtype == global_dtype\n\n    cluster_centers, labels_mean_shift = mean_shift(\n        X_with_global_dtype, cluster_all=cluster_all\n    )\n    labels_mean_shift_unique = np.unique(labels_mean_shift)\n    n_clusters_mean_shift = len(labels_mean_shift_unique)\n    assert n_clusters_mean_shift == expected\n    assert labels_mean_shift_unique[0] == first_cluster_label\n    assert cluster_centers.dtype == global_dtype\n", "type": "function"}, {"name": "test_meanshift_predict", "is_method": false, "class_name": null, "parameters": ["global_dtype"], "calls": ["MeanShift", "X.astype", "ms.fit_predict", "ms.predict", "assert_array_equal"], "code_location": {"file": "test_mean_shift.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/cluster/tests", "start_line": 105, "end_line": 111}, "code_snippet": "def test_meanshift_predict(global_dtype):\n    # Test MeanShift.predict\n    ms = MeanShift(bandwidth=1.2)\n    X_with_global_dtype = X.astype(global_dtype, copy=False)\n    labels = ms.fit_predict(X_with_global_dtype)\n    labels2 = ms.predict(X_with_global_dtype)\n    assert_array_equal(labels, labels2)\n", "type": "function"}, {"name": "test_parallel", "is_method": false, "class_name": null, "parameters": ["global_dtype", "global_random_seed"], "calls": ["make_blobs", "X.astype", "MeanShift", "ms1.fit", "MeanShift", "ms2.fit", "assert_allclose", "assert_array_equal", "np.array"], "code_location": {"file": "test_mean_shift.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/cluster/tests", "start_line": 81, "end_line": 102}, "code_snippet": "def test_parallel(global_dtype, global_random_seed):\n    centers = np.array([[1, 1], [-1, -1], [1, -1]]) + 10\n    X, _ = make_blobs(\n        n_samples=50,\n        n_features=2,\n        centers=centers,\n        cluster_std=0.4,\n        shuffle=True,\n        random_state=global_random_seed,\n    )\n\n    X = X.astype(global_dtype, copy=False)\n\n    ms1 = MeanShift(n_jobs=2)\n    ms1.fit(X)\n\n    ms2 = MeanShift()\n    ms2.fit(X)\n\n    assert_allclose(ms1.cluster_centers_, ms2.cluster_centers_)\n    assert ms1.cluster_centers_.dtype == ms2.cluster_centers_.dtype\n    assert_array_equal(ms1.labels_, ms2.labels_)\n", "type": "function"}, {"name": "test_cluster_intensity_tie", "is_method": false, "class_name": null, "parameters": ["global_dtype"], "calls": ["np.array", "fit", "np.array", "fit", "assert_array_equal", "assert_array_equal", "MeanShift", "MeanShift"], "code_location": {"file": "test_mean_shift.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/cluster/tests", "start_line": 131, "end_line": 138}, "code_snippet": "def test_cluster_intensity_tie(global_dtype):\n    X = np.array([[1, 1], [2, 1], [1, 0], [4, 7], [3, 5], [3, 6]], dtype=global_dtype)\n    c1 = MeanShift(bandwidth=2).fit(X)\n\n    X = np.array([[4, 7], [3, 5], [3, 6], [1, 1], [2, 1], [1, 0]], dtype=global_dtype)\n    c2 = MeanShift(bandwidth=2).fit(X)\n    assert_array_equal(c1.labels_, [1, 1, 1, 0, 0, 0])\n    assert_array_equal(c2.labels_, [0, 0, 0, 1, 1, 1])\n", "type": "function"}, {"name": "test_mean_shift_zero_bandwidth", "is_method": false, "class_name": null, "parameters": ["global_dtype"], "calls": ["reshape", "estimate_bandwidth", "fit", "fit", "np.array", "assert_allclose", "get_bin_seeds", "v_measure_score", "pytest.approx", "v_measure_score", "pytest.approx", "np.array", "MeanShift", "MeanShift"], "code_location": {"file": "test_mean_shift.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/cluster/tests", "start_line": 196, "end_line": 215}, "code_snippet": "def test_mean_shift_zero_bandwidth(global_dtype):\n    # Check that mean shift works when the estimated bandwidth is 0.\n    X = np.array([1, 1, 1, 2, 2, 2, 3, 3], dtype=global_dtype).reshape(-1, 1)\n\n    # estimate_bandwidth with default args returns 0 on this dataset\n    bandwidth = estimate_bandwidth(X)\n    assert bandwidth == 0\n\n    # get_bin_seeds with a 0 bin_size should return the dataset itself\n    assert get_bin_seeds(X, bin_size=bandwidth) is X\n\n    # MeanShift with binning and a 0 estimated bandwidth should be equivalent\n    # to no binning.\n    ms_binning = MeanShift(bin_seeding=True, bandwidth=None).fit(X)\n    ms_nobinning = MeanShift(bin_seeding=False).fit(X)\n    expected_labels = np.array([0, 0, 0, 1, 1, 1, 2, 2])\n\n    assert v_measure_score(ms_binning.labels_, expected_labels) == pytest.approx(1)\n    assert v_measure_score(ms_nobinning.labels_, expected_labels) == pytest.approx(1)\n    assert_allclose(ms_binning.cluster_centers_, ms_nobinning.cluster_centers_)\n", "type": "function"}, {"name": "test_bin_seeds", "is_method": false, "class_name": null, "parameters": ["global_dtype"], "calls": ["np.array", "get_bin_seeds", "set", "get_bin_seeds", "set", "assert_allclose", "make_blobs", "X.astype", "get_bin_seeds", "assert_array_equal", "len", "len", "warnings.catch_warnings", "get_bin_seeds", "tuple", "ground_truth.symmetric_difference", "tuple", "ground_truth.symmetric_difference"], "code_location": {"file": "test_mean_shift.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/cluster/tests", "start_line": 141, "end_line": 180}, "code_snippet": "def test_bin_seeds(global_dtype):\n    # Test the bin seeding technique which can be used in the mean shift\n    # algorithm\n    # Data is just 6 points in the plane\n    X = np.array(\n        [[1.0, 1.0], [1.4, 1.4], [1.8, 1.2], [2.0, 1.0], [2.1, 1.1], [0.0, 0.0]],\n        dtype=global_dtype,\n    )\n\n    # With a bin coarseness of 1.0 and min_bin_freq of 1, 3 bins should be\n    # found\n    ground_truth = {(1.0, 1.0), (2.0, 1.0), (0.0, 0.0)}\n    test_bins = get_bin_seeds(X, 1, 1)\n    test_result = set(tuple(p) for p in test_bins)\n    assert len(ground_truth.symmetric_difference(test_result)) == 0\n\n    # With a bin coarseness of 1.0 and min_bin_freq of 2, 2 bins should be\n    # found\n    ground_truth = {(1.0, 1.0), (2.0, 1.0)}\n    test_bins = get_bin_seeds(X, 1, 2)\n    test_result = set(tuple(p) for p in test_bins)\n    assert len(ground_truth.symmetric_difference(test_result)) == 0\n\n    # With a bin size of 0.01 and min_bin_freq of 1, 6 bins should be found\n    # we bail and use the whole data here.\n    with warnings.catch_warnings(record=True):\n        test_bins = get_bin_seeds(X, 0.01, 1)\n    assert_allclose(test_bins, X)\n\n    # tight clusters around [0, 0] and [1, 1], only get two bins\n    X, _ = make_blobs(\n        n_samples=100,\n        n_features=2,\n        centers=[[0, 0], [1, 1]],\n        cluster_std=0.1,\n        random_state=0,\n    )\n    X = X.astype(global_dtype, copy=False)\n    test_bins = get_bin_seeds(X, 1)\n    assert_array_equal(test_bins, [[0, 0], [1, 1]])\n", "type": "function"}, {"name": "test_subcluster_dtype", "is_method": false, "class_name": null, "parameters": ["global_dtype"], "calls": ["astype", "Birch", "make_blobs", "brc.fit"], "code_location": {"file": "test_birch.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/cluster/tests", "start_line": 201, "end_line": 206}, "code_snippet": "def test_subcluster_dtype(global_dtype):\n    X = make_blobs(n_samples=80, n_features=4, random_state=0)[0].astype(\n        global_dtype, copy=False\n    )\n    brc = Birch(n_clusters=4)\n    assert brc.fit(X).subcluster_centers_.dtype == global_dtype\n", "type": "function"}, {"name": "test_correct_clusters", "is_method": false, "class_name": null, "parameters": ["global_dtype"], "calls": ["np.array", "fit", "np.array", "assert_array_equal", "AffinityPropagation"], "code_location": {"file": "test_affinity_propagation.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/cluster/tests", "start_line": 279, "end_line": 289}, "code_snippet": "def test_correct_clusters(global_dtype):\n    # Test to fix incorrect clusters due to dtype change\n    # (non-regression test for issue #10832)\n    X = np.array(\n        [[1, 0, 0, 0], [0, 1, 1, 0], [0, 1, 1, 0], [0, 0, 0, 1]], dtype=global_dtype\n    )\n    afp = AffinityPropagation(preference=1, affinity=\"precomputed\", random_state=0).fit(\n        X\n    )\n    expected = np.array([0, 1, 1, 2])\n    assert_array_equal(afp.labels_, expected)\n", "type": "function"}, {"name": "test_fastica_return_dtypes", "is_method": false, "class_name": null, "parameters": ["global_dtype"], "calls": ["np.random.RandomState", "astype", "fastica", "rng.random_sample"], "code_location": {"file": "test_fastica.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/decomposition/tests", "start_line": 61, "end_line": 69}, "code_snippet": "def test_fastica_return_dtypes(global_dtype):\n    rng = np.random.RandomState(0)\n    X = rng.random_sample((100, 10)).astype(global_dtype, copy=False)\n    k_, mixing_, s_ = fastica(\n        X, max_iter=1000, whiten=\"unit-variance\", random_state=rng\n    )\n    assert k_.dtype == global_dtype\n    assert mixing_.dtype == global_dtype\n    assert s_.dtype == global_dtype\n", "type": "function"}, {"name": "test_lof", "is_method": false, "class_name": null, "parameters": ["global_dtype"], "calls": ["np.asarray", "neighbors.LocalOutlierFactor", "assert_array_equal", "fit", "assert_array_equal", "assert_array_equal", "clf.fit", "np.min", "np.max", "clf._predict", "clf.fit_predict", "neighbors.LocalOutlierFactor"], "code_location": {"file": "test_lof.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/neighbors/tests", "start_line": 30, "end_line": 49}, "code_snippet": "def test_lof(global_dtype):\n    # Toy sample (the last two samples are outliers):\n    X = np.asarray(\n        [[-2, -1], [-1, -1], [-1, -2], [1, 1], [1, 2], [2, 1], [5, 3], [-4, 2]],\n        dtype=global_dtype,\n    )\n\n    # Test LocalOutlierFactor:\n    clf = neighbors.LocalOutlierFactor(n_neighbors=5)\n    score = clf.fit(X).negative_outlier_factor_\n    assert_array_equal(clf._fit_X, X)\n\n    # Assert largest outlier score is smaller than smallest inlier score:\n    assert np.min(score[:-2]) > np.max(score[-2:])\n\n    # Assert predict() works:\n    clf = neighbors.LocalOutlierFactor(contamination=0.25, n_neighbors=5).fit(X)\n    expected_predictions = 6 * [1] + 2 * [-1]\n    assert_array_equal(clf._predict(), expected_predictions)\n    assert_array_equal(clf.fit_predict(X), expected_predictions)\n", "type": "function"}], "retrieved_count": 10, "cost_time": 1.1030585765838623}
{"question": "What is the semantic contract of the Transf class's transform and inverse_transform methods when it inherits from NoInvTransf and is used within sklearn's pipeline composition system?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"name": "ConsumingNoFitTransformTransformer", "docstring": "A metadata consuming transformer that doesn't inherit from\nTransformerMixin, and thus doesn't implement `fit_transform`. Note that\nTransformerMixin's `fit_transform` doesn't route metadata to `transform`.", "methods": ["__init__", "fit", "transform"], "attributes": [], "code_location": {"file": "metadata_routing_common.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/tests", "start_line": 418, "end_line": 436}, "type": "class"}, {"name": "inverse_transform", "is_method": true, "class_name": "Transf", "parameters": ["self", "X"], "calls": [], "code_location": {"file": "test_pipeline.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/tests", "start_line": 110, "end_line": 111}, "code_snippet": "    def inverse_transform(self, X):\n        return X\n", "type": "function"}, {"name": "inverse_transform", "is_method": true, "class_name": "DummyTransformer", "parameters": ["self", "X"], "calls": [], "code_location": {"file": "test_target.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/compose/tests", "start_line": 331, "end_line": 332}, "code_snippet": "    def inverse_transform(self, X):\n        return X\n", "type": "function"}, {"name": "inverse_transform", "is_method": true, "class_name": "SimpleEstimator", "parameters": ["self", "X", "sample_weight", "prop"], "calls": [], "code_location": {"file": "test_pipeline.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/tests", "start_line": 2199, "end_line": 2202}, "code_snippet": "    def inverse_transform(self, X, sample_weight=None, prop=None):\n        assert sample_weight is not None\n        assert prop is not None\n        return X - 1\n", "type": "function"}, {"name": "MinimalTransformer", "docstring": "Minimal transformer implementation without inheriting from\nBaseEstimator.\n\nThis estimator should be tested with:\n\n* `check_estimator` in `test_estimator_checks.py`;\n* within a `Pipeline` in `test_pipeline.py`;\n* within a `SearchCV` in `test_search.py`.", "methods": ["__init__", "get_params", "set_params", "fit", "transform", "fit_transform", "__sklearn_tags__"], "attributes": [], "code_location": {"file": "_testing.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/utils", "start_line": 1260, "end_line": 1302}, "type": "class"}, {"name": "inverse_transform", "is_method": true, "class_name": "ConsumingTransformer", "parameters": ["self", "X", "sample_weight", "metadata"], "calls": ["record_metadata_not_default"], "code_location": {"file": "metadata_routing_common.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/tests", "start_line": 411, "end_line": 415}, "code_snippet": "    def inverse_transform(self, X, sample_weight=None, metadata=None):\n        record_metadata_not_default(\n            self, sample_weight=sample_weight, metadata=metadata\n        )\n        return X - 1\n", "type": "function"}, {"name": "transform", "is_method": true, "class_name": "SimpleEstimator", "parameters": ["self", "X", "sample_weight", "prop"], "calls": [], "code_location": {"file": "test_pipeline.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/tests", "start_line": 2194, "end_line": 2197}, "code_snippet": "    def transform(self, X, sample_weight=None, prop=None):\n        assert sample_weight is not None\n        assert prop is not None\n        return X + 1\n", "type": "function"}, {"name": "transform", "is_method": true, "class_name": "EstimatorNoSetOutputWithTransform", "parameters": ["self", "X", "y"], "calls": [], "code_location": {"file": "test_set_output.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/utils/tests", "start_line": 163, "end_line": 164}, "code_snippet": "    def transform(self, X, y=None):\n        return X  # pragma: no cover\n", "type": "function"}, {"name": "transform", "is_method": true, "class_name": "EstimatorNoSetOutputWithTransformNoFeatureNamesOut", "parameters": ["self", "X", "y"], "calls": [], "code_location": {"file": "test_set_output.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/utils/tests", "start_line": 207, "end_line": 208}, "code_snippet": "    def transform(self, X, y=None):\n        return X  # pragma: no cover\n", "type": "function"}, {"name": "inverse_transform", "is_method": true, "class_name": "DummyCheckerArrayTransformer", "parameters": ["self", "X"], "calls": ["isinstance"], "code_location": {"file": "test_target.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/compose/tests", "start_line": 285, "end_line": 287}, "code_snippet": "    def inverse_transform(self, X):\n        assert isinstance(X, np.ndarray)\n        return X\n", "type": "function"}], "retrieved_count": 10, "cost_time": 1.0884208679199219}
{"question": "How does the convergence detection mechanism in the `fit` method handle the trade-off between numerical precision and computational efficiency when comparing label distribution changes across iterations?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"name": "test_convergence_speed", "is_method": false, "class_name": null, "parameters": ["constructor_type"], "calls": ["pytest.mark.parametrize", "_convert_container", "np.array", "label_propagation.LabelSpreading", "mdl.fit", "assert_array_equal", "mdl.predict"], "code_location": {"file": "test_label_propagation.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/semi_supervised/tests", "start_line": 147, "end_line": 156}, "code_snippet": "def test_convergence_speed(constructor_type):\n    # This is a non-regression test for #5774\n    X = _convert_container([[1.0, 0.0], [0.0, 1.0], [1.0, 2.5]], constructor_type)\n    y = np.array([0, 1, -1])\n    mdl = label_propagation.LabelSpreading(kernel=\"rbf\", max_iter=5000)\n    mdl.fit(X, y)\n\n    # this should converge quickly:\n    assert mdl.n_iter_ < 10\n    assert_array_equal(mdl.predict(X), [0, 1, 1])\n", "type": "function"}, {"name": "test_convergence_warning", "is_method": false, "class_name": null, "parameters": [], "calls": ["np.array", "np.array", "label_propagation.LabelSpreading", "label_propagation.LabelPropagation", "label_propagation.LabelSpreading", "label_propagation.LabelPropagation", "pytest.warns", "mdl.fit", "pytest.warns", "mdl.fit", "warnings.catch_warnings", "warnings.simplefilter", "mdl.fit", "warnings.catch_warnings", "warnings.simplefilter", "mdl.fit"], "code_location": {"file": "test_label_propagation.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/semi_supervised/tests", "start_line": 159, "end_line": 182}, "code_snippet": "def test_convergence_warning():\n    # This is a non-regression test for #5774\n    X = np.array([[1.0, 0.0], [0.0, 1.0], [1.0, 2.5]])\n    y = np.array([0, 1, -1])\n    mdl = label_propagation.LabelSpreading(kernel=\"rbf\", max_iter=1)\n    warn_msg = \"max_iter=1 was reached without convergence.\"\n    with pytest.warns(ConvergenceWarning, match=warn_msg):\n        mdl.fit(X, y)\n    assert mdl.n_iter_ == mdl.max_iter\n\n    mdl = label_propagation.LabelPropagation(kernel=\"rbf\", max_iter=1)\n    with pytest.warns(ConvergenceWarning, match=warn_msg):\n        mdl.fit(X, y)\n    assert mdl.n_iter_ == mdl.max_iter\n\n    mdl = label_propagation.LabelSpreading(kernel=\"rbf\", max_iter=500)\n    with warnings.catch_warnings():\n        warnings.simplefilter(\"error\", ConvergenceWarning)\n        mdl.fit(X, y)\n\n    mdl = label_propagation.LabelPropagation(kernel=\"rbf\", max_iter=500)\n    with warnings.catch_warnings():\n        warnings.simplefilter(\"error\", ConvergenceWarning)\n        mdl.fit(X, y)\n", "type": "function"}, {"name": "test_labeled_iter", "is_method": false, "class_name": null, "parameters": ["max_iter"], "calls": ["pytest.mark.parametrize", "SelfTrainingClassifier", "st.fit", "len", "range", "KNeighborsClassifier", "np.max"], "code_location": {"file": "test_self_training.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/semi_supervised/tests", "start_line": 175, "end_line": 185}, "code_snippet": "def test_labeled_iter(max_iter):\n    # Check that the amount of datapoints labeled in iteration 0 is equal to\n    # the amount of labeled datapoints we passed.\n    st = SelfTrainingClassifier(KNeighborsClassifier(), max_iter=max_iter)\n\n    st.fit(X_train, y_train_missing_labels)\n    amount_iter_0 = len(st.labeled_iter_[st.labeled_iter_ == 0])\n    assert amount_iter_0 == n_labeled_samples\n    # Check that the max of the iterations is less than the total amount of\n    # iterations\n    assert np.max(st.labeled_iter_) <= st.n_iter_ <= max_iter\n", "type": "function"}, {"name": "test_label_propagation_closed_form", "is_method": false, "class_name": null, "parameters": ["global_dtype"], "calls": ["make_classification", "X.astype", "np.zeros", "label_propagation.LabelPropagation", "clf.fit", "clf._build_graph", "np.dot", "Y.copy", "assert_allclose", "nonzero", "nonzero", "tuple", "tuple", "np.dot", "expected.sum", "len", "np.arange", "np.meshgrid", "np.meshgrid", "np.linalg.inv", "len", "np.eye"], "code_location": {"file": "test_label_propagation.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/semi_supervised/tests", "start_line": 102, "end_line": 126}, "code_snippet": "def test_label_propagation_closed_form(global_dtype):\n    n_classes = 2\n    X, y = make_classification(n_classes=n_classes, n_samples=200, random_state=0)\n    X = X.astype(global_dtype, copy=False)\n    y[::3] = -1\n    Y = np.zeros((len(y), n_classes + 1))\n    Y[np.arange(len(y)), y] = 1\n    unlabelled_idx = Y[:, (-1,)].nonzero()[0]\n    labelled_idx = (Y[:, (-1,)] == 0).nonzero()[0]\n\n    clf = label_propagation.LabelPropagation(max_iter=100, tol=1e-10, gamma=0.1)\n    clf.fit(X, y)\n    # adopting notation from Zhu et al 2002\n    T_bar = clf._build_graph()\n    Tuu = T_bar[tuple(np.meshgrid(unlabelled_idx, unlabelled_idx, indexing=\"ij\"))]\n    Tul = T_bar[tuple(np.meshgrid(unlabelled_idx, labelled_idx, indexing=\"ij\"))]\n    Y = Y[:, :-1]\n    Y_l = Y[labelled_idx, :]\n    Y_u = np.dot(np.dot(np.linalg.inv(np.eye(Tuu.shape[0]) - Tuu), Tul), Y_l)\n\n    expected = Y.copy()\n    expected[unlabelled_idx, :] = Y_u\n    expected /= expected.sum(axis=1)[:, np.newaxis]\n\n    assert_allclose(expected, clf.label_distributions_, atol=1e-4)\n", "type": "function"}, {"name": "test_label_propagation_non_zero_normalizer", "is_method": false, "class_name": null, "parameters": ["LabelPropagationCls"], "calls": ["pytest.mark.parametrize", "np.array", "np.array", "LabelPropagationCls", "warnings.catch_warnings", "warnings.simplefilter", "mdl.fit"], "code_location": {"file": "test_label_propagation.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/semi_supervised/tests", "start_line": 189, "end_line": 199}, "code_snippet": "def test_label_propagation_non_zero_normalizer(LabelPropagationCls):\n    # check that we don't divide by zero in case of null normalizer\n    # non-regression test for\n    # https://github.com/scikit-learn/scikit-learn/pull/15946\n    # https://github.com/scikit-learn/scikit-learn/issues/9292\n    X = np.array([[100.0, 100.0], [100.0, 100.0], [0.0, 0.0], [0.0, 0.0]])\n    y = np.array([0, 1, -1, -1])\n    mdl = LabelPropagationCls(kernel=\"knn\", max_iter=100, n_neighbors=1)\n    with warnings.catch_warnings():\n        warnings.simplefilter(\"error\", RuntimeWarning)\n        mdl.fit(X, y)\n", "type": "function"}, {"name": "test_convergence_dtype_consistency", "is_method": false, "class_name": null, "parameters": [], "calls": ["astype", "BernoulliRBM", "rbm_64.fit_transform", "astype", "BernoulliRBM", "rbm_32.fit_transform", "assert_allclose", "assert_allclose", "assert_allclose", "assert_allclose", "assert_allclose"], "code_location": {"file": "test_rbm.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/neural_network/tests", "start_line": 219, "end_line": 239}, "code_snippet": "def test_convergence_dtype_consistency():\n    # float 64 transformer\n    X_64 = Xdigits[:100].astype(np.float64)\n    rbm_64 = BernoulliRBM(n_components=16, batch_size=5, n_iter=5, random_state=42)\n    Xt_64 = rbm_64.fit_transform(X_64)\n\n    # float 32 transformer\n    X_32 = Xdigits[:100].astype(np.float32)\n    rbm_32 = BernoulliRBM(n_components=16, batch_size=5, n_iter=5, random_state=42)\n    Xt_32 = rbm_32.fit_transform(X_32)\n\n    # results and attributes should be close enough in 32 bit and 64 bit\n    assert_allclose(Xt_64, Xt_32, rtol=1e-06, atol=0)\n    assert_allclose(\n        rbm_64.intercept_hidden_, rbm_32.intercept_hidden_, rtol=1e-06, atol=0\n    )\n    assert_allclose(\n        rbm_64.intercept_visible_, rbm_32.intercept_visible_, rtol=1e-05, atol=0\n    )\n    assert_allclose(rbm_64.components_, rbm_32.components_, rtol=1e-03, atol=0)\n    assert_allclose(rbm_64.h_samples_, rbm_32.h_samples_)\n", "type": "function"}, {"name": "test_distribution", "is_method": false, "class_name": null, "parameters": ["global_dtype", "Estimator", "parameters"], "calls": ["pytest.mark.parametrize", "np.asarray", "fit", "assert_allclose", "pytest.skip", "Estimator"], "code_location": {"file": "test_label_propagation.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/semi_supervised/tests", "start_line": 48, "end_line": 56}, "code_snippet": "def test_distribution(global_dtype, Estimator, parameters):\n    if parameters[\"kernel\"] == \"knn\":\n        pytest.skip(\n            \"Unstable test for this configuration: changes in k-NN ordering break it.\"\n        )\n    samples = np.asarray([[1.0, 0.0], [0.0, 1.0], [1.0, 1.0]], dtype=global_dtype)\n    labels = [0, 1, -1]\n    clf = Estimator(**parameters).fit(samples, labels)\n    assert_allclose(clf.label_distributions_[2], [0.5, 0.5], atol=1e-2)\n", "type": "function"}, {"name": "test_label_spreading_closed_form", "is_method": false, "class_name": null, "parameters": ["global_dtype", "Estimator", "parameters", "alpha"], "calls": ["pytest.mark.parametrize", "pytest.mark.parametrize", "make_classification", "X.astype", "fit", "clf._build_graph", "np.zeros", "np.dot", "label_propagation.LabelSpreading", "clf.fit", "assert_allclose", "np.linalg.inv", "expected.sum", "label_propagation.LabelSpreading", "len", "np.arange", "len", "np.eye", "len"], "code_location": {"file": "test_label_propagation.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/semi_supervised/tests", "start_line": 77, "end_line": 99}, "code_snippet": "def test_label_spreading_closed_form(global_dtype, Estimator, parameters, alpha):\n    n_classes = 2\n    X, y = make_classification(n_classes=n_classes, n_samples=200, random_state=0)\n    X = X.astype(global_dtype, copy=False)\n    y[::3] = -1\n\n    gamma = 0.1\n    clf = label_propagation.LabelSpreading(gamma=gamma).fit(X, y)\n    # adopting notation from Zhou et al (2004):\n    S = clf._build_graph()\n    Y = np.zeros((len(y), n_classes + 1), dtype=X.dtype)\n    Y[np.arange(len(y)), y] = 1\n    Y = Y[:, :-1]\n\n    expected = np.dot(np.linalg.inv(np.eye(len(S), dtype=S.dtype) - alpha * S), Y)\n    expected /= expected.sum(axis=1)[:, np.newaxis]\n\n    clf = label_propagation.LabelSpreading(\n        max_iter=100, alpha=alpha, tol=1e-10, gamma=gamma\n    )\n    clf.fit(X, y)\n\n    assert_allclose(expected, clf.label_distributions_)\n", "type": "function"}, {"name": "test_none_iter", "is_method": false, "class_name": null, "parameters": [], "calls": ["SelfTrainingClassifier", "st.fit", "KNeighborsClassifier"], "code_location": {"file": "test_self_training.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/semi_supervised/tests", "start_line": 130, "end_line": 137}, "code_snippet": "def test_none_iter():\n    # Check that the all samples were labeled after a 'reasonable' number of\n    # iterations.\n    st = SelfTrainingClassifier(KNeighborsClassifier(), threshold=0.55, max_iter=None)\n    st.fit(X_train, y_train_missing_labels)\n\n    assert st.n_iter_ < 10\n    assert st.termination_condition_ == \"all_labeled\"\n", "type": "function"}, {"name": "test_n_iter_no_change_inf", "is_method": false, "class_name": null, "parameters": [], "calls": ["pytest.mark.filterwarnings", "MLPClassifier", "clf.fit"], "code_location": {"file": "test_mlp.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/neural_network/tests", "start_line": 797, "end_line": 819}, "code_snippet": "def test_n_iter_no_change_inf():\n    # test n_iter_no_change using binary data set\n    # the fitting process should go to max_iter iterations\n    X = X_digits_binary[:100]\n    y = y_digits_binary[:100]\n\n    # set a ridiculous tolerance\n    # this should always trigger _update_no_improvement_count()\n    tol = 1e9\n\n    # fit\n    n_iter_no_change = np.inf\n    max_iter = 3000\n    clf = MLPClassifier(\n        tol=tol, max_iter=max_iter, solver=\"sgd\", n_iter_no_change=n_iter_no_change\n    )\n    clf.fit(X, y)\n\n    # validate n_iter_no_change doesn't cause early stopping\n    assert clf.n_iter_ == max_iter\n\n    # validate _update_no_improvement_count() was always triggered\n    assert clf._no_improvement_count == clf.n_iter_ - 1\n", "type": "function"}], "retrieved_count": 10, "cost_time": 1.0770816802978516}
{"question": "What is the integration mechanism between the PositiveSpectrumWarning class and the _check_psd_eigenvalues function that propagates matrix conditioning issues through the scikit-learn validation pipeline, and what downstream dependencies rely on this warning mechanism to handle numerical instability in kernel matrices?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"name": "_check_psd_eigenvalues", "is_method": false, "class_name": null, "parameters": ["lambdas", "enable_warnings"], "calls": ["np.array", "np.real", "lambdas.max", "too_small_lambdas.any", "all", "max", "max", "ValueError", "lambdas.min", "ValueError", "warnings.warn", "ValueError", "warnings.warn", "np.isreal", "np.abs", "np.abs", "np.imag", "np.real", "warnings.warn"], "code_location": {"file": "validation.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/utils", "start_line": 1970, "end_line": 2140}, "code_snippet": "def _check_psd_eigenvalues(lambdas, enable_warnings=False):\n    \"\"\"Check the eigenvalues of a positive semidefinite (PSD) matrix.\n\n    Checks the provided array of PSD matrix eigenvalues for numerical or\n    conditioning issues and returns a fixed validated version. This method\n    should typically be used if the PSD matrix is user-provided (e.g. a\n    Gram matrix) or computed using a user-provided dissimilarity metric\n    (e.g. kernel function), or if the decomposition process uses approximation\n    methods (randomized SVD, etc.).\n\n    It checks for three things:\n\n    - that there are no significant imaginary parts in eigenvalues (more than\n      1e-5 times the maximum real part). If this check fails, it raises a\n      ``ValueError``. Otherwise all non-significant imaginary parts that may\n      remain are set to zero. This operation is traced with a\n      ``PositiveSpectrumWarning`` when ``enable_warnings=True``.\n\n    - that eigenvalues are not all negative. If this check fails, it raises a\n      ``ValueError``\n\n    - that there are no significant negative eigenvalues with absolute value\n      more than 1e-10 (1e-6) and more than 1e-5 (5e-3) times the largest\n      positive eigenvalue in double (simple) precision. If this check fails,\n      it raises a ``ValueError``. Otherwise all negative eigenvalues that may\n      remain are set to zero. This operation is traced with a\n      ``PositiveSpectrumWarning`` when ``enable_warnings=True``.\n\n    Finally, all the positive eigenvalues that are too small (with a value\n    smaller than the maximum eigenvalue multiplied by 1e-12 (2e-7)) are set to\n    zero. This operation is traced with a ``PositiveSpectrumWarning`` when\n    ``enable_warnings=True``.\n\n    Parameters\n    ----------\n    lambdas : array-like of shape (n_eigenvalues,)\n        Array of eigenvalues to check / fix.\n\n    enable_warnings : bool, default=False\n        When this is set to ``True``, a ``PositiveSpectrumWarning`` will be\n        raised when there are imaginary parts, negative eigenvalues, or\n        extremely small non-zero eigenvalues. Otherwise no warning will be\n        raised. In both cases, imaginary parts, negative eigenvalues, and\n        extremely small non-zero eigenvalues will be set to zero.\n\n    Returns\n    -------\n    lambdas_fixed : ndarray of shape (n_eigenvalues,)\n        A fixed validated copy of the array of eigenvalues.\n\n    Examples\n    --------\n    >>> from sklearn.utils.validation import _check_psd_eigenvalues\n    >>> _check_psd_eigenvalues([1, 2])      # nominal case\n    array([1, 2])\n    >>> _check_psd_eigenvalues([5, 5j])     # significant imag part\n    Traceback (most recent call last):\n        ...\n    ValueError: There are significant imaginary parts in eigenvalues (1\n        of the maximum real part). Either the matrix is not PSD, or there was\n        an issue while computing the eigendecomposition of the matrix.\n    >>> _check_psd_eigenvalues([5, 5e-5j])  # insignificant imag part\n    array([5., 0.])\n    >>> _check_psd_eigenvalues([-5, -1])    # all negative\n    Traceback (most recent call last):\n        ...\n    ValueError: All eigenvalues are negative (maximum is -1). Either the\n        matrix is not PSD, or there was an issue while computing the\n        eigendecomposition of the matrix.\n    >>> _check_psd_eigenvalues([5, -1])     # significant negative\n    Traceback (most recent call last):\n        ...\n    ValueError: There are significant negative eigenvalues (0.2 of the\n        maximum positive). Either the matrix is not PSD, or there was an issue\n        while computing the eigendecomposition of the matrix.\n    >>> _check_psd_eigenvalues([5, -5e-5])  # insignificant negative\n    array([5., 0.])\n    >>> _check_psd_eigenvalues([5, 4e-12])  # bad conditioning (too small)\n    array([5., 0.])\n\n    \"\"\"\n\n    lambdas = np.array(lambdas)\n    is_double_precision = lambdas.dtype == np.float64\n\n    # note: the minimum value available is\n    #  - single-precision: np.finfo('float32').eps = 1.2e-07\n    #  - double-precision: np.finfo('float64').eps = 2.2e-16\n\n    # the various thresholds used for validation\n    # we may wish to change the value according to precision.\n    significant_imag_ratio = 1e-5\n    significant_neg_ratio = 1e-5 if is_double_precision else 5e-3\n    significant_neg_value = 1e-10 if is_double_precision else 1e-6\n    small_pos_ratio = 1e-12 if is_double_precision else 2e-7\n\n    # Check that there are no significant imaginary parts\n    if not np.isreal(lambdas).all():\n        max_imag_abs = np.abs(np.imag(lambdas)).max()\n        max_real_abs = np.abs(np.real(lambdas)).max()\n        if max_imag_abs > significant_imag_ratio * max_real_abs:\n            raise ValueError(\n                \"There are significant imaginary parts in eigenvalues (%g \"\n                \"of the maximum real part). Either the matrix is not PSD, or \"\n                \"there was an issue while computing the eigendecomposition \"\n                \"of the matrix.\" % (max_imag_abs / max_real_abs)\n            )\n\n        # warn about imaginary parts being removed\n        if enable_warnings:\n            warnings.warn(\n                \"There are imaginary parts in eigenvalues (%g \"\n                \"of the maximum real part). Either the matrix is not\"\n                \" PSD, or there was an issue while computing the \"\n                \"eigendecomposition of the matrix. Only the real \"\n                \"parts will be kept.\" % (max_imag_abs / max_real_abs),\n                PositiveSpectrumWarning,\n            )\n\n    # Remove all imaginary parts (even if zero)\n    lambdas = np.real(lambdas)\n\n    # Check that there are no significant negative eigenvalues\n    max_eig = lambdas.max()\n    if max_eig < 0:\n        raise ValueError(\n            \"All eigenvalues are negative (maximum is %g). \"\n            \"Either the matrix is not PSD, or there was an \"\n            \"issue while computing the eigendecomposition of \"\n            \"the matrix.\" % max_eig\n        )\n\n    else:\n        min_eig = lambdas.min()\n        if (\n            min_eig < -significant_neg_ratio * max_eig\n            and min_eig < -significant_neg_value\n        ):\n            raise ValueError(\n                \"There are significant negative eigenvalues (%g\"\n                \" of the maximum positive). Either the matrix is \"\n                \"not PSD, or there was an issue while computing \"\n                \"the eigendecomposition of the matrix.\" % (-min_eig / max_eig)\n            )\n        elif min_eig < 0:\n            # Remove all negative values and warn about it\n            if enable_warnings:\n                warnings.warn(\n                    \"There are negative eigenvalues (%g of the \"\n                    \"maximum positive). Either the matrix is not \"\n                    \"PSD, or there was an issue while computing the\"\n                    \" eigendecomposition of the matrix. Negative \"\n                    \"eigenvalues will be replaced with 0.\" % (-min_eig / max_eig),\n                    PositiveSpectrumWarning,\n                )\n            lambdas[lambdas < 0] = 0\n\n    # Check for conditioning (small positive non-zeros)\n    too_small_lambdas = (0 < lambdas) & (lambdas < small_pos_ratio * max_eig)\n    if too_small_lambdas.any():\n        if enable_warnings:\n            warnings.warn(\n                \"Badly conditioned PSD matrix spectrum: the largest \"\n                \"eigenvalue is more than %g times the smallest. \"\n                \"Small eigenvalues will be replaced with 0.\"\n                \"\" % (1 / small_pos_ratio),\n                PositiveSpectrumWarning,\n            )\n        lambdas[too_small_lambdas] = 0\n\n    return lambdas\n", "type": "function"}, {"name": "test_kernel_conditioning", "is_method": false, "class_name": null, "parameters": [], "calls": ["KernelPCA", "kpca.fit", "np.all", "kpca.eigenvalues_.min", "_check_psd_eigenvalues"], "code_location": {"file": "test_kernel_pca.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/decomposition/tests", "start_line": 373, "end_line": 386}, "code_snippet": "def test_kernel_conditioning():\n    \"\"\"Check that ``_check_psd_eigenvalues`` is correctly called in kPCA\n\n    Non-regression test for issue #12140 (PR #12145).\n    \"\"\"\n\n    # create a pathological X leading to small non-zero eigenvalue\n    X = [[5, 1], [5 + 1e-8, 1e-8], [5 + 1e-8, 0]]\n    kpca = KernelPCA(kernel=\"linear\", n_components=2, fit_inverse_transform=True)\n    kpca.fit(X)\n\n    # check that the small non-zero eigenvalue was correctly set to zero\n    assert kpca.eigenvalues_.min() == 0\n    assert np.all(kpca.eigenvalues_ == _check_psd_eigenvalues(kpca.eigenvalues_))\n", "type": "function"}, {"name": "test_check_psd_eigenvalues_valid", "is_method": false, "class_name": null, "parameters": ["lambdas", "expected_lambdas", "w_type", "w_msg", "enable_warnings"], "calls": ["pytest.mark.parametrize", "pytest.mark.parametrize", "assert_allclose", "list", "_psd_cases_valid.values", "list", "warnings.catch_warnings", "warnings.simplefilter", "_check_psd_eigenvalues", "pytest.warns", "_check_psd_eigenvalues", "_psd_cases_valid.keys"], "code_location": {"file": "test_validation.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/utils/tests", "start_line": 1533, "end_line": 1554}, "code_snippet": "def test_check_psd_eigenvalues_valid(\n    lambdas, expected_lambdas, w_type, w_msg, enable_warnings\n):\n    # Test that ``_check_psd_eigenvalues`` returns the right output for valid\n    # input, possibly raising the right warning\n\n    if not enable_warnings:\n        w_type = None\n\n    if w_type is None:\n        with warnings.catch_warnings():\n            warnings.simplefilter(\"error\", PositiveSpectrumWarning)\n            lambdas_fixed = _check_psd_eigenvalues(\n                lambdas, enable_warnings=enable_warnings\n            )\n    else:\n        with pytest.warns(w_type, match=w_msg):\n            lambdas_fixed = _check_psd_eigenvalues(\n                lambdas, enable_warnings=enable_warnings\n            )\n\n    assert_allclose(expected_lambdas, lambdas_fixed)\n", "type": "function"}, {"name": "test_precomputed_kernel_not_psd", "is_method": false, "class_name": null, "parameters": ["solver"], "calls": ["pytest.mark.parametrize", "KernelPCA", "KernelPCA", "pytest.raises", "kpca.fit", "kpca.fit", "pytest.raises", "kpca.fit"], "code_location": {"file": "test_kernel_pca.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/decomposition/tests", "start_line": 390, "end_line": 438}, "code_snippet": "def test_precomputed_kernel_not_psd(solver):\n    \"\"\"Check how KernelPCA works with non-PSD kernels depending on n_components\n\n    Tests for all methods what happens with a non PSD gram matrix (this\n    can happen in an isomap scenario, or with custom kernel functions, or\n    maybe with ill-posed datasets).\n\n    When ``n_component`` is large enough to capture a negative eigenvalue, an\n    error should be raised. Otherwise, KernelPCA should run without error\n    since the negative eigenvalues are not selected.\n    \"\"\"\n\n    # a non PSD kernel with large eigenvalues, already centered\n    # it was captured from an isomap call and multiplied by 100 for compacity\n    K = [\n        [4.48, -1.0, 8.07, 2.33, 2.33, 2.33, -5.76, -12.78],\n        [-1.0, -6.48, 4.5, -1.24, -1.24, -1.24, -0.81, 7.49],\n        [8.07, 4.5, 15.48, 2.09, 2.09, 2.09, -11.1, -23.23],\n        [2.33, -1.24, 2.09, 4.0, -3.65, -3.65, 1.02, -0.9],\n        [2.33, -1.24, 2.09, -3.65, 4.0, -3.65, 1.02, -0.9],\n        [2.33, -1.24, 2.09, -3.65, -3.65, 4.0, 1.02, -0.9],\n        [-5.76, -0.81, -11.1, 1.02, 1.02, 1.02, 4.86, 9.75],\n        [-12.78, 7.49, -23.23, -0.9, -0.9, -0.9, 9.75, 21.46],\n    ]\n    # this gram matrix has 5 positive eigenvalues and 3 negative ones\n    # [ 52.72,   7.65,   7.65,   5.02,   0.  ,  -0.  ,  -6.13, -15.11]\n\n    # 1. ask for enough components to get a significant negative one\n    kpca = KernelPCA(kernel=\"precomputed\", eigen_solver=solver, n_components=7)\n    # make sure that the appropriate error is raised\n    with pytest.raises(ValueError, match=\"There are significant negative eigenvalues\"):\n        kpca.fit(K)\n\n    # 2. ask for a small enough n_components to get only positive ones\n    kpca = KernelPCA(kernel=\"precomputed\", eigen_solver=solver, n_components=2)\n    if solver == \"randomized\":\n        # the randomized method is still inconsistent with the others on this\n        # since it selects the eigenvalues based on the largest 2 modules, not\n        # on the largest 2 values.\n        #\n        # At least we can ensure that we return an error instead of returning\n        # the wrong eigenvalues\n        with pytest.raises(\n            ValueError, match=\"There are significant negative eigenvalues\"\n        ):\n            kpca.fit(K)\n    else:\n        # general case: make sure that it works\n        kpca.fit(K)\n", "type": "function"}, {"name": "test_spectral_embedding_amg_solver", "is_method": false, "class_name": null, "parameters": ["dtype", "coo_container", "seed"], "calls": ["pytest.mark.skipif", "pytest.mark.parametrize", "pytest.mark.parametrize", "SpectralEmbedding", "SpectralEmbedding", "se_amg.fit_transform", "se_arpack.fit_transform", "_assert_equal_with_sign_flipping", "np.array", "np.array", "np.array", "coo_container", "se_amg.fit_transform", "se_arpack.fit_transform", "_assert_equal_with_sign_flipping", "affinity.tocsr", "affinity.indptr.astype", "affinity.indices.astype", "S.astype", "S.astype", "affinity.astype", "affinity.astype", "parse_version", "se_amg.fit_transform", "np.random.RandomState", "np.random.RandomState", "np.hstack", "pytest.raises", "se_amg.fit_transform", "np.hstack", "np.hstack"], "code_location": {"file": "test_spectral_embedding.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/manifold/tests", "start_line": 253, "end_line": 304}, "code_snippet": "def test_spectral_embedding_amg_solver(dtype, coo_container, seed=36):\n    se_amg = SpectralEmbedding(\n        n_components=2,\n        affinity=\"nearest_neighbors\",\n        eigen_solver=\"amg\",\n        n_neighbors=5,\n        random_state=np.random.RandomState(seed),\n    )\n    se_arpack = SpectralEmbedding(\n        n_components=2,\n        affinity=\"nearest_neighbors\",\n        eigen_solver=\"arpack\",\n        n_neighbors=5,\n        random_state=np.random.RandomState(seed),\n    )\n    embed_amg = se_amg.fit_transform(S.astype(dtype))\n    embed_arpack = se_arpack.fit_transform(S.astype(dtype))\n    _assert_equal_with_sign_flipping(embed_amg, embed_arpack, 1e-5)\n\n    # same with special case in which amg is not actually used\n    # regression test for #10715\n    # affinity between nodes\n    row = np.array([0, 0, 1, 2, 3, 3, 4], dtype=np.int32)\n    col = np.array([1, 2, 2, 3, 4, 5, 5], dtype=np.int32)\n    val = np.array([100, 100, 100, 1, 100, 100, 100], dtype=np.int64)\n\n    affinity = coo_container(\n        (np.hstack([val, val]), (np.hstack([row, col]), np.hstack([col, row]))),\n        shape=(6, 6),\n    )\n    se_amg.affinity = \"precomputed\"\n    se_arpack.affinity = \"precomputed\"\n    embed_amg = se_amg.fit_transform(affinity.astype(dtype))\n    embed_arpack = se_arpack.fit_transform(affinity.astype(dtype))\n    _assert_equal_with_sign_flipping(embed_amg, embed_arpack, 1e-5)\n\n    # Check that passing a sparse matrix with `np.int64` indices dtype raises an error\n    # or is successful based on the version of SciPy which is installed.\n    # Use a CSR matrix to avoid any conversion during the validation\n    affinity = affinity.tocsr()\n    affinity.indptr = affinity.indptr.astype(np.int64)\n    affinity.indices = affinity.indices.astype(np.int64)\n\n    # PR: https://github.com/scipy/scipy/pull/18913\n    # First integration in 1.11.3: https://github.com/scipy/scipy/pull/19279\n    scipy_graph_traversal_supports_int64_index = sp_version >= parse_version(\"1.11.3\")\n    if scipy_graph_traversal_supports_int64_index:\n        se_amg.fit_transform(affinity)\n    else:\n        err_msg = \"Only sparse matrices with 32-bit integer indices are accepted\"\n        with pytest.raises(ValueError, match=err_msg):\n            se_amg.fit_transform(affinity)\n", "type": "function"}, {"name": "test_gpr_correct_error_message", "is_method": false, "class_name": null, "parameters": [], "calls": ["reshape", "np.ones", "DotProduct", "GaussianProcessRegressor", "pytest.raises", "gpr.fit", "np.arange", "re.escape"], "code_location": {"file": "test_gpr.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/gaussian_process/tests", "start_line": 418, "end_line": 430}, "code_snippet": "def test_gpr_correct_error_message():\n    X = np.arange(12).reshape(6, -1)\n    y = np.ones(6)\n    kernel = DotProduct()\n    gpr = GaussianProcessRegressor(kernel=kernel, alpha=0.0)\n    message = (\n        \"The kernel, %s, is not returning a \"\n        \"positive definite matrix. Try gradually increasing \"\n        \"the 'alpha' parameter of your \"\n        \"GaussianProcessRegressor estimator.\" % kernel\n    )\n    with pytest.raises(np.linalg.LinAlgError, match=re.escape(message)):\n        gpr.fit(X, y)\n", "type": "function"}, {"name": "test_warning_bounds", "is_method": false, "class_name": null, "parameters": [], "calls": ["RBF", "GaussianProcessClassifier", "GaussianProcessClassifier", "np.tile", "RBF", "GaussianProcessClassifier", "pytest.warns", "gpc.fit", "WhiteKernel", "RBF", "warnings.catch_warnings", "warnings.simplefilter", "gpc_sum.fit", "issubclass", "issubclass", "warnings.catch_warnings", "warnings.simplefilter", "gpc_dims.fit", "issubclass", "issubclass", "len", "len"], "code_location": {"file": "test_gpc.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/gaussian_process/tests", "start_line": 198, "end_line": 268}, "code_snippet": "def test_warning_bounds():\n    kernel = RBF(length_scale_bounds=[1e-5, 1e-3])\n    gpc = GaussianProcessClassifier(kernel=kernel)\n    warning_message = (\n        \"The optimal value found for dimension 0 of parameter \"\n        \"length_scale is close to the specified upper bound \"\n        \"0.001. Increasing the bound and calling fit again may \"\n        \"find a better value.\"\n    )\n    with pytest.warns(ConvergenceWarning, match=warning_message):\n        gpc.fit(X, y)\n\n    kernel_sum = WhiteKernel(noise_level_bounds=[1e-5, 1e-3]) + RBF(\n        length_scale_bounds=[1e3, 1e5]\n    )\n    gpc_sum = GaussianProcessClassifier(kernel=kernel_sum)\n    with warnings.catch_warnings(record=True) as record:\n        warnings.simplefilter(\"always\")\n        gpc_sum.fit(X, y)\n\n        assert len(record) == 2\n\n        assert issubclass(record[0].category, ConvergenceWarning)\n        assert (\n            record[0].message.args[0] == \"The optimal value found for \"\n            \"dimension 0 of parameter \"\n            \"k1__noise_level is close to the \"\n            \"specified upper bound 0.001. \"\n            \"Increasing the bound and calling \"\n            \"fit again may find a better value.\"\n        )\n\n        assert issubclass(record[1].category, ConvergenceWarning)\n        assert (\n            record[1].message.args[0] == \"The optimal value found for \"\n            \"dimension 0 of parameter \"\n            \"k2__length_scale is close to the \"\n            \"specified lower bound 1000.0. \"\n            \"Decreasing the bound and calling \"\n            \"fit again may find a better value.\"\n        )\n\n    X_tile = np.tile(X, 2)\n    kernel_dims = RBF(length_scale=[1.0, 2.0], length_scale_bounds=[1e1, 1e2])\n    gpc_dims = GaussianProcessClassifier(kernel=kernel_dims)\n\n    with warnings.catch_warnings(record=True) as record:\n        warnings.simplefilter(\"always\")\n        gpc_dims.fit(X_tile, y)\n\n        assert len(record) == 2\n\n        assert issubclass(record[0].category, ConvergenceWarning)\n        assert (\n            record[0].message.args[0] == \"The optimal value found for \"\n            \"dimension 0 of parameter \"\n            \"length_scale is close to the \"\n            \"specified upper bound 100.0. \"\n            \"Increasing the bound and calling \"\n            \"fit again may find a better value.\"\n        )\n\n        assert issubclass(record[1].category, ConvergenceWarning)\n        assert (\n            record[1].message.args[0] == \"The optimal value found for \"\n            \"dimension 1 of parameter \"\n            \"length_scale is close to the \"\n            \"specified upper bound 100.0. \"\n            \"Increasing the bound and calling \"\n            \"fit again may find a better value.\"\n        )\n", "type": "function"}, {"name": "test_sklearn_warnings_as_errors", "is_method": false, "class_name": null, "parameters": ["warning_info"], "calls": ["pytest.mark.parametrize", "check_warnings_as_errors", "_get_warnings_filters_info_list", "os.environ.get"], "code_location": {"file": "test_testing.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/utils/tests", "start_line": 1134, "end_line": 1136}, "code_snippet": "def test_sklearn_warnings_as_errors(warning_info):\n    warnings_as_errors = os.environ.get(\"SKLEARN_WARNINGS_AS_ERRORS\", \"0\") != \"0\"\n    check_warnings_as_errors(warning_info, warnings_as_errors=warnings_as_errors)\n", "type": "function"}, {"name": "test_mcd_increasing_det_warning", "is_method": false, "class_name": null, "parameters": ["global_random_seed"], "calls": ["MinCovDet", "pytest.warns", "mcd.fit"], "code_location": {"file": "test_robust_covariance.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/covariance/tests", "start_line": 140, "end_line": 171}, "code_snippet": "def test_mcd_increasing_det_warning(global_random_seed):\n    # Check that a warning is raised if we observe increasing determinants\n    # during the c_step. In theory the sequence of determinants should be\n    # decreasing. Increasing determinants are likely due to ill-conditioned\n    # covariance matrices that result in poor precision matrices.\n\n    X = [\n        [5.1, 3.5, 1.4, 0.2],\n        [4.9, 3.0, 1.4, 0.2],\n        [4.7, 3.2, 1.3, 0.2],\n        [4.6, 3.1, 1.5, 0.2],\n        [5.0, 3.6, 1.4, 0.2],\n        [4.6, 3.4, 1.4, 0.3],\n        [5.0, 3.4, 1.5, 0.2],\n        [4.4, 2.9, 1.4, 0.2],\n        [4.9, 3.1, 1.5, 0.1],\n        [5.4, 3.7, 1.5, 0.2],\n        [4.8, 3.4, 1.6, 0.2],\n        [4.8, 3.0, 1.4, 0.1],\n        [4.3, 3.0, 1.1, 0.1],\n        [5.1, 3.5, 1.4, 0.3],\n        [5.7, 3.8, 1.7, 0.3],\n        [5.4, 3.4, 1.7, 0.2],\n        [4.6, 3.6, 1.0, 0.2],\n        [5.0, 3.0, 1.6, 0.2],\n        [5.2, 3.5, 1.5, 0.2],\n    ]\n\n    mcd = MinCovDet(support_fraction=0.5, random_state=global_random_seed)\n    warn_msg = \"Determinant has increased\"\n    with pytest.warns(RuntimeWarning, match=warn_msg):\n        mcd.fit(X)\n", "type": "function"}, {"name": "test_error_pyamg_not_available", "is_method": false, "class_name": null, "parameters": [], "calls": ["pytest.mark.skipif", "SpectralEmbedding", "pytest.raises", "se_precomp.fit_transform"], "code_location": {"file": "test_spectral_embedding.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/manifold/tests", "start_line": 467, "end_line": 475}, "code_snippet": "def test_error_pyamg_not_available():\n    se_precomp = SpectralEmbedding(\n        n_components=2,\n        affinity=\"rbf\",\n        eigen_solver=\"amg\",\n    )\n    err_msg = \"The eigen_solver was set to 'amg', but pyamg is not available.\"\n    with pytest.raises(ValueError, match=err_msg):\n        se_precomp.fit_transform(S)\n", "type": "function"}], "retrieved_count": 10, "cost_time": 1.114109754562378}
{"question": "How does the delegation of the actual curve computation to `from_predictions` after response value extraction enable code reuse between estimator-based and prediction-based visualization workflows, and what is the significance of this design pattern?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"name": "_validate_and_get_response_values", "is_method": true, "class_name": "_BinaryClassifierCurveDisplayMixin", "parameters": ["cls", "estimator", "X", "y"], "calls": ["check_matplotlib_support", "_get_response_values_binary"], "code_location": {"file": "_plotting.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/utils", "start_line": 37, "end_line": 51}, "code_snippet": "    def _validate_and_get_response_values(\n        cls, estimator, X, y, *, response_method=\"auto\", pos_label=None, name=None\n    ):\n        check_matplotlib_support(f\"{cls.__name__}.from_estimator\")\n\n        name = estimator.__class__.__name__ if name is None else name\n\n        y_pred, pos_label = _get_response_values_binary(\n            estimator,\n            X,\n            response_method=response_method,\n            pos_label=pos_label,\n        )\n\n        return y_pred, pos_label, name\n", "type": "function"}, {"name": "from_estimator", "is_method": true, "class_name": "RocCurveDisplay", "parameters": ["cls", "estimator", "X", "y"], "calls": ["cls._validate_and_get_response_values", "cls.from_predictions"], "code_location": {"file": "roc_curve.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/metrics/_plot", "start_line": 306, "end_line": 449}, "code_snippet": "    def from_estimator(\n        cls,\n        estimator,\n        X,\n        y,\n        *,\n        sample_weight=None,\n        drop_intermediate=True,\n        response_method=\"auto\",\n        pos_label=None,\n        name=None,\n        ax=None,\n        curve_kwargs=None,\n        plot_chance_level=False,\n        chance_level_kw=None,\n        despine=False,\n        **kwargs,\n    ):\n        \"\"\"Create a ROC Curve display from an estimator.\n\n        For general information regarding `scikit-learn` visualization tools,\n        see the :ref:`Visualization Guide <visualizations>`.\n        For guidance on interpreting these plots, refer to the :ref:`Model\n        Evaluation Guide <roc_metrics>`.\n\n        Parameters\n        ----------\n        estimator : estimator instance\n            Fitted classifier or a fitted :class:`~sklearn.pipeline.Pipeline`\n            in which the last estimator is a classifier.\n\n        X : {array-like, sparse matrix} of shape (n_samples, n_features)\n            Input values.\n\n        y : array-like of shape (n_samples,)\n            Target values.\n\n        sample_weight : array-like of shape (n_samples,), default=None\n            Sample weights.\n\n        drop_intermediate : bool, default=True\n            Whether to drop thresholds where the resulting point is collinear\n            with its neighbors in ROC space. This has no effect on the ROC AUC\n            or visual shape of the curve, but reduces the number of plotted\n            points.\n\n        response_method : {'predict_proba', 'decision_function', 'auto'} \\\n                default='auto'\n            Specifies whether to use :term:`predict_proba` or\n            :term:`decision_function` as the target response. If set to 'auto',\n            :term:`predict_proba` is tried first and if it does not exist\n            :term:`decision_function` is tried next.\n\n        pos_label : int, float, bool or str, default=None\n            The class considered as the positive class when computing the ROC AUC.\n            By default, `estimators.classes_[1]` is considered\n            as the positive class.\n\n        name : str, default=None\n            Name of ROC Curve for labeling. If `None`, use the name of the\n            estimator.\n\n        ax : matplotlib axes, default=None\n            Axes object to plot on. If `None`, a new figure and axes is created.\n\n        curve_kwargs : dict, default=None\n            Keywords arguments to be passed to matplotlib's `plot` function.\n\n            .. versionadded:: 1.7\n\n        plot_chance_level : bool, default=False\n            Whether to plot the chance level.\n\n            .. versionadded:: 1.3\n\n        chance_level_kw : dict, default=None\n            Keyword arguments to be passed to matplotlib's `plot` for rendering\n            the chance level line.\n\n            .. versionadded:: 1.3\n\n        despine : bool, default=False\n            Whether to remove the top and right spines from the plot.\n\n            .. versionadded:: 1.6\n\n        **kwargs : dict\n            Keyword arguments to be passed to matplotlib's `plot`.\n\n            .. deprecated:: 1.7\n                kwargs is deprecated and will be removed in 1.9. Pass matplotlib\n                arguments to `curve_kwargs` as a dictionary instead.\n\n        Returns\n        -------\n        display : :class:`~sklearn.metrics.RocCurveDisplay`\n            The ROC Curve display.\n\n        See Also\n        --------\n        roc_curve : Compute Receiver operating characteristic (ROC) curve.\n        RocCurveDisplay.from_predictions : ROC Curve visualization given the\n            probabilities of scores of a classifier.\n        roc_auc_score : Compute the area under the ROC curve.\n\n        Examples\n        --------\n        >>> import matplotlib.pyplot as plt\n        >>> from sklearn.datasets import make_classification\n        >>> from sklearn.metrics import RocCurveDisplay\n        >>> from sklearn.model_selection import train_test_split\n        >>> from sklearn.svm import SVC\n        >>> X, y = make_classification(random_state=0)\n        >>> X_train, X_test, y_train, y_test = train_test_split(\n        ...     X, y, random_state=0)\n        >>> clf = SVC(random_state=0).fit(X_train, y_train)\n        >>> RocCurveDisplay.from_estimator(\n        ...    clf, X_test, y_test)\n        <...>\n        >>> plt.show()\n        \"\"\"\n        y_score, pos_label, name = cls._validate_and_get_response_values(\n            estimator,\n            X,\n            y,\n            response_method=response_method,\n            pos_label=pos_label,\n            name=name,\n        )\n\n        return cls.from_predictions(\n            y_true=y,\n            y_score=y_score,\n            sample_weight=sample_weight,\n            drop_intermediate=drop_intermediate,\n            pos_label=pos_label,\n            name=name,\n            ax=ax,\n            curve_kwargs=curve_kwargs,\n            plot_chance_level=plot_chance_level,\n            chance_level_kw=chance_level_kw,\n            despine=despine,\n            **kwargs,\n        )\n", "type": "function"}, {"name": "from_predictions", "is_method": true, "class_name": "RocCurveDisplay", "parameters": ["cls", "y_true", "y_score"], "calls": ["_deprecate_y_pred_parameter", "cls._validate_from_predictions_params", "roc_curve", "auc", "cls", "viz.plot"], "code_location": {"file": "roc_curve.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/metrics/_plot", "start_line": 452, "end_line": 607}, "code_snippet": "    def from_predictions(\n        cls,\n        y_true,\n        y_score=None,\n        *,\n        sample_weight=None,\n        drop_intermediate=True,\n        pos_label=None,\n        name=None,\n        ax=None,\n        curve_kwargs=None,\n        plot_chance_level=False,\n        chance_level_kw=None,\n        despine=False,\n        y_pred=\"deprecated\",\n        **kwargs,\n    ):\n        \"\"\"Plot ROC curve given the true and predicted values.\n\n        For general information regarding `scikit-learn` visualization tools,\n        see the :ref:`Visualization Guide <visualizations>`.\n        For guidance on interpreting these plots, refer to the :ref:`Model\n        Evaluation Guide <roc_metrics>`.\n\n        .. versionadded:: 1.0\n\n        Parameters\n        ----------\n        y_true : array-like of shape (n_samples,)\n            True labels.\n\n        y_score : array-like of shape (n_samples,)\n            Target scores, can either be probability estimates of the positive\n            class, confidence values, or non-thresholded measure of decisions\n            (as returned by decision_function on some classifiers).\n\n            .. versionadded:: 1.7\n                `y_pred` has been renamed to `y_score`.\n\n        sample_weight : array-like of shape (n_samples,), default=None\n            Sample weights.\n\n        drop_intermediate : bool, default=True\n            Whether to drop thresholds where the resulting point is collinear\n            with its neighbors in ROC space. This has no effect on the ROC AUC\n            or visual shape of the curve, but reduces the number of plotted\n            points.\n\n        pos_label : int, float, bool or str, default=None\n            The label of the positive class when computing the ROC AUC.\n            When `pos_label=None`, if `y_true` is in {-1, 1} or {0, 1}, `pos_label`\n            is set to 1, otherwise an error will be raised.\n\n        name : str, default=None\n            Name of ROC curve for legend labeling. If `None`, name will be set to\n            `\"Classifier\"`.\n\n        ax : matplotlib axes, default=None\n            Axes object to plot on. If `None`, a new figure and axes is\n            created.\n\n        curve_kwargs : dict, default=None\n            Keywords arguments to be passed to matplotlib's `plot` function.\n\n            .. versionadded:: 1.7\n\n        plot_chance_level : bool, default=False\n            Whether to plot the chance level.\n\n            .. versionadded:: 1.3\n\n        chance_level_kw : dict, default=None\n            Keyword arguments to be passed to matplotlib's `plot` for rendering\n            the chance level line.\n\n            .. versionadded:: 1.3\n\n        despine : bool, default=False\n            Whether to remove the top and right spines from the plot.\n\n            .. versionadded:: 1.6\n\n        y_pred : array-like of shape (n_samples,)\n            Target scores, can either be probability estimates of the positive\n            class, confidence values, or non-thresholded measure of decisions\n            (as returned by decision_function on some classifiers).\n\n            .. deprecated:: 1.7\n                `y_pred` is deprecated and will be removed in 1.9. Use\n                `y_score` instead.\n\n        **kwargs : dict\n            Additional keywords arguments passed to matplotlib `plot` function.\n\n            .. deprecated:: 1.7\n                kwargs is deprecated and will be removed in 1.9. Pass matplotlib\n                arguments to `curve_kwargs` as a dictionary instead.\n\n        Returns\n        -------\n        display : :class:`~sklearn.metrics.RocCurveDisplay`\n            Object that stores computed values.\n\n        See Also\n        --------\n        roc_curve : Compute Receiver operating characteristic (ROC) curve.\n        RocCurveDisplay.from_estimator : ROC Curve visualization given an\n            estimator and some data.\n        roc_auc_score : Compute the area under the ROC curve.\n\n        Examples\n        --------\n        >>> import matplotlib.pyplot as plt\n        >>> from sklearn.datasets import make_classification\n        >>> from sklearn.metrics import RocCurveDisplay\n        >>> from sklearn.model_selection import train_test_split\n        >>> from sklearn.svm import SVC\n        >>> X, y = make_classification(random_state=0)\n        >>> X_train, X_test, y_train, y_test = train_test_split(\n        ...     X, y, random_state=0)\n        >>> clf = SVC(random_state=0).fit(X_train, y_train)\n        >>> y_score = clf.decision_function(X_test)\n        >>> RocCurveDisplay.from_predictions(y_test, y_score)\n        <...>\n        >>> plt.show()\n        \"\"\"\n        y_score = _deprecate_y_pred_parameter(y_score, y_pred, \"1.7\")\n        pos_label_validated, name = cls._validate_from_predictions_params(\n            y_true, y_score, sample_weight=sample_weight, pos_label=pos_label, name=name\n        )\n\n        fpr, tpr, _ = roc_curve(\n            y_true,\n            y_score,\n            pos_label=pos_label,\n            sample_weight=sample_weight,\n            drop_intermediate=drop_intermediate,\n        )\n        roc_auc = auc(fpr, tpr)\n\n        viz = cls(\n            fpr=fpr,\n            tpr=tpr,\n            roc_auc=roc_auc,\n            name=name,\n            pos_label=pos_label_validated,\n        )\n\n        return viz.plot(\n            ax=ax,\n            curve_kwargs=curve_kwargs,\n            plot_chance_level=plot_chance_level,\n            chance_level_kw=chance_level_kw,\n            despine=despine,\n            **kwargs,\n        )\n", "type": "function"}, {"name": "test_roc_curve_chance_level_line", "is_method": false, "class_name": null, "parameters": ["pyplot", "data_binary", "plot_chance_level", "chance_level_kw", "label", "constructor_name"], "calls": ["pytest.mark.parametrize", "pytest.mark.parametrize", "pytest.mark.parametrize", "pytest.mark.parametrize", "LogisticRegression", "lr.fit", "isinstance", "isinstance", "isinstance", "_check_chance_level", "getattr", "RocCurveDisplay.from_estimator", "RocCurveDisplay.from_predictions", "display.line_.get_alpha", "display.ax_.get_legend", "chance_level_kw.get", "text.get_text", "chance_level_kw.get", "display.ax_.get_legend", "legend.get_texts"], "code_location": {"file": "test_roc_curve_display.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/metrics/_plot/tests", "start_line": 643, "end_line": 698}, "code_snippet": "def test_roc_curve_chance_level_line(\n    pyplot,\n    data_binary,\n    plot_chance_level,\n    chance_level_kw,\n    label,\n    constructor_name,\n):\n    \"\"\"Check chance level plotting behavior of `from_predictions`, `from_estimator`.\"\"\"\n    X, y = data_binary\n\n    lr = LogisticRegression()\n    lr.fit(X, y)\n\n    y_score = getattr(lr, \"predict_proba\")(X)\n    y_score = y_score if y_score.ndim == 1 else y_score[:, 1]\n\n    if constructor_name == \"from_estimator\":\n        display = RocCurveDisplay.from_estimator(\n            lr,\n            X,\n            y,\n            curve_kwargs={\"alpha\": 0.8, \"label\": label},\n            plot_chance_level=plot_chance_level,\n            chance_level_kw=chance_level_kw,\n        )\n    else:\n        display = RocCurveDisplay.from_predictions(\n            y,\n            y_score,\n            curve_kwargs={\"alpha\": 0.8, \"label\": label},\n            plot_chance_level=plot_chance_level,\n            chance_level_kw=chance_level_kw,\n        )\n\n    import matplotlib as mpl\n\n    assert isinstance(display.line_, mpl.lines.Line2D)\n    assert display.line_.get_alpha() == 0.8\n    assert isinstance(display.ax_, mpl.axes.Axes)\n    assert isinstance(display.figure_, mpl.figure.Figure)\n\n    _check_chance_level(plot_chance_level, chance_level_kw, display)\n\n    # Checking for legend behaviour\n    if plot_chance_level and chance_level_kw is not None:\n        if label is not None or chance_level_kw.get(\"label\") is not None:\n            legend = display.ax_.get_legend()\n            assert legend is not None  #  Legend should be present if any label is set\n            legend_labels = [text.get_text() for text in legend.get_texts()]\n            if label is not None:\n                assert label in legend_labels\n            if chance_level_kw.get(\"label\") is not None:\n                assert chance_level_kw[\"label\"] in legend_labels\n        else:\n            assert display.ax_.get_legend() is None\n", "type": "function"}, {"name": "from_estimator", "is_method": true, "class_name": "DetCurveDisplay", "parameters": ["cls", "estimator", "X", "y"], "calls": ["cls._validate_and_get_response_values", "cls.from_predictions"], "code_location": {"file": "det_curve.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/metrics/_plot", "start_line": 90, "end_line": 202}, "code_snippet": "    def from_estimator(\n        cls,\n        estimator,\n        X,\n        y,\n        *,\n        sample_weight=None,\n        drop_intermediate=True,\n        response_method=\"auto\",\n        pos_label=None,\n        name=None,\n        ax=None,\n        **kwargs,\n    ):\n        \"\"\"Plot DET curve given an estimator and data.\n\n        For general information regarding `scikit-learn` visualization tools, see\n        the :ref:`Visualization Guide <visualizations>`.\n        For guidance on interpreting these plots, refer to the\n        :ref:`Model Evaluation Guide <det_curve>`.\n\n        .. versionadded:: 1.0\n\n        Parameters\n        ----------\n        estimator : estimator instance\n            Fitted classifier or a fitted :class:`~sklearn.pipeline.Pipeline`\n            in which the last estimator is a classifier.\n\n        X : {array-like, sparse matrix} of shape (n_samples, n_features)\n            Input values.\n\n        y : array-like of shape (n_samples,)\n            Target values.\n\n        sample_weight : array-like of shape (n_samples,), default=None\n            Sample weights.\n\n        drop_intermediate : bool, default=True\n            Whether to drop thresholds where true positives (tp) do not change\n            from the previous or subsequent threshold. All points with the same\n            tp value have the same `fnr` and thus same y coordinate.\n\n            .. versionadded:: 1.7\n\n        response_method : {'predict_proba', 'decision_function', 'auto'} \\\n                default='auto'\n            Specifies whether to use :term:`predict_proba` or\n            :term:`decision_function` as the predicted target response. If set\n            to 'auto', :term:`predict_proba` is tried first and if it does not\n            exist :term:`decision_function` is tried next.\n\n        pos_label : int, float, bool or str, default=None\n            The label of the positive class. By default, `estimators.classes_[1]`\n            is considered as the positive class.\n\n        name : str, default=None\n            Name of DET curve for labeling. If `None`, use the name of the\n            estimator.\n\n        ax : matplotlib axes, default=None\n            Axes object to plot on. If `None`, a new figure and axes is\n            created.\n\n        **kwargs : dict\n            Additional keywords arguments passed to matplotlib `plot` function.\n\n        Returns\n        -------\n        display : :class:`~sklearn.metrics.DetCurveDisplay`\n            Object that stores computed values.\n\n        See Also\n        --------\n        det_curve : Compute error rates for different probability thresholds.\n        DetCurveDisplay.from_predictions : Plot DET curve given the true and\n            predicted labels.\n\n        Examples\n        --------\n        >>> import matplotlib.pyplot as plt\n        >>> from sklearn.datasets import make_classification\n        >>> from sklearn.metrics import DetCurveDisplay\n        >>> from sklearn.model_selection import train_test_split\n        >>> from sklearn.svm import SVC\n        >>> X, y = make_classification(n_samples=1000, random_state=0)\n        >>> X_train, X_test, y_train, y_test = train_test_split(\n        ...     X, y, test_size=0.4, random_state=0)\n        >>> clf = SVC(random_state=0).fit(X_train, y_train)\n        >>> DetCurveDisplay.from_estimator(\n        ...    clf, X_test, y_test)\n        <...>\n        >>> plt.show()\n        \"\"\"\n        y_score, pos_label, name = cls._validate_and_get_response_values(\n            estimator,\n            X,\n            y,\n            response_method=response_method,\n            pos_label=pos_label,\n            name=name,\n        )\n\n        return cls.from_predictions(\n            y_true=y,\n            y_score=y_score,\n            sample_weight=sample_weight,\n            drop_intermediate=drop_intermediate,\n            name=name,\n            ax=ax,\n            pos_label=pos_label,\n            **kwargs,\n        )\n", "type": "function"}, {"name": "from_estimator", "is_method": true, "class_name": "PrecisionRecallDisplay", "parameters": ["cls", "estimator", "X", "y"], "calls": ["cls._validate_and_get_response_values", "cls.from_predictions"], "code_location": {"file": "precision_recall_curve.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/metrics/_plot", "start_line": 264, "end_line": 408}, "code_snippet": "    def from_estimator(\n        cls,\n        estimator,\n        X,\n        y,\n        *,\n        sample_weight=None,\n        drop_intermediate=False,\n        response_method=\"auto\",\n        pos_label=None,\n        name=None,\n        ax=None,\n        plot_chance_level=False,\n        chance_level_kw=None,\n        despine=False,\n        **kwargs,\n    ):\n        \"\"\"Plot precision-recall curve given an estimator and some data.\n\n        For general information regarding `scikit-learn` visualization tools, see\n        the :ref:`Visualization Guide <visualizations>`.\n        For guidance on interpreting these plots, refer to the :ref:`Model\n        Evaluation Guide <precision_recall_f_measure_metrics>`.\n\n        Parameters\n        ----------\n        estimator : estimator instance\n            Fitted classifier or a fitted :class:`~sklearn.pipeline.Pipeline`\n            in which the last estimator is a classifier.\n\n        X : {array-like, sparse matrix} of shape (n_samples, n_features)\n            Input values.\n\n        y : array-like of shape (n_samples,)\n            Target values.\n\n        sample_weight : array-like of shape (n_samples,), default=None\n            Sample weights.\n\n        drop_intermediate : bool, default=False\n            Whether to drop some suboptimal thresholds which would not appear\n            on a plotted precision-recall curve. This is useful in order to\n            create lighter precision-recall curves.\n\n            .. versionadded:: 1.3\n\n        response_method : {'predict_proba', 'decision_function', 'auto'}, \\\n            default='auto'\n            Specifies whether to use :term:`predict_proba` or\n            :term:`decision_function` as the target response. If set to 'auto',\n            :term:`predict_proba` is tried first and if it does not exist\n            :term:`decision_function` is tried next.\n\n        pos_label : int, float, bool or str, default=None\n            The class considered as the positive class when computing the\n            precision and recall metrics. By default, `estimators.classes_[1]`\n            is considered as the positive class.\n\n        name : str, default=None\n            Name for labeling curve. If `None`, no name is used.\n\n        ax : matplotlib axes, default=None\n            Axes object to plot on. If `None`, a new figure and axes is created.\n\n        plot_chance_level : bool, default=False\n            Whether to plot the chance level. The chance level is the prevalence\n            of the positive label computed from the data passed during\n            :meth:`from_estimator` or :meth:`from_predictions` call.\n\n            .. versionadded:: 1.3\n\n        chance_level_kw : dict, default=None\n            Keyword arguments to be passed to matplotlib's `plot` for rendering\n            the chance level line.\n\n            .. versionadded:: 1.3\n\n        despine : bool, default=False\n            Whether to remove the top and right spines from the plot.\n\n            .. versionadded:: 1.6\n\n        **kwargs : dict\n            Keyword arguments to be passed to matplotlib's `plot`.\n\n        Returns\n        -------\n        display : :class:`~sklearn.metrics.PrecisionRecallDisplay`\n\n        See Also\n        --------\n        PrecisionRecallDisplay.from_predictions : Plot precision-recall curve\n            using estimated probabilities or output of decision function.\n\n        Notes\n        -----\n        The average precision (cf. :func:`~sklearn.metrics.average_precision_score`)\n        in scikit-learn is computed without any interpolation. To be consistent\n        with this metric, the precision-recall curve is plotted without any\n        interpolation as well (step-wise style).\n\n        You can change this style by passing the keyword argument\n        `drawstyle=\"default\"`. However, the curve will not be strictly\n        consistent with the reported average precision.\n\n        Examples\n        --------\n        >>> import matplotlib.pyplot as plt\n        >>> from sklearn.datasets import make_classification\n        >>> from sklearn.metrics import PrecisionRecallDisplay\n        >>> from sklearn.model_selection import train_test_split\n        >>> from sklearn.linear_model import LogisticRegression\n        >>> X, y = make_classification(random_state=0)\n        >>> X_train, X_test, y_train, y_test = train_test_split(\n        ...         X, y, random_state=0)\n        >>> clf = LogisticRegression()\n        >>> clf.fit(X_train, y_train)\n        LogisticRegression()\n        >>> PrecisionRecallDisplay.from_estimator(\n        ...    clf, X_test, y_test)\n        <...>\n        >>> plt.show()\n        \"\"\"\n        y_score, pos_label, name = cls._validate_and_get_response_values(\n            estimator,\n            X,\n            y,\n            response_method=response_method,\n            pos_label=pos_label,\n            name=name,\n        )\n\n        return cls.from_predictions(\n            y,\n            y_score,\n            sample_weight=sample_weight,\n            name=name,\n            pos_label=pos_label,\n            drop_intermediate=drop_intermediate,\n            ax=ax,\n            plot_chance_level=plot_chance_level,\n            chance_level_kw=chance_level_kw,\n            despine=despine,\n            **kwargs,\n        )\n", "type": "function"}, {"name": "from_estimator", "is_method": true, "class_name": "CalibrationDisplay", "parameters": ["cls", "estimator", "X", "y"], "calls": ["cls._validate_and_get_response_values", "cls.from_predictions"], "code_location": {"file": "calibration.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn", "start_line": 1450, "end_line": 1571}, "code_snippet": "    def from_estimator(\n        cls,\n        estimator,\n        X,\n        y,\n        *,\n        n_bins=5,\n        strategy=\"uniform\",\n        pos_label=None,\n        name=None,\n        ax=None,\n        ref_line=True,\n        **kwargs,\n    ):\n        \"\"\"Plot calibration curve using a binary classifier and data.\n\n        A calibration curve, also known as a reliability diagram, uses inputs\n        from a binary classifier and plots the average predicted probability\n        for each bin against the fraction of positive classes, on the\n        y-axis.\n\n        Extra keyword arguments will be passed to\n        :func:`matplotlib.pyplot.plot`.\n\n        Read more about calibration in the :ref:`User Guide <calibration>` and\n        more about the scikit-learn visualization API in :ref:`visualizations`.\n\n        .. versionadded:: 1.0\n\n        Parameters\n        ----------\n        estimator : estimator instance\n            Fitted classifier or a fitted :class:`~sklearn.pipeline.Pipeline`\n            in which the last estimator is a classifier. The classifier must\n            have a :term:`predict_proba` method.\n\n        X : {array-like, sparse matrix} of shape (n_samples, n_features)\n            Input values.\n\n        y : array-like of shape (n_samples,)\n            Binary target values.\n\n        n_bins : int, default=5\n            Number of bins to discretize the [0, 1] interval into when\n            calculating the calibration curve. A bigger number requires more\n            data.\n\n        strategy : {'uniform', 'quantile'}, default='uniform'\n            Strategy used to define the widths of the bins.\n\n            - `'uniform'`: The bins have identical widths.\n            - `'quantile'`: The bins have the same number of samples and depend\n              on predicted probabilities.\n\n        pos_label : int, float, bool or str, default=None\n            The positive class when computing the calibration curve.\n            By default, `estimators.classes_[1]` is considered as the\n            positive class.\n\n            .. versionadded:: 1.1\n\n        name : str, default=None\n            Name for labeling curve. If `None`, the name of the estimator is\n            used.\n\n        ax : matplotlib axes, default=None\n            Axes object to plot on. If `None`, a new figure and axes is\n            created.\n\n        ref_line : bool, default=True\n            If `True`, plots a reference line representing a perfectly\n            calibrated classifier.\n\n        **kwargs : dict\n            Keyword arguments to be passed to :func:`matplotlib.pyplot.plot`.\n\n        Returns\n        -------\n        display : :class:`~sklearn.calibration.CalibrationDisplay`.\n            Object that stores computed values.\n\n        See Also\n        --------\n        CalibrationDisplay.from_predictions : Plot calibration curve using true\n            and predicted labels.\n\n        Examples\n        --------\n        >>> import matplotlib.pyplot as plt\n        >>> from sklearn.datasets import make_classification\n        >>> from sklearn.model_selection import train_test_split\n        >>> from sklearn.linear_model import LogisticRegression\n        >>> from sklearn.calibration import CalibrationDisplay\n        >>> X, y = make_classification(random_state=0)\n        >>> X_train, X_test, y_train, y_test = train_test_split(\n        ...     X, y, random_state=0)\n        >>> clf = LogisticRegression(random_state=0)\n        >>> clf.fit(X_train, y_train)\n        LogisticRegression(random_state=0)\n        >>> disp = CalibrationDisplay.from_estimator(clf, X_test, y_test)\n        >>> plt.show()\n        \"\"\"\n        y_prob, pos_label, name = cls._validate_and_get_response_values(\n            estimator,\n            X,\n            y,\n            response_method=\"predict_proba\",\n            pos_label=pos_label,\n            name=name,\n        )\n\n        return cls.from_predictions(\n            y,\n            y_prob,\n            n_bins=n_bins,\n            strategy=strategy,\n            pos_label=pos_label,\n            name=name,\n            ref_line=ref_line,\n            ax=ax,\n            **kwargs,\n        )\n", "type": "function"}, {"name": "_validate_from_predictions_params", "is_method": true, "class_name": "_BinaryClassifierCurveDisplayMixin", "parameters": ["cls", "y_true", "y_pred"], "calls": ["check_matplotlib_support", "check_consistent_length", "_check_pos_label_consistency", "type_of_target", "ValueError", "type_of_target"], "code_location": {"file": "_plotting.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/utils", "start_line": 54, "end_line": 70}, "code_snippet": "    def _validate_from_predictions_params(\n        cls, y_true, y_pred, *, sample_weight=None, pos_label=None, name=None\n    ):\n        check_matplotlib_support(f\"{cls.__name__}.from_predictions\")\n\n        if type_of_target(y_true) != \"binary\":\n            raise ValueError(\n                f\"The target y is not binary. Got {type_of_target(y_true)} type of\"\n                \" target.\"\n            )\n\n        check_consistent_length(y_true, y_pred, sample_weight)\n        pos_label = _check_pos_label_consistency(pos_label, y_true)\n\n        name = name if name is not None else \"Classifier\"\n\n        return pos_label, name\n", "type": "function"}, {"name": "_get_response_values", "is_method": false, "class_name": null, "parameters": ["estimator", "X", "response_method", "pos_label", "return_response_method_used"], "calls": ["is_classifier", "_check_response_method", "type_of_target", "prediction_method", "is_outlier_detector", "_process_predict_proba", "_check_response_method", "ValueError", "_process_decision_function", "prediction_method", "ValueError", "prediction_method", "classes.tolist"], "code_location": {"file": "_response.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/utils", "start_line": 116, "end_line": 246}, "code_snippet": "def _get_response_values(\n    estimator,\n    X,\n    response_method,\n    pos_label=None,\n    return_response_method_used=False,\n):\n    \"\"\"Compute the response values of a classifier, an outlier detector, or a regressor.\n\n    The response values are predictions such that it follows the following shape:\n\n    - for binary classification, it is a 1d array of shape `(n_samples,)`;\n    - for multiclass classification, it is a 2d array of shape `(n_samples, n_classes)`;\n    - for multilabel classification, it is a 2d array of shape `(n_samples, n_outputs)`;\n    - for outlier detection, it is a 1d array of shape `(n_samples,)`;\n    - for regression, it is a 1d array of shape `(n_samples,)`.\n\n    If `estimator` is a binary classifier, also return the label for the\n    effective positive class.\n\n    This utility is used primarily in the displays and the scikit-learn scorers.\n\n    .. versionadded:: 1.3\n\n    Parameters\n    ----------\n    estimator : estimator instance\n        Fitted classifier, outlier detector, or regressor or a\n        fitted :class:`~sklearn.pipeline.Pipeline` in which the last estimator is a\n        classifier, an outlier detector, or a regressor.\n\n    X : {array-like, sparse matrix} of shape (n_samples, n_features)\n        Input values.\n\n    response_method : {\"predict_proba\", \"predict_log_proba\", \"decision_function\", \\\n            \"predict\"} or list of such str\n        Specifies the response method to use get prediction from an estimator\n        (i.e. :term:`predict_proba`, :term:`predict_log_proba`,\n        :term:`decision_function` or :term:`predict`). Possible choices are:\n\n        - if `str`, it corresponds to the name to the method to return;\n        - if a list of `str`, it provides the method names in order of\n          preference. The method returned corresponds to the first method in\n          the list and which is implemented by `estimator`.\n\n    pos_label : int, float, bool or str, default=None\n        The class considered as the positive class when computing\n        the metrics. If `None` and target is 'binary', `estimators.classes_[1]` is\n        considered as the positive class.\n\n    return_response_method_used : bool, default=False\n        Whether to return the response method used to compute the response\n        values.\n\n        .. versionadded:: 1.4\n\n    Returns\n    -------\n    y_pred : ndarray of shape (n_samples,), (n_samples, n_classes) or \\\n            (n_samples, n_outputs)\n        Target scores calculated from the provided `response_method`\n        and `pos_label`.\n\n    pos_label : int, float, bool, str or None\n        The class considered as the positive class when computing\n        the metrics. Returns `None` if `estimator` is a regressor or an outlier\n        detector.\n\n    response_method_used : str\n        The response method used to compute the response values. Only returned\n        if `return_response_method_used` is `True`.\n\n        .. versionadded:: 1.4\n\n    Raises\n    ------\n    ValueError\n        If `pos_label` is not a valid label.\n        If the shape of `y_pred` is not consistent for binary classifier.\n        If the response method can be applied to a classifier only and\n        `estimator` is a regressor.\n    \"\"\"\n    from sklearn.base import is_classifier, is_outlier_detector\n\n    if is_classifier(estimator):\n        prediction_method = _check_response_method(estimator, response_method)\n        classes = estimator.classes_\n        target_type = type_of_target(classes)\n\n        if target_type in (\"binary\", \"multiclass\"):\n            if pos_label is not None and pos_label not in classes.tolist():\n                raise ValueError(\n                    f\"pos_label={pos_label} is not a valid label: It should be \"\n                    f\"one of {classes}\"\n                )\n            elif pos_label is None and target_type == \"binary\":\n                pos_label = classes[-1]\n\n        y_pred = prediction_method(X)\n\n        if prediction_method.__name__ in (\"predict_proba\", \"predict_log_proba\"):\n            y_pred = _process_predict_proba(\n                y_pred=y_pred,\n                target_type=target_type,\n                classes=classes,\n                pos_label=pos_label,\n            )\n        elif prediction_method.__name__ == \"decision_function\":\n            y_pred = _process_decision_function(\n                y_pred=y_pred,\n                target_type=target_type,\n                classes=classes,\n                pos_label=pos_label,\n            )\n    elif is_outlier_detector(estimator):\n        prediction_method = _check_response_method(estimator, response_method)\n        y_pred, pos_label = prediction_method(X), None\n    else:  # estimator is a regressor\n        if response_method != \"predict\":\n            raise ValueError(\n                f\"{estimator.__class__.__name__} should either be a classifier to be \"\n                f\"used with response_method={response_method} or the response_method \"\n                \"should be 'predict'. Got a regressor with response_method=\"\n                f\"{response_method} instead.\"\n            )\n        prediction_method = estimator.predict\n        y_pred, pos_label = prediction_method(X), None\n\n    if return_response_method_used:\n        return y_pred, pos_label, prediction_method.__name__\n    return y_pred, pos_label\n", "type": "function"}, {"name": "from_predictions", "is_method": true, "class_name": "PrecisionRecallDisplay", "parameters": ["cls", "y_true", "y_score"], "calls": ["_deprecate_y_pred_parameter", "cls._validate_from_predictions_params", "precision_recall_curve", "average_precision_score", "Counter", "cls", "viz.plot", "sum", "class_count.values"], "code_location": {"file": "precision_recall_curve.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/metrics/_plot", "start_line": 411, "end_line": 570}, "code_snippet": "    def from_predictions(\n        cls,\n        y_true,\n        y_score=None,\n        *,\n        sample_weight=None,\n        drop_intermediate=False,\n        pos_label=None,\n        name=None,\n        ax=None,\n        plot_chance_level=False,\n        chance_level_kw=None,\n        despine=False,\n        y_pred=\"deprecated\",\n        **kwargs,\n    ):\n        \"\"\"Plot precision-recall curve given binary class predictions.\n\n        For general information regarding `scikit-learn` visualization tools, see\n        the :ref:`Visualization Guide <visualizations>`.\n        For guidance on interpreting these plots, refer to the :ref:`Model\n        Evaluation Guide <precision_recall_f_measure_metrics>`.\n\n        Parameters\n        ----------\n        y_true : array-like of shape (n_samples,)\n            True binary labels.\n\n        y_score : array-like of shape (n_samples,)\n            Estimated probabilities or output of decision function.\n\n            .. versionadded:: 1.8\n                `y_pred` has been renamed to `y_score`.\n\n        sample_weight : array-like of shape (n_samples,), default=None\n            Sample weights.\n\n        drop_intermediate : bool, default=False\n            Whether to drop some suboptimal thresholds which would not appear\n            on a plotted precision-recall curve. This is useful in order to\n            create lighter precision-recall curves.\n\n            .. versionadded:: 1.3\n\n        pos_label : int, float, bool or str, default=None\n            The class considered as the positive class when computing the\n            precision and recall metrics. When `pos_label=None`, if `y_true` is\n            in {-1, 1} or {0, 1}, `pos_label` is set to 1, otherwise an error\n            will be raised.\n\n        name : str, default=None\n            Name for labeling curve. If `None`, name will be set to\n            `\"Classifier\"`.\n\n        ax : matplotlib axes, default=None\n            Axes object to plot on. If `None`, a new figure and axes is created.\n\n        plot_chance_level : bool, default=False\n            Whether to plot the chance level. The chance level is the prevalence\n            of the positive label computed from the data passed during\n            :meth:`from_estimator` or :meth:`from_predictions` call.\n\n            .. versionadded:: 1.3\n\n        chance_level_kw : dict, default=None\n            Keyword arguments to be passed to matplotlib's `plot` for rendering\n            the chance level line.\n\n            .. versionadded:: 1.3\n\n        despine : bool, default=False\n            Whether to remove the top and right spines from the plot.\n\n            .. versionadded:: 1.6\n\n        y_pred : array-like of shape (n_samples,)\n            Estimated probabilities or output of decision function.\n\n            .. deprecated:: 1.8\n                `y_pred` is deprecated and will be removed in 1.10. Use\n                `y_score` instead.\n\n        **kwargs : dict\n            Keyword arguments to be passed to matplotlib's `plot`.\n\n        Returns\n        -------\n        display : :class:`~sklearn.metrics.PrecisionRecallDisplay`\n\n        See Also\n        --------\n        PrecisionRecallDisplay.from_estimator : Plot precision-recall curve\n            using an estimator.\n\n        Notes\n        -----\n        The average precision (cf. :func:`~sklearn.metrics.average_precision_score`)\n        in scikit-learn is computed without any interpolation. To be consistent\n        with this metric, the precision-recall curve is plotted without any\n        interpolation as well (step-wise style).\n\n        You can change this style by passing the keyword argument\n        `drawstyle=\"default\"`. However, the curve will not be strictly\n        consistent with the reported average precision.\n\n        Examples\n        --------\n        >>> import matplotlib.pyplot as plt\n        >>> from sklearn.datasets import make_classification\n        >>> from sklearn.metrics import PrecisionRecallDisplay\n        >>> from sklearn.model_selection import train_test_split\n        >>> from sklearn.linear_model import LogisticRegression\n        >>> X, y = make_classification(random_state=0)\n        >>> X_train, X_test, y_train, y_test = train_test_split(\n        ...         X, y, random_state=0)\n        >>> clf = LogisticRegression()\n        >>> clf.fit(X_train, y_train)\n        LogisticRegression()\n        >>> y_score = clf.predict_proba(X_test)[:, 1]\n        >>> PrecisionRecallDisplay.from_predictions(\n        ...    y_test, y_score)\n        <...>\n        >>> plt.show()\n        \"\"\"\n        y_score = _deprecate_y_pred_parameter(y_score, y_pred, \"1.8\")\n        pos_label, name = cls._validate_from_predictions_params(\n            y_true, y_score, sample_weight=sample_weight, pos_label=pos_label, name=name\n        )\n\n        precision, recall, _ = precision_recall_curve(\n            y_true,\n            y_score,\n            pos_label=pos_label,\n            sample_weight=sample_weight,\n            drop_intermediate=drop_intermediate,\n        )\n        average_precision = average_precision_score(\n            y_true, y_score, pos_label=pos_label, sample_weight=sample_weight\n        )\n\n        class_count = Counter(y_true)\n        prevalence_pos_label = class_count[pos_label] / sum(class_count.values())\n\n        viz = cls(\n            precision=precision,\n            recall=recall,\n            average_precision=average_precision,\n            estimator_name=name,\n            pos_label=pos_label,\n            prevalence_pos_label=prevalence_pos_label,\n        )\n\n        return viz.plot(\n            ax=ax,\n            name=name,\n            plot_chance_level=plot_chance_level,\n            chance_level_kw=chance_level_kw,\n            despine=despine,\n            **kwargs,\n        )\n", "type": "function"}], "retrieved_count": 10, "cost_time": 1.1081757545471191}
{"question": "How does the NearestCentroid class leverage the available_if decorator pattern to conditionally expose decision_function, predict_proba, and predict_log_proba methods only for euclidean metrics, and what are the implications for API consistency across different metric configurations?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"name": "test_multimetric_scorer_calls_method_once_classifier_no_decision", "is_method": false, "class_name": null, "parameters": ["scorers"], "calls": ["pytest.mark.parametrize", "MockKNeighborsClassifier", "clf.fit", "_check_multimetric_scoring", "_MultimetricScorer", "scorer", "np.array", "np.array", "predict_proba", "make_scorer", "make_scorer", "super"], "code_location": {"file": "test_score_objects.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/metrics/tests", "start_line": 802, "end_line": 821}, "code_snippet": "def test_multimetric_scorer_calls_method_once_classifier_no_decision(scorers):\n    predict_proba_call_cnt = 0\n\n    class MockKNeighborsClassifier(KNeighborsClassifier):\n        def predict_proba(self, X):\n            nonlocal predict_proba_call_cnt\n            predict_proba_call_cnt += 1\n            return super().predict_proba(X)\n\n    X, y = np.array([[1], [1], [0], [0], [0]]), np.array([0, 1, 1, 1, 0])\n\n    # no decision function\n    clf = MockKNeighborsClassifier(n_neighbors=1)\n    clf.fit(X, y)\n\n    scorer_dict = _check_multimetric_scoring(clf, scorers)\n    scorer = _MultimetricScorer(scorers=scorer_dict)\n    scorer(clf, X, y)\n\n    assert predict_proba_call_cnt == 1\n", "type": "function"}, {"name": "test_available_if", "is_method": false, "class_name": null, "parameters": [], "calls": ["hasattr", "AvailableParameterEstimator", "hasattr", "AvailableParameterEstimator"], "code_location": {"file": "test_metaestimators.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/utils/tests", "start_line": 33, "end_line": 35}, "code_snippet": "def test_available_if():\n    assert hasattr(AvailableParameterEstimator(), \"available_func\")\n    assert not hasattr(AvailableParameterEstimator(available=False), \"available_func\")\n", "type": "function"}, {"name": "test_hasattr_predict_proba", "is_method": false, "class_name": null, "parameters": ["global_random_seed"], "calls": ["get_iris_dataset", "svm.SVC", "hasattr", "G.fit", "hasattr", "svm.SVC", "G.fit", "hasattr", "hasattr", "hasattr", "pytest.raises", "G.predict_proba"], "code_location": {"file": "test_svm.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/svm/tests", "start_line": 1175, "end_line": 1198}, "code_snippet": "def test_hasattr_predict_proba(global_random_seed):\n    iris = get_iris_dataset(global_random_seed)\n\n    # Method must be (un)available before or after fit, switched by\n    # `probability` param\n\n    G = svm.SVC(probability=True)\n    assert hasattr(G, \"predict_proba\")\n    G.fit(iris.data, iris.target)\n    assert hasattr(G, \"predict_proba\")\n\n    G = svm.SVC(probability=False)\n    assert not hasattr(G, \"predict_proba\")\n    G.fit(iris.data, iris.target)\n    assert not hasattr(G, \"predict_proba\")\n\n    # Switching to `probability=True` after fitting should make\n    # predict_proba available, but calling it must not work:\n    G.probability = True\n    assert hasattr(G, \"predict_proba\")\n    msg = \"predict_proba is not available when fitted with probability=False\"\n\n    with pytest.raises(NotFittedError, match=msg):\n        G.predict_proba(iris.data)\n", "type": "function"}, {"name": "test_hasattr_prediction", "is_method": false, "class_name": null, "parameters": [], "calls": ["neighbors.LocalOutlierFactor", "clf.fit", "hasattr", "hasattr", "hasattr", "neighbors.LocalOutlierFactor", "clf.fit", "hasattr", "hasattr", "hasattr", "hasattr", "hasattr"], "code_location": {"file": "test_lof.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/neighbors/tests", "start_line": 204, "end_line": 222}, "code_snippet": "def test_hasattr_prediction():\n    # check availability of prediction methods depending on novelty value.\n    X = [[1, 1], [1, 2], [2, 1]]\n\n    # when novelty=True\n    clf = neighbors.LocalOutlierFactor(novelty=True)\n    clf.fit(X)\n    assert hasattr(clf, \"predict\")\n    assert hasattr(clf, \"decision_function\")\n    assert hasattr(clf, \"score_samples\")\n    assert not hasattr(clf, \"fit_predict\")\n\n    # when novelty=False\n    clf = neighbors.LocalOutlierFactor(novelty=False)\n    clf.fit(X)\n    assert hasattr(clf, \"fit_predict\")\n    assert not hasattr(clf, \"predict\")\n    assert not hasattr(clf, \"decision_function\")\n    assert not hasattr(clf, \"score_samples\")\n", "type": "function"}, {"name": "test_kneighbors_classifier_predict_proba", "is_method": false, "class_name": null, "parameters": ["global_dtype"], "calls": ["astype", "np.array", "neighbors.KNeighborsClassifier", "cls.fit", "cls.predict_proba", "assert_array_equal", "cls.fit", "cls.predict_proba", "assert_array_equal", "neighbors.KNeighborsClassifier", "cls.fit", "cls.predict_proba", "np.array", "assert_allclose", "np.array", "y.astype", "np.array", "np.array"], "code_location": {"file": "test_neighbors.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/neighbors/tests", "start_line": 717, "end_line": 749}, "code_snippet": "def test_kneighbors_classifier_predict_proba(global_dtype):\n    # Test KNeighborsClassifier.predict_proba() method\n    X = np.array(\n        [[0, 2, 0], [0, 2, 1], [2, 0, 0], [2, 2, 0], [0, 0, 2], [0, 0, 1]]\n    ).astype(global_dtype, copy=False)\n    y = np.array([4, 4, 5, 5, 1, 1])\n    cls = neighbors.KNeighborsClassifier(n_neighbors=3, p=1)  # cityblock dist\n    cls.fit(X, y)\n    y_prob = cls.predict_proba(X)\n    real_prob = (\n        np.array(\n            [\n                [0, 2, 1],\n                [1, 2, 0],\n                [1, 0, 2],\n                [0, 1, 2],\n                [2, 1, 0],\n                [2, 1, 0],\n            ]\n        )\n        / 3.0\n    )\n    assert_array_equal(real_prob, y_prob)\n    # Check that it also works with non integer labels\n    cls.fit(X, y.astype(str))\n    y_prob = cls.predict_proba(X)\n    assert_array_equal(real_prob, y_prob)\n    # Check that it works with weights='distance'\n    cls = neighbors.KNeighborsClassifier(n_neighbors=2, p=1, weights=\"distance\")\n    cls.fit(X, y)\n    y_prob = cls.predict_proba(np.array([[0, 2, 0], [2, 2, 2]]))\n    real_prob = np.array([[0, 1, 0], [0, 0.4, 0.6]])\n    assert_allclose(real_prob, y_prob)\n", "type": "function"}, {"name": "test_metric_params_interface", "is_method": false, "class_name": null, "parameters": [], "calls": ["rng.rand", "rng.randint", "neighbors.KNeighborsClassifier", "pytest.warns", "est.fit"], "code_location": {"file": "test_neighbors.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/neighbors/tests", "start_line": 1858, "end_line": 1863}, "code_snippet": "def test_metric_params_interface():\n    X = rng.rand(5, 5)\n    y = rng.randint(0, 2, 5)\n    est = neighbors.KNeighborsClassifier(metric_params={\"p\": 3})\n    with pytest.warns(SyntaxWarning):\n        est.fit(X, y)\n", "type": "function"}, {"name": "test_manhattan_metric", "is_method": false, "class_name": null, "parameters": ["csr_container"], "calls": ["pytest.mark.parametrize", "csr_container", "NearestCentroid", "clf.fit", "clf.fit", "assert_array_equal", "assert_array_equal"], "code_location": {"file": "test_nearest_centroid.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/neighbors/tests", "start_line": 168, "end_line": 177}, "code_snippet": "def test_manhattan_metric(csr_container):\n    # Test the manhattan metric.\n    X_csr = csr_container(X)\n\n    clf = NearestCentroid(metric=\"manhattan\")\n    clf.fit(X, y)\n    dense_centroid = clf.centroids_\n    clf.fit(X_csr, y)\n    assert_array_equal(clf.centroids_, dense_centroid)\n    assert_array_equal(dense_centroid, [[-1, -1], [1, 1]])\n", "type": "function"}, {"name": "test_sgd_predict_proba_method_access", "is_method": false, "class_name": null, "parameters": ["klass"], "calls": ["pytest.mark.parametrize", "SGDClassifier", "hasattr", "hasattr", "format", "isinstance", "isinstance", "hasattr", "hasattr", "pytest.raises", "str", "pytest.raises", "str"], "code_location": {"file": "test_sgd.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/linear_model/tests", "start_line": 766, "end_line": 796}, "code_snippet": "def test_sgd_predict_proba_method_access(klass):\n    # Checks that SGDClassifier predict_proba and predict_log_proba methods\n    # can either be accessed or raise an appropriate error message\n    # otherwise. See\n    # https://github.com/scikit-learn/scikit-learn/issues/10938 for more\n    # details.\n    for loss in linear_model.SGDClassifier.loss_functions:\n        clf = SGDClassifier(loss=loss)\n        if loss in (\"log_loss\", \"modified_huber\"):\n            assert hasattr(clf, \"predict_proba\")\n            assert hasattr(clf, \"predict_log_proba\")\n        else:\n            inner_msg = \"probability estimates are not available for loss={!r}\".format(\n                loss\n            )\n            assert not hasattr(clf, \"predict_proba\")\n            assert not hasattr(clf, \"predict_log_proba\")\n            with pytest.raises(\n                AttributeError, match=\"has no attribute 'predict_proba'\"\n            ) as exec_info:\n                clf.predict_proba\n\n            assert isinstance(exec_info.value.__cause__, AttributeError)\n            assert inner_msg in str(exec_info.value.__cause__)\n\n            with pytest.raises(\n                AttributeError, match=\"has no attribute 'predict_log_proba'\"\n            ) as exec_info:\n                clf.predict_log_proba\n            assert isinstance(exec_info.value.__cause__, AttributeError)\n            assert inner_msg in str(exec_info.value.__cause__)\n", "type": "function"}, {"name": "_check_euclidean_metric", "is_method": true, "class_name": "NearestCentroid", "parameters": ["self"], "calls": [], "code_location": {"file": "_nearest_centroid.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/neighbors", "start_line": 337, "end_line": 338}, "code_snippet": "    def _check_euclidean_metric(self):\n        return self.metric == \"euclidean\"\n", "type": "function"}, {"name": "_decision_function", "is_method": true, "class_name": "NearestCentroid", "parameters": ["self", "X"], "calls": ["check_is_fitted", "validate_data", "np.empty", "self.centroids_.copy", "range", "ravel", "np.squeeze", "pairwise_distances", "np.log"], "code_location": {"file": "_nearest_centroid.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/neighbors", "start_line": 309, "end_line": 335}, "code_snippet": "    def _decision_function(self, X):\n        # return discriminant scores, see eq. (18.2) p. 652 of the ESL.\n        check_is_fitted(self, \"centroids_\")\n\n        X_normalized = validate_data(\n            self, X, copy=True, reset=False, accept_sparse=\"csr\", dtype=np.float64\n        )\n\n        discriminant_score = np.empty(\n            (X_normalized.shape[0], self.classes_.size), dtype=np.float64\n        )\n\n        mask = self.within_class_std_dev_ != 0\n        X_normalized[:, mask] /= self.within_class_std_dev_[mask]\n        centroids_normalized = self.centroids_.copy()\n        centroids_normalized[:, mask] /= self.within_class_std_dev_[mask]\n\n        for class_idx in range(self.classes_.size):\n            distances = pairwise_distances(\n                X_normalized, centroids_normalized[[class_idx]], metric=self.metric\n            ).ravel()\n            distances **= 2\n            discriminant_score[:, class_idx] = np.squeeze(\n                -distances + 2.0 * np.log(self.class_prior_[class_idx])\n            )\n\n        return discriminant_score\n", "type": "function"}], "retrieved_count": 10, "cost_time": 1.0942814350128174}
{"question": "How does _get_visual_block implement the extraction and validation of parallel estimator metadata from a FeatureUnion's transformer_list structure?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"name": "test_get_visual_block_feature_union", "is_method": false, "class_name": null, "parameters": [], "calls": ["FeatureUnion", "_get_visual_block", "tuple", "PCA", "TruncatedSVD"], "code_location": {"file": "test_estimator.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/utils/_repr_html/tests", "start_line": 111, "end_line": 119}, "code_snippet": "def test_get_visual_block_feature_union():\n    f_union = FeatureUnion([(\"pca\", PCA()), (\"svd\", TruncatedSVD())])\n    est_html_info = _get_visual_block(f_union)\n    assert est_html_info.kind == \"parallel\"\n    assert est_html_info.names == (\"pca\", \"svd\")\n    assert est_html_info.estimators == tuple(\n        trans[1] for trans in f_union.transformer_list\n    )\n    assert est_html_info.name_details == (None, None)\n", "type": "function"}, {"name": "_sk_visual_block_", "is_method": true, "class_name": "FeatureUnion", "parameters": ["self"], "calls": ["zip", "_VisualBlock"], "code_location": {"file": "pipeline.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn", "start_line": 2082, "end_line": 2084}, "code_snippet": "    def _sk_visual_block_(self):\n        names, transformers = zip(*self.transformer_list)\n        return _VisualBlock(\"parallel\", transformers, names=names)\n", "type": "function"}, {"name": "_sk_visual_block_", "is_method": true, "class_name": "_BaseVoting", "parameters": ["self"], "calls": ["zip", "_VisualBlock"], "code_location": {"file": "_voting.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/ensemble", "start_line": 165, "end_line": 167}, "code_snippet": "    def _sk_visual_block_(self):\n        names, estimators = zip(*self.estimators)\n        return _VisualBlock(\"parallel\", estimators, names=names)\n", "type": "function"}, {"name": "test_get_visual_block_column_transformer", "is_method": false, "class_name": null, "parameters": [], "calls": ["ColumnTransformer", "_get_visual_block", "tuple", "PCA"], "code_location": {"file": "test_estimator.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/utils/_repr_html/tests", "start_line": 133, "end_line": 141}, "code_snippet": "def test_get_visual_block_column_transformer():\n    ct = ColumnTransformer(\n        [(\"pca\", PCA(), [\"num1\", \"num2\"]), (\"svd\", TruncatedSVD, [0, 3])]\n    )\n    est_html_info = _get_visual_block(ct)\n    assert est_html_info.kind == \"parallel\"\n    assert est_html_info.estimators == tuple(trans[1] for trans in ct.transformers)\n    assert est_html_info.names == (\"pca\", \"svd\")\n    assert est_html_info.name_details == ([\"num1\", \"num2\"], [0, 3])\n", "type": "function"}, {"name": "_sk_visual_block_", "is_method": true, "class_name": "ColumnTransformer", "parameters": ["self"], "calls": ["zip", "_VisualBlock", "isinstance", "hasattr", "chain", "chain", "hasattr", "tolist", "all", "isinstance"], "code_location": {"file": "_column_transformer.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/compose", "start_line": 1226, "end_line": 1246}, "code_snippet": "    def _sk_visual_block_(self):\n        if isinstance(self.remainder, str) and self.remainder == \"drop\":\n            transformers = self.transformers\n        elif hasattr(self, \"_remainder\"):\n            remainder_columns = self._remainder[2]\n            if (\n                hasattr(self, \"feature_names_in_\")\n                and remainder_columns\n                and not all(isinstance(col, str) for col in remainder_columns)\n            ):\n                remainder_columns = self.feature_names_in_[remainder_columns].tolist()\n            transformers = chain(\n                self.transformers, [(\"remainder\", self.remainder, remainder_columns)]\n            )\n        else:\n            transformers = chain(self.transformers, [(\"remainder\", self.remainder, \"\")])\n\n        names, transformers, name_details = zip(*transformers)\n        return _VisualBlock(\n            \"parallel\", transformers, names=names, name_details=name_details\n        )\n", "type": "function"}, {"name": "test_get_visual_block_voting", "is_method": false, "class_name": null, "parameters": [], "calls": ["VotingClassifier", "_get_visual_block", "tuple", "LogisticRegression", "MLPClassifier"], "code_location": {"file": "test_estimator.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/utils/_repr_html/tests", "start_line": 122, "end_line": 130}, "code_snippet": "def test_get_visual_block_voting():\n    clf = VotingClassifier(\n        [(\"log_reg\", LogisticRegression()), (\"mlp\", MLPClassifier())]\n    )\n    est_html_info = _get_visual_block(clf)\n    assert est_html_info.kind == \"parallel\"\n    assert est_html_info.estimators == tuple(trans[1] for trans in clf.estimators)\n    assert est_html_info.names == (\"log_reg\", \"mlp\")\n    assert est_html_info.name_details == (None, None)\n", "type": "function"}, {"name": "_sk_visual_block_with_final_estimator", "is_method": true, "class_name": "_BaseStacking", "parameters": ["self", "final_estimator"], "calls": ["zip", "_VisualBlock", "_VisualBlock", "_VisualBlock"], "code_location": {"file": "_stacking.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/ensemble", "start_line": 375, "end_line": 384}, "code_snippet": "    def _sk_visual_block_with_final_estimator(self, final_estimator):\n        names, estimators = zip(*self.estimators)\n        parallel = _VisualBlock(\"parallel\", estimators, names=names, dash_wrapped=False)\n\n        # final estimator is wrapped in a parallel block to show the label:\n        # 'final_estimator' in the html repr\n        final_block = _VisualBlock(\n            \"parallel\", [final_estimator], names=[\"final_estimator\"], dash_wrapped=False\n        )\n        return _VisualBlock(\"serial\", (parallel, final_block), dash_wrapped=False)\n", "type": "function"}, {"name": "_sk_visual_block_", "is_method": true, "class_name": "BaseSearchCV", "parameters": ["self"], "calls": ["hasattr", "_VisualBlock", "str"], "code_location": {"file": "_search.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/model_selection", "start_line": 1234, "end_line": 1245}, "code_snippet": "    def _sk_visual_block_(self):\n        if hasattr(self, \"best_estimator_\"):\n            key, estimator = \"best_estimator_\", self.best_estimator_\n        else:\n            key, estimator = \"estimator\", self.estimator\n\n        return _VisualBlock(\n            \"parallel\",\n            [estimator],\n            names=[f\"{key}: {estimator.__class__.__name__}\"],\n            name_details=[str(estimator)],\n        )\n", "type": "function"}, {"name": "_sk_visual_block_", "is_method": true, "class_name": "Pipeline", "parameters": ["self"], "calls": ["zip", "_VisualBlock", "str", "_get_name"], "code_location": {"file": "pipeline.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn", "start_line": 1312, "end_line": 1329}, "code_snippet": "    def _sk_visual_block_(self):\n        def _get_name(name, est):\n            if est is None or est == \"passthrough\":\n                return f\"{name}: passthrough\"\n            # Is an estimator\n            return f\"{name}: {est.__class__.__name__}\"\n\n        names, estimators = zip(\n            *[(_get_name(name, est), est) for name, est in self.steps]\n        )\n        name_details = [str(est) for est in estimators]\n        return _VisualBlock(\n            \"serial\",\n            estimators,\n            names=names,\n            name_details=name_details,\n            dash_wrapped=False,\n        )\n", "type": "function"}, {"name": "_get_visual_block", "is_method": false, "class_name": null, "parameters": ["estimator"], "calls": ["hasattr", "isinstance", "_VisualBlock", "_VisualBlock", "hasattr", "estimator._sk_visual_block_", "_VisualBlock", "isclass", "_VisualBlock", "str", "_VisualBlock", "items", "hasattr", "hasattr", "str", "estimator.get_params", "isclass", "str"], "code_location": {"file": "estimator.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/utils/_repr_html", "start_line": 223, "end_line": 263}, "code_snippet": "def _get_visual_block(estimator):\n    \"\"\"Generate information about how to display an estimator.\"\"\"\n    if hasattr(estimator, \"_sk_visual_block_\"):\n        try:\n            return estimator._sk_visual_block_()\n        except Exception:\n            return _VisualBlock(\n                \"single\",\n                estimator,\n                names=estimator.__class__.__name__,\n                name_details=str(estimator),\n            )\n\n    if isinstance(estimator, str):\n        return _VisualBlock(\n            \"single\", estimator, names=estimator, name_details=estimator\n        )\n    elif estimator is None:\n        return _VisualBlock(\"single\", estimator, names=\"None\", name_details=\"None\")\n\n    # check if estimator looks like a meta estimator (wraps estimators)\n    if hasattr(estimator, \"get_params\") and not isclass(estimator):\n        estimators = [\n            (key, est)\n            for key, est in estimator.get_params(deep=False).items()\n            if hasattr(est, \"get_params\") and hasattr(est, \"fit\") and not isclass(est)\n        ]\n        if estimators:\n            return _VisualBlock(\n                \"parallel\",\n                [est for _, est in estimators],\n                names=[f\"{key}: {est.__class__.__name__}\" for key, est in estimators],\n                name_details=[str(est) for _, est in estimators],\n            )\n\n    return _VisualBlock(\n        \"single\",\n        estimator,\n        names=estimator.__class__.__name__,\n        name_details=str(estimator),\n    )\n", "type": "function"}], "retrieved_count": 10, "cost_time": 1.112940788269043}
{"question": "How does AdditiveChi2Sampler's design decouple the mathematical transformation logic from input validation and sparse/dense matrix handling to maintain separation of concerns?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"name": "test_additive_chi2_sampler", "is_method": false, "class_name": null, "parameters": ["csr_container"], "calls": ["pytest.mark.parametrize", "copy", "copy", "large_kernel.sum", "AdditiveChi2Sampler", "transform.fit_transform", "transform.transform", "np.dot", "assert_array_almost_equal", "transform.fit_transform", "transform.transform", "assert_array_equal", "assert_array_equal", "Y.copy", "csr_container", "csr_container", "X_sp_trans.toarray", "Y_sp_trans.toarray", "pytest.raises", "transform.fit"], "code_location": {"file": "test_kernel_approximation.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/tests", "start_line": 98, "end_line": 131}, "code_snippet": "def test_additive_chi2_sampler(csr_container):\n    # test that AdditiveChi2Sampler approximates kernel on random data\n\n    # compute exact kernel\n    # abbreviations for easier formula\n    X_ = X[:, np.newaxis, :].copy()\n    Y_ = Y[np.newaxis, :, :].copy()\n\n    large_kernel = 2 * X_ * Y_ / (X_ + Y_)\n\n    # reduce to n_samples_x x n_samples_y by summing over features\n    kernel = large_kernel.sum(axis=2)\n\n    # approximate kernel mapping\n    transform = AdditiveChi2Sampler(sample_steps=3)\n    X_trans = transform.fit_transform(X)\n    Y_trans = transform.transform(Y)\n\n    kernel_approx = np.dot(X_trans, Y_trans.T)\n\n    assert_array_almost_equal(kernel, kernel_approx, 1)\n\n    X_sp_trans = transform.fit_transform(csr_container(X))\n    Y_sp_trans = transform.transform(csr_container(Y))\n\n    assert_array_equal(X_trans, X_sp_trans.toarray())\n    assert_array_equal(Y_trans, Y_sp_trans.toarray())\n\n    # test error is raised on negative input\n    Y_neg = Y.copy()\n    Y_neg[0, 0] = -1\n    msg = \"Negative values in data passed to\"\n    with pytest.raises(ValueError, match=msg):\n        transform.fit(Y_neg)\n", "type": "function"}, {"name": "test_input_validation", "is_method": false, "class_name": null, "parameters": ["csr_container"], "calls": ["pytest.mark.parametrize", "transform", "transform", "transform", "csr_container", "transform", "fit", "fit", "fit", "fit", "AdditiveChi2Sampler", "SkewedChi2Sampler", "RBFSampler", "RBFSampler"], "code_location": {"file": "test_kernel_approximation.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/tests", "start_line": 302, "end_line": 311}, "code_snippet": "def test_input_validation(csr_container):\n    # Regression test: kernel approx. transformers should work on lists\n    # No assertions; the old versions would simply crash\n    X = [[1, 2], [3, 4], [5, 6]]\n    AdditiveChi2Sampler().fit(X).transform(X)\n    SkewedChi2Sampler().fit(X).transform(X)\n    RBFSampler().fit(X).transform(X)\n\n    X = csr_container(X)\n    RBFSampler().fit(X).transform(X)\n", "type": "function"}, {"name": "_transform_sparse", "is_method": true, "class_name": "AdditiveChi2Sampler", "parameters": ["X", "sample_steps", "sample_interval"], "calls": ["X.indices.copy", "X.indptr.copy", "np.sqrt", "sp.csr_matrix", "range", "sp.hstack", "np.log", "np.sqrt", "sp.csr_matrix", "X_new.append", "sp.csr_matrix", "X_new.append", "np.cos", "np.sin", "np.cosh"], "code_location": {"file": "kernel_approximation.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn", "start_line": 805, "end_line": 833}, "code_snippet": "    def _transform_sparse(X, sample_steps, sample_interval):\n        indices = X.indices.copy()\n        indptr = X.indptr.copy()\n\n        data_step = np.sqrt(X.data * sample_interval)\n        X_step = sp.csr_matrix(\n            (data_step, indices, indptr), shape=X.shape, dtype=X.dtype, copy=False\n        )\n        X_new = [X_step]\n\n        log_step_nz = sample_interval * np.log(X.data)\n        step_nz = 2 * X.data * sample_interval\n\n        for j in range(1, sample_steps):\n            factor_nz = np.sqrt(step_nz / np.cosh(np.pi * j * sample_interval))\n\n            data_step = factor_nz * np.cos(j * log_step_nz)\n            X_step = sp.csr_matrix(\n                (data_step, indices, indptr), shape=X.shape, dtype=X.dtype, copy=False\n            )\n            X_new.append(X_step)\n\n            data_step = factor_nz * np.sin(j * log_step_nz)\n            X_step = sp.csr_matrix(\n                (data_step, indices, indptr), shape=X.shape, dtype=X.dtype, copy=False\n            )\n            X_new.append(X_step)\n\n        return sp.hstack(X_new)\n", "type": "function"}, {"name": "_transform_dense", "is_method": true, "class_name": "AdditiveChi2Sampler", "parameters": ["X", "sample_steps", "sample_interval"], "calls": ["np.zeros_like", "np.sqrt", "range", "np.hstack", "np.log", "np.sqrt", "np.zeros_like", "X_new.append", "np.zeros_like", "X_new.append", "np.cos", "np.sin", "np.cosh"], "code_location": {"file": "kernel_approximation.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn", "start_line": 779, "end_line": 802}, "code_snippet": "    def _transform_dense(X, sample_steps, sample_interval):\n        non_zero = X != 0.0\n        X_nz = X[non_zero]\n\n        X_step = np.zeros_like(X)\n        X_step[non_zero] = np.sqrt(X_nz * sample_interval)\n\n        X_new = [X_step]\n\n        log_step_nz = sample_interval * np.log(X_nz)\n        step_nz = 2 * X_nz * sample_interval\n\n        for j in range(1, sample_steps):\n            factor_nz = np.sqrt(step_nz / np.cosh(np.pi * j * sample_interval))\n\n            X_step = np.zeros_like(X)\n            X_step[non_zero] = factor_nz * np.cos(j * log_step_nz)\n            X_new.append(X_step)\n\n            X_step = np.zeros_like(X)\n            X_step[non_zero] = factor_nz * np.sin(j * log_step_nz)\n            X_new.append(X_step)\n\n        return np.hstack(X_new)\n", "type": "function"}, {"name": "_transform", "is_method": true, "class_name": "_BaseKMeans", "parameters": ["self", "X"], "calls": ["euclidean_distances"], "code_location": {"file": "_kmeans.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/cluster", "start_line": 1152, "end_line": 1154}, "code_snippet": "    def _transform(self, X):\n        \"\"\"Guts of transform method; no input validation.\"\"\"\n        return euclidean_distances(X, self.cluster_centers_)\n", "type": "function"}, {"name": "_transform", "is_method": true, "class_name": "DictVectorizer", "parameters": ["self", "X", "fitting"], "calls": ["array", "np.frombuffer", "sp.csr_matrix", "isinstance", "x.items", "indptr.append", "len", "ValueError", "len", "feature_names.sort", "np.empty", "enumerate", "result_matrix.sort_indices", "result_matrix.toarray", "array", "isinstance", "len", "len", "len", "isinstance", "len", "feature_names.append", "indices.append", "values.append", "isinstance", "self._add_iterable_element", "TypeError", "self.dtype", "isinstance", "type", "type"], "code_location": {"file": "_dict_vectorizer.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/feature_extraction", "start_line": 195, "end_line": 292}, "code_snippet": "    def _transform(self, X, fitting):\n        # Sanity check: Python's array has no way of explicitly requesting the\n        # signed 32-bit integers that scipy.sparse needs, so we use the next\n        # best thing: typecode \"i\" (int). However, if that gives larger or\n        # smaller integers than 32-bit ones, np.frombuffer screws up.\n        assert array(\"i\").itemsize == 4, (\n            \"sizeof(int) != 4 on your platform; please report this at\"\n            \" https://github.com/scikit-learn/scikit-learn/issues and\"\n            \" include the output from platform.platform() in your bug report\"\n        )\n\n        dtype = self.dtype\n        if fitting:\n            feature_names = []\n            vocab = {}\n        else:\n            feature_names = self.feature_names_\n            vocab = self.vocabulary_\n\n        transforming = True\n\n        # Process everything as sparse regardless of setting\n        X = [X] if isinstance(X, Mapping) else X\n\n        indices = array(\"i\")\n        indptr = [0]\n        # XXX we could change values to an array.array as well, but it\n        # would require (heuristic) conversion of dtype to typecode...\n        values = []\n\n        # collect all the possible feature names and build sparse matrix at\n        # same time\n        for x in X:\n            for f, v in x.items():\n                if isinstance(v, str):\n                    feature_name = \"%s%s%s\" % (f, self.separator, v)\n                    v = 1\n                elif isinstance(v, Number) or (v is None):\n                    feature_name = f\n                elif not isinstance(v, Mapping) and isinstance(v, Iterable):\n                    feature_name = None\n                    self._add_iterable_element(\n                        f,\n                        v,\n                        feature_names,\n                        vocab,\n                        fitting=fitting,\n                        transforming=transforming,\n                        indices=indices,\n                        values=values,\n                    )\n                else:\n                    raise TypeError(\n                        f\"Unsupported value Type {type(v)} \"\n                        f\"for {f}: {v}.\\n\"\n                        f\"{type(v)} objects are not supported.\"\n                    )\n\n                if feature_name is not None:\n                    if fitting and feature_name not in vocab:\n                        vocab[feature_name] = len(feature_names)\n                        feature_names.append(feature_name)\n\n                    if feature_name in vocab:\n                        indices.append(vocab[feature_name])\n                        values.append(self.dtype(v))\n\n            indptr.append(len(indices))\n\n        if len(indptr) == 1:\n            raise ValueError(\"Sample sequence X is empty.\")\n\n        indices = np.frombuffer(indices, dtype=np.intc)\n        shape = (len(indptr) - 1, len(vocab))\n\n        result_matrix = sp.csr_matrix(\n            (values, indices, indptr), shape=shape, dtype=dtype\n        )\n\n        # Sort everything if asked\n        if fitting and self.sort:\n            feature_names.sort()\n            map_index = np.empty(len(feature_names), dtype=np.int32)\n            for new_val, f in enumerate(feature_names):\n                map_index[new_val] = vocab[f]\n                vocab[f] = new_val\n            result_matrix = result_matrix[:, map_index]\n\n        if self.sparse:\n            result_matrix.sort_indices()\n        else:\n            result_matrix = result_matrix.toarray()\n\n        if fitting:\n            self.feature_names_ = feature_names\n            self.vocabulary_ = vocab\n\n        return result_matrix\n", "type": "function"}, {"name": "_transform", "is_method": true, "class_name": "_BasePCA", "parameters": ["self", "X", "xp", "x_is_centered"], "calls": ["xp.sqrt", "xp.reshape", "xp.finfo"], "code_location": {"file": "_base.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/decomposition", "start_line": 151, "end_line": 169}, "code_snippet": "    def _transform(self, X, xp, x_is_centered=False):\n        X_transformed = X @ self.components_.T\n        if not x_is_centered:\n            # Apply the centering after the projection.\n            # For dense X this avoids copying or mutating the data passed by\n            # the caller.\n            # For sparse X it keeps sparsity and avoids having to wrap X into\n            # a linear operator.\n            X_transformed -= xp.reshape(self.mean_, (1, -1)) @ self.components_.T\n        if self.whiten:\n            # For some solvers (such as \"arpack\" and \"covariance_eigh\"), on\n            # rank deficient data, some components can have a variance\n            # arbitrarily close to zero, leading to non-finite results when\n            # whitening. To avoid this problem we clip the variance below.\n            scale = xp.sqrt(self.explained_variance_)\n            min_scale = xp.finfo(scale.dtype).eps\n            scale[scale < min_scale] = min_scale\n            X_transformed /= scale\n        return X_transformed\n", "type": "function"}, {"name": "_randomized_range_finder", "is_method": false, "class_name": null, "parameters": ["A"], "calls": ["get_namespace", "check_random_state", "xp.asarray", "range", "qr_normalizer", "random_state.normal", "hasattr", "xp.isdtype", "xp.astype", "xp.asarray", "partial", "partial", "normalizer", "normalizer", "ValueError", "partial", "device", "warnings.warn"], "code_location": {"file": "extmath.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/utils", "start_line": 293, "end_line": 363}, "code_snippet": "def _randomized_range_finder(\n    A, *, size, n_iter, power_iteration_normalizer=\"auto\", random_state=None\n):\n    \"\"\"Body of randomized_range_finder without input validation.\"\"\"\n    xp, is_array_api_compliant = get_namespace(A)\n    random_state = check_random_state(random_state)\n\n    # Generating normal random vectors with shape: (A.shape[1], size)\n    # XXX: generate random number directly from xp if it's possible\n    # one day.\n    Q = xp.asarray(random_state.normal(size=(A.shape[1], size)))\n    if hasattr(A, \"dtype\") and xp.isdtype(A.dtype, kind=\"real floating\"):\n        # Use float32 computation and components if A has a float32 dtype.\n        Q = xp.astype(Q, A.dtype, copy=False)\n\n    # Move Q to device if needed only after converting to float32 if needed to\n    # avoid allocating unnecessary memory on the device.\n\n    # Note: we cannot combine the astype and to_device operations in one go\n    # using xp.asarray(..., dtype=dtype, device=device) because downcasting\n    # from float64 to float32 in asarray might not always be accepted as only\n    # casts following type promotion rules are guarateed to work.\n    # https://github.com/data-apis/array-api/issues/647\n    if is_array_api_compliant:\n        Q = xp.asarray(Q, device=device(A))\n\n    # Deal with \"auto\" mode\n    if power_iteration_normalizer == \"auto\":\n        if n_iter <= 2:\n            power_iteration_normalizer = \"none\"\n        elif is_array_api_compliant:\n            # XXX: https://github.com/data-apis/array-api/issues/627\n            warnings.warn(\n                \"Array API does not support LU factorization, falling back to QR\"\n                \" instead. Set `power_iteration_normalizer='QR'` explicitly to silence\"\n                \" this warning.\"\n            )\n            power_iteration_normalizer = \"QR\"\n        else:\n            power_iteration_normalizer = \"LU\"\n    elif power_iteration_normalizer == \"LU\" and is_array_api_compliant:\n        raise ValueError(\n            \"Array API does not support LU factorization. Set \"\n            \"`power_iteration_normalizer='QR'` instead.\"\n        )\n\n    if is_array_api_compliant:\n        qr_normalizer = partial(xp.linalg.qr, mode=\"reduced\")\n    else:\n        # Use scipy.linalg instead of numpy.linalg when not explicitly\n        # using the Array API.\n        qr_normalizer = partial(linalg.qr, mode=\"economic\", check_finite=False)\n\n    if power_iteration_normalizer == \"QR\":\n        normalizer = qr_normalizer\n    elif power_iteration_normalizer == \"LU\":\n        normalizer = partial(linalg.lu, permute_l=True, check_finite=False)\n    else:\n        normalizer = lambda x: (x, None)\n\n    # Perform power iterations with Q to further 'imprint' the top\n    # singular vectors of A in Q\n    for _ in range(n_iter):\n        Q, _ = normalizer(A @ Q)\n        Q, _ = normalizer(A.T @ Q)\n\n    # Sample the range of A using by linear projection of Q\n    # Extract an orthonormal basis\n    Q, _ = qr_normalizer(A @ Q)\n\n    return Q\n", "type": "function"}, {"name": "transform", "is_method": true, "class_name": "SparseTransformer", "parameters": ["self", "X"], "calls": ["check_is_fitted", "validate_data", "self.sparse_container"], "code_location": {"file": "test_estimator_checks.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/utils/tests", "start_line": 450, "end_line": 453}, "code_snippet": "    def transform(self, X):\n        check_is_fitted(self)\n        X = validate_data(self, X, accept_sparse=True, reset=False)\n        return self.sparse_container(X)\n", "type": "function"}, {"name": "_randomized_svd", "is_method": false, "class_name": null, "parameters": ["M", "n_components"], "calls": ["get_namespace", "check_random_state", "_randomized_range_finder", "sparse.issparse", "warnings.warn", "xp.linalg.svd", "linalg.svd", "format", "svd_flip", "svd_flip", "type", "min"], "code_location": {"file": "extmath.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/utils", "start_line": 537, "end_line": 610}, "code_snippet": "def _randomized_svd(\n    M,\n    n_components,\n    *,\n    n_oversamples=10,\n    n_iter=\"auto\",\n    power_iteration_normalizer=\"auto\",\n    transpose=\"auto\",\n    flip_sign=True,\n    random_state=None,\n    svd_lapack_driver=\"gesdd\",\n):\n    \"\"\"Body of randomized_svd without input validation.\"\"\"\n    xp, is_array_api_compliant = get_namespace(M)\n\n    if sparse.issparse(M) and M.format in (\"lil\", \"dok\"):\n        warnings.warn(\n            \"Calculating SVD of a {} is expensive. \"\n            \"csr_matrix is more efficient.\".format(type(M).__name__),\n            sparse.SparseEfficiencyWarning,\n        )\n\n    random_state = check_random_state(random_state)\n    n_random = n_components + n_oversamples\n    n_samples, n_features = M.shape\n\n    if n_iter == \"auto\":\n        # Checks if the number of iterations is explicitly specified\n        # Adjust n_iter. 7 was found a good compromise for PCA. See #5299\n        n_iter = 7 if n_components < 0.1 * min(M.shape) else 4\n\n    if transpose == \"auto\":\n        transpose = n_samples < n_features\n    if transpose:\n        # this implementation is a bit faster with smaller shape[1]\n        M = M.T\n\n    Q = _randomized_range_finder(\n        M,\n        size=n_random,\n        n_iter=n_iter,\n        power_iteration_normalizer=power_iteration_normalizer,\n        random_state=random_state,\n    )\n\n    # project M to the (k + p) dimensional space using the basis vectors\n    B = Q.T @ M\n\n    # compute the SVD on the thin matrix: (k + p) wide\n    if is_array_api_compliant:\n        Uhat, s, Vt = xp.linalg.svd(B, full_matrices=False)\n    else:\n        # When array_api_dispatch is disabled, rely on scipy.linalg\n        # instead of numpy.linalg to avoid introducing a behavior change w.r.t.\n        # previous versions of scikit-learn.\n        Uhat, s, Vt = linalg.svd(\n            B, full_matrices=False, lapack_driver=svd_lapack_driver\n        )\n    del B\n    U = Q @ Uhat\n\n    if flip_sign:\n        if not transpose:\n            U, Vt = svd_flip(U, Vt)\n        else:\n            # In case of transpose u_based_decision=false\n            # to actually flip based on u and not v.\n            U, Vt = svd_flip(U, Vt, u_based_decision=False)\n\n    if transpose:\n        # transpose back the results according to the input convention\n        return Vt[:n_components, :].T, s[:n_components], U[:, :n_components].T\n    else:\n        return U[:, :n_components], s[:n_components], Vt[:n_components, :]\n", "type": "function"}], "retrieved_count": 10, "cost_time": 1.111340045928955}
{"question": "What is the architectural rationale for LocalOutlierFactor's decision to cache _distances_fit_X_, _neighbors_indices_fit_X_, and _lrd as instance attributes during fit(), and how does this caching strategy impact the control flow of predict() versus score_samples()?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"name": "score_samples", "is_method": true, "class_name": "LocalOutlierFactor", "parameters": ["self", "X"], "calls": ["available_if", "check_is_fitted", "check_array", "self.kneighbors", "self._local_reachability_density", "distances_X.astype", "np.mean"], "code_location": {"file": "_lof.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/neighbors", "start_line": 446, "end_line": 491}, "code_snippet": "    def score_samples(self, X):\n        \"\"\"Opposite of the Local Outlier Factor of X.\n\n        It is the opposite as bigger is better, i.e. large values correspond\n        to inliers.\n\n        **Only available for novelty detection (when novelty is set to True).**\n        The argument X is supposed to contain *new data*: if X contains a\n        point from training, it considers the later in its own neighborhood.\n        Also, the samples in X are not considered in the neighborhood of any\n        point. Because of this, the scores obtained via ``score_samples`` may\n        differ from the standard LOF scores.\n        The standard LOF scores for the training data is available via the\n        ``negative_outlier_factor_`` attribute.\n\n        Parameters\n        ----------\n        X : {array-like, sparse matrix} of shape (n_samples, n_features)\n            The query sample or samples to compute the Local Outlier Factor\n            w.r.t. the training samples.\n\n        Returns\n        -------\n        opposite_lof_scores : ndarray of shape (n_samples,)\n            The opposite of the Local Outlier Factor of each input samples.\n            The lower, the more abnormal.\n        \"\"\"\n        check_is_fitted(self)\n        X = check_array(X, accept_sparse=\"csr\")\n\n        distances_X, neighbors_indices_X = self.kneighbors(\n            X, n_neighbors=self.n_neighbors_\n        )\n\n        if X.dtype == np.float32:\n            distances_X = distances_X.astype(X.dtype, copy=False)\n\n        X_lrd = self._local_reachability_density(\n            distances_X,\n            neighbors_indices_X,\n        )\n\n        lrd_ratios_array = self._lrd[neighbors_indices_X] / X_lrd[:, np.newaxis]\n\n        # as bigger is better:\n        return -np.mean(lrd_ratios_array, axis=1)\n", "type": "function"}, {"name": "test_lof_values", "is_method": false, "class_name": null, "parameters": ["global_dtype"], "calls": ["np.asarray", "fit", "fit", "assert_allclose", "assert_allclose", "assert_allclose", "assert_allclose", "assert_allclose", "assert_allclose", "neighbors.LocalOutlierFactor", "neighbors.LocalOutlierFactor", "sqrt", "sqrt", "sqrt", "clf1.score_samples", "clf2.score_samples", "clf1.score_samples", "clf2.score_samples", "sqrt", "sqrt"], "code_location": {"file": "test_lof.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/neighbors/tests", "start_line": 75, "end_line": 92}, "code_snippet": "def test_lof_values(global_dtype):\n    # toy samples:\n    X_train = np.asarray([[1, 1], [1, 2], [2, 1]], dtype=global_dtype)\n    clf1 = neighbors.LocalOutlierFactor(\n        n_neighbors=2, contamination=0.1, novelty=True\n    ).fit(X_train)\n    clf2 = neighbors.LocalOutlierFactor(n_neighbors=2, novelty=True).fit(X_train)\n    s_0 = 2.0 * sqrt(2.0) / (1.0 + sqrt(2.0))\n    s_1 = (1.0 + sqrt(2)) * (1.0 / (4.0 * sqrt(2.0)) + 1.0 / (2.0 + 2.0 * sqrt(2)))\n    # check predict()\n    assert_allclose(-clf1.negative_outlier_factor_, [s_0, s_1, s_1])\n    assert_allclose(-clf2.negative_outlier_factor_, [s_0, s_1, s_1])\n    # check predict(one sample not in train)\n    assert_allclose(-clf1.score_samples([[2.0, 2.0]]), [s_0])\n    assert_allclose(-clf2.score_samples([[2.0, 2.0]]), [s_0])\n    # check predict(one sample already in train)\n    assert_allclose(-clf1.score_samples([[1.0, 1.0]]), [s_1])\n    assert_allclose(-clf2.score_samples([[1.0, 1.0]]), [s_1])\n", "type": "function"}, {"name": "_predict", "is_method": true, "class_name": "LocalOutlierFactor", "parameters": ["self", "X"], "calls": ["check_is_fitted", "self.decision_function", "np.ones", "np.ones"], "code_location": {"file": "_lof.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/neighbors", "start_line": 363, "end_line": 390}, "code_snippet": "    def _predict(self, X=None):\n        \"\"\"Predict the labels (1 inlier, -1 outlier) of X according to LOF.\n\n        If X is None, returns the same as fit_predict(X_train).\n\n        Parameters\n        ----------\n        X : {array-like, sparse matrix} of shape (n_samples, n_features), default=None\n            The query sample or samples to compute the Local Outlier Factor\n            w.r.t. the training samples. If None, makes prediction on the\n            training data without considering them as their own neighbors.\n\n        Returns\n        -------\n        is_inlier : ndarray of shape (n_samples,)\n            Returns -1 for anomalies/outliers and +1 for inliers.\n        \"\"\"\n        check_is_fitted(self)\n\n        if X is not None:\n            shifted_opposite_lof_scores = self.decision_function(X)\n            is_inlier = np.ones(shifted_opposite_lof_scores.shape[0], dtype=int)\n            is_inlier[shifted_opposite_lof_scores < 0] = -1\n        else:\n            is_inlier = np.ones(self.n_samples_fit_, dtype=int)\n            is_inlier[self.negative_outlier_factor_ < self.offset_] = -1\n\n        return is_inlier\n", "type": "function"}, {"name": "test_score_samples", "is_method": false, "class_name": null, "parameters": ["global_dtype"], "calls": ["np.asarray", "np.asarray", "fit", "fit", "clf1.score_samples", "clf1.decision_function", "clf2.score_samples", "clf2.decision_function", "assert_allclose", "assert_allclose", "assert_allclose", "neighbors.LocalOutlierFactor", "neighbors.LocalOutlierFactor"], "code_location": {"file": "test_lof.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/neighbors/tests", "start_line": 133, "end_line": 155}, "code_snippet": "def test_score_samples(global_dtype):\n    X_train = np.asarray([[1, 1], [1, 2], [2, 1]], dtype=global_dtype)\n    X_test = np.asarray([[2.0, 2.0]], dtype=global_dtype)\n    clf1 = neighbors.LocalOutlierFactor(\n        n_neighbors=2, contamination=0.1, novelty=True\n    ).fit(X_train)\n    clf2 = neighbors.LocalOutlierFactor(n_neighbors=2, novelty=True).fit(X_train)\n\n    clf1_scores = clf1.score_samples(X_test)\n    clf1_decisions = clf1.decision_function(X_test)\n\n    clf2_scores = clf2.score_samples(X_test)\n    clf2_decisions = clf2.decision_function(X_test)\n\n    assert_allclose(\n        clf1_scores,\n        clf1_decisions + clf1.offset_,\n    )\n    assert_allclose(\n        clf2_scores,\n        clf2_decisions + clf2.offset_,\n    )\n    assert_allclose(clf1_scores, clf2_scores)\n", "type": "function"}, {"name": "test_novelty_training_scores", "is_method": false, "class_name": null, "parameters": ["global_dtype"], "calls": ["iris.data.astype", "neighbors.LocalOutlierFactor", "clf_1.fit", "neighbors.LocalOutlierFactor", "clf_2.fit", "assert_allclose"], "code_location": {"file": "test_lof.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/neighbors/tests", "start_line": 186, "end_line": 201}, "code_snippet": "def test_novelty_training_scores(global_dtype):\n    # check that the scores of the training samples are still accessible\n    # when novelty=True through the negative_outlier_factor_ attribute\n    X = iris.data.astype(global_dtype)\n\n    # fit with novelty=False\n    clf_1 = neighbors.LocalOutlierFactor()\n    clf_1.fit(X)\n    scores_1 = clf_1.negative_outlier_factor_\n\n    # fit with novelty=True\n    clf_2 = neighbors.LocalOutlierFactor(novelty=True)\n    clf_2.fit(X)\n    scores_2 = clf_2.negative_outlier_factor_\n\n    assert_allclose(scores_1, scores_2)\n", "type": "function"}, {"name": "fit", "is_method": true, "class_name": "LocalOutlierFactor", "parameters": ["self", "X", "y"], "calls": ["_fit_context", "self._fit", "max", "self.kneighbors", "self._local_reachability_density", "warnings.warn", "min", "self._distances_fit_X_.astype", "np.mean", "np.percentile", "warnings.warn", "np.min"], "code_location": {"file": "_lof.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/neighbors", "start_line": 261, "end_line": 327}, "code_snippet": "    def fit(self, X, y=None):\n        \"\"\"Fit the local outlier factor detector from the training dataset.\n\n        Parameters\n        ----------\n        X : {array-like, sparse matrix} of shape (n_samples, n_features) or \\\n                (n_samples, n_samples) if metric='precomputed'\n            Training data.\n\n        y : Ignored\n            Not used, present for API consistency by convention.\n\n        Returns\n        -------\n        self : LocalOutlierFactor\n            The fitted local outlier factor detector.\n        \"\"\"\n        self._fit(X)\n\n        n_samples = self.n_samples_fit_\n        if self.n_neighbors > n_samples:\n            warnings.warn(\n                \"n_neighbors (%s) is greater than the \"\n                \"total number of samples (%s). n_neighbors \"\n                \"will be set to (n_samples - 1) for estimation.\"\n                % (self.n_neighbors, n_samples)\n            )\n        self.n_neighbors_ = max(1, min(self.n_neighbors, n_samples - 1))\n\n        self._distances_fit_X_, _neighbors_indices_fit_X_ = self.kneighbors(\n            n_neighbors=self.n_neighbors_\n        )\n\n        if self._fit_X.dtype == np.float32:\n            self._distances_fit_X_ = self._distances_fit_X_.astype(\n                self._fit_X.dtype,\n                copy=False,\n            )\n\n        self._lrd = self._local_reachability_density(\n            self._distances_fit_X_, _neighbors_indices_fit_X_\n        )\n\n        # Compute lof score over training samples to define offset_:\n        lrd_ratios_array = (\n            self._lrd[_neighbors_indices_fit_X_] / self._lrd[:, np.newaxis]\n        )\n\n        self.negative_outlier_factor_ = -np.mean(lrd_ratios_array, axis=1)\n\n        if self.contamination == \"auto\":\n            # inliers score around -1 (the higher, the less abnormal).\n            self.offset_ = -1.5\n        else:\n            self.offset_ = np.percentile(\n                self.negative_outlier_factor_, 100.0 * self.contamination\n            )\n\n        # Verify if negative_outlier_factor_ values are within acceptable range.\n        # Novelty must also be false to detect outliers\n        if np.min(self.negative_outlier_factor_) < -1e7 and not self.novelty:\n            warnings.warn(\n                \"Duplicate values are leading to incorrect results. \"\n                \"Increase the number of neighbors for more accurate results.\"\n            )\n\n        return self\n", "type": "function"}, {"name": "test_novelty_errors", "is_method": false, "class_name": null, "parameters": [], "calls": ["neighbors.LocalOutlierFactor", "clf.fit", "neighbors.LocalOutlierFactor", "isinstance", "format", "isinstance", "pytest.raises", "getattr", "str", "pytest.raises", "getattr", "str"], "code_location": {"file": "test_lof.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/neighbors/tests", "start_line": 158, "end_line": 183}, "code_snippet": "def test_novelty_errors():\n    X = iris.data\n\n    # check errors for novelty=False\n    clf = neighbors.LocalOutlierFactor()\n    clf.fit(X)\n    # predict, decision_function and score_samples raise ValueError\n    for method in [\"predict\", \"decision_function\", \"score_samples\"]:\n        outer_msg = f\"'LocalOutlierFactor' has no attribute '{method}'\"\n        inner_msg = \"{} is not available when novelty=False\".format(method)\n        with pytest.raises(AttributeError, match=outer_msg) as exec_info:\n            getattr(clf, method)\n\n        assert isinstance(exec_info.value.__cause__, AttributeError)\n        assert inner_msg in str(exec_info.value.__cause__)\n\n    # check errors for novelty=True\n    clf = neighbors.LocalOutlierFactor(novelty=True)\n\n    outer_msg = \"'LocalOutlierFactor' has no attribute 'fit_predict'\"\n    inner_msg = \"fit_predict is not available when novelty=True\"\n    with pytest.raises(AttributeError, match=outer_msg) as exec_info:\n        getattr(clf, \"fit_predict\")\n\n    assert isinstance(exec_info.value.__cause__, AttributeError)\n    assert inner_msg in str(exec_info.value.__cause__)\n", "type": "function"}, {"name": "test_n_neighbors_attribute", "is_method": false, "class_name": null, "parameters": [], "calls": ["fit", "neighbors.LocalOutlierFactor", "pytest.warns", "clf.fit", "neighbors.LocalOutlierFactor", "re.escape"], "code_location": {"file": "test_lof.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/neighbors/tests", "start_line": 121, "end_line": 130}, "code_snippet": "def test_n_neighbors_attribute():\n    X = iris.data\n    clf = neighbors.LocalOutlierFactor(n_neighbors=500).fit(X)\n    assert clf.n_neighbors_ == X.shape[0] - 1\n\n    clf = neighbors.LocalOutlierFactor(n_neighbors=500)\n    msg = \"n_neighbors will be set to (n_samples - 1)\"\n    with pytest.warns(UserWarning, match=re.escape(msg)):\n        clf.fit(X)\n    assert clf.n_neighbors_ == X.shape[0] - 1\n", "type": "function"}, {"name": "predict", "is_method": true, "class_name": "LocalOutlierFactor", "parameters": ["self", "X"], "calls": ["available_if", "self._predict"], "code_location": {"file": "_lof.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/neighbors", "start_line": 341, "end_line": 361}, "code_snippet": "    def predict(self, X=None):\n        \"\"\"Predict the labels (1 inlier, -1 outlier) of X according to LOF.\n\n        **Only available for novelty detection (when novelty is set to True).**\n        This method allows to generalize prediction to *new observations* (not\n        in the training set). Note that the result of ``clf.fit(X)`` then\n        ``clf.predict(X)`` with ``novelty=True`` may differ from the result\n        obtained by ``clf.fit_predict(X)`` with ``novelty=False``.\n\n        Parameters\n        ----------\n        X : {array-like, sparse matrix} of shape (n_samples, n_features)\n            The query sample or samples to compute the Local Outlier Factor\n            w.r.t. the training samples.\n\n        Returns\n        -------\n        is_inlier : ndarray of shape (n_samples,)\n            Returns -1 for anomalies/outliers and +1 for inliers.\n        \"\"\"\n        return self._predict(X)\n", "type": "function"}, {"name": "_check_novelty_score_samples", "is_method": true, "class_name": "LocalOutlierFactor", "parameters": ["self"], "calls": ["AttributeError"], "code_location": {"file": "_lof.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/neighbors", "start_line": 433, "end_line": 443}, "code_snippet": "    def _check_novelty_score_samples(self):\n        if not self.novelty:\n            msg = (\n                \"score_samples is not available when novelty=False. The \"\n                \"scores of the training samples are always available \"\n                \"through the negative_outlier_factor_ attribute. Use \"\n                \"novelty=True if you want to use LOF for novelty detection \"\n                \"and compute score_samples for new unseen data.\"\n            )\n            raise AttributeError(msg)\n        return True\n", "type": "function"}], "retrieved_count": 10, "cost_time": 1.1384356021881104}
{"question": "What is the layered validation architecture implemented by the test_docstring_parameters function that separates concerns between module discovery, class inspection, method validation, and error aggregation?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"name": "test_docstring", "is_method": false, "class_name": null, "parameters": ["Klass", "method", "request"], "calls": ["pytest.mark.parametrize", "join", "numpydoc_validation.validate", "list", "get_all_methods", "import_path.append", "filter_errors", "repr_errors", "ValueError"], "code_location": {"file": "test_docstrings.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/tests", "start_line": 159, "end_line": 174}, "code_snippet": "def test_docstring(Klass, method, request):\n    base_import_path = Klass.__module__\n    import_path = [base_import_path, Klass.__name__]\n    if method is not None:\n        import_path.append(method)\n\n    import_path = \".\".join(import_path)\n\n    res = numpydoc_validation.validate(import_path)\n\n    res[\"errors\"] = list(filter_errors(res[\"errors\"], method, Klass=Klass))\n\n    if res[\"errors\"]:\n        msg = repr_errors(res, Klass, method)\n\n        raise ValueError(msg)\n", "type": "function"}, {"name": "test_docstring_parameters", "is_method": false, "class_name": null, "parameters": [], "calls": ["pytest.importorskip", "join", "name.endswith", "inspect.getmembers", "inspect.getmembers", "len", "AssertionError", "warnings.catch_warnings", "importlib.import_module", "inspect.isabstract", "len", "_is_deprecated", "check_docstring_parameters", "fname.startswith", "_get_func_name", "__module__.startswith", "cname.startswith", "warnings.catch_warnings", "docscrape.ClassDoc", "RuntimeError", "getattr", "_is_deprecated", "check_docstring_parameters", "name.endswith", "check_docstring_parameters", "signature", "any", "_is_deprecated"], "code_location": {"file": "test_docstring_parameters.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/tests", "start_line": 73, "end_line": 149}, "code_snippet": "def test_docstring_parameters():\n    # Test module docstring formatting\n\n    # Skip test if numpydoc is not found\n    pytest.importorskip(\n        \"numpydoc\", reason=\"numpydoc is required to test the docstrings\"\n    )\n\n    # XXX unreached code as of v0.22\n    from numpydoc import docscrape\n\n    incorrect = []\n    for name in PUBLIC_MODULES:\n        if name.endswith(\".conftest\"):\n            # pytest tooling, not part of the scikit-learn API\n            continue\n        if name == \"sklearn.utils.fixes\":\n            # We cannot always control these docstrings\n            continue\n        with warnings.catch_warnings(record=True):\n            module = importlib.import_module(name)\n        classes = inspect.getmembers(module, inspect.isclass)\n        # Exclude non-scikit-learn classes\n        classes = [cls for cls in classes if cls[1].__module__.startswith(\"sklearn\")]\n        for cname, cls in classes:\n            this_incorrect = []\n            if cname in _DOCSTRING_IGNORES or cname.startswith(\"_\"):\n                continue\n            if inspect.isabstract(cls):\n                continue\n            with warnings.catch_warnings(record=True) as w:\n                cdoc = docscrape.ClassDoc(cls)\n            if len(w):\n                raise RuntimeError(\n                    \"Error for __init__ of %s in %s:\\n%s\" % (cls, name, w[0])\n                )\n\n            # Skip checks on deprecated classes\n            if _is_deprecated(cls.__new__):\n                continue\n\n            this_incorrect += check_docstring_parameters(cls.__init__, cdoc)\n\n            for method_name in cdoc.methods:\n                method = getattr(cls, method_name)\n                if _is_deprecated(method):\n                    continue\n                param_ignore = None\n                # Now skip docstring test for y when y is None\n                # by default for API reason\n                if method_name in _METHODS_IGNORE_NONE_Y:\n                    sig = signature(method)\n                    if \"y\" in sig.parameters and sig.parameters[\"y\"].default is None:\n                        param_ignore = [\"y\"]  # ignore y for fit and score\n                result = check_docstring_parameters(method, ignore=param_ignore)\n                this_incorrect += result\n\n            incorrect += this_incorrect\n\n        functions = inspect.getmembers(module, inspect.isfunction)\n        # Exclude imported functions\n        functions = [fn for fn in functions if fn[1].__module__ == name]\n        for fname, func in functions:\n            # Don't test private methods / functions\n            if fname.startswith(\"_\"):\n                continue\n            if fname == \"configuration\" and name.endswith(\"setup\"):\n                continue\n            name_ = _get_func_name(func)\n            if not any(d in name_ for d in _DOCSTRING_IGNORES) and not _is_deprecated(\n                func\n            ):\n                incorrect += check_docstring_parameters(func)\n\n    msg = \"\\n\".join(incorrect)\n    if len(incorrect) > 0:\n        raise AssertionError(\"Docstring Error:\\n\" + msg)\n", "type": "function"}, {"name": "test_check_docstring_parameters", "is_method": false, "class_name": null, "parameters": [], "calls": ["check_docstring_parameters", "check_docstring_parameters", "check_docstring_parameters", "check_docstring_parameters", "MockMetaEstimator", "zip", "pytest.raises", "check_docstring_parameters", "pytest.raises", "check_docstring_parameters", "check_docstring_parameters", "MockEst"], "code_location": {"file": "test_testing.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/utils/tests", "start_line": 402, "end_line": 526}, "code_snippet": "def test_check_docstring_parameters():\n    incorrect = check_docstring_parameters(f_ok)\n    assert incorrect == []\n    incorrect = check_docstring_parameters(f_ok, ignore=[\"b\"])\n    assert incorrect == []\n    incorrect = check_docstring_parameters(f_missing, ignore=[\"b\"])\n    assert incorrect == []\n    with pytest.raises(RuntimeError, match=\"Unknown section Results\"):\n        check_docstring_parameters(f_bad_sections)\n    with pytest.raises(RuntimeError, match=\"Unknown section Parameter\"):\n        check_docstring_parameters(Klass.f_bad_sections)\n\n    incorrect = check_docstring_parameters(f_check_param_definition)\n    mock_meta = MockMetaEstimator(delegate=MockEst())\n    mock_meta_name = mock_meta.__class__.__name__\n    assert incorrect == [\n        (\n            \"sklearn.utils.tests.test_testing.f_check_param_definition There \"\n            \"was no space between the param name and colon ('a: int')\"\n        ),\n        (\n            \"sklearn.utils.tests.test_testing.f_check_param_definition There \"\n            \"was no space between the param name and colon ('b:')\"\n        ),\n        (\n            \"sklearn.utils.tests.test_testing.f_check_param_definition There \"\n            \"was no space between the param name and colon ('d:int')\"\n        ),\n    ]\n\n    messages = [\n        [\n            \"In function: sklearn.utils.tests.test_testing.f_bad_order\",\n            (\n                \"There's a parameter name mismatch in function docstring w.r.t.\"\n                \" function signature, at index 0 diff: 'b' != 'a'\"\n            ),\n            \"Full diff:\",\n            \"- ['b', 'a']\",\n            \"+ ['a', 'b']\",\n        ],\n        [\n            \"In function: sklearn.utils.tests.test_testing.f_too_many_param_docstring\",\n            (\n                \"Parameters in function docstring have more items w.r.t. function\"\n                \" signature, first extra item: c\"\n            ),\n            \"Full diff:\",\n            \"- ['a', 'b']\",\n            \"+ ['a', 'b', 'c']\",\n            \"?          +++++\",\n        ],\n        [\n            \"In function: sklearn.utils.tests.test_testing.f_missing\",\n            (\n                \"Parameters in function docstring have less items w.r.t. function\"\n                \" signature, first missing item: b\"\n            ),\n            \"Full diff:\",\n            \"- ['a', 'b']\",\n            \"+ ['a']\",\n        ],\n        [\n            \"In function: sklearn.utils.tests.test_testing.Klass.f_missing\",\n            (\n                \"Parameters in function docstring have less items w.r.t. function\"\n                \" signature, first missing item: X\"\n            ),\n            \"Full diff:\",\n            \"- ['X', 'y']\",\n            \"+ []\",\n        ],\n        [\n            f\"In function: sklearn.utils.tests.test_testing.{mock_meta_name}.predict\",\n            (\n                \"There's a parameter name mismatch in function docstring w.r.t.\"\n                \" function signature, at index 0 diff: 'X' != 'y'\"\n            ),\n            \"Full diff:\",\n            \"- ['X']\",\n            \"?   ^\",\n            \"+ ['y']\",\n            \"?   ^\",\n        ],\n        [\n            \"In function: \"\n            f\"sklearn.utils.tests.test_testing.{mock_meta_name}.\"\n            \"predict_proba\",\n            \"potentially wrong underline length... \",\n            \"Parameters \",\n            \"--------- in \",\n        ],\n        [\n            f\"In function: sklearn.utils.tests.test_testing.{mock_meta_name}.score\",\n            \"potentially wrong underline length... \",\n            \"Parameters \",\n            \"--------- in \",\n        ],\n        [\n            f\"In function: sklearn.utils.tests.test_testing.{mock_meta_name}.fit\",\n            (\n                \"Parameters in function docstring have less items w.r.t. function\"\n                \" signature, first missing item: X\"\n            ),\n            \"Full diff:\",\n            \"- ['X', 'y']\",\n            \"+ []\",\n        ],\n    ]\n\n    for msg, f in zip(\n        messages,\n        [\n            f_bad_order,\n            f_too_many_param_docstring,\n            f_missing,\n            Klass.f_missing,\n            mock_meta.predict,\n            mock_meta.predict_proba,\n            mock_meta.score,\n            mock_meta.fit,\n        ],\n    ):\n        incorrect = check_docstring_parameters(f)\n        assert msg == incorrect, '\\n\"%s\"\\n not in \\n\"%s\"' % (msg, incorrect)\n", "type": "function"}, {"name": "test_validate_params_method", "is_method": false, "class_name": null, "parameters": [], "calls": ["pytest.raises", "_method", "pytest.warns", "pytest.raises", "_deprecated_method", "_Class", "_Class"], "code_location": {"file": "test_param_validation.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/utils/tests", "start_line": 533, "end_line": 546}, "code_snippet": "def test_validate_params_method():\n    \"\"\"Check that validate_params works with methods\"\"\"\n    with pytest.raises(\n        InvalidParameterError, match=\"The 'a' parameter of _Class._method must be\"\n    ):\n        _Class()._method(\"wrong\")\n\n    # validated method can be decorated\n    with pytest.warns(FutureWarning, match=\"Function _deprecated_method is deprecated\"):\n        with pytest.raises(\n            InvalidParameterError,\n            match=\"The 'a' parameter of _Class._deprecated_method must be\",\n        ):\n            _Class()._deprecated_method(\"wrong\")\n", "type": "function"}, {"name": "test_validations", "is_method": false, "class_name": null, "parameters": ["obj", "method", "inputs", "err_cls", "err_msg"], "calls": ["pytest.mark.parametrize", "config_context", "pytest.raises", "getattr", "MethodMapping", "MethodMapping", "MetadataRouter", "ConsumingClassifier", "MetadataRouter"], "code_location": {"file": "test_metadata_routing.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/tests", "start_line": 775, "end_line": 777}, "code_snippet": "def test_validations(obj, method, inputs, err_cls, err_msg):\n    with pytest.raises(err_cls, match=err_msg):\n        getattr(obj, method)(**inputs)\n", "type": "function"}, {"name": "test_validate_parameter_input", "is_method": false, "class_name": null, "parameters": ["klass", "input", "error_type", "error_message"], "calls": ["pytest.mark.parametrize", "pytest.mark.parametrize", "pytest.raises", "klass", "partial"], "code_location": {"file": "test_search.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/model_selection/tests", "start_line": 178, "end_line": 180}, "code_snippet": "def test_validate_parameter_input(klass, input, error_type, error_message):\n    with pytest.raises(error_type, match=error_message):\n        klass(input)\n", "type": "function"}, {"name": "test_confusion_matrix_display_validation", "is_method": false, "class_name": null, "parameters": ["pyplot"], "calls": ["make_classification", "fit", "regressor.predict", "predict", "pytest.raises", "ConfusionMatrixDisplay.from_estimator", "pytest.raises", "ConfusionMatrixDisplay.from_estimator", "pytest.raises", "ConfusionMatrixDisplay.from_predictions", "pytest.raises", "ConfusionMatrixDisplay.from_predictions", "pytest.raises", "ConfusionMatrixDisplay.from_predictions", "SVC", "SVR", "fit", "SVC"], "code_location": {"file": "test_confusion_matrix_display.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/metrics/_plot/tests", "start_line": 18, "end_line": 44}, "code_snippet": "def test_confusion_matrix_display_validation(pyplot):\n    \"\"\"Check that we raise the proper error when validating parameters.\"\"\"\n    X, y = make_classification(\n        n_samples=100, n_informative=5, n_classes=5, random_state=0\n    )\n\n    with pytest.raises(NotFittedError):\n        ConfusionMatrixDisplay.from_estimator(SVC(), X, y)\n\n    regressor = SVR().fit(X, y)\n    y_pred_regressor = regressor.predict(X)\n    y_pred_classifier = SVC().fit(X, y).predict(X)\n\n    err_msg = \"ConfusionMatrixDisplay.from_estimator only supports classifiers\"\n    with pytest.raises(ValueError, match=err_msg):\n        ConfusionMatrixDisplay.from_estimator(regressor, X, y)\n\n    err_msg = \"Mix type of y not allowed, got types\"\n    with pytest.raises(ValueError, match=err_msg):\n        # Force `y_true` to be seen as a regression problem\n        ConfusionMatrixDisplay.from_predictions(y + 0.5, y_pred_classifier)\n    with pytest.raises(ValueError, match=err_msg):\n        ConfusionMatrixDisplay.from_predictions(y, y_pred_regressor)\n\n    err_msg = \"Found input variables with inconsistent numbers of samples\"\n    with pytest.raises(ValueError, match=err_msg):\n        ConfusionMatrixDisplay.from_predictions(y, y_pred_classifier[::2])\n", "type": "function"}, {"name": "test_prediction_error_display_raise_error", "is_method": false, "class_name": null, "parameters": ["pyplot", "class_method", "regressor", "params", "err_type", "err_msg"], "calls": ["pytest.mark.parametrize", "pytest.mark.parametrize", "pytest.raises", "PredictionErrorDisplay.from_estimator", "regressor.predict", "PredictionErrorDisplay.from_predictions", "fit", "fit", "fit", "fit", "Ridge", "Ridge", "Ridge", "Ridge"], "code_location": {"file": "test_predict_error_display.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/metrics/_plot/tests", "start_line": 47, "end_line": 57}, "code_snippet": "def test_prediction_error_display_raise_error(\n    pyplot, class_method, regressor, params, err_type, err_msg\n):\n    \"\"\"Check that we raise the proper error when making the parameters\n    # validation.\"\"\"\n    with pytest.raises(err_type, match=err_msg):\n        if class_method == \"from_estimator\":\n            PredictionErrorDisplay.from_estimator(regressor, X, y, **params)\n        else:\n            y_pred = regressor.predict(X)\n            PredictionErrorDisplay.from_predictions(y_true=y, y_pred=y_pred, **params)\n", "type": "function"}, {"name": "test_check_param_validation", "is_method": false, "class_name": null, "parameters": ["estimator"], "calls": ["pytest.mark.parametrize", "isinstance", "check_param_validation", "list", "pytest.skip", "_tested_estimators"], "code_location": {"file": "test_common.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/tests", "start_line": 327, "end_line": 331}, "code_snippet": "def test_check_param_validation(estimator):\n    if isinstance(estimator, FeatureUnion):\n        pytest.skip(\"FeatureUnion is not tested here\")\n    name = estimator.__class__.__name__\n    check_param_validation(name, estimator)\n", "type": "function"}, {"name": "check_docstring_parameters", "is_method": false, "class_name": null, "parameters": ["func", "doc", "ignore"], "calls": ["_get_func_name", "inspect.isdatadescriptor", "list", "list", "range", "splitlines", "splitlines", "message.extend", "incorrect.extend", "func_name.startswith", "filter", "param_signature.remove", "len", "len", "filter", "min", "len", "len", "len", "func_name.startswith", "func_name.split", "func_name.split", "_get_args", "len", "warnings.catch_warnings", "warnings.simplefilter", "RuntimeError", "type_definition.strip", "param_docs.append", "len", "len", "len", "len", "pprint.pformat", "pprint.pformat", "line.strip", "docscrape.FunctionDoc", "strip", "endswith", "strip", "difflib.ndiff", "records.append", "len", "str", "str", "name.rstrip", "len", "split", "str", "name.split", "name.lstrip", "str", "name.index"], "code_location": {"file": "_testing.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/utils", "start_line": 479, "end_line": 623}, "code_snippet": "def check_docstring_parameters(func, doc=None, ignore=None):\n    \"\"\"Helper to check docstring.\n\n    Parameters\n    ----------\n    func : callable\n        The function object to test.\n    doc : str, default=None\n        Docstring if it is passed manually to the test.\n    ignore : list, default=None\n        Parameters to ignore.\n\n    Returns\n    -------\n    incorrect : list\n        A list of string describing the incorrect results.\n    \"\"\"\n    from numpydoc import docscrape\n\n    incorrect = []\n    ignore = [] if ignore is None else ignore\n\n    func_name = _get_func_name(func)\n    if not func_name.startswith(\"sklearn.\") or func_name.startswith(\n        \"sklearn.externals\"\n    ):\n        return incorrect\n    # Don't check docstring for property-functions\n    if inspect.isdatadescriptor(func):\n        return incorrect\n    # Don't check docstring for setup / teardown pytest functions\n    if func_name.split(\".\")[-1] in (\"setup_module\", \"teardown_module\"):\n        return incorrect\n    # Dont check estimator_checks module\n    if func_name.split(\".\")[2] == \"estimator_checks\":\n        return incorrect\n    # Get the arguments from the function signature\n    param_signature = list(filter(lambda x: x not in ignore, _get_args(func)))\n    # drop self\n    if len(param_signature) > 0 and param_signature[0] == \"self\":\n        param_signature.remove(\"self\")\n\n    # Analyze function's docstring\n    if doc is None:\n        records = []\n        with warnings.catch_warnings(record=True):\n            warnings.simplefilter(\"error\", UserWarning)\n            try:\n                doc = docscrape.FunctionDoc(func)\n            except UserWarning as exp:\n                if \"potentially wrong underline length\" in str(exp):\n                    # Catch warning raised as of numpydoc 1.2 when\n                    # the underline length for a section of a docstring\n                    # is not consistent.\n                    message = str(exp).split(\"\\n\")[:3]\n                    incorrect += [f\"In function: {func_name}\"] + message\n                    return incorrect\n                records.append(str(exp))\n            except Exception as exp:\n                incorrect += [func_name + \" parsing error: \" + str(exp)]\n                return incorrect\n        if len(records):\n            raise RuntimeError(\"Error for %s:\\n%s\" % (func_name, records[0]))\n\n    param_docs = []\n    for name, type_definition, param_doc in doc[\"Parameters\"]:\n        # Type hints are empty only if parameter name ended with :\n        if not type_definition.strip():\n            if \":\" in name and name[: name.index(\":\")][-1:].strip():\n                incorrect += [\n                    func_name\n                    + \" There was no space between the param name and colon (%r)\" % name\n                ]\n            elif name.rstrip().endswith(\":\"):\n                incorrect += [\n                    func_name\n                    + \" Parameter %r has an empty type spec. Remove the colon\"\n                    % (name.lstrip())\n                ]\n\n        # Create a list of parameters to compare with the parameters gotten\n        # from the func signature\n        if \"*\" not in name:\n            param_docs.append(name.split(\":\")[0].strip(\"` \"))\n\n    # If one of the docstring's parameters had an error then return that\n    # incorrect message\n    if len(incorrect) > 0:\n        return incorrect\n\n    # Remove the parameters that should be ignored from list\n    param_docs = list(filter(lambda x: x not in ignore, param_docs))\n\n    # The following is derived from pytest, Copyright (c) 2004-2017 Holger\n    # Krekel and others, Licensed under MIT License. See\n    # https://github.com/pytest-dev/pytest\n\n    message = []\n    for i in range(min(len(param_docs), len(param_signature))):\n        if param_signature[i] != param_docs[i]:\n            message += [\n                \"There's a parameter name mismatch in function\"\n                \" docstring w.r.t. function signature, at index %s\"\n                \" diff: %r != %r\" % (i, param_signature[i], param_docs[i])\n            ]\n            break\n    if len(param_signature) > len(param_docs):\n        message += [\n            \"Parameters in function docstring have less items w.r.t.\"\n            \" function signature, first missing item: %s\"\n            % param_signature[len(param_docs)]\n        ]\n\n    elif len(param_signature) < len(param_docs):\n        message += [\n            \"Parameters in function docstring have more items w.r.t.\"\n            \" function signature, first extra item: %s\"\n            % param_docs[len(param_signature)]\n        ]\n\n    # If there wasn't any difference in the parameters themselves between\n    # docstring and signature including having the same length then return\n    # empty list\n    if len(message) == 0:\n        return []\n\n    import difflib\n    import pprint\n\n    param_docs_formatted = pprint.pformat(param_docs).splitlines()\n    param_signature_formatted = pprint.pformat(param_signature).splitlines()\n\n    message += [\"Full diff:\"]\n\n    message.extend(\n        line.strip()\n        for line in difflib.ndiff(param_signature_formatted, param_docs_formatted)\n    )\n\n    incorrect.extend(message)\n\n    # Prepend function name\n    incorrect = [\"In function: \" + func_name] + incorrect\n\n    return incorrect\n", "type": "function"}], "retrieved_count": 10, "cost_time": 1.152064323425293}
{"question": "How does the test_check_n_classes function construct allowed_dtypes by combining both int32 and int64 with their byte-order variants, and what would be the consequence of removing the newbyteorder() transformation step for detecting endianness-related validation failures?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"name": "test_check_n_classes", "is_method": false, "class_name": null, "parameters": [], "calls": ["np.array", "np.dtype", "np.dtype", "np.dtype", "np.dtype", "dt.newbyteorder", "_check_n_classes", "pytest.raises", "np.array", "_check_n_classes", "pytest.raises", "n_classes.astype", "_check_n_classes", "n_classes.astype"], "code_location": {"file": "test_tree.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/tree/tests", "start_line": 2201, "end_line": 2216}, "code_snippet": "def test_check_n_classes():\n    expected_dtype = np.dtype(np.int32) if _IS_32BIT else np.dtype(np.int64)\n    allowed_dtypes = [np.dtype(np.int32), np.dtype(np.int64)]\n    allowed_dtypes += [dt.newbyteorder() for dt in allowed_dtypes]\n\n    n_classes = np.array([0, 1], dtype=expected_dtype)\n    for dt in allowed_dtypes:\n        _check_n_classes(n_classes.astype(dt), expected_dtype)\n\n    with pytest.raises(ValueError, match=\"Wrong dimensions.+n_classes\"):\n        wrong_dim_n_classes = np.array([[0, 1]], dtype=expected_dtype)\n        _check_n_classes(wrong_dim_n_classes, expected_dtype)\n\n    with pytest.raises(ValueError, match=\"n_classes.+incompatible dtype\"):\n        wrong_dtype_n_classes = n_classes.astype(np.float64)\n        _check_n_classes(wrong_dtype_n_classes, expected_dtype)\n", "type": "function"}, {"name": "test_dtype_convert", "is_method": false, "class_name": null, "parameters": ["n_classes"], "calls": ["RandomForestClassifier", "np.eye", "predict", "assert_array_equal", "assert_array_equal", "classifier.fit"], "code_location": {"file": "test_forest.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/ensemble/tests", "start_line": 1406, "end_line": 1414}, "code_snippet": "def test_dtype_convert(n_classes=15):\n    classifier = RandomForestClassifier(random_state=0, bootstrap=False)\n\n    X = np.eye(n_classes)\n    y = [ch for ch in \"ABCDEFGHIJKLMNOPQRSTU\"[:n_classes]]\n\n    result = classifier.fit(X, y).predict(X)\n    assert_array_equal(classifier.classes_, y)\n    assert_array_equal(result, y)\n", "type": "function"}, {"name": "test_dtype_convert", "is_method": false, "class_name": null, "parameters": [], "calls": ["neighbors.KNeighborsClassifier", "np.eye", "predict", "assert_array_equal", "classifier.fit"], "code_location": {"file": "test_neighbors.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/neighbors/tests", "start_line": 2119, "end_line": 2126}, "code_snippet": "def test_dtype_convert():\n    classifier = neighbors.KNeighborsClassifier(n_neighbors=1)\n    CLASSES = 15\n    X = np.eye(CLASSES)\n    y = [ch for ch in \"ABCDEFGHIJKLMNOPQRSTU\"[:CLASSES]]\n\n    result = classifier.fit(X, y).predict(X)\n    assert_array_equal(result, y)\n", "type": "function"}, {"name": "test_valid_n_bins", "is_method": false, "class_name": null, "parameters": [], "calls": ["fit_transform", "fit_transform", "np.dtype", "KBinsDiscretizer", "KBinsDiscretizer", "fit", "np.array", "KBinsDiscretizer"], "code_location": {"file": "test_discretization.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/preprocessing/tests", "start_line": 95, "end_line": 102}, "code_snippet": "def test_valid_n_bins():\n    KBinsDiscretizer(n_bins=2, quantile_method=\"averaged_inverted_cdf\").fit_transform(X)\n    KBinsDiscretizer(\n        n_bins=np.array([2])[0], quantile_method=\"averaged_inverted_cdf\"\n    ).fit_transform(X)\n    assert KBinsDiscretizer(n_bins=2, quantile_method=\"averaged_inverted_cdf\").fit(\n        X\n    ).n_bins_.dtype == np.dtype(int)\n", "type": "function"}, {"name": "test_check_node_ndarray", "is_method": false, "class_name": null, "parameters": [], "calls": ["np.zeros", "dtype_dict.copy", "np.dtype", "node_ndarray.astype", "dtype_dict.copy", "np.dtype", "node_ndarray.astype", "get_different_bitness_node_ndarray", "get_different_alignment_node_ndarray", "arr.astype", "_check_node_ndarray", "pytest.raises", "np.zeros", "_check_node_ndarray", "pytest.raises", "_check_node_ndarray", "pytest.raises", "_check_node_ndarray", "pytest.raises", "_check_node_ndarray", "arr.dtype.newbyteorder", "node_ndarray.dtype.fields.items", "list", "list", "list", "list", "new_dtype_dict.keys", "new_dtype_dict.values", "new_dtype_dict.keys", "new_dtype_dict.values"], "code_location": {"file": "test_tree.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/tree/tests", "start_line": 2252, "end_line": 2301}, "code_snippet": "def test_check_node_ndarray():\n    expected_dtype = NODE_DTYPE\n\n    node_ndarray = np.zeros((5,), dtype=expected_dtype)\n\n    valid_node_ndarrays = [\n        node_ndarray,\n        get_different_bitness_node_ndarray(node_ndarray),\n        get_different_alignment_node_ndarray(node_ndarray),\n    ]\n    valid_node_ndarrays += [\n        arr.astype(arr.dtype.newbyteorder()) for arr in valid_node_ndarrays\n    ]\n\n    for arr in valid_node_ndarrays:\n        _check_node_ndarray(node_ndarray, expected_dtype=expected_dtype)\n\n    with pytest.raises(ValueError, match=\"Wrong dimensions.+node array\"):\n        problematic_node_ndarray = np.zeros((5, 2), dtype=expected_dtype)\n        _check_node_ndarray(problematic_node_ndarray, expected_dtype=expected_dtype)\n\n    with pytest.raises(ValueError, match=\"node array.+C-contiguous\"):\n        problematic_node_ndarray = node_ndarray[::2]\n        _check_node_ndarray(problematic_node_ndarray, expected_dtype=expected_dtype)\n\n    dtype_dict = {name: dtype for name, (dtype, _) in node_ndarray.dtype.fields.items()}\n\n    # array with wrong 'threshold' field dtype (int64 rather than float64)\n    new_dtype_dict = dtype_dict.copy()\n    new_dtype_dict[\"threshold\"] = np.int64\n\n    new_dtype = np.dtype(\n        {\"names\": list(new_dtype_dict.keys()), \"formats\": list(new_dtype_dict.values())}\n    )\n    problematic_node_ndarray = node_ndarray.astype(new_dtype)\n\n    with pytest.raises(ValueError, match=\"node array.+incompatible dtype\"):\n        _check_node_ndarray(problematic_node_ndarray, expected_dtype=expected_dtype)\n\n    # array with wrong 'left_child' field dtype (float64 rather than int64 or int32)\n    new_dtype_dict = dtype_dict.copy()\n    new_dtype_dict[\"left_child\"] = np.float64\n    new_dtype = np.dtype(\n        {\"names\": list(new_dtype_dict.keys()), \"formats\": list(new_dtype_dict.values())}\n    )\n\n    problematic_node_ndarray = node_ndarray.astype(new_dtype)\n\n    with pytest.raises(ValueError, match=\"node array.+incompatible dtype\"):\n        _check_node_ndarray(problematic_node_ndarray, expected_dtype=expected_dtype)\n", "type": "function"}, {"name": "test_classes_shape", "is_method": false, "class_name": null, "parameters": ["name"], "calls": ["pytest.mark.parametrize", "fit", "assert_array_equal", "fit", "assert_array_equal", "assert_array_equal", "np.vstack", "ForestClassifier", "ForestClassifier", "np.array"], "code_location": {"file": "test_forest.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/ensemble/tests", "start_line": 833, "end_line": 848}, "code_snippet": "def test_classes_shape(name):\n    # Test that n_classes_ and classes_ have proper shape.\n    ForestClassifier = FOREST_CLASSIFIERS[name]\n\n    # Classification, single output\n    clf = ForestClassifier(random_state=0).fit(X, y)\n\n    assert clf.n_classes_ == 2\n    assert_array_equal(clf.classes_, [-1, 1])\n\n    # Classification, multi-output\n    _y = np.vstack((y, np.array(y) * 2)).T\n    clf = ForestClassifier(random_state=0).fit(X, _y)\n\n    assert_array_equal(clf.n_classes_, [2, 2])\n    assert_array_equal(clf.classes_, [[-1, 1], [-2, 2]])\n", "type": "function"}, {"name": "check_estimators_dtypes", "is_method": false, "class_name": null, "parameters": ["name", "estimator_orig"], "calls": ["np.random.RandomState", "_enforce_estimator_tags_X", "X_train_32.astype", "X_train_32.astype", "X_train_32.astype", "np.array", "_enforce_estimator_tags_y", "astype", "clone", "set_random_state", "estimator.fit", "hasattr", "rnd.uniform", "getattr"], "code_location": {"file": "estimator_checks.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/utils", "start_line": 2244, "end_line": 2263}, "code_snippet": "def check_estimators_dtypes(name, estimator_orig):\n    rnd = np.random.RandomState(0)\n    X_train_32 = 3 * rnd.uniform(size=(20, 5)).astype(np.float32)\n    X_train_32 = _enforce_estimator_tags_X(estimator_orig, X_train_32)\n    X_train_64 = X_train_32.astype(np.float64)\n    X_train_int_64 = X_train_32.astype(np.int64)\n    X_train_int_32 = X_train_32.astype(np.int32)\n    y = np.array([1, 2] * 10, dtype=np.int64)\n    y = _enforce_estimator_tags_y(estimator_orig, y)\n\n    methods = [\"predict\", \"transform\", \"decision_function\", \"predict_proba\"]\n\n    for X_train in [X_train_32, X_train_64, X_train_int_64, X_train_int_32]:\n        estimator = clone(estimator_orig)\n        set_random_state(estimator, 1)\n        estimator.fit(X_train, y)\n\n        for method in methods:\n            if hasattr(estimator, method):\n                getattr(estimator, method)(X_train)\n", "type": "function"}, {"name": "test_subcluster_dtype", "is_method": false, "class_name": null, "parameters": ["global_dtype"], "calls": ["astype", "Birch", "make_blobs", "brc.fit"], "code_location": {"file": "test_birch.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/cluster/tests", "start_line": 201, "end_line": 206}, "code_snippet": "def test_subcluster_dtype(global_dtype):\n    X = make_blobs(n_samples=80, n_features=4, random_state=0)[0].astype(\n        global_dtype, copy=False\n    )\n    brc = Birch(n_clusters=4)\n    assert brc.fit(X).subcluster_centers_.dtype == global_dtype\n", "type": "function"}, {"name": "test_birch_n_clusters_long_int", "is_method": false, "class_name": null, "parameters": [], "calls": ["make_blobs", "np.int64", "fit", "Birch"], "code_location": {"file": "test_birch.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/cluster/tests", "start_line": 173, "end_line": 178}, "code_snippet": "def test_birch_n_clusters_long_int():\n    # Check that birch supports n_clusters with np.int64 dtype, for instance\n    # coming from np.arange. #16484\n    X, _ = make_blobs(random_state=0)\n    n_clusters = np.int64(5)\n    Birch(n_clusters=n_clusters).fit(X)\n", "type": "function"}, {"name": "test_check_array_dtype_warning", "is_method": false, "class_name": null, "parameters": [], "calls": ["np.asarray", "np.asarray", "sp.csr_matrix", "sp.csc_matrix", "sp.csc_matrix", "warnings.catch_warnings", "warnings.simplefilter", "check_array", "check_array", "check_array", "check_array"], "code_location": {"file": "test_validation.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/utils/tests", "start_line": 620, "end_line": 660}, "code_snippet": "def test_check_array_dtype_warning():\n    X_int_list = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]\n    X_float32 = np.asarray(X_int_list, dtype=np.float32)\n    X_int64 = np.asarray(X_int_list, dtype=np.int64)\n    X_csr_float32 = sp.csr_matrix(X_float32)\n    X_csc_float32 = sp.csc_matrix(X_float32)\n    X_csc_int32 = sp.csc_matrix(X_int64, dtype=np.int32)\n    integer_data = [X_int64, X_csc_int32]\n    float32_data = [X_float32, X_csr_float32, X_csc_float32]\n    with warnings.catch_warnings():\n        warnings.simplefilter(\"error\")\n\n        for X in integer_data:\n            X_checked = check_array(X, dtype=np.float64, accept_sparse=True)\n            assert X_checked.dtype == np.float64\n\n        for X in float32_data:\n            X_checked = check_array(\n                X, dtype=[np.float64, np.float32], accept_sparse=True\n            )\n            assert X_checked.dtype == np.float32\n            assert X_checked is X\n\n            X_checked = check_array(\n                X,\n                dtype=[np.float64, np.float32],\n                accept_sparse=[\"csr\", \"dok\"],\n                copy=True,\n            )\n            assert X_checked.dtype == np.float32\n            assert X_checked is not X\n\n        X_checked = check_array(\n            X_csc_float32,\n            dtype=[np.float64, np.float32],\n            accept_sparse=[\"csr\", \"dok\"],\n            copy=False,\n        )\n        assert X_checked.dtype == np.float32\n        assert X_checked is not X_csc_float32\n        assert X_checked.format == \"csr\"\n", "type": "function"}], "retrieved_count": 10, "cost_time": 1.1175799369812012}
{"question": "Why does BaseShuffleSplit delegate the actual index generation logic to the _iter_indices method rather than implementing it directly within the split method, and what design constraints does this separation impose on subclass implementations?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"name": "_iter_indices", "is_method": true, "class_name": "StratifiedShuffleSplit", "parameters": ["self", "X", "y", "groups"], "calls": ["_num_samples", "check_array", "_validate_shuffle_split", "get_namespace", "_convert_to_numpy", "np.unique", "np.bincount", "np.split", "check_random_state", "range", "np.array", "np.min", "ValueError", "ValueError", "ValueError", "np.argsort", "_approximate_mode", "_approximate_mode", "range", "rng.permutation", "rng.permutation", "np.cumsum", "rng.permutation", "take", "train.extend", "test.extend", "join", "row.astype"], "code_location": {"file": "_split.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/model_selection", "start_line": 2316, "end_line": 2388}, "code_snippet": "    def _iter_indices(self, X, y, groups=None):\n        n_samples = _num_samples(X)\n        y = check_array(y, input_name=\"y\", ensure_2d=False, dtype=None)\n        n_train, n_test = _validate_shuffle_split(\n            n_samples,\n            self.test_size,\n            self.train_size,\n            default_test_size=self._default_test_size,\n        )\n\n        # Convert to numpy as not all operations are supported by the Array API.\n        # `y` is probably never a very large array, which means that converting it\n        # should be cheap\n        xp, _ = get_namespace(y)\n        y = _convert_to_numpy(y, xp=xp)\n\n        if y.ndim == 2:\n            # for multi-label y, map each distinct row to a string repr\n            # using join because str(row) uses an ellipsis if len(row) > 1000\n            y = np.array([\" \".join(row.astype(\"str\")) for row in y])\n\n        classes, y_indices = np.unique(y, return_inverse=True)\n        n_classes = classes.shape[0]\n\n        class_counts = np.bincount(y_indices)\n        if np.min(class_counts) < 2:\n            raise ValueError(\n                \"The least populated class in y has only 1\"\n                \" member, which is too few. The minimum\"\n                \" number of groups for any class cannot\"\n                \" be less than 2.\"\n            )\n\n        if n_train < n_classes:\n            raise ValueError(\n                \"The train_size = %d should be greater or \"\n                \"equal to the number of classes = %d\" % (n_train, n_classes)\n            )\n        if n_test < n_classes:\n            raise ValueError(\n                \"The test_size = %d should be greater or \"\n                \"equal to the number of classes = %d\" % (n_test, n_classes)\n            )\n\n        # Find the sorted list of instances for each class:\n        # (np.unique above performs a sort, so code is O(n logn) already)\n        class_indices = np.split(\n            np.argsort(y_indices, kind=\"mergesort\"), np.cumsum(class_counts)[:-1]\n        )\n\n        rng = check_random_state(self.random_state)\n\n        for _ in range(self.n_splits):\n            # if there are ties in the class-counts, we want\n            # to make sure to break them anew in each iteration\n            n_i = _approximate_mode(class_counts, n_train, rng)\n            class_counts_remaining = class_counts - n_i\n            t_i = _approximate_mode(class_counts_remaining, n_test, rng)\n\n            train = []\n            test = []\n\n            for i in range(n_classes):\n                permutation = rng.permutation(class_counts[i])\n                perm_indices_class_i = class_indices[i].take(permutation, mode=\"clip\")\n\n                train.extend(perm_indices_class_i[: n_i[i]])\n                test.extend(perm_indices_class_i[n_i[i] : n_i[i] + t_i[i]])\n\n            train = rng.permutation(train)\n            test = rng.permutation(test)\n\n            yield train, test\n", "type": "function"}, {"name": "_iter_test_indices", "is_method": true, "class_name": "KFold", "parameters": ["self", "X", "y", "groups"], "calls": ["_num_samples", "np.arange", "np.full", "shuffle", "check_random_state"], "code_location": {"file": "_split.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/model_selection", "start_line": 516, "end_line": 529}, "code_snippet": "    def _iter_test_indices(self, X, y=None, groups=None):\n        n_samples = _num_samples(X)\n        indices = np.arange(n_samples)\n        if self.shuffle:\n            check_random_state(self.random_state).shuffle(indices)\n\n        n_splits = self.n_splits\n        fold_sizes = np.full(n_splits, n_samples // n_splits, dtype=int)\n        fold_sizes[: n_samples % n_splits] += 1\n        current = 0\n        for fold_size in fold_sizes:\n            start, stop = current, current + fold_size\n            yield indices[start:stop]\n            current = stop\n", "type": "function"}, {"name": "BaseShuffleSplit", "docstring": "Base class for *ShuffleSplit.\n\nParameters\n----------\nn_splits : int, default=10\n    Number of re-shuffling & splitting iterations.\n\ntest_size : float or int, default=None\n    If float, should be between 0.0 and 1.0 and represent the proportion\n    of the dataset to include in the test split. If int, represents the\n    absolute number of test samples. If None, the value is set to the\n    complement of the train size. If ``train_size`` is also None, it will\n    be set to 0.1.\n\ntrain_size : float or int, default=None\n    If float, should be between 0.0 and 1.0 and represent the\n    proportion of the dataset to include in the train split. If\n    int, represents the absolute number of train samples. If None,\n    the value is automatically set to the complement of the test size.\n\nrandom_state : int, RandomState instance or None, default=None\n    Controls the randomness of the training and testing indices produced.\n    Pass an int for reproducible output across multiple function calls.\n    See :term:`Glossary <random_state>`.", "methods": ["__init__", "split", "_iter_indices", "get_n_splits", "__repr__"], "attributes": ["__metadata_request__split"], "code_location": {"file": "_split.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/model_selection", "start_line": 1854, "end_line": 1970}, "type": "class"}, {"name": "_iter_test_indices", "is_method": true, "class_name": "ConsumingSplitter", "parameters": ["self", "X", "y", "groups"], "calls": ["list", "list", "len", "range", "range", "len"], "code_location": {"file": "metadata_routing_common.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/tests", "start_line": 475, "end_line": 480}, "code_snippet": "    def _iter_test_indices(self, X=None, y=None, groups=None):\n        split_index = len(X) // 2\n        train_indices = list(range(0, split_index))\n        test_indices = list(range(split_index, len(X)))\n        yield test_indices\n        yield train_indices\n", "type": "function"}, {"name": "_iter_test_indices", "is_method": true, "class_name": "GroupKFold", "parameters": ["self", "X", "y", "groups"], "calls": ["check_array", "np.unique", "len", "ValueError", "ValueError", "check_random_state", "rng.permutation", "np.array_split", "np.bincount", "np.zeros", "np.zeros", "enumerate", "range", "np.isin", "np.argsort", "len", "np.argmin", "np.where", "np.where"], "code_location": {"file": "_split.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/model_selection", "start_line": 610, "end_line": 657}, "code_snippet": "    def _iter_test_indices(self, X, y, groups):\n        if groups is None:\n            raise ValueError(\"The 'groups' parameter should not be None.\")\n        groups = check_array(groups, input_name=\"groups\", ensure_2d=False, dtype=None)\n\n        unique_groups, group_idx = np.unique(groups, return_inverse=True)\n        n_groups = len(unique_groups)\n\n        if self.n_splits > n_groups:\n            raise ValueError(\n                \"Cannot have number of splits n_splits=%d greater\"\n                \" than the number of groups: %d.\" % (self.n_splits, n_groups)\n            )\n\n        if self.shuffle:\n            # Split and shuffle unique groups across n_splits\n            rng = check_random_state(self.random_state)\n            unique_groups = rng.permutation(unique_groups)\n            split_groups = np.array_split(unique_groups, self.n_splits)\n\n            for test_group_ids in split_groups:\n                test_mask = np.isin(groups, test_group_ids)\n                yield np.where(test_mask)[0]\n\n        else:\n            # Weight groups by their number of occurrences\n            n_samples_per_group = np.bincount(group_idx)\n\n            # Distribute the most frequent groups first\n            indices = np.argsort(n_samples_per_group)[::-1]\n            n_samples_per_group = n_samples_per_group[indices]\n\n            # Total weight of each fold\n            n_samples_per_fold = np.zeros(self.n_splits)\n\n            # Mapping from group index to fold index\n            group_to_fold = np.zeros(len(unique_groups))\n\n            # Distribute samples by adding the largest weight to the lightest fold\n            for group_index, weight in enumerate(n_samples_per_group):\n                lightest_fold = np.argmin(n_samples_per_fold)\n                n_samples_per_fold[lightest_fold] += weight\n                group_to_fold[indices[group_index]] = lightest_fold\n\n            indices = group_to_fold[group_idx]\n\n            for f in range(self.n_splits):\n                yield np.where(indices == f)[0]\n", "type": "function"}, {"name": "_iter_indices", "is_method": true, "class_name": "GroupShuffleSplit", "parameters": ["self", "X", "y", "groups"], "calls": ["check_array", "np.unique", "_iter_indices", "ValueError", "np.flatnonzero", "np.flatnonzero", "super", "np.isin", "np.isin"], "code_location": {"file": "_split.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/model_selection", "start_line": 2177, "end_line": 2189}, "code_snippet": "    def _iter_indices(self, X, y, groups):\n        if groups is None:\n            raise ValueError(\"The 'groups' parameter should not be None.\")\n        groups = check_array(groups, input_name=\"groups\", ensure_2d=False, dtype=None)\n        classes, group_indices = np.unique(groups, return_inverse=True)\n        for group_train, group_test in super()._iter_indices(X=classes):\n            # these are the indices of classes in the partition\n            # invert them into data indices\n\n            train = np.flatnonzero(np.isin(group_indices, group_train))\n            test = np.flatnonzero(np.isin(group_indices, group_test))\n\n            yield train, test\n", "type": "function"}, {"name": "_iter_test_indices", "is_method": true, "class_name": "LeavePOut", "parameters": ["self", "X", "y", "groups"], "calls": ["_num_samples", "combinations", "ValueError", "range", "format", "np.array"], "code_location": {"file": "_split.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/model_selection", "start_line": 311, "end_line": 320}, "code_snippet": "    def _iter_test_indices(self, X, y=None, groups=None):\n        n_samples = _num_samples(X)\n        if n_samples <= self.p:\n            raise ValueError(\n                \"p={} must be strictly less than the number of samples={}\".format(\n                    self.p, n_samples\n                )\n            )\n        for combination in combinations(range(n_samples), self.p):\n            yield np.array(combination)\n", "type": "function"}, {"name": "_iter_test_masks", "is_method": true, "class_name": "StratifiedKFold", "parameters": ["self", "X", "y", "groups"], "calls": ["self._make_test_folds", "range"], "code_location": {"file": "_split.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/model_selection", "start_line": 843, "end_line": 846}, "code_snippet": "    def _iter_test_masks(self, X, y=None, groups=None):\n        test_folds = self._make_test_folds(X, y)\n        for i in range(self.n_splits):\n            yield test_folds == i\n", "type": "function"}, {"name": "_iter_test_indices", "is_method": true, "class_name": "LeaveOneOut", "parameters": ["self", "X", "y", "groups"], "calls": ["_num_samples", "range", "ValueError", "format"], "code_location": {"file": "_split.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/model_selection", "start_line": 217, "end_line": 223}, "code_snippet": "    def _iter_test_indices(self, X, y=None, groups=None):\n        n_samples = _num_samples(X)\n        if n_samples <= 1:\n            raise ValueError(\n                \"Cannot perform LeaveOneOut with n_samples={}.\".format(n_samples)\n            )\n        return range(n_samples)\n", "type": "function"}, {"name": "split", "is_method": true, "class_name": "GroupShuffleSplit", "parameters": ["self", "X", "y", "groups"], "calls": ["split", "super"], "code_location": {"file": "_split.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/model_selection", "start_line": 2191, "end_line": 2221}, "code_snippet": "    def split(self, X, y=None, groups=None):\n        \"\"\"Generate indices to split data into training and test set.\n\n        Parameters\n        ----------\n        X : array-like of shape (n_samples, n_features)\n            Training data, where `n_samples` is the number of samples\n            and `n_features` is the number of features.\n\n        y : array-like of shape (n_samples,), default=None\n            The target variable for supervised learning problems.\n\n        groups : array-like of shape (n_samples,)\n            Group labels for the samples used while splitting the dataset into\n            train/test set.\n\n        Yields\n        ------\n        train : ndarray\n            The training set indices for that split.\n\n        test : ndarray\n            The testing set indices for that split.\n\n        Notes\n        -----\n        Randomized CV splitters may return different results for each call of\n        split. You can make the results identical by setting `random_state`\n        to an integer.\n        \"\"\"\n        return super().split(X, y, groups)\n", "type": "function"}], "retrieved_count": 10, "cost_time": 1.1227126121520996}
{"question": "How does the shrink_threshold parameter implementation in the fit method employ soft thresholding to achieve feature selection, and what data consistency guarantees must be maintained between the deviations_ and centroids_ attributes during this transformation?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"name": "fit", "is_method": true, "class_name": "NearestCentroid", "parameters": ["self", "X", "y"], "calls": ["_fit_context", "sp.issparse", "check_classification_targets", "LabelEncoder", "le.fit_transform", "any", "np.empty", "np.zeros", "range", "np.array", "any", "X.mean", "np.sqrt", "m.reshape", "np.array", "validate_data", "validate_data", "ValueError", "np.unique", "ValueError", "np.isclose", "warnings.warn", "np.sum", "np.array", "np.sqrt", "warnings.warn", "np.all", "ValueError", "np.median", "len", "np.sign", "np.clip", "np.array", "np.bincount", "float", "np.asarray", "np.asarray", "self.class_prior_.sum", "self.class_prior_.sum", "mean", "np.all", "ValueError", "np.abs", "len", "np.where", "np.median", "csc_median_axis_0", "variance.sum", "toarray", "get_tags", "np.ptp", "X.max", "X.min"], "code_location": {"file": "_nearest_centroid.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/neighbors", "start_line": 150, "end_line": 273}, "code_snippet": "    def fit(self, X, y):\n        \"\"\"\n        Fit the NearestCentroid model according to the given training data.\n\n        Parameters\n        ----------\n        X : {array-like, sparse matrix} of shape (n_samples, n_features)\n            Training vector, where `n_samples` is the number of samples and\n            `n_features` is the number of features.\n            Note that centroid shrinking cannot be used with sparse matrices.\n        y : array-like of shape (n_samples,)\n            Target values.\n\n        Returns\n        -------\n        self : object\n            Fitted estimator.\n        \"\"\"\n        # If X is sparse and the metric is \"manhattan\", store it in a csc\n        # format is easier to calculate the median.\n        if self.metric == \"manhattan\":\n            X, y = validate_data(self, X, y, accept_sparse=[\"csc\"])\n        else:\n            ensure_all_finite = (\n                \"allow-nan\" if get_tags(self).input_tags.allow_nan else True\n            )\n            X, y = validate_data(\n                self,\n                X,\n                y,\n                ensure_all_finite=ensure_all_finite,\n                accept_sparse=[\"csr\", \"csc\"],\n            )\n        is_X_sparse = sp.issparse(X)\n        check_classification_targets(y)\n\n        n_samples, n_features = X.shape\n        le = LabelEncoder()\n        y_ind = le.fit_transform(y)\n        self.classes_ = classes = le.classes_\n        n_classes = classes.size\n        if n_classes < 2:\n            raise ValueError(\n                \"The number of classes has to be greater than one; got %d class\"\n                % (n_classes)\n            )\n\n        if self.priors == \"empirical\":  # estimate priors from sample\n            _, class_counts = np.unique(y, return_inverse=True)  # non-negative ints\n            self.class_prior_ = np.bincount(class_counts) / float(len(y))\n        elif self.priors == \"uniform\":\n            self.class_prior_ = np.asarray([1 / n_classes] * n_classes)\n        else:\n            self.class_prior_ = np.asarray(self.priors)\n\n        if (self.class_prior_ < 0).any():\n            raise ValueError(\"priors must be non-negative\")\n        if not np.isclose(self.class_prior_.sum(), 1.0):\n            warnings.warn(\n                \"The priors do not sum to 1. Normalizing such that it sums to one.\",\n                UserWarning,\n            )\n            self.class_prior_ = self.class_prior_ / self.class_prior_.sum()\n\n        # Mask mapping each class to its members.\n        self.centroids_ = np.empty((n_classes, n_features), dtype=np.float64)\n\n        # Number of clusters in each class.\n        nk = np.zeros(n_classes)\n\n        for cur_class in range(n_classes):\n            center_mask = y_ind == cur_class\n            nk[cur_class] = np.sum(center_mask)\n            if is_X_sparse:\n                center_mask = np.where(center_mask)[0]\n\n            if self.metric == \"manhattan\":\n                # NumPy does not calculate median of sparse matrices.\n                if not is_X_sparse:\n                    self.centroids_[cur_class] = np.median(X[center_mask], axis=0)\n                else:\n                    self.centroids_[cur_class] = csc_median_axis_0(X[center_mask])\n            else:  # metric == \"euclidean\"\n                self.centroids_[cur_class] = X[center_mask].mean(axis=0)\n\n        # Compute within-class std_dev with unshrunked centroids\n        variance = np.array(X - self.centroids_[y_ind], copy=False) ** 2\n        self.within_class_std_dev_ = np.array(\n            np.sqrt(variance.sum(axis=0) / (n_samples - n_classes)), copy=False\n        )\n        if any(self.within_class_std_dev_ == 0):\n            warnings.warn(\n                \"self.within_class_std_dev_ has at least 1 zero standard deviation.\"\n                \"Inputs within the same classes for at least 1 feature are identical.\"\n            )\n\n        err_msg = \"All features have zero variance. Division by zero.\"\n        if is_X_sparse and np.all((X.max(axis=0) - X.min(axis=0)).toarray() == 0):\n            raise ValueError(err_msg)\n        elif not is_X_sparse and np.all(np.ptp(X, axis=0) == 0):\n            raise ValueError(err_msg)\n\n        dataset_centroid_ = X.mean(axis=0)\n        # m parameter for determining deviation\n        m = np.sqrt((1.0 / nk) - (1.0 / n_samples))\n        # Calculate deviation using the standard deviation of centroids.\n        # To deter outliers from affecting the results.\n        s = self.within_class_std_dev_ + np.median(self.within_class_std_dev_)\n        mm = m.reshape(len(m), 1)  # Reshape to allow broadcasting.\n        ms = mm * s\n        self.deviations_ = np.array(\n            (self.centroids_ - dataset_centroid_) / ms, copy=False\n        )\n        # Soft thresholding: if the deviation crosses 0 during shrinking,\n        # it becomes zero.\n        if self.shrink_threshold:\n            signs = np.sign(self.deviations_)\n            self.deviations_ = np.abs(self.deviations_) - self.shrink_threshold\n            np.clip(self.deviations_, 0, None, out=self.deviations_)\n            self.deviations_ *= signs\n            # Now adjust the centroids using the deviation\n            msd = ms * self.deviations_\n            self.centroids_ = np.array(dataset_centroid_ + msd, copy=False)\n        return self\n", "type": "function"}, {"name": "_fit", "is_method": true, "class_name": "Birch", "parameters": ["self", "X", "partial"], "calls": ["getattr", "validate_data", "iter_func", "np.concatenate", "self._global_clustering", "warnings.warn", "_CFNode", "_CFNode", "sparse.issparse", "_CFSubcluster", "self.root_.insert_cf_subcluster", "_split_node", "_CFNode", "self.root_.append_subcluster", "self.root_.append_subcluster", "self._get_leaves"], "code_location": {"file": "_birch.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/cluster", "start_line": 534, "end_line": 611}, "code_snippet": "    def _fit(self, X, partial):\n        has_root = getattr(self, \"root_\", None)\n        first_call = not (partial and has_root)\n\n        if self.copy != \"deprecated\" and first_call:\n            warnings.warn(\n                \"`copy` was deprecated in 1.6 and will be removed in 1.8 since it \"\n                \"has no effect internally. Simply leave this parameter to its default \"\n                \"value to avoid this warning.\",\n                FutureWarning,\n            )\n\n        X = validate_data(\n            self,\n            X,\n            accept_sparse=\"csr\",\n            reset=first_call,\n            dtype=[np.float64, np.float32],\n        )\n        threshold = self.threshold\n        branching_factor = self.branching_factor\n\n        n_samples, n_features = X.shape\n\n        # If partial_fit is called for the first time or fit is called, we\n        # start a new tree.\n        if first_call:\n            # The first root is the leaf. Manipulate this object throughout.\n            self.root_ = _CFNode(\n                threshold=threshold,\n                branching_factor=branching_factor,\n                is_leaf=True,\n                n_features=n_features,\n                dtype=X.dtype,\n            )\n\n            # To enable getting back subclusters.\n            self.dummy_leaf_ = _CFNode(\n                threshold=threshold,\n                branching_factor=branching_factor,\n                is_leaf=True,\n                n_features=n_features,\n                dtype=X.dtype,\n            )\n            self.dummy_leaf_.next_leaf_ = self.root_\n            self.root_.prev_leaf_ = self.dummy_leaf_\n\n        # Cannot vectorize. Enough to convince to use cython.\n        if not sparse.issparse(X):\n            iter_func = iter\n        else:\n            iter_func = _iterate_sparse_X\n\n        for sample in iter_func(X):\n            subcluster = _CFSubcluster(linear_sum=sample)\n            split = self.root_.insert_cf_subcluster(subcluster)\n\n            if split:\n                new_subcluster1, new_subcluster2 = _split_node(\n                    self.root_, threshold, branching_factor\n                )\n                del self.root_\n                self.root_ = _CFNode(\n                    threshold=threshold,\n                    branching_factor=branching_factor,\n                    is_leaf=False,\n                    n_features=n_features,\n                    dtype=X.dtype,\n                )\n                self.root_.append_subcluster(new_subcluster1)\n                self.root_.append_subcluster(new_subcluster2)\n\n        centroids = np.concatenate([leaf.centroids_ for leaf in self._get_leaves()])\n        self.subcluster_centers_ = centroids\n        self._n_features_out = self.subcluster_centers_.shape[0]\n\n        self._global_clustering(X)\n        return self\n", "type": "function"}, {"name": "_get_support_mask", "is_method": true, "class_name": "VarianceThreshold", "parameters": ["self"], "calls": ["check_is_fitted"], "code_location": {"file": "_variance_threshold.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/feature_selection", "start_line": 132, "end_line": 135}, "code_snippet": "    def _get_support_mask(self):\n        check_is_fitted(self)\n\n        return self.variances_ > self.threshold\n", "type": "function"}, {"name": "__init__", "is_method": true, "class_name": "ShrunkCovariance", "parameters": ["self"], "calls": ["__init__", "super"], "code_location": {"file": "_shrunk_covariance.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/covariance", "start_line": 248, "end_line": 252}, "code_snippet": "    def __init__(self, *, store_precision=True, assume_centered=False, shrinkage=0.1):\n        super().__init__(\n            store_precision=store_precision, assume_centered=assume_centered\n        )\n        self.shrinkage = shrinkage\n", "type": "function"}, {"name": "__init__", "is_method": true, "class_name": "NearestCentroid", "parameters": ["self", "metric"], "calls": [], "code_location": {"file": "_nearest_centroid.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/neighbors", "start_line": 138, "end_line": 147}, "code_snippet": "    def __init__(\n        self,\n        metric=\"euclidean\",\n        *,\n        shrink_threshold=None,\n        priors=\"uniform\",\n    ):\n        self.metric = metric\n        self.shrink_threshold = shrink_threshold\n        self.priors = priors\n", "type": "function"}, {"name": "_fit", "is_method": true, "class_name": "SpectralCoclustering", "parameters": ["self", "X"], "calls": ["_scale_normalize", "self._svd", "np.vstack", "self._k_means", "np.vstack", "np.vstack", "int", "np.ceil", "np.log2", "range", "range"], "code_location": {"file": "_bicluster.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/cluster", "start_line": 342, "end_line": 357}, "code_snippet": "    def _fit(self, X):\n        normalized_data, row_diag, col_diag = _scale_normalize(X)\n        n_sv = 1 + int(np.ceil(np.log2(self.n_clusters)))\n        u, v = self._svd(normalized_data, n_sv, n_discard=1)\n        z = np.vstack((row_diag[:, np.newaxis] * u, col_diag[:, np.newaxis] * v))\n\n        _, labels = self._k_means(z, self.n_clusters)\n\n        n_rows = X.shape[0]\n        self.row_labels_ = labels[:n_rows]\n        self.column_labels_ = labels[n_rows:]\n\n        self.rows_ = np.vstack([self.row_labels_ == c for c in range(self.n_clusters)])\n        self.columns_ = np.vstack(\n            [self.column_labels_ == c for c in range(self.n_clusters)]\n        )\n", "type": "function"}, {"name": "test_kmeans_copyx", "is_method": false, "class_name": null, "parameters": [], "calls": ["X.copy", "KMeans", "km.fit", "_check_fitted_model", "assert_allclose"], "code_location": {"file": "test_k_means.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/cluster/tests", "start_line": 596, "end_line": 604}, "code_snippet": "def test_kmeans_copyx():\n    # Check that copy_x=False returns nearly equal X after de-centering.\n    my_X = X.copy()\n    km = KMeans(copy_x=False, n_clusters=n_clusters, random_state=42)\n    km.fit(my_X)\n    _check_fitted_model(km)\n\n    # check that my_X is de-centered\n    assert_allclose(my_X, X)\n", "type": "function"}, {"name": "_fit", "is_method": true, "class_name": "SpectralBiclustering", "parameters": ["self", "X"], "calls": ["self._svd", "self._fit_best_piecewise", "self._fit_best_piecewise", "self._project_and_cluster", "self._project_and_cluster", "np.vstack", "np.vstack", "_bistochastic_normalize", "_scale_normalize", "_log_normalize", "range", "range", "range", "range"], "code_location": {"file": "_bicluster.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/cluster", "start_line": 556, "end_line": 597}, "code_snippet": "    def _fit(self, X):\n        n_sv = self.n_components\n        if self.method == \"bistochastic\":\n            normalized_data = _bistochastic_normalize(X)\n            n_sv += 1\n        elif self.method == \"scale\":\n            normalized_data, _, _ = _scale_normalize(X)\n            n_sv += 1\n        elif self.method == \"log\":\n            normalized_data = _log_normalize(X)\n        n_discard = 0 if self.method == \"log\" else 1\n        u, v = self._svd(normalized_data, n_sv, n_discard)\n        ut = u.T\n        vt = v.T\n\n        try:\n            n_row_clusters, n_col_clusters = self.n_clusters\n        except TypeError:\n            n_row_clusters = n_col_clusters = self.n_clusters\n\n        best_ut = self._fit_best_piecewise(ut, self.n_best, n_row_clusters)\n\n        best_vt = self._fit_best_piecewise(vt, self.n_best, n_col_clusters)\n\n        self.row_labels_ = self._project_and_cluster(X, best_vt.T, n_row_clusters)\n\n        self.column_labels_ = self._project_and_cluster(X.T, best_ut.T, n_col_clusters)\n\n        self.rows_ = np.vstack(\n            [\n                self.row_labels_ == label\n                for label in range(n_row_clusters)\n                for _ in range(n_col_clusters)\n            ]\n        )\n        self.columns_ = np.vstack(\n            [\n                self.column_labels_ == label\n                for _ in range(n_row_clusters)\n                for label in range(n_col_clusters)\n            ]\n        )\n", "type": "function"}, {"name": "_fit_transform", "is_method": true, "class_name": "LocallyLinearEmbedding", "parameters": ["self", "X"], "calls": ["NearestNeighbors", "check_random_state", "validate_data", "self.nbrs_.fit", "_locally_linear_embedding"], "code_location": {"file": "_locally_linear.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/manifold", "start_line": 784, "end_line": 808}, "code_snippet": "    def _fit_transform(self, X):\n        self.nbrs_ = NearestNeighbors(\n            n_neighbors=self.n_neighbors,\n            algorithm=self.neighbors_algorithm,\n            n_jobs=self.n_jobs,\n        )\n\n        random_state = check_random_state(self.random_state)\n        X = validate_data(self, X, dtype=float)\n        self.nbrs_.fit(X)\n        self.embedding_, self.reconstruction_error_ = _locally_linear_embedding(\n            X=self.nbrs_,\n            n_neighbors=self.n_neighbors,\n            n_components=self.n_components,\n            eigen_solver=self.eigen_solver,\n            tol=self.tol,\n            max_iter=self.max_iter,\n            method=self.method,\n            hessian_tol=self.hessian_tol,\n            modified_tol=self.modified_tol,\n            random_state=random_state,\n            reg=self.reg,\n            n_jobs=self.n_jobs,\n        )\n        self._n_features_out = self.embedding_.shape[1]\n", "type": "function"}, {"name": "_fit", "is_method": true, "class_name": "RFE", "parameters": ["self", "X", "y", "step_score"], "calls": ["validate_data", "np.ones", "np.ones", "clone", "self.estimator_.fit", "support_.sum", "isinstance", "int", "int", "np.sum", "clone", "estimator.fit", "_get_feature_importances", "np.argsort", "np.ravel", "min", "np.arange", "self.step_n_features_.append", "self.step_scores_.append", "self.step_support_.append", "self.step_ranking_.append", "int", "max", "np.arange", "print", "self.step_n_features_.append", "self.step_scores_.append", "self.step_support_.append", "self.step_ranking_.append", "np.logical_not", "len", "step_score", "warnings.warn", "len", "step_score", "list", "list", "np.sum", "np.sum"], "code_location": {"file": "_rfe.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/feature_selection", "start_line": 284, "end_line": 382}, "code_snippet": "    def _fit(self, X, y, step_score=None, **fit_params):\n        # Parameter step_score controls the calculation of self.step_scores_\n        # step_score is not exposed to users and is used when implementing RFECV\n        # self.step_scores_ will not be calculated when calling _fit through fit\n\n        X, y = validate_data(\n            self,\n            X,\n            y,\n            accept_sparse=\"csc\",\n            ensure_min_features=2,\n            ensure_all_finite=False,\n            multi_output=True,\n        )\n\n        # Initialization\n        n_features = X.shape[1]\n        if self.n_features_to_select is None:\n            n_features_to_select = n_features // 2\n        elif isinstance(self.n_features_to_select, Integral):  # int\n            n_features_to_select = self.n_features_to_select\n            if n_features_to_select > n_features:\n                warnings.warn(\n                    (\n                        f\"Found {n_features_to_select=} > {n_features=}. There will be\"\n                        \" no feature selection and all features will be kept.\"\n                    ),\n                    UserWarning,\n                )\n        else:  # float\n            n_features_to_select = int(n_features * self.n_features_to_select)\n\n        if 0.0 < self.step < 1.0:\n            step = int(max(1, self.step * n_features))\n        else:\n            step = int(self.step)\n\n        support_ = np.ones(n_features, dtype=bool)\n        ranking_ = np.ones(n_features, dtype=int)\n\n        if step_score:\n            self.step_n_features_ = []\n            self.step_scores_ = []\n            self.step_support_ = []\n            self.step_ranking_ = []\n\n        # Elimination\n        while np.sum(support_) > n_features_to_select:\n            # Remaining features\n            features = np.arange(n_features)[support_]\n\n            # Rank the remaining features\n            estimator = clone(self.estimator)\n            if self.verbose > 0:\n                print(\"Fitting estimator with %d features.\" % np.sum(support_))\n\n            estimator.fit(X[:, features], y, **fit_params)\n\n            # Compute step values on the previous selection iteration because\n            # 'estimator' must use features that have not been eliminated yet\n            if step_score:\n                self.step_n_features_.append(len(features))\n                self.step_scores_.append(step_score(estimator, features))\n                self.step_support_.append(list(support_))\n                self.step_ranking_.append(list(ranking_))\n\n            # Get importance and rank them\n            importances = _get_feature_importances(\n                estimator,\n                self.importance_getter,\n                transform_func=\"square\",\n            )\n            ranks = np.argsort(importances)\n\n            # for sparse case ranks is matrix\n            ranks = np.ravel(ranks)\n\n            # Eliminate the worse features\n            threshold = min(step, np.sum(support_) - n_features_to_select)\n\n            support_[features[ranks][:threshold]] = False\n            ranking_[np.logical_not(support_)] += 1\n\n        # Set final attributes\n        features = np.arange(n_features)[support_]\n        self.estimator_ = clone(self.estimator)\n        self.estimator_.fit(X[:, features], y, **fit_params)\n\n        # Compute step values when only n_features_to_select features left\n        if step_score:\n            self.step_n_features_.append(len(features))\n            self.step_scores_.append(step_score(self.estimator_, features))\n            self.step_support_.append(support_)\n            self.step_ranking_.append(ranking_)\n        self.n_features_ = support_.sum()\n        self.support_ = support_\n        self.ranking_ = ranking_\n\n        return self\n", "type": "function"}], "retrieved_count": 10, "cost_time": 1.1562590599060059}
{"question": "Why does the cache lookup strategy in _cached_call affect the performance characteristics of repeated metric computations across multiple cross-validation folds, and what are the trade-offs between cache hit rates and memory overhead for large-scale datasets?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"name": "cross_validate", "is_method": false, "class_name": null, "parameters": ["estimator", "X", "y"], "calls": ["validate_params", "_check_groups_routing_disabled", "indexable", "check_cv", "check_scoring", "_routing_enabled", "cv.split", "Parallel", "parallel", "_warn_or_raise_about_fit_failures", "callable", "_aggregate_score_dicts", "_normalize_score_results", "add", "Bunch", "Bunch", "Bunch", "Bunch", "list", "_insert_error_scores", "zip", "_normalize_score_results", "is_classifier", "process_routing", "HasMethods", "StrOptions", "StrOptions", "add", "add", "UnsetMetadataPassedError", "delayed", "clone", "set", "get_scorer_names", "add", "add", "MethodMapping", "replace", "MetadataRouter", "add", "MethodMapping", "str", "MethodMapping"], "code_location": {"file": "_validation.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/model_selection", "start_line": 124, "end_line": 450}, "code_snippet": "def cross_validate(\n    estimator,\n    X,\n    y=None,\n    *,\n    groups=None,\n    scoring=None,\n    cv=None,\n    n_jobs=None,\n    verbose=0,\n    params=None,\n    pre_dispatch=\"2*n_jobs\",\n    return_train_score=False,\n    return_estimator=False,\n    return_indices=False,\n    error_score=np.nan,\n):\n    \"\"\"Evaluate metric(s) by cross-validation and also record fit/score times.\n\n    Read more in the :ref:`User Guide <multimetric_cross_validation>`.\n\n    Parameters\n    ----------\n    estimator : estimator object implementing 'fit'\n        The object to use to fit the data.\n\n    X : {array-like, sparse matrix} of shape (n_samples, n_features)\n        The data to fit. Can be for example a list, or an array.\n\n    y : array-like of shape (n_samples,) or (n_samples, n_outputs), default=None\n        The target variable to try to predict in the case of\n        supervised learning.\n\n    groups : array-like of shape (n_samples,), default=None\n        Group labels for the samples used while splitting the dataset into\n        train/test set. Only used in conjunction with a \"Group\" :term:`cv`\n        instance (e.g., :class:`GroupKFold`).\n\n        .. versionchanged:: 1.4\n            ``groups`` can only be passed if metadata routing is not enabled\n            via ``sklearn.set_config(enable_metadata_routing=True)``. When routing\n            is enabled, pass ``groups`` alongside other metadata via the ``params``\n            argument instead. E.g.:\n            ``cross_validate(..., params={'groups': groups})``.\n\n    scoring : str, callable, list, tuple, or dict, default=None\n        Strategy to evaluate the performance of the `estimator` across cross-validation\n        splits.\n\n        If `scoring` represents a single score, one can use:\n\n        - a single string (see :ref:`scoring_string_names`);\n        - a callable (see :ref:`scoring_callable`) that returns a single value.\n        - `None`, the `estimator`'s\n          :ref:`default evaluation criterion <scoring_api_overview>` is used.\n\n        If `scoring` represents multiple scores, one can use:\n\n        - a list or tuple of unique strings;\n        - a callable returning a dictionary where the keys are the metric\n          names and the values are the metric scores;\n        - a dictionary with metric names as keys and callables a values.\n\n        See :ref:`multimetric_grid_search` for an example.\n\n    cv : int, cross-validation generator or an iterable, default=None\n        Determines the cross-validation splitting strategy.\n        Possible inputs for cv are:\n\n        - None, to use the default 5-fold cross validation,\n        - int, to specify the number of folds in a `(Stratified)KFold`,\n        - :term:`CV splitter`,\n        - An iterable yielding (train, test) splits as arrays of indices.\n\n        For int/None inputs, if the estimator is a classifier and ``y`` is\n        either binary or multiclass, :class:`StratifiedKFold` is used. In all\n        other cases, :class:`KFold` is used. These splitters are instantiated\n        with `shuffle=False` so the splits will be the same across calls.\n\n        Refer :ref:`User Guide <cross_validation>` for the various\n        cross-validation strategies that can be used here.\n\n        .. versionchanged:: 0.22\n            ``cv`` default value if None changed from 3-fold to 5-fold.\n\n    n_jobs : int, default=None\n        Number of jobs to run in parallel. Training the estimator and computing\n        the score are parallelized over the cross-validation splits.\n        ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n        ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n        for more details.\n\n    verbose : int, default=0\n        The verbosity level.\n\n    params : dict, default=None\n        Parameters to pass to the underlying estimator's ``fit``, the scorer,\n        and the CV splitter.\n\n        .. versionadded:: 1.4\n\n    pre_dispatch : int or str, default='2*n_jobs'\n        Controls the number of jobs that get dispatched during parallel\n        execution. Reducing this number can be useful to avoid an\n        explosion of memory consumption when more jobs get dispatched\n        than CPUs can process. This parameter can be:\n\n        - An int, giving the exact number of total jobs that are spawned\n        - A str, giving an expression as a function of n_jobs, as in '2*n_jobs'\n\n    return_train_score : bool, default=False\n        Whether to include train scores.\n        Computing training scores is used to get insights on how different\n        parameter settings impact the overfitting/underfitting trade-off.\n        However computing the scores on the training set can be computationally\n        expensive and is not strictly required to select the parameters that\n        yield the best generalization performance.\n\n        .. versionadded:: 0.19\n\n        .. versionchanged:: 0.21\n            Default value was changed from ``True`` to ``False``\n\n    return_estimator : bool, default=False\n        Whether to return the estimators fitted on each split.\n\n        .. versionadded:: 0.20\n\n    return_indices : bool, default=False\n        Whether to return the train-test indices selected for each split.\n\n        .. versionadded:: 1.3\n\n    error_score : 'raise' or numeric, default=np.nan\n        Value to assign to the score if an error occurs in estimator fitting.\n        If set to 'raise', the error is raised.\n        If a numeric value is given, FitFailedWarning is raised.\n\n        .. versionadded:: 0.20\n\n    Returns\n    -------\n    scores : dict of float arrays of shape (n_splits,)\n        Array of scores of the estimator for each run of the cross validation.\n\n        A dict of arrays containing the score/time arrays for each scorer is\n        returned. The possible keys for this ``dict`` are:\n\n        ``test_score``\n            The score array for test scores on each cv split.\n            Suffix ``_score`` in ``test_score`` changes to a specific\n            metric like ``test_r2`` or ``test_auc`` if there are\n            multiple scoring metrics in the scoring parameter.\n        ``train_score``\n            The score array for train scores on each cv split.\n            Suffix ``_score`` in ``train_score`` changes to a specific\n            metric like ``train_r2`` or ``train_auc`` if there are\n            multiple scoring metrics in the scoring parameter.\n            This is available only if ``return_train_score`` parameter\n            is ``True``.\n        ``fit_time``\n            The time for fitting the estimator on the train\n            set for each cv split.\n        ``score_time``\n            The time for scoring the estimator on the test set for each\n            cv split. (Note: time for scoring on the train set is not\n            included even if ``return_train_score`` is set to ``True``).\n        ``estimator``\n            The estimator objects for each cv split.\n            This is available only if ``return_estimator`` parameter\n            is set to ``True``.\n        ``indices``\n            The train/test positional indices for each cv split. A dictionary\n            is returned where the keys are either `\"train\"` or `\"test\"`\n            and the associated values are a list of integer-dtyped NumPy\n            arrays with the indices. Available only if `return_indices=True`.\n\n    See Also\n    --------\n    cross_val_score : Run cross-validation for single metric evaluation.\n\n    cross_val_predict : Get predictions from each split of cross-validation for\n        diagnostic purposes.\n\n    sklearn.metrics.make_scorer : Make a scorer from a performance metric or\n        loss function.\n\n    Examples\n    --------\n    >>> from sklearn import datasets, linear_model\n    >>> from sklearn.model_selection import cross_validate\n    >>> from sklearn.metrics import make_scorer\n    >>> from sklearn.metrics import confusion_matrix\n    >>> from sklearn.svm import LinearSVC\n    >>> diabetes = datasets.load_diabetes()\n    >>> X = diabetes.data[:150]\n    >>> y = diabetes.target[:150]\n    >>> lasso = linear_model.Lasso()\n\n    Single metric evaluation using ``cross_validate``\n\n    >>> cv_results = cross_validate(lasso, X, y, cv=3)\n    >>> sorted(cv_results.keys())\n    ['fit_time', 'score_time', 'test_score']\n    >>> cv_results['test_score']\n    array([0.3315057 , 0.08022103, 0.03531816])\n\n    Multiple metric evaluation using ``cross_validate``\n    (please refer the ``scoring`` parameter doc for more information)\n\n    >>> scores = cross_validate(lasso, X, y, cv=3,\n    ...                         scoring=('r2', 'neg_mean_squared_error'),\n    ...                         return_train_score=True)\n    >>> print(scores['test_neg_mean_squared_error'])\n    [-3635.5 -3573.3 -6114.7]\n    >>> print(scores['train_r2'])\n    [0.28009951 0.3908844  0.22784907]\n    \"\"\"\n    _check_groups_routing_disabled(groups)\n\n    X, y = indexable(X, y)\n    params = {} if params is None else params\n    cv = check_cv(cv, y, classifier=is_classifier(estimator))\n\n    scorers = check_scoring(\n        estimator, scoring=scoring, raise_exc=(error_score == \"raise\")\n    )\n\n    if _routing_enabled():\n        # For estimators, a MetadataRouter is created in get_metadata_routing\n        # methods. For these router methods, we create the router to use\n        # `process_routing` on it.\n        router = (\n            MetadataRouter(owner=\"cross_validate\")\n            .add(\n                splitter=cv,\n                method_mapping=MethodMapping().add(caller=\"fit\", callee=\"split\"),\n            )\n            .add(\n                estimator=estimator,\n                # TODO(SLEP6): also pass metadata to the predict method for\n                # scoring?\n                method_mapping=MethodMapping().add(caller=\"fit\", callee=\"fit\"),\n            )\n            .add(\n                scorer=scorers,\n                method_mapping=MethodMapping().add(caller=\"fit\", callee=\"score\"),\n            )\n        )\n        try:\n            routed_params = process_routing(router, \"fit\", **params)\n        except UnsetMetadataPassedError as e:\n            # The default exception would mention `fit` since in the above\n            # `process_routing` code, we pass `fit` as the caller. However,\n            # the user is not calling `fit` directly, so we change the message\n            # to make it more suitable for this case.\n            raise UnsetMetadataPassedError(\n                message=str(e).replace(\"cross_validate.fit\", \"cross_validate\"),\n                unrequested_params=e.unrequested_params,\n                routed_params=e.routed_params,\n            )\n    else:\n        routed_params = Bunch()\n        routed_params.splitter = Bunch(split={\"groups\": groups})\n        routed_params.estimator = Bunch(fit=params)\n        routed_params.scorer = Bunch(score={})\n\n    indices = cv.split(X, y, **routed_params.splitter.split)\n    if return_indices:\n        # materialize the indices since we need to store them in the returned dict\n        indices = list(indices)\n\n    # We clone the estimator to make sure that all the folds are\n    # independent, and that it is pickle-able.\n    parallel = Parallel(n_jobs=n_jobs, verbose=verbose, pre_dispatch=pre_dispatch)\n    results = parallel(\n        delayed(_fit_and_score)(\n            clone(estimator),\n            X,\n            y,\n            scorer=scorers,\n            train=train,\n            test=test,\n            verbose=verbose,\n            parameters=None,\n            fit_params=routed_params.estimator.fit,\n            score_params=routed_params.scorer.score,\n            return_train_score=return_train_score,\n            return_times=True,\n            return_estimator=return_estimator,\n            error_score=error_score,\n        )\n        for train, test in indices\n    )\n\n    _warn_or_raise_about_fit_failures(results, error_score)\n\n    # For callable scoring, the return type is only know after calling. If the\n    # return type is a dictionary, the error scores can now be inserted with\n    # the correct key.\n    if callable(scoring):\n        _insert_error_scores(results, error_score)\n\n    results = _aggregate_score_dicts(results)\n\n    ret = {}\n    ret[\"fit_time\"] = results[\"fit_time\"]\n    ret[\"score_time\"] = results[\"score_time\"]\n\n    if return_estimator:\n        ret[\"estimator\"] = results[\"estimator\"]\n\n    if return_indices:\n        ret[\"indices\"] = {}\n        ret[\"indices\"][\"train\"], ret[\"indices\"][\"test\"] = zip(*indices)\n\n    test_scores_dict = _normalize_score_results(results[\"test_scores\"])\n    if return_train_score:\n        train_scores_dict = _normalize_score_results(results[\"train_scores\"])\n\n    for name in test_scores_dict:\n        ret[\"test_%s\" % name] = test_scores_dict[name]\n        if return_train_score:\n            key = \"train_%s\" % name\n            ret[key] = train_scores_dict[name]\n\n    return ret\n", "type": "function"}, {"name": "check_cross_validate_single_metric", "is_method": false, "class_name": null, "parameters": ["clf", "X", "y", "scores", "cv"], "calls": ["cross_validate", "enumerate", "isinstance", "assert_array_almost_equal", "isinstance", "assert_array_almost_equal", "est.coef_.copy", "issparse", "coef_.copy", "issparse", "assert_almost_equal", "assert_almost_equal", "cross_validate", "assert_array_almost_equal", "cross_validate", "len", "cross_validate", "assert_array_almost_equal", "cross_validate", "len", "est_coef.toarray", "fitted_est_coef.toarray"], "code_location": {"file": "test_validation.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/model_selection/tests", "start_line": 464, "end_line": 527}, "code_snippet": "def check_cross_validate_single_metric(clf, X, y, scores, cv):\n    (\n        train_mse_scores,\n        test_mse_scores,\n        train_r2_scores,\n        test_r2_scores,\n        fitted_estimators,\n    ) = scores\n    # Test single metric evaluation when scoring is string or singleton list\n    for return_train_score, dict_len in ((True, 4), (False, 3)):\n        # Single metric passed as a string\n        if return_train_score:\n            mse_scores_dict = cross_validate(\n                clf,\n                X,\n                y,\n                scoring=\"neg_mean_squared_error\",\n                return_train_score=True,\n                cv=cv,\n            )\n            assert_array_almost_equal(mse_scores_dict[\"train_score\"], train_mse_scores)\n        else:\n            mse_scores_dict = cross_validate(\n                clf,\n                X,\n                y,\n                scoring=\"neg_mean_squared_error\",\n                return_train_score=False,\n                cv=cv,\n            )\n        assert isinstance(mse_scores_dict, dict)\n        assert len(mse_scores_dict) == dict_len\n        assert_array_almost_equal(mse_scores_dict[\"test_score\"], test_mse_scores)\n\n        # Single metric passed as a list\n        if return_train_score:\n            # It must be True by default - deprecated\n            r2_scores_dict = cross_validate(\n                clf, X, y, scoring=[\"r2\"], return_train_score=True, cv=cv\n            )\n            assert_array_almost_equal(r2_scores_dict[\"train_r2\"], train_r2_scores, True)\n        else:\n            r2_scores_dict = cross_validate(\n                clf, X, y, scoring=[\"r2\"], return_train_score=False, cv=cv\n            )\n        assert isinstance(r2_scores_dict, dict)\n        assert len(r2_scores_dict) == dict_len\n        assert_array_almost_equal(r2_scores_dict[\"test_r2\"], test_r2_scores)\n\n    # Test return_estimator option\n    mse_scores_dict = cross_validate(\n        clf, X, y, scoring=\"neg_mean_squared_error\", return_estimator=True, cv=cv\n    )\n    for k, est in enumerate(mse_scores_dict[\"estimator\"]):\n        est_coef = est.coef_.copy()\n        if issparse(est_coef):\n            est_coef = est_coef.toarray()\n\n        fitted_est_coef = fitted_estimators[k].coef_.copy()\n        if issparse(fitted_est_coef):\n            fitted_est_coef = fitted_est_coef.toarray()\n\n        assert_almost_equal(est_coef, fitted_est_coef)\n        assert_almost_equal(est.intercept_, fitted_estimators[k].intercept_)\n", "type": "function"}, {"name": "_use_cache", "is_method": true, "class_name": "_MultimetricScorer", "parameters": ["self", "estimator"], "calls": ["Counter", "any", "len", "_check_response_method", "self._scorers.values", "isinstance", "counter.values"], "code_location": {"file": "_scorer.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/metrics", "start_line": 178, "end_line": 197}, "code_snippet": "    def _use_cache(self, estimator):\n        \"\"\"Return True if using a cache is beneficial, thus when a response method will\n        be called several time.\n        \"\"\"\n        if len(self._scorers) == 1:  # Only one scorer\n            return False\n\n        counter = Counter(\n            [\n                _check_response_method(estimator, scorer._response_method).__name__\n                for scorer in self._scorers.values()\n                if isinstance(scorer, _BaseScorer)\n            ]\n        )\n        if any(val > 1 for val in counter.values()):\n            # The exact same response method or iterable of response methods\n            # will be called more than once.\n            return True\n\n        return False\n", "type": "function"}, {"name": "_MultimetricScorer", "docstring": "Callable for multimetric scoring used to avoid repeated calls\nto `predict_proba`, `predict`, and `decision_function`.\n\n`_MultimetricScorer` will return a dictionary of scores corresponding to\nthe scorers in the dictionary. Note that `_MultimetricScorer` can be\ncreated with a dictionary with one key  (i.e. only one actual scorer).\n\nParameters\n----------\nscorers : dict\n    Dictionary mapping names to callable scorers.\n\nraise_exc : bool, default=True\n    Whether to raise the exception in `__call__` or not. If set to `False`\n    a formatted string of the exception details is passed as result of\n    the failing scorer.", "methods": ["__init__", "__call__", "__repr__", "_accept_sample_weight", "_use_cache", "get_metadata_routing"], "attributes": [], "code_location": {"file": "_scorer.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/metrics", "start_line": 105, "end_line": 216}, "type": "class"}, {"name": "test_callable_multimetric_same_as_list_of_strings", "is_method": false, "class_name": null, "parameters": [], "calls": ["make_classification", "LinearSVC", "GridSearchCV", "GridSearchCV", "search_callable.fit", "search_str.fit", "est.predict", "pytest.approx", "search_callable.score", "pytest.approx", "recall_score", "accuracy_score", "search_str.score"], "code_location": {"file": "test_search.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/model_selection/tests", "start_line": 2229, "end_line": 2252}, "code_snippet": "def test_callable_multimetric_same_as_list_of_strings():\n    # Test callable multimetric is the same as a list of strings\n    def custom_scorer(est, X, y):\n        y_pred = est.predict(X)\n        return {\n            \"recall\": recall_score(y, y_pred),\n            \"accuracy\": accuracy_score(y, y_pred),\n        }\n\n    X, y = make_classification(n_samples=40, n_features=4, random_state=42)\n    est = LinearSVC(random_state=42)\n    search_callable = GridSearchCV(\n        est, {\"C\": [0.1, 1]}, scoring=custom_scorer, refit=\"recall\"\n    )\n    search_str = GridSearchCV(\n        est, {\"C\": [0.1, 1]}, scoring=[\"recall\", \"accuracy\"], refit=\"recall\"\n    )\n\n    search_callable.fit(X, y)\n    search_str.fit(X, y)\n\n    assert search_callable.best_score_ == pytest.approx(search_str.best_score_)\n    assert search_callable.best_index_ == search_str.best_index_\n    assert search_callable.score(X, y) == pytest.approx(search_str.score(X, y))\n", "type": "function"}, {"name": "test_callable_single_metric_same_as_single_string", "is_method": false, "class_name": null, "parameters": [], "calls": ["make_classification", "LinearSVC", "GridSearchCV", "GridSearchCV", "GridSearchCV", "search_callable.fit", "search_str.fit", "search_list_str.fit", "est.predict", "recall_score", "pytest.approx", "search_callable.score", "pytest.approx", "pytest.approx", "search_list_str.score", "pytest.approx", "search_str.score", "search_str.score"], "code_location": {"file": "test_search.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/model_selection/tests", "start_line": 2255, "end_line": 2280}, "code_snippet": "def test_callable_single_metric_same_as_single_string():\n    # Tests callable scorer is the same as scoring with a single string\n    def custom_scorer(est, X, y):\n        y_pred = est.predict(X)\n        return recall_score(y, y_pred)\n\n    X, y = make_classification(n_samples=40, n_features=4, random_state=42)\n    est = LinearSVC(random_state=42)\n    search_callable = GridSearchCV(\n        est, {\"C\": [0.1, 1]}, scoring=custom_scorer, refit=True\n    )\n    search_str = GridSearchCV(est, {\"C\": [0.1, 1]}, scoring=\"recall\", refit=\"recall\")\n    search_list_str = GridSearchCV(\n        est, {\"C\": [0.1, 1]}, scoring=[\"recall\"], refit=\"recall\"\n    )\n    search_callable.fit(X, y)\n    search_str.fit(X, y)\n    search_list_str.fit(X, y)\n\n    assert search_callable.best_score_ == pytest.approx(search_str.best_score_)\n    assert search_callable.best_index_ == search_str.best_index_\n    assert search_callable.score(X, y) == pytest.approx(search_str.score(X, y))\n\n    assert search_list_str.best_score_ == pytest.approx(search_str.best_score_)\n    assert search_list_str.best_index_ == search_str.best_index_\n    assert search_list_str.score(X, y) == pytest.approx(search_str.score(X, y))\n", "type": "function"}, {"name": "_score", "is_method": true, "class_name": "ConsumingScorer", "parameters": ["self", "method_caller", "clf", "X", "y"], "calls": ["record_metadata_not_default", "kwargs.get", "_score", "self.registry.append", "super"], "code_location": {"file": "metadata_routing_common.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/tests", "start_line": 446, "end_line": 453}, "code_snippet": "    def _score(self, method_caller, clf, X, y, **kwargs):\n        if self.registry is not None:\n            self.registry.append(self)\n\n        record_metadata_not_default(self, **kwargs)\n\n        sample_weight = kwargs.get(\"sample_weight\", None)\n        return super()._score(method_caller, clf, X, y, sample_weight=sample_weight)\n", "type": "function"}, {"name": "test_grid_search_cv_results_multimetric", "is_method": false, "class_name": null, "parameters": [], "calls": ["make_classification", "compare_cv_results_multimetric_with_single", "dict", "dict", "GridSearchCV", "grid_search.fit", "grid_searches.append", "make_scorer", "make_scorer", "SVC"], "code_location": {"file": "test_search.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/model_selection/tests", "start_line": 1172, "end_line": 1204}, "code_snippet": "def test_grid_search_cv_results_multimetric():\n    X, y = make_classification(n_samples=50, n_features=4, random_state=42)\n\n    n_splits = 3\n    params = [\n        dict(\n            kernel=[\n                \"rbf\",\n            ],\n            C=[1, 10],\n            gamma=[0.1, 1],\n        ),\n        dict(\n            kernel=[\n                \"poly\",\n            ],\n            degree=[1, 2],\n        ),\n    ]\n\n    grid_searches = []\n    for scoring in (\n        {\"accuracy\": make_scorer(accuracy_score), \"recall\": make_scorer(recall_score)},\n        \"accuracy\",\n        \"recall\",\n    ):\n        grid_search = GridSearchCV(\n            SVC(), cv=n_splits, param_grid=params, scoring=scoring, refit=False\n        )\n        grid_search.fit(X, y)\n        grid_searches.append(grid_search)\n\n    compare_cv_results_multimetric_with_single(*grid_searches)\n", "type": "function"}, {"name": "learning_curve", "is_method": false, "class_name": null, "parameters": ["estimator", "X", "y"], "calls": ["validate_params", "np.linspace", "_check_params_groups_deprecation", "indexable", "check_cv", "check_scoring", "_routing_enabled", "list", "len", "_translate_train_sizes", "Parallel", "ValueError", "add", "Bunch", "Bunch", "Bunch", "Bunch", "cv.split", "print", "check_random_state", "parallel", "transpose", "parallel", "_warn_or_raise_about_fit_failures", "_aggregate_score_dicts", "hasattr", "is_classifier", "process_routing", "is_classifier", "np.unique", "reshape", "reshape", "out.extend", "HasMethods", "StrOptions", "StrOptions", "add", "add", "UnsetMetadataPassedError", "str", "rng.permutation", "np.asarray", "train_test_proportions.append", "reshape", "reshape", "set", "delayed", "clone", "delayed", "clone", "get_scorer_names", "add", "add", "MethodMapping", "replace", "MetadataRouter", "add", "MethodMapping", "str", "add", "MethodMapping"], "code_location": {"file": "_validation.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/model_selection", "start_line": 1759, "end_line": 2099}, "code_snippet": "def learning_curve(\n    estimator,\n    X,\n    y,\n    *,\n    groups=None,\n    train_sizes=np.linspace(0.1, 1.0, 5),\n    cv=None,\n    scoring=None,\n    exploit_incremental_learning=False,\n    n_jobs=None,\n    pre_dispatch=\"all\",\n    verbose=0,\n    shuffle=False,\n    random_state=None,\n    error_score=np.nan,\n    return_times=False,\n    fit_params=None,\n    params=None,\n):\n    \"\"\"Learning curve.\n\n    Determines cross-validated training and test scores for different training\n    set sizes.\n\n    A cross-validation generator splits the whole dataset k times in training\n    and test data. Subsets of the training set with varying sizes will be used\n    to train the estimator and a score for each training subset size and the\n    test set will be computed. Afterwards, the scores will be averaged over\n    all k runs for each training subset size.\n\n    Read more in the :ref:`User Guide <learning_curve>`.\n\n    Parameters\n    ----------\n    estimator : object type that implements the \"fit\" method\n        An object of that type which is cloned for each validation. It must\n        also implement \"predict\" unless `scoring` is a callable that doesn't\n        rely on \"predict\" to compute a score.\n\n    X : {array-like, sparse matrix} of shape (n_samples, n_features)\n        Training vector, where `n_samples` is the number of samples and\n        `n_features` is the number of features.\n\n    y : array-like of shape (n_samples,) or (n_samples, n_outputs) or None\n        Target relative to X for classification or regression;\n        None for unsupervised learning.\n\n    groups : array-like of shape (n_samples,), default=None\n        Group labels for the samples used while splitting the dataset into\n        train/test set. Only used in conjunction with a \"Group\" :term:`cv`\n        instance (e.g., :class:`GroupKFold`).\n\n        .. versionchanged:: 1.6\n            ``groups`` can only be passed if metadata routing is not enabled\n            via ``sklearn.set_config(enable_metadata_routing=True)``. When routing\n            is enabled, pass ``groups`` alongside other metadata via the ``params``\n            argument instead. E.g.:\n            ``learning_curve(..., params={'groups': groups})``.\n\n    train_sizes : array-like of shape (n_ticks,), \\\n            default=np.linspace(0.1, 1.0, 5)\n        Relative or absolute numbers of training examples that will be used to\n        generate the learning curve. If the dtype is float, it is regarded as a\n        fraction of the maximum size of the training set (that is determined\n        by the selected validation method), i.e. it has to be within (0, 1].\n        Otherwise it is interpreted as absolute sizes of the training sets.\n        Note that for classification the number of samples usually has to\n        be big enough to contain at least one sample from each class.\n\n    cv : int, cross-validation generator or an iterable, default=None\n        Determines the cross-validation splitting strategy.\n        Possible inputs for cv are:\n\n        - None, to use the default 5-fold cross validation,\n        - int, to specify the number of folds in a `(Stratified)KFold`,\n        - :term:`CV splitter`,\n        - An iterable yielding (train, test) splits as arrays of indices.\n\n        For int/None inputs, if the estimator is a classifier and ``y`` is\n        either binary or multiclass, :class:`StratifiedKFold` is used. In all\n        other cases, :class:`KFold` is used. These splitters are instantiated\n        with `shuffle=False` so the splits will be the same across calls.\n\n        Refer :ref:`User Guide <cross_validation>` for the various\n        cross-validation strategies that can be used here.\n\n        .. versionchanged:: 0.22\n            ``cv`` default value if None changed from 3-fold to 5-fold.\n\n    scoring : str or callable, default=None\n        Scoring method to use to evaluate the training and test sets.\n\n        - str: see :ref:`scoring_string_names` for options.\n        - callable: a scorer callable object (e.g., function) with signature\n          ``scorer(estimator, X, y)``. See :ref:`scoring_callable` for details.\n        - `None`: the `estimator`'s\n          :ref:`default evaluation criterion <scoring_api_overview>` is used.\n\n    exploit_incremental_learning : bool, default=False\n        If the estimator supports incremental learning, this will be\n        used to speed up fitting for different training set sizes.\n\n    n_jobs : int, default=None\n        Number of jobs to run in parallel. Training the estimator and computing\n        the score are parallelized over the different training and test sets.\n        ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n        ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n        for more details.\n\n    pre_dispatch : int or str, default='all'\n        Number of predispatched jobs for parallel execution (default is\n        all). The option can reduce the allocated memory. The str can\n        be an expression like '2*n_jobs'.\n\n    verbose : int, default=0\n        Controls the verbosity: the higher, the more messages.\n\n    shuffle : bool, default=False\n        Whether to shuffle training data before taking prefixes of it\n        based on``train_sizes``.\n\n    random_state : int, RandomState instance or None, default=None\n        Used when ``shuffle`` is True. Pass an int for reproducible\n        output across multiple function calls.\n        See :term:`Glossary <random_state>`.\n\n    error_score : 'raise' or numeric, default=np.nan\n        Value to assign to the score if an error occurs in estimator fitting.\n        If set to 'raise', the error is raised.\n        If a numeric value is given, FitFailedWarning is raised.\n\n        .. versionadded:: 0.20\n\n    return_times : bool, default=False\n        Whether to return the fit and score times.\n\n    fit_params : dict, default=None\n        Parameters to pass to the fit method of the estimator.\n\n        .. deprecated:: 1.6\n            This parameter is deprecated and will be removed in version 1.8. Use\n            ``params`` instead.\n\n    params : dict, default=None\n        Parameters to pass to the `fit` method of the estimator and to the scorer.\n\n        - If `enable_metadata_routing=False` (default): Parameters directly passed to\n          the `fit` method of the estimator.\n\n        - If `enable_metadata_routing=True`: Parameters safely routed to the `fit`\n          method of the estimator. See :ref:`Metadata Routing User Guide\n          <metadata_routing>` for more details.\n\n        .. versionadded:: 1.6\n\n    Returns\n    -------\n    train_sizes_abs : array of shape (n_unique_ticks,)\n        Numbers of training examples that has been used to generate the\n        learning curve. Note that the number of ticks might be less\n        than n_ticks because duplicate entries will be removed.\n\n    train_scores : array of shape (n_ticks, n_cv_folds)\n        Scores on training sets.\n\n    test_scores : array of shape (n_ticks, n_cv_folds)\n        Scores on test set.\n\n    fit_times : array of shape (n_ticks, n_cv_folds)\n        Times spent for fitting in seconds. Only present if ``return_times``\n        is True.\n\n    score_times : array of shape (n_ticks, n_cv_folds)\n        Times spent for scoring in seconds. Only present if ``return_times``\n        is True.\n\n    See Also\n    --------\n    LearningCurveDisplay.from_estimator : Plot a learning curve using an\n        estimator and data.\n\n    Examples\n    --------\n    >>> from sklearn.datasets import make_classification\n    >>> from sklearn.tree import DecisionTreeClassifier\n    >>> from sklearn.model_selection import learning_curve\n    >>> X, y = make_classification(n_samples=100, n_features=10, random_state=42)\n    >>> tree = DecisionTreeClassifier(max_depth=4, random_state=42)\n    >>> train_size_abs, train_scores, test_scores = learning_curve(\n    ...     tree, X, y, train_sizes=[0.3, 0.6, 0.9]\n    ... )\n    >>> for train_size, cv_train_scores, cv_test_scores in zip(\n    ...     train_size_abs, train_scores, test_scores\n    ... ):\n    ...     print(f\"{train_size} samples were used to train the model\")\n    ...     print(f\"The average train accuracy is {cv_train_scores.mean():.2f}\")\n    ...     print(f\"The average test accuracy is {cv_test_scores.mean():.2f}\")\n    24 samples were used to train the model\n    The average train accuracy is 1.00\n    The average test accuracy is 0.85\n    48 samples were used to train the model\n    The average train accuracy is 1.00\n    The average test accuracy is 0.90\n    72 samples were used to train the model\n    The average train accuracy is 1.00\n    The average test accuracy is 0.93\n    \"\"\"\n    if exploit_incremental_learning and not hasattr(estimator, \"partial_fit\"):\n        raise ValueError(\n            \"An estimator must support the partial_fit interface \"\n            \"to exploit incremental learning\"\n        )\n\n    params = _check_params_groups_deprecation(fit_params, params, groups, \"1.8\")\n\n    X, y, groups = indexable(X, y, groups)\n\n    cv = check_cv(cv, y, classifier=is_classifier(estimator))\n\n    scorer = check_scoring(estimator, scoring=scoring)\n\n    if _routing_enabled():\n        router = (\n            MetadataRouter(owner=\"learning_curve\")\n            .add(\n                estimator=estimator,\n                # TODO(SLEP6): also pass metadata to the predict method for\n                # scoring?\n                method_mapping=MethodMapping()\n                .add(caller=\"fit\", callee=\"fit\")\n                .add(caller=\"fit\", callee=\"partial_fit\"),\n            )\n            .add(\n                splitter=cv,\n                method_mapping=MethodMapping().add(caller=\"fit\", callee=\"split\"),\n            )\n            .add(\n                scorer=scorer,\n                method_mapping=MethodMapping().add(caller=\"fit\", callee=\"score\"),\n            )\n        )\n\n        try:\n            routed_params = process_routing(router, \"fit\", **params)\n        except UnsetMetadataPassedError as e:\n            # The default exception would mention `fit` since in the above\n            # `process_routing` code, we pass `fit` as the caller. However,\n            # the user is not calling `fit` directly, so we change the message\n            # to make it more suitable for this case.\n            raise UnsetMetadataPassedError(\n                message=str(e).replace(\"learning_curve.fit\", \"learning_curve\"),\n                unrequested_params=e.unrequested_params,\n                routed_params=e.routed_params,\n            )\n\n    else:\n        routed_params = Bunch()\n        routed_params.estimator = Bunch(fit=params, partial_fit=params)\n        routed_params.splitter = Bunch(split={\"groups\": groups})\n        routed_params.scorer = Bunch(score={})\n\n    # Store cv as list as we will be iterating over the list multiple times\n    cv_iter = list(cv.split(X, y, **routed_params.splitter.split))\n\n    n_max_training_samples = len(cv_iter[0][0])\n    # Because the lengths of folds can be significantly different, it is\n    # not guaranteed that we use all of the available training data when we\n    # use the first 'n_max_training_samples' samples.\n    train_sizes_abs = _translate_train_sizes(train_sizes, n_max_training_samples)\n    n_unique_ticks = train_sizes_abs.shape[0]\n    if verbose > 0:\n        print(\"[learning_curve] Training set sizes: \" + str(train_sizes_abs))\n\n    parallel = Parallel(n_jobs=n_jobs, pre_dispatch=pre_dispatch, verbose=verbose)\n\n    if shuffle:\n        rng = check_random_state(random_state)\n        cv_iter = ((rng.permutation(train), test) for train, test in cv_iter)\n\n    if exploit_incremental_learning:\n        classes = np.unique(y) if is_classifier(estimator) else None\n        out = parallel(\n            delayed(_incremental_fit_estimator)(\n                clone(estimator),\n                X,\n                y,\n                classes,\n                train,\n                test,\n                train_sizes_abs,\n                scorer,\n                return_times,\n                error_score=error_score,\n                fit_params=routed_params.estimator.partial_fit,\n                score_params=routed_params.scorer.score,\n            )\n            for train, test in cv_iter\n        )\n        out = np.asarray(out).transpose((2, 1, 0))\n    else:\n        train_test_proportions = []\n        for train, test in cv_iter:\n            for n_train_samples in train_sizes_abs:\n                train_test_proportions.append((train[:n_train_samples], test))\n\n        results = parallel(\n            delayed(_fit_and_score)(\n                clone(estimator),\n                X,\n                y,\n                scorer=scorer,\n                train=train,\n                test=test,\n                verbose=verbose,\n                parameters=None,\n                fit_params=routed_params.estimator.fit,\n                score_params=routed_params.scorer.score,\n                return_train_score=True,\n                error_score=error_score,\n                return_times=return_times,\n            )\n            for train, test in train_test_proportions\n        )\n        _warn_or_raise_about_fit_failures(results, error_score)\n        results = _aggregate_score_dicts(results)\n        train_scores = results[\"train_scores\"].reshape(-1, n_unique_ticks).T\n        test_scores = results[\"test_scores\"].reshape(-1, n_unique_ticks).T\n        out = [train_scores, test_scores]\n\n        if return_times:\n            fit_times = results[\"fit_time\"].reshape(-1, n_unique_ticks).T\n            score_times = results[\"score_time\"].reshape(-1, n_unique_ticks).T\n            out.extend([fit_times, score_times])\n\n    ret = train_sizes_abs, out[0], out[1]\n\n    if return_times:\n        ret = ret + (out[2], out[3])\n\n    return ret\n", "type": "function"}, {"name": "_check_multimetric_scoring", "is_method": false, "class_name": null, "parameters": ["estimator", "scoring"], "calls": ["isinstance", "isinstance", "set", "len", "len", "ValueError", "set", "ValueError", "ValueError", "len", "ValueError", "all", "ValueError", "len", "ValueError", "check_scoring", "all", "any", "check_scoring", "scoring.items", "ValueError", "ValueError", "isinstance", "isinstance", "callable"], "code_location": {"file": "_scorer.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/metrics", "start_line": 548, "end_line": 634}, "code_snippet": "def _check_multimetric_scoring(estimator, scoring):\n    \"\"\"Check the scoring parameter in cases when multiple metrics are allowed.\n\n    In addition, multimetric scoring leverages a caching mechanism to not call the same\n    estimator response method multiple times. Hence, the scorer is modified to only use\n    a single response method given a list of response methods and the estimator.\n\n    Parameters\n    ----------\n    estimator : sklearn estimator instance\n        The estimator for which the scoring will be applied.\n\n    scoring : list, tuple or dict\n        Strategy to evaluate the performance of the cross-validated model on\n        the test set.\n\n        The possibilities are:\n\n        - a list or tuple of unique strings;\n        - a callable returning a dictionary where they keys are the metric\n          names and the values are the metric scores;\n        - a dictionary with metric names as keys and callables a values.\n\n        See :ref:`multimetric_grid_search` for an example.\n\n    Returns\n    -------\n    scorers_dict : dict\n        A dict mapping each scorer name to its validated scorer.\n    \"\"\"\n    err_msg_generic = (\n        f\"scoring is invalid (got {scoring!r}). Refer to the \"\n        \"scoring glossary for details: \"\n        \"https://scikit-learn.org/stable/glossary.html#term-scoring\"\n    )\n\n    if isinstance(scoring, (list, tuple, set)):\n        err_msg = (\n            \"The list/tuple elements must be unique strings of predefined scorers. \"\n        )\n        try:\n            keys = set(scoring)\n        except TypeError as e:\n            raise ValueError(err_msg) from e\n\n        if len(keys) != len(scoring):\n            raise ValueError(\n                f\"{err_msg} Duplicate elements were found in\"\n                f\" the given list. {scoring!r}\"\n            )\n        elif len(keys) > 0:\n            if not all(isinstance(k, str) for k in keys):\n                if any(callable(k) for k in keys):\n                    raise ValueError(\n                        f\"{err_msg} One or more of the elements \"\n                        \"were callables. Use a dict of score \"\n                        \"name mapped to the scorer callable. \"\n                        f\"Got {scoring!r}\"\n                    )\n                else:\n                    raise ValueError(\n                        f\"{err_msg} Non-string types were found \"\n                        f\"in the given list. Got {scoring!r}\"\n                    )\n            scorers = {\n                scorer: check_scoring(estimator, scoring=scorer) for scorer in scoring\n            }\n        else:\n            raise ValueError(f\"{err_msg} Empty list was given. {scoring!r}\")\n\n    elif isinstance(scoring, dict):\n        keys = set(scoring)\n        if not all(isinstance(k, str) for k in keys):\n            raise ValueError(\n                \"Non-string types were found in the keys of \"\n                f\"the given dict. scoring={scoring!r}\"\n            )\n        if len(keys) == 0:\n            raise ValueError(f\"An empty dict was passed. {scoring!r}\")\n        scorers = {\n            key: check_scoring(estimator, scoring=scorer)\n            for key, scorer in scoring.items()\n        }\n    else:\n        raise ValueError(err_msg_generic)\n\n    return scorers\n", "type": "function"}], "retrieved_count": 10, "cost_time": 1.1272532939910889}
{"question": "How does SpectralEmbedding's _get_affinity_matrix method implement a fallback strategy when sparse input is detected for nearest_neighbors affinity, and what are the implications of this runtime exception handling for the algorithm's behavior?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"name": "test_spectral_embedding_amg_solver", "is_method": false, "class_name": null, "parameters": ["dtype", "coo_container", "seed"], "calls": ["pytest.mark.skipif", "pytest.mark.parametrize", "pytest.mark.parametrize", "SpectralEmbedding", "SpectralEmbedding", "se_amg.fit_transform", "se_arpack.fit_transform", "_assert_equal_with_sign_flipping", "np.array", "np.array", "np.array", "coo_container", "se_amg.fit_transform", "se_arpack.fit_transform", "_assert_equal_with_sign_flipping", "affinity.tocsr", "affinity.indptr.astype", "affinity.indices.astype", "S.astype", "S.astype", "affinity.astype", "affinity.astype", "parse_version", "se_amg.fit_transform", "np.random.RandomState", "np.random.RandomState", "np.hstack", "pytest.raises", "se_amg.fit_transform", "np.hstack", "np.hstack"], "code_location": {"file": "test_spectral_embedding.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/manifold/tests", "start_line": 253, "end_line": 304}, "code_snippet": "def test_spectral_embedding_amg_solver(dtype, coo_container, seed=36):\n    se_amg = SpectralEmbedding(\n        n_components=2,\n        affinity=\"nearest_neighbors\",\n        eigen_solver=\"amg\",\n        n_neighbors=5,\n        random_state=np.random.RandomState(seed),\n    )\n    se_arpack = SpectralEmbedding(\n        n_components=2,\n        affinity=\"nearest_neighbors\",\n        eigen_solver=\"arpack\",\n        n_neighbors=5,\n        random_state=np.random.RandomState(seed),\n    )\n    embed_amg = se_amg.fit_transform(S.astype(dtype))\n    embed_arpack = se_arpack.fit_transform(S.astype(dtype))\n    _assert_equal_with_sign_flipping(embed_amg, embed_arpack, 1e-5)\n\n    # same with special case in which amg is not actually used\n    # regression test for #10715\n    # affinity between nodes\n    row = np.array([0, 0, 1, 2, 3, 3, 4], dtype=np.int32)\n    col = np.array([1, 2, 2, 3, 4, 5, 5], dtype=np.int32)\n    val = np.array([100, 100, 100, 1, 100, 100, 100], dtype=np.int64)\n\n    affinity = coo_container(\n        (np.hstack([val, val]), (np.hstack([row, col]), np.hstack([col, row]))),\n        shape=(6, 6),\n    )\n    se_amg.affinity = \"precomputed\"\n    se_arpack.affinity = \"precomputed\"\n    embed_amg = se_amg.fit_transform(affinity.astype(dtype))\n    embed_arpack = se_arpack.fit_transform(affinity.astype(dtype))\n    _assert_equal_with_sign_flipping(embed_amg, embed_arpack, 1e-5)\n\n    # Check that passing a sparse matrix with `np.int64` indices dtype raises an error\n    # or is successful based on the version of SciPy which is installed.\n    # Use a CSR matrix to avoid any conversion during the validation\n    affinity = affinity.tocsr()\n    affinity.indptr = affinity.indptr.astype(np.int64)\n    affinity.indices = affinity.indices.astype(np.int64)\n\n    # PR: https://github.com/scipy/scipy/pull/18913\n    # First integration in 1.11.3: https://github.com/scipy/scipy/pull/19279\n    scipy_graph_traversal_supports_int64_index = sp_version >= parse_version(\"1.11.3\")\n    if scipy_graph_traversal_supports_int64_index:\n        se_amg.fit_transform(affinity)\n    else:\n        err_msg = \"Only sparse matrices with 32-bit integer indices are accepted\"\n        with pytest.raises(ValueError, match=err_msg):\n            se_amg.fit_transform(affinity)\n", "type": "function"}, {"name": "_spectral_embedding", "is_method": false, "class_name": null, "parameters": ["adjacency"], "calls": ["check_symmetric", "csgraph_laplacian", "_deterministic_vector_sign_flip", "_graph_is_connected", "warnings.warn", "_set_diag", "check_array", "_init_arpack_v0", "check_array", "eigsh", "check_array", "_set_diag", "smoothed_aggregation_solver", "ml.aspreconditioner", "random_state.standard_normal", "dd.ravel", "X.astype", "lobpcg", "sparse.issparse", "eigh", "_set_diag", "random_state.standard_normal", "dd.ravel", "X.astype", "lobpcg", "ValueError", "sparse.issparse", "warnings.warn", "sparse.eye", "hasattr", "isinstance", "sparse.csr_matrix", "check_array", "laplacian.toarray", "sparse.issparse"], "code_location": {"file": "_spectral_embedding.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/manifold", "start_line": 295, "end_line": 463}, "code_snippet": "def _spectral_embedding(\n    adjacency,\n    *,\n    n_components=8,\n    eigen_solver=None,\n    random_state=None,\n    eigen_tol=\"auto\",\n    norm_laplacian=True,\n    drop_first=True,\n):\n    adjacency = check_symmetric(adjacency)\n\n    if eigen_solver == \"amg\":\n        try:\n            from pyamg import smoothed_aggregation_solver\n        except ImportError as e:\n            raise ValueError(\n                \"The eigen_solver was set to 'amg', but pyamg is not available.\"\n            ) from e\n\n    if eigen_solver is None:\n        eigen_solver = \"arpack\"\n\n    n_nodes = adjacency.shape[0]\n    # Whether to drop the first eigenvector\n    if drop_first:\n        n_components = n_components + 1\n\n    if not _graph_is_connected(adjacency):\n        warnings.warn(\n            \"Graph is not fully connected, spectral embedding may not work as expected.\"\n        )\n\n    laplacian, dd = csgraph_laplacian(\n        adjacency, normed=norm_laplacian, return_diag=True\n    )\n    if eigen_solver == \"arpack\" or (\n        eigen_solver != \"lobpcg\"\n        and (not sparse.issparse(laplacian) or n_nodes < 5 * n_components)\n    ):\n        # lobpcg used with eigen_solver='amg' has bugs for low number of nodes\n        # for details see the source code in scipy:\n        # https://github.com/scipy/scipy/blob/v0.11.0/scipy/sparse/linalg/eigen\n        # /lobpcg/lobpcg.py#L237\n        # or matlab:\n        # https://www.mathworks.com/matlabcentral/fileexchange/48-lobpcg-m\n        laplacian = _set_diag(laplacian, 1, norm_laplacian)\n\n        # Here we'll use shift-invert mode for fast eigenvalues\n        # (see https://docs.scipy.org/doc/scipy/reference/tutorial/arpack.html\n        #  for a short explanation of what this means)\n        # Because the normalized Laplacian has eigenvalues between 0 and 2,\n        # I - L has eigenvalues between -1 and 1.  ARPACK is most efficient\n        # when finding eigenvalues of largest magnitude (keyword which='LM')\n        # and when these eigenvalues are very large compared to the rest.\n        # For very large, very sparse graphs, I - L can have many, many\n        # eigenvalues very near 1.0.  This leads to slow convergence.  So\n        # instead, we'll use ARPACK's shift-invert mode, asking for the\n        # eigenvalues near 1.0.  This effectively spreads-out the spectrum\n        # near 1.0 and leads to much faster convergence: potentially an\n        # orders-of-magnitude speedup over simply using keyword which='LA'\n        # in standard mode.\n        try:\n            # We are computing the opposite of the laplacian inplace so as\n            # to spare a memory allocation of a possibly very large array\n            tol = 0 if eigen_tol == \"auto\" else eigen_tol\n            laplacian *= -1\n            v0 = _init_arpack_v0(laplacian.shape[0], random_state)\n            laplacian = check_array(\n                laplacian, accept_sparse=\"csr\", accept_large_sparse=False\n            )\n            _, diffusion_map = eigsh(\n                laplacian, k=n_components, sigma=1.0, which=\"LM\", tol=tol, v0=v0\n            )\n            embedding = diffusion_map.T[n_components::-1]\n            if norm_laplacian:\n                # recover u = D^-1/2 x from the eigenvector output x\n                embedding = embedding / dd\n        except RuntimeError:\n            # When submatrices are exactly singular, an LU decomposition\n            # in arpack fails. We fallback to lobpcg\n            eigen_solver = \"lobpcg\"\n            # Revert the laplacian to its opposite to have lobpcg work\n            laplacian *= -1\n\n    elif eigen_solver == \"amg\":\n        # Use AMG to get a preconditioner and speed up the eigenvalue\n        # problem.\n        if not sparse.issparse(laplacian):\n            warnings.warn(\"AMG works better for sparse matrices\")\n        laplacian = check_array(\n            laplacian, dtype=[np.float64, np.float32], accept_sparse=True\n        )\n        laplacian = _set_diag(laplacian, 1, norm_laplacian)\n\n        # The Laplacian matrix is always singular, having at least one zero\n        # eigenvalue, corresponding to the trivial eigenvector, which is a\n        # constant. Using a singular matrix for preconditioning may result in\n        # random failures in LOBPCG and is not supported by the existing\n        # theory:\n        #     see https://doi.org/10.1007/s10208-015-9297-1\n        # Shift the Laplacian so its diagononal is not all ones. The shift\n        # does change the eigenpairs however, so we'll feed the shifted\n        # matrix to the solver and afterward set it back to the original.\n        diag_shift = 1e-5 * sparse.eye(laplacian.shape[0])\n        laplacian += diag_shift\n        if hasattr(sparse, \"csr_array\") and isinstance(laplacian, sparse.csr_array):\n            # `pyamg` does not work with `csr_array` and we need to convert it to a\n            # `csr_matrix` object.\n            laplacian = sparse.csr_matrix(laplacian)\n        ml = smoothed_aggregation_solver(check_array(laplacian, accept_sparse=\"csr\"))\n        laplacian -= diag_shift\n\n        M = ml.aspreconditioner()\n        # Create initial approximation X to eigenvectors\n        X = random_state.standard_normal(size=(laplacian.shape[0], n_components + 1))\n        X[:, 0] = dd.ravel()\n        X = X.astype(laplacian.dtype)\n\n        tol = None if eigen_tol == \"auto\" else eigen_tol\n        _, diffusion_map = lobpcg(laplacian, X, M=M, tol=tol, largest=False)\n        embedding = diffusion_map.T\n        if norm_laplacian:\n            # recover u = D^-1/2 x from the eigenvector output x\n            embedding = embedding / dd\n        if embedding.shape[0] == 1:\n            raise ValueError\n\n    if eigen_solver == \"lobpcg\":\n        laplacian = check_array(\n            laplacian, dtype=[np.float64, np.float32], accept_sparse=True\n        )\n        if n_nodes < 5 * n_components + 1:\n            # see note above under arpack why lobpcg has problems with small\n            # number of nodes\n            # lobpcg will fallback to eigh, so we short circuit it\n            if sparse.issparse(laplacian):\n                laplacian = laplacian.toarray()\n            _, diffusion_map = eigh(laplacian, check_finite=False)\n            embedding = diffusion_map.T[:n_components]\n            if norm_laplacian:\n                # recover u = D^-1/2 x from the eigenvector output x\n                embedding = embedding / dd\n        else:\n            laplacian = _set_diag(laplacian, 1, norm_laplacian)\n            # We increase the number of eigenvectors requested, as lobpcg\n            # doesn't behave well in low dimension and create initial\n            # approximation X to eigenvectors\n            X = random_state.standard_normal(\n                size=(laplacian.shape[0], n_components + 1)\n            )\n            X[:, 0] = dd.ravel()\n            X = X.astype(laplacian.dtype)\n            tol = None if eigen_tol == \"auto\" else eigen_tol\n            _, diffusion_map = lobpcg(\n                laplacian, X, tol=tol, largest=False, maxiter=2000\n            )\n            embedding = diffusion_map.T[:n_components]\n            if norm_laplacian:\n                # recover u = D^-1/2 x from the eigenvector output x\n                embedding = embedding / dd\n            if embedding.shape[0] == 1:\n                raise ValueError\n\n    embedding = _deterministic_vector_sign_flip(embedding)\n    if drop_first:\n        return embedding[1:n_components].T\n    else:\n        return embedding[:n_components].T\n", "type": "function"}, {"name": "test_spectral_embedding_callable_affinity", "is_method": false, "class_name": null, "parameters": ["sparse_container", "seed"], "calls": ["pytest.mark.parametrize", "rbf_kernel", "SpectralEmbedding", "SpectralEmbedding", "se_rbf.fit_transform", "se_callable.fit_transform", "assert_array_almost_equal", "assert_array_almost_equal", "_assert_equal_with_sign_flipping", "sparse_container", "np.random.RandomState", "np.random.RandomState", "rbf_kernel"], "code_location": {"file": "test_spectral_embedding.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/manifold/tests", "start_line": 223, "end_line": 245}, "code_snippet": "def test_spectral_embedding_callable_affinity(sparse_container, seed=36):\n    # Test spectral embedding with callable affinity\n    gamma = 0.9\n    kern = rbf_kernel(S, gamma=gamma)\n    X = S if sparse_container is None else sparse_container(S)\n\n    se_callable = SpectralEmbedding(\n        n_components=2,\n        affinity=(lambda x: rbf_kernel(x, gamma=gamma)),\n        gamma=gamma,\n        random_state=np.random.RandomState(seed),\n    )\n    se_rbf = SpectralEmbedding(\n        n_components=2,\n        affinity=\"rbf\",\n        gamma=gamma,\n        random_state=np.random.RandomState(seed),\n    )\n    embed_rbf = se_rbf.fit_transform(X)\n    embed_callable = se_callable.fit_transform(X)\n    assert_array_almost_equal(se_callable.affinity_matrix_, se_rbf.affinity_matrix_)\n    assert_array_almost_equal(kern, se_rbf.affinity_matrix_)\n    _assert_equal_with_sign_flipping(embed_rbf, embed_callable, 0.05)\n", "type": "function"}, {"name": "test_spectral_embedding_precomputed_affinity", "is_method": false, "class_name": null, "parameters": ["sparse_container", "eigen_solver", "dtype", "seed"], "calls": ["pytest.mark.parametrize", "pytest.mark.parametrize", "pytest.mark.parametrize", "SpectralEmbedding", "SpectralEmbedding", "se_precomp.fit_transform", "se_rbf.fit_transform", "assert_array_almost_equal", "_assert_equal_with_sign_flipping", "sparse_container", "rbf_kernel", "X.astype", "pytest.param", "np.random.RandomState", "np.random.RandomState", "X.astype"], "code_location": {"file": "test_spectral_embedding.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/manifold/tests", "start_line": 174, "end_line": 197}, "code_snippet": "def test_spectral_embedding_precomputed_affinity(\n    sparse_container, eigen_solver, dtype, seed=36\n):\n    # Test spectral embedding with precomputed kernel\n    gamma = 1.0\n    X = S if sparse_container is None else sparse_container(S)\n\n    se_precomp = SpectralEmbedding(\n        n_components=2,\n        affinity=\"precomputed\",\n        random_state=np.random.RandomState(seed),\n        eigen_solver=eigen_solver,\n    )\n    se_rbf = SpectralEmbedding(\n        n_components=2,\n        affinity=\"rbf\",\n        gamma=gamma,\n        random_state=np.random.RandomState(seed),\n        eigen_solver=eigen_solver,\n    )\n    embed_precomp = se_precomp.fit_transform(rbf_kernel(X.astype(dtype), gamma=gamma))\n    embed_rbf = se_rbf.fit_transform(X.astype(dtype))\n    assert_array_almost_equal(se_precomp.affinity_matrix_, se_rbf.affinity_matrix_)\n    _assert_equal_with_sign_flipping(embed_precomp, embed_rbf, 0.05)\n", "type": "function"}, {"name": "test_spectral_embedding_amg_solver_failure", "is_method": false, "class_name": null, "parameters": ["dtype", "seed"], "calls": ["pytest.mark.skipif", "pytest.mark.parametrize", "sparse.rand", "X.astype", "spectral_embedding", "range", "sparse.triu", "sparse.diags", "spectral_embedding", "_assert_equal_with_sign_flipping", "X.diagonal"], "code_location": {"file": "test_spectral_embedding.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/manifold/tests", "start_line": 311, "end_line": 327}, "code_snippet": "def test_spectral_embedding_amg_solver_failure(dtype, seed=36):\n    # Non-regression test for amg solver failure (issue #13393 on github)\n    num_nodes = 100\n    X = sparse.rand(num_nodes, num_nodes, density=0.1, random_state=seed)\n    X = X.astype(dtype)\n    upper = sparse.triu(X) - sparse.diags(X.diagonal())\n    sym_matrix = upper + upper.T\n    embedding = spectral_embedding(\n        sym_matrix, n_components=10, eigen_solver=\"amg\", random_state=0\n    )\n\n    # Check that the learned embedding is stable w.r.t. random solver init:\n    for i in range(3):\n        new_embedding = spectral_embedding(\n            sym_matrix, n_components=10, eigen_solver=\"amg\", random_state=i + 1\n        )\n        _assert_equal_with_sign_flipping(embedding, new_embedding, tol=0.05)\n", "type": "function"}, {"name": "_locally_linear_embedding", "is_method": false, "class_name": null, "parameters": ["X"], "calls": ["NearestNeighbors", "nbrs.fit", "null_space", "ValueError", "ValueError", "barycenter_kneighbors_graph", "M.tocsr", "toarray", "nbrs.kneighbors", "np.empty", "M_container_constructor", "range", "eye", "ValueError", "Gi.mean", "range", "qr", "w.sum", "np.meshgrid", "np.dot", "nbrs.kneighbors", "np.zeros", "min", "np.zeros", "np.dot", "np.zeros", "range", "np.median", "np.zeros", "stable_cumsum", "range", "M_container_constructor", "range", "np.dot", "np.where", "ValueError", "range", "range", "evals.sum", "V.transpose", "np.ones", "np.dot", "w_reg.sum", "sum", "sum", "np.searchsorted", "np.linalg.norm", "np.meshgrid", "np.dot", "Wi.sum", "nbrs.kneighbors", "M_container_constructor", "range", "svd", "svd", "np.dot", "eigh", "np.linalg.norm", "np.sqrt", "np.full", "np.dot", "Xi.mean", "np.zeros", "np.dot", "np.meshgrid", "np.ones", "eigh", "abs", "Vi.sum", "np.ones", "np.dot", "np.sqrt", "np.outer", "svd", "np.dot", "eigh"], "code_location": {"file": "_locally_linear.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/manifold", "start_line": 200, "end_line": 445}, "code_snippet": "def _locally_linear_embedding(\n    X,\n    *,\n    n_neighbors,\n    n_components,\n    reg=1e-3,\n    eigen_solver=\"auto\",\n    tol=1e-6,\n    max_iter=100,\n    method=\"standard\",\n    hessian_tol=1e-4,\n    modified_tol=1e-12,\n    random_state=None,\n    n_jobs=None,\n):\n    nbrs = NearestNeighbors(n_neighbors=n_neighbors + 1, n_jobs=n_jobs)\n    nbrs.fit(X)\n    X = nbrs._fit_X\n\n    N, d_in = X.shape\n\n    if n_components > d_in:\n        raise ValueError(\n            \"output dimension must be less than or equal to input dimension\"\n        )\n    if n_neighbors >= N:\n        raise ValueError(\n            \"Expected n_neighbors < n_samples, but n_samples = %d, n_neighbors = %d\"\n            % (N, n_neighbors)\n        )\n\n    M_sparse = eigen_solver != \"dense\"\n    M_container_constructor = lil_matrix if M_sparse else np.zeros\n\n    if method == \"standard\":\n        W = barycenter_kneighbors_graph(\n            nbrs, n_neighbors=n_neighbors, reg=reg, n_jobs=n_jobs\n        )\n\n        # we'll compute M = (I-W)'(I-W)\n        # depending on the solver, we'll do this differently\n        if M_sparse:\n            M = eye(*W.shape, format=W.format) - W\n            M = M.T @ M\n        else:\n            M = (W.T @ W - W.T - W).toarray()\n            M.flat[:: M.shape[0] + 1] += 1  # M = W' W - W' - W + I\n\n    elif method == \"hessian\":\n        dp = n_components * (n_components + 1) // 2\n\n        if n_neighbors <= n_components + dp:\n            raise ValueError(\n                \"for method='hessian', n_neighbors must be \"\n                \"greater than \"\n                \"[n_components * (n_components + 3) / 2]\"\n            )\n\n        neighbors = nbrs.kneighbors(\n            X, n_neighbors=n_neighbors + 1, return_distance=False\n        )\n        neighbors = neighbors[:, 1:]\n\n        Yi = np.empty((n_neighbors, 1 + n_components + dp), dtype=np.float64)\n        Yi[:, 0] = 1\n\n        M = M_container_constructor((N, N), dtype=np.float64)\n\n        use_svd = n_neighbors > d_in\n\n        for i in range(N):\n            Gi = X[neighbors[i]]\n            Gi -= Gi.mean(0)\n\n            # build Hessian estimator\n            if use_svd:\n                U = svd(Gi, full_matrices=0)[0]\n            else:\n                Ci = np.dot(Gi, Gi.T)\n                U = eigh(Ci)[1][:, ::-1]\n\n            Yi[:, 1 : 1 + n_components] = U[:, :n_components]\n\n            j = 1 + n_components\n            for k in range(n_components):\n                Yi[:, j : j + n_components - k] = U[:, k : k + 1] * U[:, k:n_components]\n                j += n_components - k\n\n            Q, R = qr(Yi)\n\n            w = Q[:, n_components + 1 :]\n            S = w.sum(0)\n\n            S[np.where(abs(S) < hessian_tol)] = 1\n            w /= S\n\n            nbrs_x, nbrs_y = np.meshgrid(neighbors[i], neighbors[i])\n            M[nbrs_x, nbrs_y] += np.dot(w, w.T)\n\n    elif method == \"modified\":\n        if n_neighbors < n_components:\n            raise ValueError(\"modified LLE requires n_neighbors >= n_components\")\n\n        neighbors = nbrs.kneighbors(\n            X, n_neighbors=n_neighbors + 1, return_distance=False\n        )\n        neighbors = neighbors[:, 1:]\n\n        # find the eigenvectors and eigenvalues of each local covariance\n        # matrix. We want V[i] to be a [n_neighbors x n_neighbors] matrix,\n        # where the columns are eigenvectors\n        V = np.zeros((N, n_neighbors, n_neighbors))\n        nev = min(d_in, n_neighbors)\n        evals = np.zeros([N, nev])\n\n        # choose the most efficient way to find the eigenvectors\n        use_svd = n_neighbors > d_in\n\n        if use_svd:\n            for i in range(N):\n                X_nbrs = X[neighbors[i]] - X[i]\n                V[i], evals[i], _ = svd(X_nbrs, full_matrices=True)\n            evals **= 2\n        else:\n            for i in range(N):\n                X_nbrs = X[neighbors[i]] - X[i]\n                C_nbrs = np.dot(X_nbrs, X_nbrs.T)\n                evi, vi = eigh(C_nbrs)\n                evals[i] = evi[::-1]\n                V[i] = vi[:, ::-1]\n\n        # find regularized weights: this is like normal LLE.\n        # because we've already computed the SVD of each covariance matrix,\n        # it's faster to use this rather than np.linalg.solve\n        reg = 1e-3 * evals.sum(1)\n\n        tmp = np.dot(V.transpose(0, 2, 1), np.ones(n_neighbors))\n        tmp[:, :nev] /= evals + reg[:, None]\n        tmp[:, nev:] /= reg[:, None]\n\n        w_reg = np.zeros((N, n_neighbors))\n        for i in range(N):\n            w_reg[i] = np.dot(V[i], tmp[i])\n        w_reg /= w_reg.sum(1)[:, None]\n\n        # calculate eta: the median of the ratio of small to large eigenvalues\n        # across the points.  This is used to determine s_i, below\n        rho = evals[:, n_components:].sum(1) / evals[:, :n_components].sum(1)\n        eta = np.median(rho)\n\n        # find s_i, the size of the \"almost null space\" for each point:\n        # this is the size of the largest set of eigenvalues\n        # such that Sum[v; v in set]/Sum[v; v not in set] < eta\n        s_range = np.zeros(N, dtype=int)\n        evals_cumsum = stable_cumsum(evals, 1)\n        eta_range = evals_cumsum[:, -1:] / evals_cumsum[:, :-1] - 1\n        for i in range(N):\n            s_range[i] = np.searchsorted(eta_range[i, ::-1], eta)\n        s_range += n_neighbors - nev  # number of zero eigenvalues\n\n        # Now calculate M.\n        # This is the [N x N] matrix whose null space is the desired embedding\n        M = M_container_constructor((N, N), dtype=np.float64)\n\n        for i in range(N):\n            s_i = s_range[i]\n\n            # select bottom s_i eigenvectors and calculate alpha\n            Vi = V[i, :, n_neighbors - s_i :]\n            alpha_i = np.linalg.norm(Vi.sum(0)) / np.sqrt(s_i)\n\n            # compute Householder matrix which satisfies\n            #  Hi*Vi.T*ones(n_neighbors) = alpha_i*ones(s)\n            # using prescription from paper\n            h = np.full(s_i, alpha_i) - np.dot(Vi.T, np.ones(n_neighbors))\n\n            norm_h = np.linalg.norm(h)\n            if norm_h < modified_tol:\n                h *= 0\n            else:\n                h /= norm_h\n\n            # Householder matrix is\n            #  >> Hi = np.identity(s_i) - 2*np.outer(h,h)\n            # Then the weight matrix is\n            #  >> Wi = np.dot(Vi,Hi) + (1-alpha_i) * w_reg[i,:,None]\n            # We do this much more efficiently:\n            Wi = Vi - 2 * np.outer(np.dot(Vi, h), h) + (1 - alpha_i) * w_reg[i, :, None]\n\n            # Update M as follows:\n            # >> W_hat = np.zeros( (N,s_i) )\n            # >> W_hat[neighbors[i],:] = Wi\n            # >> W_hat[i] -= 1\n            # >> M += np.dot(W_hat,W_hat.T)\n            # We can do this much more efficiently:\n            nbrs_x, nbrs_y = np.meshgrid(neighbors[i], neighbors[i])\n            M[nbrs_x, nbrs_y] += np.dot(Wi, Wi.T)\n            Wi_sum1 = Wi.sum(1)\n            M[i, neighbors[i]] -= Wi_sum1\n            M[neighbors[i], [i]] -= Wi_sum1\n            M[i, i] += s_i\n\n    elif method == \"ltsa\":\n        neighbors = nbrs.kneighbors(\n            X, n_neighbors=n_neighbors + 1, return_distance=False\n        )\n        neighbors = neighbors[:, 1:]\n\n        M = M_container_constructor((N, N), dtype=np.float64)\n\n        use_svd = n_neighbors > d_in\n\n        for i in range(N):\n            Xi = X[neighbors[i]]\n            Xi -= Xi.mean(0)\n\n            # compute n_components largest eigenvalues of Xi @ Xi^T\n            if use_svd:\n                v = svd(Xi, full_matrices=True)[0]\n            else:\n                Ci = np.dot(Xi, Xi.T)\n                v = eigh(Ci)[1][:, ::-1]\n\n            Gi = np.zeros((n_neighbors, n_components + 1))\n            Gi[:, 1:] = v[:, :n_components]\n            Gi[:, 0] = 1.0 / np.sqrt(n_neighbors)\n\n            GiGiT = np.dot(Gi, Gi.T)\n\n            nbrs_x, nbrs_y = np.meshgrid(neighbors[i], neighbors[i])\n            M[nbrs_x, nbrs_y] -= GiGiT\n\n            M[neighbors[i], neighbors[i]] += np.ones(shape=n_neighbors)\n\n    if M_sparse:\n        M = M.tocsr()\n\n    return null_space(\n        M,\n        n_components,\n        k_skip=1,\n        eigen_solver=eigen_solver,\n        tol=tol,\n        max_iter=max_iter,\n        random_state=random_state,\n    )\n", "type": "function"}, {"name": "spectral_embedding", "is_method": false, "class_name": null, "parameters": ["adjacency"], "calls": ["validate_params", "check_random_state", "_spectral_embedding", "Interval", "StrOptions", "Interval", "StrOptions"], "code_location": {"file": "_spectral_embedding.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/manifold", "start_line": 162, "end_line": 292}, "code_snippet": "def spectral_embedding(\n    adjacency,\n    *,\n    n_components=8,\n    eigen_solver=None,\n    random_state=None,\n    eigen_tol=\"auto\",\n    norm_laplacian=True,\n    drop_first=True,\n):\n    \"\"\"Project the sample on the first eigenvectors of the graph Laplacian.\n\n    The adjacency matrix is used to compute a normalized graph Laplacian\n    whose spectrum (especially the eigenvectors associated to the\n    smallest eigenvalues) has an interpretation in terms of minimal\n    number of cuts necessary to split the graph into comparably sized\n    components.\n\n    This embedding can also 'work' even if the ``adjacency`` variable is\n    not strictly the adjacency matrix of a graph but more generally\n    an affinity or similarity matrix between samples (for instance the\n    heat kernel of a euclidean distance matrix or a k-NN matrix).\n\n    However care must taken to always make the affinity matrix symmetric\n    so that the eigenvector decomposition works as expected.\n\n    Note : Laplacian Eigenmaps is the actual algorithm implemented here.\n\n    Read more in the :ref:`User Guide <spectral_embedding>`.\n\n    Parameters\n    ----------\n    adjacency : {array-like, sparse graph} of shape (n_samples, n_samples)\n        The adjacency matrix of the graph to embed.\n\n    n_components : int, default=8\n        The dimension of the projection subspace.\n\n    eigen_solver : {'arpack', 'lobpcg', 'amg'}, default=None\n        The eigenvalue decomposition strategy to use. AMG requires pyamg\n        to be installed. It can be faster on very large, sparse problems,\n        but may also lead to instabilities. If None, then ``'arpack'`` is\n        used.\n\n    random_state : int, RandomState instance or None, default=None\n        A pseudo random number generator used for the initialization\n        of the lobpcg eigen vectors decomposition when `eigen_solver ==\n        'amg'`, and for the K-Means initialization. Use an int to make\n        the results deterministic across calls (See\n        :term:`Glossary <random_state>`).\n\n        .. note::\n            When using `eigen_solver == 'amg'`,\n            it is necessary to also fix the global numpy seed with\n            `np.random.seed(int)` to get deterministic results. See\n            https://github.com/pyamg/pyamg/issues/139 for further\n            information.\n\n    eigen_tol : float, default=\"auto\"\n        Stopping criterion for eigendecomposition of the Laplacian matrix.\n        If `eigen_tol=\"auto\"` then the passed tolerance will depend on the\n        `eigen_solver`:\n\n        - If `eigen_solver=\"arpack\"`, then `eigen_tol=0.0`;\n        - If `eigen_solver=\"lobpcg\"` or `eigen_solver=\"amg\"`, then\n          `eigen_tol=None` which configures the underlying `lobpcg` solver to\n          automatically resolve the value according to their heuristics. See,\n          :func:`scipy.sparse.linalg.lobpcg` for details.\n\n        Note that when using `eigen_solver=\"amg\"` values of `tol<1e-5` may lead\n        to convergence issues and should be avoided.\n\n        .. versionadded:: 1.2\n           Added 'auto' option.\n\n    norm_laplacian : bool, default=True\n        If True, then compute symmetric normalized Laplacian.\n\n    drop_first : bool, default=True\n        Whether to drop the first eigenvector. For spectral embedding, this\n        should be True as the first eigenvector should be constant vector for\n        connected graph, but for spectral clustering, this should be kept as\n        False to retain the first eigenvector.\n\n    Returns\n    -------\n    embedding : ndarray of shape (n_samples, n_components)\n        The reduced samples.\n\n    Notes\n    -----\n    Spectral Embedding (Laplacian Eigenmaps) is most useful when the graph\n    has one connected component. If there graph has many components, the first\n    few eigenvectors will simply uncover the connected components of the graph.\n\n    References\n    ----------\n    * https://en.wikipedia.org/wiki/LOBPCG\n\n    * :doi:`\"Toward the Optimal Preconditioned Eigensolver: Locally Optimal\n      Block Preconditioned Conjugate Gradient Method\",\n      Andrew V. Knyazev\n      <10.1137/S1064827500366124>`\n\n    Examples\n    --------\n    >>> from sklearn.datasets import load_digits\n    >>> from sklearn.neighbors import kneighbors_graph\n    >>> from sklearn.manifold import spectral_embedding\n    >>> X, _ = load_digits(return_X_y=True)\n    >>> X = X[:100]\n    >>> affinity_matrix = kneighbors_graph(\n    ...     X, n_neighbors=int(X.shape[0] / 10), include_self=True\n    ... )\n    >>> # make the matrix symmetric\n    >>> affinity_matrix = 0.5 * (affinity_matrix + affinity_matrix.T)\n    >>> embedding = spectral_embedding(affinity_matrix, n_components=2, random_state=42)\n    >>> embedding.shape\n    (100, 2)\n    \"\"\"\n    random_state = check_random_state(random_state)\n\n    return _spectral_embedding(\n        adjacency,\n        n_components=n_components,\n        eigen_solver=eigen_solver,\n        random_state=random_state,\n        eigen_tol=eigen_tol,\n        norm_laplacian=norm_laplacian,\n        drop_first=drop_first,\n    )\n", "type": "function"}, {"name": "spectral_clustering", "is_method": false, "class_name": null, "parameters": ["affinity"], "calls": ["validate_params", "fit", "SpectralClustering"], "code_location": {"file": "_spectral.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/cluster", "start_line": 194, "end_line": 376}, "code_snippet": "def spectral_clustering(\n    affinity,\n    *,\n    n_clusters=8,\n    n_components=None,\n    eigen_solver=None,\n    random_state=None,\n    n_init=10,\n    eigen_tol=\"auto\",\n    assign_labels=\"kmeans\",\n    verbose=False,\n):\n    \"\"\"Apply clustering to a projection of the normalized Laplacian.\n\n    In practice Spectral Clustering is very useful when the structure of\n    the individual clusters is highly non-convex or more generally when\n    a measure of the center and spread of the cluster is not a suitable\n    description of the complete cluster. For instance, when clusters are\n    nested circles on the 2D plane.\n\n    If affinity is the adjacency matrix of a graph, this method can be\n    used to find normalized graph cuts [1]_, [2]_.\n\n    Read more in the :ref:`User Guide <spectral_clustering>`.\n\n    Parameters\n    ----------\n    affinity : {array-like, sparse matrix} of shape (n_samples, n_samples)\n        The affinity matrix describing the relationship of the samples to\n        embed. **Must be symmetric**.\n\n        Possible examples:\n          - adjacency matrix of a graph,\n          - heat kernel of the pairwise distance matrix of the samples,\n          - symmetric k-nearest neighbours connectivity matrix of the samples.\n\n    n_clusters : int, default=None\n        Number of clusters to extract.\n\n    n_components : int, default=n_clusters\n        Number of eigenvectors to use for the spectral embedding.\n\n    eigen_solver : {None, 'arpack', 'lobpcg', or 'amg'}\n        The eigenvalue decomposition method. If None then ``'arpack'`` is used.\n        See [4]_ for more details regarding ``'lobpcg'``.\n        Eigensolver ``'amg'`` runs ``'lobpcg'`` with optional\n        Algebraic MultiGrid preconditioning and requires pyamg to be installed.\n        It can be faster on very large sparse problems [6]_ and [7]_.\n\n    random_state : int, RandomState instance, default=None\n        A pseudo random number generator used for the initialization\n        of the lobpcg eigenvectors decomposition when `eigen_solver ==\n        'amg'`, and for the K-Means initialization. Use an int to make\n        the results deterministic across calls (See\n        :term:`Glossary <random_state>`).\n\n        .. note::\n            When using `eigen_solver == 'amg'`,\n            it is necessary to also fix the global numpy seed with\n            `np.random.seed(int)` to get deterministic results. See\n            https://github.com/pyamg/pyamg/issues/139 for further\n            information.\n\n    n_init : int, default=10\n        Number of time the k-means algorithm will be run with different\n        centroid seeds. The final results will be the best output of n_init\n        consecutive runs in terms of inertia. Only used if\n        ``assign_labels='kmeans'``.\n\n    eigen_tol : float, default=\"auto\"\n        Stopping criterion for eigendecomposition of the Laplacian matrix.\n        If `eigen_tol=\"auto\"` then the passed tolerance will depend on the\n        `eigen_solver`:\n\n        - If `eigen_solver=\"arpack\"`, then `eigen_tol=0.0`;\n        - If `eigen_solver=\"lobpcg\"` or `eigen_solver=\"amg\"`, then\n          `eigen_tol=None` which configures the underlying `lobpcg` solver to\n          automatically resolve the value according to their heuristics. See,\n          :func:`scipy.sparse.linalg.lobpcg` for details.\n\n        Note that when using `eigen_solver=\"lobpcg\"` or `eigen_solver=\"amg\"`\n        values of `tol<1e-5` may lead to convergence issues and should be\n        avoided.\n\n        .. versionadded:: 1.2\n           Added 'auto' option.\n\n    assign_labels : {'kmeans', 'discretize', 'cluster_qr'}, default='kmeans'\n        The strategy to use to assign labels in the embedding\n        space.  There are three ways to assign labels after the Laplacian\n        embedding.  k-means can be applied and is a popular choice. But it can\n        also be sensitive to initialization. Discretization is another\n        approach which is less sensitive to random initialization [3]_.\n        The cluster_qr method [5]_ directly extracts clusters from eigenvectors\n        in spectral clustering. In contrast to k-means and discretization, cluster_qr\n        has no tuning parameters and is not an iterative method, yet may outperform\n        k-means and discretization in terms of both quality and speed. For a detailed\n        comparison of clustering strategies, refer to the following example:\n        :ref:`sphx_glr_auto_examples_cluster_plot_coin_segmentation.py`.\n\n        .. versionchanged:: 1.1\n           Added new labeling method 'cluster_qr'.\n\n    verbose : bool, default=False\n        Verbosity mode.\n\n        .. versionadded:: 0.24\n\n    Returns\n    -------\n    labels : array of integers, shape: n_samples\n        The labels of the clusters.\n\n    Notes\n    -----\n    The graph should contain only one connected component, elsewhere\n    the results make little sense.\n\n    This algorithm solves the normalized cut for `k=2`: it is a\n    normalized spectral clustering.\n\n    References\n    ----------\n\n    .. [1] :doi:`Normalized cuts and image segmentation, 2000\n           Jianbo Shi, Jitendra Malik\n           <10.1109/34.868688>`\n\n    .. [2] :doi:`A Tutorial on Spectral Clustering, 2007\n           Ulrike von Luxburg\n           <10.1007/s11222-007-9033-z>`\n\n    .. [3] `Multiclass spectral clustering, 2003\n           Stella X. Yu, Jianbo Shi\n           <https://people.eecs.berkeley.edu/~jordan/courses/281B-spring04/readings/yu-shi.pdf>`_\n\n    .. [4] :doi:`Toward the Optimal Preconditioned Eigensolver:\n           Locally Optimal Block Preconditioned Conjugate Gradient Method, 2001\n           A. V. Knyazev\n           SIAM Journal on Scientific Computing 23, no. 2, pp. 517-541.\n           <10.1137/S1064827500366124>`\n\n    .. [5] :doi:`Simple, direct, and efficient multi-way spectral clustering, 2019\n           Anil Damle, Victor Minden, Lexing Ying\n           <10.1093/imaiai/iay008>`\n\n    .. [6] :doi:`Multiscale Spectral Image Segmentation Multiscale preconditioning\n           for computing eigenvalues of graph Laplacians in image segmentation, 2006\n           Andrew Knyazev\n           <10.13140/RG.2.2.35280.02565>`\n\n    .. [7] :doi:`Preconditioned spectral clustering for stochastic block partition\n           streaming graph challenge (Preliminary version at arXiv.)\n           David Zhuzhunashvili, Andrew Knyazev\n           <10.1109/HPEC.2017.8091045>`\n\n    Examples\n    --------\n    >>> import numpy as np\n    >>> from sklearn.metrics.pairwise import pairwise_kernels\n    >>> from sklearn.cluster import spectral_clustering\n    >>> X = np.array([[1, 1], [2, 1], [1, 0],\n    ...               [4, 7], [3, 5], [3, 6]])\n    >>> affinity = pairwise_kernels(X, metric='rbf')\n    >>> spectral_clustering(\n    ...     affinity=affinity, n_clusters=2, assign_labels=\"discretize\", random_state=0\n    ... )\n    array([1, 1, 1, 0, 0, 0])\n    \"\"\"\n\n    clusterer = SpectralClustering(\n        n_clusters=n_clusters,\n        n_components=n_components,\n        eigen_solver=eigen_solver,\n        random_state=random_state,\n        n_init=n_init,\n        affinity=\"precomputed\",\n        eigen_tol=eigen_tol,\n        assign_labels=assign_labels,\n        verbose=verbose,\n    ).fit(affinity)\n\n    return clusterer.labels_\n", "type": "function"}, {"name": "test_affinity_propagation_precomputed_with_sparse_input", "is_method": false, "class_name": null, "parameters": ["csr_container"], "calls": ["pytest.mark.parametrize", "pytest.raises", "fit", "csr_container", "AffinityPropagation"], "code_location": {"file": "test_affinity_propagation.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/cluster/tests", "start_line": 108, "end_line": 111}, "code_snippet": "def test_affinity_propagation_precomputed_with_sparse_input(csr_container):\n    err_msg = \"Sparse data was passed for X, but dense data is required\"\n    with pytest.raises(TypeError, match=err_msg):\n        AffinityPropagation(affinity=\"precomputed\").fit(csr_container((3, 3)))\n", "type": "function"}, {"name": "test_affinities", "is_method": false, "class_name": null, "parameters": ["global_random_seed"], "calls": ["make_blobs", "SpectralClustering", "SpectralClustering", "kernel_metrics", "SpectralClustering", "SpectralClustering", "pytest.warns", "sp.fit", "adjusted_rand_score", "sp.fit", "adjusted_rand_score", "rand", "sp.fit", "sum", "sp.fit", "SpectralClustering", "check_random_state", "sp.fit", "np.minimum"], "code_location": {"file": "test_spectral.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/cluster/tests", "start_line": 133, "end_line": 172}, "code_snippet": "def test_affinities(global_random_seed):\n    # Note: in the following, random_state has been selected to have\n    # a dataset that yields a stable eigen decomposition both when built\n    # on OSX and Linux\n    X, y = make_blobs(\n        n_samples=20, random_state=0, centers=[[1, 1], [-1, -1]], cluster_std=0.01\n    )\n    # nearest neighbors affinity\n    sp = SpectralClustering(n_clusters=2, affinity=\"nearest_neighbors\", random_state=0)\n    with pytest.warns(UserWarning, match=\"not fully connected\"):\n        sp.fit(X)\n    assert adjusted_rand_score(y, sp.labels_) == 1\n\n    sp = SpectralClustering(n_clusters=2, gamma=2, random_state=global_random_seed)\n    labels = sp.fit(X).labels_\n    assert adjusted_rand_score(y, labels) == 1\n\n    X = check_random_state(10).rand(10, 5) * 10\n\n    kernels_available = kernel_metrics()\n    for kern in kernels_available:\n        # Additive chi^2 gives a negative similarity matrix which\n        # doesn't make sense for spectral clustering\n        if kern != \"additive_chi2\":\n            sp = SpectralClustering(n_clusters=2, affinity=kern, random_state=0)\n            labels = sp.fit(X).labels_\n            assert (X.shape[0],) == labels.shape\n\n    sp = SpectralClustering(n_clusters=2, affinity=lambda x, y: 1, random_state=0)\n    labels = sp.fit(X).labels_\n    assert (X.shape[0],) == labels.shape\n\n    def histogram(x, y, **kwargs):\n        # Histogram kernel implemented as a callable.\n        assert kwargs == {}  # no kernel_params that we didn't ask for\n        return np.minimum(x, y).sum()\n\n    sp = SpectralClustering(n_clusters=2, affinity=histogram, random_state=0)\n    labels = sp.fit(X).labels_\n    assert (X.shape[0],) == labels.shape\n", "type": "function"}], "retrieved_count": 10, "cost_time": 1.1628313064575195}
{"question": "What is the impact of the dependency on StandardScaler within the _fit method on the correctness of PowerTransformer's standardization logic when standardize=True, and what would break if StandardScaler's fit_transform behavior changed?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"name": "test_power_transformer_fit_transform", "is_method": false, "class_name": null, "parameters": ["method", "standardize"], "calls": ["pytest.mark.parametrize", "pytest.mark.parametrize", "PowerTransformer", "assert_array_almost_equal", "np.abs", "transform", "pt.fit_transform", "pt.fit"], "code_location": {"file": "test_data.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/preprocessing/tests", "start_line": 2416, "end_line": 2423}, "code_snippet": "def test_power_transformer_fit_transform(method, standardize):\n    # check that fit_transform() and fit().transform() return the same values\n    X = X_1col\n    if method == \"box-cox\":\n        X = np.abs(X)\n\n    pt = PowerTransformer(method, standardize=standardize)\n    assert_array_almost_equal(pt.fit(X).transform(X), pt.fit_transform(X))\n", "type": "function"}, {"name": "test_power_transformer_copy_False", "is_method": false, "class_name": null, "parameters": ["method", "standardize"], "calls": ["pytest.mark.parametrize", "pytest.mark.parametrize", "X.copy", "assert_array_almost_equal", "PowerTransformer", "pt.fit", "assert_array_almost_equal", "pt.transform", "pt.fit_transform", "pt.inverse_transform", "np.abs", "np.abs"], "code_location": {"file": "test_data.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/preprocessing/tests", "start_line": 2456, "end_line": 2481}, "code_snippet": "def test_power_transformer_copy_False(method, standardize):\n    # check that when copy=False fit doesn't change X inplace but transform,\n    # fit_transform and inverse_transform do.\n    X = X_1col\n    if method == \"box-cox\":\n        X = np.abs(X)\n\n    X_original = X.copy()\n    assert X is not X_original  # sanity checks\n    assert_array_almost_equal(X, X_original)\n\n    pt = PowerTransformer(method, standardize=standardize, copy=False)\n\n    pt.fit(X)\n    assert_array_almost_equal(X, X_original)  # fit didn't change X\n\n    X_trans = pt.transform(X)\n    assert X_trans is X\n\n    if method == \"box-cox\":\n        X = np.abs(X)\n    X_trans = pt.fit_transform(X)\n    assert X_trans is X\n\n    X_inv_trans = pt.inverse_transform(X_trans)\n    assert X_trans is X_inv_trans\n", "type": "function"}, {"name": "test_power_transformer_copy_True", "is_method": false, "class_name": null, "parameters": ["method", "standardize"], "calls": ["pytest.mark.parametrize", "pytest.mark.parametrize", "X.copy", "assert_array_almost_equal", "PowerTransformer", "pt.fit", "assert_array_almost_equal", "pt.transform", "pt.fit_transform", "assert_array_almost_equal", "pt.inverse_transform", "np.abs"], "code_location": {"file": "test_data.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/preprocessing/tests", "start_line": 2428, "end_line": 2451}, "code_snippet": "def test_power_transformer_copy_True(method, standardize):\n    # Check that neither fit, transform, fit_transform nor inverse_transform\n    # modify X inplace when copy=True\n    X = X_1col\n    if method == \"box-cox\":\n        X = np.abs(X)\n\n    X_original = X.copy()\n    assert X is not X_original  # sanity checks\n    assert_array_almost_equal(X, X_original)\n\n    pt = PowerTransformer(method, standardize=standardize, copy=True)\n\n    pt.fit(X)\n    assert_array_almost_equal(X, X_original)\n    X_trans = pt.transform(X)\n    assert X_trans is not X\n\n    X_trans = pt.fit_transform(X)\n    assert_array_almost_equal(X, X_original)\n    assert X_trans is not X\n\n    X_inv_trans = pt.inverse_transform(X_trans)\n    assert X_trans is not X_inv_trans\n", "type": "function"}, {"name": "_fit", "is_method": true, "class_name": "PowerTransformer", "parameters": ["self", "X", "y", "force_transform"], "calls": ["self._check_input", "np.mean", "np.var", "X.copy", "np.errstate", "np.empty", "enumerate", "set_output", "_is_constant_feature", "optim_function", "self._scaler.fit_transform", "self._scaler.fit", "transform_function", "StandardScaler"], "code_location": {"file": "_data.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/preprocessing", "start_line": 3380, "end_line": 3422}, "code_snippet": "    def _fit(self, X, y=None, force_transform=False):\n        X = self._check_input(X, in_fit=True, check_positive=True)\n\n        if not self.copy and not force_transform:  # if call from fit()\n            X = X.copy()  # force copy so that fit does not change X inplace\n\n        n_samples = X.shape[0]\n        mean = np.mean(X, axis=0, dtype=np.float64)\n        var = np.var(X, axis=0, dtype=np.float64)\n\n        optim_function = {\n            \"box-cox\": self._box_cox_optimize,\n            \"yeo-johnson\": self._yeo_johnson_optimize,\n        }[self.method]\n\n        transform_function = {\n            \"box-cox\": boxcox,\n            \"yeo-johnson\": self._yeo_johnson_transform,\n        }[self.method]\n\n        with np.errstate(invalid=\"ignore\"):  # hide NaN warnings\n            self.lambdas_ = np.empty(X.shape[1], dtype=X.dtype)\n            for i, col in enumerate(X.T):\n                # For yeo-johnson, leave constant features unchanged\n                # lambda=1 corresponds to the identity transformation\n                is_constant_feature = _is_constant_feature(var[i], mean[i], n_samples)\n                if self.method == \"yeo-johnson\" and is_constant_feature:\n                    self.lambdas_[i] = 1.0\n                    continue\n\n                self.lambdas_[i] = optim_function(col)\n\n                if self.standardize or force_transform:\n                    X[:, i] = transform_function(X[:, i], self.lambdas_[i])\n\n        if self.standardize:\n            self._scaler = StandardScaler(copy=False).set_output(transform=\"default\")\n            if force_transform:\n                X = self._scaler.fit_transform(X)\n            else:\n                self._scaler.fit(X)\n\n        return X\n", "type": "function"}, {"name": "test_power_transformer_notfitted", "is_method": false, "class_name": null, "parameters": ["method"], "calls": ["pytest.mark.parametrize", "PowerTransformer", "np.abs", "pytest.raises", "pt.transform", "pytest.raises", "pt.inverse_transform"], "code_location": {"file": "test_data.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/preprocessing/tests", "start_line": 2191, "end_line": 2197}, "code_snippet": "def test_power_transformer_notfitted(method):\n    pt = PowerTransformer(method=method)\n    X = np.abs(X_1col)\n    with pytest.raises(NotFittedError):\n        pt.transform(X)\n    with pytest.raises(NotFittedError):\n        pt.inverse_transform(X)\n", "type": "function"}, {"name": "test_power_transformer_inverse", "is_method": false, "class_name": null, "parameters": ["method", "standardize", "X"], "calls": ["pytest.mark.parametrize", "pytest.mark.parametrize", "pytest.mark.parametrize", "PowerTransformer", "pt.fit_transform", "assert_almost_equal", "np.abs", "pt.inverse_transform"], "code_location": {"file": "test_data.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/preprocessing/tests", "start_line": 2203, "end_line": 2209}, "code_snippet": "def test_power_transformer_inverse(method, standardize, X):\n    # Make sure we get the original input when applying transform and then\n    # inverse transform\n    X = np.abs(X) if method == \"box-cox\" else X\n    pt = PowerTransformer(method=method, standardize=standardize)\n    X_trans = pt.fit_transform(X)\n    assert_almost_equal(X, pt.inverse_transform(X_trans))\n", "type": "function"}, {"name": "test_power_transformer_2d", "is_method": false, "class_name": null, "parameters": [], "calls": ["np.abs", "PowerTransformer", "pt.fit_transform", "power_transform", "isinstance", "range", "pt.inverse_transform", "assert_array_almost_equal", "len", "stats.boxcox", "assert_almost_equal", "assert_almost_equal", "flatten", "scale"], "code_location": {"file": "test_data.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/preprocessing/tests", "start_line": 2236, "end_line": 2260}, "code_snippet": "def test_power_transformer_2d():\n    X = np.abs(X_2d)\n\n    for standardize in [True, False]:\n        pt = PowerTransformer(method=\"box-cox\", standardize=standardize)\n\n        X_trans_class = pt.fit_transform(X)\n        X_trans_func = power_transform(X, method=\"box-cox\", standardize=standardize)\n\n        for X_trans in [X_trans_class, X_trans_func]:\n            for j in range(X_trans.shape[1]):\n                X_expected, lmbda = stats.boxcox(X[:, j].flatten())\n\n                if standardize:\n                    X_expected = scale(X_expected)\n\n                assert_almost_equal(X_trans[:, j], X_expected)\n                assert_almost_equal(lmbda, pt.lambdas_[j])\n\n            # Test inverse transformation\n            X_inv = pt.inverse_transform(X_trans)\n            assert_array_almost_equal(X_inv, X)\n\n        assert len(pt.lambdas_) == X.shape[1]\n        assert isinstance(pt.lambdas_, np.ndarray)\n", "type": "function"}, {"name": "test_power_transformer_1d", "is_method": false, "class_name": null, "parameters": [], "calls": ["np.abs", "PowerTransformer", "pt.fit_transform", "power_transform", "stats.boxcox", "assert_almost_equal", "assert_almost_equal", "assert_almost_equal", "assert_almost_equal", "isinstance", "X.flatten", "scale", "X_expected.reshape", "X_expected.reshape", "pt.inverse_transform", "len"], "code_location": {"file": "test_data.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/preprocessing/tests", "start_line": 2212, "end_line": 2233}, "code_snippet": "def test_power_transformer_1d():\n    X = np.abs(X_1col)\n\n    for standardize in [True, False]:\n        pt = PowerTransformer(method=\"box-cox\", standardize=standardize)\n\n        X_trans = pt.fit_transform(X)\n        X_trans_func = power_transform(X, method=\"box-cox\", standardize=standardize)\n\n        X_expected, lambda_expected = stats.boxcox(X.flatten())\n\n        if standardize:\n            X_expected = scale(X_expected)\n\n        assert_almost_equal(X_expected.reshape(-1, 1), X_trans)\n        assert_almost_equal(X_expected.reshape(-1, 1), X_trans_func)\n\n        assert_almost_equal(X, pt.inverse_transform(X_trans))\n        assert_almost_equal(lambda_expected, pt.lambdas_[0])\n\n        assert len(pt.lambdas_) == X.shape[1]\n        assert isinstance(pt.lambdas_, np.ndarray)\n", "type": "function"}, {"name": "test_optimization_power_transformer", "is_method": false, "class_name": null, "parameters": ["method", "lmbda"], "calls": ["pytest.mark.parametrize", "np.random.RandomState", "rng.normal", "PowerTransformer", "pt.inverse_transform", "PowerTransformer", "pt.fit_transform", "assert_almost_equal", "assert_almost_equal", "assert_almost_equal", "np.clip", "X_inv_trans.mean", "X_inv_trans.std", "np.linalg.norm"], "code_location": {"file": "test_data.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/preprocessing/tests", "start_line": 2346, "end_line": 2371}, "code_snippet": "def test_optimization_power_transformer(method, lmbda):\n    # Test the optimization procedure:\n    # - set a predefined value for lambda\n    # - apply inverse_transform to a normal dist (we get X_inv)\n    # - apply fit_transform to X_inv (we get X_inv_trans)\n    # - check that X_inv_trans is roughly equal to X\n\n    rng = np.random.RandomState(0)\n    n_samples = 20000\n    X = rng.normal(loc=0, scale=1, size=(n_samples, 1))\n\n    if method == \"box-cox\":\n        # For box-cox, means that lmbda * y + 1 > 0 or y > - 1 / lmbda\n        # Clip the data here to make sure the inequality is valid.\n        X = np.clip(X, -1 / lmbda + 1e-5, None)\n\n    pt = PowerTransformer(method=method, standardize=False)\n    pt.lambdas_ = [lmbda]\n    X_inv = pt.inverse_transform(X)\n\n    pt = PowerTransformer(method=method, standardize=False)\n    X_inv_trans = pt.fit_transform(X_inv)\n\n    assert_almost_equal(0, np.linalg.norm(X - X_inv_trans) / n_samples, decimal=2)\n    assert_almost_equal(0, X_inv_trans.mean(), decimal=1)\n    assert_almost_equal(1, X_inv_trans.std(), decimal=1)\n", "type": "function"}, {"name": "test_column_transformer_cloning", "is_method": false, "class_name": null, "parameters": [], "calls": ["ColumnTransformer", "ct.fit", "hasattr", "ColumnTransformer", "ct.fit_transform", "hasattr", "np.array", "hasattr", "hasattr", "StandardScaler", "StandardScaler"], "code_location": {"file": "test_column_transformer.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/compose/tests", "start_line": 842, "end_line": 853}, "code_snippet": "def test_column_transformer_cloning():\n    X_array = np.array([[0.0, 1.0, 2.0], [2.0, 4.0, 6.0]]).T\n\n    ct = ColumnTransformer([(\"trans\", StandardScaler(), [0])])\n    ct.fit(X_array)\n    assert not hasattr(ct.transformers[0][1], \"mean_\")\n    assert hasattr(ct.transformers_[0][1], \"mean_\")\n\n    ct = ColumnTransformer([(\"trans\", StandardScaler(), [0])])\n    ct.fit_transform(X_array)\n    assert not hasattr(ct.transformers[0][1], \"mean_\")\n    assert hasattr(ct.transformers_[0][1], \"mean_\")\n", "type": "function"}], "retrieved_count": 10, "cost_time": 1.1728153228759766}
{"question": "How does the `pos_label` parameter resolution process handle the case where a user provides an explicit `pos_label` value versus relying on the default `estimators.classes_[1]` assumption in multi-class classification scenarios?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"name": "_get_pos_label", "is_method": true, "class_name": "_BaseScorer", "parameters": ["self"], "calls": ["signature"], "code_location": {"file": "_scorer.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/metrics", "start_line": 247, "end_line": 253}, "code_snippet": "    def _get_pos_label(self):\n        if \"pos_label\" in self._kwargs:\n            return self._kwargs[\"pos_label\"]\n        score_func_params = signature(self._score_func).parameters\n        if \"pos_label\" in score_func_params:\n            return score_func_params[\"pos_label\"].default\n        return None\n", "type": "function"}, {"name": "_check_pos_label_consistency", "is_method": false, "class_name": null, "parameters": ["pos_label", "y_true"], "calls": ["get_namespace_and_device", "xp.unique_values", "_convert_to_numpy", "join", "ValueError", "_is_numpy_namespace", "xp.all", "xp.all", "xp.all", "xp.all", "xp.all", "repr", "classes.tolist", "xp.asarray", "xp.asarray", "xp.asarray", "xp.asarray", "xp.asarray"], "code_location": {"file": "validation.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/utils", "start_line": 2642, "end_line": 2695}, "code_snippet": "def _check_pos_label_consistency(pos_label, y_true):\n    \"\"\"Check if `pos_label` need to be specified or not.\n\n    In binary classification, we fix `pos_label=1` if the labels are in the set\n    {-1, 1} or {0, 1}. Otherwise, we raise an error asking to specify the\n    `pos_label` parameters.\n\n    Parameters\n    ----------\n    pos_label : int, float, bool, str or None\n        The positive label.\n    y_true : ndarray of shape (n_samples,)\n        The target vector.\n\n    Returns\n    -------\n    pos_label : int, float, bool or str\n        If `pos_label` can be inferred, it will be returned.\n\n    Raises\n    ------\n    ValueError\n        In the case that `y_true` does not have label in {-1, 1} or {0, 1},\n        it will raise a `ValueError`.\n    \"\"\"\n    # ensure binary classification if pos_label is not specified\n    # classes.dtype.kind in ('O', 'U', 'S') is required to avoid\n    # triggering a FutureWarning by calling np.array_equal(a, b)\n    # when elements in the two arrays are not comparable.\n    if pos_label is None:\n        # Compute classes only if pos_label is not specified:\n        xp, _, device = get_namespace_and_device(y_true)\n        classes = xp.unique_values(y_true)\n        if (\n            (_is_numpy_namespace(xp) and classes.dtype.kind in \"OUS\")\n            or classes.shape[0] > 2\n            or not (\n                xp.all(classes == xp.asarray([0, 1], device=device))\n                or xp.all(classes == xp.asarray([-1, 1], device=device))\n                or xp.all(classes == xp.asarray([0], device=device))\n                or xp.all(classes == xp.asarray([-1], device=device))\n                or xp.all(classes == xp.asarray([1], device=device))\n            )\n        ):\n            classes = _convert_to_numpy(classes, xp=xp)\n            classes_repr = \", \".join([repr(c) for c in classes.tolist()])\n            raise ValueError(\n                f\"y_true takes value in {{{classes_repr}}} and pos_label is not \"\n                \"specified: either make y_true take value in {0, 1} or \"\n                \"{-1, 1} or pass pos_label explicitly.\"\n            )\n        pos_label = 1\n\n    return pos_label\n", "type": "function"}, {"name": "test_check_pos_label_consistency", "is_method": false, "class_name": null, "parameters": ["y_true"], "calls": ["pytest.mark.parametrize", "_check_pos_label_consistency"], "code_location": {"file": "test_validation.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/utils/tests", "start_line": 1667, "end_line": 1668}, "code_snippet": "def test_check_pos_label_consistency(y_true):\n    assert _check_pos_label_consistency(None, y_true) == 1\n", "type": "function"}, {"name": "test_check_pos_label_consistency_invalid", "is_method": false, "class_name": null, "parameters": ["y_true"], "calls": ["pytest.mark.parametrize", "pytest.raises", "_check_pos_label_consistency", "_check_pos_label_consistency"], "code_location": {"file": "test_validation.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/utils/tests", "start_line": 1685, "end_line": 1689}, "code_snippet": "def test_check_pos_label_consistency_invalid(y_true):\n    with pytest.raises(ValueError, match=\"y_true takes value in\"):\n        _check_pos_label_consistency(None, y_true)\n    # Make sure we only raise if pos_label is None\n    assert _check_pos_label_consistency(\"a\", y_true) == \"a\"\n", "type": "function"}, {"name": "test_scorer_select_proba_error", "is_method": false, "class_name": null, "parameters": ["scorer"], "calls": ["pytest.mark.parametrize", "make_classification", "fit", "tolist", "pytest.raises", "scorer", "make_scorer", "make_scorer", "make_scorer", "LogisticRegression", "np.unique"], "code_location": {"file": "test_score_objects.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/metrics/tests", "start_line": 1168, "end_line": 1179}, "code_snippet": "def test_scorer_select_proba_error(scorer):\n    # check that we raise the proper error when passing an unknown\n    # pos_label\n    X, y = make_classification(\n        n_classes=2, n_informative=3, n_samples=20, random_state=0\n    )\n    lr = LogisticRegression().fit(X, y)\n    assert scorer._kwargs[\"pos_label\"] not in np.unique(y).tolist()\n\n    err_msg = \"is not a valid label\"\n    with pytest.raises(ValueError, match=err_msg):\n        scorer(lr, X, y)\n", "type": "function"}, {"name": "test_average_precision_pos_label", "is_method": false, "class_name": null, "parameters": ["string_labeled_classification_problem"], "calls": ["average_precision_score", "average_precision_score", "make_scorer", "make_scorer", "average_precision_scorer", "deepcopy", "partial", "average_precision_scorer", "pytest.approx", "pytest.raises", "average_precision_scorer", "pytest.approx", "pytest.raises", "clf_without_predict_proba.predict_proba", "pytest.approx"], "code_location": {"file": "test_score_objects.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/metrics/tests", "start_line": 1042, "end_line": 1105}, "code_snippet": "def test_average_precision_pos_label(string_labeled_classification_problem):\n    # check that _Scorer will lead to the right score when passing\n    # `pos_label`. Currently, only `average_precision_score` is defined to\n    # be such a scorer.\n    (\n        clf,\n        X_test,\n        y_test,\n        _,\n        y_pred_proba,\n        y_pred_decision,\n    ) = string_labeled_classification_problem\n\n    pos_label = \"cancer\"\n    # we need to select the positive column or reverse the decision values\n    y_pred_proba = y_pred_proba[:, 0]\n    y_pred_decision = y_pred_decision * -1\n    assert clf.classes_[0] == pos_label\n\n    # check that when calling the scoring function, probability estimates and\n    # decision values lead to the same results\n    ap_proba = average_precision_score(y_test, y_pred_proba, pos_label=pos_label)\n    ap_decision_function = average_precision_score(\n        y_test, y_pred_decision, pos_label=pos_label\n    )\n    assert ap_proba == pytest.approx(ap_decision_function)\n\n    # create a scorer which would require to pass a `pos_label`\n    # check that it fails if `pos_label` is not provided\n    average_precision_scorer = make_scorer(\n        average_precision_score,\n        response_method=(\"decision_function\", \"predict_proba\"),\n    )\n    err_msg = \"pos_label=1 is not a valid label. It should be one of \"\n    with pytest.raises(ValueError, match=err_msg):\n        average_precision_scorer(clf, X_test, y_test)\n\n    # otherwise, the scorer should give the same results than calling the\n    # scoring function\n    average_precision_scorer = make_scorer(\n        average_precision_score,\n        response_method=(\"decision_function\", \"predict_proba\"),\n        pos_label=pos_label,\n    )\n    ap_scorer = average_precision_scorer(clf, X_test, y_test)\n\n    assert ap_scorer == pytest.approx(ap_proba)\n\n    # The above scorer call is using `clf.decision_function`. We will force\n    # it to use `clf.predict_proba`.\n    clf_without_predict_proba = deepcopy(clf)\n\n    def _predict_proba(self, X):\n        raise NotImplementedError\n\n    clf_without_predict_proba.predict_proba = partial(\n        _predict_proba, clf_without_predict_proba\n    )\n    # sanity check\n    with pytest.raises(NotImplementedError):\n        clf_without_predict_proba.predict_proba(X_test)\n\n    ap_scorer = average_precision_scorer(clf_without_predict_proba, X_test, y_test)\n    assert ap_scorer == pytest.approx(ap_proba)\n", "type": "function"}, {"name": "test_get_response_values_multilabel_indicator", "is_method": false, "class_name": null, "parameters": ["response_method"], "calls": ["pytest.mark.parametrize", "make_multilabel_classification", "fit", "_get_response_values", "all", "ClassifierChain", "all", "LogisticRegression", "np.logical_and", "sum", "sum", "np.logical_or"], "code_location": {"file": "test_response.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/utils/tests", "start_line": 356, "end_line": 373}, "code_snippet": "def test_get_response_values_multilabel_indicator(response_method):\n    X, Y = make_multilabel_classification(random_state=0)\n    estimator = ClassifierChain(LogisticRegression()).fit(X, Y)\n\n    y_pred, pos_label = _get_response_values(\n        estimator, X, response_method=response_method\n    )\n    assert pos_label is None\n    assert y_pred.shape == Y.shape\n\n    if response_method == \"predict_proba\":\n        assert np.logical_and(y_pred >= 0, y_pred <= 1).all()\n    elif response_method == \"decision_function\":\n        # values returned by `decision_function` are not bounded in [0, 1]\n        assert (y_pred < 0).sum() > 0\n        assert (y_pred > 1).sum() > 0\n    else:  # response_method == \"predict\"\n        assert np.logical_or(y_pred == 0, y_pred == 1).all()\n", "type": "function"}, {"name": "_process_predict_proba", "is_method": false, "class_name": null, "parameters": [], "calls": ["ValueError", "np.flatnonzero", "isinstance", "np.vstack"], "code_location": {"file": "_response.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/utils", "start_line": 16, "end_line": 73}, "code_snippet": "def _process_predict_proba(*, y_pred, target_type, classes, pos_label):\n    \"\"\"Get the response values when the response method is `predict_proba`.\n\n    This function process the `y_pred` array in the binary and multi-label cases.\n    In the binary case, it selects the column corresponding to the positive\n    class. In the multi-label case, it stacks the predictions if they are not\n    in the \"compressed\" format `(n_samples, n_outputs)`.\n\n    Parameters\n    ----------\n    y_pred : ndarray\n        Output of `estimator.predict_proba`. The shape depends on the target type:\n\n        - for binary classification, it is a 2d array of shape `(n_samples, 2)`;\n        - for multiclass classification, it is a 2d array of shape\n          `(n_samples, n_classes)`;\n        - for multilabel classification, it is either a list of 2d arrays of shape\n          `(n_samples, 2)` (e.g. `RandomForestClassifier` or `KNeighborsClassifier`) or\n          an array of shape `(n_samples, n_outputs)` (e.g. `MLPClassifier` or\n          `RidgeClassifier`).\n\n    target_type : {\"binary\", \"multiclass\", \"multilabel-indicator\"}\n        Type of the target.\n\n    classes : ndarray of shape (n_classes,) or list of such arrays\n        Class labels as reported by `estimator.classes_`.\n\n    pos_label : int, float, bool or str\n        Only used with binary and multiclass targets.\n\n    Returns\n    -------\n    y_pred : ndarray of shape (n_samples,), (n_samples, n_classes) or \\\n            (n_samples, n_output)\n        Compressed predictions format as requested by the metrics.\n    \"\"\"\n    if target_type == \"binary\" and y_pred.shape[1] < 2:\n        # We don't handle classifiers trained on a single class.\n        raise ValueError(\n            f\"Got predict_proba of shape {y_pred.shape}, but need \"\n            \"classifier with two classes.\"\n        )\n\n    if target_type == \"binary\":\n        col_idx = np.flatnonzero(classes == pos_label)[0]\n        return y_pred[:, col_idx]\n    elif target_type == \"multilabel-indicator\":\n        # Use a compress format of shape `(n_samples, n_output)`.\n        # Only `MLPClassifier` and `RidgeClassifier` return an array of shape\n        # `(n_samples, n_outputs)`.\n        if isinstance(y_pred, list):\n            # list of arrays of shape `(n_samples, 2)`\n            return np.vstack([p[:, -1] for p in y_pred]).T\n        else:\n            # array of shape `(n_samples, n_outputs)`\n            return y_pred\n\n    return y_pred\n", "type": "function"}, {"name": "_process_decision_function", "is_method": false, "class_name": null, "parameters": [], "calls": [], "code_location": {"file": "_response.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/utils", "start_line": 76, "end_line": 113}, "code_snippet": "def _process_decision_function(*, y_pred, target_type, classes, pos_label):\n    \"\"\"Get the response values when the response method is `decision_function`.\n\n    This function process the `y_pred` array in the binary and multi-label cases.\n    In the binary case, it inverts the sign of the score if the positive label\n    is not `classes[1]`. In the multi-label case, it stacks the predictions if\n    they are not in the \"compressed\" format `(n_samples, n_outputs)`.\n\n    Parameters\n    ----------\n    y_pred : ndarray\n        Output of `estimator.decision_function`. The shape depends on the target type:\n\n        - for binary classification, it is a 1d array of shape `(n_samples,)` where the\n          sign is assuming that `classes[1]` is the positive class;\n        - for multiclass classification, it is a 2d array of shape\n          `(n_samples, n_classes)`;\n        - for multilabel classification, it is a 2d array of shape `(n_samples,\n          n_outputs)`.\n\n    target_type : {\"binary\", \"multiclass\", \"multilabel-indicator\"}\n        Type of the target.\n\n    classes : ndarray of shape (n_classes,) or list of such arrays\n        Class labels as reported by `estimator.classes_`.\n\n    pos_label : int, float, bool or str\n        Only used with binary and multiclass targets.\n\n    Returns\n    -------\n    y_pred : ndarray of shape (n_samples,), (n_samples, n_classes) or \\\n            (n_samples, n_output)\n        Compressed predictions format as requested by the metrics.\n    \"\"\"\n    if target_type == \"binary\" and pos_label == classes[0]:\n        return -1 * y_pred\n    return y_pred\n", "type": "function"}, {"name": "test_non_symmetric_metric_pos_label", "is_method": false, "class_name": null, "parameters": ["score_func", "string_labeled_classification_problem"], "calls": ["pytest.mark.parametrize", "score_func", "score_func", "make_scorer", "pytest.approx", "scorer", "pytest.approx"], "code_location": {"file": "test_score_objects.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/metrics/tests", "start_line": 1135, "end_line": 1152}, "code_snippet": "def test_non_symmetric_metric_pos_label(\n    score_func, string_labeled_classification_problem\n):\n    # check that _Scorer leads to the right score when `pos_label` is\n    # provided. We check for all possible metric supported.\n    # Note: At some point we may end up having \"scorer tags\".\n    clf, X_test, y_test, y_pred, _, _ = string_labeled_classification_problem\n\n    pos_label = \"cancer\"\n    assert clf.classes_[0] == pos_label\n\n    score_pos_cancer = score_func(y_test, y_pred, pos_label=\"cancer\")\n    score_pos_not_cancer = score_func(y_test, y_pred, pos_label=\"not cancer\")\n\n    assert score_pos_cancer != pytest.approx(score_pos_not_cancer)\n\n    scorer = make_scorer(score_func, pos_label=pos_label)\n    assert scorer(clf, X_test, y_test) == pytest.approx(score_pos_cancer)\n", "type": "function"}], "retrieved_count": 10, "cost_time": 1.145721197128296}
{"question": "Why does the Version class defer the extraction of numeric components from pre, post, and dev tuples until property access time rather than storing them directly during initialization?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"name": "_parse_letter_version", "is_method": false, "class_name": null, "parameters": ["letter", "number"], "calls": ["letter.lower", "int", "int"], "code_location": {"file": "version.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/externals/_packaging", "start_line": 424, "end_line": 457}, "code_snippet": "def _parse_letter_version(\n    letter: str, number: Union[str, bytes, SupportsInt]\n) -> Optional[Tuple[str, int]]:\n\n    if letter:\n        # We consider there to be an implicit 0 in a pre-release if there is\n        # not a numeral associated with it.\n        if number is None:\n            number = 0\n\n        # We normalize any letters to their lower case form\n        letter = letter.lower()\n\n        # We consider some words to be alternate spellings of other words and\n        # in those cases we want to normalize the spellings to our preferred\n        # spelling.\n        if letter == \"alpha\":\n            letter = \"a\"\n        elif letter == \"beta\":\n            letter = \"b\"\n        elif letter in [\"c\", \"pre\", \"preview\"]:\n            letter = \"rc\"\n        elif letter in [\"rev\", \"r\"]:\n            letter = \"post\"\n\n        return letter, int(number)\n    if not letter and number:\n        # We assume if we are given a number, but we are not given a letter\n        # then this is using the implicit post release syntax (e.g. 1.0-1)\n        letter = \"post\"\n\n        return letter, int(number)\n\n    return None\n", "type": "function"}, {"name": "__init__", "is_method": true, "class_name": "Version", "parameters": ["self", "version"], "calls": ["self._regex.search", "_Version", "_cmpkey", "InvalidVersion", "tuple", "_parse_letter_version", "_parse_letter_version", "_parse_letter_version", "_parse_local_version", "match.group", "int", "match.group", "match.group", "match.group", "match.group", "match.group", "match.group", "match.group", "int", "match.group", "match.group", "split", "match.group"], "code_location": {"file": "version.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/externals/_packaging", "start_line": 292, "end_line": 319}, "code_snippet": "    def __init__(self, version: str) -> None:\n\n        # Validate the version and parse it into pieces\n        match = self._regex.search(version)\n        if not match:\n            raise InvalidVersion(f\"Invalid version: '{version}'\")\n\n        # Store the parsed out pieces of the version\n        self._version = _Version(\n            epoch=int(match.group(\"epoch\")) if match.group(\"epoch\") else 0,\n            release=tuple(int(i) for i in match.group(\"release\").split(\".\")),\n            pre=_parse_letter_version(match.group(\"pre_l\"), match.group(\"pre_n\")),\n            post=_parse_letter_version(\n                match.group(\"post_l\"), match.group(\"post_n1\") or match.group(\"post_n2\")\n            ),\n            dev=_parse_letter_version(match.group(\"dev_l\"), match.group(\"dev_n\")),\n            local=_parse_local_version(match.group(\"local\")),\n        )\n\n        # Generate a key which will be used for sorting\n        self._key = _cmpkey(\n            self._version.epoch,\n            self._version.release,\n            self._version.pre,\n            self._version.post,\n            self._version.dev,\n            self._version.local,\n        )\n", "type": "function"}, {"name": "_cmpkey", "is_method": false, "class_name": null, "parameters": ["epoch", "release", "pre", "post", "dev", "local"], "calls": ["tuple", "reversed", "tuple", "list", "itertools.dropwhile", "reversed", "isinstance"], "code_location": {"file": "version.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/externals/_packaging", "start_line": 475, "end_line": 535}, "code_snippet": "def _cmpkey(\n    epoch: int,\n    release: Tuple[int, ...],\n    pre: Optional[Tuple[str, int]],\n    post: Optional[Tuple[str, int]],\n    dev: Optional[Tuple[str, int]],\n    local: Optional[Tuple[SubLocalType]],\n) -> CmpKey:\n\n    # When we compare a release version, we want to compare it with all of the\n    # trailing zeros removed. So we'll use a reverse the list, drop all the now\n    # leading zeros until we come to something non zero, then take the rest\n    # re-reverse it back into the correct order and make it a tuple and use\n    # that for our sorting key.\n    _release = tuple(\n        reversed(list(itertools.dropwhile(lambda x: x == 0, reversed(release))))\n    )\n\n    # We need to \"trick\" the sorting algorithm to put 1.0.dev0 before 1.0a0.\n    # We'll do this by abusing the pre segment, but we _only_ want to do this\n    # if there is not a pre or a post segment. If we have one of those then\n    # the normal sorting rules will handle this case correctly.\n    if pre is None and post is None and dev is not None:\n        _pre: PrePostDevType = NegativeInfinity\n    # Versions without a pre-release (except as noted above) should sort after\n    # those with one.\n    elif pre is None:\n        _pre = Infinity\n    else:\n        _pre = pre\n\n    # Versions without a post segment should sort before those with one.\n    if post is None:\n        _post: PrePostDevType = NegativeInfinity\n\n    else:\n        _post = post\n\n    # Versions without a development segment should sort after those with one.\n    if dev is None:\n        _dev: PrePostDevType = Infinity\n\n    else:\n        _dev = dev\n\n    if local is None:\n        # Versions without a local segment should sort before those with one.\n        _local: LocalType = NegativeInfinity\n    else:\n        # Versions with a local segment need that segment parsed to implement\n        # the sorting rules in PEP440.\n        # - Alpha numeric segments sort before numeric segments\n        # - Alpha numeric segments sort lexicographically\n        # - Numeric segments sort numerically\n        # - Shorter versions sort before longer versions when the prefixes\n        #   match exactly\n        _local = tuple(\n            (i, \"\") if isinstance(i, int) else (NegativeInfinity, i) for i in local\n        )\n\n    return epoch, _release, _pre, _post, _dev, _local\n", "type": "function"}, {"name": "_parse_version_parts", "is_method": false, "class_name": null, "parameters": ["s"], "calls": ["_legacy_version_component_re.split", "_legacy_version_replacement_map.get", "part.zfill"], "code_location": {"file": "version.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/externals/_packaging", "start_line": 210, "end_line": 224}, "code_snippet": "def _parse_version_parts(s: str) -> Iterator[str]:\n    for part in _legacy_version_component_re.split(s):\n        part = _legacy_version_replacement_map.get(part, part)\n\n        if not part or part == \".\":\n            continue\n\n        if part[:1] in \"0123456789\":\n            # pad for numeric comparison\n            yield part.zfill(8)\n        else:\n            yield \"*\" + part\n\n    # ensure that alpha/beta/candidate are before final\n    yield \"*final\"\n", "type": "function"}, {"name": "pre", "is_method": true, "class_name": "Version", "parameters": ["self"], "calls": [], "code_location": {"file": "version.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/externals/_packaging", "start_line": 363, "end_line": 365}, "code_snippet": "    def pre(self) -> Optional[Tuple[str, int]]:\n        _pre: Optional[Tuple[str, int]] = self._version.pre\n        return _pre\n", "type": "function"}, {"name": "release", "is_method": true, "class_name": "Version", "parameters": ["self"], "calls": [], "code_location": {"file": "version.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/externals/_packaging", "start_line": 358, "end_line": 360}, "code_snippet": "    def release(self) -> Tuple[int, ...]:\n        _release: Tuple[int, ...] = self._version.release\n        return _release\n", "type": "function"}, {"name": "__init__", "is_method": true, "class_name": "LegacyVersion", "parameters": ["self", "version"], "calls": ["str", "_legacy_cmpkey", "warnings.warn"], "code_location": {"file": "version.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/externals/_packaging", "start_line": 138, "end_line": 146}, "code_snippet": "    def __init__(self, version: str) -> None:\n        self._version = str(version)\n        self._key = _legacy_cmpkey(self._version)\n\n        warnings.warn(\n            \"Creating a LegacyVersion has been deprecated and will be \"\n            \"removed in the next major release\",\n            DeprecationWarning,\n        )\n", "type": "function"}, {"name": "__str__", "is_method": true, "class_name": "Version", "parameters": ["self"], "calls": ["parts.append", "join", "parts.append", "join", "parts.append", "parts.append", "parts.append", "parts.append", "join", "str", "str"], "code_location": {"file": "version.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/externals/_packaging", "start_line": 324, "end_line": 350}, "code_snippet": "    def __str__(self) -> str:\n        parts = []\n\n        # Epoch\n        if self.epoch != 0:\n            parts.append(f\"{self.epoch}!\")\n\n        # Release segment\n        parts.append(\".\".join(str(x) for x in self.release))\n\n        # Pre-release\n        if self.pre is not None:\n            parts.append(\"\".join(str(x) for x in self.pre))\n\n        # Post-release\n        if self.post is not None:\n            parts.append(f\".post{self.post}\")\n\n        # Development release\n        if self.dev is not None:\n            parts.append(f\".dev{self.dev}\")\n\n        # Local version segment\n        if self.local is not None:\n            parts.append(f\"+{self.local}\")\n\n        return \"\".join(parts)\n", "type": "function"}, {"name": "_legacy_cmpkey", "is_method": false, "class_name": null, "parameters": ["version"], "calls": ["_parse_version_parts", "version.lower", "part.startswith", "parts.append", "tuple", "parts.pop", "parts.pop"], "code_location": {"file": "version.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/externals/_packaging", "start_line": 227, "end_line": 251}, "code_snippet": "def _legacy_cmpkey(version: str) -> LegacyCmpKey:\n\n    # We hardcode an epoch of -1 here. A PEP 440 version can only have a epoch\n    # greater than or equal to 0. This will effectively put the LegacyVersion,\n    # which uses the defacto standard originally implemented by setuptools,\n    # as before all PEP 440 versions.\n    epoch = -1\n\n    # This scheme is taken from pkg_resources.parse_version setuptools prior to\n    # it's adoption of the packaging library.\n    parts: List[str] = []\n    for part in _parse_version_parts(version.lower()):\n        if part.startswith(\"*\"):\n            # remove \"-\" before a prerelease tag\n            if part < \"*final\":\n                while parts and parts[-1] == \"*final-\":\n                    parts.pop()\n\n            # remove trailing zeros from each series of numeric parts\n            while parts and parts[-1] == \"00000000\":\n                parts.pop()\n\n        parts.append(part)\n\n    return epoch, tuple(parts)\n", "type": "function"}, {"name": "base_version", "is_method": true, "class_name": "Version", "parameters": ["self"], "calls": ["parts.append", "join", "parts.append", "join", "str"], "code_location": {"file": "version.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/externals/_packaging", "start_line": 387, "end_line": 397}, "code_snippet": "    def base_version(self) -> str:\n        parts = []\n\n        # Epoch\n        if self.epoch != 0:\n            parts.append(f\"{self.epoch}!\")\n\n        # Release segment\n        parts.append(\".\".join(str(x) for x in self.release))\n\n        return \"\".join(parts)\n", "type": "function"}], "retrieved_count": 10, "cost_time": 1.144974946975708}
{"question": "Why does the exception handling mechanism in OpenMLError impact the performance of HTTP error recovery operations when processing large-scale dataset downloads with retry logic?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"name": "test_open_openml_url_retry_on_network_error", "is_method": false, "class_name": null, "parameters": ["monkeypatch"], "calls": ["monkeypatch.setattr", "HTTPError", "pytest.warns", "pytest.raises", "_open_openml_url", "len", "BytesIO", "re.escape"], "code_location": {"file": "test_openml.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/datasets/tests", "start_line": 1524, "end_line": 1545}, "code_snippet": "def test_open_openml_url_retry_on_network_error(monkeypatch):\n    def _mock_urlopen_network_error(request, *args, **kwargs):\n        raise HTTPError(\n            url=None, code=404, msg=\"Simulated network error\", hdrs=None, fp=BytesIO()\n        )\n\n    monkeypatch.setattr(\n        sklearn.datasets._openml, \"urlopen\", _mock_urlopen_network_error\n    )\n\n    invalid_openml_url = \"https://api.openml.org/invalid-url\"\n\n    with pytest.warns(\n        UserWarning,\n        match=re.escape(\n            \"A network error occurred while downloading\"\n            f\" {invalid_openml_url}. Retrying...\"\n        ),\n    ) as record:\n        with pytest.raises(HTTPError, match=\"Simulated network error\"):\n            _open_openml_url(invalid_openml_url, None, delay=0)\n        assert len(record) == 3\n", "type": "function"}, {"name": "test_retry_with_clean_cache_http_error", "is_method": false, "class_name": null, "parameters": ["tmpdir"], "calls": ["_MONKEY_PATCH_LOCAL_OPENML_PATH.format", "str", "_retry_with_clean_cache", "tmpdir.mkdir", "HTTPError", "pytest.raises", "_load_data", "BytesIO"], "code_location": {"file": "test_openml.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/datasets/tests", "start_line": 1418, "end_line": 1431}, "code_snippet": "def test_retry_with_clean_cache_http_error(tmpdir):\n    data_id = 61\n    openml_path = _MONKEY_PATCH_LOCAL_OPENML_PATH.format(data_id)\n    cache_directory = str(tmpdir.mkdir(\"scikit_learn_data\"))\n\n    @_retry_with_clean_cache(openml_path, cache_directory)\n    def _load_data():\n        raise HTTPError(\n            url=None, code=412, msg=\"Simulated mock error\", hdrs=None, fp=BytesIO()\n        )\n\n    error_msg = \"Simulated mock error\"\n    with pytest.raises(HTTPError, match=error_msg):\n        _load_data()\n", "type": "function"}, {"name": "test_fetch_openml_error", "is_method": false, "class_name": null, "parameters": ["monkeypatch", "gzip_response", "data_id", "params", "err_type", "err_msg", "parser"], "calls": ["pytest.mark.parametrize", "pytest.mark.parametrize", "pytest.mark.parametrize", "_monkey_patch_webbased_functions", "params.get", "pytest.importorskip", "pytest.raises", "fetch_openml"], "code_location": {"file": "test_openml.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/datasets/tests", "start_line": 1215, "end_line": 1222}, "code_snippet": "def test_fetch_openml_error(\n    monkeypatch, gzip_response, data_id, params, err_type, err_msg, parser\n):\n    _monkey_patch_webbased_functions(monkeypatch, data_id, gzip_response)\n    if params.get(\"as_frame\", True) or parser == \"pandas\":\n        pytest.importorskip(\"pandas\")\n    with pytest.raises(err_type, match=err_msg):\n        fetch_openml(cache=False, parser=parser, **params)\n", "type": "function"}, {"name": "test_dataset_with_openml_error", "is_method": false, "class_name": null, "parameters": ["monkeypatch", "gzip_response"], "calls": ["pytest.mark.parametrize", "_monkey_patch_webbased_functions", "pytest.warns", "fetch_openml"], "code_location": {"file": "test_openml.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/datasets/tests", "start_line": 1306, "end_line": 1311}, "code_snippet": "def test_dataset_with_openml_error(monkeypatch, gzip_response):\n    data_id = 1\n    _monkey_patch_webbased_functions(monkeypatch, data_id, gzip_response)\n    msg = \"OpenML registered a problem with the dataset. It might be unusable. Error:\"\n    with pytest.warns(UserWarning, match=msg):\n        fetch_openml(data_id=data_id, cache=False, as_frame=False, parser=\"liac-arff\")\n", "type": "function"}, {"name": "_retry_on_network_error", "is_method": false, "class_name": null, "parameters": ["n_retries", "delay", "url"], "calls": ["wraps", "f", "warn", "time.sleep", "isinstance"], "code_location": {"file": "_openml.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/datasets", "start_line": 85, "end_line": 117}, "code_snippet": "def _retry_on_network_error(\n    n_retries: int = 3, delay: float = 1.0, url: str = \"\"\n) -> Callable:\n    \"\"\"If the function call results in a network error, call the function again\n    up to ``n_retries`` times with a ``delay`` between each call. If the error\n    has a 412 status code, don't call the function again as this is a specific\n    OpenML error.\n    The url parameter is used to give more information to the user about the\n    error.\n    \"\"\"\n\n    def decorator(f):\n        @wraps(f)\n        def wrapper(*args, **kwargs):\n            retry_counter = n_retries\n            while True:\n                try:\n                    return f(*args, **kwargs)\n                except (URLError, TimeoutError) as e:\n                    # 412 is a specific OpenML error code.\n                    if isinstance(e, HTTPError) and e.code == 412:\n                        raise\n                    if retry_counter == 0:\n                        raise\n                    warn(\n                        f\"A network error occurred while downloading {url}. Retrying...\"\n                    )\n                    retry_counter -= 1\n                    time.sleep(delay)\n\n        return wrapper\n\n    return decorator\n", "type": "function"}, {"name": "test_open_openml_url_unlinks_local_path", "is_method": false, "class_name": null, "parameters": ["monkeypatch", "tmpdir", "write_to_disk"], "calls": ["pytest.mark.parametrize", "str", "_get_local_path", "monkeypatch.setattr", "_MONKEY_PATCH_LOCAL_OPENML_PATH.format", "tmpdir.mkdir", "ValueError", "pytest.raises", "_open_openml_url", "os.path.exists", "open", "f.write"], "code_location": {"file": "test_openml.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/datasets/tests", "start_line": 1374, "end_line": 1392}, "code_snippet": "def test_open_openml_url_unlinks_local_path(monkeypatch, tmpdir, write_to_disk):\n    data_id = 61\n    openml_path = _MONKEY_PATCH_LOCAL_OPENML_PATH.format(data_id) + \"/filename.arff\"\n    url = f\"https://www.openml.org/{openml_path}\"\n    cache_directory = str(tmpdir.mkdir(\"scikit_learn_data\"))\n    location = _get_local_path(openml_path, cache_directory)\n\n    def _mock_urlopen(request, *args, **kwargs):\n        if write_to_disk:\n            with open(location, \"w\") as f:\n                f.write(\"\")\n        raise ValueError(\"Invalid request\")\n\n    monkeypatch.setattr(sklearn.datasets._openml, \"urlopen\", _mock_urlopen)\n\n    with pytest.raises(ValueError, match=\"Invalid request\"):\n        _open_openml_url(url, cache_directory)\n\n    assert not os.path.exists(location)\n", "type": "function"}, {"name": "_open_openml_url", "is_method": false, "class_name": null, "parameters": ["url", "data_home", "n_retries", "delay"], "calls": ["Request", "req.add_header", "path.lstrip", "_get_local_path", "os.path.split", "gzip.GzipFile", "is_gzip_encoded", "os.path.exists", "os.makedirs", "get", "gzip.GzipFile", "_retry_on_network_error", "urlparse", "TemporaryDirectory", "shutil.move", "os.path.exists", "_fsrc.info", "closing", "is_gzip_encoded", "os.unlink", "opener", "shutil.copyfileobj", "os.path.join", "_retry_on_network_error"], "code_location": {"file": "_openml.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/datasets", "start_line": 120, "end_line": 193}, "code_snippet": "def _open_openml_url(\n    url: str, data_home: Optional[str], n_retries: int = 3, delay: float = 1.0\n):\n    \"\"\"\n    Returns a resource from OpenML.org. Caches it to data_home if required.\n\n    Parameters\n    ----------\n    url : str\n        OpenML URL that will be downloaded and cached locally. The path component\n        of the URL is used to replicate the tree structure as sub-folders of the local\n        cache folder.\n\n    data_home : str\n        Directory to which the files will be cached. If None, no caching will\n        be applied.\n\n    n_retries : int, default=3\n        Number of retries when HTTP errors are encountered. Error with status\n        code 412 won't be retried as they represent OpenML generic errors.\n\n    delay : float, default=1.0\n        Number of seconds between retries.\n\n    Returns\n    -------\n    result : stream\n        A stream to the OpenML resource.\n    \"\"\"\n\n    def is_gzip_encoded(_fsrc):\n        return _fsrc.info().get(\"Content-Encoding\", \"\") == \"gzip\"\n\n    req = Request(url)\n    req.add_header(\"Accept-encoding\", \"gzip\")\n\n    if data_home is None:\n        fsrc = _retry_on_network_error(n_retries, delay, req.full_url)(urlopen)(req)\n        if is_gzip_encoded(fsrc):\n            return gzip.GzipFile(fileobj=fsrc, mode=\"rb\")\n        return fsrc\n\n    openml_path = urlparse(url).path.lstrip(\"/\")\n    local_path = _get_local_path(openml_path, data_home)\n    dir_name, file_name = os.path.split(local_path)\n    if not os.path.exists(local_path):\n        os.makedirs(dir_name, exist_ok=True)\n        try:\n            # Create a tmpdir as a subfolder of dir_name where the final file will\n            # be moved to if the download is successful. This guarantees that the\n            # renaming operation to the final location is atomic to ensure the\n            # concurrence safety of the dataset caching mechanism.\n            with TemporaryDirectory(dir=dir_name) as tmpdir:\n                with closing(\n                    _retry_on_network_error(n_retries, delay, req.full_url)(urlopen)(\n                        req\n                    )\n                ) as fsrc:\n                    opener: Callable\n                    if is_gzip_encoded(fsrc):\n                        opener = open\n                    else:\n                        opener = gzip.GzipFile\n                    with opener(os.path.join(tmpdir, file_name), \"wb\") as fdst:\n                        shutil.copyfileobj(fsrc, fdst)\n                shutil.move(fdst.name, local_path)\n        except Exception:\n            if os.path.exists(local_path):\n                os.unlink(local_path)\n            raise\n\n    # XXX: First time, decompression will not be necessary (by using fsrc), but\n    # it will happen nonetheless\n    return gzip.GzipFile(local_path, \"rb\")\n", "type": "function"}, {"name": "test_retry_with_clean_cache", "is_method": false, "class_name": null, "parameters": ["tmpdir"], "calls": ["_MONKEY_PATCH_LOCAL_OPENML_PATH.format", "str", "_get_local_path", "os.makedirs", "_retry_with_clean_cache", "tmpdir.mkdir", "os.path.dirname", "open", "f.write", "os.path.exists", "pytest.warns", "_load_data", "Exception"], "code_location": {"file": "test_openml.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/datasets/tests", "start_line": 1395, "end_line": 1415}, "code_snippet": "def test_retry_with_clean_cache(tmpdir):\n    data_id = 61\n    openml_path = _MONKEY_PATCH_LOCAL_OPENML_PATH.format(data_id)\n    cache_directory = str(tmpdir.mkdir(\"scikit_learn_data\"))\n    location = _get_local_path(openml_path, cache_directory)\n    os.makedirs(os.path.dirname(location))\n\n    with open(location, \"w\") as f:\n        f.write(\"\")\n\n    @_retry_with_clean_cache(openml_path, cache_directory)\n    def _load_data():\n        # The first call will raise an error since location exists\n        if os.path.exists(location):\n            raise Exception(\"File exist!\")\n        return 1\n\n    warn_msg = \"Invalid cache, redownloading file\"\n    with pytest.warns(RuntimeWarning, match=warn_msg):\n        result = _load_data()\n    assert result == 1\n", "type": "function"}, {"name": "_monkey_patch_webbased_functions", "is_method": false, "class_name": null, "parameters": ["context", "data_id", "gzip_response"], "calls": ["replace", "url.startswith", "_file_name", "_mock_urlopen_shared", "_mock_urlopen_shared", "_mock_urlopen_shared", "url.startswith", "_file_name", "request.get_full_url", "url.startswith", "context.setattr", "resources.files", "data_file_path.open", "url.rsplit", "resources.files", "data_file_path.open", "read_fn", "decode", "json.loads", "HTTPError", "data_file_path.open", "request.get_header", "_mock_urlopen_data_list", "url.startswith", "re.sub", "replace", "BytesIO", "_MockHTTPResponse", "read_fn", "BytesIO", "_MockHTTPResponse", "BytesIO", "_MockHTTPResponse", "read_fn", "BytesIO", "_MockHTTPResponse", "_mock_urlopen_data_features", "url.startswith", "f.read", "decompressed_f.read", "decompressed_f.read", "BytesIO", "f.read", "decompressed_f.read", "_mock_urlopen_download_data", "url.startswith", "replace", "_mock_urlopen_data_description", "ValueError", "len", "replace", "replace", "replace", "replace", "replace", "replace", "replace", "output.replace"], "code_location": {"file": "test_openml.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/datasets/tests", "start_line": 71, "end_line": 201}, "code_snippet": "def _monkey_patch_webbased_functions(context, data_id, gzip_response):\n    # monkey patches the urlopen function. Important note: Do NOT use this\n    # in combination with a regular cache directory, as the files that are\n    # stored as cache should not be mixed up with real openml datasets\n    url_prefix_data_description = \"https://api.openml.org/api/v1/json/data/\"\n    url_prefix_data_features = \"https://api.openml.org/api/v1/json/data/features/\"\n    url_prefix_download_data = \"https://www.openml.org/data/v1/download\"\n    url_prefix_data_list = \"https://api.openml.org/api/v1/json/data/list/\"\n\n    path_suffix = \".gz\"\n    read_fn = gzip.open\n\n    data_module = OPENML_TEST_DATA_MODULE + \".\" + f\"id_{data_id}\"\n\n    def _file_name(url, suffix):\n        output = (\n            re.sub(r\"\\W\", \"-\", url[len(\"https://api.openml.org/\") :])\n            + suffix\n            + path_suffix\n        )\n        # Shorten the filenames to have better compatibility with windows 10\n        # and filenames > 260 characters\n        return (\n            output.replace(\"-json-data-list\", \"-jdl\")\n            .replace(\"-json-data-features\", \"-jdf\")\n            .replace(\"-json-data-qualities\", \"-jdq\")\n            .replace(\"-json-data\", \"-jd\")\n            .replace(\"-data_name\", \"-dn\")\n            .replace(\"-download\", \"-dl\")\n            .replace(\"-limit\", \"-l\")\n            .replace(\"-data_version\", \"-dv\")\n            .replace(\"-status\", \"-s\")\n            .replace(\"-deactivated\", \"-dact\")\n            .replace(\"-active\", \"-act\")\n        )\n\n    def _mock_urlopen_shared(url, has_gzip_header, expected_prefix, suffix):\n        assert url.startswith(expected_prefix), (\n            f\"{expected_prefix!r} does not match {url!r}\"\n        )\n\n        data_file_name = _file_name(url, suffix)\n        data_file_path = resources.files(data_module) / data_file_name\n\n        with data_file_path.open(\"rb\") as f:\n            if has_gzip_header and gzip_response:\n                fp = BytesIO(f.read())\n                return _MockHTTPResponse(fp, True)\n            else:\n                decompressed_f = read_fn(f, \"rb\")\n                fp = BytesIO(decompressed_f.read())\n                return _MockHTTPResponse(fp, False)\n\n    def _mock_urlopen_data_description(url, has_gzip_header):\n        return _mock_urlopen_shared(\n            url=url,\n            has_gzip_header=has_gzip_header,\n            expected_prefix=url_prefix_data_description,\n            suffix=\".json\",\n        )\n\n    def _mock_urlopen_data_features(url, has_gzip_header):\n        return _mock_urlopen_shared(\n            url=url,\n            has_gzip_header=has_gzip_header,\n            expected_prefix=url_prefix_data_features,\n            suffix=\".json\",\n        )\n\n    def _mock_urlopen_download_data(url, has_gzip_header):\n        # For simplicity the mock filenames don't contain the filename, i.e.\n        # the last part of the data description url after the last /.\n        # For example for id_1, data description download url is:\n        # gunzip -c sklearn/datasets/tests/data/openml/id_1/api-v1-jd-1.json.gz | grep '\"url\"  # noqa: E501\n        # \"https:\\/\\/www.openml.org\\/data\\/v1\\/download\\/1\\/anneal.arff\"\n        # but the mock filename does not contain anneal.arff and is:\n        # sklearn/datasets/tests/data/openml/id_1/data-v1-dl-1.arff.gz.\n        # We only keep the part of the url before the last /\n        url_without_filename = url.rsplit(\"/\", 1)[0]\n\n        return _mock_urlopen_shared(\n            url=url_without_filename,\n            has_gzip_header=has_gzip_header,\n            expected_prefix=url_prefix_download_data,\n            suffix=\".arff\",\n        )\n\n    def _mock_urlopen_data_list(url, has_gzip_header):\n        assert url.startswith(url_prefix_data_list), (\n            f\"{url_prefix_data_list!r} does not match {url!r}\"\n        )\n\n        data_file_name = _file_name(url, \".json\")\n        data_file_path = resources.files(data_module) / data_file_name\n\n        # load the file itself, to simulate a http error\n        with data_file_path.open(\"rb\") as f:\n            decompressed_f = read_fn(f, \"rb\")\n            decoded_s = decompressed_f.read().decode(\"utf-8\")\n            json_data = json.loads(decoded_s)\n        if \"error\" in json_data:\n            raise HTTPError(\n                url=None, code=412, msg=\"Simulated mock error\", hdrs=None, fp=BytesIO()\n            )\n\n        with data_file_path.open(\"rb\") as f:\n            if has_gzip_header:\n                fp = BytesIO(f.read())\n                return _MockHTTPResponse(fp, True)\n            else:\n                decompressed_f = read_fn(f, \"rb\")\n                fp = BytesIO(decompressed_f.read())\n                return _MockHTTPResponse(fp, False)\n\n    def _mock_urlopen(request, *args, **kwargs):\n        url = request.get_full_url()\n        has_gzip_header = request.get_header(\"Accept-encoding\") == \"gzip\"\n        if url.startswith(url_prefix_data_list):\n            return _mock_urlopen_data_list(url, has_gzip_header)\n        elif url.startswith(url_prefix_data_features):\n            return _mock_urlopen_data_features(url, has_gzip_header)\n        elif url.startswith(url_prefix_download_data):\n            return _mock_urlopen_download_data(url, has_gzip_header)\n        elif url.startswith(url_prefix_data_description):\n            return _mock_urlopen_data_description(url, has_gzip_header)\n        else:\n            raise ValueError(\"Unknown mocking URL pattern: %s\" % url)\n\n    # XXX: Global variable\n    if test_offline:\n        context.setattr(sklearn.datasets._openml, \"urlopen\", _mock_urlopen)\n", "type": "function"}, {"name": "test_fetch_remote_raise_warnings_with_invalid_url", "is_method": false, "class_name": null, "parameters": ["monkeypatch"], "calls": ["RemoteFileMetadata", "Mock", "monkeypatch.setattr", "pytest.warns", "HTTPError", "pytest.raises", "_fetch_remote", "len", "str", "io.BytesIO"], "code_location": {"file": "test_base.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/datasets/tests", "start_line": 378, "end_line": 398}, "code_snippet": "def test_fetch_remote_raise_warnings_with_invalid_url(monkeypatch):\n    \"\"\"Check retry mechanism in _fetch_remote.\"\"\"\n\n    url = \"https://scikit-learn.org/this_file_does_not_exist.tar.gz\"\n    invalid_remote_file = RemoteFileMetadata(\"invalid_file\", url, None)\n    urlretrieve_mock = Mock(\n        side_effect=HTTPError(\n            url=url, code=404, msg=\"Not Found\", hdrs=None, fp=io.BytesIO()\n        )\n    )\n    monkeypatch.setattr(\"sklearn.datasets._base.urlretrieve\", urlretrieve_mock)\n\n    with pytest.warns(UserWarning, match=\"Retry downloading\") as record:\n        with pytest.raises(HTTPError, match=\"HTTP Error 404\"):\n            _fetch_remote(invalid_remote_file, n_retries=3, delay=0)\n\n        assert urlretrieve_mock.call_count == 4\n\n        for r in record:\n            assert str(r.message) == f\"Retry downloading from url: {url}\"\n        assert len(record) == 3\n", "type": "function"}], "retrieved_count": 10, "cost_time": 1.1575603485107422}
{"question": "How does the NearestCentroid classifier reconcile the different centroid computation strategies between euclidean and manhattan metrics during the fit phase, and what architectural implications does this dual-path approach have for maintaining consistency across sparse and dense data representations?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"name": "test_manhattan_metric", "is_method": false, "class_name": null, "parameters": ["csr_container"], "calls": ["pytest.mark.parametrize", "csr_container", "NearestCentroid", "clf.fit", "clf.fit", "assert_array_equal", "assert_array_equal"], "code_location": {"file": "test_nearest_centroid.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/neighbors/tests", "start_line": 168, "end_line": 177}, "code_snippet": "def test_manhattan_metric(csr_container):\n    # Test the manhattan metric.\n    X_csr = csr_container(X)\n\n    clf = NearestCentroid(metric=\"manhattan\")\n    clf.fit(X, y)\n    dense_centroid = clf.centroids_\n    clf.fit(X_csr, y)\n    assert_array_equal(clf.centroids_, dense_centroid)\n    assert_array_equal(dense_centroid, [[-1, -1], [1, 1]])\n", "type": "function"}, {"name": "test_radius_neighbors_classmode_strategy_consistent", "is_method": false, "class_name": null, "parameters": ["outlier_label"], "calls": ["pytest.mark.parametrize", "np.random.RandomState", "rng.rand", "rng.rand", "rng.randint", "np.unique", "RadiusNeighborsClassMode.compute", "RadiusNeighborsClassMode.compute", "assert_allclose"], "code_location": {"file": "test_pairwise_distances_reduction.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/metrics/tests", "start_line": 1611, "end_line": 1643}, "code_snippet": "def test_radius_neighbors_classmode_strategy_consistent(outlier_label):\n    rng = np.random.RandomState(1)\n    X = rng.rand(100, 10)\n    Y = rng.rand(100, 10)\n    radius = 5\n    metric = \"manhattan\"\n\n    weights = \"uniform\"\n    Y_labels = rng.randint(low=0, high=10, size=100)\n    unique_Y_labels = np.unique(Y_labels)\n    results_X = RadiusNeighborsClassMode.compute(\n        X=X,\n        Y=Y,\n        radius=radius,\n        metric=metric,\n        weights=weights,\n        Y_labels=Y_labels,\n        unique_Y_labels=unique_Y_labels,\n        outlier_label=outlier_label,\n        strategy=\"parallel_on_X\",\n    )\n    results_Y = RadiusNeighborsClassMode.compute(\n        X=X,\n        Y=Y,\n        radius=radius,\n        metric=metric,\n        weights=weights,\n        Y_labels=Y_labels,\n        unique_Y_labels=unique_Y_labels,\n        outlier_label=outlier_label,\n        strategy=\"parallel_on_Y\",\n    )\n    assert_allclose(results_X, results_Y)\n", "type": "function"}, {"name": "test_euclidean_distance", "is_method": false, "class_name": null, "parameters": ["dtype", "squared", "global_random_seed"], "calls": ["pytest.mark.parametrize", "pytest.mark.parametrize", "np.random.RandomState", "sp.random", "reshape", "astype", "sum", "sum", "_euclidean_dense_dense_wrapper", "_euclidean_sparse_dense_wrapper", "assert_allclose", "assert_allclose", "assert_allclose", "np.sqrt", "a_sparse.toarray", "rng.randn"], "code_location": {"file": "test_k_means.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/cluster/tests", "start_line": 1029, "end_line": 1051}, "code_snippet": "def test_euclidean_distance(dtype, squared, global_random_seed):\n    # Check that the _euclidean_(dense/sparse)_dense helpers produce correct\n    # results\n    rng = np.random.RandomState(global_random_seed)\n    a_sparse = sp.random(\n        1, 100, density=0.5, format=\"csr\", random_state=rng, dtype=dtype\n    )\n    a_dense = a_sparse.toarray().reshape(-1)\n    b = rng.randn(100).astype(dtype, copy=False)\n    b_squared_norm = (b**2).sum()\n\n    expected = ((a_dense - b) ** 2).sum()\n    expected = expected if squared else np.sqrt(expected)\n\n    distance_dense_dense = _euclidean_dense_dense_wrapper(a_dense, b, squared)\n    distance_sparse_dense = _euclidean_sparse_dense_wrapper(\n        a_sparse.data, a_sparse.indices, b, b_squared_norm, squared\n    )\n\n    rtol = 1e-4 if dtype == np.float32 else 1e-7\n    assert_allclose(distance_dense_dense, distance_sparse_dense, rtol=rtol)\n    assert_allclose(distance_dense_dense, expected, rtol=rtol)\n    assert_allclose(distance_sparse_dense, expected, rtol=rtol)\n", "type": "function"}, {"name": "test_pairwise_distances_reduction_is_usable_for", "is_method": false, "class_name": null, "parameters": ["csr_container"], "calls": ["pytest.mark.parametrize", "np.random.RandomState", "rng.rand", "rng.rand", "csr_container", "csr_container", "BaseDistancesReductionDispatcher.is_usable_for", "BaseDistancesReductionDispatcher.is_usable_for", "BaseDistancesReductionDispatcher.is_usable_for", "BaseDistancesReductionDispatcher.is_usable_for", "BaseDistancesReductionDispatcher.is_usable_for", "BaseDistancesReductionDispatcher.is_usable_for", "BaseDistancesReductionDispatcher.is_usable_for", "BaseDistancesReductionDispatcher.is_usable_for", "csr_container", "csr_container", "X_csr_int64.indices.astype", "X.astype", "Y.astype", "X.astype", "Y.astype", "BaseDistancesReductionDispatcher.is_usable_for", "BaseDistancesReductionDispatcher.is_usable_for", "BaseDistancesReductionDispatcher.is_usable_for", "BaseDistancesReductionDispatcher.is_usable_for", "BaseDistancesReductionDispatcher.is_usable_for", "BaseDistancesReductionDispatcher.is_usable_for", "BaseDistancesReductionDispatcher.is_usable_for", "BaseDistancesReductionDispatcher.is_usable_for", "BaseDistancesReductionDispatcher.is_usable_for", "X.astype", "Y.astype", "X.astype", "Y.astype", "np.asfortranarray"], "code_location": {"file": "test_pairwise_distances_reduction.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/metrics/tests", "start_line": 654, "end_line": 719}, "code_snippet": "def test_pairwise_distances_reduction_is_usable_for(csr_container):\n    rng = np.random.RandomState(0)\n    X = rng.rand(100, 10)\n    Y = rng.rand(100, 10)\n    X_csr = csr_container(X)\n    Y_csr = csr_container(Y)\n    metric = \"manhattan\"\n\n    # Must be usable for all possible pair of {dense, sparse} datasets\n    assert BaseDistancesReductionDispatcher.is_usable_for(X, Y, metric)\n    assert BaseDistancesReductionDispatcher.is_usable_for(X_csr, Y_csr, metric)\n    assert BaseDistancesReductionDispatcher.is_usable_for(X_csr, Y, metric)\n    assert BaseDistancesReductionDispatcher.is_usable_for(X, Y_csr, metric)\n\n    assert BaseDistancesReductionDispatcher.is_usable_for(\n        X.astype(np.float64), Y.astype(np.float64), metric\n    )\n\n    assert BaseDistancesReductionDispatcher.is_usable_for(\n        X.astype(np.float32), Y.astype(np.float32), metric\n    )\n\n    assert not BaseDistancesReductionDispatcher.is_usable_for(\n        X.astype(np.int64), Y.astype(np.int64), metric\n    )\n\n    assert not BaseDistancesReductionDispatcher.is_usable_for(X, Y, metric=\"pyfunc\")\n    assert not BaseDistancesReductionDispatcher.is_usable_for(\n        X.astype(np.float32), Y, metric\n    )\n    assert not BaseDistancesReductionDispatcher.is_usable_for(\n        X, Y.astype(np.int32), metric\n    )\n\n    # F-ordered arrays are not supported\n    assert not BaseDistancesReductionDispatcher.is_usable_for(\n        np.asfortranarray(X), Y, metric\n    )\n\n    assert BaseDistancesReductionDispatcher.is_usable_for(X_csr, Y, metric=\"euclidean\")\n    assert BaseDistancesReductionDispatcher.is_usable_for(\n        X, Y_csr, metric=\"sqeuclidean\"\n    )\n\n    # FIXME: the current Cython implementation is too slow for a large number of\n    # features. We temporarily disable it to fallback on SciPy's implementation.\n    # See: https://github.com/scikit-learn/scikit-learn/issues/28191\n    assert not BaseDistancesReductionDispatcher.is_usable_for(\n        X_csr, Y_csr, metric=\"sqeuclidean\"\n    )\n    assert not BaseDistancesReductionDispatcher.is_usable_for(\n        X_csr, Y_csr, metric=\"euclidean\"\n    )\n\n    # CSR matrices without non-zeros elements aren't currently supported\n    # TODO: support CSR matrices without non-zeros elements\n    X_csr_0_nnz = csr_container(X * 0)\n    assert not BaseDistancesReductionDispatcher.is_usable_for(X_csr_0_nnz, Y, metric)\n\n    # CSR matrices with int64 indices and indptr (e.g. large nnz, or large n_features)\n    # aren't supported as of now.\n    # See: https://github.com/scikit-learn/scikit-learn/issues/23653\n    # TODO: support CSR matrices with int64 indices and indptr\n    X_csr_int64 = csr_container(X)\n    X_csr_int64.indices = X_csr_int64.indices.astype(np.int64)\n    assert not BaseDistancesReductionDispatcher.is_usable_for(X_csr_int64, Y, metric)\n", "type": "function"}, {"name": "test_classification_toy", "is_method": false, "class_name": null, "parameters": ["csr_container"], "calls": ["pytest.mark.parametrize", "csr_container", "csr_container", "NearestCentroid", "clf.fit", "assert_array_equal", "assert_array_almost_equal", "assert_array_almost_equal", "NearestCentroid", "clf.fit", "assert_array_equal", "assert_array_almost_equal", "assert_array_almost_equal", "NearestCentroid", "clf.fit", "assert_array_equal", "assert_array_almost_equal", "assert_array_almost_equal", "NearestCentroid", "clf.fit", "assert_array_equal", "NearestCentroid", "clf.fit", "assert_array_equal", "NearestCentroid", "clf.fit", "assert_array_equal", "NearestCentroid", "clf.fit", "assert_array_equal", "NearestCentroid", "clf.fit", "assert_array_equal", "clf.predict", "clf.decision_function", "clf.predict_proba", "clf.predict", "clf.decision_function", "clf.predict_proba", "clf.predict", "clf.decision_function", "clf.predict_proba", "clf.predict", "clf.predict", "clf.predict", "clf.predict", "X_csr.tocoo", "clf.predict", "T_csr.tolil"], "code_location": {"file": "test_nearest_centroid.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/neighbors/tests", "start_line": 38, "end_line": 86}, "code_snippet": "def test_classification_toy(csr_container):\n    # Check classification on a toy dataset, including sparse versions.\n    X_csr = csr_container(X)\n    T_csr = csr_container(T)\n\n    # Check classification on a toy dataset, including sparse versions.\n    clf = NearestCentroid()\n    clf.fit(X, y)\n    assert_array_equal(clf.predict(T), true_result)\n    assert_array_almost_equal(clf.decision_function(T), true_discriminant_scores)\n    assert_array_almost_equal(clf.predict_proba(T), true_proba)\n\n    # Test uniform priors\n    clf = NearestCentroid(priors=\"uniform\")\n    clf.fit(X, y)\n    assert_array_equal(clf.predict(T), true_result)\n    assert_array_almost_equal(clf.decision_function(T), true_discriminant_scores)\n    assert_array_almost_equal(clf.predict_proba(T), true_proba)\n\n    clf = NearestCentroid(priors=\"empirical\")\n    clf.fit(X, y)\n    assert_array_equal(clf.predict(T), true_result)\n    assert_array_almost_equal(clf.decision_function(T), true_discriminant_scores)\n    assert_array_almost_equal(clf.predict_proba(T), true_proba)\n\n    # Test custom priors\n    clf = NearestCentroid(priors=[0.25, 0.75])\n    clf.fit(X, y)\n    assert_array_equal(clf.predict(T), true_result_prior1)\n\n    # Same test, but with a sparse matrix to fit and test.\n    clf = NearestCentroid()\n    clf.fit(X_csr, y)\n    assert_array_equal(clf.predict(T_csr), true_result)\n\n    # Fit with sparse, test with non-sparse\n    clf = NearestCentroid()\n    clf.fit(X_csr, y)\n    assert_array_equal(clf.predict(T), true_result)\n\n    # Fit with non-sparse, test with sparse\n    clf = NearestCentroid()\n    clf.fit(X, y)\n    assert_array_equal(clf.predict(T_csr), true_result)\n\n    # Fit and predict with non-CSR sparse matrices\n    clf = NearestCentroid()\n    clf.fit(X_csr.tocoo(), y)\n    assert_array_equal(clf.predict(T_csr.tolil()), true_result)\n", "type": "function"}, {"name": "test_pairwise_distances_for_sparse_data", "is_method": false, "class_name": null, "parameters": ["coo_container", "csc_container", "bsr_container", "csr_container", "global_dtype"], "calls": ["pytest.mark.parametrize", "pytest.mark.parametrize", "pytest.mark.parametrize", "pytest.mark.parametrize", "np.random.RandomState", "astype", "astype", "csr_container", "csr_container", "pairwise_distances", "euclidean_distances", "assert_allclose", "pairwise_distances", "cosine_distances", "assert_allclose", "pairwise_distances", "manhattan_distances", "assert_allclose", "manhattan_distances", "assert_allclose", "pairwise_distances", "pairwise_distances", "assert_allclose", "pairwise_distances", "pairwise_distances", "assert_allclose", "csc_container", "bsr_container", "coo_container", "pytest.raises", "pairwise_distances", "pytest.raises", "pairwise_distances", "rng.random_sample", "rng.random_sample", "pytest.raises", "pytest.raises"], "code_location": {"file": "test_pairwise.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/metrics/tests", "start_line": 197, "end_line": 259}, "code_snippet": "def test_pairwise_distances_for_sparse_data(\n    coo_container, csc_container, bsr_container, csr_container, global_dtype\n):\n    # Test the pairwise_distance helper function.\n    rng = np.random.RandomState(0)\n    X = rng.random_sample((5, 4)).astype(global_dtype, copy=False)\n    Y = rng.random_sample((2, 4)).astype(global_dtype, copy=False)\n\n    # Test with sparse X and Y,\n    # currently only supported for Euclidean, L1 and cosine.\n    X_sparse = csr_container(X)\n    Y_sparse = csr_container(Y)\n\n    S = pairwise_distances(X_sparse, Y_sparse, metric=\"euclidean\")\n    S2 = euclidean_distances(X_sparse, Y_sparse)\n    assert_allclose(S, S2)\n    assert S.dtype == S2.dtype == global_dtype\n\n    S = pairwise_distances(X_sparse, Y_sparse, metric=\"cosine\")\n    S2 = cosine_distances(X_sparse, Y_sparse)\n    assert_allclose(S, S2)\n    assert S.dtype == S2.dtype == global_dtype\n\n    S = pairwise_distances(X_sparse, csc_container(Y), metric=\"manhattan\")\n    S2 = manhattan_distances(bsr_container(X), coo_container(Y))\n    assert_allclose(S, S2)\n    if global_dtype == np.float64:\n        assert S.dtype == S2.dtype == global_dtype\n    else:\n        # TODO Fix manhattan_distances to preserve dtype.\n        # currently pairwise_distances uses manhattan_distances but converts the result\n        # back to the input dtype\n        with pytest.raises(AssertionError):\n            assert S.dtype == S2.dtype == global_dtype\n\n    S2 = manhattan_distances(X, Y)\n    assert_allclose(S, S2)\n    if global_dtype == np.float64:\n        assert S.dtype == S2.dtype == global_dtype\n    else:\n        # TODO Fix manhattan_distances to preserve dtype.\n        # currently pairwise_distances uses manhattan_distances but converts the result\n        # back to the input dtype\n        with pytest.raises(AssertionError):\n            assert S.dtype == S2.dtype == global_dtype\n\n    # Test with scipy.spatial.distance metric, with a kwd\n    kwds = {\"p\": 2.0}\n    S = pairwise_distances(X, Y, metric=\"minkowski\", **kwds)\n    S2 = pairwise_distances(X, Y, metric=minkowski, **kwds)\n    assert_allclose(S, S2)\n\n    # same with Y = None\n    kwds = {\"p\": 2.0}\n    S = pairwise_distances(X, metric=\"minkowski\", **kwds)\n    S2 = pairwise_distances(X, metric=minkowski, **kwds)\n    assert_allclose(S, S2)\n\n    # Test that scipy distance metrics throw an error if sparse matrix given\n    with pytest.raises(TypeError):\n        pairwise_distances(X_sparse, metric=\"minkowski\")\n    with pytest.raises(TypeError):\n        pairwise_distances(X, Y_sparse, metric=\"minkowski\")\n", "type": "function"}, {"name": "test_cdist", "is_method": false, "class_name": null, "parameters": ["metric_param_grid", "X", "Y", "csr_container"], "calls": ["pytest.mark.parametrize", "pytest.mark.parametrize", "pytest.mark.parametrize", "param_grid.keys", "itertools.product", "csr_container", "csr_container", "dict", "cdist", "DistanceMetric.get_metric", "dm.pairwise", "assert_allclose", "dm.pairwise", "assert_allclose", "dm.pairwise", "assert_allclose", "dm.pairwise", "assert_allclose", "param_grid.values", "zip"], "code_location": {"file": "test_dist_metrics.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/metrics/tests", "start_line": 69, "end_line": 104}, "code_snippet": "def test_cdist(metric_param_grid, X, Y, csr_container):\n    metric, param_grid = metric_param_grid\n    keys = param_grid.keys()\n    X_csr, Y_csr = csr_container(X), csr_container(Y)\n    for vals in itertools.product(*param_grid.values()):\n        kwargs = dict(zip(keys, vals))\n        rtol_dict = {}\n        if metric == \"mahalanobis\" and X.dtype == np.float32:\n            # Computation of mahalanobis differs between\n            # the scipy and scikit-learn implementation.\n            # Hence, we increase the relative tolerance.\n            # TODO: Inspect slight numerical discrepancy\n            # with scipy\n            rtol_dict = {\"rtol\": 1e-6}\n\n        D_scipy_cdist = cdist(X, Y, metric, **kwargs)\n\n        dm = DistanceMetric.get_metric(metric, X.dtype, **kwargs)\n\n        # DistanceMetric.pairwise must be consistent for all\n        # combinations of formats in {sparse, dense}.\n        D_sklearn = dm.pairwise(X, Y)\n        assert D_sklearn.flags.c_contiguous\n        assert_allclose(D_sklearn, D_scipy_cdist, **rtol_dict)\n\n        D_sklearn = dm.pairwise(X_csr, Y_csr)\n        assert D_sklearn.flags.c_contiguous\n        assert_allclose(D_sklearn, D_scipy_cdist, **rtol_dict)\n\n        D_sklearn = dm.pairwise(X_csr, Y)\n        assert D_sklearn.flags.c_contiguous\n        assert_allclose(D_sklearn, D_scipy_cdist, **rtol_dict)\n\n        D_sklearn = dm.pairwise(X, Y_csr)\n        assert D_sklearn.flags.c_contiguous\n        assert_allclose(D_sklearn, D_scipy_cdist, **rtol_dict)\n", "type": "function"}, {"name": "test_minibatch_update_consistency", "is_method": false, "class_name": null, "parameters": ["X_csr", "global_random_seed"], "calls": ["pytest.mark.parametrize", "np.random.RandomState", "centers_old.copy", "np.zeros_like", "np.zeros_like", "np.zeros", "np.zeros", "np.ones", "_mini_batch_step", "_labels_inertia", "_mini_batch_step", "_labels_inertia", "assert_array_equal", "assert_allclose", "assert_allclose", "assert_allclose", "rng.normal", "np.random.RandomState", "np.random.RandomState"], "code_location": {"file": "test_k_means.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/cluster/tests", "start_line": 206, "end_line": 266}, "code_snippet": "def test_minibatch_update_consistency(X_csr, global_random_seed):\n    # Check that dense and sparse minibatch update give the same results\n    rng = np.random.RandomState(global_random_seed)\n\n    centers_old = centers + rng.normal(size=centers.shape)\n    centers_old_csr = centers_old.copy()\n\n    centers_new = np.zeros_like(centers_old)\n    centers_new_csr = np.zeros_like(centers_old_csr)\n\n    weight_sums = np.zeros(centers_old.shape[0], dtype=X.dtype)\n    weight_sums_csr = np.zeros(centers_old.shape[0], dtype=X.dtype)\n\n    sample_weight = np.ones(X.shape[0], dtype=X.dtype)\n\n    # extract a small minibatch\n    X_mb = X[:10]\n    X_mb_csr = X_csr[:10]\n    sample_weight_mb = sample_weight[:10]\n\n    # step 1: compute the dense minibatch update\n    old_inertia = _mini_batch_step(\n        X_mb,\n        sample_weight_mb,\n        centers_old,\n        centers_new,\n        weight_sums,\n        np.random.RandomState(global_random_seed),\n        random_reassign=False,\n    )\n    assert old_inertia > 0.0\n\n    # compute the new inertia on the same batch to check that it decreased\n    labels, new_inertia = _labels_inertia(X_mb, sample_weight_mb, centers_new)\n    assert new_inertia > 0.0\n    assert new_inertia < old_inertia\n\n    # step 2: compute the sparse minibatch update\n    old_inertia_csr = _mini_batch_step(\n        X_mb_csr,\n        sample_weight_mb,\n        centers_old_csr,\n        centers_new_csr,\n        weight_sums_csr,\n        np.random.RandomState(global_random_seed),\n        random_reassign=False,\n    )\n    assert old_inertia_csr > 0.0\n\n    # compute the new inertia on the same batch to check that it decreased\n    labels_csr, new_inertia_csr = _labels_inertia(\n        X_mb_csr, sample_weight_mb, centers_new_csr\n    )\n    assert new_inertia_csr > 0.0\n    assert new_inertia_csr < old_inertia_csr\n\n    # step 3: check that sparse and dense updates lead to the same results\n    assert_array_equal(labels, labels_csr)\n    assert_allclose(centers_new, centers_new_csr)\n    assert_allclose(old_inertia, old_inertia_csr)\n    assert_allclose(new_inertia, new_inertia_csr)\n", "type": "function"}, {"name": "test_dense_sparse", "is_method": false, "class_name": null, "parameters": ["Estimator", "X_csr", "global_random_seed"], "calls": ["pytest.mark.parametrize", "pytest.mark.parametrize", "random_sample", "Estimator", "km_dense.fit", "Estimator", "km_sparse.fit", "assert_array_equal", "assert_allclose", "np.random.RandomState"], "code_location": {"file": "test_k_means.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/cluster/tests", "start_line": 663, "end_line": 678}, "code_snippet": "def test_dense_sparse(Estimator, X_csr, global_random_seed):\n    # Check that the results are the same for dense and sparse input.\n    sample_weight = np.random.RandomState(global_random_seed).random_sample(\n        (n_samples,)\n    )\n    km_dense = Estimator(\n        n_clusters=n_clusters, random_state=global_random_seed, n_init=1\n    )\n    km_dense.fit(X, sample_weight=sample_weight)\n    km_sparse = Estimator(\n        n_clusters=n_clusters, random_state=global_random_seed, n_init=1\n    )\n    km_sparse.fit(X_csr, sample_weight=sample_weight)\n\n    assert_array_equal(km_dense.labels_, km_sparse.labels_)\n    assert_allclose(km_dense.cluster_centers_, km_sparse.cluster_centers_)\n", "type": "function"}, {"name": "test_valid_brute_metric_for_auto_algorithm", "is_method": false, "class_name": null, "parameters": ["global_dtype", "metric", "csr_container", "n_samples", "n_features"], "calls": ["pytest.mark.parametrize", "pytest.mark.parametrize", "_parse_metric", "astype", "csr_container", "_generate_test_params_for", "rng.random_sample", "rng.random_sample", "metrics.pairwise_distances", "metrics.pairwise_distances", "neighbors.NearestNeighbors", "nb_p.fit", "nb_p.kneighbors", "rng.rand", "neighbors.NearestNeighbors", "nn.fit", "nn.kneighbors", "slice", "np.ascontiguousarray", "fit", "nn.kneighbors", "neighbors.NearestNeighbors"], "code_location": {"file": "test_neighbors.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/neighbors/tests", "start_line": 1814, "end_line": 1855}, "code_snippet": "def test_valid_brute_metric_for_auto_algorithm(\n    global_dtype, metric, csr_container, n_samples=20, n_features=12\n):\n    metric = _parse_metric(metric, global_dtype)\n\n    X = rng.rand(n_samples, n_features).astype(global_dtype, copy=False)\n    Xcsr = csr_container(X)\n\n    metric_params_list = _generate_test_params_for(metric, n_features)\n\n    if metric == \"precomputed\":\n        X_precomputed = rng.random_sample((10, 4))\n        Y_precomputed = rng.random_sample((3, 4))\n        DXX = metrics.pairwise_distances(X_precomputed, metric=\"euclidean\")\n        DYX = metrics.pairwise_distances(\n            Y_precomputed, X_precomputed, metric=\"euclidean\"\n        )\n        nb_p = neighbors.NearestNeighbors(n_neighbors=3, metric=\"precomputed\")\n        nb_p.fit(DXX)\n        nb_p.kneighbors(DYX)\n\n    else:\n        for metric_params in metric_params_list:\n            nn = neighbors.NearestNeighbors(\n                n_neighbors=3,\n                algorithm=\"auto\",\n                metric=metric,\n                metric_params=metric_params,\n            )\n            # Haversine distance only accepts 2D data\n            if metric == \"haversine\":\n                feature_sl = slice(None, 2)\n                X = np.ascontiguousarray(X[:, feature_sl])\n\n            nn.fit(X)\n            nn.kneighbors(X)\n\n            if metric in VALID_METRICS_SPARSE[\"brute\"]:\n                nn = neighbors.NearestNeighbors(\n                    n_neighbors=3, algorithm=\"auto\", metric=metric\n                ).fit(Xcsr)\n                nn.kneighbors(Xcsr)\n", "type": "function"}], "retrieved_count": 10, "cost_time": 1.1740267276763916}
{"question": "How does the Splitter API handle the interaction between categorical feature splitting and missing value routing when the missing_values_bin_idx parameter is combined with the is_categorical flag, and what determines whether missing samples are routed to the left or right child node during the find_node_split operation?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"name": "test_splitting_missing_values", "is_method": false, "class_name": null, "parameters": ["X_binned", "all_gradients", "has_missing_values", "n_bins_non_missing", "expected_split_on_nan", "expected_bin_idx", "expected_go_to_left"], "calls": ["pytest.mark.parametrize", "len", "np.arange", "reshape", "np.asfortranarray", "np.array", "np.array", "np.ones", "all_gradients.sum", "HistogramBuilder", "np.array", "np.array", "np.zeros_like", "Splitter", "builder.compute_histograms_brute", "compute_node_value", "splitter.find_node_split", "splitter.split_indices", "max", "np.flatnonzero", "np.flatnonzero", "np.array", "set", "set", "set", "set", "set", "set", "set", "set", "np.array", "np.array"], "code_location": {"file": "test_splitting.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/ensemble/_hist_gradient_boosting/tests", "start_line": 487, "end_line": 583}, "code_snippet": "def test_splitting_missing_values(\n    X_binned,\n    all_gradients,\n    has_missing_values,\n    n_bins_non_missing,\n    expected_split_on_nan,\n    expected_bin_idx,\n    expected_go_to_left,\n):\n    # Make sure missing values are properly supported.\n    # we build an artificial example with gradients such that the best split\n    # is on bin_idx=3, when there are no missing values.\n    # Then we introduce missing values and:\n    #   - make sure the chosen bin is correct (find_best_bin()): it's\n    #     still the same split, even though the index of the bin may change\n    #   - make sure the missing values are mapped to the correct child\n    #     (split_indices())\n\n    n_bins = max(X_binned) + 1\n    n_samples = len(X_binned)\n    l2_regularization = 0.0\n    min_hessian_to_split = 1e-3\n    min_samples_leaf = 1\n    min_gain_to_split = 0.0\n\n    sample_indices = np.arange(n_samples, dtype=np.uint32)\n    X_binned = np.array(X_binned, dtype=X_BINNED_DTYPE).reshape(-1, 1)\n    X_binned = np.asfortranarray(X_binned)\n    all_gradients = np.array(all_gradients, dtype=G_H_DTYPE)\n    has_missing_values = np.array([has_missing_values], dtype=np.uint8)\n    all_hessians = np.ones(1, dtype=G_H_DTYPE)\n    sum_gradients = all_gradients.sum()\n    sum_hessians = 1 * n_samples\n    hessians_are_constant = True\n\n    builder = HistogramBuilder(\n        X_binned, n_bins, all_gradients, all_hessians, hessians_are_constant, n_threads\n    )\n\n    n_bins_non_missing = np.array([n_bins_non_missing], dtype=np.uint32)\n    monotonic_cst = np.array(\n        [MonotonicConstraint.NO_CST] * X_binned.shape[1], dtype=np.int8\n    )\n    is_categorical = np.zeros_like(monotonic_cst, dtype=np.uint8)\n    missing_values_bin_idx = n_bins - 1\n    splitter = Splitter(\n        X_binned,\n        n_bins_non_missing,\n        missing_values_bin_idx,\n        has_missing_values,\n        is_categorical,\n        monotonic_cst,\n        l2_regularization,\n        min_hessian_to_split,\n        min_samples_leaf,\n        min_gain_to_split,\n        hessians_are_constant,\n    )\n\n    histograms = builder.compute_histograms_brute(sample_indices)\n    value = compute_node_value(\n        sum_gradients, sum_hessians, -np.inf, np.inf, l2_regularization\n    )\n    split_info = splitter.find_node_split(\n        n_samples, histograms, sum_gradients, sum_hessians, value\n    )\n\n    assert split_info.bin_idx == expected_bin_idx\n    if has_missing_values:\n        assert split_info.missing_go_to_left == expected_go_to_left\n\n    split_on_nan = split_info.bin_idx == n_bins_non_missing[0] - 1\n    assert split_on_nan == expected_split_on_nan\n\n    # Make sure the split is properly computed.\n    # This also make sure missing values are properly assigned to the correct\n    # child in split_indices()\n    samples_left, samples_right, _ = splitter.split_indices(\n        split_info, splitter.partition\n    )\n\n    if not expected_split_on_nan:\n        # When we don't split on nans, the split should always be the same.\n        assert set(samples_left) == set([0, 1, 2, 3])\n        assert set(samples_right) == set([4, 5, 6, 7, 8, 9])\n    else:\n        # When we split on nans, samples with missing values are always mapped\n        # to the right child.\n        missing_samples_indices = np.flatnonzero(\n            np.array(X_binned) == missing_values_bin_idx\n        )\n        non_missing_samples_indices = np.flatnonzero(\n            np.array(X_binned) != missing_values_bin_idx\n        )\n\n        assert set(samples_right) == set(missing_samples_indices)\n        assert set(samples_left) == set(non_missing_samples_indices)\n", "type": "function"}, {"name": "test_splitting_categorical_sanity", "is_method": false, "class_name": null, "parameters": ["X_binned", "all_gradients", "expected_categories_left", "n_bins_non_missing", "missing_values_bin_idx", "has_missing_values", "expected_missing_go_to_left"], "calls": ["pytest.mark.parametrize", "len", "reshape", "np.asfortranarray", "np.arange", "np.array", "np.ones", "np.array", "all_gradients.sum", "HistogramBuilder", "np.array", "np.array", "np.ones_like", "Splitter", "builder.compute_histograms_brute", "compute_node_value", "splitter.find_node_split", "_assert_categories_equals_bitset", "splitter.split_indices", "np.isin", "assert_array_equal", "assert_array_equal", "max", "X_binned.ravel", "np.array", "list", "list", "list", "range", "list", "range", "range", "range"], "code_location": {"file": "test_splitting.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/ensemble/_hist_gradient_boosting/tests", "start_line": 784, "end_line": 864}, "code_snippet": "def test_splitting_categorical_sanity(\n    X_binned,\n    all_gradients,\n    expected_categories_left,\n    n_bins_non_missing,\n    missing_values_bin_idx,\n    has_missing_values,\n    expected_missing_go_to_left,\n):\n    # Tests various combinations of categorical splits\n\n    n_samples = len(X_binned)\n    n_bins = max(X_binned) + 1\n\n    X_binned = np.array(X_binned, dtype=X_BINNED_DTYPE).reshape(-1, 1)\n    X_binned = np.asfortranarray(X_binned)\n\n    l2_regularization = 0.0\n    min_hessian_to_split = 1e-3\n    min_samples_leaf = 1\n    min_gain_to_split = 0.0\n\n    sample_indices = np.arange(n_samples, dtype=np.uint32)\n    all_gradients = np.array(all_gradients, dtype=G_H_DTYPE)\n    all_hessians = np.ones(1, dtype=G_H_DTYPE)\n    has_missing_values = np.array([has_missing_values], dtype=np.uint8)\n    sum_gradients = all_gradients.sum()\n    sum_hessians = n_samples\n    hessians_are_constant = True\n\n    builder = HistogramBuilder(\n        X_binned, n_bins, all_gradients, all_hessians, hessians_are_constant, n_threads\n    )\n\n    n_bins_non_missing = np.array([n_bins_non_missing], dtype=np.uint32)\n    monotonic_cst = np.array(\n        [MonotonicConstraint.NO_CST] * X_binned.shape[1], dtype=np.int8\n    )\n    is_categorical = np.ones_like(monotonic_cst, dtype=np.uint8)\n\n    splitter = Splitter(\n        X_binned,\n        n_bins_non_missing,\n        missing_values_bin_idx,\n        has_missing_values,\n        is_categorical,\n        monotonic_cst,\n        l2_regularization,\n        min_hessian_to_split,\n        min_samples_leaf,\n        min_gain_to_split,\n        hessians_are_constant,\n    )\n\n    histograms = builder.compute_histograms_brute(sample_indices)\n\n    value = compute_node_value(\n        sum_gradients, sum_hessians, -np.inf, np.inf, l2_regularization\n    )\n    split_info = splitter.find_node_split(\n        n_samples, histograms, sum_gradients, sum_hessians, value\n    )\n\n    assert split_info.is_categorical\n    assert split_info.gain > 0\n    _assert_categories_equals_bitset(\n        expected_categories_left, split_info.left_cat_bitset\n    )\n    if has_missing_values:\n        assert split_info.missing_go_to_left == expected_missing_go_to_left\n    # If there is no missing value during training, the flag missing_go_to_left\n    # is set later in the grower.\n\n    # make sure samples are split correctly\n    samples_left, samples_right, _ = splitter.split_indices(\n        split_info, splitter.partition\n    )\n\n    left_mask = np.isin(X_binned.ravel(), expected_categories_left)\n    assert_array_equal(sample_indices[left_mask], samples_left)\n    assert_array_equal(sample_indices[~left_mask], samples_right)\n", "type": "function"}, {"name": "test_splitting_categorical_cat_smooth", "is_method": false, "class_name": null, "parameters": ["X_binned", "has_missing_values", "n_bins_non_missing"], "calls": ["pytest.mark.parametrize", "len", "np.asfortranarray", "np.arange", "np.ones", "np.array", "np.ones", "all_gradients.sum", "HistogramBuilder", "np.array", "np.array", "np.ones_like", "Splitter", "builder.compute_histograms_brute", "compute_node_value", "splitter.find_node_split", "max", "np.array"], "code_location": {"file": "test_splitting.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/ensemble/_hist_gradient_boosting/tests", "start_line": 602, "end_line": 660}, "code_snippet": "def test_splitting_categorical_cat_smooth(\n    X_binned, has_missing_values, n_bins_non_missing\n):\n    # Checks categorical splits are correct when the MIN_CAT_SUPPORT constraint\n    # isn't respected: there are no splits\n\n    n_bins = max(X_binned) + 1\n    n_samples = len(X_binned)\n    X_binned = np.array([X_binned], dtype=X_BINNED_DTYPE).T\n    X_binned = np.asfortranarray(X_binned)\n\n    l2_regularization = 0.0\n    min_hessian_to_split = 1e-3\n    min_samples_leaf = 1\n    min_gain_to_split = 0.0\n\n    sample_indices = np.arange(n_samples, dtype=np.uint32)\n    all_gradients = np.ones(n_samples, dtype=G_H_DTYPE)\n    has_missing_values = np.array([has_missing_values], dtype=np.uint8)\n    all_hessians = np.ones(1, dtype=G_H_DTYPE)\n    sum_gradients = all_gradients.sum()\n    sum_hessians = n_samples\n    hessians_are_constant = True\n\n    builder = HistogramBuilder(\n        X_binned, n_bins, all_gradients, all_hessians, hessians_are_constant, n_threads\n    )\n\n    n_bins_non_missing = np.array([n_bins_non_missing], dtype=np.uint32)\n    monotonic_cst = np.array(\n        [MonotonicConstraint.NO_CST] * X_binned.shape[1], dtype=np.int8\n    )\n    is_categorical = np.ones_like(monotonic_cst, dtype=np.uint8)\n    missing_values_bin_idx = n_bins - 1\n\n    splitter = Splitter(\n        X_binned,\n        n_bins_non_missing,\n        missing_values_bin_idx,\n        has_missing_values,\n        is_categorical,\n        monotonic_cst,\n        l2_regularization,\n        min_hessian_to_split,\n        min_samples_leaf,\n        min_gain_to_split,\n        hessians_are_constant,\n    )\n\n    histograms = builder.compute_histograms_brute(sample_indices)\n    value = compute_node_value(\n        sum_gradients, sum_hessians, -np.inf, np.inf, l2_regularization\n    )\n    split_info = splitter.find_node_split(\n        n_samples, histograms, sum_gradients, sum_hessians, value\n    )\n\n    # no split found\n    assert split_info.gain == -1\n", "type": "function"}, {"name": "test_split_indices", "is_method": false, "class_name": null, "parameters": [], "calls": ["np.random.RandomState", "np.asfortranarray", "np.arange", "astype", "np.ones", "all_gradients.sum", "HistogramBuilder", "np.array", "np.array", "np.array", "np.zeros_like", "Splitter", "np.all", "builder.compute_histograms_brute", "compute_node_value", "splitter.find_node_split", "splitter.split_indices", "set", "set", "set", "set", "list", "list", "list", "list", "rng.randn"], "code_location": {"file": "test_splitting.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/ensemble/_hist_gradient_boosting/tests", "start_line": 242, "end_line": 325}, "code_snippet": "def test_split_indices():\n    # Check that split_indices returns the correct splits and that\n    # splitter.partition is consistent with what is returned.\n    rng = np.random.RandomState(421)\n\n    n_bins = 5\n    n_samples = 10\n    l2_regularization = 0.0\n    min_hessian_to_split = 1e-3\n    min_samples_leaf = 1\n    min_gain_to_split = 0.0\n\n    # split will happen on feature 1 and on bin 3\n    X_binned = [\n        [0, 0],\n        [0, 3],\n        [0, 4],\n        [0, 0],\n        [0, 0],\n        [0, 0],\n        [0, 0],\n        [0, 4],\n        [0, 0],\n        [0, 4],\n    ]\n    X_binned = np.asfortranarray(X_binned, dtype=X_BINNED_DTYPE)\n    sample_indices = np.arange(n_samples, dtype=np.uint32)\n    all_gradients = rng.randn(n_samples).astype(G_H_DTYPE)\n    all_hessians = np.ones(1, dtype=G_H_DTYPE)\n    sum_gradients = all_gradients.sum()\n    sum_hessians = 1 * n_samples\n    hessians_are_constant = True\n\n    builder = HistogramBuilder(\n        X_binned, n_bins, all_gradients, all_hessians, hessians_are_constant, n_threads\n    )\n    n_bins_non_missing = np.array([n_bins] * X_binned.shape[1], dtype=np.uint32)\n    has_missing_values = np.array([False] * X_binned.shape[1], dtype=np.uint8)\n    monotonic_cst = np.array(\n        [MonotonicConstraint.NO_CST] * X_binned.shape[1], dtype=np.int8\n    )\n    is_categorical = np.zeros_like(monotonic_cst, dtype=np.uint8)\n    missing_values_bin_idx = n_bins - 1\n    splitter = Splitter(\n        X_binned,\n        n_bins_non_missing,\n        missing_values_bin_idx,\n        has_missing_values,\n        is_categorical,\n        monotonic_cst,\n        l2_regularization,\n        min_hessian_to_split,\n        min_samples_leaf,\n        min_gain_to_split,\n        hessians_are_constant,\n    )\n\n    assert np.all(sample_indices == splitter.partition)\n\n    histograms = builder.compute_histograms_brute(sample_indices)\n    value = compute_node_value(\n        sum_gradients, sum_hessians, -np.inf, np.inf, l2_regularization\n    )\n    si_root = splitter.find_node_split(\n        n_samples, histograms, sum_gradients, sum_hessians, value\n    )\n\n    # sanity checks for best split\n    assert si_root.feature_idx == 1\n    assert si_root.bin_idx == 3\n\n    samples_left, samples_right, position_right = splitter.split_indices(\n        si_root, splitter.partition\n    )\n    assert set(samples_left) == set([0, 1, 3, 4, 5, 6, 8])\n    assert set(samples_right) == set([2, 7, 9])\n\n    assert list(samples_left) == list(splitter.partition[:position_right])\n    assert list(samples_right) == list(splitter.partition[position_right:])\n\n    # Check that the resulting split indices sizes are consistent with the\n    # count statistics anticipated when looking for the best split.\n    assert samples_left.shape[0] == si_root.n_samples_left\n    assert samples_right.shape[0] == si_root.n_samples_right\n", "type": "function"}, {"name": "test_grow_tree_categories", "is_method": false, "class_name": null, "parameters": [], "calls": ["np.asfortranarray", "np.array", "np.ones", "np.ones", "TreeGrower", "grower.grow", "grower.make_predictor", "assert_array_equal", "assert_array_equal", "predictor.predict_binned", "assert_allclose", "np.zeros", "np.array", "predictor.predict", "assert_allclose", "np.array", "np.array", "astype", "np.array", "np.asarray"], "code_location": {"file": "test_grower.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/ensemble/_hist_gradient_boosting/tests", "start_line": 442, "end_line": 509}, "code_snippet": "def test_grow_tree_categories():\n    # Check that the grower produces the right predictor tree when a split is\n    # categorical\n    X_binned = np.array([[0, 1] * 11 + [1]], dtype=X_BINNED_DTYPE).T\n    X_binned = np.asfortranarray(X_binned)\n\n    all_gradients = np.array([10, 1] * 11 + [1], dtype=G_H_DTYPE)\n    all_hessians = np.ones(1, dtype=G_H_DTYPE)\n    is_categorical = np.ones(1, dtype=np.uint8)\n\n    grower = TreeGrower(\n        X_binned,\n        all_gradients,\n        all_hessians,\n        n_bins=4,\n        shrinkage=1.0,\n        min_samples_leaf=1,\n        is_categorical=is_categorical,\n        n_threads=n_threads,\n    )\n    grower.grow()\n    assert grower.n_nodes == 3\n\n    categories = [np.array([4, 9], dtype=X_DTYPE)]\n    predictor = grower.make_predictor(binning_thresholds=categories)\n    root = predictor.nodes[0]\n    assert root[\"count\"] == 23\n    assert root[\"depth\"] == 0\n    assert root[\"is_categorical\"]\n\n    left, right = predictor.nodes[root[\"left\"]], predictor.nodes[root[\"right\"]]\n\n    # arbitrary validation, but this means ones go to the left.\n    assert left[\"count\"] >= right[\"count\"]\n\n    # check binned category value (1)\n    expected_binned_cat_bitset = [2**1] + [0] * 7\n    binned_cat_bitset = predictor.binned_left_cat_bitsets\n    assert_array_equal(binned_cat_bitset[0], expected_binned_cat_bitset)\n\n    # check raw category value (9)\n    expected_raw_cat_bitsets = [2**9] + [0] * 7\n    raw_cat_bitsets = predictor.raw_left_cat_bitsets\n    assert_array_equal(raw_cat_bitsets[0], expected_raw_cat_bitsets)\n\n    # Note that since there was no missing values during training, the missing\n    # values aren't part of the bitsets. However, we expect the missing values\n    # to go to the biggest child (i.e. the left one).\n    # The left child has a value of -1 = negative gradient.\n    assert root[\"missing_go_to_left\"]\n\n    # make sure binned missing values are mapped to the left child during\n    # prediction\n    prediction_binned = predictor.predict_binned(\n        np.asarray([[6]]).astype(X_BINNED_DTYPE),\n        missing_values_bin_idx=6,\n        n_threads=n_threads,\n    )\n    assert_allclose(prediction_binned, [-1])  # negative gradient\n\n    # make sure raw missing values are mapped to the left child during\n    # prediction\n    known_cat_bitsets = np.zeros((1, 8), dtype=np.uint32)  # ignored anyway\n    f_idx_map = np.array([0], dtype=np.uint32)\n    prediction = predictor.predict(\n        np.array([[np.nan]]), known_cat_bitsets, f_idx_map, n_threads\n    )\n    assert_allclose(prediction, [-1])\n", "type": "function"}, {"name": "test_min_gain_to_split", "is_method": false, "class_name": null, "parameters": [], "calls": ["np.random.RandomState", "np.asfortranarray", "np.arange", "np.ones_like", "np.ones_like", "all_gradients.sum", "all_hessians.sum", "HistogramBuilder", "np.array", "np.array", "np.array", "np.zeros_like", "Splitter", "builder.compute_histograms_brute", "compute_node_value", "splitter.find_node_split", "rng.randint"], "code_location": {"file": "test_splitting.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/ensemble/_hist_gradient_boosting/tests", "start_line": 328, "end_line": 382}, "code_snippet": "def test_min_gain_to_split():\n    # Try to split a pure node (all gradients are equal, same for hessians)\n    # with min_gain_to_split = 0 and make sure that the node is not split (best\n    # possible gain = -1). Note: before the strict inequality comparison, this\n    # test would fail because the node would be split with a gain of 0.\n    rng = np.random.RandomState(42)\n    l2_regularization = 0\n    min_hessian_to_split = 0\n    min_samples_leaf = 1\n    min_gain_to_split = 0.0\n    n_bins = 255\n    n_samples = 100\n    X_binned = np.asfortranarray(\n        rng.randint(0, n_bins, size=(n_samples, 1)), dtype=X_BINNED_DTYPE\n    )\n    binned_feature = X_binned[:, 0]\n    sample_indices = np.arange(n_samples, dtype=np.uint32)\n    all_hessians = np.ones_like(binned_feature, dtype=G_H_DTYPE)\n    all_gradients = np.ones_like(binned_feature, dtype=G_H_DTYPE)\n    sum_gradients = all_gradients.sum()\n    sum_hessians = all_hessians.sum()\n    hessians_are_constant = False\n\n    builder = HistogramBuilder(\n        X_binned, n_bins, all_gradients, all_hessians, hessians_are_constant, n_threads\n    )\n    n_bins_non_missing = np.array([n_bins - 1] * X_binned.shape[1], dtype=np.uint32)\n    has_missing_values = np.array([False] * X_binned.shape[1], dtype=np.uint8)\n    monotonic_cst = np.array(\n        [MonotonicConstraint.NO_CST] * X_binned.shape[1], dtype=np.int8\n    )\n    is_categorical = np.zeros_like(monotonic_cst, dtype=np.uint8)\n    missing_values_bin_idx = n_bins - 1\n    splitter = Splitter(\n        X_binned,\n        n_bins_non_missing,\n        missing_values_bin_idx,\n        has_missing_values,\n        is_categorical,\n        monotonic_cst,\n        l2_regularization,\n        min_hessian_to_split,\n        min_samples_leaf,\n        min_gain_to_split,\n        hessians_are_constant,\n    )\n\n    histograms = builder.compute_histograms_brute(sample_indices)\n    value = compute_node_value(\n        sum_gradients, sum_hessians, -np.inf, np.inf, l2_regularization\n    )\n    split_info = splitter.find_node_split(\n        n_samples, histograms, sum_gradients, sum_hessians, value\n    )\n    assert split_info.gain == -1\n", "type": "function"}, {"name": "test_histogram_split", "is_method": false, "class_name": null, "parameters": ["n_bins"], "calls": ["pytest.mark.parametrize", "np.random.RandomState", "np.asfortranarray", "np.arange", "np.ones_like", "all_hessians.sum", "range", "rng.randint", "np.full_like", "all_gradients.sum", "HistogramBuilder", "np.array", "np.array", "np.array", "np.zeros_like", "Splitter", "builder.compute_histograms_brute", "compute_node_value", "splitter.find_node_split", "int"], "code_location": {"file": "test_splitting.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/ensemble/_hist_gradient_boosting/tests", "start_line": 23, "end_line": 94}, "code_snippet": "def test_histogram_split(n_bins):\n    rng = np.random.RandomState(42)\n    feature_idx = 0\n    l2_regularization = 0\n    min_hessian_to_split = 1e-3\n    min_samples_leaf = 1\n    min_gain_to_split = 0.0\n    X_binned = np.asfortranarray(\n        rng.randint(0, n_bins - 1, size=(int(1e4), 1)), dtype=X_BINNED_DTYPE\n    )\n    binned_feature = X_binned.T[feature_idx]\n    sample_indices = np.arange(binned_feature.shape[0], dtype=np.uint32)\n    ordered_hessians = np.ones_like(binned_feature, dtype=G_H_DTYPE)\n    all_hessians = ordered_hessians\n    sum_hessians = all_hessians.sum()\n    hessians_are_constant = False\n\n    for true_bin in range(1, n_bins - 2):\n        for sign in [-1, 1]:\n            ordered_gradients = np.full_like(binned_feature, sign, dtype=G_H_DTYPE)\n            ordered_gradients[binned_feature <= true_bin] *= -1\n            all_gradients = ordered_gradients\n            sum_gradients = all_gradients.sum()\n\n            builder = HistogramBuilder(\n                X_binned,\n                n_bins,\n                all_gradients,\n                all_hessians,\n                hessians_are_constant,\n                n_threads,\n            )\n            n_bins_non_missing = np.array(\n                [n_bins - 1] * X_binned.shape[1], dtype=np.uint32\n            )\n            has_missing_values = np.array([False] * X_binned.shape[1], dtype=np.uint8)\n            monotonic_cst = np.array(\n                [MonotonicConstraint.NO_CST] * X_binned.shape[1], dtype=np.int8\n            )\n            is_categorical = np.zeros_like(monotonic_cst, dtype=np.uint8)\n            missing_values_bin_idx = n_bins - 1\n            splitter = Splitter(\n                X_binned,\n                n_bins_non_missing,\n                missing_values_bin_idx,\n                has_missing_values,\n                is_categorical,\n                monotonic_cst,\n                l2_regularization,\n                min_hessian_to_split,\n                min_samples_leaf,\n                min_gain_to_split,\n                hessians_are_constant,\n            )\n\n            histograms = builder.compute_histograms_brute(sample_indices)\n            value = compute_node_value(\n                sum_gradients, sum_hessians, -np.inf, np.inf, l2_regularization\n            )\n            split_info = splitter.find_node_split(\n                sample_indices.shape[0], histograms, sum_gradients, sum_hessians, value\n            )\n\n            assert split_info.bin_idx == true_bin\n            assert split_info.gain >= 0\n            assert split_info.feature_idx == feature_idx\n            assert (\n                split_info.n_samples_left + split_info.n_samples_right\n                == sample_indices.shape[0]\n            )\n            # Constant hessian: 1. per sample.\n            assert split_info.n_samples_left == split_info.sum_hessian_left\n", "type": "function"}, {"name": "test_missing_values_best_splitter_to_right", "is_method": false, "class_name": null, "parameters": ["criterion"], "calls": ["pytest.mark.parametrize", "np.array", "DecisionTreeClassifier", "dtc.fit", "dtc.predict", "assert_array_equal", "np.array", "np.array"], "code_location": {"file": "test_tree.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/tree/tests", "start_line": 2456, "end_line": 2469}, "code_snippet": "def test_missing_values_best_splitter_to_right(criterion):\n    \"\"\"Missing values and non-missing values sharing one class at fit-time\n    must make missing values at predict-time be classified has belonging\n    to this class.\"\"\"\n    X = np.array([[np.nan] * 4 + [0, 1, 2, 3, 4, 5]]).T\n    y = np.array([1] * 4 + [0] * 4 + [1] * 2)\n\n    dtc = DecisionTreeClassifier(random_state=42, max_depth=2, criterion=criterion)\n    dtc.fit(X, y)\n\n    X_test = np.array([[np.nan, 1.2, 4.8]]).T\n    y_pred = dtc.predict(X_test)\n\n    assert_array_equal(y_pred, [1, 0, 1])\n", "type": "function"}, {"name": "test_unknown_categories_nan", "is_method": false, "class_name": null, "parameters": ["insert_missing", "Est", "bool_categorical_parameter", "missing_value"], "calls": ["pytest.mark.parametrize", "pytest.mark.parametrize", "pytest.mark.parametrize", "pytest.mark.parametrize", "np.random.RandomState", "rng.rand", "rng.randint", "np.zeros", "fit", "assert_array_equal", "np.zeros", "astype", "len", "mask.sum", "Est", "np.unique", "rng.binomial", "est.predict"], "code_location": {"file": "test_gradient_boosting.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/ensemble/_hist_gradient_boosting/tests", "start_line": 1022, "end_line": 1054}, "code_snippet": "def test_unknown_categories_nan(\n    insert_missing, Est, bool_categorical_parameter, missing_value\n):\n    # Make sure no error is raised at predict if a category wasn't seen during\n    # fit. We also make sure they're treated as nans.\n\n    rng = np.random.RandomState(0)\n    n_samples = 1000\n    f1 = rng.rand(n_samples)\n    f2 = rng.randint(4, size=n_samples)\n    X = np.c_[f1, f2]\n    y = np.zeros(shape=n_samples)\n    y[X[:, 1] % 2 == 0] = 1\n\n    if bool_categorical_parameter:\n        categorical_features = [False, True]\n    else:\n        categorical_features = [1]\n\n    if insert_missing:\n        mask = rng.binomial(1, 0.01, size=X.shape).astype(bool)\n        assert mask.sum() > 0\n        X[mask] = missing_value\n\n    est = Est(max_iter=20, categorical_features=categorical_features).fit(X, y)\n    assert_array_equal(est.is_categorical_, [False, True])\n\n    # Make sure no error is raised on unknown categories and nans\n    # unknown categories will be treated as nans\n    X_test = np.zeros((10, X.shape[1]), dtype=float)\n    X_test[:5, 1] = 30\n    X_test[5:, 1] = missing_value\n    assert len(np.unique(est.predict(X_test))) == 1\n", "type": "function"}, {"name": "test_categorical_feature", "is_method": false, "class_name": null, "parameters": ["n_bins"], "calls": ["pytest.mark.parametrize", "fit", "assert_array_equal", "assert_array_equal", "assert_array_equal", "np.array", "np.unique", "np.array", "np.array", "bin_mapper.transform", "np.array", "np.array", "bin_mapper.transform", "_BinMapper", "np.isnan", "np.array"], "code_location": {"file": "test_binning.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/ensemble/_hist_gradient_boosting/tests", "start_line": 341, "end_line": 369}, "code_snippet": "def test_categorical_feature(n_bins):\n    # Basic test for categorical features\n    # we make sure that categories are mapped into [0, n_categories - 1] and\n    # that nans are mapped to the last bin\n    X = np.array(\n        [[4] * 500 + [1] * 3 + [10] * 4 + [0] * 4 + [13] + [7] * 5 + [np.nan] * 2],\n        dtype=X_DTYPE,\n    ).T\n    known_categories = [np.unique(X[~np.isnan(X)])]\n\n    bin_mapper = _BinMapper(\n        n_bins=n_bins,\n        is_categorical=np.array([True]),\n        known_categories=known_categories,\n    ).fit(X)\n    assert bin_mapper.n_bins_non_missing_ == [6]\n    assert_array_equal(bin_mapper.bin_thresholds_[0], [0, 1, 4, 7, 10, 13])\n\n    X = np.array([[0, 1, 4, np.nan, 7, 10, 13]], dtype=X_DTYPE).T\n    expected_trans = np.array([[0, 1, 2, n_bins - 1, 3, 4, 5]]).T\n    assert_array_equal(bin_mapper.transform(X), expected_trans)\n\n    # Negative categories are mapped to the missing values' bin\n    # (i.e. the bin of index `missing_values_bin_idx_ == n_bins - 1).\n    # Unknown positive categories does not happen in practice and tested\n    # for illustration purpose.\n    X = np.array([[-4, -1, 100]], dtype=X_DTYPE).T\n    expected_trans = np.array([[n_bins - 1, n_bins - 1, 6]]).T\n    assert_array_equal(bin_mapper.transform(X), expected_trans)\n", "type": "function"}], "retrieved_count": 10, "cost_time": 1.170954704284668}
{"question": "Why does the warm_start mechanism in _posterior_mode() reduce computational overhead during hyperparameter optimization, and what performance trade-offs occur when caching the latent function values across multiple log_marginal_likelihood evaluations?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"name": "_posterior_mode", "is_method": true, "class_name": "_BinaryGaussianProcessClassifierLaplace", "parameters": ["self", "K", "return_temporaries"], "calls": ["range", "hasattr", "np.zeros_like", "expit", "np.sqrt", "cholesky", "K.dot", "np.eye", "sum", "cho_solve", "sum", "W_sr_K.dot", "a.T.dot", "np.log", "np.log1p", "np.diag", "np.exp"], "code_location": {"file": "_gpc.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/gaussian_process", "start_line": 443, "end_line": 499}, "code_snippet": "    def _posterior_mode(self, K, return_temporaries=False):\n        \"\"\"Mode-finding for binary Laplace GPC and fixed kernel.\n\n        This approximates the posterior of the latent function values for given\n        inputs and target observations with a Gaussian approximation and uses\n        Newton's iteration to find the mode of this approximation.\n        \"\"\"\n        # Based on Algorithm 3.1 of GPML\n\n        # If warm_start are enabled, we reuse the last solution for the\n        # posterior mode as initialization; otherwise, we initialize with 0\n        if (\n            self.warm_start\n            and hasattr(self, \"f_cached\")\n            and self.f_cached.shape == self.y_train_.shape\n        ):\n            f = self.f_cached\n        else:\n            f = np.zeros_like(self.y_train_, dtype=np.float64)\n\n        # Use Newton's iteration method to find mode of Laplace approximation\n        log_marginal_likelihood = -np.inf\n        for _ in range(self.max_iter_predict):\n            # Line 4\n            pi = expit(f)\n            W = pi * (1 - pi)\n            # Line 5\n            W_sr = np.sqrt(W)\n            W_sr_K = W_sr[:, np.newaxis] * K\n            B = np.eye(W.shape[0]) + W_sr_K * W_sr\n            L = cholesky(B, lower=True)\n            # Line 6\n            b = W * f + (self.y_train_ - pi)\n            # Line 7\n            a = b - W_sr * cho_solve((L, True), W_sr_K.dot(b))\n            # Line 8\n            f = K.dot(a)\n\n            # Line 10: Compute log marginal likelihood in loop and use as\n            #          convergence criterion\n            lml = (\n                -0.5 * a.T.dot(f)\n                - np.log1p(np.exp(-(self.y_train_ * 2 - 1) * f)).sum()\n                - np.log(np.diag(L)).sum()\n            )\n            # Check if we have converged (log marginal likelihood does\n            # not decrease)\n            # XXX: more complex convergence criterion\n            if lml - log_marginal_likelihood < 1e-10:\n                break\n            log_marginal_likelihood = lml\n\n        self.f_cached = f  # Remember solution for later warm-starts\n        if return_temporaries:\n            return log_marginal_likelihood, (pi, W_sr, L, b, a)\n        else:\n            return log_marginal_likelihood\n", "type": "function"}, {"name": "test_learning_rate_warmstart", "is_method": false, "class_name": null, "parameters": [], "calls": ["MLPClassifier", "ignore_warnings", "mlp.fit", "mlp.fit", "pow"], "code_location": {"file": "test_mlp.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/neural_network/tests", "start_line": 339, "end_line": 361}, "code_snippet": "def test_learning_rate_warmstart():\n    # Tests that warm_start reuse past solutions.\n    X = [[3, 2], [1, 6], [5, 6], [-2, -4]]\n    y = [1, 1, 1, 0]\n    for learning_rate in [\"invscaling\", \"constant\"]:\n        mlp = MLPClassifier(\n            solver=\"sgd\",\n            hidden_layer_sizes=4,\n            learning_rate=learning_rate,\n            max_iter=1,\n            power_t=0.25,\n            warm_start=True,\n        )\n        with ignore_warnings(category=ConvergenceWarning):\n            mlp.fit(X, y)\n            prev_eta = mlp._optimizer.learning_rate\n            mlp.fit(X, y)\n            post_eta = mlp._optimizer.learning_rate\n\n        if learning_rate == \"constant\":\n            assert prev_eta == post_eta\n        elif learning_rate == \"invscaling\":\n            assert mlp.learning_rate_init / pow(8 + 1, mlp.power_t) == post_eta\n", "type": "function"}, {"name": "test_lml_precomputed", "is_method": false, "class_name": null, "parameters": ["kernel"], "calls": ["pytest.mark.parametrize", "fit", "gpr.log_marginal_likelihood", "pytest.approx", "GaussianProcessRegressor", "gpr.log_marginal_likelihood"], "code_location": {"file": "test_gpr.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/gaussian_process/tests", "start_line": 97, "end_line": 102}, "code_snippet": "def test_lml_precomputed(kernel):\n    # Test that lml of optimized kernel is stored correctly.\n    gpr = GaussianProcessRegressor(kernel=kernel).fit(X, y)\n    assert gpr.log_marginal_likelihood(gpr.kernel_.theta) == pytest.approx(\n        gpr.log_marginal_likelihood()\n    )\n", "type": "function"}, {"name": "test_lml_precomputed", "is_method": false, "class_name": null, "parameters": ["kernel"], "calls": ["pytest.mark.parametrize", "fit", "assert_almost_equal", "gpc.log_marginal_likelihood", "gpc.log_marginal_likelihood", "GaussianProcessClassifier"], "code_location": {"file": "test_gpc.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/gaussian_process/tests", "start_line": 76, "end_line": 81}, "code_snippet": "def test_lml_precomputed(kernel):\n    # Test that lml of optimized kernel is stored correctly.\n    gpc = GaussianProcessClassifier(kernel=kernel).fit(X, y)\n    assert_almost_equal(\n        gpc.log_marginal_likelihood(gpc.kernel_.theta), gpc.log_marginal_likelihood(), 7\n    )\n", "type": "function"}, {"name": "log_marginal_likelihood", "is_method": true, "class_name": "_BinaryGaussianProcessClassifierLaplace", "parameters": ["self", "theta", "eval_gradient", "clone_kernel"], "calls": ["self._posterior_mode", "np.empty", "solve", "range", "self.kernel_.clone_with_theta", "kernel", "kernel", "cho_solve", "C.dot", "ValueError", "np.diag", "K.dot", "s_2.T.dot", "np.diag", "np.einsum", "dot", "dot", "R.dot", "C.ravel", "a.T.dot", "R.T.ravel"], "code_location": {"file": "_gpc.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/gaussian_process", "start_line": 331, "end_line": 408}, "code_snippet": "    def log_marginal_likelihood(\n        self, theta=None, eval_gradient=False, clone_kernel=True\n    ):\n        \"\"\"Returns log-marginal likelihood of theta for training data.\n\n        Parameters\n        ----------\n        theta : array-like of shape (n_kernel_params,), default=None\n            Kernel hyperparameters for which the log-marginal likelihood is\n            evaluated. If None, the precomputed log_marginal_likelihood\n            of ``self.kernel_.theta`` is returned.\n\n        eval_gradient : bool, default=False\n            If True, the gradient of the log-marginal likelihood with respect\n            to the kernel hyperparameters at position theta is returned\n            additionally. If True, theta must not be None.\n\n        clone_kernel : bool, default=True\n            If True, the kernel attribute is copied. If False, the kernel\n            attribute is modified, but may result in a performance improvement.\n\n        Returns\n        -------\n        log_likelihood : float\n            Log-marginal likelihood of theta for training data.\n\n        log_likelihood_gradient : ndarray of shape (n_kernel_params,), \\\n                optional\n            Gradient of the log-marginal likelihood with respect to the kernel\n            hyperparameters at position theta.\n            Only returned when `eval_gradient` is True.\n        \"\"\"\n        if theta is None:\n            if eval_gradient:\n                raise ValueError(\"Gradient can only be evaluated for theta!=None\")\n            return self.log_marginal_likelihood_value_\n\n        if clone_kernel:\n            kernel = self.kernel_.clone_with_theta(theta)\n        else:\n            kernel = self.kernel_\n            kernel.theta = theta\n\n        if eval_gradient:\n            K, K_gradient = kernel(self.X_train_, eval_gradient=True)\n        else:\n            K = kernel(self.X_train_)\n\n        # Compute log-marginal-likelihood Z and also store some temporaries\n        # which can be reused for computing Z's gradient\n        Z, (pi, W_sr, L, b, a) = self._posterior_mode(K, return_temporaries=True)\n\n        if not eval_gradient:\n            return Z\n\n        # Compute gradient based on Algorithm 5.1 of GPML\n        d_Z = np.empty(theta.shape[0])\n        # XXX: Get rid of the np.diag() in the next line\n        R = W_sr[:, np.newaxis] * cho_solve((L, True), np.diag(W_sr))  # Line 7\n        C = solve(L, W_sr[:, np.newaxis] * K)  # Line 8\n        # Line 9: (use einsum to compute np.diag(C.T.dot(C))))\n        s_2 = (\n            -0.5\n            * (np.diag(K) - np.einsum(\"ij, ij -> j\", C, C))\n            * (pi * (1 - pi) * (1 - 2 * pi))\n        )  # third derivative\n\n        for j in range(d_Z.shape[0]):\n            C = K_gradient[:, :, j]  # Line 11\n            # Line 12: (R.T.ravel().dot(C.ravel()) = np.trace(R.dot(C)))\n            s_1 = 0.5 * a.T.dot(C).dot(a) - 0.5 * R.T.ravel().dot(C.ravel())\n\n            b = C.dot(self.y_train_ - pi)  # Line 13\n            s_3 = b - K.dot(R.dot(b))  # Line 14\n\n            d_Z[j] = s_1 + s_2.T.dot(s_3)  # Line 15\n\n        return Z, d_Z\n", "type": "function"}, {"name": "test_warm_start", "is_method": false, "class_name": null, "parameters": ["seed"], "calls": ["pytest.mark.filterwarnings", "pytest.mark.parametrize", "np.random.RandomState", "rng.rand", "GaussianMixture", "GaussianMixture", "g.fit", "score", "score", "assert_almost_equal", "assert_almost_equal", "assert_almost_equal", "GaussianMixture", "GaussianMixture", "g.fit", "h.fit", "range", "h.fit", "h.fit", "h.fit"], "code_location": {"file": "test_gaussian_mixture.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/mixture/tests", "start_line": 852, "end_line": 916}, "code_snippet": "def test_warm_start(seed):\n    random_state = seed\n    rng = np.random.RandomState(random_state)\n    n_samples, n_features, n_components = 500, 2, 2\n    X = rng.rand(n_samples, n_features)\n\n    # Assert the warm_start give the same result for the same number of iter\n    g = GaussianMixture(\n        n_components=n_components,\n        n_init=1,\n        max_iter=2,\n        reg_covar=0,\n        random_state=random_state,\n        warm_start=False,\n    )\n    h = GaussianMixture(\n        n_components=n_components,\n        n_init=1,\n        max_iter=1,\n        reg_covar=0,\n        random_state=random_state,\n        warm_start=True,\n    )\n\n    g.fit(X)\n    score1 = h.fit(X).score(X)\n    score2 = h.fit(X).score(X)\n\n    assert_almost_equal(g.weights_, h.weights_)\n    assert_almost_equal(g.means_, h.means_)\n    assert_almost_equal(g.precisions_, h.precisions_)\n    assert score2 > score1\n\n    # Assert that by using warm_start we can converge to a good solution\n    g = GaussianMixture(\n        n_components=n_components,\n        n_init=1,\n        max_iter=5,\n        reg_covar=0,\n        random_state=random_state,\n        warm_start=False,\n        tol=1e-6,\n    )\n    h = GaussianMixture(\n        n_components=n_components,\n        n_init=1,\n        max_iter=5,\n        reg_covar=0,\n        random_state=random_state,\n        warm_start=True,\n        tol=1e-6,\n    )\n\n    g.fit(X)\n    assert not g.converged_\n\n    h.fit(X)\n    # depending on the data there is large variability in the number of\n    # refit necessary to converge due to the complete randomness of the\n    # data\n    for _ in range(1000):\n        h.fit(X)\n        if h.converged_:\n            break\n    assert h.converged_\n", "type": "function"}, {"name": "test_random_starts", "is_method": false, "class_name": null, "parameters": ["global_random_seed"], "calls": ["np.random.RandomState", "range", "C", "RBF", "fit", "gp.log_marginal_likelihood", "rng.randn", "sum", "sum", "GaussianProcessClassifier", "np.sin", "np.sin", "np.finfo"], "code_location": {"file": "test_gpc.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/gaussian_process/tests", "start_line": 121, "end_line": 141}, "code_snippet": "def test_random_starts(global_random_seed):\n    # Test that an increasing number of random-starts of GP fitting only\n    # increases the log marginal likelihood of the chosen theta.\n    n_samples, n_features = 25, 2\n    rng = np.random.RandomState(global_random_seed)\n    X = rng.randn(n_samples, n_features) * 2 - 1\n    y = (np.sin(X).sum(axis=1) + np.sin(3 * X).sum(axis=1)) > 0\n\n    kernel = C(1.0, (1e-2, 1e2)) * RBF(\n        length_scale=[1e-3] * n_features, length_scale_bounds=[(1e-4, 1e2)] * n_features\n    )\n    last_lml = -np.inf\n    for n_restarts_optimizer in range(5):\n        gp = GaussianProcessClassifier(\n            kernel=kernel,\n            n_restarts_optimizer=n_restarts_optimizer,\n            random_state=global_random_seed,\n        ).fit(X, y)\n        lml = gp.log_marginal_likelihood(gp.kernel_.theta)\n        assert lml > last_lml - np.finfo(np.float32).eps\n        last_lml = lml\n", "type": "function"}, {"name": "__init__", "is_method": true, "class_name": "_BinaryGaussianProcessClassifierLaplace", "parameters": ["self", "kernel"], "calls": [], "code_location": {"file": "_gpc.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/gaussian_process", "start_line": 152, "end_line": 169}, "code_snippet": "    def __init__(\n        self,\n        kernel=None,\n        *,\n        optimizer=\"fmin_l_bfgs_b\",\n        n_restarts_optimizer=0,\n        max_iter_predict=100,\n        warm_start=False,\n        copy_X_train=True,\n        random_state=None,\n    ):\n        self.kernel = kernel\n        self.optimizer = optimizer\n        self.n_restarts_optimizer = n_restarts_optimizer\n        self.max_iter_predict = max_iter_predict\n        self.warm_start = warm_start\n        self.copy_X_train = copy_X_train\n        self.random_state = random_state\n", "type": "function"}, {"name": "test_random_starts", "is_method": false, "class_name": null, "parameters": [], "calls": ["np.random.RandomState", "range", "rng.normal", "WhiteKernel", "fit", "gp.log_marginal_likelihood", "rng.randn", "sum", "sum", "C", "RBF", "GaussianProcessRegressor", "np.sin", "np.sin", "np.finfo"], "code_location": {"file": "test_gpr.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/gaussian_process/tests", "start_line": 223, "end_line": 247}, "code_snippet": "def test_random_starts():\n    # Test that an increasing number of random-starts of GP fitting only\n    # increases the log marginal likelihood of the chosen theta.\n    n_samples, n_features = 25, 2\n    rng = np.random.RandomState(0)\n    X = rng.randn(n_samples, n_features) * 2 - 1\n    y = (\n        np.sin(X).sum(axis=1)\n        + np.sin(3 * X).sum(axis=1)\n        + rng.normal(scale=0.1, size=n_samples)\n    )\n\n    kernel = C(1.0, (1e-2, 1e2)) * RBF(\n        length_scale=[1.0] * n_features, length_scale_bounds=[(1e-4, 1e2)] * n_features\n    ) + WhiteKernel(noise_level=1e-5, noise_level_bounds=(1e-5, 1e1))\n    last_lml = -np.inf\n    for n_restarts_optimizer in range(5):\n        gp = GaussianProcessRegressor(\n            kernel=kernel,\n            n_restarts_optimizer=n_restarts_optimizer,\n            random_state=0,\n        ).fit(X, y)\n        lml = gp.log_marginal_likelihood(gp.kernel_.theta)\n        assert lml > last_lml - np.finfo(np.float32).eps\n        last_lml = lml\n", "type": "function"}, {"name": "test_lml_improving", "is_method": false, "class_name": null, "parameters": ["kernel"], "calls": ["pytest.mark.parametrize", "fit", "pytest.xfail", "gpr.log_marginal_likelihood", "gpr.log_marginal_likelihood", "GaussianProcessRegressor"], "code_location": {"file": "test_gpr.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/gaussian_process/tests", "start_line": 85, "end_line": 93}, "code_snippet": "def test_lml_improving(kernel):\n    if sys.maxsize <= 2**32:\n        pytest.xfail(\"This test may fail on 32 bit Python\")\n\n    # Test that hyperparameter-tuning improves log-marginal likelihood.\n    gpr = GaussianProcessRegressor(kernel=kernel).fit(X, y)\n    assert gpr.log_marginal_likelihood(gpr.kernel_.theta) > gpr.log_marginal_likelihood(\n        kernel.theta\n    )\n", "type": "function"}], "retrieved_count": 10, "cost_time": 1.1566603183746338}
{"question": "Why does the Normalizer class's __sklearn_tags__ method set requires_fit to False despite inheriting from TransformerMixin, and how does this design choice reflect the fundamental algorithmic nature of row normalization?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"name": "test_normalizer_l1_l2_max_non_csr", "is_method": false, "class_name": null, "parameters": ["norm", "sparse_container"], "calls": ["pytest.mark.parametrize", "pytest.mark.parametrize", "np.random.RandomState", "rng.randn", "sparse_container", "transform", "toarray", "check_normalizer", "sparse.issparse", "Normalizer"], "code_location": {"file": "test_data.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/preprocessing/tests", "start_line": 1872, "end_line": 1886}, "code_snippet": "def test_normalizer_l1_l2_max_non_csr(norm, sparse_container):\n    rng = np.random.RandomState(0)\n    X_dense = rng.randn(4, 5)\n\n    # set the row number 3 to zero\n    X_dense[3, :] = 0.0\n\n    X = sparse_container(X_dense)\n    X_norm = Normalizer(norm=norm, copy=False).transform(X)\n\n    assert X_norm is not X\n    assert sparse.issparse(X_norm) and X_norm.format == \"csr\"\n\n    X_norm = toarray(X_norm)\n    check_normalizer(norm, X_norm)\n", "type": "function"}, {"name": "__sklearn_tags__", "is_method": true, "class_name": "TfidfTransformer", "parameters": ["self"], "calls": ["__sklearn_tags__", "super"], "code_location": {"file": "text.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/feature_extraction", "start_line": 1735, "end_line": 1741}, "code_snippet": "    def __sklearn_tags__(self):\n        tags = super().__sklearn_tags__()\n        tags.input_tags.sparse = True\n        # FIXME: np.float16 could be preserved if _inplace_csr_row_normalize_l2\n        # accepted it.\n        tags.transformer_tags.preserves_dtype = [\"float64\", \"float32\"]\n        return tags\n", "type": "function"}, {"name": "__sklearn_tags__", "is_method": true, "class_name": "GaussianProcessRegressor", "parameters": ["self"], "calls": ["__sklearn_tags__", "super"], "code_location": {"file": "_gpr.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/gaussian_process", "start_line": 679, "end_line": 682}, "code_snippet": "    def __sklearn_tags__(self):\n        tags = super().__sklearn_tags__()\n        tags.requires_fit = False\n        return tags\n", "type": "function"}, {"name": "__sklearn_tags__", "is_method": true, "class_name": "SparseCoder", "parameters": ["self"], "calls": ["__sklearn_tags__", "super"], "code_location": {"file": "_dict_learning.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/decomposition", "start_line": 1386, "end_line": 1390}, "code_snippet": "    def __sklearn_tags__(self):\n        tags = super().__sklearn_tags__()\n        tags.requires_fit = False\n        tags.transformer_tags.preserves_dtype = [\"float64\", \"float32\"]\n        return tags\n", "type": "function"}, {"name": "test_normalizer_l1_l2_max", "is_method": false, "class_name": null, "parameters": ["norm", "csr_container"], "calls": ["pytest.mark.parametrize", "pytest.mark.parametrize", "np.random.RandomState", "rng.randn", "csr_container", "csr_container", "Normalizer", "normalizer.transform", "toarray", "Normalizer", "normalizer.transform", "toarray", "check_normalizer"], "code_location": {"file": "test_data.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/preprocessing/tests", "start_line": 1836, "end_line": 1865}, "code_snippet": "def test_normalizer_l1_l2_max(norm, csr_container):\n    rng = np.random.RandomState(0)\n    X_dense = rng.randn(4, 5)\n    X_sparse_unpruned = csr_container(X_dense)\n\n    # set the row number 3 to zero\n    X_dense[3, :] = 0.0\n\n    # set the row number 3 to zero without pruning (can happen in real life)\n    indptr_3 = X_sparse_unpruned.indptr[3]\n    indptr_4 = X_sparse_unpruned.indptr[4]\n    X_sparse_unpruned.data[indptr_3:indptr_4] = 0.0\n\n    # build the pruned variant using the regular constructor\n    X_sparse_pruned = csr_container(X_dense)\n\n    # check inputs that support the no-copy optim\n    for X in (X_dense, X_sparse_pruned, X_sparse_unpruned):\n        normalizer = Normalizer(norm=norm, copy=True)\n        X_norm1 = normalizer.transform(X)\n        assert X_norm1 is not X\n        X_norm1 = toarray(X_norm1)\n\n        normalizer = Normalizer(norm=norm, copy=False)\n        X_norm2 = normalizer.transform(X)\n        assert X_norm2 is X\n        X_norm2 = toarray(X_norm2)\n\n        for X_norm in (X_norm1, X_norm2):\n            check_normalizer(norm, X_norm)\n", "type": "function"}, {"name": "test_normalize", "is_method": false, "class_name": null, "parameters": ["csr_container"], "calls": ["pytest.mark.parametrize", "randn", "assert_array_equal", "np.random.RandomState", "rs.randn", "csr_container", "np.ones", "np.array", "csr_container", "normalize", "assert_array_almost_equal", "normalize", "normalize", "np.array", "np.random.RandomState", "normalize", "assert_array_almost_equal", "pytest.raises", "normalize", "X.astype", "normalize", "toarray", "assert_array_almost_equal", "np.array", "assert_array_almost_equal", "assert_array_almost_equal", "sum", "X_norm_squared.sum", "np.array", "np.array", "np.abs"], "code_location": {"file": "test_data.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/preprocessing/tests", "start_line": 1911, "end_line": 1953}, "code_snippet": "def test_normalize(csr_container):\n    # Test normalize function\n    # Only tests functionality not used by the tests for Normalizer.\n    X = np.random.RandomState(37).randn(3, 2)\n    assert_array_equal(normalize(X, copy=False), normalize(X.T, axis=0, copy=False).T)\n\n    rs = np.random.RandomState(0)\n    X_dense = rs.randn(10, 5)\n    X_sparse = csr_container(X_dense)\n    ones = np.ones((10))\n    for X in (X_dense, X_sparse):\n        for dtype in (np.float32, np.float64):\n            for norm in (\"l1\", \"l2\"):\n                X = X.astype(dtype)\n                X_norm = normalize(X, norm=norm)\n                assert X_norm.dtype == dtype\n\n                X_norm = toarray(X_norm)\n                if norm == \"l1\":\n                    row_sums = np.abs(X_norm).sum(axis=1)\n                else:\n                    X_norm_squared = X_norm**2\n                    row_sums = X_norm_squared.sum(axis=1)\n\n                assert_array_almost_equal(row_sums, ones)\n\n    # Test return_norm\n    X_dense = np.array([[3.0, 0, 4.0], [1.0, 0.0, 0.0], [2.0, 3.0, 0.0]])\n    for norm in (\"l1\", \"l2\", \"max\"):\n        _, norms = normalize(X_dense, norm=norm, return_norm=True)\n        if norm == \"l1\":\n            assert_array_almost_equal(norms, np.array([7.0, 1.0, 5.0]))\n        elif norm == \"l2\":\n            assert_array_almost_equal(norms, np.array([5.0, 1.0, 3.60555127]))\n        else:\n            assert_array_almost_equal(norms, np.array([4.0, 1.0, 3.0]))\n\n    X_sparse = csr_container(X_dense)\n    for norm in (\"l1\", \"l2\"):\n        with pytest.raises(NotImplementedError):\n            normalize(X_sparse, norm=norm, return_norm=True)\n    _, norms = normalize(X_sparse, norm=\"max\", return_norm=True)\n    assert_array_almost_equal(norms, np.array([4.0, 1.0, 3.0]))\n", "type": "function"}, {"name": "__sklearn_tags__", "is_method": true, "class_name": "Binarizer", "parameters": ["self"], "calls": ["__sklearn_tags__", "super"], "code_location": {"file": "_data.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/preprocessing", "start_line": 2404, "end_line": 2409}, "code_snippet": "    def __sklearn_tags__(self):\n        tags = super().__sklearn_tags__()\n        tags.requires_fit = False\n        tags.array_api_support = True\n        tags.input_tags.sparse = True\n        return tags\n", "type": "function"}, {"name": "__sklearn_tags__", "is_method": true, "class_name": "AdditiveChi2Sampler", "parameters": ["self"], "calls": ["__sklearn_tags__", "super"], "code_location": {"file": "kernel_approximation.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn", "start_line": 835, "end_line": 840}, "code_snippet": "    def __sklearn_tags__(self):\n        tags = super().__sklearn_tags__()\n        tags.requires_fit = False\n        tags.input_tags.positive_only = True\n        tags.input_tags.sparse = True\n        return tags\n", "type": "function"}, {"name": "__sklearn_tags__", "is_method": true, "class_name": "Normalizer", "parameters": ["self"], "calls": ["__sklearn_tags__", "super"], "code_location": {"file": "_data.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/preprocessing", "start_line": 2195, "end_line": 2200}, "code_snippet": "    def __sklearn_tags__(self):\n        tags = super().__sklearn_tags__()\n        tags.input_tags.sparse = True\n        tags.requires_fit = False\n        tags.array_api_support = True\n        return tags\n", "type": "function"}, {"name": "__sklearn_tags__", "is_method": true, "class_name": "ColumnTransformer", "parameters": ["self"], "calls": ["__sklearn_tags__", "all", "super", "get_tags"], "code_location": {"file": "_column_transformer.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/compose", "start_line": 1320, "end_line": 1333}, "code_snippet": "    def __sklearn_tags__(self):\n        tags = super().__sklearn_tags__()\n        try:\n            tags.input_tags.sparse = all(\n                get_tags(trans).input_tags.sparse\n                for name, trans, _ in self.transformers\n                if trans not in {\"passthrough\", \"drop\"}\n            )\n        except Exception:\n            # If `transformers` does not comply with our API (list of tuples)\n            # then it will fail. In this case, we assume that `sparse` is False\n            # but the parameter validation will raise an error during `fit`.\n            pass  # pragma: no cover\n        return tags\n", "type": "function"}], "retrieved_count": 10, "cost_time": 1.1610798835754395}
{"question": "Why does the SplineTransformer add degree number of knots both before and after the base knots during the fit process, and why does the periodic extrapolation mode require a fundamentally different knot extension strategy?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"name": "periodic_spline_transformer", "is_method": false, "class_name": null, "parameters": ["period", "n_splines", "degree"], "calls": ["SplineTransformer", "reshape", "np.linspace"], "code_location": {"file": "plot_cyclical_feature_engineering.py", "path": "/data3/pwh/swebench-repos/scikit-learn/examples/applications", "start_line": 427, "end_line": 437}, "code_snippet": "def periodic_spline_transformer(period, n_splines=None, degree=3):\n    if n_splines is None:\n        n_splines = period\n    n_knots = n_splines + 1  # periodic and include_bias is True\n    return SplineTransformer(\n        degree=degree,\n        n_knots=n_knots,\n        knots=np.linspace(0, period, n_knots).reshape(n_knots, 1),\n        extrapolation=\"periodic\",\n        include_bias=True,\n    )\n", "type": "function"}, {"name": "SplineTransformer", "docstring": "Generate univariate B-spline bases for features.\n\nGenerate a new feature matrix consisting of\n`n_splines=n_knots + degree - 1` (`n_knots - 1` for\n`extrapolation=\"periodic\"`) spline basis functions\n(B-splines) of polynomial order=`degree` for each feature.\n\nIn order to learn more about the SplineTransformer class go to:\n:ref:`sphx_glr_auto_examples_applications_plot_cyclical_feature_engineering.py`\n\nRead more in the :ref:`User Guide <spline_transformer>`.\n\n.. versionadded:: 1.0\n\nParameters\n----------\nn_knots : int, default=5\n    Number of knots of the splines if `knots` equals one of\n    {'uniform', 'quantile'}. Must be larger or equal 2. Ignored if `knots`\n    is array-like.\n\ndegree : int, default=3\n    The polynomial degree of the spline basis. Must be a non-negative\n    integer.\n\nknots : {'uniform', 'quantile'} or array-like of shape         (n_knots, n_features), default='uniform'\n    Set knot positions such that first knot <= features <= last knot.\n\n    - If 'uniform', `n_knots` number of knots are distributed uniformly\n      from min to max values of the features.\n    - If 'quantile', they are distributed uniformly along the quantiles of\n      the features.\n    - If an array-like is given, it directly specifies the sorted knot\n      positions including the boundary knots. Note that, internally,\n      `degree` number of knots are added before the first knot, the same\n      after the last knot.\n\nextrapolation : {'error', 'constant', 'linear', 'continue', 'periodic'},         default='constant'\n    If 'error', values outside the min and max values of the training\n    features raises a `ValueError`. If 'constant', the value of the\n    splines at minimum and maximum value of the features is used as\n    constant extrapolation. If 'linear', a linear extrapolation is used.\n    If 'continue', the splines are extrapolated as is, i.e. option\n    `extrapolate=True` in :class:`scipy.interpolate.BSpline`. If\n    'periodic', periodic splines with a periodicity equal to the distance\n    between the first and last knot are used. Periodic splines enforce\n    equal function values and derivatives at the first and last knot.\n    For example, this makes it possible to avoid introducing an arbitrary\n    jump between Dec 31st and Jan 1st in spline features derived from a\n    naturally periodic \"day-of-year\" input feature. In this case it is\n    recommended to manually set the knot values to control the period.\n\ninclude_bias : bool, default=True\n    If False, then the last spline element inside the data range\n    of a feature is dropped. As B-splines sum to one over the spline basis\n    functions for each data point, they implicitly include a bias term,\n    i.e. a column of ones. It acts as an intercept term in a linear models.\n\norder : {'C', 'F'}, default='C'\n    Order of output array in the dense case. `'F'` order is faster to compute, but\n    may slow down subsequent estimators.\n\nhandle_missing : {'error', 'zeros'}, default='error'\n    Specifies the way missing values are handled.\n\n    - 'error' : Raise an error if `np.nan` values are present during :meth:`fit`.\n    - 'zeros' : Encode splines of missing values with values `0`.\n\n    Note that `handle_missing='zeros'` differs from first imputing missing values\n    with zeros and then creating the spline basis. The latter creates spline basis\n    functions which have non-zero values at the missing values\n    whereas this option simply sets all spline basis function values to zero at the\n    missing values.\n\n    .. versionadded:: 1.8\n\nsparse_output : bool, default=False\n    Will return sparse CSR matrix if set True else will return an array.\n\n    .. versionadded:: 1.2\n\nAttributes\n----------\nbsplines_ : list of shape (n_features,)\n    List of BSplines objects, one for each feature.\n\nn_features_in_ : int\n    The total number of input features.\n\nfeature_names_in_ : ndarray of shape (`n_features_in_`,)\n    Names of features seen during :term:`fit`. Defined only when `X`\n    has feature names that are all strings.\n\n    .. versionadded:: 1.0\n\nn_features_out_ : int\n    The total number of output features, which is computed as\n    `n_features * n_splines`, where `n_splines` is\n    the number of bases elements of the B-splines,\n    `n_knots + degree - 1` for non-periodic splines and\n    `n_knots - 1` for periodic ones.\n    If `include_bias=False`, then it is only\n    `n_features * (n_splines - 1)`.\n\nSee Also\n--------\nKBinsDiscretizer : Transformer that bins continuous data into intervals.\n\nPolynomialFeatures : Transformer that generates polynomial and interaction\n    features.\n\nNotes\n-----\nHigh degrees and a high number of knots can cause overfitting.\n\nSee :ref:`examples/linear_model/plot_polynomial_interpolation.py\n<sphx_glr_auto_examples_linear_model_plot_polynomial_interpolation.py>`.\n\nExamples\n--------\n>>> import numpy as np\n>>> from sklearn.preprocessing import SplineTransformer\n>>> X = np.arange(6).reshape(6, 1)\n>>> spline = SplineTransformer(degree=2, n_knots=3)\n>>> spline.fit_transform(X)\narray([[0.5 , 0.5 , 0.  , 0.  ],\n       [0.18, 0.74, 0.08, 0.  ],\n       [0.02, 0.66, 0.32, 0.  ],\n       [0.  , 0.32, 0.66, 0.02],\n       [0.  , 0.08, 0.74, 0.18],\n       [0.  , 0.  , 0.5 , 0.5 ]])", "methods": ["__init__", "_get_base_knot_positions", "get_feature_names_out", "fit", "transform", "__sklearn_tags__"], "attributes": [], "code_location": {"file": "_polynomial.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/preprocessing", "start_line": 603, "end_line": 1314}, "type": "class"}, {"name": "test_spline_transformer_periodic_splines_smoothness", "is_method": false, "class_name": null, "parameters": ["degree"], "calls": ["pytest.mark.parametrize", "SplineTransformer", "transformer.fit_transform", "range", "np.diff", "np.linspace", "len", "np.diff", "max", "X.max", "X.min", "max", "np.abs", "np.abs"], "code_location": {"file": "test_polynomial.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/preprocessing/tests", "start_line": 296, "end_line": 331}, "code_snippet": "def test_spline_transformer_periodic_splines_smoothness(degree):\n    \"\"\"Test that spline transformation is smooth at first / last knot.\"\"\"\n    X = np.linspace(-2, 10, 10_000)[:, None]\n\n    transformer = SplineTransformer(\n        degree=degree,\n        extrapolation=\"periodic\",\n        knots=[[0.0], [1.0], [3.0], [4.0], [5.0], [8.0]],\n    )\n    Xt = transformer.fit_transform(X)\n\n    delta = (X.max() - X.min()) / len(X)\n    tol = 10 * delta\n\n    dXt = Xt\n    # We expect splines of degree `degree` to be (`degree`-1) times\n    # continuously differentiable. I.e. for d = 0, ..., `degree` - 1 the d-th\n    # derivative should be continuous. This is the case if the (d+1)-th\n    # numerical derivative is reasonably small (smaller than `tol` in absolute\n    # value). We thus compute d-th numeric derivatives for d = 1, ..., `degree`\n    # and compare them to `tol`.\n    #\n    # Note that the 0-th derivative is the function itself, such that we are\n    # also checking its continuity.\n    for d in range(1, degree + 1):\n        # Check continuity of the (d-1)-th derivative\n        diff = np.diff(dXt, axis=0)\n        assert np.abs(diff).max() < tol\n        # Compute d-th numeric derivative\n        dXt = diff / delta\n\n    # As degree `degree` splines are not `degree` times continuously\n    # differentiable at the knots, the `degree + 1`-th numeric derivative\n    # should have spikes at the knots.\n    diff = np.diff(dXt, axis=0)\n    assert np.abs(diff).max() > 1\n", "type": "function"}, {"name": "__init__", "is_method": true, "class_name": "SplineTransformer", "parameters": ["self", "n_knots", "degree"], "calls": [], "code_location": {"file": "_polynomial.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/preprocessing", "start_line": 752, "end_line": 771}, "code_snippet": "    def __init__(\n        self,\n        n_knots=5,\n        degree=3,\n        *,\n        knots=\"uniform\",\n        extrapolation=\"constant\",\n        include_bias=True,\n        order=\"C\",\n        handle_missing=\"error\",\n        sparse_output=False,\n    ):\n        self.n_knots = n_knots\n        self.degree = degree\n        self.knots = knots\n        self.extrapolation = extrapolation\n        self.include_bias = include_bias\n        self.order = order\n        self.handle_missing = handle_missing\n        self.sparse_output = sparse_output\n", "type": "function"}, {"name": "test_spline_transformer_periodic_spline_backport", "is_method": false, "class_name": null, "parameters": [], "calls": ["SplineTransformer", "transformer.fit_transform", "np.array", "BSpline", "spl", "assert_allclose", "np.linspace", "np.arange"], "code_location": {"file": "test_polynomial.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/preprocessing/tests", "start_line": 255, "end_line": 270}, "code_snippet": "def test_spline_transformer_periodic_spline_backport():\n    \"\"\"Test that the backport of extrapolate=\"periodic\" works correctly\"\"\"\n    X = np.linspace(-2, 3.5, 10)[:, None]\n    degree = 2\n\n    # Use periodic extrapolation backport in SplineTransformer\n    transformer = SplineTransformer(\n        degree=degree, extrapolation=\"periodic\", knots=[[-1.0], [0.0], [1.0]]\n    )\n    Xt = transformer.fit_transform(X)\n\n    # Use periodic extrapolation in BSpline\n    coef = np.array([[1.0, 0.0], [0.0, 1.0], [1.0, 0.0], [0.0, 1.0]])\n    spl = BSpline(np.arange(-3, 4), coef, degree, \"periodic\")\n    Xspl = spl(X[:, 0])\n    assert_allclose(Xt, Xspl)\n", "type": "function"}, {"name": "test_spline_transformer_extrapolation", "is_method": false, "class_name": null, "parameters": ["bias", "intercept", "degree"], "calls": ["pytest.mark.parametrize", "pytest.mark.parametrize", "X.squeeze", "Pipeline", "pipe.fit", "assert_allclose", "Pipeline", "pipe.fit", "assert_allclose", "SplineTransformer", "splt.fit", "np.linspace", "pipe.predict", "pipe.predict", "pytest.raises", "splt.transform", "pytest.raises", "splt.transform", "SplineTransformer", "LinearRegression", "SplineTransformer", "LinearRegression"], "code_location": {"file": "test_polynomial.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/preprocessing/tests", "start_line": 336, "end_line": 387}, "code_snippet": "def test_spline_transformer_extrapolation(bias, intercept, degree):\n    \"\"\"Test that B-spline extrapolation works correctly.\"\"\"\n    # we use a straight line for that\n    X = np.linspace(-1, 1, 100)[:, None]\n    y = X.squeeze()\n\n    # 'constant'\n    pipe = Pipeline(\n        [\n            [\n                \"spline\",\n                SplineTransformer(\n                    n_knots=4,\n                    degree=degree,\n                    include_bias=bias,\n                    extrapolation=\"constant\",\n                ),\n            ],\n            [\"ols\", LinearRegression(fit_intercept=intercept)],\n        ]\n    )\n    pipe.fit(X, y)\n    assert_allclose(pipe.predict([[-10], [5]]), [-1, 1])\n\n    # 'linear'\n    pipe = Pipeline(\n        [\n            [\n                \"spline\",\n                SplineTransformer(\n                    n_knots=4,\n                    degree=degree,\n                    include_bias=bias,\n                    extrapolation=\"linear\",\n                ),\n            ],\n            [\"ols\", LinearRegression(fit_intercept=intercept)],\n        ]\n    )\n    pipe.fit(X, y)\n    assert_allclose(pipe.predict([[-10], [5]]), [-10, 5])\n\n    # 'error'\n    splt = SplineTransformer(\n        n_knots=4, degree=degree, include_bias=bias, extrapolation=\"error\"\n    )\n    splt.fit(X)\n    msg = \"`X` contains values beyond the limits of the knots\"\n    with pytest.raises(ValueError, match=msg):\n        splt.transform([[-10]])\n    with pytest.raises(ValueError, match=msg):\n        splt.transform([[5]])\n", "type": "function"}, {"name": "test_spline_transformer_periodic_linear_regression", "is_method": false, "class_name": null, "parameters": ["bias", "intercept"], "calls": ["pytest.mark.parametrize", "Pipeline", "pipe.fit", "pipe.predict", "assert_allclose", "assert_allclose", "np.linspace", "f", "np.linspace", "f", "np.sin", "np.sin", "SplineTransformer", "LinearRegression"], "code_location": {"file": "test_polynomial.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/preprocessing/tests", "start_line": 224, "end_line": 252}, "code_snippet": "def test_spline_transformer_periodic_linear_regression(bias, intercept):\n    \"\"\"Test that B-splines fit a periodic curve pretty well.\"\"\"\n\n    # \"+ 3\" to avoid the value 0 in assert_allclose\n    def f(x):\n        return np.sin(2 * np.pi * x) - np.sin(8 * np.pi * x) + 3\n\n    X = np.linspace(0, 1, 101)[:, None]\n    pipe = Pipeline(\n        steps=[\n            (\n                \"spline\",\n                SplineTransformer(\n                    n_knots=20,\n                    degree=3,\n                    include_bias=bias,\n                    extrapolation=\"periodic\",\n                ),\n            ),\n            (\"ols\", LinearRegression(fit_intercept=intercept)),\n        ]\n    )\n    pipe.fit(X, f(X[:, 0]))\n\n    # Generate larger array to check periodic extrapolation\n    X_ = np.linspace(-1, 2, 301)[:, None]\n    predictions = pipe.predict(X_)\n    assert_allclose(predictions, f(X_[:, 0]), atol=0.01, rtol=0.01)\n    assert_allclose(predictions[0:100], predictions[100:200], rtol=1e-3)\n", "type": "function"}, {"name": "test_spline_transformer_handles_missing_values", "is_method": false, "class_name": null, "parameters": ["extrapolation", "sparse_output"], "calls": ["pytest.mark.parametrize", "pytest.mark.parametrize", "np.array", "X.copy", "SplineTransformer", "spline.fit_transform", "transform", "assert_allclose_dense_sparse", "spline.fit_transform", "assert_allclose_dense_sparse", "transform", "assert_allclose_dense_sparse", "_get_mask", "np.repeat", "all", "spline.fit_transform", "sparse.issparse", "all", "all", "spline.fit_transform", "spline.fit_transform", "assert_allclose_dense_sparse", "pytest.raises", "SplineTransformer", "spline.fit_transform", "spline.fit_transform", "X_nan_transform.toarray", "spline.fit", "spline.fit", "re.escape"], "code_location": {"file": "test_polynomial.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/preprocessing/tests", "start_line": 497, "end_line": 567}, "code_snippet": "def test_spline_transformer_handles_missing_values(extrapolation, sparse_output):\n    \"\"\"Test that SplineTransformer handles missing values correctly.\n    We only test for knots=\"uniform\", since for \"quantile\" the metrics are calculated\n    differently with nans present and a different result is thus expected.\n    \"\"\"\n    X = np.array([[1, 1], [2, 2], [3, 3], [4, 5], [4, 4]], dtype=np.float64)\n    X_nan = X.copy()\n    X_nan[3, 0] = np.nan\n\n    # Check correct error message for handle_missing=\"error\":\n    msg = \"Input X contains NaN values and `SplineTransformer` is configured to error\"\n    with pytest.raises(ValueError, match=re.escape(msg)):\n        spline = SplineTransformer(\n            degree=2,\n            n_knots=3,\n            handle_missing=\"error\",\n            extrapolation=extrapolation,\n        )\n        spline.fit_transform(X_nan)\n\n    # Test correct results for handle_missing=\"zeros\"\n    spline = SplineTransformer(\n        degree=2,\n        n_knots=3,\n        handle_missing=\"zeros\",\n        extrapolation=extrapolation,\n        sparse_output=sparse_output,\n    )\n\n    # Check `fit_transform` does the same as `fit` and then `transform`:\n    X_nan_transform = spline.fit_transform(X_nan)\n    X_nan_fit_then_transform = spline.fit(X_nan).transform(X_nan)\n    assert_allclose_dense_sparse(X_nan_transform, X_nan_fit_then_transform)\n\n    # Check that missing values are handled the same when sample_weight is passed:\n    X_nan_transform_with_sample_weight = spline.fit_transform(\n        X_nan, sample_weight=[1, 1, 1, 1, 1]\n    )\n    assert_allclose_dense_sparse(X_nan_transform, X_nan_transform_with_sample_weight)\n\n    # Check that `transform` works as expected when the passed data has a different\n    # shape than the training data passed to `fit`:\n    X_nan_transform_same_shape = spline.fit_transform(X_nan)[::2]\n    X_nan_transform_different_shapes = spline.fit(X_nan).transform(X_nan[::2])\n    assert_allclose_dense_sparse(\n        X_nan_transform_same_shape, X_nan_transform_different_shapes\n    )\n\n    # Check that the masked nan-values are 0s:\n    nan_mask = _get_mask(X_nan, np.nan)\n    encoded_nan_mask = np.repeat(nan_mask, spline.bsplines_[0].c.shape[1], axis=1)\n    assert (X_nan_transform[encoded_nan_mask] == 0).all()\n\n    # Check the nan handling doesn't change that B-Splines basis functions are always in\n    # the interval [0, 1]:\n    X_nan_transform = spline.fit_transform(X_nan)\n    if sparse.issparse(X_nan_transform):\n        X_nan_transform = X_nan_transform.toarray()\n    assert (X_nan_transform >= 0).all()\n    assert (X_nan_transform <= 1).all()\n\n    # Check that additional nan values don't change the calculation of the other\n    # splines. Note: this assertion only holds as long as no np.nan value constructs the\n    # min or max value of the data space (in this case, SplineTransformer's stats would\n    # be calculated based on the other values and thus differ from another\n    # SplineTransformer fit on the whole range).\n    X_transform = spline.fit_transform(X)\n    X_nan_transform = spline.fit_transform(X_nan)\n    assert_allclose_dense_sparse(\n        X_transform[~encoded_nan_mask], X_nan_transform[~encoded_nan_mask]\n    )\n", "type": "function"}, {"name": "test_spline_transformer_unity_decomposition", "is_method": false, "class_name": null, "parameters": ["degree", "n_knots", "knots", "extrapolation"], "calls": ["pytest.mark.parametrize", "pytest.mark.parametrize", "pytest.mark.parametrize", "pytest.mark.parametrize", "SplineTransformer", "splt.fit", "range", "range", "np.linspace", "assert_allclose", "np.sum", "splt.transform"], "code_location": {"file": "test_polynomial.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/preprocessing/tests", "start_line": 144, "end_line": 166}, "code_snippet": "def test_spline_transformer_unity_decomposition(degree, n_knots, knots, extrapolation):\n    \"\"\"Test that B-splines are indeed a decomposition of unity.\n\n    Splines basis functions must sum up to 1 per row, if we stay in between boundaries.\n    \"\"\"\n    X = np.linspace(0, 1, 100)[:, None]\n    # make the boundaries 0 and 1 part of X_train, for sure.\n    X_train = np.r_[[[0]], X[::2, :], [[1]]]\n    X_test = X[1::2, :]\n\n    if extrapolation == \"periodic\":\n        n_knots = n_knots + degree  # periodic splines require degree < n_knots\n\n    splt = SplineTransformer(\n        n_knots=n_knots,\n        degree=degree,\n        knots=knots,\n        include_bias=True,\n        extrapolation=extrapolation,\n    )\n    splt.fit(X_train)\n    for X in [X_train, X_test]:\n        assert_allclose(np.sum(splt.transform(X), axis=1), 1)\n", "type": "function"}, {"name": "test_spline_transformer_periodic_splines_periodicity", "is_method": false, "class_name": null, "parameters": [], "calls": ["SplineTransformer", "SplineTransformer", "transformer_1.fit_transform", "transformer_2.fit_transform", "assert_allclose", "np.linspace"], "code_location": {"file": "test_polynomial.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/preprocessing/tests", "start_line": 273, "end_line": 292}, "code_snippet": "def test_spline_transformer_periodic_splines_periodicity():\n    \"\"\"Test if shifted knots result in the same transformation up to permutation.\"\"\"\n    X = np.linspace(0, 10, 101)[:, None]\n\n    transformer_1 = SplineTransformer(\n        degree=3,\n        extrapolation=\"periodic\",\n        knots=[[0.0], [1.0], [3.0], [4.0], [5.0], [8.0]],\n    )\n\n    transformer_2 = SplineTransformer(\n        degree=3,\n        extrapolation=\"periodic\",\n        knots=[[1.0], [3.0], [4.0], [5.0], [8.0], [9.0]],\n    )\n\n    Xt_1 = transformer_1.fit_transform(X)\n    Xt_2 = transformer_2.fit_transform(X)\n\n    assert_allclose(Xt_1, Xt_2[:, [4, 0, 1, 2, 3]])\n", "type": "function"}], "retrieved_count": 10, "cost_time": 1.2285680770874023}
{"question": "Why does the SplineTransformer use a diagonal coefficient matrix during fit, and how does this design choice enable the generation of the spline basis functions?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"name": "SplineTransformer", "docstring": "Generate univariate B-spline bases for features.\n\nGenerate a new feature matrix consisting of\n`n_splines=n_knots + degree - 1` (`n_knots - 1` for\n`extrapolation=\"periodic\"`) spline basis functions\n(B-splines) of polynomial order=`degree` for each feature.\n\nIn order to learn more about the SplineTransformer class go to:\n:ref:`sphx_glr_auto_examples_applications_plot_cyclical_feature_engineering.py`\n\nRead more in the :ref:`User Guide <spline_transformer>`.\n\n.. versionadded:: 1.0\n\nParameters\n----------\nn_knots : int, default=5\n    Number of knots of the splines if `knots` equals one of\n    {'uniform', 'quantile'}. Must be larger or equal 2. Ignored if `knots`\n    is array-like.\n\ndegree : int, default=3\n    The polynomial degree of the spline basis. Must be a non-negative\n    integer.\n\nknots : {'uniform', 'quantile'} or array-like of shape         (n_knots, n_features), default='uniform'\n    Set knot positions such that first knot <= features <= last knot.\n\n    - If 'uniform', `n_knots` number of knots are distributed uniformly\n      from min to max values of the features.\n    - If 'quantile', they are distributed uniformly along the quantiles of\n      the features.\n    - If an array-like is given, it directly specifies the sorted knot\n      positions including the boundary knots. Note that, internally,\n      `degree` number of knots are added before the first knot, the same\n      after the last knot.\n\nextrapolation : {'error', 'constant', 'linear', 'continue', 'periodic'},         default='constant'\n    If 'error', values outside the min and max values of the training\n    features raises a `ValueError`. If 'constant', the value of the\n    splines at minimum and maximum value of the features is used as\n    constant extrapolation. If 'linear', a linear extrapolation is used.\n    If 'continue', the splines are extrapolated as is, i.e. option\n    `extrapolate=True` in :class:`scipy.interpolate.BSpline`. If\n    'periodic', periodic splines with a periodicity equal to the distance\n    between the first and last knot are used. Periodic splines enforce\n    equal function values and derivatives at the first and last knot.\n    For example, this makes it possible to avoid introducing an arbitrary\n    jump between Dec 31st and Jan 1st in spline features derived from a\n    naturally periodic \"day-of-year\" input feature. In this case it is\n    recommended to manually set the knot values to control the period.\n\ninclude_bias : bool, default=True\n    If False, then the last spline element inside the data range\n    of a feature is dropped. As B-splines sum to one over the spline basis\n    functions for each data point, they implicitly include a bias term,\n    i.e. a column of ones. It acts as an intercept term in a linear models.\n\norder : {'C', 'F'}, default='C'\n    Order of output array in the dense case. `'F'` order is faster to compute, but\n    may slow down subsequent estimators.\n\nhandle_missing : {'error', 'zeros'}, default='error'\n    Specifies the way missing values are handled.\n\n    - 'error' : Raise an error if `np.nan` values are present during :meth:`fit`.\n    - 'zeros' : Encode splines of missing values with values `0`.\n\n    Note that `handle_missing='zeros'` differs from first imputing missing values\n    with zeros and then creating the spline basis. The latter creates spline basis\n    functions which have non-zero values at the missing values\n    whereas this option simply sets all spline basis function values to zero at the\n    missing values.\n\n    .. versionadded:: 1.8\n\nsparse_output : bool, default=False\n    Will return sparse CSR matrix if set True else will return an array.\n\n    .. versionadded:: 1.2\n\nAttributes\n----------\nbsplines_ : list of shape (n_features,)\n    List of BSplines objects, one for each feature.\n\nn_features_in_ : int\n    The total number of input features.\n\nfeature_names_in_ : ndarray of shape (`n_features_in_`,)\n    Names of features seen during :term:`fit`. Defined only when `X`\n    has feature names that are all strings.\n\n    .. versionadded:: 1.0\n\nn_features_out_ : int\n    The total number of output features, which is computed as\n    `n_features * n_splines`, where `n_splines` is\n    the number of bases elements of the B-splines,\n    `n_knots + degree - 1` for non-periodic splines and\n    `n_knots - 1` for periodic ones.\n    If `include_bias=False`, then it is only\n    `n_features * (n_splines - 1)`.\n\nSee Also\n--------\nKBinsDiscretizer : Transformer that bins continuous data into intervals.\n\nPolynomialFeatures : Transformer that generates polynomial and interaction\n    features.\n\nNotes\n-----\nHigh degrees and a high number of knots can cause overfitting.\n\nSee :ref:`examples/linear_model/plot_polynomial_interpolation.py\n<sphx_glr_auto_examples_linear_model_plot_polynomial_interpolation.py>`.\n\nExamples\n--------\n>>> import numpy as np\n>>> from sklearn.preprocessing import SplineTransformer\n>>> X = np.arange(6).reshape(6, 1)\n>>> spline = SplineTransformer(degree=2, n_knots=3)\n>>> spline.fit_transform(X)\narray([[0.5 , 0.5 , 0.  , 0.  ],\n       [0.18, 0.74, 0.08, 0.  ],\n       [0.02, 0.66, 0.32, 0.  ],\n       [0.  , 0.32, 0.66, 0.02],\n       [0.  , 0.08, 0.74, 0.18],\n       [0.  , 0.  , 0.5 , 0.5 ]])", "methods": ["__init__", "_get_base_knot_positions", "get_feature_names_out", "fit", "transform", "__sklearn_tags__"], "attributes": [], "code_location": {"file": "_polynomial.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/preprocessing", "start_line": 603, "end_line": 1314}, "type": "class"}, {"name": "transform", "is_method": true, "class_name": "SplineTransformer", "parameters": ["self", "X"], "calls": ["check_is_fitted", "validate_data", "range", "parse_version", "dict", "np.zeros", "np.flatnonzero", "sparse.hstack", "_get_mask", "XBS_sparse.tocsr", "output_list.append", "np.iinfo", "ValueError", "sparse.csr_matrix", "BSpline.design_matrix", "spl", "range", "spl", "spl", "copy", "BSpline.design_matrix", "np.any", "spl", "XBS_sparse.tocsr", "np.any", "slice", "np.any", "ValueError", "np.any", "np.any", "parse_version", "range", "np.zeros_like", "np.zeros_like", "XBS_sparse.tolil", "XBS_sparse.tolil", "XBS_sparse.tolil", "np.isnan", "np.isnan", "range", "x.copy", "np.nanmin", "XBS_sparse.tolil", "XBS_sparse.tolil", "spl", "spl", "np.any", "np.any", "XBS_sparse.tolil", "XBS_sparse.tolil"], "code_location": {"file": "_polynomial.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/preprocessing", "start_line": 1001, "end_line": 1309}, "code_snippet": "    def transform(self, X):\n        \"\"\"Transform each feature data to B-splines.\n\n        Parameters\n        ----------\n        X : array-like of shape (n_samples, n_features)\n            The data to transform.\n\n        Returns\n        -------\n        XBS : {ndarray, sparse matrix} of shape (n_samples, n_features * n_splines)\n            The matrix of features, where n_splines is the number of bases\n            elements of the B-splines, n_knots + degree - 1.\n        \"\"\"\n        check_is_fitted(self)\n\n        X = validate_data(\n            self,\n            X,\n            reset=False,\n            accept_sparse=False,\n            ensure_2d=True,\n            ensure_all_finite=(self.handle_missing != \"zeros\"),\n        )\n\n        n_samples, n_features = X.shape\n        n_splines = self.bsplines_[0].c.shape[1]\n        degree = self.degree\n\n        # TODO: Remove this condition, once scipy 1.10 is the minimum version.\n        #       Only scipy >= 1.10 supports design_matrix(.., extrapolate=..).\n        #       The default (implicit in scipy < 1.10) is extrapolate=False.\n        scipy_1_10 = sp_version >= parse_version(\"1.10.0\")\n        # Note: self.bsplines_[0].extrapolate is True for extrapolation in\n        # [\"periodic\", \"continue\"]\n        if scipy_1_10:\n            use_sparse = self.sparse_output\n            kwargs_extrapolate = {\"extrapolate\": self.bsplines_[0].extrapolate}\n        else:\n            use_sparse = self.sparse_output and not self.bsplines_[0].extrapolate\n            kwargs_extrapolate = dict()\n\n        # Note that scipy BSpline returns float64 arrays and converts input\n        # x=X[:, i] to c-contiguous float64.\n        n_out = self.n_features_out_ + n_features * (1 - self.include_bias)\n        if X.dtype in FLOAT_DTYPES:\n            dtype = X.dtype\n        else:\n            dtype = np.float64\n        if use_sparse:\n            output_list = []\n        else:\n            XBS = np.zeros((n_samples, n_out), dtype=dtype, order=self.order)\n\n        for feature_idx in range(n_features):\n            spl = self.bsplines_[feature_idx]\n            # Get indicator for nan values in the current column.\n            nan_row_indices = np.flatnonzero(_get_mask(X[:, feature_idx], np.nan))\n\n            if self.extrapolation in (\"continue\", \"error\", \"periodic\"):\n                if self.extrapolation == \"periodic\":\n                    # With periodic extrapolation we map x to the segment\n                    # [spl.t[k], spl.t[n]].\n                    # This is equivalent to BSpline(.., extrapolate=\"periodic\")\n                    # for scipy>=1.0.0.\n                    n = spl.t.size - spl.k - 1\n                    if spl.t[n] - spl.t[spl.k] > 0:\n                        # Assign to new array to avoid inplace operation\n                        x = spl.t[spl.k] + (X[:, feature_idx] - spl.t[spl.k]) % (\n                            spl.t[n] - spl.t[spl.k]\n                        )\n                    else:\n                        # This can happen if the column has a single non-nan\n                        # value. Treat as a constant feature.\n                        x = np.zeros_like(X[:, feature_idx])\n                else:  # self.extrapolation in (\"continue\", \"error\")\n                    x = X[:, feature_idx]\n\n                if use_sparse:\n                    # We replace the nan values in the input column by some\n                    # arbitrary, in-range, numerical value since\n                    # BSpline.design_matrix() would otherwise raise on any nan\n                    # value in its input. The spline encoded values in\n                    # the output of that function that correspond to missing\n                    # values in the original input will be replaced by 0.0\n                    # afterwards.\n                    #\n                    # Note that in the following we use np.nanmin(x) as the\n                    # input replacement to make sure that this code works even\n                    # when `extrapolation == \"error\"`. Any other choice of\n                    # in-range value would have worked work since the\n                    # corresponding values in the array are replaced by zeros.\n                    if nan_row_indices.size == x.size:\n                        # The column is all np.nan valued. Replace it by a\n                        # constant column with an arbitrary non-nan value\n                        # inside so that it is encoded as constant column.\n                        x = np.zeros_like(x)  # avoid mutation of input data\n                    elif nan_row_indices.shape[0] > 0:\n                        x = x.copy()  # avoid mutation of input data\n                        x[nan_row_indices] = np.nanmin(x)\n                    XBS_sparse = BSpline.design_matrix(\n                        x, spl.t, spl.k, **kwargs_extrapolate\n                    )\n\n                    if self.extrapolation == \"periodic\":\n                        # See the construction of coef in fit. We need to add the last\n                        # degree spline basis function to the first degree ones and\n                        # then drop the last ones.\n                        # Note: See comment about SparseEfficiencyWarning below.\n                        XBS_sparse = XBS_sparse.tolil()\n                        XBS_sparse[:, :degree] += XBS_sparse[:, -degree:]\n                        XBS_sparse = XBS_sparse[:, :-degree]\n\n                    if nan_row_indices.shape[0] > 0:\n                        # Note: See comment about SparseEfficiencyWarning below.\n                        XBS = XBS_sparse.tolil()\n\n                else:\n                    XBS[\n                        :, (feature_idx * n_splines) : ((feature_idx + 1) * n_splines)\n                    ] = spl(x)\n\n                # Replace any indicated values with 0:\n                if nan_row_indices.shape[0] > 0:\n                    for spline_idx in range(n_splines):\n                        output_feature_idx = n_splines * feature_idx + spline_idx\n                        XBS[\n                            nan_row_indices, output_feature_idx : output_feature_idx + 1\n                        ] = 0\n                    if use_sparse:\n                        XBS_sparse = XBS\n\n            else:  # extrapolation in (\"constant\", \"linear\")\n                xmin, xmax = spl.t[degree], spl.t[-degree - 1]\n                # spline values at boundaries\n                f_min, f_max = spl(xmin), spl(xmax)\n                # Values outside of the feature range during fit and nan values get\n                # filtered out:\n                inside_range_mask = (xmin <= X[:, feature_idx]) & (\n                    X[:, feature_idx] <= xmax\n                )\n\n                if use_sparse:\n                    outside_range_mask = ~inside_range_mask\n                    x = X[:, feature_idx].copy()\n                    # Set to some arbitrary value within the range of values\n                    # observed on the training set before calling\n                    # BSpline.design_matrix. Those transformed will be\n                    # reassigned later when handling with extrapolation.\n                    x[outside_range_mask] = xmin\n                    XBS_sparse = BSpline.design_matrix(x, spl.t, spl.k)\n                    # Note: Without converting to lil_matrix we would get:\n                    # scipy.sparse._base.SparseEfficiencyWarning: Changing the sparsity\n                    # structure of a csr_matrix is expensive. lil_matrix is more\n                    # efficient.\n                    if np.any(outside_range_mask):\n                        XBS_sparse = XBS_sparse.tolil()\n                        XBS_sparse[outside_range_mask, :] = 0\n\n                else:\n                    XBS[\n                        inside_range_mask,\n                        (feature_idx * n_splines) : ((feature_idx + 1) * n_splines),\n                    ] = spl(X[inside_range_mask, feature_idx])\n\n            # Note for extrapolation:\n            # 'continue' is already returned as is by scipy BSplines\n            if self.extrapolation == \"error\":\n                has_nan_output_values = False\n                if use_sparse:\n                    # Early convert to CSR as the sparsity structure of this\n                    # block should not change anymore. This is needed to be able\n                    # to safely assume that `.data` is a 1D array.\n                    XBS_sparse = XBS_sparse.tocsr()\n                    has_nan_output_values = np.any(np.isnan(XBS_sparse.data))\n                else:\n                    output_features = slice(\n                        feature_idx * n_splines, (feature_idx + 1) * n_splines\n                    )\n                    has_nan_output_values = np.any(np.isnan(XBS[:, output_features]))\n\n                if has_nan_output_values:\n                    raise ValueError(\n                        \"`X` contains values beyond the limits of the knots.\"\n                    )\n\n            elif self.extrapolation == \"constant\":\n                # Set all values beyond xmin and xmax to the value of the\n                # spline basis functions at those two positions.\n                # Only the first degree and last degree number of splines\n                # have non-zero values at the boundaries.\n\n                below_xmin_mask = X[:, feature_idx] < xmin\n                if np.any(below_xmin_mask):\n                    if use_sparse:\n                        # Note: See comment about SparseEfficiencyWarning above.\n                        XBS_sparse = XBS_sparse.tolil()\n                        XBS_sparse[below_xmin_mask, :degree] = f_min[:degree]\n\n                    else:\n                        XBS[\n                            below_xmin_mask,\n                            (feature_idx * n_splines) : (\n                                feature_idx * n_splines + degree\n                            ),\n                        ] = f_min[:degree]\n\n                above_xmax_mask = X[:, feature_idx] > xmax\n                if np.any(above_xmax_mask):\n                    if use_sparse:\n                        # Note: See comment about SparseEfficiencyWarning above.\n                        XBS_sparse = XBS_sparse.tolil()\n                        XBS_sparse[above_xmax_mask, -degree:] = f_max[-degree:]\n                    else:\n                        XBS[\n                            above_xmax_mask,\n                            ((feature_idx + 1) * n_splines - degree) : (\n                                (feature_idx + 1) * n_splines\n                            ),\n                        ] = f_max[-degree:]\n\n            elif self.extrapolation == \"linear\":\n                # Continue the degree first and degree last spline bases\n                # linearly beyond the boundaries, with slope = derivative at\n                # the boundary.\n                # Note that all others have derivative = value = 0 at the\n                # boundaries.\n\n                # spline derivatives = slopes at boundaries\n                fp_min, fp_max = spl(xmin, nu=1), spl(xmax, nu=1)\n                # Compute the linear continuation.\n                if degree <= 1:\n                    # For degree=1, the derivative of 2nd spline is not zero at\n                    # boundary. For degree=0 it is the same as 'constant'.\n                    degree += 1\n                for j in range(degree):\n                    below_xmin_mask = X[:, feature_idx] < xmin\n                    if np.any(below_xmin_mask):\n                        linear_extr = (\n                            f_min[j]\n                            + (X[below_xmin_mask, feature_idx] - xmin) * fp_min[j]\n                        )\n                        if use_sparse:\n                            # Note: See comment about SparseEfficiencyWarning above.\n                            XBS_sparse = XBS_sparse.tolil()\n                            XBS_sparse[below_xmin_mask, j] = linear_extr\n                        else:\n                            XBS[below_xmin_mask, feature_idx * n_splines + j] = (\n                                linear_extr\n                            )\n\n                    above_xmax_mask = X[:, feature_idx] > xmax\n                    if np.any(above_xmax_mask):\n                        k = n_splines - 1 - j\n                        linear_extr = (\n                            f_max[k]\n                            + (X[above_xmax_mask, feature_idx] - xmax) * fp_max[k]\n                        )\n                        if use_sparse:\n                            # Note: See comment about SparseEfficiencyWarning above.\n                            XBS_sparse = XBS_sparse.tolil()\n                            XBS_sparse[above_xmax_mask, k : k + 1] = linear_extr[\n                                :, None\n                            ]\n                        else:\n                            XBS[above_xmax_mask, feature_idx * n_splines + k] = (\n                                linear_extr\n                            )\n\n            if use_sparse:\n                XBS_sparse = XBS_sparse.tocsr()\n                output_list.append(XBS_sparse)\n\n        if use_sparse:\n            # TODO: Remove this conditional error when the minimum supported version of\n            # SciPy is 1.9.2\n            # `scipy.sparse.hstack` breaks in scipy<1.9.2\n            # when `n_features_out_ > max_int32`\n            max_int32 = np.iinfo(np.int32).max\n            all_int32 = True\n            for mat in output_list:\n                all_int32 &= mat.indices.dtype == np.int32\n            if (\n                sp_version < parse_version(\"1.9.2\")\n                and self.n_features_out_ > max_int32\n                and all_int32\n            ):\n                raise ValueError(\n                    \"In scipy versions `<1.9.2`, the function `scipy.sparse.hstack`\"\n                    \" produces negative columns when:\\n1. The output shape contains\"\n                    \" `n_cols` too large to be represented by a 32bit signed\"\n                    \" integer.\\n. All sub-matrices to be stacked have indices of\"\n                    \" dtype `np.int32`.\\nTo avoid this error, either use a version\"\n                    \" of scipy `>=1.9.2` or alter the `SplineTransformer`\"\n                    \" transformer to produce fewer than 2^31 output features\"\n                )\n            XBS = sparse.hstack(output_list, format=\"csr\")\n        elif self.sparse_output:\n            # TODO: Remove conversion to csr, once scipy 1.10 is the minimum version:\n            # Adjust format of XBS to sparse, for scipy versions < 1.10.0:\n            XBS = sparse.csr_matrix(XBS)\n\n        if self.include_bias:\n            return XBS\n        else:\n            # We throw away one spline basis per feature.\n            # We chose the last one.\n            indices = [j for j in range(XBS.shape[1]) if (j + 1) % n_splines != 0]\n            return XBS[:, indices]\n", "type": "function"}, {"name": "periodic_spline_transformer", "is_method": false, "class_name": null, "parameters": ["period", "n_splines", "degree"], "calls": ["SplineTransformer", "reshape", "np.linspace"], "code_location": {"file": "plot_cyclical_feature_engineering.py", "path": "/data3/pwh/swebench-repos/scikit-learn/examples/applications", "start_line": 427, "end_line": 437}, "code_snippet": "def periodic_spline_transformer(period, n_splines=None, degree=3):\n    if n_splines is None:\n        n_splines = period\n    n_knots = n_splines + 1  # periodic and include_bias is True\n    return SplineTransformer(\n        degree=degree,\n        n_knots=n_knots,\n        knots=np.linspace(0, period, n_knots).reshape(n_knots, 1),\n        extrapolation=\"periodic\",\n        include_bias=True,\n    )\n", "type": "function"}, {"name": "test_spline_transformer_sparse_output", "is_method": false, "class_name": null, "parameters": ["degree", "knots", "extrapolation", "include_bias", "global_random_seed"], "calls": ["pytest.mark.parametrize", "pytest.mark.parametrize", "pytest.mark.parametrize", "pytest.mark.parametrize", "np.random.RandomState", "reshape", "SplineTransformer", "SplineTransformer", "splt_dense.fit", "splt_sparse.fit", "splt_sparse.transform", "splt_dense.transform", "assert_allclose", "np.amin", "np.amax", "range", "sparse.issparse", "X_trans_sparse.toarray", "assert_allclose", "rng.randn", "np.linspace", "np.linspace", "pytest.raises", "splt_dense.transform", "pytest.raises", "splt_sparse.transform", "splt_dense.transform", "toarray", "splt_sparse.transform"], "code_location": {"file": "test_polynomial.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/preprocessing/tests", "start_line": 421, "end_line": 466}, "code_snippet": "def test_spline_transformer_sparse_output(\n    degree, knots, extrapolation, include_bias, global_random_seed\n):\n    rng = np.random.RandomState(global_random_seed)\n    X = rng.randn(200).reshape(40, 5)\n\n    splt_dense = SplineTransformer(\n        degree=degree,\n        knots=knots,\n        extrapolation=extrapolation,\n        include_bias=include_bias,\n        sparse_output=False,\n    )\n    splt_sparse = SplineTransformer(\n        degree=degree,\n        knots=knots,\n        extrapolation=extrapolation,\n        include_bias=include_bias,\n        sparse_output=True,\n    )\n\n    splt_dense.fit(X)\n    splt_sparse.fit(X)\n\n    X_trans_sparse = splt_sparse.transform(X)\n    X_trans_dense = splt_dense.transform(X)\n    assert sparse.issparse(X_trans_sparse) and X_trans_sparse.format == \"csr\"\n    assert_allclose(X_trans_dense, X_trans_sparse.toarray())\n\n    # extrapolation regime\n    X_min = np.amin(X, axis=0)\n    X_max = np.amax(X, axis=0)\n    X_extra = np.r_[\n        np.linspace(X_min - 5, X_min, 10), np.linspace(X_max, X_max + 5, 10)\n    ]\n    if extrapolation == \"error\":\n        msg = \"`X` contains values beyond the limits of the knots\"\n        with pytest.raises(ValueError, match=msg):\n            splt_dense.transform(X_extra)\n        msg = \"Out of bounds\"\n        with pytest.raises(ValueError, match=msg):\n            splt_sparse.transform(X_extra)\n    else:\n        assert_allclose(\n            splt_dense.transform(X_extra), splt_sparse.transform(X_extra).toarray()\n        )\n", "type": "function"}, {"name": "test_spline_transformer_n_features_out", "is_method": false, "class_name": null, "parameters": ["n_knots", "include_bias", "degree", "extrapolation", "sparse_output"], "calls": ["pytest.mark.parametrize", "pytest.mark.parametrize", "pytest.mark.parametrize", "pytest.mark.parametrize", "pytest.mark.parametrize", "SplineTransformer", "splt.fit", "np.linspace", "splt.transform"], "code_location": {"file": "test_polynomial.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/preprocessing/tests", "start_line": 476, "end_line": 490}, "code_snippet": "def test_spline_transformer_n_features_out(\n    n_knots, include_bias, degree, extrapolation, sparse_output\n):\n    \"\"\"Test that transform results in n_features_out_ features.\"\"\"\n    splt = SplineTransformer(\n        n_knots=n_knots,\n        degree=degree,\n        include_bias=include_bias,\n        extrapolation=extrapolation,\n        sparse_output=sparse_output,\n    )\n    X = np.linspace(0, 1, 10)[:, None]\n    splt.fit(X)\n\n    assert splt.transform(X).shape[1] == splt.n_features_out_\n", "type": "function"}, {"name": "test_spline_transformer_unity_decomposition", "is_method": false, "class_name": null, "parameters": ["degree", "n_knots", "knots", "extrapolation"], "calls": ["pytest.mark.parametrize", "pytest.mark.parametrize", "pytest.mark.parametrize", "pytest.mark.parametrize", "SplineTransformer", "splt.fit", "range", "range", "np.linspace", "assert_allclose", "np.sum", "splt.transform"], "code_location": {"file": "test_polynomial.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/preprocessing/tests", "start_line": 144, "end_line": 166}, "code_snippet": "def test_spline_transformer_unity_decomposition(degree, n_knots, knots, extrapolation):\n    \"\"\"Test that B-splines are indeed a decomposition of unity.\n\n    Splines basis functions must sum up to 1 per row, if we stay in between boundaries.\n    \"\"\"\n    X = np.linspace(0, 1, 100)[:, None]\n    # make the boundaries 0 and 1 part of X_train, for sure.\n    X_train = np.r_[[[0]], X[::2, :], [[1]]]\n    X_test = X[1::2, :]\n\n    if extrapolation == \"periodic\":\n        n_knots = n_knots + degree  # periodic splines require degree < n_knots\n\n    splt = SplineTransformer(\n        n_knots=n_knots,\n        degree=degree,\n        knots=knots,\n        include_bias=True,\n        extrapolation=extrapolation,\n    )\n    splt.fit(X_train)\n    for X in [X_train, X_test]:\n        assert_allclose(np.sum(splt.transform(X), axis=1), 1)\n", "type": "function"}, {"name": "test_spline_transformer_linear_regression", "is_method": false, "class_name": null, "parameters": ["bias", "intercept"], "calls": ["pytest.mark.parametrize", "Pipeline", "pipe.fit", "assert_allclose", "np.linspace", "np.sin", "pipe.predict", "SplineTransformer", "LinearRegression"], "code_location": {"file": "test_polynomial.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/preprocessing/tests", "start_line": 170, "end_line": 189}, "code_snippet": "def test_spline_transformer_linear_regression(bias, intercept):\n    \"\"\"Test that B-splines fit a sinusodial curve pretty well.\"\"\"\n    X = np.linspace(0, 10, 100)[:, None]\n    y = np.sin(X[:, 0]) + 2  # +2 to avoid the value 0 in assert_allclose\n    pipe = Pipeline(\n        steps=[\n            (\n                \"spline\",\n                SplineTransformer(\n                    n_knots=15,\n                    degree=3,\n                    include_bias=bias,\n                    extrapolation=\"constant\",\n                ),\n            ),\n            (\"ols\", LinearRegression(fit_intercept=intercept)),\n        ]\n    )\n    pipe.fit(X, y)\n    assert_allclose(pipe.predict(X), y, rtol=1e-3)\n", "type": "function"}, {"name": "test_spline_transformer_periodic_splines_smoothness", "is_method": false, "class_name": null, "parameters": ["degree"], "calls": ["pytest.mark.parametrize", "SplineTransformer", "transformer.fit_transform", "range", "np.diff", "np.linspace", "len", "np.diff", "max", "X.max", "X.min", "max", "np.abs", "np.abs"], "code_location": {"file": "test_polynomial.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/preprocessing/tests", "start_line": 296, "end_line": 331}, "code_snippet": "def test_spline_transformer_periodic_splines_smoothness(degree):\n    \"\"\"Test that spline transformation is smooth at first / last knot.\"\"\"\n    X = np.linspace(-2, 10, 10_000)[:, None]\n\n    transformer = SplineTransformer(\n        degree=degree,\n        extrapolation=\"periodic\",\n        knots=[[0.0], [1.0], [3.0], [4.0], [5.0], [8.0]],\n    )\n    Xt = transformer.fit_transform(X)\n\n    delta = (X.max() - X.min()) / len(X)\n    tol = 10 * delta\n\n    dXt = Xt\n    # We expect splines of degree `degree` to be (`degree`-1) times\n    # continuously differentiable. I.e. for d = 0, ..., `degree` - 1 the d-th\n    # derivative should be continuous. This is the case if the (d+1)-th\n    # numerical derivative is reasonably small (smaller than `tol` in absolute\n    # value). We thus compute d-th numeric derivatives for d = 1, ..., `degree`\n    # and compare them to `tol`.\n    #\n    # Note that the 0-th derivative is the function itself, such that we are\n    # also checking its continuity.\n    for d in range(1, degree + 1):\n        # Check continuity of the (d-1)-th derivative\n        diff = np.diff(dXt, axis=0)\n        assert np.abs(diff).max() < tol\n        # Compute d-th numeric derivative\n        dXt = diff / delta\n\n    # As degree `degree` splines are not `degree` times continuously\n    # differentiable at the knots, the `degree + 1`-th numeric derivative\n    # should have spikes at the knots.\n    diff = np.diff(dXt, axis=0)\n    assert np.abs(diff).max() > 1\n", "type": "function"}, {"name": "test_spline_transformer_integer_knots", "is_method": false, "class_name": null, "parameters": ["extrapolation"], "calls": ["pytest.mark.parametrize", "reshape", "fit_transform", "np.arange", "SplineTransformer"], "code_location": {"file": "test_polynomial.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/preprocessing/tests", "start_line": 74, "end_line": 80}, "code_snippet": "def test_spline_transformer_integer_knots(extrapolation):\n    \"\"\"Test that SplineTransformer accepts integer value knot positions.\"\"\"\n    X = np.arange(20).reshape(10, 2)\n    knots = [[0, 1], [1, 2], [5, 5], [11, 10], [12, 11]]\n    _ = SplineTransformer(\n        degree=3, knots=knots, extrapolation=extrapolation\n    ).fit_transform(X)\n", "type": "function"}, {"name": "test_spline_transformer_periodic_linear_regression", "is_method": false, "class_name": null, "parameters": ["bias", "intercept"], "calls": ["pytest.mark.parametrize", "Pipeline", "pipe.fit", "pipe.predict", "assert_allclose", "assert_allclose", "np.linspace", "f", "np.linspace", "f", "np.sin", "np.sin", "SplineTransformer", "LinearRegression"], "code_location": {"file": "test_polynomial.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/preprocessing/tests", "start_line": 224, "end_line": 252}, "code_snippet": "def test_spline_transformer_periodic_linear_regression(bias, intercept):\n    \"\"\"Test that B-splines fit a periodic curve pretty well.\"\"\"\n\n    # \"+ 3\" to avoid the value 0 in assert_allclose\n    def f(x):\n        return np.sin(2 * np.pi * x) - np.sin(8 * np.pi * x) + 3\n\n    X = np.linspace(0, 1, 101)[:, None]\n    pipe = Pipeline(\n        steps=[\n            (\n                \"spline\",\n                SplineTransformer(\n                    n_knots=20,\n                    degree=3,\n                    include_bias=bias,\n                    extrapolation=\"periodic\",\n                ),\n            ),\n            (\"ols\", LinearRegression(fit_intercept=intercept)),\n        ]\n    )\n    pipe.fit(X, f(X[:, 0]))\n\n    # Generate larger array to check periodic extrapolation\n    X_ = np.linspace(-1, 2, 301)[:, None]\n    predictions = pipe.predict(X_)\n    assert_allclose(predictions, f(X_[:, 0]), atol=0.01, rtol=0.01)\n    assert_allclose(predictions[0:100], predictions[100:200], rtol=1e-3)\n", "type": "function"}], "retrieved_count": 10, "cost_time": 1.2619776725769043}
{"question": "How does the `response_method` parameter's 'auto' fallback mechanism interact with the `_validate_and_get_response_values` method to determine which scoring function to use when an estimator lacks `predict_proba`?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"name": "test_get_response_values_multilabel_indicator", "is_method": false, "class_name": null, "parameters": ["response_method"], "calls": ["pytest.mark.parametrize", "make_multilabel_classification", "fit", "_get_response_values", "all", "ClassifierChain", "all", "LogisticRegression", "np.logical_and", "sum", "sum", "np.logical_or"], "code_location": {"file": "test_response.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/utils/tests", "start_line": 356, "end_line": 373}, "code_snippet": "def test_get_response_values_multilabel_indicator(response_method):\n    X, Y = make_multilabel_classification(random_state=0)\n    estimator = ClassifierChain(LogisticRegression()).fit(X, Y)\n\n    y_pred, pos_label = _get_response_values(\n        estimator, X, response_method=response_method\n    )\n    assert pos_label is None\n    assert y_pred.shape == Y.shape\n\n    if response_method == \"predict_proba\":\n        assert np.logical_and(y_pred >= 0, y_pred <= 1).all()\n    elif response_method == \"decision_function\":\n        # values returned by `decision_function` are not bounded in [0, 1]\n        assert (y_pred < 0).sum() > 0\n        assert (y_pred > 1).sum() > 0\n    else:  # response_method == \"predict\"\n        assert np.logical_or(y_pred == 0, y_pred == 1).all()\n", "type": "function"}, {"name": "_method_name", "is_method": true, "class_name": "_BaseStacking", "parameters": ["name", "estimator", "method"], "calls": ["_check_response_method", "ValueError"], "code_location": {"file": "_stacking.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/ensemble", "start_line": 141, "end_line": 153}, "code_snippet": "    def _method_name(name, estimator, method):\n        if estimator == \"drop\":\n            return None\n        if method == \"auto\":\n            method = [\"predict_proba\", \"decision_function\", \"predict\"]\n        try:\n            method_name = _check_response_method(estimator, method).__name__\n        except AttributeError as e:\n            raise ValueError(\n                f\"Underlying estimator {name} does not implement the method {method}.\"\n            ) from e\n\n        return method_name\n", "type": "function"}, {"name": "_check_boundary_response_method", "is_method": false, "class_name": null, "parameters": ["estimator", "response_method", "class_of_interest"], "calls": ["hasattr", "_is_arraylike_not_scalar", "ValueError", "is_regressor"], "code_location": {"file": "decision_boundary.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/inspection/_plot", "start_line": 23, "end_line": 60}, "code_snippet": "def _check_boundary_response_method(estimator, response_method, class_of_interest):\n    \"\"\"Validate the response methods to be used with the fitted estimator.\n\n    Parameters\n    ----------\n    estimator : object\n        Fitted estimator to check.\n\n    response_method : {'auto', 'decision_function', 'predict_proba', 'predict'}\n        Specifies whether to use :term:`decision_function`, :term:`predict_proba`,\n        :term:`predict` as the target response. If set to 'auto', the response method is\n        tried in the before mentioned order.\n\n    class_of_interest : int, float, bool, str or None\n        The class considered when plotting the decision. Cannot be None if\n        multiclass and `response_method` is 'predict_proba' or 'decision_function'.\n\n        .. versionadded:: 1.4\n\n    Returns\n    -------\n    prediction_method : list of str or str\n        The name or list of names of the response methods to use.\n    \"\"\"\n    has_classes = hasattr(estimator, \"classes_\")\n    if has_classes and _is_arraylike_not_scalar(estimator.classes_[0]):\n        msg = \"Multi-label and multi-output multi-class classifiers are not supported\"\n        raise ValueError(msg)\n\n    if response_method == \"auto\":\n        if is_regressor(estimator):\n            prediction_method = \"predict\"\n        else:\n            prediction_method = [\"decision_function\", \"predict_proba\", \"predict\"]\n    else:\n        prediction_method = response_method\n\n    return prediction_method\n", "type": "function"}, {"name": "test_get_response_values_binary_classifier_predict_proba", "is_method": false, "class_name": null, "parameters": ["return_response_method_used", "response_method"], "calls": ["pytest.mark.parametrize", "pytest.mark.parametrize", "make_classification", "fit", "_get_response_values", "assert_allclose", "_get_response_values", "assert_allclose", "LogisticRegression", "len", "len", "getattr", "getattr"], "code_location": {"file": "test_response.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/utils/tests", "start_line": 170, "end_line": 208}, "code_snippet": "def test_get_response_values_binary_classifier_predict_proba(\n    return_response_method_used, response_method\n):\n    \"\"\"Check that `_get_response_values` with `predict_proba` and binary\n    classifier.\"\"\"\n    X, y = make_classification(\n        n_samples=10,\n        n_classes=2,\n        weights=[0.3, 0.7],\n        random_state=0,\n    )\n    classifier = LogisticRegression().fit(X, y)\n\n    # default `pos_label`\n    results = _get_response_values(\n        classifier,\n        X,\n        response_method=response_method,\n        pos_label=None,\n        return_response_method_used=return_response_method_used,\n    )\n    assert_allclose(results[0], getattr(classifier, response_method)(X)[:, 1])\n    assert results[1] == 1\n    if return_response_method_used:\n        assert len(results) == 3\n        assert results[2] == response_method\n    else:\n        assert len(results) == 2\n\n    # when forcing `pos_label=classifier.classes_[0]`\n    y_pred, pos_label, *_ = _get_response_values(\n        classifier,\n        X,\n        response_method=response_method,\n        pos_label=classifier.classes_[0],\n        return_response_method_used=return_response_method_used,\n    )\n    assert_allclose(y_pred, getattr(classifier, response_method)(X)[:, 0])\n    assert pos_label == 0\n", "type": "function"}, {"name": "_score", "is_method": true, "class_name": "_Scorer", "parameters": ["self", "method_caller", "estimator", "X", "y_true"], "calls": ["self._warn_overlap", "_check_response_method", "method_caller", "is_regressor", "self._get_pos_label", "_get_response_method_name", "self._score_func"], "code_location": {"file": "_scorer.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/metrics", "start_line": 365, "end_line": 413}, "code_snippet": "    def _score(self, method_caller, estimator, X, y_true, **kwargs):\n        \"\"\"Evaluate the response method of `estimator` on `X` and `y_true`.\n\n        Parameters\n        ----------\n        method_caller : callable\n            Returns predictions given an estimator, method name, and other\n            arguments, potentially caching results.\n\n        estimator : object\n            Trained estimator to use for scoring.\n\n        X : {array-like, sparse matrix}\n            Test data that will be fed to clf.decision_function or\n            clf.predict_proba.\n\n        y_true : array-like\n            Gold standard target values for X. These must be class labels,\n            not decision function values.\n\n        **kwargs : dict\n            Other parameters passed to the scorer. Refer to\n            :func:`set_score_request` for more details.\n\n        Returns\n        -------\n        score : float\n            Score function applied to prediction of estimator on X.\n        \"\"\"\n        self._warn_overlap(\n            message=(\n                \"There is an overlap between set kwargs of this scorer instance and\"\n                \" passed metadata. Please pass them either as kwargs to `make_scorer`\"\n                \" or metadata, but not both.\"\n            ),\n            kwargs=kwargs,\n        )\n\n        pos_label = None if is_regressor(estimator) else self._get_pos_label()\n        response_method = _check_response_method(estimator, self._response_method)\n        y_pred = method_caller(\n            estimator,\n            _get_response_method_name(response_method),\n            X,\n            pos_label=pos_label,\n        )\n\n        scoring_kwargs = {**self._kwargs, **kwargs}\n        return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n", "type": "function"}, {"name": "test_get_response_values_classifier_inconsistent_y_pred_for_binary_proba", "is_method": false, "class_name": null, "parameters": ["response_method"], "calls": ["pytest.mark.parametrize", "make_classification", "np.zeros_like", "fit", "pytest.raises", "_get_response_values", "DecisionTreeClassifier"], "code_location": {"file": "test_response.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/utils/tests", "start_line": 109, "end_line": 123}, "code_snippet": "def test_get_response_values_classifier_inconsistent_y_pred_for_binary_proba(\n    response_method,\n):\n    \"\"\"Check that `_get_response_values` will raise an error when `y_pred` has a\n    single class with `predict_proba`.\"\"\"\n    X, y_two_class = make_classification(n_samples=10, n_classes=2, random_state=0)\n    y_single_class = np.zeros_like(y_two_class)\n    classifier = DecisionTreeClassifier().fit(X, y_single_class)\n\n    err_msg = (\n        r\"Got predict_proba of shape \\(10, 1\\), but need classifier with \"\n        r\"two classes\"\n    )\n    with pytest.raises(ValueError, match=err_msg):\n        _get_response_values(classifier, X, response_method=response_method)\n", "type": "function"}, {"name": "test_get_response_predict_proba", "is_method": false, "class_name": null, "parameters": ["return_response_method_used"], "calls": ["pytest.mark.parametrize", "fit", "_get_response_values_binary", "assert_allclose", "_get_response_values_binary", "assert_allclose", "DecisionTreeClassifier", "classifier.predict_proba", "classifier.predict_proba"], "code_location": {"file": "test_response.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/utils/tests", "start_line": 246, "end_line": 270}, "code_snippet": "def test_get_response_predict_proba(return_response_method_used):\n    \"\"\"Check the behaviour of `_get_response_values_binary` using `predict_proba`.\"\"\"\n    classifier = DecisionTreeClassifier().fit(X_binary, y_binary)\n    results = _get_response_values_binary(\n        classifier,\n        X_binary,\n        response_method=\"predict_proba\",\n        return_response_method_used=return_response_method_used,\n    )\n    assert_allclose(results[0], classifier.predict_proba(X_binary)[:, 1])\n    assert results[1] == 1\n    if return_response_method_used:\n        assert results[2] == \"predict_proba\"\n\n    results = _get_response_values_binary(\n        classifier,\n        X_binary,\n        response_method=\"predict_proba\",\n        pos_label=0,\n        return_response_method_used=return_response_method_used,\n    )\n    assert_allclose(results[0], classifier.predict_proba(X_binary)[:, 0])\n    assert results[1] == 0\n    if return_response_method_used:\n        assert results[2] == \"predict_proba\"\n", "type": "function"}, {"name": "test_make_scorer_reponse_method_default_warning", "is_method": false, "class_name": null, "parameters": [], "calls": ["pytest.warns", "make_scorer", "warnings.catch_warnings", "warnings.simplefilter", "make_scorer"], "code_location": {"file": "test_score_objects.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/metrics/tests", "start_line": 1657, "end_line": 1665}, "code_snippet": "def test_make_scorer_reponse_method_default_warning():\n    with pytest.warns(FutureWarning, match=\"response_method=None is deprecated\"):\n        make_scorer(accuracy_score, response_method=None)\n\n    # No warning is raised if response_method is left to its default value\n    # because the future default value has the same effect as the current one.\n    with warnings.catch_warnings():\n        warnings.simplefilter(\"error\", FutureWarning)\n        make_scorer(accuracy_score)\n", "type": "function"}, {"name": "_check_response_method", "is_method": false, "class_name": null, "parameters": ["estimator", "response_method"], "calls": ["isinstance", "reduce", "getattr", "AttributeError", "join"], "code_location": {"file": "validation.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/utils", "start_line": 2279, "end_line": 2322}, "code_snippet": "def _check_response_method(estimator, response_method):\n    \"\"\"Check if `response_method` is available in estimator and return it.\n\n    .. versionadded:: 1.3\n\n    Parameters\n    ----------\n    estimator : estimator instance\n        Classifier or regressor to check.\n\n    response_method : {\"predict_proba\", \"predict_log_proba\", \"decision_function\",\n            \"predict\"} or list of such str\n        Specifies the response method to use get prediction from an estimator\n        (i.e. :term:`predict_proba`, :term:`predict_log_proba`,\n        :term:`decision_function` or :term:`predict`). Possible choices are:\n        - if `str`, it corresponds to the name to the method to return;\n        - if a list of `str`, it provides the method names in order of\n          preference. The method returned corresponds to the first method in\n          the list and which is implemented by `estimator`.\n\n    Returns\n    -------\n    prediction_method : callable\n        Prediction method of estimator.\n\n    Raises\n    ------\n    AttributeError\n        If `response_method` is not available in `estimator`.\n    \"\"\"\n    if isinstance(response_method, str):\n        list_methods = [response_method]\n    else:\n        list_methods = response_method\n\n    prediction_method = [getattr(estimator, method, None) for method in list_methods]\n    prediction_method = reduce(lambda x, y: x or y, prediction_method)\n    if prediction_method is None:\n        raise AttributeError(\n            f\"{estimator.__class__.__name__} has none of the following attributes: \"\n            f\"{', '.join(list_methods)}.\"\n        )\n\n    return prediction_method\n", "type": "function"}, {"name": "test_get_response_values_multiclass", "is_method": false, "class_name": null, "parameters": ["estimator", "response_method"], "calls": ["pytest.mark.parametrize", "estimator.fit", "_get_response_values", "all", "len", "all", "DecisionTreeClassifier", "DecisionTreeClassifier", "LogisticRegression", "np.logical_and"], "code_location": {"file": "test_response.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/utils/tests", "start_line": 309, "end_line": 323}, "code_snippet": "def test_get_response_values_multiclass(estimator, response_method):\n    \"\"\"Check that we can call `_get_response_values` with a multiclass estimator.\n    It should return the predictions untouched.\n    \"\"\"\n    estimator.fit(X, y)\n    predictions, pos_label = _get_response_values(\n        estimator, X, response_method=response_method\n    )\n\n    assert pos_label is None\n    assert predictions.shape == (X.shape[0], len(estimator.classes_))\n    if response_method == \"predict_proba\":\n        assert np.logical_and(predictions >= 0, predictions <= 1).all()\n    elif response_method == \"predict_log_proba\":\n        assert (predictions <= 0.0).all()\n", "type": "function"}], "retrieved_count": 10, "cost_time": 1.2832763195037842}
{"question": "Why does the repeated instantiation of SelectKBest and GenericUnivariateSelect objects in test_mutual_info_regression impact memory allocation and computational overhead compared to reusing a single fitted estimator instance across multiple transform operations?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"name": "test_mutual_info_regression", "is_method": false, "class_name": null, "parameters": [], "calls": ["make_regression", "SelectKBest", "transform", "assert_best_scores_kept", "transform", "assert_array_equal", "univariate_filter.get_support", "np.zeros", "assert_array_equal", "SelectPercentile", "transform", "transform", "assert_array_equal", "univariate_filter.get_support", "np.zeros", "assert_array_equal", "univariate_filter.fit", "fit", "univariate_filter.fit", "fit", "GenericUnivariateSelect", "GenericUnivariateSelect"], "code_location": {"file": "test_feature_select.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/feature_selection/tests", "start_line": 916, "end_line": 953}, "code_snippet": "def test_mutual_info_regression():\n    X, y = make_regression(\n        n_samples=100,\n        n_features=10,\n        n_informative=2,\n        shuffle=False,\n        random_state=0,\n        noise=10,\n    )\n\n    # Test in KBest mode.\n    univariate_filter = SelectKBest(mutual_info_regression, k=2)\n    X_r = univariate_filter.fit(X, y).transform(X)\n    assert_best_scores_kept(univariate_filter)\n    X_r2 = (\n        GenericUnivariateSelect(mutual_info_regression, mode=\"k_best\", param=2)\n        .fit(X, y)\n        .transform(X)\n    )\n    assert_array_equal(X_r, X_r2)\n    support = univariate_filter.get_support()\n    gtruth = np.zeros(10)\n    gtruth[:2] = 1\n    assert_array_equal(support, gtruth)\n\n    # Test in Percentile mode.\n    univariate_filter = SelectPercentile(mutual_info_regression, percentile=20)\n    X_r = univariate_filter.fit(X, y).transform(X)\n    X_r2 = (\n        GenericUnivariateSelect(mutual_info_regression, mode=\"percentile\", param=20)\n        .fit(X, y)\n        .transform(X)\n    )\n    assert_array_equal(X_r, X_r2)\n    support = univariate_filter.get_support()\n    gtruth = np.zeros(10)\n    gtruth[:2] = 1\n    assert_array_equal(support, gtruth)\n", "type": "function"}, {"name": "test_mutual_info_classif", "is_method": false, "class_name": null, "parameters": [], "calls": ["make_classification", "SelectKBest", "transform", "transform", "assert_array_equal", "univariate_filter.get_support", "np.zeros", "assert_array_equal", "SelectPercentile", "transform", "transform", "assert_array_equal", "univariate_filter.get_support", "np.zeros", "assert_array_equal", "univariate_filter.fit", "fit", "univariate_filter.fit", "fit", "GenericUnivariateSelect", "GenericUnivariateSelect"], "code_location": {"file": "test_feature_select.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/feature_selection/tests", "start_line": 872, "end_line": 913}, "code_snippet": "def test_mutual_info_classif():\n    X, y = make_classification(\n        n_samples=100,\n        n_features=5,\n        n_informative=1,\n        n_redundant=1,\n        n_repeated=0,\n        n_classes=2,\n        n_clusters_per_class=1,\n        flip_y=0.0,\n        class_sep=10,\n        shuffle=False,\n        random_state=0,\n    )\n\n    # Test in KBest mode.\n    univariate_filter = SelectKBest(mutual_info_classif, k=2)\n    X_r = univariate_filter.fit(X, y).transform(X)\n    X_r2 = (\n        GenericUnivariateSelect(mutual_info_classif, mode=\"k_best\", param=2)\n        .fit(X, y)\n        .transform(X)\n    )\n    assert_array_equal(X_r, X_r2)\n    support = univariate_filter.get_support()\n    gtruth = np.zeros(5)\n    gtruth[:2] = 1\n    assert_array_equal(support, gtruth)\n\n    # Test in Percentile mode.\n    univariate_filter = SelectPercentile(mutual_info_classif, percentile=40)\n    X_r = univariate_filter.fit(X, y).transform(X)\n    X_r2 = (\n        GenericUnivariateSelect(mutual_info_classif, mode=\"percentile\", param=40)\n        .fit(X, y)\n        .transform(X)\n    )\n    assert_array_equal(X_r, X_r2)\n    support = univariate_filter.get_support()\n    gtruth = np.zeros(5)\n    gtruth[:2] = 1\n    assert_array_equal(support, gtruth)\n", "type": "function"}, {"name": "test_select_kbest_regression", "is_method": false, "class_name": null, "parameters": [], "calls": ["make_regression", "SelectKBest", "transform", "assert_best_scores_kept", "transform", "assert_array_equal", "univariate_filter.get_support", "np.zeros", "assert_array_equal", "univariate_filter.fit", "fit", "GenericUnivariateSelect"], "code_location": {"file": "test_feature_select.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/feature_selection/tests", "start_line": 572, "end_line": 597}, "code_snippet": "def test_select_kbest_regression():\n    # Test whether the relative univariate feature selection\n    # gets the correct items in a simple regression problem\n    # with the k best heuristic\n    X, y = make_regression(\n        n_samples=200,\n        n_features=20,\n        n_informative=5,\n        shuffle=False,\n        random_state=0,\n        noise=10,\n    )\n\n    univariate_filter = SelectKBest(f_regression, k=5)\n    X_r = univariate_filter.fit(X, y).transform(X)\n    assert_best_scores_kept(univariate_filter)\n    X_r2 = (\n        GenericUnivariateSelect(f_regression, mode=\"k_best\", param=5)\n        .fit(X, y)\n        .transform(X)\n    )\n    assert_array_equal(X_r, X_r2)\n    support = univariate_filter.get_support()\n    gtruth = np.zeros(20)\n    gtruth[:5] = 1\n    assert_array_equal(support, gtruth)\n", "type": "function"}, {"name": "test_select_kbest_all", "is_method": false, "class_name": null, "parameters": [], "calls": ["make_classification", "SelectKBest", "transform", "assert_array_equal", "transform", "assert_array_equal", "univariate_filter.fit", "fit", "GenericUnivariateSelect"], "code_location": {"file": "test_feature_select.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/feature_selection/tests", "start_line": 440, "end_line": 456}, "code_snippet": "def test_select_kbest_all():\n    # Test whether k=\"all\" correctly returns all features.\n    X, y = make_classification(\n        n_samples=20, n_features=10, shuffle=False, random_state=0\n    )\n\n    univariate_filter = SelectKBest(f_classif, k=\"all\")\n    X_r = univariate_filter.fit(X, y).transform(X)\n    assert_array_equal(X, X_r)\n    # Non-regression test for:\n    # https://github.com/scikit-learn/scikit-learn/issues/24949\n    X_r2 = (\n        GenericUnivariateSelect(f_classif, mode=\"k_best\", param=\"all\")\n        .fit(X, y)\n        .transform(X)\n    )\n    assert_array_equal(X_r, X_r2)\n", "type": "function"}, {"name": "test_select_heuristics_regression", "is_method": false, "class_name": null, "parameters": [], "calls": ["make_regression", "SelectFpr", "transform", "np.zeros", "transform", "assert_array_equal", "univariate_filter.get_support", "assert_array_equal", "univariate_filter.fit", "np.ones", "np.sum", "fit", "GenericUnivariateSelect"], "code_location": {"file": "test_feature_select.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/feature_selection/tests", "start_line": 600, "end_line": 626}, "code_snippet": "def test_select_heuristics_regression():\n    # Test whether the relative univariate feature selection\n    # gets the correct items in a simple regression problem\n    # with the fpr, fdr or fwe heuristics\n    X, y = make_regression(\n        n_samples=200,\n        n_features=20,\n        n_informative=5,\n        shuffle=False,\n        random_state=0,\n        noise=10,\n    )\n\n    univariate_filter = SelectFpr(f_regression, alpha=0.01)\n    X_r = univariate_filter.fit(X, y).transform(X)\n    gtruth = np.zeros(20)\n    gtruth[:5] = 1\n    for mode in [\"fdr\", \"fpr\", \"fwe\"]:\n        X_r2 = (\n            GenericUnivariateSelect(f_regression, mode=mode, param=0.01)\n            .fit(X, y)\n            .transform(X)\n        )\n        assert_array_equal(X_r, X_r2)\n        support = univariate_filter.get_support()\n        assert_array_equal(support[:5], np.ones((5,), dtype=bool))\n        assert np.sum(support[5:] == 1) < 3\n", "type": "function"}, {"name": "test_selectkbest_tiebreaking", "is_method": false, "class_name": null, "parameters": [], "calls": ["SelectKBest", "assert_best_scores_kept", "SelectKBest", "assert_best_scores_kept", "ignore_warnings", "ignore_warnings"], "code_location": {"file": "test_feature_select.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/feature_selection/tests", "start_line": 737, "end_line": 752}, "code_snippet": "def test_selectkbest_tiebreaking():\n    # Test whether SelectKBest actually selects k features in case of ties.\n    # Prior to 0.11, SelectKBest would return more features than requested.\n    Xs = [[0, 1, 1], [0, 0, 1], [1, 0, 0], [1, 1, 0]]\n    y = [1]\n    dummy_score = lambda X, y: (X[0], X[0])\n    for X in Xs:\n        sel = SelectKBest(dummy_score, k=1)\n        X1 = ignore_warnings(sel.fit_transform)([X], y)\n        assert X1.shape[1] == 1\n        assert_best_scores_kept(sel)\n\n        sel = SelectKBest(dummy_score, k=2)\n        X2 = ignore_warnings(sel.fit_transform)([X], y)\n        assert X2.shape[1] == 2\n        assert_best_scores_kept(sel)\n", "type": "function"}, {"name": "test_select_fdr_regression", "is_method": false, "class_name": null, "parameters": ["alpha", "n_informative"], "calls": ["pytest.mark.parametrize", "pytest.mark.parametrize", "np.mean", "make_regression", "assert_array_equal", "univariate_filter.get_support", "np.sum", "np.sum", "warnings.catch_warnings", "SelectFdr", "transform", "transform", "single_fdr", "range", "univariate_filter.fit", "fit", "GenericUnivariateSelect"], "code_location": {"file": "test_feature_select.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/feature_selection/tests", "start_line": 665, "end_line": 711}, "code_snippet": "def test_select_fdr_regression(alpha, n_informative):\n    # Test that fdr heuristic actually has low FDR.\n    def single_fdr(alpha, n_informative, random_state):\n        X, y = make_regression(\n            n_samples=150,\n            n_features=20,\n            n_informative=n_informative,\n            shuffle=False,\n            random_state=random_state,\n            noise=10,\n        )\n\n        with warnings.catch_warnings(record=True):\n            # Warnings can be raised when no features are selected\n            # (low alpha or very noisy data)\n            univariate_filter = SelectFdr(f_regression, alpha=alpha)\n            X_r = univariate_filter.fit(X, y).transform(X)\n            X_r2 = (\n                GenericUnivariateSelect(f_regression, mode=\"fdr\", param=alpha)\n                .fit(X, y)\n                .transform(X)\n            )\n\n        assert_array_equal(X_r, X_r2)\n        support = univariate_filter.get_support()\n        num_false_positives = np.sum(support[n_informative:] == 1)\n        num_true_positives = np.sum(support[:n_informative] == 1)\n\n        if num_false_positives == 0:\n            return 0.0\n        false_discovery_rate = num_false_positives / (\n            num_true_positives + num_false_positives\n        )\n        return false_discovery_rate\n\n    # As per Benjamini-Hochberg, the expected false discovery rate\n    # should be lower than alpha:\n    # FDR = E(FP / (TP + FP)) <= alpha\n    false_discovery_rate = np.mean(\n        [single_fdr(alpha, n_informative, random_state) for random_state in range(100)]\n    )\n    assert alpha >= false_discovery_rate\n\n    # Make sure that the empirical false discovery rate increases\n    # with alpha:\n    if false_discovery_rate != 0:\n        assert false_discovery_rate > alpha / 10\n", "type": "function"}, {"name": "test_select_kbest_classif", "is_method": false, "class_name": null, "parameters": [], "calls": ["make_classification", "SelectKBest", "transform", "transform", "assert_array_equal", "univariate_filter.get_support", "np.zeros", "assert_array_equal", "univariate_filter.fit", "fit", "GenericUnivariateSelect"], "code_location": {"file": "test_feature_select.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/feature_selection/tests", "start_line": 408, "end_line": 437}, "code_snippet": "def test_select_kbest_classif():\n    # Test whether the relative univariate feature selection\n    # gets the correct items in a simple classification problem\n    # with the k best heuristic\n    X, y = make_classification(\n        n_samples=200,\n        n_features=20,\n        n_informative=3,\n        n_redundant=2,\n        n_repeated=0,\n        n_classes=8,\n        n_clusters_per_class=1,\n        flip_y=0.0,\n        class_sep=10,\n        shuffle=False,\n        random_state=0,\n    )\n\n    univariate_filter = SelectKBest(f_classif, k=5)\n    X_r = univariate_filter.fit(X, y).transform(X)\n    X_r2 = (\n        GenericUnivariateSelect(f_classif, mode=\"k_best\", param=5)\n        .fit(X, y)\n        .transform(X)\n    )\n    assert_array_equal(X_r, X_r2)\n    support = univariate_filter.get_support()\n    gtruth = np.zeros(20)\n    gtruth[:5] = 1\n    assert_array_equal(support, gtruth)\n", "type": "function"}, {"name": "test_select_percentile_regression", "is_method": false, "class_name": null, "parameters": [], "calls": ["make_regression", "SelectPercentile", "transform", "assert_best_scores_kept", "transform", "assert_array_equal", "univariate_filter.get_support", "np.zeros", "assert_array_equal", "X.copy", "assert_array_equal", "assert_array_equal", "univariate_filter.inverse_transform", "X_2.astype", "univariate_filter.inverse_transform", "univariate_filter.fit", "fit", "np.logical_not", "X_r.astype", "GenericUnivariateSelect"], "code_location": {"file": "test_feature_select.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/feature_selection/tests", "start_line": 521, "end_line": 548}, "code_snippet": "def test_select_percentile_regression():\n    # Test whether the relative univariate feature selection\n    # gets the correct items in a simple regression problem\n    # with the percentile heuristic\n    X, y = make_regression(\n        n_samples=200, n_features=20, n_informative=5, shuffle=False, random_state=0\n    )\n\n    univariate_filter = SelectPercentile(f_regression, percentile=25)\n    X_r = univariate_filter.fit(X, y).transform(X)\n    assert_best_scores_kept(univariate_filter)\n    X_r2 = (\n        GenericUnivariateSelect(f_regression, mode=\"percentile\", param=25)\n        .fit(X, y)\n        .transform(X)\n    )\n    assert_array_equal(X_r, X_r2)\n    support = univariate_filter.get_support()\n    gtruth = np.zeros(20)\n    gtruth[:5] = 1\n    assert_array_equal(support, gtruth)\n    X_2 = X.copy()\n    X_2[:, np.logical_not(support)] = 0\n    assert_array_equal(X_2, univariate_filter.inverse_transform(X_r))\n    # Check inverse_transform respects dtype\n    assert_array_equal(\n        X_2.astype(bool), univariate_filter.inverse_transform(X_r.astype(bool))\n    )\n", "type": "function"}, {"name": "test_rfe_wrapped_estimator", "is_method": false, "class_name": null, "parameters": ["importance_getter", "selector", "expected_n_features"], "calls": ["pytest.mark.parametrize", "pytest.mark.parametrize", "make_friedman1", "LinearSVR", "TransformedTargetRegressor", "selector", "selector.fit", "sel.support_.sum", "attrgetter"], "code_location": {"file": "test_rfe.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/feature_selection/tests", "start_line": 468, "end_line": 480}, "code_snippet": "def test_rfe_wrapped_estimator(importance_getter, selector, expected_n_features):\n    # Non-regression test for\n    # https://github.com/scikit-learn/scikit-learn/issues/15312\n    X, y = make_friedman1(n_samples=50, n_features=10, random_state=0)\n    estimator = LinearSVR(random_state=0)\n\n    log_estimator = TransformedTargetRegressor(\n        regressor=estimator, func=np.log, inverse_func=np.exp\n    )\n\n    selector = selector(log_estimator, importance_getter=importance_getter)\n    sel = selector.fit(X, y)\n    assert sel.support_.sum() == expected_n_features\n", "type": "function"}], "retrieved_count": 10, "cost_time": 0.3413808345794678}
{"question": "Why does the Pipeline class explicitly reject the sample_weight parameter during fit when the underlying estimator does not declare support for it through metadata routing?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"name": "test_metadata_routing_error_for_pipeline", "is_method": false, "class_name": null, "parameters": ["method"], "calls": ["pytest.mark.parametrize", "config_context", "SimpleEstimator", "Pipeline", "sorted", "pytest.raises", "set", "re.escape", "getattr", "getattr"], "code_location": {"file": "test_pipeline.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/tests", "start_line": 2277, "end_line": 2295}, "code_snippet": "def test_metadata_routing_error_for_pipeline(method):\n    \"\"\"Test that metadata is not routed for pipelines when not requested.\"\"\"\n    X, y = [[1]], [1]\n    sample_weight, prop = [1], \"a\"\n    est = SimpleEstimator()\n    # here not setting sample_weight request and leaving it as None\n    pipeline = Pipeline([(\"estimator\", est)])\n    error_message = (\n        \"[sample_weight, prop] are passed but are not explicitly set as requested\"\n        f\" or not requested for SimpleEstimator.{method}\"\n    )\n    with pytest.raises(ValueError, match=re.escape(error_message)):\n        try:\n            # passing X, y positional as the first two arguments\n            getattr(pipeline, method)(X, y, sample_weight=sample_weight, prop=prop)\n        except TypeError:\n            # not all methods accept y (like `predict`), so here we only\n            # pass X as a positional arg.\n            getattr(pipeline, method)(X, sample_weight=sample_weight, prop=prop)\n", "type": "function"}, {"name": "_accept_sample_weight", "is_method": true, "class_name": "_PassthroughScorer", "parameters": ["self"], "calls": ["signature"], "code_location": {"file": "_scorer.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/metrics", "start_line": 502, "end_line": 504}, "code_snippet": "    def _accept_sample_weight(self):\n        # TODO(slep006): remove when metadata routing is the only way\n        return \"sample_weight\" in signature(self._estimator.score).parameters\n", "type": "function"}, {"name": "test_pipeline_sample_weight_unsupported", "is_method": false, "class_name": null, "parameters": [], "calls": ["np.array", "Pipeline", "pipe.fit", "re.escape", "pipe.score", "pipe.score", "pytest.raises", "pipe.score", "Transf", "Mult", "np.array"], "code_location": {"file": "test_pipeline.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/tests", "start_line": 349, "end_line": 359}, "code_snippet": "def test_pipeline_sample_weight_unsupported():\n    # When sample_weight is None it shouldn't be passed\n    X = np.array([[1, 2]])\n    pipe = Pipeline([(\"transf\", Transf()), (\"clf\", Mult())])\n    pipe.fit(X, y=None)\n    assert pipe.score(X) == 3\n    assert pipe.score(X, sample_weight=None) == 3\n\n    msg = re.escape(\"score() got an unexpected keyword argument 'sample_weight'\")\n    with pytest.raises(TypeError, match=msg):\n        pipe.score(X, sample_weight=np.array([2, 3]))\n", "type": "function"}, {"name": "test_fit_rejects_params_with_no_routing_enabled", "is_method": false, "class_name": null, "parameters": [], "calls": ["make_classification", "LinearRegression", "SequentialFeatureSelector", "pytest.raises", "sfs.fit", "np.ones_like"], "code_location": {"file": "test_sequential.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/feature_selection/tests", "start_line": 326, "end_line": 332}, "code_snippet": "def test_fit_rejects_params_with_no_routing_enabled():\n    X, y = make_classification(random_state=42)\n    est = LinearRegression()\n    sfs = SequentialFeatureSelector(estimator=est)\n\n    with pytest.raises(ValueError, match=\"is only supported if\"):\n        sfs.fit(X, y, sample_weight=np.ones_like(y))\n", "type": "function"}, {"name": "_consumes_sample_weight", "is_method": false, "class_name": null, "parameters": ["estimator"], "calls": ["_routing_enabled", "get_routing_for_object", "request_or_router.consumes", "has_fit_parameter"], "code_location": {"file": "_bagging.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/ensemble", "start_line": 96, "end_line": 102}, "code_snippet": "def _consumes_sample_weight(estimator):\n    if _routing_enabled():\n        request_or_router = get_routing_for_object(estimator)\n        consumes_sample_weight = request_or_router.consumes(\"fit\", (\"sample_weight\",))\n    else:\n        consumes_sample_weight = has_fit_parameter(estimator, \"sample_weight\")\n    return consumes_sample_weight\n", "type": "function"}, {"name": "fit", "is_method": true, "class_name": "WeightedMetaRegressor", "parameters": ["self", "X", "y", "sample_weight"], "calls": ["process_routing", "check_metadata", "fit", "clone"], "code_location": {"file": "plot_metadata_routing.py", "path": "/data3/pwh/swebench-repos/scikit-learn/examples/miscellaneous", "start_line": 644, "end_line": 649}, "code_snippet": "    def fit(self, X, y, sample_weight=None, **fit_params):\n        routed_params = process_routing(\n            self, \"fit\", sample_weight=sample_weight, **fit_params\n        )\n        check_metadata(self, sample_weight=sample_weight)\n        self.estimator_ = clone(self.estimator).fit(X, y, **routed_params.estimator.fit)\n", "type": "function"}, {"name": "test_unsupported_estimators_fit_with_metadata", "is_method": false, "class_name": null, "parameters": ["estimator"], "calls": ["pytest.mark.parametrize", "config_context", "pytest.raises", "estimator.fit"], "code_location": {"file": "test_metaestimators_metadata_routing.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/tests", "start_line": 644, "end_line": 654}, "code_snippet": "def test_unsupported_estimators_fit_with_metadata(estimator):\n    \"\"\"Test that fit raises NotImplementedError when metadata routing is\n    enabled and a metadata is passed on meta-estimators for which we haven't\n    implemented routing yet.\"\"\"\n    with pytest.raises(NotImplementedError):\n        try:\n            estimator.fit([[1]], [1], sample_weight=[1])\n        except TypeError:\n            # not all meta-estimators in the list support sample_weight,\n            # and for those we skip this test.\n            raise NotImplementedError\n", "type": "function"}, {"name": "_accept_sample_weight", "is_method": true, "class_name": "_BaseScorer", "parameters": ["self"], "calls": ["signature"], "code_location": {"file": "_scorer.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/metrics", "start_line": 255, "end_line": 257}, "code_snippet": "    def _accept_sample_weight(self):\n        # TODO(slep006): remove when metadata routing is the only way\n        return \"sample_weight\" in signature(self._score_func).parameters\n", "type": "function"}, {"name": "_accept_sample_weight", "is_method": true, "class_name": "_MultimetricScorer", "parameters": ["self"], "calls": ["any", "scorer._accept_sample_weight", "self._scorers.values"], "code_location": {"file": "_scorer.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/metrics", "start_line": 174, "end_line": 176}, "code_snippet": "    def _accept_sample_weight(self):\n        # TODO(slep006): remove when metadata routing is the only way\n        return any(scorer._accept_sample_weight() for scorer in self._scorers.values())\n", "type": "function"}, {"name": "fit", "is_method": true, "class_name": "RouterConsumerClassifier", "parameters": ["self", "X", "y", "sample_weight"], "calls": ["check_metadata", "get_routing_for_object", "request_router.validate_metadata", "request_router.route_params", "fit", "ValueError", "clone"], "code_location": {"file": "plot_metadata_routing.py", "path": "/data3/pwh/swebench-repos/scikit-learn/examples/miscellaneous", "start_line": 372, "end_line": 387}, "code_snippet": "    def fit(self, X, y, sample_weight, **fit_params):\n        if self.estimator is None:\n            raise ValueError(\"estimator cannot be None!\")\n\n        check_metadata(self, sample_weight=sample_weight)\n\n        # We add `sample_weight` to the `fit_params` dictionary.\n        if sample_weight is not None:\n            fit_params[\"sample_weight\"] = sample_weight\n\n        request_router = get_routing_for_object(self)\n        request_router.validate_metadata(params=fit_params, method=\"fit\")\n        routed_params = request_router.route_params(params=fit_params, caller=\"fit\")\n        self.estimator_ = clone(self.estimator).fit(X, y, **routed_params.estimator.fit)\n        self.classes_ = self.estimator_.classes_\n        return self\n", "type": "function"}], "retrieved_count": 10, "cost_time": 0.33426523208618164}
{"question": "Where does the InfinityType class control the flow of comparison operations to ensure that its ordering semantics are preserved across all comparison chains, and what data transformation occurs when the __neg__ method is invoked to produce a NegativeInfinityType instance?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"name": "__neg__", "is_method": true, "class_name": "NegativeInfinityType", "parameters": ["self"], "calls": [], "code_location": {"file": "_structures.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/externals/_packaging", "start_line": 86, "end_line": 87}, "code_snippet": "    def __neg__(self: object) -> InfinityType:\n        return Infinity\n", "type": "function"}, {"name": "__neg__", "is_method": true, "class_name": "InfinityType", "parameters": ["self"], "calls": [], "code_location": {"file": "_structures.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/externals/_packaging", "start_line": 54, "end_line": 55}, "code_snippet": "    def __neg__(self: object) -> \"NegativeInfinityType\":\n        return NegativeInfinity\n", "type": "function"}, {"name": "NegativeInfinityType", "docstring": "", "methods": ["__repr__", "__hash__", "__lt__", "__le__", "__eq__", "__ne__", "__gt__", "__ge__", "__neg__"], "attributes": [], "code_location": {"file": "_structures.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/externals/_packaging", "start_line": 61, "end_line": 87}, "type": "class"}, {"name": "InfinityType", "docstring": "", "methods": ["__repr__", "__hash__", "__lt__", "__le__", "__eq__", "__ne__", "__gt__", "__ge__", "__neg__"], "attributes": [], "code_location": {"file": "_structures.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/externals/_packaging", "start_line": 29, "end_line": 55}, "type": "class"}, {"name": "__repr__", "is_method": true, "class_name": "NegativeInfinityType", "parameters": ["self"], "calls": [], "code_location": {"file": "_structures.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/externals/_packaging", "start_line": 62, "end_line": 63}, "code_snippet": "    def __repr__(self) -> str:\n        return \"-Infinity\"\n", "type": "function"}, {"name": "__lt__", "is_method": true, "class_name": "NegativeInfinityType", "parameters": ["self", "other"], "calls": [], "code_location": {"file": "_structures.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/externals/_packaging", "start_line": 68, "end_line": 69}, "code_snippet": "    def __lt__(self, other: object) -> bool:\n        return True\n", "type": "function"}, {"name": "__repr__", "is_method": true, "class_name": "InfinityType", "parameters": ["self"], "calls": [], "code_location": {"file": "_structures.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/externals/_packaging", "start_line": 30, "end_line": 31}, "code_snippet": "    def __repr__(self) -> str:\n        return \"Infinity\"\n", "type": "function"}, {"name": "__lt__", "is_method": true, "class_name": "InfinityType", "parameters": ["self", "other"], "calls": [], "code_location": {"file": "_structures.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/externals/_packaging", "start_line": 36, "end_line": 37}, "code_snippet": "    def __lt__(self, other: object) -> bool:\n        return False\n", "type": "function"}, {"name": "__gt__", "is_method": true, "class_name": "InfinityType", "parameters": ["self", "other"], "calls": [], "code_location": {"file": "_structures.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/externals/_packaging", "start_line": 48, "end_line": 49}, "code_snippet": "    def __gt__(self, other: object) -> bool:\n        return True\n", "type": "function"}, {"name": "__gt__", "is_method": true, "class_name": "NegativeInfinityType", "parameters": ["self", "other"], "calls": [], "code_location": {"file": "_structures.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/externals/_packaging", "start_line": 80, "end_line": 81}, "code_snippet": "    def __gt__(self, other: object) -> bool:\n        return False\n", "type": "function"}], "retrieved_count": 10, "cost_time": 0.3417649269104004}
{"question": "Where does the permutation loop control the data transformation flow between y_true and y_score, and what specific inverse mapping mechanism ensures that the metric computation remains invariant across all class label permutations?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"name": "test_multilabel_label_permutations_invariance", "is_method": false, "class_name": null, "parameters": ["name"], "calls": ["pytest.mark.parametrize", "check_random_state", "random_state.randint", "random_state.randint", "metric", "permutations", "sorted", "range", "metric", "assert_almost_equal"], "code_location": {"file": "test_common.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/metrics/tests", "start_line": 1789, "end_line": 1804}, "code_snippet": "def test_multilabel_label_permutations_invariance(name):\n    random_state = check_random_state(0)\n    n_samples, n_classes = 20, 4\n\n    y_true = random_state.randint(0, 2, size=(n_samples, n_classes))\n    y_score = random_state.randint(0, 2, size=(n_samples, n_classes))\n\n    metric = ALL_METRICS[name]\n    score = metric(y_true, y_score)\n\n    for perm in permutations(range(n_classes), n_classes):\n        y_score_perm = y_score[:, perm]\n        y_true_perm = y_true[:, perm]\n\n        current_score = metric(y_true_perm, y_score_perm)\n        assert_almost_equal(score, current_score)\n", "type": "function"}, {"name": "test_thresholded_metric_permutation_invariance", "is_method": false, "class_name": null, "parameters": ["name"], "calls": ["pytest.mark.parametrize", "check_random_state", "random_state.rand", "np.exp", "random_state.randint", "metric", "permutations", "sorted", "reshape", "range", "np.zeros", "np.arange", "np.take", "metric", "assert_almost_equal", "list", "set", "temp.sum"], "code_location": {"file": "test_common.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/metrics/tests", "start_line": 1846, "end_line": 1864}, "code_snippet": "def test_thresholded_metric_permutation_invariance(name):\n    n_samples, n_classes = 100, 3\n    random_state = check_random_state(0)\n\n    y_score = random_state.rand(n_samples, n_classes)\n    temp = np.exp(-y_score)\n    y_score = temp / temp.sum(axis=-1).reshape(-1, 1)\n    y_true = random_state.randint(0, n_classes, size=n_samples)\n\n    metric = ALL_METRICS[name]\n    score = metric(y_true, y_score)\n    for perm in permutations(range(n_classes), n_classes):\n        inverse_perm = np.zeros(n_classes, dtype=int)\n        inverse_perm[list(perm)] = np.arange(n_classes)\n        y_score_perm = y_score[:, inverse_perm]\n        y_true_perm = np.take(perm, y_true)\n\n        current_score = metric(y_true_perm, y_score_perm)\n        assert_almost_equal(score, current_score)\n", "type": "function"}, {"name": "test_permute_labels", "is_method": false, "class_name": null, "parameters": ["metric_name"], "calls": ["pytest.mark.parametrize", "np.array", "np.array", "chain", "metric", "assert_allclose", "assert_allclose", "assert_allclose", "np.random.randint", "metric", "assert_allclose", "metric", "metric", "metric", "metric"], "code_location": {"file": "test_common.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/metrics/cluster/tests", "start_line": 135, "end_line": 150}, "code_snippet": "def test_permute_labels(metric_name):\n    # All clustering metrics do not change score due to permutations of labels\n    # that is when 0 and 1 exchanged.\n    y_label = np.array([0, 0, 0, 1, 1, 0, 1])\n    y_pred = np.array([1, 0, 1, 0, 1, 1, 0])\n    if metric_name in SUPERVISED_METRICS:\n        metric = SUPERVISED_METRICS[metric_name]\n        score_1 = metric(y_pred, y_label)\n        assert_allclose(score_1, metric(1 - y_pred, y_label))\n        assert_allclose(score_1, metric(1 - y_pred, 1 - y_label))\n        assert_allclose(score_1, metric(y_pred, 1 - y_label))\n    else:\n        metric = UNSUPERVISED_METRICS[metric_name]\n        X = np.random.randint(10, size=(7, 10))\n        score_1 = metric(X, y_pred)\n        assert_allclose(score_1, metric(X, 1 - y_pred))\n", "type": "function"}, {"name": "test_thresholded_multilabel_multioutput_permutations_invariance", "is_method": false, "class_name": null, "parameters": ["name"], "calls": ["pytest.mark.parametrize", "check_random_state", "random_state.randint", "random_state.uniform", "y_score.sum", "metric", "permutations", "sorted", "range", "metric", "np.isfinite", "assert_almost_equal", "y_true.sum", "y_true.sum"], "code_location": {"file": "test_common.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/metrics/tests", "start_line": 1810, "end_line": 1840}, "code_snippet": "def test_thresholded_multilabel_multioutput_permutations_invariance(name):\n    random_state = check_random_state(0)\n    n_samples, n_classes = 20, 4\n    y_true = random_state.randint(0, 2, size=(n_samples, n_classes))\n    y_score = random_state.uniform(size=y_true.shape)\n\n    # Some metrics (e.g. log_loss) require y_score to be probabilities (sum to 1)\n    y_score /= y_score.sum(axis=1, keepdims=True)\n\n    # Makes sure all samples have at least one label. This works around errors\n    # when running metrics where average=\"sample\"\n    y_true[y_true.sum(1) == 4, 0] = 0\n    y_true[y_true.sum(1) == 0, 0] = 1\n\n    metric = ALL_METRICS[name]\n    score = metric(y_true, y_score)\n\n    for perm in permutations(range(n_classes), n_classes):\n        y_score_perm = y_score[:, perm]\n        y_true_perm = y_true[:, perm]\n\n        current_score = metric(y_true_perm, y_score_perm)\n        if metric == mean_absolute_percentage_error:\n            assert np.isfinite(current_score)\n            assert current_score > 1e6\n            # Here we are not comparing the values in case of MAPE because\n            # whenever y_true value is exactly zero, the MAPE value doesn't\n            # signify anything. Thus, in this case we are just expecting\n            # very large finite value.\n        else:\n            assert_almost_equal(score, current_score)\n", "type": "function"}, {"name": "_calculate_permutation_scores", "is_method": false, "class_name": null, "parameters": ["estimator", "X", "y", "sample_weight", "col_idx", "random_state", "n_repeats", "scorer", "max_samples"], "calls": ["check_random_state", "np.arange", "range", "isinstance", "_generate_indices", "_safe_indexing", "_safe_indexing", "X.copy", "random_state.shuffle", "hasattr", "scores.append", "_aggregate_score_dicts", "np.array", "_safe_indexing", "_weights_scorer"], "code_location": {"file": "_permutation_importance.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/inspection", "start_line": 31, "end_line": 82}, "code_snippet": "def _calculate_permutation_scores(\n    estimator,\n    X,\n    y,\n    sample_weight,\n    col_idx,\n    random_state,\n    n_repeats,\n    scorer,\n    max_samples,\n):\n    \"\"\"Calculate score when `col_idx` is permuted.\"\"\"\n    random_state = check_random_state(random_state)\n\n    # Work on a copy of X to ensure thread-safety in case of threading based\n    # parallelism. Furthermore, making a copy is also useful when the joblib\n    # backend is 'loky' (default) or the old 'multiprocessing': in those cases,\n    # if X is large it will be automatically be backed by a readonly memory map\n    # (memmap). X.copy() on the other hand is always guaranteed to return a\n    # writable data-structure whose columns can be shuffled inplace.\n    if max_samples < X.shape[0]:\n        row_indices = _generate_indices(\n            random_state=random_state,\n            bootstrap=False,\n            n_population=X.shape[0],\n            n_samples=max_samples,\n        )\n        X_permuted = _safe_indexing(X, row_indices, axis=0)\n        y = _safe_indexing(y, row_indices, axis=0)\n        if sample_weight is not None:\n            sample_weight = _safe_indexing(sample_weight, row_indices, axis=0)\n    else:\n        X_permuted = X.copy()\n\n    scores = []\n    shuffling_idx = np.arange(X_permuted.shape[0])\n    for _ in range(n_repeats):\n        random_state.shuffle(shuffling_idx)\n        if hasattr(X_permuted, \"iloc\"):\n            col = X_permuted.iloc[shuffling_idx, col_idx]\n            col.index = X_permuted.index\n            X_permuted[X_permuted.columns[col_idx]] = col\n        else:\n            X_permuted[:, col_idx] = X_permuted[shuffling_idx, col_idx]\n        scores.append(_weights_scorer(scorer, estimator, X_permuted, y, sample_weight))\n\n    if isinstance(scores[0], dict):\n        scores = _aggregate_score_dicts(scores)\n    else:\n        scores = np.array(scores)\n\n    return scores\n", "type": "function"}, {"name": "test_sample_order_invariance", "is_method": false, "class_name": null, "parameters": ["name"], "calls": ["pytest.mark.parametrize", "check_random_state", "random_state.randint", "random_state.randint", "shuffle", "sorted", "_require_positive_targets", "ignore_warnings", "assert_allclose", "_require_log1p_targets", "metric", "metric", "set"], "code_location": {"file": "test_common.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/metrics/tests", "start_line": 689, "end_line": 707}, "code_snippet": "def test_sample_order_invariance(name):\n    random_state = check_random_state(0)\n    y_true = random_state.randint(0, 2, size=(20,))\n    y_pred = random_state.randint(0, 2, size=(20,))\n\n    if name in METRICS_REQUIRE_POSITIVE_Y:\n        y_true, y_pred = _require_positive_targets(y_true, y_pred)\n    elif name in METRICS_WITH_LOG1P_Y:\n        y_true, y_pred = _require_log1p_targets(y_true, y_pred)\n\n    y_true_shuffle, y_pred_shuffle = shuffle(y_true, y_pred, random_state=0)\n\n    with ignore_warnings():\n        metric = ALL_METRICS[name]\n        assert_allclose(\n            metric(y_true, y_pred),\n            metric(y_true_shuffle, y_pred_shuffle),\n            err_msg=\"%s is not sample order invariant\" % name,\n        )\n", "type": "function"}, {"name": "test_sample_order_invariance_multilabel_and_multioutput", "is_method": false, "class_name": null, "parameters": [], "calls": ["check_random_state", "random_state.randint", "random_state.randint", "random_state.uniform", "y_score.sum", "shuffle", "assert_allclose", "assert_allclose", "assert_allclose", "assert_allclose", "metric", "metric", "metric", "metric", "metric", "metric", "metric", "metric"], "code_location": {"file": "test_common.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/metrics/tests", "start_line": 710, "end_line": 752}, "code_snippet": "def test_sample_order_invariance_multilabel_and_multioutput():\n    random_state = check_random_state(0)\n\n    # Generate some data\n    y_true = random_state.randint(0, 2, size=(20, 25))\n    y_pred = random_state.randint(0, 2, size=(20, 25))\n    y_score = random_state.uniform(size=y_true.shape)\n\n    # Some metrics (e.g. log_loss) require y_score to be probabilities (sum to 1)\n    y_score /= y_score.sum(axis=1, keepdims=True)\n\n    y_true_shuffle, y_pred_shuffle, y_score_shuffle = shuffle(\n        y_true, y_pred, y_score, random_state=0\n    )\n\n    for name in MULTILABELS_METRICS:\n        metric = ALL_METRICS[name]\n        assert_allclose(\n            metric(y_true, y_pred),\n            metric(y_true_shuffle, y_pred_shuffle),\n            err_msg=\"%s is not sample order invariant\" % name,\n        )\n\n    for name in THRESHOLDED_MULTILABEL_METRICS:\n        metric = ALL_METRICS[name]\n        assert_allclose(\n            metric(y_true, y_score),\n            metric(y_true_shuffle, y_score_shuffle),\n            err_msg=\"%s is not sample order invariant\" % name,\n        )\n\n    for name in MULTIOUTPUT_METRICS:\n        metric = ALL_METRICS[name]\n        assert_allclose(\n            metric(y_true, y_score),\n            metric(y_true_shuffle, y_score_shuffle),\n            err_msg=\"%s is not sample order invariant\" % name,\n        )\n        assert_allclose(\n            metric(y_true, y_pred),\n            metric(y_true_shuffle, y_pred_shuffle),\n            err_msg=\"%s is not sample order invariant\" % name,\n        )\n", "type": "function"}, {"name": "_permutation_test_score", "is_method": false, "class_name": null, "parameters": ["estimator", "X", "y", "cv", "scorer", "split_params", "fit_params", "score_params"], "calls": ["cv.split", "np.mean", "_safe_split", "_safe_split", "_check_method_params", "_check_method_params", "estimator.fit", "avg_score.append", "scorer"], "code_location": {"file": "_validation.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/model_selection", "start_line": 1706, "end_line": 1722}, "code_snippet": "def _permutation_test_score(\n    estimator, X, y, cv, scorer, split_params, fit_params, score_params\n):\n    \"\"\"Auxiliary function for permutation_test_score\"\"\"\n    # Adjust length of sample weights\n    fit_params = fit_params if fit_params is not None else {}\n    score_params = score_params if score_params is not None else {}\n\n    avg_score = []\n    for train, test in cv.split(X, y, **split_params):\n        X_train, y_train = _safe_split(estimator, X, y, train)\n        X_test, y_test = _safe_split(estimator, X, y, test, train)\n        fit_params_train = _check_method_params(X, params=fit_params, indices=train)\n        score_params_test = _check_method_params(X, params=score_params, indices=test)\n        estimator.fit(X_train, y_train, **fit_params_train)\n        avg_score.append(scorer(estimator, X_test, y_test, **score_params_test))\n    return np.mean(avg_score)\n", "type": "function"}, {"name": "check_averaging", "is_method": false, "class_name": null, "parameters": ["name", "y_true", "y_true_binarize", "y_pred", "y_pred_binarize", "y_score"], "calls": ["startswith", "_check_averaging", "type_of_target", "_check_averaging", "ValueError"], "code_location": {"file": "test_common.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/metrics/tests", "start_line": 1416, "end_line": 1430}, "code_snippet": "def check_averaging(name, y_true, y_true_binarize, y_pred, y_pred_binarize, y_score):\n    is_multilabel = type_of_target(y_true).startswith(\"multilabel\")\n\n    metric = ALL_METRICS[name]\n\n    if name in METRICS_WITH_AVERAGING:\n        _check_averaging(\n            metric, y_true, y_pred, y_true_binarize, y_pred_binarize, is_multilabel\n        )\n    elif name in THRESHOLDED_METRICS_WITH_AVERAGING:\n        _check_averaging(\n            metric, y_true, y_score, y_true_binarize, y_score, is_multilabel\n        )\n    else:\n        raise ValueError(\"Metric is not recorded as having an average option\")\n", "type": "function"}, {"name": "test_invariance_of_encoding_under_label_permutation", "is_method": false, "class_name": null, "parameters": ["smooth", "global_random_seed"], "calls": ["pytest.mark.parametrize", "np.random.RandomState", "rng.normal", "fit_transform", "train_test_split", "rng.permutation", "TargetEncoder", "target_encoder.fit_transform", "target_encoder.transform", "target_encoder.fit_transform", "target_encoder.transform", "assert_allclose", "assert_allclose", "y.reshape", "X_train.astype", "X_test.astype", "KBinsDiscretizer"], "code_location": {"file": "test_target_encoder.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/preprocessing/tests", "start_line": 554, "end_line": 586}, "code_snippet": "def test_invariance_of_encoding_under_label_permutation(smooth, global_random_seed):\n    # Check that the encoding does not depend on the integer of the value of\n    # the integer labels. This is quite a trivial property but it is helpful\n    # to understand the following test.\n    rng = np.random.RandomState(global_random_seed)\n\n    # Random y and informative categorical X to make the test non-trivial when\n    # using smoothing.\n    y = rng.normal(size=1000)\n    n_categories = 30\n    X = KBinsDiscretizer(\n        n_bins=n_categories, quantile_method=\"averaged_inverted_cdf\", encode=\"ordinal\"\n    ).fit_transform(y.reshape(-1, 1))\n\n    X_train, X_test, y_train, y_test = train_test_split(\n        X, y, random_state=global_random_seed\n    )\n\n    # Shuffle the labels to make sure that the encoding is invariant to the\n    # permutation of the labels\n    permutated_labels = rng.permutation(n_categories)\n    X_train_permuted = permutated_labels[X_train.astype(np.int32)]\n    X_test_permuted = permutated_labels[X_test.astype(np.int32)]\n\n    target_encoder = TargetEncoder(smooth=smooth, random_state=global_random_seed)\n    X_train_encoded = target_encoder.fit_transform(X_train, y_train)\n    X_test_encoded = target_encoder.transform(X_test)\n\n    X_train_permuted_encoded = target_encoder.fit_transform(X_train_permuted, y_train)\n    X_test_permuted_encoded = target_encoder.transform(X_test_permuted)\n\n    assert_allclose(X_train_encoded, X_train_permuted_encoded)\n    assert_allclose(X_test_encoded, X_test_permuted_encoded)\n", "type": "function"}], "retrieved_count": 10, "cost_time": 0.3320639133453369}
{"question": "Why does DummyTransformer's fit_counter mechanism enable detection of redundant fit invocations in scikit-learn's pipeline cloning and composition workflows?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"name": "test_transform_target_regressor_count_fit", "is_method": false, "class_name": null, "parameters": ["check_inverse"], "calls": ["pytest.mark.parametrize", "TransformedTargetRegressor", "ttr.fit", "DummyTransformer"], "code_location": {"file": "test_target.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/compose/tests", "start_line": 336, "end_line": 344}, "code_snippet": "def test_transform_target_regressor_count_fit(check_inverse):\n    # regression test for gh-issue #11618\n    # check that we only call a single time fit for the transformer\n    X, y = friedman\n    ttr = TransformedTargetRegressor(\n        transformer=DummyTransformer(), check_inverse=check_inverse\n    )\n    ttr.fit(X, y)\n    assert ttr.transformer_.fit_counter == 1\n", "type": "function"}, {"name": "test_column_transformer_cloning", "is_method": false, "class_name": null, "parameters": [], "calls": ["ColumnTransformer", "ct.fit", "hasattr", "ColumnTransformer", "ct.fit_transform", "hasattr", "np.array", "hasattr", "hasattr", "StandardScaler", "StandardScaler"], "code_location": {"file": "test_column_transformer.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/compose/tests", "start_line": 842, "end_line": 853}, "code_snippet": "def test_column_transformer_cloning():\n    X_array = np.array([[0.0, 1.0, 2.0], [2.0, 4.0, 6.0]]).T\n\n    ct = ColumnTransformer([(\"trans\", StandardScaler(), [0])])\n    ct.fit(X_array)\n    assert not hasattr(ct.transformers[0][1], \"mean_\")\n    assert hasattr(ct.transformers_[0][1], \"mean_\")\n\n    ct = ColumnTransformer([(\"trans\", StandardScaler(), [0])])\n    ct.fit_transform(X_array)\n    assert not hasattr(ct.transformers[0][1], \"mean_\")\n    assert hasattr(ct.transformers_[0][1], \"mean_\")\n", "type": "function"}, {"name": "test_transform_target_regressor_pass_fit_parameters", "is_method": false, "class_name": null, "parameters": [], "calls": ["TransformedTargetRegressor", "regr.fit", "DummyRegressorWithExtraFitParams", "DummyTransformer"], "code_location": {"file": "test_target.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/compose/tests", "start_line": 355, "end_line": 362}, "code_snippet": "def test_transform_target_regressor_pass_fit_parameters():\n    X, y = friedman\n    regr = TransformedTargetRegressor(\n        regressor=DummyRegressorWithExtraFitParams(), transformer=DummyTransformer()\n    )\n\n    regr.fit(X, y, check_input=False)\n    assert regr.transformer_.fit_counter == 1\n", "type": "function"}, {"name": "test_transform_target_regressor_route_pipeline", "is_method": false, "class_name": null, "parameters": [], "calls": ["TransformedTargetRegressor", "Pipeline", "pip.fit", "DummyRegressorWithExtraFitParams", "DummyTransformer", "StandardScaler"], "code_location": {"file": "test_target.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/compose/tests", "start_line": 365, "end_line": 376}, "code_snippet": "def test_transform_target_regressor_route_pipeline():\n    X, y = friedman\n\n    regr = TransformedTargetRegressor(\n        regressor=DummyRegressorWithExtraFitParams(), transformer=DummyTransformer()\n    )\n    estimators = [(\"normalize\", StandardScaler()), (\"est\", regr)]\n\n    pip = Pipeline(estimators)\n    pip.fit(X, y, **{\"est__check_input\": False})\n\n    assert regr.transformer_.fit_counter == 1\n", "type": "function"}, {"name": "check_transformer_n_iter", "is_method": false, "class_name": null, "parameters": ["name", "estimator_orig"], "calls": ["ignore_warnings", "clone", "hasattr", "set_random_state", "estimator.fit", "make_blobs", "_enforce_estimator_tags_X"], "code_location": {"file": "estimator_checks.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/utils", "start_line": 4049, "end_line": 4076}, "code_snippet": "def check_transformer_n_iter(name, estimator_orig):\n    # Test that transformers with a parameter max_iter, return the\n    # attribute of n_iter_ at least 1.\n    estimator = clone(estimator_orig)\n    if hasattr(estimator, \"max_iter\"):\n        if name in CROSS_DECOMPOSITION:\n            # Check using default data\n            X = [[0.0, 0.0, 1.0], [1.0, 0.0, 0.0], [2.0, 2.0, 2.0], [2.0, 5.0, 4.0]]\n            y_ = [[0.1, -0.2], [0.9, 1.1], [0.1, -0.5], [0.3, -0.2]]\n\n        else:\n            X, y_ = make_blobs(\n                n_samples=30,\n                centers=[[0, 0, 0], [1, 1, 1]],\n                random_state=0,\n                n_features=2,\n                cluster_std=0.1,\n            )\n            X = _enforce_estimator_tags_X(estimator_orig, X)\n        set_random_state(estimator, 0)\n        estimator.fit(X, y_)\n\n        # These return a n_iter per component.\n        if name in CROSS_DECOMPOSITION:\n            for iter_ in estimator.n_iter_:\n                assert iter_ >= 1\n        else:\n            assert estimator.n_iter_ >= 1\n", "type": "function"}, {"name": "test_composite_fit", "is_method": false, "class_name": null, "parameters": ["classification_dataset"], "calls": ["fit", "FrozenEstimator", "pytest.raises", "frozen.fit_predict", "pytest.raises", "frozen.fit_transform", "Estimator"], "code_location": {"file": "test_frozen.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/frozen/tests", "start_line": 135, "end_line": 163}, "code_snippet": "def test_composite_fit(classification_dataset):\n    \"\"\"Test that calling fit_transform and fit_predict doesn't call fit.\"\"\"\n\n    class Estimator(BaseEstimator):\n        def fit(self, X, y):\n            try:\n                self._fit_counter += 1\n            except AttributeError:\n                self._fit_counter = 1\n            return self\n\n        def fit_transform(self, X, y=None):\n            # only here to test that it doesn't get called\n            ...  # pragma: no cover\n\n        def fit_predict(self, X, y=None):\n            # only here to test that it doesn't get called\n            ...  # pragma: no cover\n\n    X, y = classification_dataset\n    est = Estimator().fit(X, y)\n    frozen = FrozenEstimator(est)\n\n    with pytest.raises(AttributeError):\n        frozen.fit_predict(X, y)\n    with pytest.raises(AttributeError):\n        frozen.fit_transform(X, y)\n\n    assert frozen._fit_counter == 1\n", "type": "function"}, {"name": "fit", "is_method": true, "class_name": "DummyTransformer", "parameters": ["self", "X", "y"], "calls": [], "code_location": {"file": "test_target.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/compose/tests", "start_line": 324, "end_line": 326}, "code_snippet": "    def fit(self, X, y=None):\n        self.fit_counter += 1\n        return self\n", "type": "function"}, {"name": "test_feature_union_fit_params", "is_method": false, "class_name": null, "parameters": [], "calls": ["FeatureUnion", "t.fit", "t.fit_transform", "pytest.raises", "t.fit", "pytest.raises", "t.fit_transform", "DummyTransformer", "DummyTransformer"], "code_location": {"file": "test_pipeline.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/tests", "start_line": 1643, "end_line": 1663}, "code_snippet": "def test_feature_union_fit_params():\n    # Regression test for issue: #15117\n    class DummyTransformer(TransformerMixin, BaseEstimator):\n        def fit(self, X, y=None, **fit_params):\n            if fit_params != {\"a\": 0}:\n                raise ValueError\n            return self\n\n        def transform(self, X, y=None):\n            return X\n\n    X, y = iris.data, iris.target\n    t = FeatureUnion([(\"dummy0\", DummyTransformer()), (\"dummy1\", DummyTransformer())])\n    with pytest.raises(ValueError):\n        t.fit(X, y)\n\n    with pytest.raises(ValueError):\n        t.fit_transform(X, y)\n\n    t.fit(X, y, a=0)\n    t.fit_transform(X, y, a=0)\n", "type": "function"}, {"name": "_check_transformer", "is_method": false, "class_name": null, "parameters": ["name", "transformer_orig", "X", "y"], "calls": ["clone", "set_random_state", "transformer.fit", "clone", "transformer_clone.fit_transform", "isinstance", "hasattr", "np.asarray", "isinstance", "_NotAnArray", "transformer.transform", "transformer.fit_transform", "transformer.transform", "transformer.fit_transform", "get_tags", "SkipTest", "isinstance", "isinstance", "zip", "assert_allclose_dense_sparse", "assert_allclose_dense_sparse", "hasattr", "np.asarray", "np.asarray", "assert_allclose_dense_sparse", "assert_allclose_dense_sparse", "_num_samples", "_num_samples", "get_tags", "raises", "transformer.transform"], "code_location": {"file": "estimator_checks.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/utils", "start_line": 2048, "end_line": 2136}, "code_snippet": "def _check_transformer(name, transformer_orig, X, y):\n    n_samples, n_features = np.asarray(X).shape\n    transformer = clone(transformer_orig)\n    set_random_state(transformer)\n\n    # fit\n\n    if name in CROSS_DECOMPOSITION:\n        y_ = np.c_[np.asarray(y), np.asarray(y)]\n        y_[::2, 1] *= 2\n        if isinstance(X, _NotAnArray):\n            y_ = _NotAnArray(y_)\n    else:\n        y_ = y\n\n    transformer.fit(X, y_)\n    # fit_transform method should work on non fitted estimator\n    transformer_clone = clone(transformer)\n    X_pred = transformer_clone.fit_transform(X, y=y_)\n\n    if isinstance(X_pred, tuple):\n        for x_pred in X_pred:\n            assert x_pred.shape[0] == n_samples\n    else:\n        # check for consistent n_samples\n        assert X_pred.shape[0] == n_samples\n\n    if hasattr(transformer, \"transform\"):\n        if name in CROSS_DECOMPOSITION:\n            X_pred2 = transformer.transform(X, y_)\n            X_pred3 = transformer.fit_transform(X, y=y_)\n        else:\n            X_pred2 = transformer.transform(X)\n            X_pred3 = transformer.fit_transform(X, y=y_)\n\n        if get_tags(transformer_orig).non_deterministic:\n            msg = name + \" is non deterministic\"\n            raise SkipTest(msg)\n        if isinstance(X_pred, tuple) and isinstance(X_pred2, tuple):\n            for x_pred, x_pred2, x_pred3 in zip(X_pred, X_pred2, X_pred3):\n                assert_allclose_dense_sparse(\n                    x_pred,\n                    x_pred2,\n                    atol=1e-2,\n                    err_msg=\"fit_transform and transform outcomes not consistent in %s\"\n                    % transformer,\n                )\n                assert_allclose_dense_sparse(\n                    x_pred,\n                    x_pred3,\n                    atol=1e-2,\n                    err_msg=\"consecutive fit_transform outcomes not consistent in %s\"\n                    % transformer,\n                )\n        else:\n            assert_allclose_dense_sparse(\n                X_pred,\n                X_pred2,\n                err_msg=\"fit_transform and transform outcomes not consistent in %s\"\n                % transformer,\n                atol=1e-2,\n            )\n            assert_allclose_dense_sparse(\n                X_pred,\n                X_pred3,\n                atol=1e-2,\n                err_msg=\"consecutive fit_transform outcomes not consistent in %s\"\n                % transformer,\n            )\n            assert _num_samples(X_pred2) == n_samples\n            assert _num_samples(X_pred3) == n_samples\n\n        # raises error on malformed input for transform\n        if (\n            hasattr(X, \"shape\")\n            and get_tags(transformer).requires_fit\n            and X.ndim == 2\n            and X.shape[1] > 1\n        ):\n            # If it's not an array, it does not have a 'T' property\n            with raises(\n                ValueError,\n                err_msg=(\n                    f\"The transformer {name} does not raise an error \"\n                    \"when the number of features in transform is different from \"\n                    \"the number of features in fit.\"\n                ),\n            ):\n                transformer.transform(X[:, :-1])\n", "type": "function"}, {"name": "check_non_transformer_estimators_n_iter", "is_method": false, "class_name": null, "parameters": ["name", "estimator_orig"], "calls": ["ignore_warnings", "clone", "load_iris", "_enforce_estimator_tags_y", "set_random_state", "_enforce_estimator_tags_X", "estimator.fit", "np.all", "hasattr", "np.asarray"], "code_location": {"file": "estimator_checks.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/utils", "start_line": 4025, "end_line": 4045}, "code_snippet": "def check_non_transformer_estimators_n_iter(name, estimator_orig):\n    # Test that estimators that are not transformers with a parameter\n    # max_iter, return the attribute of n_iter_ at least 1.\n\n    if not hasattr(estimator_orig, \"max_iter\"):\n        return\n\n    estimator = clone(estimator_orig)\n    iris = load_iris()\n    X, y_ = iris.data, iris.target\n    y_ = _enforce_estimator_tags_y(estimator, y_)\n    set_random_state(estimator, 0)\n    X = _enforce_estimator_tags_X(estimator_orig, X)\n\n    estimator.fit(X, y_)\n\n    assert np.all(np.asarray(estimator.n_iter_) >= 1), (\n        \"Estimators with a `max_iter` parameter, should expose an `n_iter_` attribute,\"\n        \" indicating the number of iterations that were executed. The values in the \"\n        \"`n_iter_` attribute should be greater or equal to 1.\"\n    )\n", "type": "function"}], "retrieved_count": 10, "cost_time": 0.3439192771911621}
{"question": "Where does the control flow in _NotAnArray.__array_function__ determine whether a TypeError is raised versus a boolean value returned, and what is the data dependency between the func parameter's __name__ attribute and the exception handling path?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"name": "__array_function__", "is_method": true, "class_name": "_NotAnArray", "parameters": ["self", "func", "types", "args", "kwargs"], "calls": ["TypeError", "format"], "code_location": {"file": "estimator_checks.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/utils", "start_line": 951, "end_line": 954}, "code_snippet": "    def __array_function__(self, func, types, args, kwargs):\n        if func.__name__ == \"may_share_memory\":\n            return True\n        raise TypeError(\"Don't want to call array_function {}!\".format(func.__name__))\n", "type": "function"}, {"name": "test_not_an_array_array_function", "is_method": false, "class_name": null, "parameters": [], "calls": ["_NotAnArray", "np.may_share_memory", "np.ones", "raises", "np.sum"], "code_location": {"file": "test_estimator_checks.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/utils/tests", "start_line": 591, "end_line": 597}, "code_snippet": "def test_not_an_array_array_function():\n    not_array = _NotAnArray(np.ones(10))\n    msg = \"Don't want to call array_function sum!\"\n    with raises(TypeError, match=msg):\n        np.sum(not_array)\n    # always returns True\n    assert np.may_share_memory(not_array, None)\n", "type": "function"}, {"name": "_is_array_api_cls", "is_method": false, "class_name": null, "parameters": ["cls"], "calls": ["lru_cache", "_issubclass_fast", "_issubclass_fast", "_issubclass_fast", "_issubclass_fast", "_issubclass_fast", "_issubclass_fast", "_issubclass_fast"], "code_location": {"file": "_helpers.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/externals/array_api_compat/common", "start_line": 291, "end_line": 302}, "code_snippet": "def _is_array_api_cls(cls: type) -> bool:\n    return (\n        # TODO: drop support for numpy<2 which didn't have __array_namespace__\n        _issubclass_fast(cls, \"numpy\", \"ndarray\")\n        or _issubclass_fast(cls, \"numpy\", \"generic\")\n        or _issubclass_fast(cls, \"cupy\", \"ndarray\")\n        or _issubclass_fast(cls, \"torch\", \"Tensor\")\n        or _issubclass_fast(cls, \"dask.array\", \"Array\")\n        or _issubclass_fast(cls, \"sparse\", \"SparseArray\")\n        # TODO: drop support for jax<0.4.32 which didn't have __array_namespace__\n        or _issubclass_fast(cls, \"jax\", \"Array\")\n    )\n", "type": "function"}, {"name": "_is_xp_namespace", "is_method": false, "class_name": null, "parameters": ["xp", "name"], "calls": [], "code_location": {"file": "_array_api.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/utils", "start_line": 553, "end_line": 558}, "code_snippet": "def _is_xp_namespace(xp, name):\n    return xp.__name__ in (\n        name,\n        f\"array_api_compat.{name}\",\n        f\"sklearn.externals.array_api_compat.{name}\",\n    )\n", "type": "function"}, {"name": "is_numpy_array", "is_method": false, "class_name": null, "parameters": ["x"], "calls": ["cast", "type", "_issubclass_fast", "_issubclass_fast", "_is_jax_zero_gradient_array"], "code_location": {"file": "_helpers.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/externals/array_api_compat/common", "start_line": 98, "end_line": 124}, "code_snippet": "def is_numpy_array(x: object) -> TypeGuard[npt.NDArray[Any]]:\n    \"\"\"\n    Return True if `x` is a NumPy array.\n\n    This function does not import NumPy if it has not already been imported\n    and is therefore cheap to use.\n\n    This also returns True for `ndarray` subclasses and NumPy scalar objects.\n\n    See Also\n    --------\n\n    array_namespace\n    is_array_api_obj\n    is_cupy_array\n    is_torch_array\n    is_ndonnx_array\n    is_dask_array\n    is_jax_array\n    is_pydata_sparse_array\n    \"\"\"\n    # TODO: Should we reject ndarray subclasses?\n    cls = cast(Hashable, type(x))\n    return (\n        _issubclass_fast(cls, \"numpy\", \"ndarray\") \n        or _issubclass_fast(cls, \"numpy\", \"generic\")\n    ) and not _is_jax_zero_gradient_array(x)\n", "type": "function"}, {"name": "_is_writeable_cls", "is_method": false, "class_name": null, "parameters": ["cls"], "calls": ["lru_cache", "_is_array_api_cls", "_issubclass_fast", "_issubclass_fast", "_issubclass_fast"], "code_location": {"file": "_helpers.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/externals/array_api_compat/common", "start_line": 923, "end_line": 932}, "code_snippet": "def _is_writeable_cls(cls: type) -> bool | None:\n    if (\n        _issubclass_fast(cls, \"numpy\", \"generic\")\n        or _issubclass_fast(cls, \"jax\", \"Array\")\n        or _issubclass_fast(cls, \"sparse\", \"SparseArray\")\n    ):\n        return False\n    if _is_array_api_cls(cls):\n        return True\n    return None\n", "type": "function"}, {"name": "is_lazy_array", "is_method": false, "class_name": null, "parameters": ["x"], "calls": ["cast", "_is_lazy_cls", "size", "array_namespace", "xp.any", "type", "hasattr", "cast", "bool", "xp.reshape"], "code_location": {"file": "_helpers.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/externals/array_api_compat/common", "start_line": 973, "end_line": 1026}, "code_snippet": "def is_lazy_array(x: object) -> bool:\n    \"\"\"Return True if x is potentially a future or it may be otherwise impossible or\n    expensive to eagerly read its contents, regardless of their size, e.g. by\n    calling ``bool(x)`` or ``float(x)``.\n\n    Return False otherwise; e.g. ``bool(x)`` etc. is guaranteed to succeed and to be\n    cheap as long as the array has the right dtype and size.\n\n    Note\n    ----\n    This function errs on the side of caution for array types that may or may not be\n    lazy, e.g. JAX arrays, by always returning True for them.\n    \"\"\"\n    # **JAX note:** while it is possible to determine if you're inside or outside\n    # jax.jit by testing the subclass of a jax.Array object, as well as testing bool()\n    # as we do below for unknown arrays, this is not recommended by JAX best practices.\n\n    # **Dask note:** Dask eagerly computes the graph on __bool__, __float__, and so on.\n    # This behaviour, while impossible to change without breaking backwards\n    # compatibility, is highly detrimental to performance as the whole graph will end\n    # up being computed multiple times.\n\n    # Note: skipping reclassification of JAX zero gradient arrays, as one will\n    # exclusively get them once they leave a jax.grad JIT context.\n    cls = cast(Hashable, type(x))\n    res = _is_lazy_cls(cls)\n    if res is not None:\n        return res\n\n    if not hasattr(x, \"__array_namespace__\"):\n        return False\n\n    # Unknown Array API compatible object. Note that this test may have dire consequences\n    # in terms of performance, e.g. for a lazy object that eagerly computes the graph\n    # on __bool__ (dask is one such example, which however is special-cased above).\n\n    # Select a single point of the array\n    s = size(cast(\"HasShape[Collection[SupportsIndex | None]]\", x))\n    if s is None:\n        return True\n    xp = array_namespace(x)\n    if s > 1:\n        x = xp.reshape(x, (-1,))[0]\n    # Cast to dtype=bool and deal with size 0 arrays\n    x = xp.any(x)\n\n    try:\n        bool(x)\n        return False\n    # The Array API standard dictactes that __bool__ should raise TypeError if the\n    # output cannot be defined.\n    # Here we allow for it to raise arbitrary exceptions, e.g. like Dask does.\n    except Exception:\n        return True\n", "type": "function"}, {"name": "_modify_in_place_if_numpy", "is_method": false, "class_name": null, "parameters": ["xp", "func"], "calls": ["_is_numpy_namespace", "func", "func"], "code_location": {"file": "_array_api.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/utils", "start_line": 992, "end_line": 997}, "code_snippet": "def _modify_in_place_if_numpy(xp, func, *args, out=None, **kwargs):\n    if _is_numpy_namespace(xp):\n        func(*args, out=out, **kwargs)\n    else:\n        out = func(*args, **kwargs)\n    return out\n", "type": "function"}, {"name": "is_writeable_array", "is_method": false, "class_name": null, "parameters": ["x"], "calls": ["cast", "_issubclass_fast", "_is_writeable_cls", "hasattr", "type", "cast"], "code_location": {"file": "_helpers.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/externals/array_api_compat/common", "start_line": 935, "end_line": 951}, "code_snippet": "def is_writeable_array(x: object) -> bool:\n    \"\"\"\n    Return False if ``x.__setitem__`` is expected to raise; True otherwise.\n    Return False if `x` is not an array API compatible object.\n\n    Warning\n    -------\n    As there is no standard way to check if an array is writeable without actually\n    writing to it, this function blindly returns True for all unknown array types.\n    \"\"\"\n    cls = cast(Hashable, type(x))\n    if _issubclass_fast(cls, \"numpy\", \"ndarray\"):\n        return cast(\"npt.NDArray\", x).flags.writeable\n    res = _is_writeable_cls(cls)\n    if res is not None:\n        return res\n    return hasattr(x, '__array_namespace__')\n", "type": "function"}, {"name": "lazy_apply", "is_method": false, "class_name": null, "parameters": ["func"], "calls": ["is_dask_namespace", "ValueError", "array_namespace", "all", "len", "len", "ValueError", "array_namespace", "dask.delayed", "wrapped", "tuple", "broadcast_shapes", "list", "len", "list", "isinstance", "_lazy_apply_wrapper", "is_jax_namespace", "_is_jax_jit_enabled", "any", "_lazy_apply_wrapper", "cast", "_lazy_apply_wrapper", "wrapped", "is_python_scalar", "isinstance", "cast", "xp.result_type", "isinstance", "ValueError", "ValueError", "len", "len", "xp.from_delayed", "ValueError", "partial", "jax.pure_callback", "enumerate", "tuple", "tuple", "zip", "jax.ShapeDtypeStruct", "zip"], "code_location": {"file": "_lazy.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/externals/array_api_extra/_lib", "start_line": 57, "end_line": 297}, "code_snippet": "def lazy_apply(  # type: ignore[valid-type]  # numpydoc ignore=GL07,SA04\n    func: Callable[P, Array | ArrayLike | Sequence[Array | ArrayLike]],\n    *args: Array | complex | None,\n    shape: tuple[int | None, ...] | Sequence[tuple[int | None, ...]] | None = None,\n    dtype: DType | Sequence[DType] | None = None,\n    as_numpy: bool = False,\n    xp: ModuleType | None = None,\n    **kwargs: P.kwargs,  # pyright: ignore[reportGeneralTypeIssues]\n) -> Array | tuple[Array, ...]:\n    \"\"\"\n    Lazily apply an eager function.\n\n    If the backend of the input arrays is lazy, e.g. Dask or jitted JAX, the execution\n    of the function is delayed until the graph is materialized; if it's eager, the\n    function is executed immediately.\n\n    Parameters\n    ----------\n    func : callable\n        The function to apply.\n\n        It must accept one or more array API compliant arrays as positional arguments.\n        If `as_numpy=True`, inputs are converted to NumPy before they are passed to\n        `func`.\n        It must return either a single array-like or a sequence of array-likes.\n\n        `func` must be a pure function, i.e. without side effects, as depending on the\n        backend it may be executed more than once or never.\n    *args : Array | int | float | complex | bool | None\n        One or more Array API compliant arrays, Python scalars, or None's.\n\n        If `as_numpy=True`, you need to be able to apply :func:`numpy.asarray` to\n        non-None args to convert them to NumPy; read notes below about specific\n        backends.\n    shape : tuple[int | None, ...] | Sequence[tuple[int | None, ...]], optional\n        Output shape or sequence of output shapes, one for each output of `func`.\n        Default: assume single output and broadcast shapes of the input arrays.\n    dtype : DType | Sequence[DType], optional\n        Output dtype or sequence of output dtypes, one for each output of `func`.\n        dtype(s) must belong to the same array namespace as the input arrays.\n        Default: infer the result type(s) from the input arrays.\n    as_numpy : bool, optional\n        If True, convert the input arrays to NumPy before passing them to `func`.\n        This is particularly useful to make NumPy-only functions, e.g. written in Cython\n       or Numba, work transparently with array API-compliant arrays.\n        Default: False.\n    xp : array_namespace, optional\n        The standard-compatible namespace for `args`. Default: infer.\n    **kwargs : Any, optional\n        Additional keyword arguments to pass verbatim to `func`.\n        They cannot contain Array objects.\n\n    Returns\n    -------\n    Array | tuple[Array, ...]\n        The result(s) of `func` applied to the input arrays, wrapped in the same\n        array namespace as the inputs.\n        If shape is omitted or a single `tuple[int | None, ...]`, return a single array.\n        Otherwise, return a tuple of arrays.\n\n    Notes\n    -----\n    JAX\n        This allows applying eager functions to jitted JAX arrays, which are lazy.\n        The function won't be applied until the JAX array is materialized.\n        When running inside ``jax.jit``, `shape` must be fully known, i.e. it cannot\n        contain any `None` elements.\n\n        .. warning::\n\n            `func` must never raise inside ``jax.jit``, as the resulting behavior is\n            undefined.\n\n        Using this with `as_numpy=False` is particularly useful to apply non-jittable\n        JAX functions to arrays on GPU devices.\n        If ``as_numpy=True``, the :doc:`jax:transfer_guard` may prevent arrays on a GPU\n        device from being transferred back to CPU. This is treated as an implicit\n        transfer.\n\n    PyTorch, CuPy\n        If ``as_numpy=True``, these backends raise by default if you attempt to convert\n        arrays on a GPU device to NumPy.\n\n    Sparse\n        If ``as_numpy=True``, by default sparse prevents implicit densification through\n        :func:`numpy.asarray`. `This safety mechanism can be disabled\n        <https://sparse.pydata.org/en/stable/operations.html#package-configuration>`_.\n\n    Dask\n        This allows applying eager functions to Dask arrays.\n        The Dask graph won't be computed.\n\n        `lazy_apply` doesn't know if `func` reduces along any axes; also, shape\n        changes are non-trivial in chunked Dask arrays. For these reasons, all inputs\n        will be rechunked into a single chunk.\n\n        .. warning::\n\n           The whole operation needs to fit in memory all at once on a single worker.\n\n        The outputs will also be returned as a single chunk and you should consider\n        rechunking them into smaller chunks afterwards.\n\n        If you want to distribute the calculation across multiple workers, you\n        should use :func:`dask.array.map_blocks`, :func:`dask.array.map_overlap`,\n        :func:`dask.array.blockwise`, or a native Dask wrapper instead of\n        `lazy_apply`.\n\n    Dask wrapping around other backends\n        If ``as_numpy=False``, `func` will receive in input eager arrays of the meta\n        namespace, as defined by the ``._meta`` attribute of the input Dask arrays.\n        The outputs of `func` will be wrapped by the meta namespace, and then wrapped\n        again by Dask.\n\n    Raises\n    ------\n    ValueError\n        When ``xp=jax.numpy``, the output `shape` is unknown (it contains ``None`` on\n        one or more axes) and this function was called inside ``jax.jit``.\n    RuntimeError\n        When ``xp=sparse`` and auto-densification is disabled.\n    Exception (backend-specific)\n        When the backend disallows implicit device to host transfers and the input\n        arrays are on a non-CPU device, e.g. on GPU.\n\n    See Also\n    --------\n    jax.transfer_guard\n    jax.pure_callback\n    dask.array.map_blocks\n    dask.array.map_overlap\n    dask.array.blockwise\n    \"\"\"\n    args_not_none = [arg for arg in args if arg is not None]\n    array_args = [arg for arg in args_not_none if not is_python_scalar(arg)]\n    if not array_args:\n        msg = \"Must have at least one argument array\"\n        raise ValueError(msg)\n    if xp is None:\n        xp = array_namespace(*args)\n\n    # Normalize and validate shape and dtype\n    shapes: list[tuple[int | None, ...]]\n    dtypes: list[DType]\n    multi_output = False\n\n    if shape is None:\n        shapes = [broadcast_shapes(*(arg.shape for arg in array_args))]\n    elif all(isinstance(s, int | None) for s in shape):\n        # Do not test for shape to be a tuple\n        # https://github.com/data-apis/array-api/issues/891#issuecomment-2637430522\n        shapes = [cast(tuple[int | None, ...], shape)]\n    else:\n        shapes = list(shape)  # type: ignore[arg-type]  # pyright: ignore[reportAssignmentType]\n        multi_output = True\n\n    if dtype is None:\n        dtypes = [xp.result_type(*args_not_none)] * len(shapes)\n    elif multi_output:\n        if not isinstance(dtype, Sequence):\n            msg = \"Got multiple shapes but only one dtype\"\n            raise ValueError(msg)\n        dtypes = list(dtype)  # pyright: ignore[reportUnknownArgumentType]\n    else:\n        if isinstance(dtype, Sequence):\n            msg = \"Got single shape but multiple dtypes\"\n            raise ValueError(msg)\n\n        dtypes = [dtype]\n\n    if len(shapes) != len(dtypes):\n        msg = f\"Got {len(shapes)} shapes and {len(dtypes)} dtypes\"\n        raise ValueError(msg)\n    del shape\n    del dtype\n    # End of shape and dtype parsing\n\n    # Backend-specific branches\n    if is_dask_namespace(xp):\n        import dask\n\n        metas: list[Array] = [arg._meta for arg in array_args]  # pylint: disable=protected-access    # pyright: ignore[reportAttributeAccessIssue]\n        meta_xp = array_namespace(*metas)\n\n        wrapped = dask.delayed(  # type: ignore[attr-defined]  # pyright: ignore[reportPrivateImportUsage]\n            _lazy_apply_wrapper(func, as_numpy, multi_output, meta_xp),\n            pure=True,\n        )\n        # This finalizes each arg, which is the same as arg.rechunk(-1).\n        # Please read docstring above for why we're not using\n        # dask.array.map_blocks or dask.array.blockwise!\n        delayed_out = wrapped(*args, **kwargs)\n\n        out = tuple(\n            xp.from_delayed(\n                delayed_out[i],  # pyright: ignore[reportIndexIssue]\n                # Dask's unknown shapes diverge from the Array API specification\n                shape=tuple(math.nan if s is None else s for s in shape),\n                dtype=dtype,\n                meta=metas[0],\n            )\n            for i, (shape, dtype) in enumerate(zip(shapes, dtypes, strict=True))\n        )\n\n    elif is_jax_namespace(xp) and _is_jax_jit_enabled(xp):\n        # Delay calling func with jax.pure_callback, which will forward to func eager\n        # JAX arrays. Do not use jax.pure_callback when running outside of the JIT,\n        # as it does not support raising exceptions:\n        # https://github.com/jax-ml/jax/issues/26102\n        import jax\n\n        if any(None in shape for shape in shapes):\n            msg = \"Output shape must be fully known when running inside jax.jit\"\n            raise ValueError(msg)\n\n        # Shield kwargs from being coerced into JAX arrays.\n        # jax.pure_callback calls jax.jit under the hood, but without the chance of\n        # passing static_argnames / static_argnums.\n        wrapped = _lazy_apply_wrapper(\n            partial(func, **kwargs), as_numpy, multi_output, xp\n        )\n\n        # suppress unused-ignore to run mypy in -e lint as well as -e dev\n        out = cast(  # type: ignore[bad-cast,unused-ignore]\n            tuple[Array, ...],\n            jax.pure_callback(\n                wrapped,\n                tuple(\n                    jax.ShapeDtypeStruct(shape, dtype)  # pyright: ignore[reportUnknownArgumentType]\n                    for shape, dtype in zip(shapes, dtypes, strict=True)\n                ),\n                *args,\n            ),\n        )\n\n    else:\n        # Eager backends, including non-jitted JAX\n        wrapped = _lazy_apply_wrapper(func, as_numpy, multi_output, xp)\n        out = wrapped(*args, **kwargs)\n\n    return out if multi_output else out[0]\n", "type": "function"}], "retrieved_count": 10, "cost_time": 0.34206700325012207}
{"question": "Where in the codebase are the lower-level helper functions that _SetOutputMixin delegates to in order to wrap the tuple output returned by EstimatorReturnTuple's transform method?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"name": "_SetOutputMixin", "docstring": "Mixin that dynamically wraps methods to return container based on config.\n\nCurrently `_SetOutputMixin` wraps `transform` and `fit_transform` and configures\nit based on `set_output` of the global configuration.\n\n`set_output` is only defined if `get_feature_names_out` is defined and\n`auto_wrap_output_keys` is the default value.", "methods": ["__init_subclass__", "set_output"], "attributes": [], "code_location": {"file": "_set_output.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/utils", "start_line": 347, "end_line": 421}, "type": "class"}, {"name": "EstimatorReturnTuple", "docstring": "", "methods": ["__init__", "transform"], "attributes": [], "code_location": {"file": "test_set_output.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/utils/tests", "start_line": 391, "end_line": 396}, "type": "class"}, {"name": "EstimatorWithSetOutputNoAutoWrap", "docstring": "", "methods": ["transform"], "attributes": [], "code_location": {"file": "test_set_output.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/utils/tests", "start_line": 295, "end_line": 297}, "type": "class"}, {"name": "EstimatorWithSetOutput", "docstring": "", "methods": ["fit", "transform", "get_feature_names_out"], "attributes": [], "code_location": {"file": "test_set_output.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/utils/tests", "start_line": 167, "end_line": 176}, "type": "class"}, {"name": "EstimatorNoSetOutputWithTransform", "docstring": "", "methods": ["transform"], "attributes": [], "code_location": {"file": "test_set_output.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/utils/tests", "start_line": 162, "end_line": 164}, "type": "class"}, {"name": "_wrap_method_output", "is_method": false, "class_name": null, "parameters": ["f", "method"], "calls": ["wraps", "f", "isinstance", "_wrap_data_with_container", "hasattr", "_wrap_data_with_container", "type", "_make", "type"], "code_location": {"file": "_set_output.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/utils", "start_line": 311, "end_line": 331}, "code_snippet": "def _wrap_method_output(f, method):\n    \"\"\"Wrapper used by `_SetOutputMixin` to automatically wrap methods.\"\"\"\n\n    @wraps(f)\n    def wrapped(self, X, *args, **kwargs):\n        data_to_wrap = f(self, X, *args, **kwargs)\n        if isinstance(data_to_wrap, tuple):\n            # only wrap the first output for cross decomposition\n            return_tuple = (\n                _wrap_data_with_container(method, data_to_wrap[0], X, self),\n                *data_to_wrap[1:],\n            )\n            # Support for namedtuples `_make` is a documented API for namedtuples:\n            # https://docs.python.org/3/library/collections.html#collections.somenamedtuple._make\n            if hasattr(type(data_to_wrap), \"_make\"):\n                return type(data_to_wrap)._make(return_tuple)\n            return return_tuple\n\n        return _wrap_data_with_container(method, data_to_wrap, X, self)\n\n    return wrapped\n", "type": "function"}, {"name": "EstimatorWithSetOutputIndex", "docstring": "", "methods": ["fit", "transform", "get_feature_names_out"], "attributes": [], "code_location": {"file": "test_set_output.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/utils/tests", "start_line": 361, "end_line": 373}, "type": "class"}, {"name": "test_set_output_mixin", "is_method": false, "class_name": null, "parameters": [], "calls": ["EstimatorNoSetOutputWithTransformNoFeatureNamesOut", "hasattr"], "code_location": {"file": "test_set_output.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/utils/tests", "start_line": 211, "end_line": 214}, "code_snippet": "def test_set_output_mixin():\n    \"\"\"Estimator without get_feature_names_out does not define `set_output`.\"\"\"\n    est = EstimatorNoSetOutputWithTransformNoFeatureNamesOut()\n    assert not hasattr(est, \"set_output\")\n", "type": "function"}, {"name": "__init_subclass__", "is_method": true, "class_name": "_SetOutputMixin", "parameters": ["cls", "auto_wrap_output_keys"], "calls": ["__init_subclass__", "set", "method_to_key.items", "ValueError", "set", "cls._sklearn_auto_wrap_output_keys.add", "_wrap_method_output", "setattr", "super", "isinstance", "getattr", "hasattr"], "code_location": {"file": "_set_output.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/utils", "start_line": 357, "end_line": 387}, "code_snippet": "    def __init_subclass__(cls, auto_wrap_output_keys=(\"transform\",), **kwargs):\n        super().__init_subclass__(**kwargs)\n\n        # Dynamically wraps `transform` and `fit_transform` and configure it's\n        # output based on `set_output`.\n        if not (\n            isinstance(auto_wrap_output_keys, tuple) or auto_wrap_output_keys is None\n        ):\n            raise ValueError(\"auto_wrap_output_keys must be None or a tuple of keys.\")\n\n        if auto_wrap_output_keys is None:\n            cls._sklearn_auto_wrap_output_keys = set()\n            return\n\n        # Mapping from method to key in configurations\n        method_to_key = {\n            \"transform\": \"transform\",\n            \"fit_transform\": \"transform\",\n        }\n        cls._sklearn_auto_wrap_output_keys = set()\n\n        for method, key in method_to_key.items():\n            if not hasattr(cls, method) or key not in auto_wrap_output_keys:\n                continue\n            cls._sklearn_auto_wrap_output_keys.add(key)\n\n            # Only wrap methods defined by cls itself\n            if method not in cls.__dict__:\n                continue\n            wrapped_method = _wrap_method_output(getattr(cls, method), key)\n            setattr(cls, method, wrapped_method)\n", "type": "function"}, {"name": "test_set_output_transform_configured", "is_method": false, "class_name": null, "parameters": ["estimator", "check_func"], "calls": ["pytest.mark.parametrize", "pytest.mark.parametrize", "hasattr", "pytest.skip", "ignore_warnings", "check_func"], "code_location": {"file": "test_common.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/tests", "start_line": 372, "end_line": 380}, "code_snippet": "def test_set_output_transform_configured(estimator, check_func):\n    name = estimator.__class__.__name__\n    if not hasattr(estimator, \"set_output\"):\n        pytest.skip(\n            f\"Skipping {check_func.__name__} for {name}: Does not support\"\n            \" set_output API yet\"\n        )\n    with ignore_warnings(category=(FutureWarning)):\n        check_func(estimator.__class__.__name__, estimator)\n", "type": "function"}], "retrieved_count": 10, "cost_time": 0.351945161819458}
{"question": "Why does the test_minibatch_nmf_transform function require the fresh_restarts parameter to be set to True to guarantee equivalence between fit_transform and transform outputs, and what underlying algorithmic behavior would be violated if this constraint were removed?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"name": "test_minibatch_nmf_transform", "is_method": false, "class_name": null, "parameters": [], "calls": ["np.random.mtrand.RandomState", "np.abs", "MiniBatchNMF", "m.fit_transform", "m.transform", "assert_allclose", "rng.randn"], "code_location": {"file": "test_nmf.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/decomposition/tests", "start_line": 217, "end_line": 230}, "code_snippet": "def test_minibatch_nmf_transform():\n    # Test that fit_transform is equivalent to fit.transform for MiniBatchNMF\n    # Only guaranteed with fresh restarts\n    rng = np.random.mtrand.RandomState(42)\n    A = np.abs(rng.randn(6, 5))\n    m = MiniBatchNMF(\n        n_components=3,\n        random_state=0,\n        tol=1e-3,\n        fresh_restarts=True,\n    )\n    ft = m.fit_transform(A)\n    t = m.transform(A)\n    assert_allclose(ft, t)\n", "type": "function"}, {"name": "test_mbnmf_inverse_transform", "is_method": false, "class_name": null, "parameters": [], "calls": ["np.random.RandomState", "np.abs", "MiniBatchNMF", "nmf.fit_transform", "nmf.inverse_transform", "assert_allclose", "rng.randn"], "code_location": {"file": "test_nmf.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/decomposition/tests", "start_line": 270, "end_line": 283}, "code_snippet": "def test_mbnmf_inverse_transform():\n    # Test that MiniBatchNMF.transform followed by MiniBatchNMF.inverse_transform\n    # is close to the identity\n    rng = np.random.RandomState(0)\n    A = np.abs(rng.randn(6, 4))\n    nmf = MiniBatchNMF(\n        random_state=rng,\n        max_iter=500,\n        init=\"nndsvdar\",\n        fresh_restarts=True,\n    )\n    ft = nmf.fit_transform(A)\n    A_new = nmf.inverse_transform(ft)\n    assert_allclose(A, A_new, rtol=1e-3, atol=1e-2)\n", "type": "function"}, {"name": "test_minibatch_nmf_partial_fit", "is_method": false, "class_name": null, "parameters": [], "calls": ["np.random.mtrand.RandomState", "np.abs", "MiniBatchNMF", "MiniBatchNMF", "nmf._initialize_nmf", "mbnmf1.fit", "range", "assert_allclose", "rng.randn", "range", "mbnmf2.partial_fit"], "code_location": {"file": "test_nmf.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/decomposition/tests", "start_line": 864, "end_line": 896}, "code_snippet": "def test_minibatch_nmf_partial_fit():\n    # Check fit / partial_fit equivalence. Applicable only with fresh restarts.\n    rng = np.random.mtrand.RandomState(42)\n    X = np.abs(rng.randn(100, 5))\n\n    n_components = 5\n    batch_size = 10\n    max_iter = 2\n\n    mbnmf1 = MiniBatchNMF(\n        n_components=n_components,\n        init=\"custom\",\n        random_state=0,\n        max_iter=max_iter,\n        batch_size=batch_size,\n        tol=0,\n        max_no_improvement=None,\n        fresh_restarts=False,\n    )\n    mbnmf2 = MiniBatchNMF(n_components=n_components, init=\"custom\", random_state=0)\n\n    # Force the same init of H (W is recomputed anyway) to be able to compare results.\n    W, H = nmf._initialize_nmf(\n        X, n_components=n_components, init=\"random\", random_state=0\n    )\n\n    mbnmf1.fit(X, W=W, H=H)\n    for i in range(max_iter):\n        for j in range(batch_size):\n            mbnmf2.partial_fit(X[j : j + batch_size], W=W[:batch_size], H=H)\n\n    assert mbnmf1.n_steps_ == mbnmf2.n_steps_\n    assert_allclose(mbnmf1.components_, mbnmf2.components_)\n", "type": "function"}, {"name": "test_nmf_minibatchnmf_equivalence", "is_method": false, "class_name": null, "parameters": ["beta_loss"], "calls": ["pytest.mark.parametrize", "np.random.mtrand.RandomState", "np.abs", "NMF", "MiniBatchNMF", "nmf.fit_transform", "mbnmf.fit_transform", "assert_allclose", "rng.randn"], "code_location": {"file": "test_nmf.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/decomposition/tests", "start_line": 837, "end_line": 861}, "code_snippet": "def test_nmf_minibatchnmf_equivalence(beta_loss):\n    # Test that MiniBatchNMF is equivalent to NMF when batch_size = n_samples and\n    # forget_factor 0.0 (stopping criterion put aside)\n    rng = np.random.mtrand.RandomState(42)\n    X = np.abs(rng.randn(48, 5))\n\n    nmf = NMF(\n        n_components=5,\n        beta_loss=beta_loss,\n        solver=\"mu\",\n        random_state=0,\n        tol=0,\n    )\n    mbnmf = MiniBatchNMF(\n        n_components=5,\n        beta_loss=beta_loss,\n        random_state=0,\n        tol=0,\n        max_no_improvement=None,\n        batch_size=X.shape[0],\n        forget_factor=0.0,\n    )\n    W = nmf.fit_transform(X)\n    mbW = mbnmf.fit_transform(X)\n    assert_allclose(W, mbW)\n", "type": "function"}, {"name": "test_nmf_transform", "is_method": false, "class_name": null, "parameters": ["solver"], "calls": ["pytest.mark.parametrize", "np.random.mtrand.RandomState", "np.abs", "NMF", "m.fit_transform", "m.transform", "assert_allclose", "rng.randn"], "code_location": {"file": "test_nmf.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/decomposition/tests", "start_line": 200, "end_line": 214}, "code_snippet": "def test_nmf_transform(solver):\n    # Test that fit_transform is equivalent to fit.transform for NMF\n    # Test that NMF.transform returns close values\n    rng = np.random.mtrand.RandomState(42)\n    A = np.abs(rng.randn(6, 5))\n    m = NMF(\n        solver=solver,\n        n_components=3,\n        init=\"random\",\n        random_state=0,\n        tol=1e-6,\n    )\n    ft = m.fit_transform(A)\n    t = m.transform(A)\n    assert_allclose(ft, t, atol=1e-1)\n", "type": "function"}, {"name": "_fit_transform", "is_method": true, "class_name": "MiniBatchNMF", "parameters": ["self", "X", "W", "H", "update_H"], "calls": ["check_non_negative", "self._check_params", "self._check_w_h", "H.copy", "H.copy", "np.ones", "gen_batches", "itertools.cycle", "int", "zip", "int", "ValueError", "np.ceil", "range", "self._minibatch_step", "self._solve_W", "np.ceil", "warnings.warn", "X.min", "self._minibatch_convergence"], "code_location": {"file": "_nmf.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/decomposition", "start_line": 2219, "end_line": 2314}, "code_snippet": "    def _fit_transform(self, X, W=None, H=None, update_H=True):\n        \"\"\"Learn a NMF model for the data X and returns the transformed data.\n\n        Parameters\n        ----------\n        X : {ndarray, sparse matrix} of shape (n_samples, n_features)\n            Data matrix to be decomposed.\n\n        W : array-like of shape (n_samples, n_components), default=None\n            If `init='custom'`, it is used as initial guess for the solution.\n            If `update_H=False`, it is initialised as an array of zeros, unless\n            `solver='mu'`, then it is filled with values calculated by\n            `np.sqrt(X.mean() / self._n_components)`.\n            If `None`, uses the initialisation method specified in `init`.\n\n        H : array-like of shape (n_components, n_features), default=None\n            If `init='custom'`, it is used as initial guess for the solution.\n            If `update_H=False`, it is used as a constant, to solve for W only.\n            If `None`, uses the initialisation method specified in `init`.\n\n        update_H : bool, default=True\n            If True, both W and H will be estimated from initial guesses,\n            this corresponds to a call to the `fit_transform` method.\n            If False, only W will be estimated, this corresponds to a call\n            to the `transform` method.\n\n        Returns\n        -------\n        W : ndarray of shape (n_samples, n_components)\n            Transformed data.\n\n        H : ndarray of shape (n_components, n_features)\n            Factorization matrix, sometimes called 'dictionary'.\n\n        n_iter : int\n            Actual number of started iterations over the whole dataset.\n\n        n_steps : int\n            Number of mini-batches processed.\n        \"\"\"\n        check_non_negative(X, \"MiniBatchNMF (input X)\")\n        self._check_params(X)\n\n        if X.min() == 0 and self._beta_loss <= 0:\n            raise ValueError(\n                \"When beta_loss <= 0 and X contains zeros, \"\n                \"the solver may diverge. Please add small values \"\n                \"to X, or use a positive beta_loss.\"\n            )\n\n        n_samples = X.shape[0]\n\n        # initialize or check W and H\n        W, H = self._check_w_h(X, W, H, update_H)\n        H_buffer = H.copy()\n\n        # Initialize auxiliary matrices\n        self._components_numerator = H.copy()\n        self._components_denominator = np.ones(H.shape, dtype=H.dtype)\n\n        # Attributes to monitor the convergence\n        self._ewa_cost = None\n        self._ewa_cost_min = None\n        self._no_improvement = 0\n\n        batches = gen_batches(n_samples, self._batch_size)\n        batches = itertools.cycle(batches)\n        n_steps_per_iter = int(np.ceil(n_samples / self._batch_size))\n        n_steps = self.max_iter * n_steps_per_iter\n\n        for i, batch in zip(range(n_steps), batches):\n            batch_cost = self._minibatch_step(X[batch], W[batch], H, update_H)\n\n            if update_H and self._minibatch_convergence(\n                X[batch], batch_cost, H, H_buffer, n_samples, i, n_steps\n            ):\n                break\n\n            H_buffer[:] = H\n\n        if self.fresh_restarts:\n            W = self._solve_W(X, H, self._transform_max_iter)\n\n        n_steps = i + 1\n        n_iter = int(np.ceil(n_steps / n_steps_per_iter))\n\n        if n_iter == self.max_iter and self.tol > 0:\n            warnings.warn(\n                (\n                    f\"Maximum number of iterations {self.max_iter} reached. \"\n                    \"Increase it to improve convergence.\"\n                ),\n                ConvergenceWarning,\n            )\n\n        return W, H, n_iter, n_steps\n", "type": "function"}, {"name": "test_non_negative_factorization_consistency", "is_method": false, "class_name": null, "parameters": ["init", "solver", "alpha_W", "alpha_H"], "calls": ["pytest.mark.parametrize", "pytest.mark.parametrize", "pytest.mark.parametrize", "pytest.mark.parametrize", "np.random.mtrand.RandomState", "np.abs", "non_negative_factorization", "non_negative_factorization", "NMF", "model_class.fit_transform", "model_class.transform", "assert_allclose", "assert_allclose", "rng.randn", "np.arange"], "code_location": {"file": "test_nmf.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/decomposition/tests", "start_line": 351, "end_line": 395}, "code_snippet": "def test_non_negative_factorization_consistency(init, solver, alpha_W, alpha_H):\n    # Test that the function is called in the same way, either directly\n    # or through the NMF class\n    max_iter = 500\n    rng = np.random.mtrand.RandomState(42)\n    A = np.abs(rng.randn(10, 10))\n    A[:, 2 * np.arange(5)] = 0\n\n    W_nmf, H, _ = non_negative_factorization(\n        A,\n        init=init,\n        solver=solver,\n        max_iter=max_iter,\n        alpha_W=alpha_W,\n        alpha_H=alpha_H,\n        random_state=1,\n        tol=1e-2,\n    )\n    W_nmf_2, H, _ = non_negative_factorization(\n        A,\n        H=H,\n        update_H=False,\n        init=init,\n        solver=solver,\n        max_iter=max_iter,\n        alpha_W=alpha_W,\n        alpha_H=alpha_H,\n        random_state=1,\n        tol=1e-2,\n    )\n\n    model_class = NMF(\n        init=init,\n        solver=solver,\n        max_iter=max_iter,\n        alpha_W=alpha_W,\n        alpha_H=alpha_H,\n        random_state=1,\n        tol=1e-2,\n    )\n    W_cls = model_class.fit_transform(A)\n    W_cls_2 = model_class.transform(A)\n\n    assert_allclose(W_nmf, W_cls)\n    assert_allclose(W_nmf_2, W_cls_2)\n", "type": "function"}, {"name": "test_nmf_transform_custom_init", "is_method": false, "class_name": null, "parameters": ["Estimator", "solver"], "calls": ["pytest.mark.parametrize", "np.random.RandomState", "np.abs", "np.sqrt", "np.abs", "np.abs", "Estimator", "m.fit_transform", "m.transform", "random_state.randn", "A.mean", "random_state.randn", "random_state.randn"], "code_location": {"file": "test_nmf.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/decomposition/tests", "start_line": 237, "end_line": 250}, "code_snippet": "def test_nmf_transform_custom_init(Estimator, solver):\n    # Smoke test that checks if NMF.transform works with custom initialization\n    random_state = np.random.RandomState(0)\n    A = np.abs(random_state.randn(6, 5))\n    n_components = 4\n    avg = np.sqrt(A.mean() / n_components)\n    H_init = np.abs(avg * random_state.randn(n_components, 5))\n    W_init = np.abs(avg * random_state.randn(6, n_components))\n\n    m = Estimator(\n        n_components=n_components, init=\"custom\", random_state=0, tol=1e-3, **solver\n    )\n    m.fit_transform(A, W=W_init, H=H_init)\n    m.transform(A)\n", "type": "function"}, {"name": "test_nmf_true_reconstruction", "is_method": false, "class_name": null, "parameters": [], "calls": ["np.random.mtrand.RandomState", "np.zeros", "np.abs", "range", "np.zeros", "np.abs", "range", "np.dot", "NMF", "model.fit_transform", "np.dot", "assert_allclose", "MiniBatchNMF", "mbmodel.fit_transform", "np.dot", "assert_allclose", "rng.randn", "rng.randn"], "code_location": {"file": "test_nmf.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/decomposition/tests", "start_line": 151, "end_line": 196}, "code_snippet": "def test_nmf_true_reconstruction():\n    # Test that the fit is not too far away from an exact solution\n    # (by construction)\n    n_samples = 15\n    n_features = 10\n    n_components = 5\n    beta_loss = 1\n    batch_size = 3\n    max_iter = 1000\n\n    rng = np.random.mtrand.RandomState(42)\n    W_true = np.zeros([n_samples, n_components])\n    W_array = np.abs(rng.randn(n_samples))\n    for j in range(n_components):\n        W_true[j % n_samples, j] = W_array[j % n_samples]\n    H_true = np.zeros([n_components, n_features])\n    H_array = np.abs(rng.randn(n_components))\n    for j in range(n_features):\n        H_true[j % n_components, j] = H_array[j % n_components]\n    X = np.dot(W_true, H_true)\n\n    model = NMF(\n        n_components=n_components,\n        solver=\"mu\",\n        beta_loss=beta_loss,\n        max_iter=max_iter,\n        random_state=0,\n    )\n    transf = model.fit_transform(X)\n    X_calc = np.dot(transf, model.components_)\n\n    assert model.reconstruction_err_ < 0.1\n    assert_allclose(X, X_calc)\n\n    mbmodel = MiniBatchNMF(\n        n_components=n_components,\n        beta_loss=beta_loss,\n        batch_size=batch_size,\n        random_state=0,\n        max_iter=max_iter,\n    )\n    transf = mbmodel.fit_transform(X)\n    X_calc = np.dot(transf, mbmodel.components_)\n\n    assert mbmodel.reconstruction_err_ < 0.1\n    assert_allclose(X, X_calc, atol=1)\n", "type": "function"}, {"name": "test_nmf_inverse_transform", "is_method": false, "class_name": null, "parameters": ["solver"], "calls": ["pytest.mark.parametrize", "np.random.RandomState", "np.abs", "NMF", "m.fit_transform", "m.inverse_transform", "assert_array_almost_equal", "random_state.randn"], "code_location": {"file": "test_nmf.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/decomposition/tests", "start_line": 254, "end_line": 267}, "code_snippet": "def test_nmf_inverse_transform(solver):\n    # Test that NMF.inverse_transform returns close values\n    random_state = np.random.RandomState(0)\n    A = np.abs(random_state.randn(6, 4))\n    m = NMF(\n        solver=solver,\n        n_components=4,\n        init=\"random\",\n        random_state=0,\n        max_iter=1000,\n    )\n    ft = m.fit_transform(A)\n    A_new = m.inverse_transform(ft)\n    assert_array_almost_equal(A, A_new, decimal=2)\n", "type": "function"}], "retrieved_count": 10, "cost_time": 0.33557629585266113}
{"question": "Where does the `set_params` method in `_BaseHeterogeneousEnsemble` delegate parameter setting to its parent class, and what is the control flow path that determines whether individual estimators are modified, replaced, or dropped based on the 'drop' sentinel value?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"name": "set_params", "is_method": true, "class_name": "_BaseHeterogeneousEnsemble", "parameters": ["self"], "calls": ["_set_params", "super"], "code_location": {"file": "_base.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/ensemble", "start_line": 251, "end_line": 274}, "code_snippet": "    def set_params(self, **params):\n        \"\"\"\n        Set the parameters of an estimator from the ensemble.\n\n        Valid parameter keys can be listed with `get_params()`. Note that you\n        can directly set the parameters of the estimators contained in\n        `estimators`.\n\n        Parameters\n        ----------\n        **params : keyword arguments\n            Specific parameters using e.g.\n            `set_params(parameter_name=new_value)`. In addition, to setting the\n            parameters of the estimator, the individual estimator of the\n            estimators can also be set, or can be removed by setting them to\n            'drop'.\n\n        Returns\n        -------\n        self : object\n            Estimator instance.\n        \"\"\"\n        super()._set_params(\"estimators\", **params)\n        return self\n", "type": "function"}, {"name": "test_ensemble_heterogeneous_estimators_behavior", "is_method": false, "class_name": null, "parameters": ["X", "y", "estimator"], "calls": ["pytest.mark.parametrize", "estimator.fit", "clone", "fit", "clone", "estimator_dropped.set_params", "estimator_dropped.fit", "estimator.set_params", "estimator.set_params", "len", "len", "sorted", "sorted", "is_classifier", "SVC", "SVR", "hasattr", "estimator_new_params.named_estimators.lr.get_params", "estimator.named_estimators.lr.get_params", "estimator_new_params.named_estimators.rf.get_params", "estimator.named_estimators.rf.get_params", "len", "len", "sorted", "sorted", "list", "estimator_new_params.set_params", "list", "isinstance", "estimator.get_params", "get_params", "estimator.get_params", "get_params", "StackingClassifier", "VotingClassifier", "StackingRegressor", "VotingRegressor", "estimator.named_estimators_.keys", "estimator_dropped.named_estimators_.keys", "type", "make_classification", "make_classification", "make_regression", "make_regression", "estimator.get_params", "estimator.get_params", "LogisticRegression", "LinearSVC", "RandomForestClassifier", "LogisticRegression", "LinearSVC", "RandomForestClassifier", "LinearRegression", "LinearSVR", "RandomForestRegressor", "LinearRegression", "LinearSVR", "RandomForestRegressor"], "code_location": {"file": "test_common.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/ensemble/tests", "start_line": 82, "end_line": 138}, "code_snippet": "def test_ensemble_heterogeneous_estimators_behavior(X, y, estimator):\n    # check that the behavior of `estimators`, `estimators_`,\n    # `named_estimators`, `named_estimators_` is consistent across all\n    # ensemble classes and when using `set_params()`.\n\n    # before fit\n    assert \"svm\" in estimator.named_estimators\n    assert estimator.named_estimators.svm is estimator.estimators[1][1]\n    assert estimator.named_estimators.svm is estimator.named_estimators[\"svm\"]\n\n    # check fitted attributes\n    estimator.fit(X, y)\n    assert len(estimator.named_estimators) == 3\n    assert len(estimator.named_estimators_) == 3\n    assert sorted(list(estimator.named_estimators_.keys())) == sorted(\n        [\"lr\", \"svm\", \"rf\"]\n    )\n\n    # check that set_params() does not add a new attribute\n    estimator_new_params = clone(estimator)\n    svm_estimator = SVC() if is_classifier(estimator) else SVR()\n    estimator_new_params.set_params(svm=svm_estimator).fit(X, y)\n    assert not hasattr(estimator_new_params, \"svm\")\n    assert (\n        estimator_new_params.named_estimators.lr.get_params()\n        == estimator.named_estimators.lr.get_params()\n    )\n    assert (\n        estimator_new_params.named_estimators.rf.get_params()\n        == estimator.named_estimators.rf.get_params()\n    )\n\n    # check the behavior when setting an dropping an estimator\n    estimator_dropped = clone(estimator)\n    estimator_dropped.set_params(svm=\"drop\")\n    estimator_dropped.fit(X, y)\n    assert len(estimator_dropped.named_estimators) == 3\n    assert estimator_dropped.named_estimators.svm == \"drop\"\n    assert len(estimator_dropped.named_estimators_) == 3\n    assert sorted(list(estimator_dropped.named_estimators_.keys())) == sorted(\n        [\"lr\", \"svm\", \"rf\"]\n    )\n    for sub_est in estimator_dropped.named_estimators_:\n        # check that the correspondence is correct\n        assert not isinstance(sub_est, type(estimator.named_estimators.svm))\n\n    # check that we can set the parameters of the underlying classifier\n    estimator.set_params(svm__C=10.0)\n    estimator.set_params(rf__max_depth=5)\n    assert (\n        estimator.get_params()[\"svm__C\"]\n        == estimator.get_params()[\"svm\"].get_params()[\"C\"]\n    )\n    assert (\n        estimator.get_params()[\"rf__max_depth\"]\n        == estimator.get_params()[\"rf\"].get_params()[\"max_depth\"]\n    )\n", "type": "function"}, {"name": "_set_params", "is_method": true, "class_name": "_BaseComposition", "parameters": ["self", "attr"], "calls": ["getattr", "set_params", "setattr", "isinstance", "params.pop", "suppress", "zip", "list", "super", "params.keys", "self._replace_estimator", "params.pop"], "code_location": {"file": "metaestimators.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/utils", "start_line": 52, "end_line": 71}, "code_snippet": "    def _set_params(self, attr, **params):\n        # Ensure strict ordering of parameter setting:\n        # 1. All steps\n        if attr in params:\n            setattr(self, attr, params.pop(attr))\n        # 2. Replace items with estimators in params\n        items = getattr(self, attr)\n        if isinstance(items, list) and items:\n            # Get item names used to identify valid names in params\n            # `zip` raises a TypeError when `items` does not contains\n            # elements of length 2\n            with suppress(TypeError):\n                item_names, _ = zip(*items)\n                for name in list(params.keys()):\n                    if \"__\" not in name and name in item_names:\n                        self._replace_estimator(attr, name, params.pop(name))\n\n        # 3. Step parameters and other initialisation arguments\n        super().set_params(**params)\n        return self\n", "type": "function"}, {"name": "test_set_estimator_drop", "is_method": false, "class_name": null, "parameters": [], "calls": ["LogisticRegression", "RandomForestClassifier", "GaussianNB", "fit", "VotingClassifier", "fit", "assert_array_equal", "all", "fit", "fit", "assert_array_equal", "assert_array_almost_equal", "np.array", "np.array", "fit", "VotingClassifier", "fit", "assert_array_almost_equal", "assert_array_almost_equal", "eclf1.set_params", "eclf2.set_params", "assert_array_equal", "assert_array_equal", "eclf1.predict", "eclf2.predict", "len", "eclf1.predict", "eclf2.predict", "eclf1.predict_proba", "eclf2.predict_proba", "pytest.raises", "fit", "eclf1.transform", "np.array", "eclf2.transform", "np.array", "eclf1.transform", "np.array", "eclf2.transform", "np.array", "VotingClassifier", "eclf2.set_params", "dict", "isinstance", "eclf2.get_params", "eclf1.set_params", "eclf2.set_params", "VotingClassifier", "eclf2.set_params", "eclf2.set_params"], "code_location": {"file": "test_voting.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/ensemble/tests", "start_line": 409, "end_line": 471}, "code_snippet": "def test_set_estimator_drop():\n    # VotingClassifier set_params should be able to set estimators as drop\n    # Test predict\n    clf1 = LogisticRegression(random_state=123)\n    clf2 = RandomForestClassifier(n_estimators=10, random_state=123)\n    clf3 = GaussianNB()\n    eclf1 = VotingClassifier(\n        estimators=[(\"lr\", clf1), (\"rf\", clf2), (\"nb\", clf3)],\n        voting=\"hard\",\n        weights=[1, 0, 0.5],\n    ).fit(X, y)\n\n    eclf2 = VotingClassifier(\n        estimators=[(\"lr\", clf1), (\"rf\", clf2), (\"nb\", clf3)],\n        voting=\"hard\",\n        weights=[1, 1, 0.5],\n    )\n    eclf2.set_params(rf=\"drop\").fit(X, y)\n\n    assert_array_equal(eclf1.predict(X), eclf2.predict(X))\n\n    assert dict(eclf2.estimators)[\"rf\"] == \"drop\"\n    assert len(eclf2.estimators_) == 2\n    assert all(\n        isinstance(est, (LogisticRegression, GaussianNB)) for est in eclf2.estimators_\n    )\n    assert eclf2.get_params()[\"rf\"] == \"drop\"\n\n    eclf1.set_params(voting=\"soft\").fit(X, y)\n    eclf2.set_params(voting=\"soft\").fit(X, y)\n\n    assert_array_equal(eclf1.predict(X), eclf2.predict(X))\n    assert_array_almost_equal(eclf1.predict_proba(X), eclf2.predict_proba(X))\n    msg = \"All estimators are dropped. At least one is required\"\n    with pytest.raises(ValueError, match=msg):\n        eclf2.set_params(lr=\"drop\", rf=\"drop\", nb=\"drop\").fit(X, y)\n\n    # Test soft voting transform\n    X1 = np.array([[1], [2]])\n    y1 = np.array([1, 2])\n    eclf1 = VotingClassifier(\n        estimators=[(\"rf\", clf2), (\"nb\", clf3)],\n        voting=\"soft\",\n        weights=[0, 0.5],\n        flatten_transform=False,\n    ).fit(X1, y1)\n\n    eclf2 = VotingClassifier(\n        estimators=[(\"rf\", clf2), (\"nb\", clf3)],\n        voting=\"soft\",\n        weights=[1, 0.5],\n        flatten_transform=False,\n    )\n    eclf2.set_params(rf=\"drop\").fit(X1, y1)\n    assert_array_almost_equal(\n        eclf1.transform(X1),\n        np.array([[[0.7, 0.3], [0.3, 0.7]], [[1.0, 0.0], [0.0, 1.0]]]),\n    )\n    assert_array_almost_equal(eclf2.transform(X1), np.array([[[1.0, 0.0], [0.0, 1.0]]]))\n    eclf1.set_params(voting=\"hard\")\n    eclf2.set_params(voting=\"hard\")\n    assert_array_equal(eclf1.transform(X1), np.array([[0, 0], [1, 1]]))\n    assert_array_equal(eclf2.transform(X1), np.array([[0], [1]]))\n", "type": "function"}, {"name": "test_set_feature_union_step_drop", "is_method": false, "class_name": null, "parameters": [], "calls": ["Mult", "Mult", "np.asarray", "FeatureUnion", "assert_array_equal", "assert_array_equal", "assert_array_equal", "ft.set_params", "assert_array_equal", "assert_array_equal", "assert_array_equal", "ft.set_params", "assert_array_equal", "assert_array_equal", "assert_array_equal", "ft.set_params", "assert_array_equal", "FeatureUnion", "assert_array_equal", "assert_array_equal", "assert_array_equal", "transform", "ft.fit_transform", "ft.get_feature_names_out", "transform", "ft.fit_transform", "ft.get_feature_names_out", "transform", "ft.fit_transform", "ft.get_feature_names_out", "transform", "transform", "ft.fit_transform", "ft.get_feature_names_out", "ft.fit", "ft.fit", "ft.fit", "ft.fit", "ft.fit"], "code_location": {"file": "test_pipeline.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/tests", "start_line": 1104, "end_line": 1136}, "code_snippet": "def test_set_feature_union_step_drop():\n    mult2 = Mult(2)\n    mult3 = Mult(3)\n\n    mult2.get_feature_names_out = lambda input_features: [\"x2\"]\n    mult3.get_feature_names_out = lambda input_features: [\"x3\"]\n\n    X = np.asarray([[1]])\n\n    ft = FeatureUnion([(\"m2\", mult2), (\"m3\", mult3)])\n    assert_array_equal([[2, 3]], ft.fit(X).transform(X))\n    assert_array_equal([[2, 3]], ft.fit_transform(X))\n    assert_array_equal([\"m2__x2\", \"m3__x3\"], ft.get_feature_names_out())\n\n    ft.set_params(m2=\"drop\")\n    assert_array_equal([[3]], ft.fit(X).transform(X))\n    assert_array_equal([[3]], ft.fit_transform(X))\n    assert_array_equal([\"m3__x3\"], ft.get_feature_names_out())\n\n    ft.set_params(m3=\"drop\")\n    assert_array_equal([[]], ft.fit(X).transform(X))\n    assert_array_equal([[]], ft.fit_transform(X))\n    assert_array_equal([], ft.get_feature_names_out())\n\n    # check we can change back\n    ft.set_params(m3=mult3)\n    assert_array_equal([[3]], ft.fit(X).transform(X))\n\n    # Check 'drop' step at construction time\n    ft = FeatureUnion([(\"m2\", \"drop\"), (\"m3\", mult3)])\n    assert_array_equal([[3]], ft.fit(X).transform(X))\n    assert_array_equal([[3]], ft.fit_transform(X))\n    assert_array_equal([\"m3__x3\"], ft.get_feature_names_out())\n", "type": "function"}, {"name": "_get_params", "is_method": true, "class_name": "_BaseComposition", "parameters": ["self", "attr", "deep"], "calls": ["get_params", "getattr", "out.update", "hasattr", "super", "items", "estimator.get_params"], "code_location": {"file": "metaestimators.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/utils", "start_line": 30, "end_line": 50}, "code_snippet": "    def _get_params(self, attr, deep=True):\n        out = super().get_params(deep=deep)\n        if not deep:\n            return out\n\n        estimators = getattr(self, attr)\n        try:\n            out.update(estimators)\n        except (TypeError, ValueError):\n            # Ignore TypeError for cases where estimators is not a list of\n            # (name, estimator) and ignore ValueError when the list is not\n            # formatted correctly. This is to prevent errors when calling\n            # `set_params`. `BaseEstimator.set_params` calls `get_params` which\n            # can error for invalid values for `estimators`.\n            return out\n\n        for name, estimator in estimators:\n            if hasattr(estimator, \"get_params\"):\n                for key, value in estimator.get_params(deep=True).items():\n                    out[\"%s__%s\" % (name, key)] = value\n        return out\n", "type": "function"}, {"name": "test_set_feature_union_steps", "is_method": false, "class_name": null, "parameters": [], "calls": ["Mult", "Mult", "Mult", "FeatureUnion", "assert_array_equal", "assert_array_equal", "assert_array_equal", "assert_array_equal", "ft.set_params", "assert_array_equal", "assert_array_equal", "ft.set_params", "assert_array_equal", "assert_array_equal", "ft.transform", "ft.get_feature_names_out", "ft.transform", "ft.get_feature_names_out", "ft.transform", "ft.get_feature_names_out", "ft.transform", "ft.get_feature_names_out", "np.asarray", "np.asarray", "np.asarray", "np.asarray"], "code_location": {"file": "test_pipeline.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/tests", "start_line": 1075, "end_line": 1101}, "code_snippet": "def test_set_feature_union_steps():\n    mult2 = Mult(2)\n    mult3 = Mult(3)\n    mult5 = Mult(5)\n\n    mult3.get_feature_names_out = lambda input_features: [\"x3\"]\n    mult2.get_feature_names_out = lambda input_features: [\"x2\"]\n    mult5.get_feature_names_out = lambda input_features: [\"x5\"]\n\n    ft = FeatureUnion([(\"m2\", mult2), (\"m3\", mult3)])\n    assert_array_equal([[2, 3]], ft.transform(np.asarray([[1]])))\n    assert_array_equal([\"m2__x2\", \"m3__x3\"], ft.get_feature_names_out())\n\n    # Directly setting attr\n    ft.transformer_list = [(\"m5\", mult5)]\n    assert_array_equal([[5]], ft.transform(np.asarray([[1]])))\n    assert_array_equal([\"m5__x5\"], ft.get_feature_names_out())\n\n    # Using set_params\n    ft.set_params(transformer_list=[(\"mock\", mult3)])\n    assert_array_equal([[3]], ft.transform(np.asarray([[1]])))\n    assert_array_equal([\"mock__x3\"], ft.get_feature_names_out())\n\n    # Using set_params to replace single step\n    ft.set_params(mock=mult5)\n    assert_array_equal([[5]], ft.transform(np.asarray([[1]])))\n    assert_array_equal([\"mock__x5\"], ft.get_feature_names_out())\n", "type": "function"}, {"name": "test_voting_classifier_set_params", "is_method": false, "class_name": null, "parameters": ["global_random_seed"], "calls": ["LogisticRegression", "RandomForestClassifier", "GaussianNB", "fit", "VotingClassifier", "fit", "assert_array_equal", "assert_array_almost_equal", "eclf1.predict", "eclf2.predict", "eclf1.predict_proba", "eclf2.predict_proba", "get_params", "clf1.get_params", "get_params", "clf2.get_params", "VotingClassifier", "eclf2.set_params"], "code_location": {"file": "test_voting.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/ensemble/tests", "start_line": 385, "end_line": 406}, "code_snippet": "def test_voting_classifier_set_params(global_random_seed):\n    # check equivalence in the output when setting underlying estimators\n    clf1 = LogisticRegression(random_state=global_random_seed)\n    clf2 = RandomForestClassifier(\n        n_estimators=10, random_state=global_random_seed, max_depth=None\n    )\n    clf3 = GaussianNB()\n\n    eclf1 = VotingClassifier(\n        [(\"lr\", clf1), (\"rf\", clf2)], voting=\"soft\", weights=[1, 2]\n    ).fit(X_scaled, y)\n    eclf2 = VotingClassifier(\n        [(\"lr\", clf1), (\"nb\", clf3)], voting=\"soft\", weights=[1, 2]\n    )\n    eclf2.set_params(nb=clf2).fit(X_scaled, y)\n\n    assert_array_equal(eclf1.predict(X_scaled), eclf2.predict(X_scaled))\n    assert_array_almost_equal(\n        eclf1.predict_proba(X_scaled), eclf2.predict_proba(X_scaled)\n    )\n    assert eclf2.estimators[0][1].get_params() == clf1.get_params()\n    assert eclf2.estimators[1][1].get_params() == clf2.get_params()\n", "type": "function"}, {"name": "test_base", "is_method": false, "class_name": null, "parameters": [], "calls": ["BaggingClassifier", "load_iris", "ensemble.fit", "ensemble._make_estimator", "np.random.RandomState", "ensemble._make_estimator", "ensemble._make_estimator", "ensemble._make_estimator", "isinstance", "isinstance", "isinstance", "BaggingClassifier", "np_int_ensemble.fit", "len", "len", "Perceptron", "Perceptron", "np.int32"], "code_location": {"file": "test_base.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/ensemble/tests", "start_line": 21, "end_line": 49}, "code_snippet": "def test_base():\n    # Check BaseEnsemble methods.\n    ensemble = BaggingClassifier(\n        estimator=Perceptron(random_state=None), n_estimators=3\n    )\n\n    iris = load_iris()\n    ensemble.fit(iris.data, iris.target)\n    ensemble.estimators_ = []  # empty the list and create estimators manually\n\n    ensemble._make_estimator()\n    random_state = np.random.RandomState(3)\n    ensemble._make_estimator(random_state=random_state)\n    ensemble._make_estimator(random_state=random_state)\n    ensemble._make_estimator(append=False)\n\n    assert 3 == len(ensemble)\n    assert 3 == len(ensemble.estimators_)\n\n    assert isinstance(ensemble[0], Perceptron)\n    assert ensemble[0].random_state is None\n    assert isinstance(ensemble[1].random_state, int)\n    assert isinstance(ensemble[2].random_state, int)\n    assert ensemble[1].random_state != ensemble[2].random_state\n\n    np_int_ensemble = BaggingClassifier(\n        estimator=Perceptron(), n_estimators=np.int32(3)\n    )\n    np_int_ensemble.fit(iris.data, iris.target)\n", "type": "function"}, {"name": "_validate_estimators", "is_method": true, "class_name": "_BaseHeterogeneousEnsemble", "parameters": ["self"], "calls": ["zip", "self._validate_names", "any", "ValueError", "ValueError", "is_classifier", "len", "all", "ValueError", "is_estimator_type", "format", "isinstance", "isinstance"], "code_location": {"file": "_base.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/ensemble", "start_line": 219, "end_line": 249}, "code_snippet": "    def _validate_estimators(self):\n        if len(self.estimators) == 0 or not all(\n            isinstance(item, (tuple, list)) and isinstance(item[0], str)\n            for item in self.estimators\n        ):\n            raise ValueError(\n                \"Invalid 'estimators' attribute, 'estimators' should be a \"\n                \"non-empty list of (string, estimator) tuples.\"\n            )\n        names, estimators = zip(*self.estimators)\n        # defined by MetaEstimatorMixin\n        self._validate_names(names)\n\n        has_estimator = any(est != \"drop\" for est in estimators)\n        if not has_estimator:\n            raise ValueError(\n                \"All estimators are dropped. At least one is required \"\n                \"to be an estimator.\"\n            )\n\n        is_estimator_type = is_classifier if is_classifier(self) else is_regressor\n\n        for est in estimators:\n            if est != \"drop\" and not is_estimator_type(est):\n                raise ValueError(\n                    \"The estimator {} should be a {}.\".format(\n                        est.__class__.__name__, is_estimator_type.__name__[3:]\n                    )\n                )\n\n        return names, estimators\n", "type": "function"}], "retrieved_count": 10, "cost_time": 0.33084535598754883}
{"question": "Where in the codebase are the probability calibration mechanisms that enable SVC and NuSVC to produce consistent probability estimates through predict_proba and predict_log_proba methods?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"name": "test_probability", "is_method": false, "class_name": null, "parameters": ["global_random_seed"], "calls": ["get_iris_dataset", "svm.SVC", "svm.NuSVC", "clf.fit", "clf.predict_proba", "assert_array_almost_equal", "assert_almost_equal", "np.sum", "np.ones", "np.mean", "clf.predict_proba", "np.exp", "clf.predict_log_proba", "np.argmax", "clf.predict"], "code_location": {"file": "test_svm.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/svm/tests", "start_line": 376, "end_line": 393}, "code_snippet": "def test_probability(global_random_seed):\n    # Predict probabilities using SVC\n    # This uses cross validation, so we use a slightly bigger testing set.\n    iris = get_iris_dataset(global_random_seed)\n\n    for clf in (\n        svm.SVC(probability=True, random_state=global_random_seed, C=1.0),\n        svm.NuSVC(probability=True, random_state=global_random_seed),\n    ):\n        clf.fit(iris.data, iris.target)\n\n        prob_predict = clf.predict_proba(iris.data)\n        assert_array_almost_equal(np.sum(prob_predict, 1), np.ones(iris.data.shape[0]))\n        assert np.mean(np.argmax(prob_predict, 1) == clf.predict(iris.data)) > 0.9\n\n        assert_almost_equal(\n            clf.predict_proba(iris.data), np.exp(clf.predict_log_proba(iris.data)), 8\n        )\n", "type": "function"}, {"name": "test_consistent_proba", "is_method": false, "class_name": null, "parameters": [], "calls": ["svm.SVC", "svm.SVC", "assert_allclose", "ignore_warnings", "predict_proba", "ignore_warnings", "predict_proba", "a.fit", "a.fit"], "code_location": {"file": "test_sparse.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/svm/tests", "start_line": 489, "end_line": 496}, "code_snippet": "def test_consistent_proba():\n    a = svm.SVC(probability=True, max_iter=1, random_state=0)\n    with ignore_warnings(category=ConvergenceWarning):\n        proba_1 = a.fit(X, Y).predict_proba(X)\n    a = svm.SVC(probability=True, max_iter=1, random_state=0)\n    with ignore_warnings(category=ConvergenceWarning):\n        proba_2 = a.fit(X, Y).predict_proba(X)\n    assert_allclose(proba_1, proba_2)\n", "type": "function"}, {"name": "test_sgd_proba", "is_method": false, "class_name": null, "parameters": ["klass"], "calls": ["pytest.mark.parametrize", "fit", "fit", "clf.decision_function", "clf.predict_proba", "assert_array_equal", "assert_almost_equal", "np.all", "clf.predict_proba", "clf.decision_function", "assert_array_equal", "clf.predict_log_proba", "clf.predict_proba", "assert_array_almost_equal", "clf.predict_log_proba", "clf.predict_proba", "assert_array_almost_equal", "klass", "clf.fit", "clf.decision_function", "clf.predict_proba", "X.mean", "clf.decision_function", "np.all", "hasattr", "hasattr", "klass", "clf.fit", "clf.predict_proba", "clf.predict_proba", "np.argmax", "np.argmax", "sum", "np.argsort", "np.argsort", "np.log", "np.log", "clf.predict_proba", "assert_array_almost_equal", "SGDClassifier", "np.errstate", "clf.predict_log_proba", "clf.predict_log_proba", "klass", "np.argmax", "np.argmax", "np.argmin", "np.argmin"], "code_location": {"file": "test_sgd.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/linear_model/tests", "start_line": 800, "end_line": 868}, "code_snippet": "def test_sgd_proba(klass):\n    # Check SGD.predict_proba\n\n    # Hinge loss does not allow for conditional prob estimate.\n    # We cannot use the factory here, because it defines predict_proba\n    # anyway.\n    clf = SGDClassifier(loss=\"hinge\", alpha=0.01, max_iter=10, tol=None).fit(X, Y)\n    assert not hasattr(clf, \"predict_proba\")\n    assert not hasattr(clf, \"predict_log_proba\")\n\n    # log and modified_huber losses can output probability estimates\n    # binary case\n    for loss in [\"log_loss\", \"modified_huber\"]:\n        clf = klass(loss=loss, alpha=0.01, max_iter=10)\n        clf.fit(X, Y)\n        p = clf.predict_proba([[3, 2]])\n        assert p[0, 1] > 0.5\n        p = clf.predict_proba([[-1, -1]])\n        assert p[0, 1] < 0.5\n\n        # If predict_proba is 0, we get \"RuntimeWarning: divide by zero encountered\n        # in log\". We avoid it here.\n        with np.errstate(divide=\"ignore\"):\n            p = clf.predict_log_proba([[3, 2]])\n            assert p[0, 1] > p[0, 0]\n            p = clf.predict_log_proba([[-1, -1]])\n            assert p[0, 1] < p[0, 0]\n\n    # log loss multiclass probability estimates\n    clf = klass(loss=\"log_loss\", alpha=0.01, max_iter=10).fit(X2, Y2)\n\n    d = clf.decision_function([[0.1, -0.1], [0.3, 0.2]])\n    p = clf.predict_proba([[0.1, -0.1], [0.3, 0.2]])\n    assert_array_equal(np.argmax(p, axis=1), np.argmax(d, axis=1))\n    assert_almost_equal(p[0].sum(), 1)\n    assert np.all(p[0] >= 0)\n\n    p = clf.predict_proba([[-1, -1]])\n    d = clf.decision_function([[-1, -1]])\n    assert_array_equal(np.argsort(p[0]), np.argsort(d[0]))\n\n    lp = clf.predict_log_proba([[3, 2]])\n    p = clf.predict_proba([[3, 2]])\n    assert_array_almost_equal(np.log(p), lp)\n\n    lp = clf.predict_log_proba([[-1, -1]])\n    p = clf.predict_proba([[-1, -1]])\n    assert_array_almost_equal(np.log(p), lp)\n\n    # Modified Huber multiclass probability estimates; requires a separate\n    # test because the hard zero/one probabilities may destroy the\n    # ordering present in decision_function output.\n    clf = klass(loss=\"modified_huber\", alpha=0.01, max_iter=10)\n    clf.fit(X2, Y2)\n    d = clf.decision_function([[3, 2]])\n    p = clf.predict_proba([[3, 2]])\n    if klass != SparseSGDClassifier:\n        assert np.argmax(d, axis=1) == np.argmax(p, axis=1)\n    else:  # XXX the sparse test gets a different X2 (?)\n        assert np.argmin(d, axis=1) == np.argmin(p, axis=1)\n\n    # the following sample produces decision_function values < -1,\n    # which would cause naive normalization to fail (see comment\n    # in SGDClassifier.predict_proba)\n    x = X.mean(axis=0)\n    d = clf.decision_function([x])\n    if np.all(d < -1):  # XXX not true in sparse test case (why?)\n        p = clf.predict_proba([x])\n        assert_array_almost_equal(p[0], [1 / 3.0] * 3)\n", "type": "function"}, {"name": "test_calibration_prob_sum", "is_method": false, "class_name": null, "parameters": ["method", "ensemble"], "calls": ["pytest.mark.parametrize", "pytest.mark.parametrize", "make_classification", "LinearSVC", "CalibratedClassifierCV", "clf_prob.fit", "assert_allclose", "sum", "KFold", "clf_prob.predict_proba"], "code_location": {"file": "test_calibration.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/tests", "start_line": 565, "end_line": 576}, "code_snippet": "def test_calibration_prob_sum(method, ensemble):\n    # Test that sum of probabilities is (max) 1. A non-regression test for\n    # issue #7796 - when test has fewer classes than train\n    X, _ = make_classification(n_samples=10, n_features=5, n_classes=2)\n    y = [1, 1, 1, 1, 1, 0, 0, 0, 0, 0]\n    clf = LinearSVC(C=1.0, random_state=7)\n    # In the first and last fold, test will have 1 class while train will have 2\n    clf_prob = CalibratedClassifierCV(\n        clf, method=method, cv=KFold(n_splits=3), ensemble=ensemble\n    )\n    clf_prob.fit(X, y)\n    assert_allclose(clf_prob.predict_proba(X).sum(axis=1), 1.0)\n", "type": "function"}, {"name": "test_consistent_proba", "is_method": false, "class_name": null, "parameters": ["global_random_seed"], "calls": ["pytest.mark.filterwarnings", "svm.SVC", "predict_proba", "svm.SVC", "predict_proba", "assert_array_almost_equal", "a.fit", "a.fit"], "code_location": {"file": "test_svm.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/svm/tests", "start_line": 1120, "end_line": 1125}, "code_snippet": "def test_consistent_proba(global_random_seed):\n    a = svm.SVC(probability=True, max_iter=1, random_state=global_random_seed)\n    proba_1 = a.fit(X, Y).predict_proba(X)\n    a = svm.SVC(probability=True, max_iter=1, random_state=global_random_seed)\n    proba_2 = a.fit(X, Y).predict_proba(X)\n    assert_array_almost_equal(proba_1, proba_2)\n", "type": "function"}, {"name": "_sparse_predict_proba", "is_method": true, "class_name": "BaseSVC", "parameters": ["self", "X"], "calls": ["np.asarray", "callable", "self._sparse_kernels.index", "libsvm_sparse.libsvm_sparse_predict_proba", "LIBSVM_IMPL.index", "getattr", "np.empty"], "code_location": {"file": "_base.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/svm", "start_line": 940, "end_line": 973}, "code_snippet": "    def _sparse_predict_proba(self, X):\n        X.data = np.asarray(X.data, dtype=np.float64, order=\"C\")\n\n        kernel = self.kernel\n        if callable(kernel):\n            kernel = \"precomputed\"\n\n        kernel_type = self._sparse_kernels.index(kernel)\n\n        return libsvm_sparse.libsvm_sparse_predict_proba(\n            X.data,\n            X.indices,\n            X.indptr,\n            self.support_vectors_.data,\n            self.support_vectors_.indices,\n            self.support_vectors_.indptr,\n            self._dual_coef_.data,\n            self._intercept_,\n            LIBSVM_IMPL.index(self._impl),\n            kernel_type,\n            self.degree,\n            self._gamma,\n            self.coef0,\n            self.tol,\n            self.C,\n            getattr(self, \"class_weight_\", np.empty(0)),\n            self.nu,\n            self.epsilon,\n            self.shrinking,\n            self.probability,\n            self._n_support,\n            self._probA,\n            self._probB,\n        )\n", "type": "function"}, {"name": "test_sgd_predict_proba_method_access", "is_method": false, "class_name": null, "parameters": ["klass"], "calls": ["pytest.mark.parametrize", "SGDClassifier", "hasattr", "hasattr", "format", "isinstance", "isinstance", "hasattr", "hasattr", "pytest.raises", "str", "pytest.raises", "str"], "code_location": {"file": "test_sgd.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/linear_model/tests", "start_line": 766, "end_line": 796}, "code_snippet": "def test_sgd_predict_proba_method_access(klass):\n    # Checks that SGDClassifier predict_proba and predict_log_proba methods\n    # can either be accessed or raise an appropriate error message\n    # otherwise. See\n    # https://github.com/scikit-learn/scikit-learn/issues/10938 for more\n    # details.\n    for loss in linear_model.SGDClassifier.loss_functions:\n        clf = SGDClassifier(loss=loss)\n        if loss in (\"log_loss\", \"modified_huber\"):\n            assert hasattr(clf, \"predict_proba\")\n            assert hasattr(clf, \"predict_log_proba\")\n        else:\n            inner_msg = \"probability estimates are not available for loss={!r}\".format(\n                loss\n            )\n            assert not hasattr(clf, \"predict_proba\")\n            assert not hasattr(clf, \"predict_log_proba\")\n            with pytest.raises(\n                AttributeError, match=\"has no attribute 'predict_proba'\"\n            ) as exec_info:\n                clf.predict_proba\n\n            assert isinstance(exec_info.value.__cause__, AttributeError)\n            assert inner_msg in str(exec_info.value.__cause__)\n\n            with pytest.raises(\n                AttributeError, match=\"has no attribute 'predict_log_proba'\"\n            ) as exec_info:\n                clf.predict_log_proba\n            assert isinstance(exec_info.value.__cause__, AttributeError)\n            assert inner_msg in str(exec_info.value.__cause__)\n", "type": "function"}, {"name": "test_hasattr_predict_proba", "is_method": false, "class_name": null, "parameters": ["global_random_seed"], "calls": ["get_iris_dataset", "svm.SVC", "hasattr", "G.fit", "hasattr", "svm.SVC", "G.fit", "hasattr", "hasattr", "hasattr", "pytest.raises", "G.predict_proba"], "code_location": {"file": "test_svm.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/svm/tests", "start_line": 1175, "end_line": 1198}, "code_snippet": "def test_hasattr_predict_proba(global_random_seed):\n    iris = get_iris_dataset(global_random_seed)\n\n    # Method must be (un)available before or after fit, switched by\n    # `probability` param\n\n    G = svm.SVC(probability=True)\n    assert hasattr(G, \"predict_proba\")\n    G.fit(iris.data, iris.target)\n    assert hasattr(G, \"predict_proba\")\n\n    G = svm.SVC(probability=False)\n    assert not hasattr(G, \"predict_proba\")\n    G.fit(iris.data, iris.target)\n    assert not hasattr(G, \"predict_proba\")\n\n    # Switching to `probability=True` after fitting should make\n    # predict_proba available, but calling it must not work:\n    G.probability = True\n    assert hasattr(G, \"predict_proba\")\n    msg = \"predict_proba is not available when fitted with probability=False\"\n\n    with pytest.raises(NotFittedError, match=msg):\n        G.predict_proba(iris.data)\n", "type": "function"}, {"name": "_dense_predict_proba", "is_method": true, "class_name": "BaseSVC", "parameters": ["self", "X"], "calls": ["self._compute_kernel", "callable", "LIBSVM_IMPL.index", "libsvm.predict_proba"], "code_location": {"file": "_base.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/svm", "start_line": 913, "end_line": 938}, "code_snippet": "    def _dense_predict_proba(self, X):\n        X = self._compute_kernel(X)\n\n        kernel = self.kernel\n        if callable(kernel):\n            kernel = \"precomputed\"\n\n        svm_type = LIBSVM_IMPL.index(self._impl)\n        pprob = libsvm.predict_proba(\n            X,\n            self.support_,\n            self.support_vectors_,\n            self._n_support,\n            self._dual_coef_,\n            self._intercept_,\n            self._probA,\n            self._probB,\n            svm_type=svm_type,\n            kernel=kernel,\n            degree=self.degree,\n            cache_size=self.cache_size,\n            coef0=self.coef0,\n            gamma=self._gamma,\n        )\n\n        return pprob\n", "type": "function"}, {"name": "test_calibration_default_estimator", "is_method": false, "class_name": null, "parameters": ["data"], "calls": ["CalibratedClassifierCV", "calib_clf.fit", "isinstance"], "code_location": {"file": "test_calibration.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/tests", "start_line": 142, "end_line": 149}, "code_snippet": "def test_calibration_default_estimator(data):\n    # Check estimator default is LinearSVC\n    X, y = data\n    calib_clf = CalibratedClassifierCV(cv=2)\n    calib_clf.fit(X, y)\n\n    base_est = calib_clf.calibrated_classifiers_[0].estimator\n    assert isinstance(base_est, LinearSVC)\n", "type": "function"}], "retrieved_count": 10, "cost_time": 0.3359534740447998}
{"question": "Where in the CountVectorizer class initialization is the token_pattern parameter processed and how does its assignment relate to the subsequent tokenizer parameter validation logic?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"name": "test_countvectorizer_custom_token_pattern_with_several_group", "is_method": false, "class_name": null, "parameters": [], "calls": ["CountVectorizer", "pytest.raises", "vectorizer.fit"], "code_location": {"file": "test_text.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/feature_extraction/tests", "start_line": 411, "end_line": 427}, "code_snippet": "def test_countvectorizer_custom_token_pattern_with_several_group():\n    \"\"\"Check that we raise an error if token pattern capture several groups.\n    Non-regression test for:\n    https://github.com/scikit-learn/scikit-learn/issues/12971\n    \"\"\"\n    corpus = [\n        \"This is the 1st document in my corpus.\",\n        \"This document is the 2nd sample.\",\n        \"And this is the 3rd one.\",\n        \"Is this the 4th document?\",\n    ]\n\n    token_pattern = r\"([0-9]{1,3}(?:st|nd|rd|th))\\s\\b(\\w{2,})\\b\"\n    err_msg = \"More than 1 capturing group in token pattern\"\n    vectorizer = CountVectorizer(token_pattern=token_pattern)\n    with pytest.raises(ValueError, match=err_msg):\n        vectorizer.fit(corpus)\n", "type": "function"}, {"name": "CountVectorizer", "docstring": "Convert a collection of text documents to a matrix of token counts.\n\nThis implementation produces a sparse representation of the counts using\nscipy.sparse.csr_matrix.\n\nIf you do not provide an a-priori dictionary and you do not use an analyzer\nthat does some kind of feature selection then the number of features will\nbe equal to the vocabulary size found by analyzing the data.\n\nFor an efficiency comparison of the different feature extractors, see\n:ref:`sphx_glr_auto_examples_text_plot_hashing_vs_dict_vectorizer.py`.\n\nRead more in the :ref:`User Guide <text_feature_extraction>`.\n\nParameters\n----------\ninput : {'filename', 'file', 'content'}, default='content'\n    - If `'filename'`, the sequence passed as an argument to fit is\n      expected to be a list of filenames that need reading to fetch\n      the raw content to analyze.\n\n    - If `'file'`, the sequence items must have a 'read' method (file-like\n      object) that is called to fetch the bytes in memory.\n\n    - If `'content'`, the input is expected to be a sequence of items that\n      can be of type string or byte.\n\nencoding : str, default='utf-8'\n    If bytes or files are given to analyze, this encoding is used to\n    decode.\n\ndecode_error : {'strict', 'ignore', 'replace'}, default='strict'\n    Instruction on what to do if a byte sequence is given to analyze that\n    contains characters not of the given `encoding`. By default, it is\n    'strict', meaning that a UnicodeDecodeError will be raised. Other\n    values are 'ignore' and 'replace'.\n\nstrip_accents : {'ascii', 'unicode'} or callable, default=None\n    Remove accents and perform other character normalization\n    during the preprocessing step.\n    'ascii' is a fast method that only works on characters that have\n    a direct ASCII mapping.\n    'unicode' is a slightly slower method that works on any characters.\n    None (default) means no character normalization is performed.\n\n    Both 'ascii' and 'unicode' use NFKD normalization from\n    :func:`unicodedata.normalize`.\n\nlowercase : bool, default=True\n    Convert all characters to lowercase before tokenizing.\n\npreprocessor : callable, default=None\n    Override the preprocessing (strip_accents and lowercase) stage while\n    preserving the tokenizing and n-grams generation steps.\n    Only applies if ``analyzer`` is not callable.\n\ntokenizer : callable, default=None\n    Override the string tokenization step while preserving the\n    preprocessing and n-grams generation steps.\n    Only applies if ``analyzer == 'word'``.\n\nstop_words : {'english'}, list, default=None\n    If 'english', a built-in stop word list for English is used.\n    There are several known issues with 'english' and you should\n    consider an alternative (see :ref:`stop_words`).\n\n    If a list, that list is assumed to contain stop words, all of which\n    will be removed from the resulting tokens.\n    Only applies if ``analyzer == 'word'``.\n\n    If None, no stop words will be used. In this case, setting `max_df`\n    to a higher value, such as in the range (0.7, 1.0), can automatically detect\n    and filter stop words based on intra corpus document frequency of terms.\n\ntoken_pattern : str or None, default=r\"(?u)\\\\b\\\\w\\\\w+\\\\b\"\n    Regular expression denoting what constitutes a \"token\", only used\n    if ``analyzer == 'word'``. The default regexp select tokens of 2\n    or more alphanumeric characters (punctuation is completely ignored\n    and always treated as a token separator).\n\n    If there is a capturing group in token_pattern then the\n    captured group content, not the entire match, becomes the token.\n    At most one capturing group is permitted.\n\nngram_range : tuple (min_n, max_n), default=(1, 1)\n    The lower and upper boundary of the range of n-values for different\n    word n-grams or char n-grams to be extracted. All values of n such\n    such that min_n <= n <= max_n will be used. For example an\n    ``ngram_range`` of ``(1, 1)`` means only unigrams, ``(1, 2)`` means\n    unigrams and bigrams, and ``(2, 2)`` means only bigrams.\n    Only applies if ``analyzer`` is not callable.\n\nanalyzer : {'word', 'char', 'char_wb'} or callable, default='word'\n    Whether the feature should be made of word n-gram or character\n    n-grams.\n    Option 'char_wb' creates character n-grams only from text inside\n    word boundaries; n-grams at the edges of words are padded with space.\n\n    If a callable is passed it is used to extract the sequence of features\n    out of the raw, unprocessed input.\n\n    .. versionchanged:: 0.21\n\n    Since v0.21, if ``input`` is ``filename`` or ``file``, the data is\n    first read from the file and then passed to the given callable\n    analyzer.\n\nmax_df : float in range [0.0, 1.0] or int, default=1.0\n    When building the vocabulary ignore terms that have a document\n    frequency strictly higher than the given threshold (corpus-specific\n    stop words).\n    If float, the parameter represents a proportion of documents, integer\n    absolute counts.\n    This parameter is ignored if vocabulary is not None.\n\nmin_df : float in range [0.0, 1.0] or int, default=1\n    When building the vocabulary ignore terms that have a document\n    frequency strictly lower than the given threshold. This value is also\n    called cut-off in the literature.\n    If float, the parameter represents a proportion of documents, integer\n    absolute counts.\n    This parameter is ignored if vocabulary is not None.\n\nmax_features : int, default=None\n    If not None, build a vocabulary that only consider the top\n    `max_features` ordered by term frequency across the corpus.\n    Otherwise, all features are used.\n\n    This parameter is ignored if vocabulary is not None.\n\nvocabulary : Mapping or iterable, default=None\n    Either a Mapping (e.g., a dict) where keys are terms and values are\n    indices in the feature matrix, or an iterable over terms. If not\n    given, a vocabulary is determined from the input documents. Indices\n    in the mapping should not be repeated and should not have any gap\n    between 0 and the largest index.\n\nbinary : bool, default=False\n    If True, all non zero counts are set to 1. This is useful for discrete\n    probabilistic models that model binary events rather than integer\n    counts.\n\ndtype : dtype, default=np.int64\n    Type of the matrix returned by fit_transform() or transform().\n\nAttributes\n----------\nvocabulary_ : dict\n    A mapping of terms to feature indices.\n\nfixed_vocabulary_ : bool\n    True if a fixed vocabulary of term to indices mapping\n    is provided by the user.\n\nSee Also\n--------\nHashingVectorizer : Convert a collection of text documents to a\n    matrix of token counts.\n\nTfidfVectorizer : Convert a collection of raw documents to a matrix\n    of TF-IDF features.\n\nExamples\n--------\n>>> from sklearn.feature_extraction.text import CountVectorizer\n>>> corpus = [\n...     'This is the first document.',\n...     'This document is the second document.',\n...     'And this is the third one.',\n...     'Is this the first document?',\n... ]\n>>> vectorizer = CountVectorizer()\n>>> X = vectorizer.fit_transform(corpus)\n>>> vectorizer.get_feature_names_out()\narray(['and', 'document', 'first', 'is', 'one', 'second', 'the', 'third',\n       'this'], ...)\n>>> print(X.toarray())\n[[0 1 1 1 0 0 1 0 1]\n [0 2 0 1 0 1 1 0 1]\n [1 0 0 1 1 0 1 1 1]\n [0 1 1 1 0 0 1 0 1]]\n>>> vectorizer2 = CountVectorizer(analyzer='word', ngram_range=(2, 2))\n>>> X2 = vectorizer2.fit_transform(corpus)\n>>> vectorizer2.get_feature_names_out()\narray(['and this', 'document is', 'first document', 'is the', 'is this',\n       'second document', 'the first', 'the second', 'the third', 'third one',\n       'this document', 'this is', 'this the'], ...)\n >>> print(X2.toarray())\n [[0 0 1 1 0 0 1 0 0 0 0 1 0]\n [0 1 0 1 0 1 0 1 0 0 1 0 0]\n [1 0 0 1 0 0 0 0 1 1 0 1 0]\n [0 0 1 0 1 0 1 0 0 0 0 0 1]]", "methods": ["__init__", "_sort_features", "_limit_features", "_count_vocab", "fit", "fit_transform", "transform", "inverse_transform", "get_feature_names_out", "__sklearn_tags__", "__init__"], "attributes": ["__metadata_request__fit", "__metadata_request__transform"], "code_location": {"file": "text.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/feature_extraction", "start_line": 938, "end_line": 1492}, "type": "class"}, {"name": "__init__", "is_method": true, "class_name": "CountVectorizer", "parameters": ["self"], "calls": [], "code_location": {"file": "text.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/feature_extraction", "start_line": 1164, "end_line": 1201}, "code_snippet": "    def __init__(\n        self,\n        *,\n        input=\"content\",\n        encoding=\"utf-8\",\n        decode_error=\"strict\",\n        strip_accents=None,\n        lowercase=True,\n        preprocessor=None,\n        tokenizer=None,\n        stop_words=None,\n        token_pattern=r\"(?u)\\b\\w\\w+\\b\",\n        ngram_range=(1, 1),\n        analyzer=\"word\",\n        max_df=1.0,\n        min_df=1,\n        max_features=None,\n        vocabulary=None,\n        binary=False,\n        dtype=np.int64,\n    ):\n        self.input = input\n        self.encoding = encoding\n        self.decode_error = decode_error\n        self.strip_accents = strip_accents\n        self.preprocessor = preprocessor\n        self.tokenizer = tokenizer\n        self.analyzer = analyzer\n        self.lowercase = lowercase\n        self.token_pattern = token_pattern\n        self.stop_words = stop_words\n        self.max_df = max_df\n        self.min_df = min_df\n        self.max_features = max_features\n        self.ngram_range = ngram_range\n        self.vocabulary = vocabulary\n        self.binary = binary\n        self.dtype = dtype\n", "type": "function"}, {"name": "__init__", "is_method": true, "class_name": "CountVectorizer", "parameters": ["self", "input", "encoding", "decode_error", "strip_accents", "lowercase", "preprocessor", "tokenizer", "stop_words", "token_pattern", "ngram_range", "analyzer", "max_df", "min_df", "max_features", "vocabulary", "binary", "dtype"], "calls": [], "code_location": {"file": "test_pprint.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/utils/tests", "start_line": 102, "end_line": 138}, "code_snippet": "    def __init__(\n        self,\n        input=\"content\",\n        encoding=\"utf-8\",\n        decode_error=\"strict\",\n        strip_accents=None,\n        lowercase=True,\n        preprocessor=None,\n        tokenizer=None,\n        stop_words=None,\n        token_pattern=r\"(?u)\\b\\w\\w+\\b\",\n        ngram_range=(1, 1),\n        analyzer=\"word\",\n        max_df=1.0,\n        min_df=1,\n        max_features=None,\n        vocabulary=None,\n        binary=False,\n        dtype=np.int64,\n    ):\n        self.input = input\n        self.encoding = encoding\n        self.decode_error = decode_error\n        self.strip_accents = strip_accents\n        self.preprocessor = preprocessor\n        self.tokenizer = tokenizer\n        self.analyzer = analyzer\n        self.lowercase = lowercase\n        self.token_pattern = token_pattern\n        self.stop_words = stop_words\n        self.max_df = max_df\n        self.min_df = min_df\n        self.max_features = max_features\n        self.ngram_range = ngram_range\n        self.vocabulary = vocabulary\n        self.binary = binary\n        self.dtype = dtype\n", "type": "function"}, {"name": "test_countvectorizer_stop_words", "is_method": false, "class_name": null, "parameters": [], "calls": ["CountVectorizer", "cv.set_params", "cv.set_params", "cv.set_params", "cv.set_params", "cv.get_stop_words", "pytest.raises", "cv.get_stop_words", "pytest.raises", "cv.get_stop_words", "cv.get_stop_words", "set"], "code_location": {"file": "test_text.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/feature_extraction/tests", "start_line": 359, "end_line": 371}, "code_snippet": "def test_countvectorizer_stop_words():\n    cv = CountVectorizer()\n    cv.set_params(stop_words=\"english\")\n    assert cv.get_stop_words() == ENGLISH_STOP_WORDS\n    cv.set_params(stop_words=\"_bad_str_stop_\")\n    with pytest.raises(ValueError):\n        cv.get_stop_words()\n    cv.set_params(stop_words=\"_bad_unicode_stop_\")\n    with pytest.raises(ValueError):\n        cv.get_stop_words()\n    stoplist = [\"some\", \"other\", \"words\"]\n    cv.set_params(stop_words=stoplist)\n    assert cv.get_stop_words() == set(stoplist)\n", "type": "function"}, {"name": "__init__", "is_method": true, "class_name": "HashingVectorizer", "parameters": ["self"], "calls": [], "code_location": {"file": "text.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/feature_extraction", "start_line": 773, "end_line": 808}, "code_snippet": "    def __init__(\n        self,\n        *,\n        input=\"content\",\n        encoding=\"utf-8\",\n        decode_error=\"strict\",\n        strip_accents=None,\n        lowercase=True,\n        preprocessor=None,\n        tokenizer=None,\n        stop_words=None,\n        token_pattern=r\"(?u)\\b\\w\\w+\\b\",\n        ngram_range=(1, 1),\n        analyzer=\"word\",\n        n_features=(2**20),\n        binary=False,\n        norm=\"l2\",\n        alternate_sign=True,\n        dtype=np.float64,\n    ):\n        self.input = input\n        self.encoding = encoding\n        self.decode_error = decode_error\n        self.strip_accents = strip_accents\n        self.preprocessor = preprocessor\n        self.tokenizer = tokenizer\n        self.analyzer = analyzer\n        self.lowercase = lowercase\n        self.token_pattern = token_pattern\n        self.stop_words = stop_words\n        self.n_features = n_features\n        self.ngram_range = ngram_range\n        self.binary = binary\n        self.norm = norm\n        self.alternate_sign = alternate_sign\n        self.dtype = dtype\n", "type": "function"}, {"name": "test_pickling_built_processors", "is_method": false, "class_name": null, "parameters": ["factory"], "calls": ["pytest.mark.parametrize", "CountVectorizer", "factory", "pickle.loads", "function", "roundtripped_function", "pickle.dumps"], "code_location": {"file": "test_text.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/feature_extraction/tests", "start_line": 1062, "end_line": 1072}, "code_snippet": "def test_pickling_built_processors(factory):\n    \"\"\"Tokenizers cannot be pickled\n    https://github.com/scikit-learn/scikit-learn/issues/12833\n    \"\"\"\n    vec = CountVectorizer()\n    function = factory(vec)\n    text = \"J'ai mang du kangourou  ce midi, c'tait pas trs bon.\"\n    roundtripped_function = pickle.loads(pickle.dumps(function))\n    expected = function(text)\n    result = roundtripped_function(text)\n    assert result == expected\n", "type": "function"}, {"name": "test_unused_parameters_warn", "is_method": false, "class_name": null, "parameters": ["Vectorizer", "stop_words", "tokenizer", "preprocessor", "ngram_range", "token_pattern", "analyzer", "unused_name", "ovrd_name", "ovrd_msg"], "calls": ["pytest.mark.parametrize", "pytest.mark.parametrize", "Vectorizer", "vect.set_params", "pytest.warns", "vect.fit", "s.split", "s.split", "s.upper", "s.upper", "s.upper"], "code_location": {"file": "test_text.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/feature_extraction/tests", "start_line": 1526, "end_line": 1555}, "code_snippet": "def test_unused_parameters_warn(\n    Vectorizer,\n    stop_words,\n    tokenizer,\n    preprocessor,\n    ngram_range,\n    token_pattern,\n    analyzer,\n    unused_name,\n    ovrd_name,\n    ovrd_msg,\n):\n    train_data = JUNK_FOOD_DOCS\n    # setting parameter and checking for corresponding warning messages\n    vect = Vectorizer()\n    vect.set_params(\n        stop_words=stop_words,\n        tokenizer=tokenizer,\n        preprocessor=preprocessor,\n        ngram_range=ngram_range,\n        token_pattern=token_pattern,\n        analyzer=analyzer,\n    )\n    msg = \"The parameter %s will not be used since %s %s\" % (\n        unused_name,\n        ovrd_name,\n        ovrd_msg,\n    )\n    with pytest.warns(UserWarning, match=msg):\n        vect.fit(train_data)\n", "type": "function"}, {"name": "test_countvectorizer_empty_vocabulary", "is_method": false, "class_name": null, "parameters": [], "calls": ["pytest.raises", "CountVectorizer", "vect.fit", "pytest.raises", "CountVectorizer", "v.fit"], "code_location": {"file": "test_text.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/feature_extraction/tests", "start_line": 374, "end_line": 382}, "code_snippet": "def test_countvectorizer_empty_vocabulary():\n    with pytest.raises(ValueError, match=\"empty vocabulary\"):\n        vect = CountVectorizer(vocabulary=[])\n        vect.fit([\"foo\"])\n\n    with pytest.raises(ValueError, match=\"empty vocabulary\"):\n        v = CountVectorizer(max_df=1.0, stop_words=\"english\")\n        # fit on stopwords only\n        v.fit([\"to be or not to be\", \"and me too\", \"and so do you\"])\n", "type": "function"}, {"name": "test_vectorizer", "is_method": false, "class_name": null, "parameters": [], "calls": ["iter", "CountVectorizer", "v1.fit_transform", "hasattr", "CountVectorizer", "TfidfTransformer", "toarray", "toarray", "TfidfTransformer", "toarray", "TfidfTransformer", "assert_array_almost_equal", "iter", "TfidfVectorizer", "toarray", "assert_array_almost_equal", "toarray", "assert_array_almost_equal", "CountVectorizer", "v3.set_params", "v3.build_preprocessor", "strip_accents_ascii", "processor", "v3.set_params", "len", "counts_train.tocsr", "v.transform", "hasattr", "len", "len", "hasattr", "pytest.raises", "t3.transform", "np.sum", "pytest.raises", "v3.transform", "pytest.raises", "v3.build_preprocessor", "pytest.raises", "v3.build_analyzer", "counts_test.tocsr", "transform", "len", "t1.transform", "len", "len", "transform", "tv.fit_transform", "tv.transform", "t1.fit", "t2.fit"], "code_location": {"file": "test_text.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/feature_extraction/tests", "start_line": 514, "end_line": 614}, "code_snippet": "def test_vectorizer():\n    # raw documents as an iterator\n    train_data = iter(ALL_FOOD_DOCS[:-1])\n    test_data = [ALL_FOOD_DOCS[-1]]\n    n_train = len(ALL_FOOD_DOCS) - 1\n\n    # test without vocabulary\n    v1 = CountVectorizer(max_df=0.5)\n    counts_train = v1.fit_transform(train_data)\n    if hasattr(counts_train, \"tocsr\"):\n        counts_train = counts_train.tocsr()\n    assert counts_train[0, v1.vocabulary_[\"pizza\"]] == 2\n\n    # build a vectorizer v1 with the same vocabulary as the one fitted by v1\n    v2 = CountVectorizer(vocabulary=v1.vocabulary_)\n\n    # compare that the two vectorizer give the same output on the test sample\n    for v in (v1, v2):\n        counts_test = v.transform(test_data)\n        if hasattr(counts_test, \"tocsr\"):\n            counts_test = counts_test.tocsr()\n\n        vocabulary = v.vocabulary_\n        assert counts_test[0, vocabulary[\"salad\"]] == 1\n        assert counts_test[0, vocabulary[\"tomato\"]] == 1\n        assert counts_test[0, vocabulary[\"water\"]] == 1\n\n        # stop word from the fixed list\n        assert \"the\" not in vocabulary\n\n        # stop word found automatically by the vectorizer DF thresholding\n        # words that are high frequent across the complete corpus are likely\n        # to be not informative (either real stop words of extraction\n        # artifacts)\n        assert \"copyright\" not in vocabulary\n\n        # not present in the sample\n        assert counts_test[0, vocabulary[\"coke\"]] == 0\n        assert counts_test[0, vocabulary[\"burger\"]] == 0\n        assert counts_test[0, vocabulary[\"beer\"]] == 0\n        assert counts_test[0, vocabulary[\"pizza\"]] == 0\n\n    # test tf-idf\n    t1 = TfidfTransformer(norm=\"l1\")\n    tfidf = t1.fit(counts_train).transform(counts_train).toarray()\n    assert len(t1.idf_) == len(v1.vocabulary_)\n    assert tfidf.shape == (n_train, len(v1.vocabulary_))\n\n    # test tf-idf with new data\n    tfidf_test = t1.transform(counts_test).toarray()\n    assert tfidf_test.shape == (len(test_data), len(v1.vocabulary_))\n\n    # test tf alone\n    t2 = TfidfTransformer(norm=\"l1\", use_idf=False)\n    tf = t2.fit(counts_train).transform(counts_train).toarray()\n    assert not hasattr(t2, \"idf_\")\n\n    # test idf transform with unlearned idf vector\n    t3 = TfidfTransformer(use_idf=True)\n    with pytest.raises(ValueError):\n        t3.transform(counts_train)\n\n    # L1-normalized term frequencies sum to one\n    assert_array_almost_equal(np.sum(tf, axis=1), [1.0] * n_train)\n\n    # test the direct tfidf vectorizer\n    # (equivalent to term count vectorizer + tfidf transformer)\n    train_data = iter(ALL_FOOD_DOCS[:-1])\n    tv = TfidfVectorizer(norm=\"l1\")\n\n    tv.max_df = v1.max_df\n    tfidf2 = tv.fit_transform(train_data).toarray()\n    assert not tv.fixed_vocabulary_\n    assert_array_almost_equal(tfidf, tfidf2)\n\n    # test the direct tfidf vectorizer with new data\n    tfidf_test2 = tv.transform(test_data).toarray()\n    assert_array_almost_equal(tfidf_test, tfidf_test2)\n\n    # test transform on unfitted vectorizer with empty vocabulary\n    v3 = CountVectorizer(vocabulary=None)\n    with pytest.raises(ValueError):\n        v3.transform(train_data)\n\n    # ascii preprocessor?\n    v3.set_params(strip_accents=\"ascii\", lowercase=False)\n    processor = v3.build_preprocessor()\n    text = \"J'ai mang du kangourou  ce midi, c'tait pas trs bon.\"\n    expected = strip_accents_ascii(text)\n    result = processor(text)\n    assert expected == result\n\n    # error on bad strip_accents param\n    v3.set_params(strip_accents=\"_gabbledegook_\", preprocessor=None)\n    with pytest.raises(ValueError):\n        v3.build_preprocessor()\n\n    # error with bad analyzer type\n    v3.set_params = \"_invalid_analyzer_type_\"\n    with pytest.raises(ValueError):\n        v3.build_analyzer()\n", "type": "function"}], "retrieved_count": 10, "cost_time": 0.3365457057952881}
{"question": "Where in the codebase are the constraint validation classes that invoke InvalidParameterError, and how does the error propagation chain from _Constraint subclasses back to the parameter validation entry points?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"name": "check_param_validation", "is_method": false, "class_name": null, "parameters": ["name", "estimator_orig"], "calls": ["np.random.RandomState", "rng.uniform", "rng.randint", "_enforce_estimator_tags_y", "get_tags", "keys", "estimator_orig._parameter_constraints.keys", "type", "clone", "estimator.set_params", "estimator_orig.get_params", "set", "set", "set", "set", "any", "any", "ValueError", "make_constraint", "estimator.set_params", "hasattr", "raises", "generate_invalid_param_val", "hasattr", "raises", "isinstance", "isinstance", "getattr", "getattr", "getattr", "getattr"], "code_location": {"file": "estimator_checks.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/utils", "start_line": 4843, "end_line": 4954}, "code_snippet": "def check_param_validation(name, estimator_orig):\n    # Check that an informative error is raised when the value of a constructor\n    # parameter does not have an appropriate type or value.\n    rng = np.random.RandomState(0)\n    X = rng.uniform(size=(20, 5))\n    y = rng.randint(0, 2, size=20)\n    y = _enforce_estimator_tags_y(estimator_orig, y)\n    tags = get_tags(estimator_orig)\n\n    estimator_params = estimator_orig.get_params(deep=False).keys()\n\n    # check that there is a constraint for each parameter\n    if estimator_params:\n        validation_params = estimator_orig._parameter_constraints.keys()\n        unexpected_params = set(validation_params) - set(estimator_params)\n        missing_params = set(estimator_params) - set(validation_params)\n        err_msg = (\n            f\"Mismatch between _parameter_constraints and the parameters of {name}.\"\n            f\"\\nConsider the unexpected parameters {unexpected_params} and expected but\"\n            f\" missing parameters {missing_params}\"\n        )\n        assert validation_params == estimator_params, err_msg\n\n    # this object does not have a valid type for sure for all params\n    param_with_bad_type = type(\"BadType\", (), {})()\n\n    fit_methods = [\"fit\", \"partial_fit\", \"fit_transform\", \"fit_predict\"]\n\n    for param_name in estimator_params:\n        constraints = estimator_orig._parameter_constraints[param_name]\n\n        if constraints == \"no_validation\":\n            # This parameter is not validated\n            continue\n\n        # Mixing an interval of reals and an interval of integers must be avoided.\n        if any(\n            isinstance(constraint, Interval) and constraint.type == Integral\n            for constraint in constraints\n        ) and any(\n            isinstance(constraint, Interval) and constraint.type == Real\n            for constraint in constraints\n        ):\n            raise ValueError(\n                f\"The constraint for parameter {param_name} of {name} can't have a mix\"\n                \" of intervals of Integral and Real types. Use the type RealNotInt\"\n                \" instead of Real.\"\n            )\n\n        match = rf\"The '{param_name}' parameter of {name} must be .* Got .* instead.\"\n        err_msg = (\n            f\"{name} does not raise an informative error message when the \"\n            f\"parameter {param_name} does not have a valid type or value.\"\n        )\n\n        estimator = clone(estimator_orig)\n\n        # First, check that the error is raised if param doesn't match any valid type.\n        estimator.set_params(**{param_name: param_with_bad_type})\n\n        for method in fit_methods:\n            if not hasattr(estimator, method):\n                # the method is not accessible with the current set of parameters\n                continue\n\n            err_msg = (\n                f\"{name} does not raise an informative error message when the parameter\"\n                f\" {param_name} does not have a valid type. If any Python type is\"\n                \" valid, the constraint should be 'no_validation'.\"\n            )\n\n            with raises(InvalidParameterError, match=match, err_msg=err_msg):\n                if tags.target_tags.one_d_labels or tags.target_tags.two_d_labels:\n                    # The estimator is a label transformer and take only `y`\n                    getattr(estimator, method)(y)\n                else:\n                    getattr(estimator, method)(X, y)\n\n        # Then, for constraints that are more than a type constraint, check that the\n        # error is raised if param does match a valid type but does not match any valid\n        # value for this type.\n        constraints = [make_constraint(constraint) for constraint in constraints]\n\n        for constraint in constraints:\n            try:\n                bad_value = generate_invalid_param_val(constraint)\n            except NotImplementedError:\n                continue\n\n            estimator.set_params(**{param_name: bad_value})\n\n            for method in fit_methods:\n                if not hasattr(estimator, method):\n                    # the method is not accessible with the current set of parameters\n                    continue\n\n                err_msg = (\n                    f\"{name} does not raise an informative error message when the \"\n                    f\"parameter {param_name} does not have a valid value.\\n\"\n                    \"Constraints should be disjoint. For instance \"\n                    \"[StrOptions({'a_string'}), str] is not a acceptable set of \"\n                    \"constraint because generating an invalid string for the first \"\n                    \"constraint will always produce a valid string for the second \"\n                    \"constraint.\"\n                )\n\n                with raises(InvalidParameterError, match=match, err_msg=err_msg):\n                    if tags.target_tags.one_d_labels or tags.target_tags.two_d_labels:\n                        # The estimator is a label transformer and take only `y`\n                        getattr(estimator, method)(y)\n                    else:\n                        getattr(estimator, method)(X, y)\n", "type": "function"}, {"name": "test_hidden_constraint", "is_method": false, "class_name": null, "parameters": [], "calls": ["validate_params", "f", "f", "str", "pytest.raises", "f", "Hidden"], "code_location": {"file": "test_param_validation.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/utils/tests", "start_line": 566, "end_line": 587}, "code_snippet": "def test_hidden_constraint():\n    \"\"\"Check that internal constraints are not exposed in the error message.\"\"\"\n\n    @validate_params(\n        {\"param\": [Hidden(list), dict]}, prefer_skip_nested_validation=True\n    )\n    def f(param):\n        pass\n\n    # list and dict are valid params\n    f({\"a\": 1, \"b\": 2, \"c\": 3})\n    f([1, 2, 3])\n\n    with pytest.raises(\n        InvalidParameterError, match=\"The 'param' parameter\"\n    ) as exc_info:\n        f(param=\"bad\")\n\n    # the list option is not exposed in the error message\n    err_msg = str(exc_info.value)\n    assert \"an instance of 'dict'\" in err_msg\n    assert \"an instance of 'list'\" not in err_msg\n", "type": "function"}, {"name": "_Constraint", "docstring": "Base class for the constraint objects.", "methods": ["__init__", "is_satisfied_by", "__str__"], "attributes": [], "code_location": {"file": "_param_validation.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/utils", "start_line": 261, "end_line": 284}, "type": "class"}, {"name": "Hidden", "docstring": "Class encapsulating a constraint not meant to be exposed to the user.\n\nParameters\n----------\nconstraint : str or _Constraint instance\n    The constraint to be used internally.", "methods": ["__init__"], "attributes": [], "code_location": {"file": "_param_validation.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/utils", "start_line": 753, "end_line": 763}, "type": "class"}, {"name": "InvalidParameterError", "docstring": "Custom exception to be raised when the parameter of a class/method/function\ndoes not have a valid type or value.", "methods": [], "attributes": [], "code_location": {"file": "_param_validation.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/utils", "start_line": 20, "end_line": 23}, "type": "class"}, {"name": "validate_parameter_constraints", "is_method": false, "class_name": null, "parameters": ["parameter_constraints", "params", "caller_name"], "calls": ["params.items", "make_constraint", "constraint.is_satisfied_by", "InvalidParameterError", "len", "join", "str"], "code_location": {"file": "_param_validation.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/utils", "start_line": 28, "end_line": 101}, "code_snippet": "def validate_parameter_constraints(parameter_constraints, params, caller_name):\n    \"\"\"Validate types and values of given parameters.\n\n    Parameters\n    ----------\n    parameter_constraints : dict or {\"no_validation\"}\n        If \"no_validation\", validation is skipped for this parameter.\n\n        If a dict, it must be a dictionary `param_name: list of constraints`.\n        A parameter is valid if it satisfies one of the constraints from the list.\n        Constraints can be:\n        - an Interval object, representing a continuous or discrete range of numbers\n        - the string \"array-like\"\n        - the string \"sparse matrix\"\n        - the string \"random_state\"\n        - callable\n        - None, meaning that None is a valid value for the parameter\n        - any type, meaning that any instance of this type is valid\n        - an Options object, representing a set of elements of a given type\n        - a StrOptions object, representing a set of strings\n        - the string \"boolean\"\n        - the string \"verbose\"\n        - the string \"cv_object\"\n        - the string \"nan\"\n        - a MissingValues object representing markers for missing values\n        - a HasMethods object, representing method(s) an object must have\n        - a Hidden object, representing a constraint not meant to be exposed to the user\n\n    params : dict\n        A dictionary `param_name: param_value`. The parameters to validate against the\n        constraints.\n\n    caller_name : str\n        The name of the estimator or function or method that called this function.\n    \"\"\"\n    for param_name, param_val in params.items():\n        # We allow parameters to not have a constraint so that third party estimators\n        # can inherit from sklearn estimators without having to necessarily use the\n        # validation tools.\n        if param_name not in parameter_constraints:\n            continue\n\n        constraints = parameter_constraints[param_name]\n\n        if constraints == \"no_validation\":\n            continue\n\n        constraints = [make_constraint(constraint) for constraint in constraints]\n\n        for constraint in constraints:\n            if constraint.is_satisfied_by(param_val):\n                # this constraint is satisfied, no need to check further.\n                break\n        else:\n            # No constraint is satisfied, raise with an informative message.\n\n            # Ignore constraints that we don't want to expose in the error message,\n            # i.e. options that are for internal purpose or not officially supported.\n            constraints = [\n                constraint for constraint in constraints if not constraint.hidden\n            ]\n\n            if len(constraints) == 1:\n                constraints_str = f\"{constraints[0]}\"\n            else:\n                constraints_str = (\n                    f\"{', '.join([str(c) for c in constraints[:-1]])} or\"\n                    f\" {constraints[-1]}\"\n                )\n\n            raise InvalidParameterError(\n                f\"The {param_name!r} parameter of {caller_name} must be\"\n                f\" {constraints_str}. Got {param_val!r} instead.\"\n            )\n", "type": "function"}, {"name": "test_validate_params_set_param_constraints_attribute", "is_method": false, "class_name": null, "parameters": [], "calls": ["hasattr", "hasattr", "_Class"], "code_location": {"file": "test_param_validation.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/utils/tests", "start_line": 615, "end_line": 620}, "code_snippet": "def test_validate_params_set_param_constraints_attribute():\n    \"\"\"Check that the validate_params decorator properly sets the parameter constraints\n    as attribute of the decorated function/method.\n    \"\"\"\n    assert hasattr(_func, \"_skl_parameter_constraints\")\n    assert hasattr(_Class()._method, \"_skl_parameter_constraints\")\n", "type": "function"}, {"name": "_validate_params", "is_method": true, "class_name": "BaseEstimator", "parameters": ["self"], "calls": ["validate_parameter_constraints", "self.get_params"], "code_location": {"file": "base.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn", "start_line": 463, "end_line": 475}, "code_snippet": "    def _validate_params(self):\n        \"\"\"Validate types and values of constructor parameters\n\n        The expected type and values must be defined in the `_parameter_constraints`\n        class attribute, which is a dictionary `param_name: list of constraints`. See\n        the docstring of `validate_parameter_constraints` for a description of the\n        accepted constraints.\n        \"\"\"\n        validate_parameter_constraints(\n            self._parameter_constraints,\n            self.get_params(deep=False),\n            caller_name=self.__class__.__name__,\n        )\n", "type": "function"}, {"name": "_NanConstraint", "docstring": "Constraint representing the indicator `np.nan`.", "methods": ["is_satisfied_by", "__str__"], "attributes": [], "code_location": {"file": "_param_validation.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/utils", "start_line": 317, "end_line": 326}, "type": "class"}, {"name": "_check_function_param_validation", "is_method": false, "class_name": null, "parameters": ["func", "func_name", "func_params", "required_params", "parameter_constraints"], "calls": ["parameter_constraints.keys", "type", "generate_valid_param", "set", "set", "set", "set", "set", "set", "any", "any", "ValueError", "pytest.raises", "func", "pytest.fail", "make_constraint", "make_constraint", "generate_invalid_param_val", "pytest.raises", "func", "pytest.fail", "isinstance", "isinstance"], "code_location": {"file": "test_public_functions.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/tests", "start_line": 39, "end_line": 129}, "code_snippet": "def _check_function_param_validation(\n    func, func_name, func_params, required_params, parameter_constraints\n):\n    \"\"\"Check that an informative error is raised when the value of a parameter does not\n    have an appropriate type or value.\n    \"\"\"\n    # generate valid values for the required parameters\n    valid_required_params = {}\n    for param_name in required_params:\n        if parameter_constraints[param_name] == \"no_validation\":\n            valid_required_params[param_name] = 1\n        else:\n            valid_required_params[param_name] = generate_valid_param(\n                make_constraint(parameter_constraints[param_name][0])\n            )\n\n    # check that there is a constraint for each parameter\n    if func_params:\n        validation_params = parameter_constraints.keys()\n        unexpected_params = set(validation_params) - set(func_params)\n        missing_params = set(func_params) - set(validation_params)\n        err_msg = (\n            \"Mismatch between _parameter_constraints and the parameters of\"\n            f\" {func_name}.\\nConsider the unexpected parameters {unexpected_params} and\"\n            f\" expected but missing parameters {missing_params}\\n\"\n        )\n        assert set(validation_params) == set(func_params), err_msg\n\n    # this object does not have a valid type for sure for all params\n    param_with_bad_type = type(\"BadType\", (), {})()\n\n    for param_name in func_params:\n        constraints = parameter_constraints[param_name]\n\n        if constraints == \"no_validation\":\n            # This parameter is not validated\n            continue\n\n        # Mixing an interval of reals and an interval of integers must be avoided.\n        if any(\n            isinstance(constraint, Interval) and constraint.type == Integral\n            for constraint in constraints\n        ) and any(\n            isinstance(constraint, Interval) and constraint.type == Real\n            for constraint in constraints\n        ):\n            raise ValueError(\n                f\"The constraint for parameter {param_name} of {func_name} can't have a\"\n                \" mix of intervals of Integral and Real types. Use the type\"\n                \" RealNotInt instead of Real.\"\n            )\n\n        match = (\n            rf\"The '{param_name}' parameter of {func_name} must be .* Got .* instead.\"\n        )\n\n        err_msg = (\n            f\"{func_name} does not raise an informative error message when the \"\n            f\"parameter {param_name} does not have a valid type. If any Python type \"\n            \"is valid, the constraint should be 'no_validation'.\"\n        )\n\n        # First, check that the error is raised if param doesn't match any valid type.\n        with pytest.raises(InvalidParameterError, match=match):\n            func(**{**valid_required_params, param_name: param_with_bad_type})\n            pytest.fail(err_msg)\n\n        # Then, for constraints that are more than a type constraint, check that the\n        # error is raised if param does match a valid type but does not match any valid\n        # value for this type.\n        constraints = [make_constraint(constraint) for constraint in constraints]\n\n        for constraint in constraints:\n            try:\n                bad_value = generate_invalid_param_val(constraint)\n            except NotImplementedError:\n                continue\n\n            err_msg = (\n                f\"{func_name} does not raise an informative error message when the \"\n                f\"parameter {param_name} does not have a valid value.\\n\"\n                \"Constraints should be disjoint. For instance \"\n                \"[StrOptions({'a_string'}), str] is not a acceptable set of \"\n                \"constraint because generating an invalid string for the first \"\n                \"constraint will always produce a valid string for the second \"\n                \"constraint.\"\n            )\n\n            with pytest.raises(InvalidParameterError, match=match):\n                func(**{**valid_required_params, param_name: bad_value})\n                pytest.fail(err_msg)\n", "type": "function"}], "retrieved_count": 10, "cost_time": 0.337770938873291}
{"question": "Where in the codebase do functions conditionally invoke the _CVObjects constraint validation logic, and how does the constraint's is_satisfied_by method propagate validation results through the parameter validation framework?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"name": "test_cv_objects", "is_method": false, "class_name": null, "parameters": [], "calls": ["_CVObjects", "constraint.is_satisfied_by", "constraint.is_satisfied_by", "constraint.is_satisfied_by", "constraint.is_satisfied_by", "LeaveOneOut", "constraint.is_satisfied_by"], "code_location": {"file": "test_param_validation.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/utils/tests", "start_line": 676, "end_line": 684}, "code_snippet": "def test_cv_objects():\n    \"\"\"Check that the _CVObjects constraint accepts all current ways\n    to pass cv objects.\"\"\"\n    constraint = _CVObjects()\n    assert constraint.is_satisfied_by(5)\n    assert constraint.is_satisfied_by(LeaveOneOut())\n    assert constraint.is_satisfied_by([([1, 2], [3, 4]), ([3, 4], [1, 2])])\n    assert constraint.is_satisfied_by(None)\n    assert not constraint.is_satisfied_by(\"not a CV object\")\n", "type": "function"}, {"name": "is_satisfied_by", "is_method": true, "class_name": "_Constraint", "parameters": ["self", "val"], "calls": [], "code_location": {"file": "_param_validation.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/utils", "start_line": 268, "end_line": 280}, "code_snippet": "    def is_satisfied_by(self, val):\n        \"\"\"Whether or not a value satisfies the constraint.\n\n        Parameters\n        ----------\n        val : object\n            The value to check.\n\n        Returns\n        -------\n        is_satisfied : bool\n            Whether or not the constraint is satisfied by this value.\n        \"\"\"\n", "type": "function"}, {"name": "test_validate_params_set_param_constraints_attribute", "is_method": false, "class_name": null, "parameters": [], "calls": ["hasattr", "hasattr", "_Class"], "code_location": {"file": "test_param_validation.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/utils/tests", "start_line": 615, "end_line": 620}, "code_snippet": "def test_validate_params_set_param_constraints_attribute():\n    \"\"\"Check that the validate_params decorator properly sets the parameter constraints\n    as attribute of the decorated function/method.\n    \"\"\"\n    assert hasattr(_func, \"_skl_parameter_constraints\")\n    assert hasattr(_Class()._method, \"_skl_parameter_constraints\")\n", "type": "function"}, {"name": "is_satisfied_by", "is_method": true, "class_name": "_Booleans", "parameters": ["self", "val"], "calls": ["any", "c.is_satisfied_by"], "code_location": {"file": "_param_validation.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/utils", "start_line": 596, "end_line": 597}, "code_snippet": "    def is_satisfied_by(self, val):\n        return any(c.is_satisfied_by(val) for c in self._constraints)\n", "type": "function"}, {"name": "is_satisfied_by", "is_method": true, "class_name": "_RandomStates", "parameters": ["self", "val"], "calls": ["any", "c.is_satisfied_by"], "code_location": {"file": "_param_validation.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/utils", "start_line": 572, "end_line": 573}, "code_snippet": "    def is_satisfied_by(self, val):\n        return any(c.is_satisfied_by(val) for c in self._constraints)\n", "type": "function"}, {"name": "is_satisfied_by", "is_method": true, "class_name": "_CVObjects", "parameters": ["self", "val"], "calls": ["any", "c.is_satisfied_by"], "code_location": {"file": "_param_validation.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/utils", "start_line": 743, "end_line": 744}, "code_snippet": "    def is_satisfied_by(self, val):\n        return any(c.is_satisfied_by(val) for c in self._constraints)\n", "type": "function"}, {"name": "is_satisfied_by", "is_method": true, "class_name": "MissingValues", "parameters": ["self", "val"], "calls": ["any", "c.is_satisfied_by"], "code_location": {"file": "_param_validation.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/utils", "start_line": 666, "end_line": 667}, "code_snippet": "    def is_satisfied_by(self, val):\n        return any(c.is_satisfied_by(val) for c in self._constraints)\n", "type": "function"}, {"name": "is_satisfied_by", "is_method": true, "class_name": "_VerboseHelper", "parameters": ["self", "val"], "calls": ["any", "c.is_satisfied_by"], "code_location": {"file": "_param_validation.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/utils", "start_line": 621, "end_line": 622}, "code_snippet": "    def is_satisfied_by(self, val):\n        return any(c.is_satisfied_by(val) for c in self._constraints)\n", "type": "function"}, {"name": "test_generate_valid_param", "is_method": false, "class_name": null, "parameters": ["constraint"], "calls": ["pytest.mark.parametrize", "generate_valid_param", "constraint.is_satisfied_by", "_ArrayLikes", "_Callables", "_InstancesOf", "_NoneConstraint", "_RandomStates", "_SparseMatrices", "_Booleans", "_VerboseHelper", "MissingValues", "MissingValues", "StrOptions", "Options", "Interval", "Interval", "Interval", "Interval", "Interval", "Interval", "Interval", "HasMethods", "_IterablesNotString", "_CVObjects"], "code_location": {"file": "test_param_validation.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/utils/tests", "start_line": 391, "end_line": 394}, "code_snippet": "def test_generate_valid_param(constraint):\n    \"\"\"Check that the value generated does satisfy the constraint.\"\"\"\n    value = generate_valid_param(constraint)\n    assert constraint.is_satisfied_by(value)\n", "type": "function"}, {"name": "check_param_validation", "is_method": false, "class_name": null, "parameters": ["name", "estimator_orig"], "calls": ["np.random.RandomState", "rng.uniform", "rng.randint", "_enforce_estimator_tags_y", "get_tags", "keys", "estimator_orig._parameter_constraints.keys", "type", "clone", "estimator.set_params", "estimator_orig.get_params", "set", "set", "set", "set", "any", "any", "ValueError", "make_constraint", "estimator.set_params", "hasattr", "raises", "generate_invalid_param_val", "hasattr", "raises", "isinstance", "isinstance", "getattr", "getattr", "getattr", "getattr"], "code_location": {"file": "estimator_checks.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/utils", "start_line": 4843, "end_line": 4954}, "code_snippet": "def check_param_validation(name, estimator_orig):\n    # Check that an informative error is raised when the value of a constructor\n    # parameter does not have an appropriate type or value.\n    rng = np.random.RandomState(0)\n    X = rng.uniform(size=(20, 5))\n    y = rng.randint(0, 2, size=20)\n    y = _enforce_estimator_tags_y(estimator_orig, y)\n    tags = get_tags(estimator_orig)\n\n    estimator_params = estimator_orig.get_params(deep=False).keys()\n\n    # check that there is a constraint for each parameter\n    if estimator_params:\n        validation_params = estimator_orig._parameter_constraints.keys()\n        unexpected_params = set(validation_params) - set(estimator_params)\n        missing_params = set(estimator_params) - set(validation_params)\n        err_msg = (\n            f\"Mismatch between _parameter_constraints and the parameters of {name}.\"\n            f\"\\nConsider the unexpected parameters {unexpected_params} and expected but\"\n            f\" missing parameters {missing_params}\"\n        )\n        assert validation_params == estimator_params, err_msg\n\n    # this object does not have a valid type for sure for all params\n    param_with_bad_type = type(\"BadType\", (), {})()\n\n    fit_methods = [\"fit\", \"partial_fit\", \"fit_transform\", \"fit_predict\"]\n\n    for param_name in estimator_params:\n        constraints = estimator_orig._parameter_constraints[param_name]\n\n        if constraints == \"no_validation\":\n            # This parameter is not validated\n            continue\n\n        # Mixing an interval of reals and an interval of integers must be avoided.\n        if any(\n            isinstance(constraint, Interval) and constraint.type == Integral\n            for constraint in constraints\n        ) and any(\n            isinstance(constraint, Interval) and constraint.type == Real\n            for constraint in constraints\n        ):\n            raise ValueError(\n                f\"The constraint for parameter {param_name} of {name} can't have a mix\"\n                \" of intervals of Integral and Real types. Use the type RealNotInt\"\n                \" instead of Real.\"\n            )\n\n        match = rf\"The '{param_name}' parameter of {name} must be .* Got .* instead.\"\n        err_msg = (\n            f\"{name} does not raise an informative error message when the \"\n            f\"parameter {param_name} does not have a valid type or value.\"\n        )\n\n        estimator = clone(estimator_orig)\n\n        # First, check that the error is raised if param doesn't match any valid type.\n        estimator.set_params(**{param_name: param_with_bad_type})\n\n        for method in fit_methods:\n            if not hasattr(estimator, method):\n                # the method is not accessible with the current set of parameters\n                continue\n\n            err_msg = (\n                f\"{name} does not raise an informative error message when the parameter\"\n                f\" {param_name} does not have a valid type. If any Python type is\"\n                \" valid, the constraint should be 'no_validation'.\"\n            )\n\n            with raises(InvalidParameterError, match=match, err_msg=err_msg):\n                if tags.target_tags.one_d_labels or tags.target_tags.two_d_labels:\n                    # The estimator is a label transformer and take only `y`\n                    getattr(estimator, method)(y)\n                else:\n                    getattr(estimator, method)(X, y)\n\n        # Then, for constraints that are more than a type constraint, check that the\n        # error is raised if param does match a valid type but does not match any valid\n        # value for this type.\n        constraints = [make_constraint(constraint) for constraint in constraints]\n\n        for constraint in constraints:\n            try:\n                bad_value = generate_invalid_param_val(constraint)\n            except NotImplementedError:\n                continue\n\n            estimator.set_params(**{param_name: bad_value})\n\n            for method in fit_methods:\n                if not hasattr(estimator, method):\n                    # the method is not accessible with the current set of parameters\n                    continue\n\n                err_msg = (\n                    f\"{name} does not raise an informative error message when the \"\n                    f\"parameter {param_name} does not have a valid value.\\n\"\n                    \"Constraints should be disjoint. For instance \"\n                    \"[StrOptions({'a_string'}), str] is not a acceptable set of \"\n                    \"constraint because generating an invalid string for the first \"\n                    \"constraint will always produce a valid string for the second \"\n                    \"constraint.\"\n                )\n\n                with raises(InvalidParameterError, match=match, err_msg=err_msg):\n                    if tags.target_tags.one_d_labels or tags.target_tags.two_d_labels:\n                        # The estimator is a label transformer and take only `y`\n                        getattr(estimator, method)(y)\n                    else:\n                        getattr(estimator, method)(X, y)\n", "type": "function"}], "retrieved_count": 10, "cost_time": 0.36771488189697266}
{"question": "Where in the scikit-learn repository are the manifold learning classes and dimensionality reduction algorithms imported and utilized within the plot_embedding function's execution context?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"name": "plot_embedding", "is_method": false, "class_name": null, "parameters": ["X", "title"], "calls": ["plt.subplots", "fit_transform", "np.array", "range", "ax.set_title", "ax.axis", "ax.scatter", "np.sum", "np.concatenate", "offsetbox.AnnotationBbox", "imagebox.set", "ax.add_artist", "MinMaxScaler", "np.min", "offsetbox.OffsetImage", "plt.cm.Dark2"], "code_location": {"file": "plot_lle_digits.py", "path": "/data3/pwh/swebench-repos/scikit-learn/examples/manifold", "start_line": 47, "end_line": 76}, "code_snippet": "def plot_embedding(X, title):\n    _, ax = plt.subplots()\n    X = MinMaxScaler().fit_transform(X)\n\n    for digit in digits.target_names:\n        ax.scatter(\n            *X[y == digit].T,\n            marker=f\"${digit}$\",\n            s=60,\n            color=plt.cm.Dark2(digit),\n            alpha=0.425,\n            zorder=2,\n        )\n    shown_images = np.array([[1.0, 1.0]])  # just something big\n    for i in range(X.shape[0]):\n        # plot every digit on the embedding\n        # show an annotation box for a group of digits\n        dist = np.sum((X[i] - shown_images) ** 2, 1)\n        if np.min(dist) < 4e-3:\n            # don't show points that are too close\n            continue\n        shown_images = np.concatenate([shown_images, [X[i]]], axis=0)\n        imagebox = offsetbox.AnnotationBbox(\n            offsetbox.OffsetImage(digits.images[i], cmap=plt.cm.gray_r), X[i]\n        )\n        imagebox.set(zorder=1)\n        ax.add_artist(imagebox)\n\n    ax.set_title(title)\n    ax.axis(\"off\")\n", "type": "function"}, {"name": "SpectralEmbedding", "docstring": "Spectral embedding for non-linear dimensionality reduction.\n\nForms an affinity matrix given by the specified function and\napplies spectral decomposition to the corresponding graph laplacian.\nThe resulting transformation is given by the value of the\neigenvectors for each data point.\n\nNote : Laplacian Eigenmaps is the actual algorithm implemented here.\n\nRead more in the :ref:`User Guide <spectral_embedding>`.\n\nParameters\n----------\nn_components : int, default=2\n    The dimension of the projected subspace.\n\naffinity : {'nearest_neighbors', 'rbf', 'precomputed',                 'precomputed_nearest_neighbors'} or callable,                 default='nearest_neighbors'\n    How to construct the affinity matrix.\n     - 'nearest_neighbors' : construct the affinity matrix by computing a\n       graph of nearest neighbors.\n     - 'rbf' : construct the affinity matrix by computing a radial basis\n       function (RBF) kernel.\n     - 'precomputed' : interpret ``X`` as a precomputed affinity matrix.\n     - 'precomputed_nearest_neighbors' : interpret ``X`` as a sparse graph\n       of precomputed nearest neighbors, and constructs the affinity matrix\n       by selecting the ``n_neighbors`` nearest neighbors.\n     - callable : use passed in function as affinity\n       the function takes in data matrix (n_samples, n_features)\n       and return affinity matrix (n_samples, n_samples).\n\ngamma : float, default=None\n    Kernel coefficient for rbf kernel. If None, gamma will be set to\n    1/n_features.\n\nrandom_state : int, RandomState instance or None, default=None\n    A pseudo random number generator used for the initialization\n    of the lobpcg eigen vectors decomposition when `eigen_solver ==\n    'amg'`, and for the K-Means initialization. Use an int to make\n    the results deterministic across calls (See\n    :term:`Glossary <random_state>`).\n\n    .. note::\n        When using `eigen_solver == 'amg'`,\n        it is necessary to also fix the global numpy seed with\n        `np.random.seed(int)` to get deterministic results. See\n        https://github.com/pyamg/pyamg/issues/139 for further\n        information.\n\neigen_solver : {'arpack', 'lobpcg', 'amg'}, default=None\n    The eigenvalue decomposition strategy to use. AMG requires pyamg\n    to be installed. It can be faster on very large, sparse problems.\n    If None, then ``'arpack'`` is used.\n\neigen_tol : float, default=\"auto\"\n    Stopping criterion for eigendecomposition of the Laplacian matrix.\n    If `eigen_tol=\"auto\"` then the passed tolerance will depend on the\n    `eigen_solver`:\n\n    - If `eigen_solver=\"arpack\"`, then `eigen_tol=0.0`;\n    - If `eigen_solver=\"lobpcg\"` or `eigen_solver=\"amg\"`, then\n      `eigen_tol=None` which configures the underlying `lobpcg` solver to\n      automatically resolve the value according to their heuristics. See,\n      :func:`scipy.sparse.linalg.lobpcg` for details.\n\n    Note that when using `eigen_solver=\"lobpcg\"` or `eigen_solver=\"amg\"`\n    values of `tol<1e-5` may lead to convergence issues and should be\n    avoided.\n\n    .. versionadded:: 1.2\n\nn_neighbors : int, default=None\n    Number of nearest neighbors for nearest_neighbors graph building.\n    If None, n_neighbors will be set to max(n_samples/10, 1).\n\nn_jobs : int, default=None\n    The number of parallel jobs to run.\n    ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n    ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n    for more details.\n\nAttributes\n----------\nembedding_ : ndarray of shape (n_samples, n_components)\n    Spectral embedding of the training matrix.\n\naffinity_matrix_ : ndarray of shape (n_samples, n_samples)\n    Affinity_matrix constructed from samples or precomputed.\n\nn_features_in_ : int\n    Number of features seen during :term:`fit`.\n\n    .. versionadded:: 0.24\n\nfeature_names_in_ : ndarray of shape (`n_features_in_`,)\n    Names of features seen during :term:`fit`. Defined only when `X`\n    has feature names that are all strings.\n\n    .. versionadded:: 1.0\n\nn_neighbors_ : int\n    Number of nearest neighbors effectively used.\n\nSee Also\n--------\nIsomap : Non-linear dimensionality reduction through Isometric Mapping.\n\nReferences\n----------\n\n- :doi:`A Tutorial on Spectral Clustering, 2007\n  Ulrike von Luxburg\n  <10.1007/s11222-007-9033-z>`\n\n- `On Spectral Clustering: Analysis and an algorithm, 2001\n  Andrew Y. Ng, Michael I. Jordan, Yair Weiss\n  <https://citeseerx.ist.psu.edu/doc_view/pid/796c5d6336fc52aa84db575fb821c78918b65f58>`_\n\n- :doi:`Normalized cuts and image segmentation, 2000\n  Jianbo Shi, Jitendra Malik\n  <10.1109/34.868688>`\n\nExamples\n--------\n>>> from sklearn.datasets import load_digits\n>>> from sklearn.manifold import SpectralEmbedding\n>>> X, _ = load_digits(return_X_y=True)\n>>> X.shape\n(1797, 64)\n>>> embedding = SpectralEmbedding(n_components=2)\n>>> X_transformed = embedding.fit_transform(X[:100])\n>>> X_transformed.shape\n(100, 2)", "methods": ["__init__", "__sklearn_tags__", "_get_affinity_matrix", "fit", "fit_transform"], "attributes": [], "code_location": {"file": "_spectral_embedding.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/manifold", "start_line": 466, "end_line": 772}, "type": "class"}, {"name": "LocallyLinearEmbedding", "docstring": "Locally Linear Embedding.\n\nRead more in the :ref:`User Guide <locally_linear_embedding>`.\n\nParameters\n----------\nn_neighbors : int, default=5\n    Number of neighbors to consider for each point.\n\nn_components : int, default=2\n    Number of coordinates for the manifold.\n\nreg : float, default=1e-3\n    Regularization constant, multiplies the trace of the local covariance\n    matrix of the distances.\n\neigen_solver : {'auto', 'arpack', 'dense'}, default='auto'\n    The solver used to compute the eigenvectors. The available options are:\n\n    - `'auto'` : algorithm will attempt to choose the best method for input\n      data.\n    - `'arpack'` : use arnoldi iteration in shift-invert mode. For this\n      method, M may be a dense matrix, sparse matrix, or general linear\n      operator.\n    - `'dense'`  : use standard dense matrix operations for the eigenvalue\n      decomposition. For this method, M must be an array or matrix type.\n      This method should be avoided for large problems.\n\n    .. warning::\n       ARPACK can be unstable for some problems.  It is best to try several\n       random seeds in order to check results.\n\ntol : float, default=1e-6\n    Tolerance for 'arpack' method\n    Not used if eigen_solver=='dense'.\n\nmax_iter : int, default=100\n    Maximum number of iterations for the arpack solver.\n    Not used if eigen_solver=='dense'.\n\nmethod : {'standard', 'hessian', 'modified', 'ltsa'}, default='standard'\n    - `standard`: use the standard locally linear embedding algorithm. see\n      reference [1]_\n    - `hessian`: use the Hessian eigenmap method. This method requires\n      ``n_neighbors > n_components * (1 + (n_components + 1) / 2``. see\n      reference [2]_\n    - `modified`: use the modified locally linear embedding algorithm.\n      see reference [3]_\n    - `ltsa`: use local tangent space alignment algorithm. see\n      reference [4]_\n\nhessian_tol : float, default=1e-4\n    Tolerance for Hessian eigenmapping method.\n    Only used if ``method == 'hessian'``.\n\nmodified_tol : float, default=1e-12\n    Tolerance for modified LLE method.\n    Only used if ``method == 'modified'``.\n\nneighbors_algorithm : {'auto', 'brute', 'kd_tree', 'ball_tree'},                           default='auto'\n    Algorithm to use for nearest neighbors search, passed to\n    :class:`~sklearn.neighbors.NearestNeighbors` instance.\n\nrandom_state : int, RandomState instance, default=None\n    Determines the random number generator when\n    ``eigen_solver`` == 'arpack'. Pass an int for reproducible results\n    across multiple function calls. See :term:`Glossary <random_state>`.\n\nn_jobs : int or None, default=None\n    The number of parallel jobs to run.\n    ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n    ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n    for more details.\n\nAttributes\n----------\nembedding_ : array-like, shape [n_samples, n_components]\n    Stores the embedding vectors\n\nreconstruction_error_ : float\n    Reconstruction error associated with `embedding_`\n\nn_features_in_ : int\n    Number of features seen during :term:`fit`.\n\n    .. versionadded:: 0.24\n\nfeature_names_in_ : ndarray of shape (`n_features_in_`,)\n    Names of features seen during :term:`fit`. Defined only when `X`\n    has feature names that are all strings.\n\n    .. versionadded:: 1.0\n\nnbrs_ : NearestNeighbors object\n    Stores nearest neighbors instance, including BallTree or KDtree\n    if applicable.\n\nSee Also\n--------\nSpectralEmbedding : Spectral embedding for non-linear dimensionality\n    reduction.\nTSNE : Distributed Stochastic Neighbor Embedding.\n\nReferences\n----------\n\n.. [1] Roweis, S. & Saul, L. Nonlinear dimensionality reduction\n    by locally linear embedding.  Science 290:2323 (2000).\n.. [2] Donoho, D. & Grimes, C. Hessian eigenmaps: Locally\n    linear embedding techniques for high-dimensional data.\n    Proc Natl Acad Sci U S A.  100:5591 (2003).\n.. [3] `Zhang, Z. & Wang, J. MLLE: Modified Locally Linear\n    Embedding Using Multiple Weights.\n    <https://citeseerx.ist.psu.edu/doc_view/pid/0b060fdbd92cbcc66b383bcaa9ba5e5e624d7ee3>`_\n.. [4] Zhang, Z. & Zha, H. Principal manifolds and nonlinear\n    dimensionality reduction via tangent space alignment.\n    Journal of Shanghai Univ.  8:406 (2004)\n\nExamples\n--------\n>>> from sklearn.datasets import load_digits\n>>> from sklearn.manifold import LocallyLinearEmbedding\n>>> X, _ = load_digits(return_X_y=True)\n>>> X.shape\n(1797, 64)\n>>> embedding = LocallyLinearEmbedding(n_components=2)\n>>> X_transformed = embedding.fit_transform(X[:100])\n>>> X_transformed.shape\n(100, 2)", "methods": ["__init__", "_fit_transform", "fit", "fit_transform", "transform"], "attributes": [], "code_location": {"file": "_locally_linear.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/manifold", "start_line": 602, "end_line": 879}, "type": "class"}, {"name": "TSNE", "docstring": "T-distributed Stochastic Neighbor Embedding.\n\nt-SNE [1] is a tool to visualize high-dimensional data. It converts\nsimilarities between data points to joint probabilities and tries\nto minimize the Kullback-Leibler divergence between the joint\nprobabilities of the low-dimensional embedding and the\nhigh-dimensional data. t-SNE has a cost function that is not convex,\ni.e. with different initializations we can get different results.\n\nIt is highly recommended to use another dimensionality reduction\nmethod (e.g. PCA for dense data or TruncatedSVD for sparse data)\nto reduce the number of dimensions to a reasonable amount (e.g. 50)\nif the number of features is very high. This will suppress some\nnoise and speed up the computation of pairwise distances between\nsamples. For more tips see Laurens van der Maaten's FAQ [2].\n\nRead more in the :ref:`User Guide <t_sne>`.\n\nParameters\n----------\nn_components : int, default=2\n    Dimension of the embedded space.\n\nperplexity : float, default=30.0\n    The perplexity is related to the number of nearest neighbors that\n    is used in other manifold learning algorithms. Larger datasets\n    usually require a larger perplexity. Consider selecting a value\n    between 5 and 50. Different values can result in significantly\n    different results. The perplexity must be less than the number\n    of samples.\n\nearly_exaggeration : float, default=12.0\n    Controls how tight natural clusters in the original space are in\n    the embedded space and how much space will be between them. For\n    larger values, the space between natural clusters will be larger\n    in the embedded space. Again, the choice of this parameter is not\n    very critical. If the cost function increases during initial\n    optimization, the early exaggeration factor or the learning rate\n    might be too high.\n\nlearning_rate : float or \"auto\", default=\"auto\"\n    The learning rate for t-SNE is usually in the range [10.0, 1000.0]. If\n    the learning rate is too high, the data may look like a 'ball' with any\n    point approximately equidistant from its nearest neighbours. If the\n    learning rate is too low, most points may look compressed in a dense\n    cloud with few outliers. If the cost function gets stuck in a bad local\n    minimum increasing the learning rate may help.\n    Note that many other t-SNE implementations (bhtsne, FIt-SNE, openTSNE,\n    etc.) use a definition of learning_rate that is 4 times smaller than\n    ours. So our learning_rate=200 corresponds to learning_rate=800 in\n    those other implementations. The 'auto' option sets the learning_rate\n    to `max(N / early_exaggeration / 4, 50)` where N is the sample size,\n    following [4] and [5].\n\n    .. versionchanged:: 1.2\n       The default value changed to `\"auto\"`.\n\nmax_iter : int, default=1000\n    Maximum number of iterations for the optimization. Should be at\n    least 250.\n\n    .. versionchanged:: 1.5\n        Parameter name changed from `n_iter` to `max_iter`.\n\nn_iter_without_progress : int, default=300\n    Maximum number of iterations without progress before we abort the\n    optimization, used after 250 initial iterations with early\n    exaggeration. Note that progress is only checked every 50 iterations so\n    this value is rounded to the next multiple of 50.\n\n    .. versionadded:: 0.17\n       parameter *n_iter_without_progress* to control stopping criteria.\n\nmin_grad_norm : float, default=1e-7\n    If the gradient norm is below this threshold, the optimization will\n    be stopped.\n\nmetric : str or callable, default='euclidean'\n    The metric to use when calculating distance between instances in a\n    feature array. If metric is a string, it must be one of the options\n    allowed by scipy.spatial.distance.pdist for its metric parameter, or\n    a metric listed in pairwise.PAIRWISE_DISTANCE_FUNCTIONS.\n    If metric is \"precomputed\", X is assumed to be a distance matrix.\n    Alternatively, if metric is a callable function, it is called on each\n    pair of instances (rows) and the resulting value recorded. The callable\n    should take two arrays from X as input and return a value indicating\n    the distance between them. The default is \"euclidean\" which is\n    interpreted as squared euclidean distance.\n\nmetric_params : dict, default=None\n    Additional keyword arguments for the metric function.\n\n    .. versionadded:: 1.1\n\ninit : {\"random\", \"pca\"} or ndarray of shape (n_samples, n_components),             default=\"pca\"\n    Initialization of embedding.\n    PCA initialization cannot be used with precomputed distances and is\n    usually more globally stable than random initialization.\n\n    .. versionchanged:: 1.2\n       The default value changed to `\"pca\"`.\n\nverbose : int, default=0\n    Verbosity level.\n\nrandom_state : int, RandomState instance or None, default=None\n    Determines the random number generator. Pass an int for reproducible\n    results across multiple function calls. Note that different\n    initializations might result in different local minima of the cost\n    function. See :term:`Glossary <random_state>`.\n\nmethod : {'barnes_hut', 'exact'}, default='barnes_hut'\n    By default the gradient calculation algorithm uses Barnes-Hut\n    approximation running in O(NlogN) time. method='exact'\n    will run on the slower, but exact, algorithm in O(N^2) time. The\n    exact algorithm should be used when nearest-neighbor errors need\n    to be better than 3%. However, the exact method cannot scale to\n    millions of examples.\n\n    .. versionadded:: 0.17\n       Approximate optimization *method* via the Barnes-Hut.\n\nangle : float, default=0.5\n    Only used if method='barnes_hut'\n    This is the trade-off between speed and accuracy for Barnes-Hut T-SNE.\n    'angle' is the angular size (referred to as theta in [3]) of a distant\n    node as measured from a point. If this size is below 'angle' then it is\n    used as a summary node of all points contained within it.\n    This method is not very sensitive to changes in this parameter\n    in the range of 0.2 - 0.8. Angle less than 0.2 has quickly increasing\n    computation time and angle greater 0.8 has quickly increasing error.\n\nn_jobs : int, default=None\n    The number of parallel jobs to run for neighbors search. This parameter\n    has no impact when ``metric=\"precomputed\"`` or\n    (``metric=\"euclidean\"`` and ``method=\"exact\"``).\n    ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n    ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n    for more details.\n\n    .. versionadded:: 0.22\n\nAttributes\n----------\nembedding_ : array-like of shape (n_samples, n_components)\n    Stores the embedding vectors.\n\nkl_divergence_ : float\n    Kullback-Leibler divergence after optimization.\n\nn_features_in_ : int\n    Number of features seen during :term:`fit`.\n\n    .. versionadded:: 0.24\n\nfeature_names_in_ : ndarray of shape (`n_features_in_`,)\n    Names of features seen during :term:`fit`. Defined only when `X`\n    has feature names that are all strings.\n\n    .. versionadded:: 1.0\n\nlearning_rate_ : float\n    Effective learning rate.\n\n    .. versionadded:: 1.2\n\nn_iter_ : int\n    Number of iterations run.\n\nSee Also\n--------\nsklearn.decomposition.PCA : Principal component analysis that is a linear\n    dimensionality reduction method.\nsklearn.decomposition.KernelPCA : Non-linear dimensionality reduction using\n    kernels and PCA.\nMDS : Manifold learning using multidimensional scaling.\nIsomap : Manifold learning based on Isometric Mapping.\nLocallyLinearEmbedding : Manifold learning using Locally Linear Embedding.\nSpectralEmbedding : Spectral embedding for non-linear dimensionality.\n\nNotes\n-----\nFor an example of using :class:`~sklearn.manifold.TSNE` in combination with\n:class:`~sklearn.neighbors.KNeighborsTransformer` see\n:ref:`sphx_glr_auto_examples_neighbors_approximate_nearest_neighbors.py`.\n\nReferences\n----------\n\n[1] van der Maaten, L.J.P.; Hinton, G.E. Visualizing High-Dimensional Data\n    Using t-SNE. Journal of Machine Learning Research 9:2579-2605, 2008.\n\n[2] van der Maaten, L.J.P. t-Distributed Stochastic Neighbor Embedding\n    https://lvdmaaten.github.io/tsne/\n\n[3] L.J.P. van der Maaten. Accelerating t-SNE using Tree-Based Algorithms.\n    Journal of Machine Learning Research 15(Oct):3221-3245, 2014.\n    https://lvdmaaten.github.io/publications/papers/JMLR_2014.pdf\n\n[4] Belkina, A. C., Ciccolella, C. O., Anno, R., Halpert, R., Spidlen, J.,\n    & Snyder-Cappione, J. E. (2019). Automated optimized parameters for\n    T-distributed stochastic neighbor embedding improve visualization\n    and analysis of large datasets. Nature Communications, 10(1), 1-12.\n\n[5] Kobak, D., & Berens, P. (2019). The art of using t-SNE for single-cell\n    transcriptomics. Nature Communications, 10(1), 1-14.\n\nExamples\n--------\n>>> import numpy as np\n>>> from sklearn.manifold import TSNE\n>>> X = np.array([[0, 0, 0], [0, 1, 1], [1, 0, 1], [1, 1, 1]])\n>>> X_embedded = TSNE(n_components=2, learning_rate='auto',\n...                   init='random', perplexity=3).fit_transform(X)\n>>> X_embedded.shape\n(4, 2)", "methods": ["__init__", "_check_params_vs_input", "_fit", "_tsne", "fit_transform", "fit", "_n_features_out", "__sklearn_tags__"], "attributes": ["_EXPLORATION_MAX_ITER", "_N_ITER_CHECK"], "code_location": {"file": "_t_sne.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/manifold", "start_line": 560, "end_line": 1184}, "type": "class"}, {"name": "Isomap", "docstring": "Isomap Embedding.\n\nNon-linear dimensionality reduction through Isometric Mapping\n\nRead more in the :ref:`User Guide <isomap>`.\n\nParameters\n----------\nn_neighbors : int or None, default=5\n    Number of neighbors to consider for each point. If `n_neighbors` is an int,\n    then `radius` must be `None`.\n\nradius : float or None, default=None\n    Limiting distance of neighbors to return. If `radius` is a float,\n    then `n_neighbors` must be set to `None`.\n\n    .. versionadded:: 1.1\n\nn_components : int, default=2\n    Number of coordinates for the manifold.\n\neigen_solver : {'auto', 'arpack', 'dense'}, default='auto'\n    'auto' : Attempt to choose the most efficient solver\n    for the given problem.\n\n    'arpack' : Use Arnoldi decomposition to find the eigenvalues\n    and eigenvectors.\n\n    'dense' : Use a direct solver (i.e. LAPACK)\n    for the eigenvalue decomposition.\n\ntol : float, default=0\n    Convergence tolerance passed to arpack or lobpcg.\n    not used if eigen_solver == 'dense'.\n\nmax_iter : int, default=None\n    Maximum number of iterations for the arpack solver.\n    not used if eigen_solver == 'dense'.\n\npath_method : {'auto', 'FW', 'D'}, default='auto'\n    Method to use in finding shortest path.\n\n    'auto' : attempt to choose the best algorithm automatically.\n\n    'FW' : Floyd-Warshall algorithm.\n\n    'D' : Dijkstra's algorithm.\n\nneighbors_algorithm : {'auto', 'brute', 'kd_tree', 'ball_tree'},                           default='auto'\n    Algorithm to use for nearest neighbors search,\n    passed to neighbors.NearestNeighbors instance.\n\nn_jobs : int or None, default=None\n    The number of parallel jobs to run.\n    ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n    ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n    for more details.\n\nmetric : str, or callable, default=\"minkowski\"\n    The metric to use when calculating distance between instances in a\n    feature array. If metric is a string or callable, it must be one of\n    the options allowed by :func:`sklearn.metrics.pairwise_distances` for\n    its metric parameter.\n    If metric is \"precomputed\", X is assumed to be a distance matrix and\n    must be square. X may be a :term:`Glossary <sparse graph>`.\n\n    .. versionadded:: 0.22\n\np : float, default=2\n    Parameter for the Minkowski metric from\n    sklearn.metrics.pairwise.pairwise_distances. When p = 1, this is\n    equivalent to using manhattan_distance (l1), and euclidean_distance\n    (l2) for p = 2. For arbitrary p, minkowski_distance (l_p) is used.\n\n    .. versionadded:: 0.22\n\nmetric_params : dict, default=None\n    Additional keyword arguments for the metric function.\n\n    .. versionadded:: 0.22\n\nAttributes\n----------\nembedding_ : array-like, shape (n_samples, n_components)\n    Stores the embedding vectors.\n\nkernel_pca_ : object\n    :class:`~sklearn.decomposition.KernelPCA` object used to implement the\n    embedding.\n\nnbrs_ : sklearn.neighbors.NearestNeighbors instance\n    Stores nearest neighbors instance, including BallTree or KDtree\n    if applicable.\n\ndist_matrix_ : array-like, shape (n_samples, n_samples)\n    Stores the geodesic distance matrix of training data.\n\nn_features_in_ : int\n    Number of features seen during :term:`fit`.\n\n    .. versionadded:: 0.24\n\nfeature_names_in_ : ndarray of shape (`n_features_in_`,)\n    Names of features seen during :term:`fit`. Defined only when `X`\n    has feature names that are all strings.\n\n    .. versionadded:: 1.0\n\nSee Also\n--------\nsklearn.decomposition.PCA : Principal component analysis that is a linear\n    dimensionality reduction method.\nsklearn.decomposition.KernelPCA : Non-linear dimensionality reduction using\n    kernels and PCA.\nMDS : Manifold learning using multidimensional scaling.\nTSNE : T-distributed Stochastic Neighbor Embedding.\nLocallyLinearEmbedding : Manifold learning using Locally Linear Embedding.\nSpectralEmbedding : Spectral embedding for non-linear dimensionality.\n\nReferences\n----------\n\n.. [1] Tenenbaum, J.B.; De Silva, V.; & Langford, J.C. A global geometric\n       framework for nonlinear dimensionality reduction. Science 290 (5500)\n\nExamples\n--------\n>>> from sklearn.datasets import load_digits\n>>> from sklearn.manifold import Isomap\n>>> X, _ = load_digits(return_X_y=True)\n>>> X.shape\n(1797, 64)\n>>> embedding = Isomap(n_components=2)\n>>> X_transformed = embedding.fit_transform(X[:100])\n>>> X_transformed.shape\n(100, 2)", "methods": ["__init__", "_fit_transform", "reconstruction_error", "fit", "fit_transform", "transform", "__sklearn_tags__"], "attributes": [], "code_location": {"file": "_isomap.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/manifold", "start_line": 28, "end_line": 442}, "type": "class"}, {"name": "plot_clustering", "is_method": false, "class_name": null, "parameters": ["X_red", "labels", "title"], "calls": ["plt.figure", "plt.xticks", "plt.yticks", "plt.axis", "plt.tight_layout", "np.min", "np.max", "plt.scatter", "plt.title", "plt.cm.nipy_spectral"], "code_location": {"file": "plot_digits_linkage.py", "path": "/data3/pwh/swebench-repos/scikit-learn/examples/cluster", "start_line": 49, "end_line": 68}, "code_snippet": "def plot_clustering(X_red, labels, title=None):\n    x_min, x_max = np.min(X_red, axis=0), np.max(X_red, axis=0)\n    X_red = (X_red - x_min) / (x_max - x_min)\n\n    plt.figure(figsize=(6, 4))\n    for digit in digits.target_names:\n        plt.scatter(\n            *X_red[y == digit].T,\n            marker=f\"${digit}$\",\n            s=50,\n            c=plt.cm.nipy_spectral(labels[y == digit] / 10),\n            alpha=0.5,\n        )\n\n    plt.xticks([])\n    plt.yticks([])\n    if title is not None:\n        plt.title(title, size=17)\n    plt.axis(\"off\")\n    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n", "type": "function"}, {"name": "MDS", "docstring": "Multidimensional scaling.\n\nRead more in the :ref:`User Guide <multidimensional_scaling>`.\n\nParameters\n----------\nn_components : int, default=2\n    Number of dimensions in which to immerse the dissimilarities.\n\nmetric : bool, default=True\n    If ``True``, perform metric MDS; otherwise, perform nonmetric MDS.\n    When ``False`` (i.e. non-metric MDS), dissimilarities with 0 are considered as\n    missing values.\n\nn_init : int, default=4\n    Number of times the SMACOF algorithm will be run with different\n    initializations. The final results will be the best output of the runs,\n    determined by the run with the smallest final stress.\n\n    .. versionchanged:: 1.9\n       The default value for `n_init` will change from 4 to 1 in version 1.9.\n\nmax_iter : int, default=300\n    Maximum number of iterations of the SMACOF algorithm for a single run.\n\nverbose : int, default=0\n    Level of verbosity.\n\neps : float, default=1e-6\n    The tolerance with respect to stress (normalized by the sum of squared\n    embedding distances) at which to declare convergence.\n\n    .. versionchanged:: 1.7\n       The default value for `eps` has changed from 1e-3 to 1e-6, as a result\n       of a bugfix in the computation of the convergence criterion.\n\nn_jobs : int, default=None\n    The number of jobs to use for the computation. If multiple\n    initializations are used (``n_init``), each run of the algorithm is\n    computed in parallel.\n\n    ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n    ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n    for more details.\n\nrandom_state : int, RandomState instance or None, default=None\n    Determines the random number generator used to initialize the centers.\n    Pass an int for reproducible results across multiple function calls.\n    See :term:`Glossary <random_state>`.\n\ndissimilarity : {'euclidean', 'precomputed'}, default='euclidean'\n    Dissimilarity measure to use:\n\n    - 'euclidean':\n        Pairwise Euclidean distances between points in the dataset.\n\n    - 'precomputed':\n        Pre-computed dissimilarities are passed directly to ``fit`` and\n        ``fit_transform``.\n\nnormalized_stress : bool or \"auto\" default=\"auto\"\n    Whether to return normalized stress value (Stress-1) instead of raw\n    stress. By default, metric MDS returns raw stress while non-metric MDS\n    returns normalized stress.\n\n    .. versionadded:: 1.2\n\n    .. versionchanged:: 1.4\n       The default value changed from `False` to `\"auto\"` in version 1.4.\n\n    .. versionchanged:: 1.7\n       Normalized stress is now supported for metric MDS as well.\n\nAttributes\n----------\nembedding_ : ndarray of shape (n_samples, n_components)\n    Stores the position of the dataset in the embedding space.\n\nstress_ : float\n    The final value of the stress (sum of squared distance of the\n    disparities and the distances for all constrained points).\n    If `normalized_stress=True`, returns Stress-1.\n    A value of 0 indicates \"perfect\" fit, 0.025 excellent, 0.05 good,\n    0.1 fair, and 0.2 poor [1]_.\n\ndissimilarity_matrix_ : ndarray of shape (n_samples, n_samples)\n    Pairwise dissimilarities between the points. Symmetric matrix that:\n\n    - either uses a custom dissimilarity matrix by setting `dissimilarity`\n      to 'precomputed';\n    - or constructs a dissimilarity matrix from data using\n      Euclidean distances.\n\nn_features_in_ : int\n    Number of features seen during :term:`fit`.\n\n    .. versionadded:: 0.24\n\nfeature_names_in_ : ndarray of shape (`n_features_in_`,)\n    Names of features seen during :term:`fit`. Defined only when `X`\n    has feature names that are all strings.\n\n    .. versionadded:: 1.0\n\nn_iter_ : int\n    The number of iterations corresponding to the best stress.\n\nSee Also\n--------\nsklearn.decomposition.PCA : Principal component analysis that is a linear\n    dimensionality reduction method.\nsklearn.decomposition.KernelPCA : Non-linear dimensionality reduction using\n    kernels and PCA.\nTSNE : T-distributed Stochastic Neighbor Embedding.\nIsomap : Manifold learning based on Isometric Mapping.\nLocallyLinearEmbedding : Manifold learning using Locally Linear Embedding.\nSpectralEmbedding : Spectral embedding for non-linear dimensionality.\n\nReferences\n----------\n.. [1] \"Nonmetric multidimensional scaling: a numerical method\" Kruskal, J.\n   Psychometrika, 29 (1964)\n\n.. [2] \"Multidimensional scaling by optimizing goodness of fit to a nonmetric\n   hypothesis\" Kruskal, J. Psychometrika, 29, (1964)\n\n.. [3] \"Modern Multidimensional Scaling - Theory and Applications\" Borg, I.;\n   Groenen P. Springer Series in Statistics (1997)\n\nExamples\n--------\n>>> from sklearn.datasets import load_digits\n>>> from sklearn.manifold import MDS\n>>> X, _ = load_digits(return_X_y=True)\n>>> X.shape\n(1797, 64)\n>>> embedding = MDS(n_components=2, n_init=1)\n>>> X_transformed = embedding.fit_transform(X[:100])\n>>> X_transformed.shape\n(100, 2)\n\nFor a more detailed example of usage, see\n:ref:`sphx_glr_auto_examples_manifold_plot_mds.py`.\n\nFor a comparison of manifold learning techniques, see\n:ref:`sphx_glr_auto_examples_manifold_plot_compare_methods.py`.", "methods": ["__init__", "__sklearn_tags__", "fit", "fit_transform"], "attributes": [], "code_location": {"file": "_mds.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/manifold", "start_line": 431, "end_line": 714}, "type": "class"}, {"name": "__init__", "is_method": true, "class_name": "TSNE", "parameters": ["self", "n_components"], "calls": [], "code_location": {"file": "_t_sne.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/manifold", "start_line": 810, "end_line": 843}, "code_snippet": "    def __init__(\n        self,\n        n_components=2,\n        *,\n        perplexity=30.0,\n        early_exaggeration=12.0,\n        learning_rate=\"auto\",\n        max_iter=1000,\n        n_iter_without_progress=300,\n        min_grad_norm=1e-7,\n        metric=\"euclidean\",\n        metric_params=None,\n        init=\"pca\",\n        verbose=0,\n        random_state=None,\n        method=\"barnes_hut\",\n        angle=0.5,\n        n_jobs=None,\n    ):\n        self.n_components = n_components\n        self.perplexity = perplexity\n        self.early_exaggeration = early_exaggeration\n        self.learning_rate = learning_rate\n        self.max_iter = max_iter\n        self.n_iter_without_progress = n_iter_without_progress\n        self.min_grad_norm = min_grad_norm\n        self.metric = metric\n        self.metric_params = metric_params\n        self.init = init\n        self.verbose = verbose\n        self.random_state = random_state\n        self.method = method\n        self.angle = angle\n        self.n_jobs = n_jobs\n", "type": "function"}, {"name": "spectral_embedding", "is_method": false, "class_name": null, "parameters": ["adjacency"], "calls": ["validate_params", "check_random_state", "_spectral_embedding", "Interval", "StrOptions", "Interval", "StrOptions"], "code_location": {"file": "_spectral_embedding.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/manifold", "start_line": 162, "end_line": 292}, "code_snippet": "def spectral_embedding(\n    adjacency,\n    *,\n    n_components=8,\n    eigen_solver=None,\n    random_state=None,\n    eigen_tol=\"auto\",\n    norm_laplacian=True,\n    drop_first=True,\n):\n    \"\"\"Project the sample on the first eigenvectors of the graph Laplacian.\n\n    The adjacency matrix is used to compute a normalized graph Laplacian\n    whose spectrum (especially the eigenvectors associated to the\n    smallest eigenvalues) has an interpretation in terms of minimal\n    number of cuts necessary to split the graph into comparably sized\n    components.\n\n    This embedding can also 'work' even if the ``adjacency`` variable is\n    not strictly the adjacency matrix of a graph but more generally\n    an affinity or similarity matrix between samples (for instance the\n    heat kernel of a euclidean distance matrix or a k-NN matrix).\n\n    However care must taken to always make the affinity matrix symmetric\n    so that the eigenvector decomposition works as expected.\n\n    Note : Laplacian Eigenmaps is the actual algorithm implemented here.\n\n    Read more in the :ref:`User Guide <spectral_embedding>`.\n\n    Parameters\n    ----------\n    adjacency : {array-like, sparse graph} of shape (n_samples, n_samples)\n        The adjacency matrix of the graph to embed.\n\n    n_components : int, default=8\n        The dimension of the projection subspace.\n\n    eigen_solver : {'arpack', 'lobpcg', 'amg'}, default=None\n        The eigenvalue decomposition strategy to use. AMG requires pyamg\n        to be installed. It can be faster on very large, sparse problems,\n        but may also lead to instabilities. If None, then ``'arpack'`` is\n        used.\n\n    random_state : int, RandomState instance or None, default=None\n        A pseudo random number generator used for the initialization\n        of the lobpcg eigen vectors decomposition when `eigen_solver ==\n        'amg'`, and for the K-Means initialization. Use an int to make\n        the results deterministic across calls (See\n        :term:`Glossary <random_state>`).\n\n        .. note::\n            When using `eigen_solver == 'amg'`,\n            it is necessary to also fix the global numpy seed with\n            `np.random.seed(int)` to get deterministic results. See\n            https://github.com/pyamg/pyamg/issues/139 for further\n            information.\n\n    eigen_tol : float, default=\"auto\"\n        Stopping criterion for eigendecomposition of the Laplacian matrix.\n        If `eigen_tol=\"auto\"` then the passed tolerance will depend on the\n        `eigen_solver`:\n\n        - If `eigen_solver=\"arpack\"`, then `eigen_tol=0.0`;\n        - If `eigen_solver=\"lobpcg\"` or `eigen_solver=\"amg\"`, then\n          `eigen_tol=None` which configures the underlying `lobpcg` solver to\n          automatically resolve the value according to their heuristics. See,\n          :func:`scipy.sparse.linalg.lobpcg` for details.\n\n        Note that when using `eigen_solver=\"amg\"` values of `tol<1e-5` may lead\n        to convergence issues and should be avoided.\n\n        .. versionadded:: 1.2\n           Added 'auto' option.\n\n    norm_laplacian : bool, default=True\n        If True, then compute symmetric normalized Laplacian.\n\n    drop_first : bool, default=True\n        Whether to drop the first eigenvector. For spectral embedding, this\n        should be True as the first eigenvector should be constant vector for\n        connected graph, but for spectral clustering, this should be kept as\n        False to retain the first eigenvector.\n\n    Returns\n    -------\n    embedding : ndarray of shape (n_samples, n_components)\n        The reduced samples.\n\n    Notes\n    -----\n    Spectral Embedding (Laplacian Eigenmaps) is most useful when the graph\n    has one connected component. If there graph has many components, the first\n    few eigenvectors will simply uncover the connected components of the graph.\n\n    References\n    ----------\n    * https://en.wikipedia.org/wiki/LOBPCG\n\n    * :doi:`\"Toward the Optimal Preconditioned Eigensolver: Locally Optimal\n      Block Preconditioned Conjugate Gradient Method\",\n      Andrew V. Knyazev\n      <10.1137/S1064827500366124>`\n\n    Examples\n    --------\n    >>> from sklearn.datasets import load_digits\n    >>> from sklearn.neighbors import kneighbors_graph\n    >>> from sklearn.manifold import spectral_embedding\n    >>> X, _ = load_digits(return_X_y=True)\n    >>> X = X[:100]\n    >>> affinity_matrix = kneighbors_graph(\n    ...     X, n_neighbors=int(X.shape[0] / 10), include_self=True\n    ... )\n    >>> # make the matrix symmetric\n    >>> affinity_matrix = 0.5 * (affinity_matrix + affinity_matrix.T)\n    >>> embedding = spectral_embedding(affinity_matrix, n_components=2, random_state=42)\n    >>> embedding.shape\n    (100, 2)\n    \"\"\"\n    random_state = check_random_state(random_state)\n\n    return _spectral_embedding(\n        adjacency,\n        n_components=n_components,\n        eigen_solver=eigen_solver,\n        random_state=random_state,\n        eigen_tol=eigen_tol,\n        norm_laplacian=norm_laplacian,\n        drop_first=drop_first,\n    )\n", "type": "function"}, {"name": "_locally_linear_embedding", "is_method": false, "class_name": null, "parameters": ["X"], "calls": ["NearestNeighbors", "nbrs.fit", "null_space", "ValueError", "ValueError", "barycenter_kneighbors_graph", "M.tocsr", "toarray", "nbrs.kneighbors", "np.empty", "M_container_constructor", "range", "eye", "ValueError", "Gi.mean", "range", "qr", "w.sum", "np.meshgrid", "np.dot", "nbrs.kneighbors", "np.zeros", "min", "np.zeros", "np.dot", "np.zeros", "range", "np.median", "np.zeros", "stable_cumsum", "range", "M_container_constructor", "range", "np.dot", "np.where", "ValueError", "range", "range", "evals.sum", "V.transpose", "np.ones", "np.dot", "w_reg.sum", "sum", "sum", "np.searchsorted", "np.linalg.norm", "np.meshgrid", "np.dot", "Wi.sum", "nbrs.kneighbors", "M_container_constructor", "range", "svd", "svd", "np.dot", "eigh", "np.linalg.norm", "np.sqrt", "np.full", "np.dot", "Xi.mean", "np.zeros", "np.dot", "np.meshgrid", "np.ones", "eigh", "abs", "Vi.sum", "np.ones", "np.dot", "np.sqrt", "np.outer", "svd", "np.dot", "eigh"], "code_location": {"file": "_locally_linear.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/manifold", "start_line": 200, "end_line": 445}, "code_snippet": "def _locally_linear_embedding(\n    X,\n    *,\n    n_neighbors,\n    n_components,\n    reg=1e-3,\n    eigen_solver=\"auto\",\n    tol=1e-6,\n    max_iter=100,\n    method=\"standard\",\n    hessian_tol=1e-4,\n    modified_tol=1e-12,\n    random_state=None,\n    n_jobs=None,\n):\n    nbrs = NearestNeighbors(n_neighbors=n_neighbors + 1, n_jobs=n_jobs)\n    nbrs.fit(X)\n    X = nbrs._fit_X\n\n    N, d_in = X.shape\n\n    if n_components > d_in:\n        raise ValueError(\n            \"output dimension must be less than or equal to input dimension\"\n        )\n    if n_neighbors >= N:\n        raise ValueError(\n            \"Expected n_neighbors < n_samples, but n_samples = %d, n_neighbors = %d\"\n            % (N, n_neighbors)\n        )\n\n    M_sparse = eigen_solver != \"dense\"\n    M_container_constructor = lil_matrix if M_sparse else np.zeros\n\n    if method == \"standard\":\n        W = barycenter_kneighbors_graph(\n            nbrs, n_neighbors=n_neighbors, reg=reg, n_jobs=n_jobs\n        )\n\n        # we'll compute M = (I-W)'(I-W)\n        # depending on the solver, we'll do this differently\n        if M_sparse:\n            M = eye(*W.shape, format=W.format) - W\n            M = M.T @ M\n        else:\n            M = (W.T @ W - W.T - W).toarray()\n            M.flat[:: M.shape[0] + 1] += 1  # M = W' W - W' - W + I\n\n    elif method == \"hessian\":\n        dp = n_components * (n_components + 1) // 2\n\n        if n_neighbors <= n_components + dp:\n            raise ValueError(\n                \"for method='hessian', n_neighbors must be \"\n                \"greater than \"\n                \"[n_components * (n_components + 3) / 2]\"\n            )\n\n        neighbors = nbrs.kneighbors(\n            X, n_neighbors=n_neighbors + 1, return_distance=False\n        )\n        neighbors = neighbors[:, 1:]\n\n        Yi = np.empty((n_neighbors, 1 + n_components + dp), dtype=np.float64)\n        Yi[:, 0] = 1\n\n        M = M_container_constructor((N, N), dtype=np.float64)\n\n        use_svd = n_neighbors > d_in\n\n        for i in range(N):\n            Gi = X[neighbors[i]]\n            Gi -= Gi.mean(0)\n\n            # build Hessian estimator\n            if use_svd:\n                U = svd(Gi, full_matrices=0)[0]\n            else:\n                Ci = np.dot(Gi, Gi.T)\n                U = eigh(Ci)[1][:, ::-1]\n\n            Yi[:, 1 : 1 + n_components] = U[:, :n_components]\n\n            j = 1 + n_components\n            for k in range(n_components):\n                Yi[:, j : j + n_components - k] = U[:, k : k + 1] * U[:, k:n_components]\n                j += n_components - k\n\n            Q, R = qr(Yi)\n\n            w = Q[:, n_components + 1 :]\n            S = w.sum(0)\n\n            S[np.where(abs(S) < hessian_tol)] = 1\n            w /= S\n\n            nbrs_x, nbrs_y = np.meshgrid(neighbors[i], neighbors[i])\n            M[nbrs_x, nbrs_y] += np.dot(w, w.T)\n\n    elif method == \"modified\":\n        if n_neighbors < n_components:\n            raise ValueError(\"modified LLE requires n_neighbors >= n_components\")\n\n        neighbors = nbrs.kneighbors(\n            X, n_neighbors=n_neighbors + 1, return_distance=False\n        )\n        neighbors = neighbors[:, 1:]\n\n        # find the eigenvectors and eigenvalues of each local covariance\n        # matrix. We want V[i] to be a [n_neighbors x n_neighbors] matrix,\n        # where the columns are eigenvectors\n        V = np.zeros((N, n_neighbors, n_neighbors))\n        nev = min(d_in, n_neighbors)\n        evals = np.zeros([N, nev])\n\n        # choose the most efficient way to find the eigenvectors\n        use_svd = n_neighbors > d_in\n\n        if use_svd:\n            for i in range(N):\n                X_nbrs = X[neighbors[i]] - X[i]\n                V[i], evals[i], _ = svd(X_nbrs, full_matrices=True)\n            evals **= 2\n        else:\n            for i in range(N):\n                X_nbrs = X[neighbors[i]] - X[i]\n                C_nbrs = np.dot(X_nbrs, X_nbrs.T)\n                evi, vi = eigh(C_nbrs)\n                evals[i] = evi[::-1]\n                V[i] = vi[:, ::-1]\n\n        # find regularized weights: this is like normal LLE.\n        # because we've already computed the SVD of each covariance matrix,\n        # it's faster to use this rather than np.linalg.solve\n        reg = 1e-3 * evals.sum(1)\n\n        tmp = np.dot(V.transpose(0, 2, 1), np.ones(n_neighbors))\n        tmp[:, :nev] /= evals + reg[:, None]\n        tmp[:, nev:] /= reg[:, None]\n\n        w_reg = np.zeros((N, n_neighbors))\n        for i in range(N):\n            w_reg[i] = np.dot(V[i], tmp[i])\n        w_reg /= w_reg.sum(1)[:, None]\n\n        # calculate eta: the median of the ratio of small to large eigenvalues\n        # across the points.  This is used to determine s_i, below\n        rho = evals[:, n_components:].sum(1) / evals[:, :n_components].sum(1)\n        eta = np.median(rho)\n\n        # find s_i, the size of the \"almost null space\" for each point:\n        # this is the size of the largest set of eigenvalues\n        # such that Sum[v; v in set]/Sum[v; v not in set] < eta\n        s_range = np.zeros(N, dtype=int)\n        evals_cumsum = stable_cumsum(evals, 1)\n        eta_range = evals_cumsum[:, -1:] / evals_cumsum[:, :-1] - 1\n        for i in range(N):\n            s_range[i] = np.searchsorted(eta_range[i, ::-1], eta)\n        s_range += n_neighbors - nev  # number of zero eigenvalues\n\n        # Now calculate M.\n        # This is the [N x N] matrix whose null space is the desired embedding\n        M = M_container_constructor((N, N), dtype=np.float64)\n\n        for i in range(N):\n            s_i = s_range[i]\n\n            # select bottom s_i eigenvectors and calculate alpha\n            Vi = V[i, :, n_neighbors - s_i :]\n            alpha_i = np.linalg.norm(Vi.sum(0)) / np.sqrt(s_i)\n\n            # compute Householder matrix which satisfies\n            #  Hi*Vi.T*ones(n_neighbors) = alpha_i*ones(s)\n            # using prescription from paper\n            h = np.full(s_i, alpha_i) - np.dot(Vi.T, np.ones(n_neighbors))\n\n            norm_h = np.linalg.norm(h)\n            if norm_h < modified_tol:\n                h *= 0\n            else:\n                h /= norm_h\n\n            # Householder matrix is\n            #  >> Hi = np.identity(s_i) - 2*np.outer(h,h)\n            # Then the weight matrix is\n            #  >> Wi = np.dot(Vi,Hi) + (1-alpha_i) * w_reg[i,:,None]\n            # We do this much more efficiently:\n            Wi = Vi - 2 * np.outer(np.dot(Vi, h), h) + (1 - alpha_i) * w_reg[i, :, None]\n\n            # Update M as follows:\n            # >> W_hat = np.zeros( (N,s_i) )\n            # >> W_hat[neighbors[i],:] = Wi\n            # >> W_hat[i] -= 1\n            # >> M += np.dot(W_hat,W_hat.T)\n            # We can do this much more efficiently:\n            nbrs_x, nbrs_y = np.meshgrid(neighbors[i], neighbors[i])\n            M[nbrs_x, nbrs_y] += np.dot(Wi, Wi.T)\n            Wi_sum1 = Wi.sum(1)\n            M[i, neighbors[i]] -= Wi_sum1\n            M[neighbors[i], [i]] -= Wi_sum1\n            M[i, i] += s_i\n\n    elif method == \"ltsa\":\n        neighbors = nbrs.kneighbors(\n            X, n_neighbors=n_neighbors + 1, return_distance=False\n        )\n        neighbors = neighbors[:, 1:]\n\n        M = M_container_constructor((N, N), dtype=np.float64)\n\n        use_svd = n_neighbors > d_in\n\n        for i in range(N):\n            Xi = X[neighbors[i]]\n            Xi -= Xi.mean(0)\n\n            # compute n_components largest eigenvalues of Xi @ Xi^T\n            if use_svd:\n                v = svd(Xi, full_matrices=True)[0]\n            else:\n                Ci = np.dot(Xi, Xi.T)\n                v = eigh(Ci)[1][:, ::-1]\n\n            Gi = np.zeros((n_neighbors, n_components + 1))\n            Gi[:, 1:] = v[:, :n_components]\n            Gi[:, 0] = 1.0 / np.sqrt(n_neighbors)\n\n            GiGiT = np.dot(Gi, Gi.T)\n\n            nbrs_x, nbrs_y = np.meshgrid(neighbors[i], neighbors[i])\n            M[nbrs_x, nbrs_y] -= GiGiT\n\n            M[neighbors[i], neighbors[i]] += np.ones(shape=n_neighbors)\n\n    if M_sparse:\n        M = M.tocsr()\n\n    return null_space(\n        M,\n        n_components,\n        k_skip=1,\n        eigen_solver=eigen_solver,\n        tol=tol,\n        max_iter=max_iter,\n        random_state=random_state,\n    )\n", "type": "function"}], "retrieved_count": 10, "cost_time": 0.36434268951416016}
{"question": "Where does the solver selection logic in _BaseRidge.fit() determine which lower-level helper functions to invoke based on the combination of sparse data, intercept fitting, and solver parameters?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"name": "_ridge_regression", "is_method": false, "class_name": null, "parameters": ["X", "y", "alpha", "sample_weight", "solver", "max_iter", "tol", "verbose", "positive", "random_state", "return_n_iter", "return_intercept", "return_solver", "X_scale", "X_offset", "check_input", "fit_intercept"], "calls": ["get_namespace_and_device", "_is_numpy_namespace", "sparse.issparse", "resolve_solver", "check_consistent_length", "_ravel", "xp.asarray", "np.asarray", "ValueError", "ValueError", "ValueError", "ValueError", "_get_valid_accept_sparse", "check_array", "check_array", "ValueError", "xp.reshape", "ValueError", "_check_sample_weight", "check_scalar", "xp.asarray", "ValueError", "xp.full", "_solve_sparse_cg", "_solve_svd", "_ravel", "_rescale_data", "isinstance", "_solve_lsqr", "TypeError", "str", "type", "xp.asarray", "safe_sparse_dot", "max", "np.empty", "np.empty", "np.zeros", "enumerate", "_solve_cholesky_kernel", "_solve_cholesky", "zip", "sag_solver", "_solve_lbfgs", "safe_sparse_dot", "row_norms", "np.zeros", "target.ravel", "int"], "code_location": {"file": "_ridge.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/linear_model", "start_line": 610, "end_line": 836}, "code_snippet": "def _ridge_regression(\n    X,\n    y,\n    alpha,\n    sample_weight=None,\n    solver=\"auto\",\n    max_iter=None,\n    tol=1e-4,\n    verbose=0,\n    positive=False,\n    random_state=None,\n    return_n_iter=False,\n    return_intercept=False,\n    return_solver=False,\n    X_scale=None,\n    X_offset=None,\n    check_input=True,\n    fit_intercept=False,\n):\n    xp, is_array_api_compliant, device_ = get_namespace_and_device(\n        X, y, sample_weight, X_scale, X_offset\n    )\n    is_numpy_namespace = _is_numpy_namespace(xp)\n    X_is_sparse = sparse.issparse(X)\n\n    has_sw = sample_weight is not None\n\n    solver = resolve_solver(solver, positive, return_intercept, X_is_sparse, xp)\n\n    if is_numpy_namespace and not X_is_sparse:\n        X = np.asarray(X)\n\n    if not is_numpy_namespace and solver != \"svd\":\n        raise ValueError(\n            f\"Array API dispatch to namespace {xp.__name__} only supports \"\n            f\"solver 'svd'. Got '{solver}'.\"\n        )\n\n    if positive and solver != \"lbfgs\":\n        raise ValueError(\n            \"When positive=True, only 'lbfgs' solver can be used. \"\n            f\"Please change solver {solver} to 'lbfgs' \"\n            \"or set positive=False.\"\n        )\n\n    if solver == \"lbfgs\" and not positive:\n        raise ValueError(\n            \"'lbfgs' solver can be used only when positive=True. \"\n            \"Please use another solver.\"\n        )\n\n    if return_intercept and solver != \"sag\":\n        raise ValueError(\n            \"In Ridge, only 'sag' solver can directly fit the \"\n            \"intercept. Please change solver to 'sag' or set \"\n            \"return_intercept=False.\"\n        )\n\n    if check_input:\n        _dtype = [xp.float64, xp.float32]\n        _accept_sparse = _get_valid_accept_sparse(X_is_sparse, solver)\n        X = check_array(X, accept_sparse=_accept_sparse, dtype=_dtype, order=\"C\")\n        y = check_array(y, dtype=X.dtype, ensure_2d=False, order=None)\n    check_consistent_length(X, y)\n\n    n_samples, n_features = X.shape\n\n    if y.ndim > 2:\n        raise ValueError(\"Target y has the wrong shape %s\" % str(y.shape))\n\n    if y.ndim == 1:\n        y = xp.reshape(y, (-1, 1))\n\n    n_samples_, n_targets = y.shape\n\n    if n_samples != n_samples_:\n        raise ValueError(\n            \"Number of samples in X and y does not correspond: %d != %d\"\n            % (n_samples, n_samples_)\n        )\n\n    if has_sw:\n        sample_weight = _check_sample_weight(sample_weight, X, dtype=X.dtype)\n\n        if solver not in [\"sag\", \"saga\"]:\n            # SAG supports sample_weight directly. For other solvers,\n            # we implement sample_weight via a simple rescaling.\n            X, y, sample_weight_sqrt = _rescale_data(X, y, sample_weight)\n\n    # Some callers of this method might pass alpha as single\n    # element array which already has been validated.\n    if alpha is not None and not isinstance(alpha, type(xp.asarray([0.0]))):\n        alpha = check_scalar(\n            alpha,\n            \"alpha\",\n            target_type=numbers.Real,\n            min_val=0.0,\n            include_boundaries=\"left\",\n        )\n\n    # There should be either 1 or n_targets penalties\n    alpha = _ravel(xp.asarray(alpha, device=device_, dtype=X.dtype), xp=xp)\n    if alpha.shape[0] not in [1, n_targets]:\n        raise ValueError(\n            \"Number of targets and number of penalties do not correspond: %d != %d\"\n            % (alpha.shape[0], n_targets)\n        )\n\n    if alpha.shape[0] == 1 and n_targets > 1:\n        alpha = xp.full(\n            shape=(n_targets,), fill_value=alpha[0], dtype=alpha.dtype, device=device_\n        )\n\n    n_iter = None\n    if solver == \"sparse_cg\":\n        coef = _solve_sparse_cg(\n            X,\n            y,\n            alpha,\n            max_iter=max_iter,\n            tol=tol,\n            verbose=verbose,\n            X_offset=X_offset,\n            X_scale=X_scale,\n            sample_weight_sqrt=sample_weight_sqrt if has_sw else None,\n        )\n\n    elif solver == \"lsqr\":\n        coef, n_iter = _solve_lsqr(\n            X,\n            y,\n            alpha=alpha,\n            fit_intercept=fit_intercept,\n            max_iter=max_iter,\n            tol=tol,\n            X_offset=X_offset,\n            X_scale=X_scale,\n            sample_weight_sqrt=sample_weight_sqrt if has_sw else None,\n        )\n\n    elif solver == \"cholesky\":\n        if n_features > n_samples:\n            K = safe_sparse_dot(X, X.T, dense_output=True)\n            try:\n                dual_coef = _solve_cholesky_kernel(K, y, alpha)\n\n                coef = safe_sparse_dot(X.T, dual_coef, dense_output=True).T\n            except linalg.LinAlgError:\n                # use SVD solver if matrix is singular\n                solver = \"svd\"\n        else:\n            try:\n                coef = _solve_cholesky(X, y, alpha)\n            except linalg.LinAlgError:\n                # use SVD solver if matrix is singular\n                solver = \"svd\"\n\n    elif solver in [\"sag\", \"saga\"]:\n        # precompute max_squared_sum for all targets\n        max_squared_sum = row_norms(X, squared=True).max()\n\n        coef = np.empty((y.shape[1], n_features), dtype=X.dtype)\n        n_iter = np.empty(y.shape[1], dtype=np.int32)\n        intercept = np.zeros((y.shape[1],), dtype=X.dtype)\n        for i, (alpha_i, target) in enumerate(zip(alpha, y.T)):\n            init = {\n                \"coef\": np.zeros((n_features + int(return_intercept), 1), dtype=X.dtype)\n            }\n            coef_, n_iter_, _ = sag_solver(\n                X,\n                target.ravel(),\n                sample_weight,\n                \"squared\",\n                alpha_i,\n                0,\n                max_iter,\n                tol,\n                verbose,\n                random_state,\n                False,\n                max_squared_sum,\n                init,\n                is_saga=solver == \"saga\",\n            )\n            if return_intercept:\n                coef[i] = coef_[:-1]\n                intercept[i] = coef_[-1]\n            else:\n                coef[i] = coef_\n            n_iter[i] = n_iter_\n\n        if intercept.shape[0] == 1:\n            intercept = intercept[0]\n\n    elif solver == \"lbfgs\":\n        coef = _solve_lbfgs(\n            X,\n            y,\n            alpha,\n            positive=positive,\n            tol=tol,\n            max_iter=max_iter,\n            X_offset=X_offset,\n            X_scale=X_scale,\n            sample_weight_sqrt=sample_weight_sqrt if has_sw else None,\n        )\n\n    if solver == \"svd\":\n        if X_is_sparse:\n            raise TypeError(\"SVD solver does not support sparse inputs currently\")\n        coef = _solve_svd(X, y, alpha, xp)\n\n    if n_targets == 1:\n        coef = _ravel(coef)\n\n    coef = xp.asarray(coef)\n\n    if return_n_iter and return_intercept:\n        res = coef, n_iter, intercept\n    elif return_intercept:\n        res = coef, intercept\n    elif return_n_iter:\n        res = coef, n_iter\n    else:\n        res = coef\n\n    return (*res, solver) if return_solver else res\n", "type": "function"}, {"name": "resolve_solver_for_numpy", "is_method": false, "class_name": null, "parameters": ["positive", "return_intercept", "is_sparse"], "calls": [], "code_location": {"file": "_ridge.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/linear_model", "start_line": 871, "end_line": 882}, "code_snippet": "def resolve_solver_for_numpy(positive, return_intercept, is_sparse):\n    if positive:\n        return \"lbfgs\"\n\n    if return_intercept:\n        # sag supports fitting intercept directly\n        return \"sag\"\n\n    if not is_sparse:\n        return \"cholesky\"\n\n    return \"sparse_cg\"\n", "type": "function"}, {"name": "test_ridge_fit_intercept_sparse_error", "is_method": false, "class_name": null, "parameters": ["solver", "csr_container"], "calls": ["pytest.mark.parametrize", "pytest.mark.parametrize", "_make_sparse_offset_regression", "csr_container", "Ridge", "format", "pytest.raises", "sparse_ridge.fit"], "code_location": {"file": "test_ridge.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/linear_model/tests", "start_line": 1775, "end_line": 1781}, "code_snippet": "def test_ridge_fit_intercept_sparse_error(solver, csr_container):\n    X, y = _make_sparse_offset_regression(n_features=20, random_state=0)\n    X_csr = csr_container(X)\n    sparse_ridge = Ridge(solver=solver)\n    err_msg = \"solver='{}' does not support\".format(solver)\n    with pytest.raises(ValueError, match=err_msg):\n        sparse_ridge.fit(X_csr, y)\n", "type": "function"}, {"name": "fit", "is_method": true, "class_name": "_BaseRidge", "parameters": ["self", "X", "y", "sample_weight"], "calls": ["get_namespace", "_preprocess_data", "ValueError", "_check_sample_weight", "sparse.issparse", "_ridge_regression", "_ridge_regression", "self._set_intercept", "ValueError", "sparse.issparse", "sparse.issparse", "ValueError", "format", "warnings.warn"], "code_location": {"file": "_ridge.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/linear_model", "start_line": 923, "end_line": 1023}, "code_snippet": "    def fit(self, X, y, sample_weight=None):\n        xp, is_array_api_compliant = get_namespace(X, y, sample_weight)\n\n        if self.solver == \"lbfgs\" and not self.positive:\n            raise ValueError(\n                \"'lbfgs' solver can be used only when positive=True. \"\n                \"Please use another solver.\"\n            )\n\n        if self.positive:\n            if self.solver not in [\"auto\", \"lbfgs\"]:\n                raise ValueError(\n                    f\"solver='{self.solver}' does not support positive fitting. Please\"\n                    \" set the solver to 'auto' or 'lbfgs', or set `positive=False`\"\n                )\n            else:\n                solver = self.solver\n        elif sparse.issparse(X) and self.fit_intercept:\n            if self.solver not in [\"auto\", \"lbfgs\", \"lsqr\", \"sag\", \"sparse_cg\"]:\n                raise ValueError(\n                    \"solver='{}' does not support fitting the intercept \"\n                    \"on sparse data. Please set the solver to 'auto' or \"\n                    \"'lsqr', 'sparse_cg', 'sag', 'lbfgs' \"\n                    \"or set `fit_intercept=False`\".format(self.solver)\n                )\n            if self.solver in [\"lsqr\", \"lbfgs\"]:\n                solver = self.solver\n            elif self.solver == \"sag\" and self.max_iter is None and self.tol > 1e-4:\n                warnings.warn(\n                    '\"sag\" solver requires many iterations to fit '\n                    \"an intercept with sparse inputs. Either set the \"\n                    'solver to \"auto\" or \"sparse_cg\", or set a low '\n                    '\"tol\" and a high \"max_iter\" (especially if inputs are '\n                    \"not standardized).\"\n                )\n                solver = \"sag\"\n            else:\n                solver = \"sparse_cg\"\n        else:\n            solver = self.solver\n\n        if sample_weight is not None:\n            sample_weight = _check_sample_weight(sample_weight, X, dtype=X.dtype)\n\n        # when X is sparse we only remove offset from y\n        X, y, X_offset, y_offset, X_scale, _ = _preprocess_data(\n            X,\n            y,\n            fit_intercept=self.fit_intercept,\n            copy=self.copy_X,\n            sample_weight=sample_weight,\n            rescale_with_sw=False,\n        )\n\n        if solver == \"sag\" and sparse.issparse(X) and self.fit_intercept:\n            self.coef_, self.n_iter_, self.intercept_, self.solver_ = _ridge_regression(\n                X,\n                y,\n                alpha=self.alpha,\n                sample_weight=sample_weight,\n                max_iter=self.max_iter,\n                tol=self.tol,\n                solver=\"sag\",\n                positive=self.positive,\n                random_state=self.random_state,\n                return_n_iter=True,\n                return_intercept=True,\n                return_solver=True,\n                check_input=False,\n            )\n            # add the offset which was subtracted by _preprocess_data\n            self.intercept_ += y_offset\n\n        else:\n            if sparse.issparse(X) and self.fit_intercept:\n                # required to fit intercept with sparse_cg and lbfgs solver\n                params = {\"X_offset\": X_offset, \"X_scale\": X_scale}\n            else:\n                # for dense matrices or when intercept is set to 0\n                params = {}\n\n            self.coef_, self.n_iter_, self.solver_ = _ridge_regression(\n                X,\n                y,\n                alpha=self.alpha,\n                sample_weight=sample_weight,\n                max_iter=self.max_iter,\n                tol=self.tol,\n                solver=solver,\n                positive=self.positive,\n                random_state=self.random_state,\n                return_n_iter=True,\n                return_intercept=False,\n                return_solver=True,\n                check_input=False,\n                fit_intercept=self.fit_intercept,\n                **params,\n            )\n            self._set_intercept(X_offset, y_offset, X_scale)\n\n        return self\n", "type": "function"}, {"name": "_solve_sparse_cg", "is_method": false, "class_name": null, "parameters": ["X", "y", "alpha", "max_iter", "tol", "verbose", "X_offset", "X_scale", "sample_weight_sqrt"], "calls": ["np.empty", "range", "np.ones", "sp_linalg.aslinearoperator", "_get_rescaled_operator", "create_mv", "sp_linalg.LinearOperator", "_sparse_linalg_cg", "X1.rmatvec", "X1.rmatvec", "sp_linalg.LinearOperator", "_sparse_linalg_cg", "ValueError", "warnings.warn", "X1.matvec", "X1.rmatvec", "X1.rmatvec", "X1.matvec"], "code_location": {"file": "_ridge.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/linear_model", "start_line": 85, "end_line": 155}, "code_snippet": "def _solve_sparse_cg(\n    X,\n    y,\n    alpha,\n    max_iter=None,\n    tol=1e-4,\n    verbose=0,\n    X_offset=None,\n    X_scale=None,\n    sample_weight_sqrt=None,\n):\n    if sample_weight_sqrt is None:\n        sample_weight_sqrt = np.ones(X.shape[0], dtype=X.dtype)\n\n    n_samples, n_features = X.shape\n\n    if X_offset is None or X_scale is None:\n        X1 = sp_linalg.aslinearoperator(X)\n    else:\n        X_offset_scale = X_offset / X_scale\n        X1 = _get_rescaled_operator(X, X_offset_scale, sample_weight_sqrt)\n\n    coefs = np.empty((y.shape[1], n_features), dtype=X.dtype)\n\n    if n_features > n_samples:\n\n        def create_mv(curr_alpha):\n            def _mv(x):\n                return X1.matvec(X1.rmatvec(x)) + curr_alpha * x\n\n            return _mv\n\n    else:\n\n        def create_mv(curr_alpha):\n            def _mv(x):\n                return X1.rmatvec(X1.matvec(x)) + curr_alpha * x\n\n            return _mv\n\n    for i in range(y.shape[1]):\n        y_column = y[:, i]\n\n        mv = create_mv(alpha[i])\n        if n_features > n_samples:\n            # kernel ridge\n            # w = X.T * inv(X X^t + alpha*Id) y\n            C = sp_linalg.LinearOperator(\n                (n_samples, n_samples), matvec=mv, dtype=X.dtype\n            )\n            coef, info = _sparse_linalg_cg(C, y_column, rtol=tol)\n            coefs[i] = X1.rmatvec(coef)\n        else:\n            # linear ridge\n            # w = inv(X^t X + alpha*Id) * X.T y\n            y_column = X1.rmatvec(y_column)\n            C = sp_linalg.LinearOperator(\n                (n_features, n_features), matvec=mv, dtype=X.dtype\n            )\n            coefs[i], info = _sparse_linalg_cg(C, y_column, maxiter=max_iter, rtol=tol)\n\n        if info < 0:\n            raise ValueError(\"Failed with error code %d\" % info)\n\n        if max_iter is None and info > 0 and verbose:\n            warnings.warn(\n                \"sparse_cg did not converge after %d iterations.\" % info,\n                ConvergenceWarning,\n            )\n\n    return coefs\n", "type": "function"}, {"name": "test_ridge_fit_intercept_sparse", "is_method": false, "class_name": null, "parameters": ["solver", "with_sample_weight", "global_random_seed", "csr_container"], "calls": ["pytest.mark.parametrize", "pytest.mark.parametrize", "pytest.mark.parametrize", "_make_sparse_offset_regression", "Ridge", "Ridge", "dense_ridge.fit", "sparse_ridge.fit", "assert_allclose", "assert_allclose", "np.random.RandomState", "csr_container", "rng.uniform"], "code_location": {"file": "test_ridge.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/linear_model/tests", "start_line": 1735, "end_line": 1770}, "code_snippet": "def test_ridge_fit_intercept_sparse(\n    solver, with_sample_weight, global_random_seed, csr_container\n):\n    \"\"\"Check that ridge finds the same coefs and intercept on dense and sparse input\n    in the presence of sample weights.\n\n    For now only sparse_cg and lbfgs can correctly fit an intercept\n    with sparse X with default tol and max_iter.\n    'sag' is tested separately in test_ridge_fit_intercept_sparse_sag because it\n    requires more iterations and should raise a warning if default max_iter is used.\n    Other solvers raise an exception, as checked in\n    test_ridge_fit_intercept_sparse_error\n    \"\"\"\n    positive = solver == \"lbfgs\"\n    X, y = _make_sparse_offset_regression(\n        n_features=20, random_state=global_random_seed, positive=positive\n    )\n\n    sample_weight = None\n    if with_sample_weight:\n        rng = np.random.RandomState(global_random_seed)\n        sample_weight = 1.0 + rng.uniform(size=X.shape[0])\n\n    # \"auto\" should switch to \"sparse_cg\" when X is sparse\n    # so the reference we use for both (\"auto\" and \"sparse_cg\") is\n    # Ridge(solver=\"sparse_cg\"), fitted using the dense representation (note\n    # that \"sparse_cg\" can fit sparse or dense data)\n    dense_solver = \"sparse_cg\" if solver == \"auto\" else solver\n    dense_ridge = Ridge(solver=dense_solver, tol=1e-12, positive=positive)\n    sparse_ridge = Ridge(solver=solver, tol=1e-12, positive=positive)\n\n    dense_ridge.fit(X, y, sample_weight=sample_weight)\n    sparse_ridge.fit(csr_container(X), y, sample_weight=sample_weight)\n\n    assert_allclose(dense_ridge.intercept_, sparse_ridge.intercept_)\n    assert_allclose(dense_ridge.coef_, sparse_ridge.coef_, rtol=5e-7)\n", "type": "function"}, {"name": "_sparse_fit", "is_method": true, "class_name": "BaseLibSVM", "parameters": ["self", "X", "y", "sample_weight", "solver_type", "kernel", "random_seed"], "calls": ["np.asarray", "X.sort_indices", "self._sparse_kernels.index", "libsvm_sparse.set_verbosity_wrap", "libsvm_sparse.libsvm_sparse_train", "self._warn_from_fit_status", "hasattr", "np.tile", "getattr", "int", "int", "np.arange", "sp.csr_matrix", "np.arange", "sp.csr_matrix", "np.empty", "len"], "code_location": {"file": "_base.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/svm", "start_line": 367, "end_line": 426}, "code_snippet": "    def _sparse_fit(self, X, y, sample_weight, solver_type, kernel, random_seed):\n        X.data = np.asarray(X.data, dtype=np.float64, order=\"C\")\n        X.sort_indices()\n\n        kernel_type = self._sparse_kernels.index(kernel)\n\n        libsvm_sparse.set_verbosity_wrap(self.verbose)\n\n        (\n            self.support_,\n            self.support_vectors_,\n            dual_coef_data,\n            self.intercept_,\n            self._n_support,\n            self._probA,\n            self._probB,\n            self.fit_status_,\n            self._num_iter,\n        ) = libsvm_sparse.libsvm_sparse_train(\n            X.shape[1],\n            X.data,\n            X.indices,\n            X.indptr,\n            y,\n            solver_type,\n            kernel_type,\n            self.degree,\n            self._gamma,\n            self.coef0,\n            self.tol,\n            self.C,\n            getattr(self, \"class_weight_\", np.empty(0)),\n            sample_weight,\n            self.nu,\n            self.cache_size,\n            self.epsilon,\n            int(self.shrinking),\n            int(self.probability),\n            self.max_iter,\n            random_seed,\n        )\n\n        self._warn_from_fit_status()\n\n        if hasattr(self, \"classes_\"):\n            n_class = len(self.classes_) - 1\n        else:  # regression\n            n_class = 1\n        n_SV = self.support_vectors_.shape[0]\n\n        dual_coef_indices = np.tile(np.arange(n_SV), n_class)\n        if not n_SV:\n            self.dual_coef_ = sp.csr_matrix([])\n        else:\n            dual_coef_indptr = np.arange(\n                0, dual_coef_indices.size + 1, dual_coef_indices.size / n_class\n            )\n            self.dual_coef_ = sp.csr_matrix(\n                (dual_coef_data, dual_coef_indices, dual_coef_indptr), (n_class, n_SV)\n            )\n", "type": "function"}, {"name": "test_ridge_fit_intercept_sparse_sag", "is_method": false, "class_name": null, "parameters": ["with_sample_weight", "global_random_seed", "csr_container"], "calls": ["pytest.mark.parametrize", "pytest.mark.parametrize", "_make_sparse_offset_regression", "csr_container", "dict", "Ridge", "Ridge", "dense_ridge.fit", "assert_allclose", "assert_allclose", "np.random.RandomState", "warnings.catch_warnings", "warnings.simplefilter", "sparse_ridge.fit", "pytest.warns", "fit", "rng.uniform", "Ridge"], "code_location": {"file": "test_ridge.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/linear_model/tests", "start_line": 1786, "end_line": 1811}, "code_snippet": "def test_ridge_fit_intercept_sparse_sag(\n    with_sample_weight, global_random_seed, csr_container\n):\n    X, y = _make_sparse_offset_regression(\n        n_features=5, n_samples=20, random_state=global_random_seed, X_offset=5.0\n    )\n    if with_sample_weight:\n        rng = np.random.RandomState(global_random_seed)\n        sample_weight = 1.0 + rng.uniform(size=X.shape[0])\n    else:\n        sample_weight = None\n    X_csr = csr_container(X)\n\n    params = dict(\n        alpha=1.0, solver=\"sag\", fit_intercept=True, tol=1e-10, max_iter=100000\n    )\n    dense_ridge = Ridge(**params)\n    sparse_ridge = Ridge(**params)\n    dense_ridge.fit(X, y, sample_weight=sample_weight)\n    with warnings.catch_warnings():\n        warnings.simplefilter(\"error\", UserWarning)\n        sparse_ridge.fit(X_csr, y, sample_weight=sample_weight)\n    assert_allclose(dense_ridge.intercept_, sparse_ridge.intercept_, rtol=1e-4)\n    assert_allclose(dense_ridge.coef_, sparse_ridge.coef_, rtol=1e-4)\n    with pytest.warns(UserWarning, match='\"sag\" solver requires.*'):\n        Ridge(solver=\"sag\", fit_intercept=True, tol=1e-3, max_iter=None).fit(X_csr, y)\n", "type": "function"}, {"name": "resolve_solver", "is_method": false, "class_name": null, "parameters": ["solver", "positive", "return_intercept", "is_sparse", "xp"], "calls": ["_is_numpy_namespace", "resolve_solver_for_numpy", "ValueError", "warnings.warn"], "code_location": {"file": "_ridge.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/linear_model", "start_line": 839, "end_line": 868}, "code_snippet": "def resolve_solver(solver, positive, return_intercept, is_sparse, xp):\n    if solver != \"auto\":\n        return solver\n\n    is_numpy_namespace = _is_numpy_namespace(xp)\n\n    auto_solver_np = resolve_solver_for_numpy(positive, return_intercept, is_sparse)\n    if is_numpy_namespace:\n        return auto_solver_np\n\n    if positive:\n        raise ValueError(\n            \"The solvers that support positive fitting do not support \"\n            f\"Array API dispatch to namespace {xp.__name__}. Please \"\n            \"either disable Array API dispatch, or use a numpy-like \"\n            \"namespace, or set `positive=False`.\"\n        )\n\n    # At the moment, Array API dispatch only supports the \"svd\" solver.\n    solver = \"svd\"\n    if solver != auto_solver_np:\n        warnings.warn(\n            f\"Using Array API dispatch to namespace {xp.__name__} with \"\n            f\"`solver='auto'` will result in using the solver '{solver}'. \"\n            \"The results may differ from those when using a Numpy array, \"\n            f\"because in that case the preferred solver would be {auto_solver_np}. \"\n            f\"Set `solver='{solver}'` to suppress this warning.\"\n        )\n\n    return solver\n", "type": "function"}, {"name": "_solve_lsqr", "is_method": false, "class_name": null, "parameters": ["X", "y"], "calls": ["np.empty", "np.empty", "np.sqrt", "range", "np.ones", "sparse.issparse", "_get_rescaled_operator", "sp_linalg.lsqr"], "code_location": {"file": "_ridge.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/linear_model", "start_line": 158, "end_line": 211}, "code_snippet": "def _solve_lsqr(\n    X,\n    y,\n    *,\n    alpha,\n    fit_intercept=True,\n    max_iter=None,\n    tol=1e-4,\n    X_offset=None,\n    X_scale=None,\n    sample_weight_sqrt=None,\n):\n    \"\"\"Solve Ridge regression via LSQR.\n\n    We expect that y is always mean centered.\n    If X is dense, we expect it to be mean centered such that we can solve\n        ||y - Xw||_2^2 + alpha * ||w||_2^2\n\n    If X is sparse, we expect X_offset to be given such that we can solve\n        ||y - (X - X_offset)w||_2^2 + alpha * ||w||_2^2\n\n    With sample weights S=diag(sample_weight), this becomes\n        ||sqrt(S) (y - (X - X_offset) w)||_2^2 + alpha * ||w||_2^2\n    and we expect y and X to already be rescaled, i.e. sqrt(S) @ y, sqrt(S) @ X. In\n    this case, X_offset is the sample_weight weighted mean of X before scaling by\n    sqrt(S). The objective then reads\n       ||y - (X - sqrt(S) X_offset) w)||_2^2 + alpha * ||w||_2^2\n    \"\"\"\n    if sample_weight_sqrt is None:\n        sample_weight_sqrt = np.ones(X.shape[0], dtype=X.dtype)\n\n    if sparse.issparse(X) and fit_intercept:\n        X_offset_scale = X_offset / X_scale\n        X1 = _get_rescaled_operator(X, X_offset_scale, sample_weight_sqrt)\n    else:\n        # No need to touch anything\n        X1 = X\n\n    n_samples, n_features = X.shape\n    coefs = np.empty((y.shape[1], n_features), dtype=X.dtype)\n    n_iter = np.empty(y.shape[1], dtype=np.int32)\n\n    # According to the lsqr documentation, alpha = damp^2.\n    sqrt_alpha = np.sqrt(alpha)\n\n    for i in range(y.shape[1]):\n        y_column = y[:, i]\n        info = sp_linalg.lsqr(\n            X1, y_column, damp=sqrt_alpha[i], atol=tol, btol=tol, iter_lim=max_iter\n        )\n        coefs[i] = info[0]\n        n_iter[i] = info[2]\n\n    return coefs, n_iter\n", "type": "function"}], "retrieved_count": 10, "cost_time": 0.5525352954864502}
{"question": "Where does the control flow in test_affinities determine which affinity computation pathway is executed based on the kernel type, and what data transformations occur at each decision point before labels are generated?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"name": "test_affinities", "is_method": false, "class_name": null, "parameters": ["global_random_seed"], "calls": ["make_blobs", "SpectralClustering", "SpectralClustering", "kernel_metrics", "SpectralClustering", "SpectralClustering", "pytest.warns", "sp.fit", "adjusted_rand_score", "sp.fit", "adjusted_rand_score", "rand", "sp.fit", "sum", "sp.fit", "SpectralClustering", "check_random_state", "sp.fit", "np.minimum"], "code_location": {"file": "test_spectral.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/cluster/tests", "start_line": 133, "end_line": 172}, "code_snippet": "def test_affinities(global_random_seed):\n    # Note: in the following, random_state has been selected to have\n    # a dataset that yields a stable eigen decomposition both when built\n    # on OSX and Linux\n    X, y = make_blobs(\n        n_samples=20, random_state=0, centers=[[1, 1], [-1, -1]], cluster_std=0.01\n    )\n    # nearest neighbors affinity\n    sp = SpectralClustering(n_clusters=2, affinity=\"nearest_neighbors\", random_state=0)\n    with pytest.warns(UserWarning, match=\"not fully connected\"):\n        sp.fit(X)\n    assert adjusted_rand_score(y, sp.labels_) == 1\n\n    sp = SpectralClustering(n_clusters=2, gamma=2, random_state=global_random_seed)\n    labels = sp.fit(X).labels_\n    assert adjusted_rand_score(y, labels) == 1\n\n    X = check_random_state(10).rand(10, 5) * 10\n\n    kernels_available = kernel_metrics()\n    for kern in kernels_available:\n        # Additive chi^2 gives a negative similarity matrix which\n        # doesn't make sense for spectral clustering\n        if kern != \"additive_chi2\":\n            sp = SpectralClustering(n_clusters=2, affinity=kern, random_state=0)\n            labels = sp.fit(X).labels_\n            assert (X.shape[0],) == labels.shape\n\n    sp = SpectralClustering(n_clusters=2, affinity=lambda x, y: 1, random_state=0)\n    labels = sp.fit(X).labels_\n    assert (X.shape[0],) == labels.shape\n\n    def histogram(x, y, **kwargs):\n        # Histogram kernel implemented as a callable.\n        assert kwargs == {}  # no kernel_params that we didn't ask for\n        return np.minimum(x, y).sum()\n\n    sp = SpectralClustering(n_clusters=2, affinity=histogram, random_state=0)\n    labels = sp.fit(X).labels_\n    assert (X.shape[0],) == labels.shape\n", "type": "function"}, {"name": "test_predict_sparse_callable_kernel", "is_method": false, "class_name": null, "parameters": ["global_dtype"], "calls": ["make_classification", "X.astype", "train_test_split", "label_propagation.LabelSpreading", "model.fit", "label_propagation.LabelPropagation", "model.fit", "NearestNeighbors", "nn.fit", "np.exp", "issparse", "model.score", "model.score", "power", "nn.kneighbors_graph"], "code_location": {"file": "test_label_propagation.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/semi_supervised/tests", "start_line": 202, "end_line": 238}, "code_snippet": "def test_predict_sparse_callable_kernel(global_dtype):\n    # This is a non-regression test for #15866\n\n    # Custom sparse kernel (top-K RBF)\n    def topk_rbf(X, Y=None, n_neighbors=10, gamma=1e-5):\n        nn = NearestNeighbors(n_neighbors=10, metric=\"euclidean\", n_jobs=2)\n        nn.fit(X)\n        W = -1 * nn.kneighbors_graph(Y, mode=\"distance\").power(2) * gamma\n        np.exp(W.data, out=W.data)\n        assert issparse(W)\n        return W.T\n\n    n_classes = 4\n    n_samples = 500\n    n_test = 10\n    X, y = make_classification(\n        n_classes=n_classes,\n        n_samples=n_samples,\n        n_features=20,\n        n_informative=20,\n        n_redundant=0,\n        n_repeated=0,\n        random_state=0,\n    )\n    X = X.astype(global_dtype)\n\n    X_train, X_test, y_train, y_test = train_test_split(\n        X, y, test_size=n_test, random_state=0\n    )\n\n    model = label_propagation.LabelSpreading(kernel=topk_rbf)\n    model.fit(X_train, y_train)\n    assert model.score(X_test, y_test) >= 0.9\n\n    model = label_propagation.LabelPropagation(kernel=topk_rbf)\n    model.fit(X_train, y_train)\n    assert model.score(X_test, y_test) >= 0.9\n", "type": "function"}, {"name": "test_spectral_embedding_precomputed_affinity", "is_method": false, "class_name": null, "parameters": ["sparse_container", "eigen_solver", "dtype", "seed"], "calls": ["pytest.mark.parametrize", "pytest.mark.parametrize", "pytest.mark.parametrize", "SpectralEmbedding", "SpectralEmbedding", "se_precomp.fit_transform", "se_rbf.fit_transform", "assert_array_almost_equal", "_assert_equal_with_sign_flipping", "sparse_container", "rbf_kernel", "X.astype", "pytest.param", "np.random.RandomState", "np.random.RandomState", "X.astype"], "code_location": {"file": "test_spectral_embedding.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/manifold/tests", "start_line": 174, "end_line": 197}, "code_snippet": "def test_spectral_embedding_precomputed_affinity(\n    sparse_container, eigen_solver, dtype, seed=36\n):\n    # Test spectral embedding with precomputed kernel\n    gamma = 1.0\n    X = S if sparse_container is None else sparse_container(S)\n\n    se_precomp = SpectralEmbedding(\n        n_components=2,\n        affinity=\"precomputed\",\n        random_state=np.random.RandomState(seed),\n        eigen_solver=eigen_solver,\n    )\n    se_rbf = SpectralEmbedding(\n        n_components=2,\n        affinity=\"rbf\",\n        gamma=gamma,\n        random_state=np.random.RandomState(seed),\n        eigen_solver=eigen_solver,\n    )\n    embed_precomp = se_precomp.fit_transform(rbf_kernel(X.astype(dtype), gamma=gamma))\n    embed_rbf = se_rbf.fit_transform(X.astype(dtype))\n    assert_array_almost_equal(se_precomp.affinity_matrix_, se_rbf.affinity_matrix_)\n    _assert_equal_with_sign_flipping(embed_precomp, embed_rbf, 0.05)\n", "type": "function"}, {"name": "test_kernel_density", "is_method": false, "class_name": null, "parameters": ["kernel", "bandwidth"], "calls": ["pytest.mark.parametrize", "pytest.mark.parametrize", "np.random.RandomState", "rng.randn", "rng.randn", "compute_kernel_slow", "check_results"], "code_location": {"file": "test_kde.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/neighbors/tests", "start_line": 54, "end_line": 66}, "code_snippet": "def test_kernel_density(kernel, bandwidth):\n    n_samples, n_features = (100, 3)\n\n    rng = np.random.RandomState(0)\n    X = rng.randn(n_samples, n_features)\n    Y = rng.randn(n_samples, n_features)\n\n    dens_true = compute_kernel_slow(Y, X, kernel, bandwidth)\n\n    for rtol in [0, 1e-5]:\n        for atol in [1e-6, 1e-2]:\n            for breadth_first in (True, False):\n                check_results(kernel, bandwidth, atol, rtol, X, Y, dens_true)\n", "type": "function"}, {"name": "test_spectral_embedding_callable_affinity", "is_method": false, "class_name": null, "parameters": ["sparse_container", "seed"], "calls": ["pytest.mark.parametrize", "rbf_kernel", "SpectralEmbedding", "SpectralEmbedding", "se_rbf.fit_transform", "se_callable.fit_transform", "assert_array_almost_equal", "assert_array_almost_equal", "_assert_equal_with_sign_flipping", "sparse_container", "np.random.RandomState", "np.random.RandomState", "rbf_kernel"], "code_location": {"file": "test_spectral_embedding.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/manifold/tests", "start_line": 223, "end_line": 245}, "code_snippet": "def test_spectral_embedding_callable_affinity(sparse_container, seed=36):\n    # Test spectral embedding with callable affinity\n    gamma = 0.9\n    kern = rbf_kernel(S, gamma=gamma)\n    X = S if sparse_container is None else sparse_container(S)\n\n    se_callable = SpectralEmbedding(\n        n_components=2,\n        affinity=(lambda x: rbf_kernel(x, gamma=gamma)),\n        gamma=gamma,\n        random_state=np.random.RandomState(seed),\n    )\n    se_rbf = SpectralEmbedding(\n        n_components=2,\n        affinity=\"rbf\",\n        gamma=gamma,\n        random_state=np.random.RandomState(seed),\n    )\n    embed_rbf = se_rbf.fit_transform(X)\n    embed_callable = se_callable.fit_transform(X)\n    assert_array_almost_equal(se_callable.affinity_matrix_, se_rbf.affinity_matrix_)\n    assert_array_almost_equal(kern, se_rbf.affinity_matrix_)\n    _assert_equal_with_sign_flipping(embed_rbf, embed_callable, 0.05)\n", "type": "function"}, {"name": "test_label_propagation_closed_form", "is_method": false, "class_name": null, "parameters": ["global_dtype"], "calls": ["make_classification", "X.astype", "np.zeros", "label_propagation.LabelPropagation", "clf.fit", "clf._build_graph", "np.dot", "Y.copy", "assert_allclose", "nonzero", "nonzero", "tuple", "tuple", "np.dot", "expected.sum", "len", "np.arange", "np.meshgrid", "np.meshgrid", "np.linalg.inv", "len", "np.eye"], "code_location": {"file": "test_label_propagation.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/semi_supervised/tests", "start_line": 102, "end_line": 126}, "code_snippet": "def test_label_propagation_closed_form(global_dtype):\n    n_classes = 2\n    X, y = make_classification(n_classes=n_classes, n_samples=200, random_state=0)\n    X = X.astype(global_dtype, copy=False)\n    y[::3] = -1\n    Y = np.zeros((len(y), n_classes + 1))\n    Y[np.arange(len(y)), y] = 1\n    unlabelled_idx = Y[:, (-1,)].nonzero()[0]\n    labelled_idx = (Y[:, (-1,)] == 0).nonzero()[0]\n\n    clf = label_propagation.LabelPropagation(max_iter=100, tol=1e-10, gamma=0.1)\n    clf.fit(X, y)\n    # adopting notation from Zhu et al 2002\n    T_bar = clf._build_graph()\n    Tuu = T_bar[tuple(np.meshgrid(unlabelled_idx, unlabelled_idx, indexing=\"ij\"))]\n    Tul = T_bar[tuple(np.meshgrid(unlabelled_idx, labelled_idx, indexing=\"ij\"))]\n    Y = Y[:, :-1]\n    Y_l = Y[labelled_idx, :]\n    Y_u = np.dot(np.dot(np.linalg.inv(np.eye(Tuu.shape[0]) - Tuu), Tul), Y_l)\n\n    expected = Y.copy()\n    expected[unlabelled_idx, :] = Y_u\n    expected /= expected.sum(axis=1)[:, np.newaxis]\n\n    assert_allclose(expected, clf.label_distributions_, atol=1e-4)\n", "type": "function"}, {"name": "test_label_spreading_closed_form", "is_method": false, "class_name": null, "parameters": ["global_dtype", "Estimator", "parameters", "alpha"], "calls": ["pytest.mark.parametrize", "pytest.mark.parametrize", "make_classification", "X.astype", "fit", "clf._build_graph", "np.zeros", "np.dot", "label_propagation.LabelSpreading", "clf.fit", "assert_allclose", "np.linalg.inv", "expected.sum", "label_propagation.LabelSpreading", "len", "np.arange", "len", "np.eye", "len"], "code_location": {"file": "test_label_propagation.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/semi_supervised/tests", "start_line": 77, "end_line": 99}, "code_snippet": "def test_label_spreading_closed_form(global_dtype, Estimator, parameters, alpha):\n    n_classes = 2\n    X, y = make_classification(n_classes=n_classes, n_samples=200, random_state=0)\n    X = X.astype(global_dtype, copy=False)\n    y[::3] = -1\n\n    gamma = 0.1\n    clf = label_propagation.LabelSpreading(gamma=gamma).fit(X, y)\n    # adopting notation from Zhou et al (2004):\n    S = clf._build_graph()\n    Y = np.zeros((len(y), n_classes + 1), dtype=X.dtype)\n    Y[np.arange(len(y)), y] = 1\n    Y = Y[:, :-1]\n\n    expected = np.dot(np.linalg.inv(np.eye(len(S), dtype=S.dtype) - alpha * S), Y)\n    expected /= expected.sum(axis=1)[:, np.newaxis]\n\n    clf = label_propagation.LabelSpreading(\n        max_iter=100, alpha=alpha, tol=1e-10, gamma=gamma\n    )\n    clf.fit(X, y)\n\n    assert_allclose(expected, clf.label_distributions_)\n", "type": "function"}, {"name": "test_kernel_density", "is_method": false, "class_name": null, "parameters": ["Cls", "kernel", "h", "rtol", "atol", "breadth_first", "n_samples", "n_features"], "calls": ["pytest.mark.parametrize", "pytest.mark.parametrize", "pytest.mark.parametrize", "pytest.mark.parametrize", "pytest.mark.parametrize", "pytest.mark.parametrize", "check_random_state", "rng.random_sample", "rng.random_sample", "compute_kernel_slow", "Cls", "tree.kernel_density", "assert_allclose", "max"], "code_location": {"file": "test_neighbors_tree.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/neighbors/tests", "start_line": 96, "end_line": 108}, "code_snippet": "def test_kernel_density(\n    Cls, kernel, h, rtol, atol, breadth_first, n_samples=100, n_features=3\n):\n    rng = check_random_state(1)\n    X = rng.random_sample((n_samples, n_features))\n    Y = rng.random_sample((n_samples, n_features))\n    dens_true = compute_kernel_slow(Y, X, kernel, h)\n\n    tree = Cls(X, leaf_size=10)\n    dens = tree.kernel_density(\n        Y, h, atol=atol, rtol=rtol, kernel=kernel, breadth_first=breadth_first\n    )\n    assert_allclose(dens, dens_true, atol=atol, rtol=max(rtol, 1e-7))\n", "type": "function"}, {"name": "test_pairwise_similarity_sparse_output", "is_method": false, "class_name": null, "parameters": ["metric", "pairwise_func", "csr_container"], "calls": ["pytest.mark.parametrize", "pytest.mark.parametrize", "np.random.RandomState", "rng.random_sample", "rng.random_sample", "csr_container", "csr_container", "pairwise_func", "issparse", "pairwise_func", "assert_allclose", "pairwise_kernels", "assert_allclose", "issparse", "K1.toarray", "K1.toarray"], "code_location": {"file": "test_pairwise.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/metrics/tests", "start_line": 1484, "end_line": 1502}, "code_snippet": "def test_pairwise_similarity_sparse_output(metric, pairwise_func, csr_container):\n    rng = np.random.RandomState(0)\n    X = rng.random_sample((5, 4))\n    Y = rng.random_sample((3, 4))\n    Xcsr = csr_container(X)\n    Ycsr = csr_container(Y)\n\n    # should be sparse\n    K1 = pairwise_func(Xcsr, Ycsr, dense_output=False)\n    assert issparse(K1)\n\n    # should be dense, and equal to K1\n    K2 = pairwise_func(X, Y, dense_output=True)\n    assert not issparse(K2)\n    assert_allclose(K1.toarray(), K2)\n\n    # show the kernel output equal to the sparse.toarray()\n    K3 = pairwise_kernels(X, Y=Y, metric=metric)\n    assert_allclose(K1.toarray(), K3)\n", "type": "function"}, {"name": "test_affinity_propagation_predict", "is_method": false, "class_name": null, "parameters": ["global_random_seed", "global_dtype"], "calls": ["AffinityPropagation", "X.astype", "af.fit_predict", "af.predict", "assert_array_equal"], "code_location": {"file": "test_affinity_propagation.py", "path": "/data3/pwh/swebench-repos/scikit-learn/sklearn/cluster/tests", "start_line": 114, "end_line": 120}, "code_snippet": "def test_affinity_propagation_predict(global_random_seed, global_dtype):\n    # Test AffinityPropagation.predict\n    af = AffinityPropagation(affinity=\"euclidean\", random_state=global_random_seed)\n    X_ = X.astype(global_dtype, copy=False)\n    labels = af.fit_predict(X_)\n    labels2 = af.predict(X_)\n    assert_array_equal(labels, labels2)\n", "type": "function"}], "retrieved_count": 10, "cost_time": 0.7935311794281006}
