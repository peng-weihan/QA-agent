{"question": "What is the architectural pattern in the TestArgComplete class that decouples the comparison logic between FastFilesCompleter and FilesCompleter implementations to enable independent evolution of bash completion strategies?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"name": "test_compare_with_compgen", "is_method": true, "class_name": "TestArgComplete", "parameters": ["self", "tmp_path", "monkeypatch"], "calls": ["pytest.mark.skipif", "FastFilesCompleter", "FilesCompleter", "monkeypatch.chdir", "equal_with_bash", "touch", "equal_with_bash", "joinpath", "tmp_path.cwd"], "code_location": {"file": "test_argcomplete.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 74, "end_line": 89}, "code_snippet": "    def test_compare_with_compgen(\n        self, tmp_path: Path, monkeypatch: MonkeyPatch\n    ) -> None:\n        from _pytest._argcomplete import FastFilesCompleter\n\n        ffc = FastFilesCompleter()\n        fc = FilesCompleter()\n\n        monkeypatch.chdir(tmp_path)\n\n        assert equal_with_bash(\"\", ffc, fc, out=sys.stdout)\n\n        tmp_path.cwd().joinpath(\"data\").touch()\n\n        for x in [\"d\", \"data\", \"doesnotexist\", \"\"]:\n            assert equal_with_bash(x, ffc, fc, out=sys.stdout)\n", "type": "function"}, {"name": "test_remove_dir_prefix", "is_method": true, "class_name": "TestArgComplete", "parameters": ["self"], "calls": ["pytest.mark.skipif", "FastFilesCompleter", "FilesCompleter", "split", "equal_with_bash"], "code_location": {"file": "test_argcomplete.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 92, "end_line": 99}, "code_snippet": "    def test_remove_dir_prefix(self):\n        \"\"\"This is not compatible with compgen but it is with bash itself: ls /usr/<TAB>.\"\"\"\n        from _pytest._argcomplete import FastFilesCompleter\n\n        ffc = FastFilesCompleter()\n        fc = FilesCompleter()\n        for x in \"/usr/\".split():\n            assert not equal_with_bash(x, ffc, fc, out=sys.stdout)\n", "type": "function"}, {"name": "__call__", "is_method": true, "class_name": "FilesCompleter", "parameters": ["self", "prefix"], "calls": ["_wrapcall", "_wrapcall", "list", "_wrapcall", "_wrapcall", "set", "set"], "code_location": {"file": "test_argcomplete.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 50, "end_line": 69}, "code_snippet": "    def __call__(self, prefix, **kwargs):\n        completion = []\n        if self.allowednames:\n            if self.directories:\n                files = _wrapcall([\"bash\", \"-c\", f\"compgen -A directory -- '{prefix}'\"])\n                completion += [f + \"/\" for f in files]\n            for x in self.allowednames:\n                completion += _wrapcall(\n                    [\"bash\", \"-c\", f\"compgen -A file -X '!*.{x}' -- '{prefix}'\"]\n                )\n        else:\n            completion += _wrapcall([\"bash\", \"-c\", f\"compgen -A file -- '{prefix}'\"])\n\n            anticomp = _wrapcall([\"bash\", \"-c\", f\"compgen -A directory -- '{prefix}'\"])\n\n            completion = list(set(completion) - set(anticomp))\n\n            if self.directories:\n                completion += [f + \"/\" for f in anticomp]\n        return completion\n", "type": "function"}, {"name": "__call__", "is_method": true, "class_name": "FastFilesCompleter", "parameters": ["self", "prefix"], "calls": ["globbed.extend", "sorted", "len", "glob", "os.path.isdir", "completion.append", "globbed.extend", "os.path.dirname", "glob"], "code_location": {"file": "_argcomplete.py", "path": "/data3/pwh/swebench-repos/pytest/src/_pytest", "start_line": 80, "end_line": 99}, "code_snippet": "    def __call__(self, prefix: str, **kwargs: Any) -> list[str]:\n        # Only called on non option completions.\n        if os.sep in prefix[1:]:\n            prefix_dir = len(os.path.dirname(prefix) + os.sep)\n        else:\n            prefix_dir = 0\n        completion = []\n        globbed = []\n        if \"*\" not in prefix and \"?\" not in prefix:\n            # We are on unix, otherwise no bash.\n            if not prefix or prefix[-1] == os.sep:\n                globbed.extend(glob(prefix + \".*\"))\n            prefix += \"*\"\n        globbed.extend(glob(prefix))\n        for x in sorted(globbed):\n            if os.path.isdir(x):\n                x += \"/\"\n            # Append stripping the prefix (like bash, not like compgen).\n            completion.append(x[prefix_dir:])\n        return completion\n", "type": "function"}, {"name": "equal_with_bash", "is_method": false, "class_name": null, "parameters": ["prefix", "ffc", "fc", "out"], "calls": ["ffc", "set", "fc", "set", "out.write", "out.write", "out.write", "set", "set"], "code_location": {"file": "test_argcomplete.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 15, "end_line": 24}, "code_snippet": "def equal_with_bash(prefix, ffc, fc, out=None):\n    res = ffc(prefix)\n    res_bash = set(fc(prefix))\n    retval = set(res) == res_bash\n    if out:\n        out.write(f\"equal_with_bash({prefix}) {retval} {res}\\n\")\n        if not retval:\n            out.write(\" python - bash: %s\\n\" % (set(res) - res_bash))\n            out.write(\" bash - python: %s\\n\" % (res_bash - set(res)))\n    return retval\n", "type": "function"}, {"name": "basestarts", "is_method": true, "class_name": "Checkers", "parameters": ["self", "arg"], "calls": ["self.path.basename.startswith"], "code_location": {"file": "path.py", "path": "/data3/pwh/swebench-repos/pytest/src/_pytest/_py", "start_line": 58, "end_line": 59}, "code_snippet": "    def basestarts(self, arg):\n        return self.path.basename.startswith(arg)\n", "type": "function"}, {"name": "test_cmp", "is_method": true, "class_name": "CommonFSTests", "parameters": ["self", "path1"], "calls": ["path1.join", "path1.join"], "code_location": {"file": "test_local.py", "path": "/data3/pwh/swebench-repos/pytest/testing/_py", "start_line": 233, "end_line": 237}, "code_snippet": "    def test_cmp(self, path1):\n        path1 = path1.join(\"samplefile\")\n        path2 = path1.join(\"samplefile2\")\n        assert (path1 < path2) == (\"samplefile\" < \"samplefile2\")\n        assert not (path1 < path1)\n", "type": "function"}, {"name": "test_fnmatch_file_abspath", "is_method": true, "class_name": "TestLocalPath", "parameters": ["self", "tmpdir"], "calls": ["tmpdir.join", "b.fnmatch", "os.sep.join", "b.fnmatch", "os.sep.join", "str"], "code_location": {"file": "test_local.py", "path": "/data3/pwh/swebench-repos/pytest/testing/_py", "start_line": 851, "end_line": 855}, "code_snippet": "    def test_fnmatch_file_abspath(self, tmpdir):\n        b = tmpdir.join(\"a\", \"b\")\n        assert b.fnmatch(os.sep.join(\"ab\"))\n        pattern = os.sep.join([str(tmpdir), \"*\", \"b\"])\n        assert b.fnmatch(pattern)\n", "type": "function"}, {"name": "test_check_equality", "is_method": true, "class_name": "TestSorting", "parameters": ["self", "pytester"], "calls": ["pytester.getmodulecol", "pytester.collect_by_name", "isinstance", "pytester.collect_by_name", "isinstance", "pytester.collect_by_name", "isinstance", "hash", "hash"], "code_location": {"file": "collect.py", "path": "/data3/pwh/swebench-repos/pytest/testing/python", "start_line": 788, "end_line": 814}, "code_snippet": "    def test_check_equality(self, pytester: Pytester) -> None:\n        modcol = pytester.getmodulecol(\n            \"\"\"\n            def test_pass(): pass\n            def test_fail(): assert 0\n        \"\"\"\n        )\n        fn1 = pytester.collect_by_name(modcol, \"test_pass\")\n        assert isinstance(fn1, pytest.Function)\n        fn2 = pytester.collect_by_name(modcol, \"test_pass\")\n        assert isinstance(fn2, pytest.Function)\n\n        assert fn1 == fn2\n        assert fn1 != modcol\n        assert hash(fn1) == hash(fn2)\n\n        fn3 = pytester.collect_by_name(modcol, \"test_fail\")\n        assert isinstance(fn3, pytest.Function)\n        assert not (fn1 == fn3)\n        assert fn1 != fn3\n\n        for fn in fn1, fn2, fn3:\n            assert fn != 3  # type: ignore[comparison-overlap]\n            assert fn != modcol\n            assert fn != [1, 2, 3]  # type: ignore[comparison-overlap]\n            assert [1, 2, 3] != fn  # type: ignore[comparison-overlap]\n            assert modcol != fn\n", "type": "function"}, {"name": "test_linematcher_no_matching", "is_method": false, "class_name": null, "parameters": ["function"], "calls": ["pytest.mark.parametrize", "LineMatcher", "range", "getattr", "func", "splitlines", "pytest.raises", "getattr", "func", "str"], "code_location": {"file": "test_pytester.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 547, "end_line": 592}, "code_snippet": "def test_linematcher_no_matching(function: str) -> None:\n    if function == \"no_fnmatch_line\":\n        good_pattern = \"*.py OK*\"\n        bad_pattern = \"*X.py OK*\"\n    else:\n        assert function == \"no_re_match_line\"\n        good_pattern = r\".*py OK\"\n        bad_pattern = r\".*Xpy OK\"\n\n    lm = LineMatcher(\n        [\n            \"cachedir: .pytest_cache\",\n            \"collecting ... collected 1 item\",\n            \"\",\n            \"show_fixtures_per_test.py OK\",\n            \"=== elapsed 1s ===\",\n        ]\n    )\n\n    # check the function twice to ensure we don't accumulate the internal buffer\n    for i in range(2):\n        with pytest.raises(pytest.fail.Exception) as e:\n            func = getattr(lm, function)\n            func(good_pattern)\n        obtained = str(e.value).splitlines()\n        if function == \"no_fnmatch_line\":\n            assert obtained == [\n                f\"nomatch: '{good_pattern}'\",\n                \"    and: 'cachedir: .pytest_cache'\",\n                \"    and: 'collecting ... collected 1 item'\",\n                \"    and: ''\",\n                f\"fnmatch: '{good_pattern}'\",\n                \"   with: 'show_fixtures_per_test.py OK'\",\n            ]\n        else:\n            assert obtained == [\n                f\" nomatch: '{good_pattern}'\",\n                \"     and: 'cachedir: .pytest_cache'\",\n                \"     and: 'collecting ... collected 1 item'\",\n                \"     and: ''\",\n                f\"re.match: '{good_pattern}'\",\n                \"    with: 'show_fixtures_per_test.py OK'\",\n            ]\n\n    func = getattr(lm, function)\n    func(bad_pattern)  # bad pattern does not match any line: passes\n", "type": "function"}], "retrieved_count": 10, "cost_time": 1.0155398845672607}
{"question": "What is the execution semantics encoded by the return value from `pytester.runpytest_subprocess()`, and what specific exit code semantics does the `.ret` attribute represent in the context of pytest's test execution model?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"name": "test_pytester_subprocess", "is_method": false, "class_name": null, "parameters": ["pytester"], "calls": ["pytester.makepyfile", "pytester.runpytest_subprocess"], "code_location": {"file": "test_pytester.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 413, "end_line": 415}, "code_snippet": "def test_pytester_subprocess(pytester: Pytester) -> None:\n    testfile = pytester.makepyfile(\"def test_one(): pass\")\n    assert pytester.runpytest_subprocess(testfile).ret == 0\n", "type": "function"}, {"name": "test_pytester_run_no_timeout", "is_method": false, "class_name": null, "parameters": ["pytester"], "calls": ["pytester.makepyfile", "pytester.runpytest_subprocess"], "code_location": {"file": "test_pytester.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 444, "end_line": 446}, "code_snippet": "def test_pytester_run_no_timeout(pytester: Pytester) -> None:\n    testfile = pytester.makepyfile(\"def test_no_timeout(): pass\")\n    assert pytester.runpytest_subprocess(testfile).ret == ExitCode.OK\n", "type": "function"}, {"name": "test_pytester_subprocess_via_runpytest_arg", "is_method": false, "class_name": null, "parameters": ["pytester"], "calls": ["pytester.makepyfile", "pytester.runpytest_inprocess"], "code_location": {"file": "test_pytester.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 418, "end_line": 436}, "code_snippet": "def test_pytester_subprocess_via_runpytest_arg(pytester: Pytester) -> None:\n    testfile = pytester.makepyfile(\n        \"\"\"\n        def test_pytester_subprocess(pytester):\n            import os\n            testfile = pytester.makepyfile(\n                \\\"\"\"\n                import os\n                def test_one():\n                    assert {} != os.getpid()\n                \\\"\"\".format(os.getpid())\n            )\n            assert pytester.runpytest(testfile).ret == 0\n        \"\"\"\n    )\n    result = pytester.runpytest_inprocess(\n        \"-p\", \"pytester\", \"--runpytest\", \"subprocess\", testfile\n    )\n    assert result.ret == 0\n", "type": "function"}, {"name": "test_pytest_no_tests_collected_exit_status", "is_method": false, "class_name": null, "parameters": ["pytester"], "calls": ["pytester.runpytest", "result.stdout.fnmatch_lines", "pytester.makepyfile", "pytester.runpytest", "result.stdout.fnmatch_lines", "result.stdout.fnmatch_lines", "pytester.runpytest", "result.stdout.fnmatch_lines", "result.stdout.fnmatch_lines"], "code_location": {"file": "test_runner.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 731, "end_line": 750}, "code_snippet": "def test_pytest_no_tests_collected_exit_status(pytester: Pytester) -> None:\n    result = pytester.runpytest()\n    result.stdout.fnmatch_lines([\"*collected 0 items*\"])\n    assert result.ret == ExitCode.NO_TESTS_COLLECTED\n\n    pytester.makepyfile(\n        test_foo=\"\"\"\n        def test_foo():\n            assert 1\n    \"\"\"\n    )\n    result = pytester.runpytest()\n    result.stdout.fnmatch_lines([\"*collected 1 item*\"])\n    result.stdout.fnmatch_lines([\"*1 passed*\"])\n    assert result.ret == ExitCode.OK\n\n    result = pytester.runpytest(\"-k nonmatch\")\n    result.stdout.fnmatch_lines([\"*collected 1 item*\"])\n    result.stdout.fnmatch_lines([\"*1 deselected*\"])\n    assert result.ret == ExitCode.NO_TESTS_COLLECTED\n", "type": "function"}, {"name": "runpytest_subprocess", "is_method": true, "class_name": "Testdir", "parameters": ["self"], "calls": ["self._pytester.runpytest_subprocess"], "code_location": {"file": "legacypath.py", "path": "/data3/pwh/swebench-repos/pytest/src/_pytest", "start_line": 234, "end_line": 236}, "code_snippet": "    def runpytest_subprocess(self, *args, timeout=None) -> RunResult:\n        \"\"\"See :meth:`Pytester.runpytest_subprocess`.\"\"\"\n        return self._pytester.runpytest_subprocess(*args, timeout=timeout)\n", "type": "function"}, {"name": "test_teardown_final_returncode", "is_method": true, "class_name": "BaseFunctionalTests", "parameters": ["self", "pytester"], "calls": ["pytester.inline_runsource"], "code_location": {"file": "test_runner.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 313, "end_line": 322}, "code_snippet": "    def test_teardown_final_returncode(self, pytester: Pytester) -> None:\n        rec = pytester.inline_runsource(\n            \"\"\"\n            def test_func():\n                pass\n            def teardown_function(func):\n                raise ValueError(42)\n        \"\"\"\n        )\n        assert rec.ret == 1\n", "type": "function"}, {"name": "test_pytester_run_with_timeout", "is_method": false, "class_name": null, "parameters": ["pytester"], "calls": ["pytester.makepyfile", "_pytest.timing.Instant", "pytester.runpytest_subprocess", "instant.elapsed"], "code_location": {"file": "test_pytester.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 449, "end_line": 459}, "code_snippet": "def test_pytester_run_with_timeout(pytester: Pytester) -> None:\n    testfile = pytester.makepyfile(\"def test_no_timeout(): pass\")\n\n    timeout = 120\n\n    instant = _pytest.timing.Instant()\n    result = pytester.runpytest_subprocess(testfile, timeout=timeout)\n    duration = instant.elapsed()\n\n    assert result.ret == ExitCode.OK\n    assert duration.seconds < timeout\n", "type": "function"}, {"name": "test_python_minus_m_invocation_fail", "is_method": true, "class_name": "TestInvocationVariants", "parameters": ["self", "pytester"], "calls": ["pytester.makepyfile", "pytester.run", "str"], "code_location": {"file": "acceptance_test.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 630, "end_line": 633}, "code_snippet": "    def test_python_minus_m_invocation_fail(self, pytester: Pytester) -> None:\n        p1 = pytester.makepyfile(\"def test_fail(): 0/0\")\n        res = pytester.run(sys.executable, \"-m\", \"pytest\", str(p1))\n        assert res.ret == 1\n", "type": "function"}, {"name": "test_pytest_exit_returncode", "is_method": false, "class_name": null, "parameters": ["pytester"], "calls": ["pytester.makepyfile", "pytester.runpytest", "result.stdout.fnmatch_lines", "pytester.makeconftest", "pytester.runpytest", "result.stdout.fnmatch_lines", "_strip_resource_warnings", "_strip_resource_warnings"], "code_location": {"file": "test_runner.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 651, "end_line": 679}, "code_snippet": "def test_pytest_exit_returncode(pytester: Pytester) -> None:\n    pytester.makepyfile(\n        \"\"\"\\\n        import pytest\n        def test_foo():\n            pytest.exit(\"some exit msg\", 99)\n    \"\"\"\n    )\n    result = pytester.runpytest()\n    result.stdout.fnmatch_lines([\"*! *Exit: some exit msg !*\"])\n\n    assert _strip_resource_warnings(result.stderr.lines) == []\n    assert result.ret == 99\n\n    # It prints to stderr also in case of exit during pytest_sessionstart.\n    pytester.makeconftest(\n        \"\"\"\\\n        import pytest\n\n        def pytest_sessionstart():\n            pytest.exit(\"during_sessionstart\", 98)\n        \"\"\"\n    )\n    result = pytester.runpytest()\n    result.stdout.fnmatch_lines([\"*! *Exit: during_sessionstart !*\"])\n    assert _strip_resource_warnings(result.stderr.lines) == [\n        \"Exit: during_sessionstart\"\n    ]\n    assert result.ret == 98\n", "type": "function"}, {"name": "test_run_result_repr", "is_method": false, "class_name": null, "parameters": [], "calls": ["pytester_mod.RunResult", "pytester_mod.RunResult", "repr", "repr"], "code_location": {"file": "test_pytester.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 721, "end_line": 737}, "code_snippet": "def test_run_result_repr() -> None:\n    outlines = [\"some\", \"normal\", \"output\"]\n    errlines = [\"some\", \"nasty\", \"errors\", \"happened\"]\n\n    # known exit code\n    r = pytester_mod.RunResult(1, outlines, errlines, duration=0.5)\n    assert repr(r) == (\n        f\"<RunResult ret={pytest.ExitCode.TESTS_FAILED!s} len(stdout.lines)=3\"\n        \" len(stderr.lines)=4 duration=0.50s>\"\n    )\n\n    # unknown exit code: just the number\n    r = pytester_mod.RunResult(99, outlines, errlines, duration=0.5)\n    assert (\n        repr(r) == \"<RunResult ret=99 len(stdout.lines)=3\"\n        \" len(stderr.lines)=4 duration=0.50s>\"\n    )\n", "type": "function"}], "retrieved_count": 10, "cost_time": 1.0501716136932373}
{"question": "What is the dependency chain between the TestRequestScopeAccess class, the pytest fixture system, the parametrization mechanism, the Pytester fixture, and the internal request attribute resolution logic that validates request object attributes are correctly scoped?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"name": "test_request_attributes", "is_method": true, "class_name": "TestRequestBasic", "parameters": ["self", "pytester"], "calls": ["pytester.getitem", "isinstance", "TopRequest", "hasattr", "find", "repr"], "code_location": {"file": "fixtures.py", "path": "/data3/pwh/swebench-repos/pytest/testing/python", "start_line": 680, "end_line": 698}, "code_snippet": "    def test_request_attributes(self, pytester: Pytester) -> None:\n        item = pytester.getitem(\n            \"\"\"\n            import pytest\n\n            @pytest.fixture\n            def something(request): pass\n            def test_func(something): pass\n        \"\"\"\n        )\n        assert isinstance(item, Function)\n        req = TopRequest(item, _ispytest=True)\n        assert req.function == item.obj\n        assert req.keywords == item.keywords\n        assert hasattr(req.module, \"test_func\")\n        assert req.cls is None\n        assert req.function.__name__ == \"test_func\"\n        assert req.config == item.config\n        assert repr(req).find(req.function.__name__) != -1\n", "type": "function"}, {"name": "test_request_attributes_method", "is_method": true, "class_name": "TestRequestBasic", "parameters": ["self", "pytester"], "calls": ["pytester.getitems", "isinstance"], "code_location": {"file": "fixtures.py", "path": "/data3/pwh/swebench-repos/pytest/testing/python", "start_line": 700, "end_line": 716}, "code_snippet": "    def test_request_attributes_method(self, pytester: Pytester) -> None:\n        (item,) = pytester.getitems(\n            \"\"\"\n            import pytest\n            class TestB(object):\n\n                @pytest.fixture\n                def something(self, request):\n                    return 1\n                def test_func(self, something):\n                    pass\n        \"\"\"\n        )\n        assert isinstance(item, Function)\n        req = item._request\n        assert req.cls.__name__ == \"TestB\"\n        assert req.instance.__class__ == req.cls\n", "type": "function"}, {"name": "test_request_is_clean", "is_method": true, "class_name": "TestFixtureMarker", "parameters": ["self", "pytester"], "calls": ["pytester.makepyfile", "pytester.inline_run", "reprec.getcalls"], "code_location": {"file": "fixtures.py", "path": "/data3/pwh/swebench-repos/pytest/testing/python", "start_line": 3153, "end_line": 3167}, "code_snippet": "    def test_request_is_clean(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n            values = []\n            @pytest.fixture(params=[1, 2])\n            def fix(request):\n                request.addfinalizer(lambda: values.append(request.param))\n            def test_fix(fix):\n                pass\n        \"\"\"\n        )\n        reprec = pytester.inline_run(\"-s\")\n        values = reprec.getcalls(\"pytest_runtest_call\")[0].item.module.values\n        assert values == [1, 2]\n", "type": "function"}, {"name": "test_setup", "is_method": true, "class_name": "TestRequestScopeAccess", "parameters": ["self", "pytester", "scope", "ok", "error"], "calls": ["pytester.makepyfile", "pytester.inline_run", "reprec.assertoutcome", "ok.split", "error.split"], "code_location": {"file": "fixtures.py", "path": "/data3/pwh/swebench-repos/pytest/testing/python", "start_line": 3441, "end_line": 3459}, "code_snippet": "    def test_setup(self, pytester: Pytester, scope, ok, error) -> None:\n        pytester.makepyfile(\n            f\"\"\"\n            import pytest\n            @pytest.fixture(scope={scope!r}, autouse=True)\n            def myscoped(request):\n                for x in {ok.split()}:\n                    assert hasattr(request, x)\n                for x in {error.split()}:\n                    pytest.raises(AttributeError, lambda:\n                        getattr(request, x))\n                assert request.session\n                assert request.config\n            def test_func():\n                pass\n        \"\"\"\n        )\n        reprec = pytester.inline_run(\"-l\")\n        reprec.assertoutcome(passed=1)\n", "type": "function"}, {"name": "test_parametrized_fixture_scope_allowed", "is_method": false, "class_name": null, "parameters": ["pytester"], "calls": ["pytester.makepyfile", "pytester.runpytest", "result.assert_outcomes"], "code_location": {"file": "fixtures.py", "path": "/data3/pwh/swebench-repos/pytest/testing/python", "start_line": 5026, "end_line": 5051}, "code_snippet": "def test_parametrized_fixture_scope_allowed(pytester: Pytester) -> None:\n    \"\"\"\n    Make sure scope from parametrize does not affect fixture's ability to be\n    depended upon.\n\n    Regression test for #13248\n    \"\"\"\n    pytester.makepyfile(\n        \"\"\"\n        import pytest\n\n        @pytest.fixture(scope=\"session\")\n        def my_fixture(request):\n            return getattr(request, \"param\", None)\n\n        @pytest.fixture(scope=\"session\")\n        def another_fixture(my_fixture):\n            return my_fixture\n\n        @pytest.mark.parametrize(\"my_fixture\", [\"a value\"], indirect=True, scope=\"function\")\n        def test_foo(another_fixture):\n            assert another_fixture == \"a value\"\n        \"\"\"\n    )\n    result = pytester.runpytest()\n    result.assert_outcomes(passed=1)\n", "type": "function"}, {"name": "test_funcarg", "is_method": true, "class_name": "TestRequestScopeAccess", "parameters": ["self", "pytester", "scope", "ok", "error"], "calls": ["pytester.makepyfile", "pytester.inline_run", "reprec.assertoutcome", "ok.split", "error.split"], "code_location": {"file": "fixtures.py", "path": "/data3/pwh/swebench-repos/pytest/testing/python", "start_line": 3461, "end_line": 3479}, "code_snippet": "    def test_funcarg(self, pytester: Pytester, scope, ok, error) -> None:\n        pytester.makepyfile(\n            f\"\"\"\n            import pytest\n            @pytest.fixture(scope={scope!r})\n            def arg(request):\n                for x in {ok.split()!r}:\n                    assert hasattr(request, x)\n                for x in {error.split()!r}:\n                    pytest.raises(AttributeError, lambda:\n                        getattr(request, x))\n                assert request.session\n                assert request.config\n            def test_func(arg):\n                pass\n        \"\"\"\n        )\n        reprec = pytester.inline_run()\n        reprec.assertoutcome(passed=1)\n", "type": "function"}, {"name": "test_request_fixturenames", "is_method": true, "class_name": "TestRequestBasic", "parameters": ["self", "pytester"], "calls": ["pytester.makepyfile", "pytester.inline_run", "reprec.assertoutcome"], "code_location": {"file": "fixtures.py", "path": "/data3/pwh/swebench-repos/pytest/testing/python", "start_line": 1011, "end_line": 1032}, "code_snippet": "    def test_request_fixturenames(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n            from _pytest.pytester import get_public_names\n            @pytest.fixture()\n            def arg1():\n                pass\n            @pytest.fixture()\n            def farg(arg1):\n                pass\n            @pytest.fixture(autouse=True)\n            def sarg(tmp_path):\n                pass\n            def test_function(request, farg):\n                assert set(get_public_names(request.fixturenames)) == \\\n                       set([\"sarg\", \"arg1\", \"request\", \"farg\",\n                            \"tmp_path\", \"tmp_path_factory\"])\n        \"\"\"\n        )\n        reprec = pytester.inline_run()\n        reprec.assertoutcome(passed=1)\n", "type": "function"}, {"name": "test_request_contains_funcarg_arg2fixturedefs", "is_method": true, "class_name": "TestRequestBasic", "parameters": ["self", "pytester"], "calls": ["pytester.getmodulecol", "pytester.genitems", "isinstance", "TopRequest", "len"], "code_location": {"file": "fixtures.py", "path": "/data3/pwh/swebench-repos/pytest/testing/python", "start_line": 718, "end_line": 735}, "code_snippet": "    def test_request_contains_funcarg_arg2fixturedefs(self, pytester: Pytester) -> None:\n        modcol = pytester.getmodulecol(\n            \"\"\"\n            import pytest\n            @pytest.fixture\n            def something(request):\n                pass\n            class TestClass(object):\n                def test_method(self, something):\n                    pass\n        \"\"\"\n        )\n        (item1,) = pytester.genitems([modcol])\n        assert isinstance(item1, Function)\n        assert item1.name == \"test_method\"\n        arg2fixturedefs = TopRequest(item1, _ispytest=True)._arg2fixturedefs\n        assert len(arg2fixturedefs) == 1\n        assert arg2fixturedefs[\"something\"][0].argname == \"something\"\n", "type": "function"}, {"name": "FixtureRequest", "docstring": "The type of the ``request`` fixture.\n\nA request object gives access to the requesting test context and has a\n``param`` attribute in case the fixture is parametrized.", "methods": ["__init__", "_fixturemanager", "_scope", "scope", "_check_scope", "fixturenames", "node", "config", "function", "cls", "instance", "module", "path", "keywords", "session", "addfinalizer", "applymarker", "raiseerror", "getfixturevalue", "_iter_chain", "_get_active_fixturedef", "_check_fixturedef_without_param", "_get_fixturestack"], "attributes": [], "code_location": {"file": "fixtures.py", "path": "/data3/pwh/swebench-repos/pytest/src/_pytest", "start_line": 372, "end_line": 681}, "type": "class"}, {"name": "test_parametrize_scope_overrides", "is_method": true, "class_name": "TestMetafuncFunctional", "parameters": ["self", "pytester", "scope", "length"], "calls": ["pytest.mark.parametrize", "pytester.makepyfile", "pytester.inline_run", "reprec.assertoutcome"], "code_location": {"file": "metafunc.py", "path": "/data3/pwh/swebench-repos/pytest/testing/python", "start_line": 1442, "end_line": 1466}, "code_snippet": "    def test_parametrize_scope_overrides(\n        self, pytester: Pytester, scope: str, length: int\n    ) -> None:\n        pytester.makepyfile(\n            f\"\"\"\n            import pytest\n            values = []\n            def pytest_generate_tests(metafunc):\n                if \"arg\" in metafunc.fixturenames:\n                    metafunc.parametrize(\"arg\", [1,2], indirect=True,\n                                         scope={scope!r})\n            @pytest.fixture\n            def arg(request):\n                values.append(request.param)\n                return request.param\n            def test_hello(arg):\n                assert arg in (1,2)\n            def test_world(arg):\n                assert arg in (1,2)\n            def test_checklength():\n                assert len(values) == {length}\n        \"\"\"\n        )\n        reprec = pytester.inline_run()\n        reprec.assertoutcome(passed=5)\n", "type": "function"}], "retrieved_count": 10, "cost_time": 1.058734655380249}
{"question": "How does the `from_item_and_call` classmethod implement conditional logic to determine the appropriate outcome and longrepr representation based on exception type and execution phase?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"name": "call_and_report", "is_method": false, "class_name": null, "parameters": ["item", "when", "log"], "calls": ["CallInfo.from_call", "ihook.pytest_runtest_makereport", "check_interactive_exception", "item.config.getoption", "ihook.pytest_runtest_logreport", "ihook.pytest_exception_interact", "runtest_hook"], "code_location": {"file": "runner.py", "path": "/data3/pwh/swebench-repos/pytest/src/_pytest", "start_line": 230, "end_line": 253}, "code_snippet": "def call_and_report(\n    item: Item, when: Literal[\"setup\", \"call\", \"teardown\"], log: bool = True, **kwds\n) -> TestReport:\n    ihook = item.ihook\n    if when == \"setup\":\n        runtest_hook: Callable[..., None] = ihook.pytest_runtest_setup\n    elif when == \"call\":\n        runtest_hook = ihook.pytest_runtest_call\n    elif when == \"teardown\":\n        runtest_hook = ihook.pytest_runtest_teardown\n    else:\n        assert False, f\"Unhandled runtest hook case: {when}\"\n    reraise: tuple[type[BaseException], ...] = (Exit,)\n    if not item.config.getoption(\"usepdb\", False):\n        reraise += (KeyboardInterrupt,)\n    call = CallInfo.from_call(\n        lambda: runtest_hook(item=item, **kwds), when=when, reraise=reraise\n    )\n    report: TestReport = ihook.pytest_runtest_makereport(item=item, call=call)\n    if log:\n        ihook.pytest_runtest_logreport(report=report)\n    if check_interactive_exception(call, report):\n        ihook.pytest_exception_interact(node=item, call=call, report=report)\n    return report\n", "type": "function"}, {"name": "pytest_runtest_makereport", "is_method": false, "class_name": null, "parameters": ["item", "call"], "calls": ["hookimpl", "item.stash.get", "isinstance", "isinstance", "isinstance", "isinstance", "raises.matches"], "code_location": {"file": "skipping.py", "path": "/data3/pwh/swebench-repos/pytest/src/_pytest", "start_line": 272, "end_line": 307}, "code_snippet": "def pytest_runtest_makereport(\n    item: Item, call: CallInfo[None]\n) -> Generator[None, TestReport, TestReport]:\n    rep = yield\n    xfailed = item.stash.get(xfailed_key, None)\n    if item.config.option.runxfail:\n        pass  # don't interfere\n    elif call.excinfo and isinstance(call.excinfo.value, xfail.Exception):\n        assert call.excinfo.value.msg is not None\n        rep.wasxfail = call.excinfo.value.msg\n        rep.outcome = \"skipped\"\n    elif not rep.skipped and xfailed:\n        if call.excinfo:\n            raises = xfailed.raises\n            if raises is None or (\n                (\n                    isinstance(raises, (type, tuple))\n                    and isinstance(call.excinfo.value, raises)\n                )\n                or (\n                    isinstance(raises, AbstractRaises)\n                    and raises.matches(call.excinfo.value)\n                )\n            ):\n                rep.outcome = \"skipped\"\n                rep.wasxfail = xfailed.reason\n            else:\n                rep.outcome = \"failed\"\n        elif call.when == \"call\":\n            if xfailed.strict:\n                rep.outcome = \"failed\"\n                rep.longrepr = \"[XPASS(strict)] \" + xfailed.reason\n            else:\n                rep.outcome = \"passed\"\n                rep.wasxfail = xfailed.reason\n    return rep\n", "type": "function"}, {"name": "from_item_and_call", "is_method": true, "class_name": "TestReport", "parameters": ["cls", "item", "call"], "calls": ["cls", "sections.append", "isinstance", "isinstance", "excinfo._getreprcrash", "item.repr_failure", "item._repr_failure_py", "item.reportinfo", "os.fspath", "str", "item.config.getoption"], "code_location": {"file": "reports.py", "path": "/data3/pwh/swebench-repos/pytest/src/_pytest", "start_line": 334, "end_line": 396}, "code_snippet": "    def from_item_and_call(cls, item: Item, call: CallInfo[None]) -> TestReport:\n        \"\"\"Create and fill a TestReport with standard item and call info.\n\n        :param item: The item.\n        :param call: The call info.\n        \"\"\"\n        when = call.when\n        # Remove \"collect\" from the Literal type -- only for collection calls.\n        assert when != \"collect\"\n        duration = call.duration\n        start = call.start\n        stop = call.stop\n        keywords = {x: 1 for x in item.keywords}\n        excinfo = call.excinfo\n        sections = []\n        if not call.excinfo:\n            outcome: Literal[\"passed\", \"failed\", \"skipped\"] = \"passed\"\n            longrepr: (\n                None\n                | ExceptionInfo[BaseException]\n                | tuple[str, int, str]\n                | str\n                | TerminalRepr\n            ) = None\n        else:\n            if not isinstance(excinfo, ExceptionInfo):\n                outcome = \"failed\"\n                longrepr = excinfo\n            elif isinstance(excinfo.value, skip.Exception):\n                outcome = \"skipped\"\n                r = excinfo._getreprcrash()\n                assert r is not None, (\n                    \"There should always be a traceback entry for skipping a test.\"\n                )\n                if excinfo.value._use_item_location:\n                    path, line = item.reportinfo()[:2]\n                    assert line is not None\n                    longrepr = os.fspath(path), line + 1, r.message\n                else:\n                    longrepr = (str(r.path), r.lineno, r.message)\n            else:\n                outcome = \"failed\"\n                if call.when == \"call\":\n                    longrepr = item.repr_failure(excinfo)\n                else:  # exception in setup or teardown\n                    longrepr = item._repr_failure_py(\n                        excinfo, style=item.config.getoption(\"tbstyle\", \"auto\")\n                    )\n        for rwhen, key, content in item._report_sections:\n            sections.append((f\"Captured {key} {rwhen}\", content))\n        return cls(\n            item.nodeid,\n            item.location,\n            keywords,\n            outcome,\n            longrepr,\n            when,\n            sections,\n            duration,\n            start,\n            stop,\n            user_properties=item.user_properties,\n        )\n", "type": "function"}, {"name": "pytest_runtest_call", "is_method": false, "class_name": null, "parameters": ["item"], "calls": ["_update_current_test_var", "item.runtest", "type"], "code_location": {"file": "runner.py", "path": "/data3/pwh/swebench-repos/pytest/src/_pytest", "start_line": 167, "end_line": 188}, "code_snippet": "def pytest_runtest_call(item: Item) -> None:\n    _update_current_test_var(item, \"call\")\n    try:\n        del sys.last_type\n        del sys.last_value\n        del sys.last_traceback\n        if sys.version_info >= (3, 12, 0):\n            del sys.last_exc  # type:ignore[attr-defined]\n    except AttributeError:\n        pass\n    try:\n        item.runtest()\n    except Exception as e:\n        # Store trace info to allow postmortem debugging\n        sys.last_type = type(e)\n        sys.last_value = e\n        if sys.version_info >= (3, 12, 0):\n            sys.last_exc = e  # type:ignore[attr-defined]\n        assert e.__traceback__ is not None\n        # Skip *this* frame\n        sys.last_traceback = e.__traceback__.tb_next\n        raise\n", "type": "function"}, {"name": "pytest_runtest_call", "is_method": true, "class_name": "CaptureManager", "parameters": ["self", "item"], "calls": ["hookimpl", "self.item_capture"], "code_location": {"file": "capture.py", "path": "/data3/pwh/swebench-repos/pytest/src/_pytest", "start_line": 898, "end_line": 900}, "code_snippet": "    def pytest_runtest_call(self, item: Item) -> Generator[None]:\n        with self.item_capture(\"call\", item):\n            return (yield)\n", "type": "function"}, {"name": "test_longrepr_type", "is_method": true, "class_name": "TestReportContents", "parameters": ["self", "pytester"], "calls": ["pytester.runitem", "isinstance"], "code_location": {"file": "test_runner.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 1175, "end_line": 1184}, "code_snippet": "    def test_longrepr_type(self, pytester: Pytester) -> None:\n        reports = pytester.runitem(\n            \"\"\"\n            import pytest\n            def test_func():\n                pytest.fail(pytrace=False)\n        \"\"\"\n        )\n        rep = reports[1]\n        assert isinstance(rep.longrepr, ExceptionChainRepr)\n", "type": "function"}, {"name": "pytest_runtest_makereport", "is_method": false, "class_name": null, "parameters": ["item", "call"], "calls": ["hookimpl", "isinstance", "item._excinfo.pop"], "code_location": {"file": "unittest.py", "path": "/data3/pwh/swebench-repos/pytest/src/_pytest", "start_line": 368, "end_line": 375}, "code_snippet": "def pytest_runtest_makereport(item: Item, call: CallInfo[None]) -> None:\n    if isinstance(item, TestCaseFunction):\n        if item._excinfo:\n            call.excinfo = item._excinfo.pop(0)\n            try:\n                del call.result\n            except AttributeError:\n                pass\n", "type": "function"}, {"name": "pytest_runtest_call", "is_method": false, "class_name": null, "parameters": ["item"], "calls": ["hookimpl", "item.stash.get", "evaluate_xfail_marks", "xfail", "item.stash.get", "evaluate_xfail_marks"], "code_location": {"file": "skipping.py", "path": "/data3/pwh/swebench-repos/pytest/src/_pytest", "start_line": 254, "end_line": 268}, "code_snippet": "def pytest_runtest_call(item: Item) -> Generator[None]:\n    xfailed = item.stash.get(xfailed_key, None)\n    if xfailed is None:\n        item.stash[xfailed_key] = xfailed = evaluate_xfail_marks(item)\n\n    if xfailed and not item.config.option.runxfail and not xfailed.run:\n        xfail(\"[NOTRUN] \" + xfailed.reason)\n\n    try:\n        return (yield)\n    finally:\n        # The test run may have added an xfail mark dynamically.\n        xfailed = item.stash.get(xfailed_key, None)\n        if xfailed is None:\n            item.stash[xfailed_key] = xfailed = evaluate_xfail_marks(item)\n", "type": "function"}, {"name": "pytest_runtest_call", "is_method": true, "class_name": "LoggingPlugin", "parameters": ["self", "item"], "calls": ["hookimpl", "self.log_cli_handler.set_when", "self._runtest_for"], "code_location": {"file": "logging.py", "path": "/data3/pwh/swebench-repos/pytest/src/_pytest", "start_line": 846, "end_line": 850}, "code_snippet": "    def pytest_runtest_call(self, item: nodes.Item) -> Generator[None]:\n        self.log_cli_handler.set_when(\"call\")\n\n        with self._runtest_for(item, \"call\"):\n            yield\n", "type": "function"}, {"name": "pytest_runtest_makereport", "is_method": false, "class_name": null, "parameters": ["item", "call"], "calls": ["TestReport.from_item_and_call"], "code_location": {"file": "runner.py", "path": "/data3/pwh/swebench-repos/pytest/src/_pytest", "start_line": 367, "end_line": 368}, "code_snippet": "def pytest_runtest_makereport(item: Item, call: CallInfo[None]) -> TestReport:\n    return TestReport.from_item_and_call(item, call)\n", "type": "function"}], "retrieved_count": 10, "cost_time": 1.070930004119873}
{"question": "What is the architectural separation in the pytest fixture resolution system that decouples fixture discovery and validation to enable the error reporting mechanism that distinguishes between missing fixtures and internal failures?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"name": "test_funcarg_lookup_error", "is_method": true, "class_name": "TestFillFixtures", "parameters": ["self", "pytester"], "calls": ["pytester.makeconftest", "pytester.makepyfile", "pytester.runpytest", "result.stdout.fnmatch_lines", "result.stdout.no_fnmatch_line"], "code_location": {"file": "fixtures.py", "path": "/data3/pwh/swebench-repos/pytest/testing/python", "start_line": 616, "end_line": 652}, "code_snippet": "    def test_funcarg_lookup_error(self, pytester: Pytester) -> None:\n        pytester.makeconftest(\n            \"\"\"\n            import pytest\n\n            @pytest.fixture\n            def a_fixture(): pass\n\n            @pytest.fixture\n            def b_fixture(): pass\n\n            @pytest.fixture\n            def c_fixture(): pass\n\n            @pytest.fixture\n            def d_fixture(): pass\n        \"\"\"\n        )\n        pytester.makepyfile(\n            \"\"\"\n            def test_lookup_error(unknown):\n                pass\n        \"\"\"\n        )\n        result = pytester.runpytest()\n        result.stdout.fnmatch_lines(\n            [\n                \"*ERROR at setup of test_lookup_error*\",\n                \"  def test_lookup_error(unknown):*\",\n                \"E       fixture 'unknown' not found\",\n                \">       available fixtures:*a_fixture,*b_fixture,*c_fixture,*d_fixture*monkeypatch,*\",\n                # sorted\n                \">       use 'py*test --fixtures *' for help on them.\",\n                \"*1 error*\",\n            ]\n        )\n        result.stdout.no_fnmatch_line(\"*INTERNAL*\")\n", "type": "function"}, {"name": "test_factory_uses_unknown_funcarg_as_dependency_error", "is_method": true, "class_name": "TestFixtureUsages", "parameters": ["self", "pytester"], "calls": ["pytester.makepyfile", "pytester.runpytest", "result.stdout.fnmatch_lines"], "code_location": {"file": "fixtures.py", "path": "/data3/pwh/swebench-repos/pytest/testing/python", "start_line": 1384, "end_line": 1412}, "code_snippet": "    def test_factory_uses_unknown_funcarg_as_dependency_error(\n        self, pytester: Pytester\n    ) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n\n            @pytest.fixture()\n            def fail(missing):\n                return\n\n            @pytest.fixture()\n            def call_fail(fail):\n                return\n\n            def test_missing(call_fail):\n                pass\n            \"\"\"\n        )\n        result = pytester.runpytest()\n        result.stdout.fnmatch_lines(\n            \"\"\"\n            *pytest.fixture()*\n            *def call_fail(fail)*\n            *pytest.fixture()*\n            *def fail*\n            *fixture*'missing'*not found*\n        \"\"\"\n        )\n", "type": "function"}, {"name": "FixtureManager", "docstring": "pytest fixture definitions and information is stored and managed\nfrom this class.\n\nDuring collection fm.parsefactories() is called multiple times to parse\nfixture function definitions into FixtureDef objects and internal\ndata structures.\n\nDuring collection of test functions, metafunc-mechanics instantiate\na FuncFixtureInfo object which is cached per node/func-name.\nThis FuncFixtureInfo object is later retrieved by Function nodes\nwhich themselves offer a fixturenames attribute.\n\nThe FuncFixtureInfo object holds information about fixtures and FixtureDefs\nrelevant for a particular function. An initial list of fixtures is\nassembled like this:\n\n- ini-defined usefixtures\n- autouse-marked fixtures along the collection chain up from the function\n- usefixtures markers at module/class/function level\n- test function funcargs\n\nSubsequently the funcfixtureinfo.fixturenames attribute is computed\nas the closure of the fixtures needed to setup the initial fixtures,\ni.e. fixtures needed by fixture functions themselves are appended\nto the fixturenames list.\n\nUpon the test-setup phases all fixturenames are instantiated, retrieved\nby a lookup of their FuncFixtureInfo.", "methods": ["__init__", "getfixtureinfo", "pytest_plugin_registered", "_getautousenames", "_getusefixturesnames", "getfixtureclosure", "pytest_generate_tests", "pytest_collection_modifyitems", "_register_fixture", "parsefactories", "parsefactories", "parsefactories", "getfixturedefs", "_matchfactories"], "attributes": [], "code_location": {"file": "fixtures.py", "path": "/data3/pwh/swebench-repos/pytest/src/_pytest", "start_line": 1501, "end_line": 1879}, "type": "class"}, {"name": "test_fixture_dependency", "is_method": false, "class_name": null, "parameters": ["pytester"], "calls": ["pytester.makeconftest", "touch", "pytester.mkdir", "touch", "write_text", "sub.joinpath", "subsub.mkdir", "touch", "write_text", "pytester.runpytest", "result.stdout.fnmatch_lines", "textwrap.dedent", "textwrap.dedent", "pytester.path.joinpath", "sub.joinpath", "sub.joinpath", "subsub.joinpath", "subsub.joinpath"], "code_location": {"file": "test_conftest.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 466, "end_line": 510}, "code_snippet": "def test_fixture_dependency(pytester: Pytester) -> None:\n    pytester.makeconftest(\"\")\n    pytester.path.joinpath(\"__init__.py\").touch()\n    sub = pytester.mkdir(\"sub\")\n    sub.joinpath(\"__init__.py\").touch()\n    sub.joinpath(\"conftest.py\").write_text(\n        textwrap.dedent(\n            \"\"\"\\\n            import pytest\n\n            @pytest.fixture\n            def not_needed():\n                assert False, \"Should not be called!\"\n\n            @pytest.fixture\n            def foo():\n                assert False, \"Should not be called!\"\n\n            @pytest.fixture\n            def bar(foo):\n                return 'bar'\n            \"\"\"\n        ),\n        encoding=\"utf-8\",\n    )\n    subsub = sub.joinpath(\"subsub\")\n    subsub.mkdir()\n    subsub.joinpath(\"__init__.py\").touch()\n    subsub.joinpath(\"test_bar.py\").write_text(\n        textwrap.dedent(\n            \"\"\"\\\n            import pytest\n\n            @pytest.fixture\n            def bar():\n                return 'sub bar'\n\n            def test_event_fixture(bar):\n                assert bar == 'sub bar'\n            \"\"\"\n        ),\n        encoding=\"utf-8\",\n    )\n    result = pytester.runpytest(\"sub\")\n    result.stdout.fnmatch_lines([\"*1 passed*\"])\n", "type": "function"}, {"name": "test_conftest_symlink", "is_method": false, "class_name": null, "parameters": ["pytester"], "calls": ["pytester.mkdir", "real.joinpath", "realtests.mkdir", "symlink_or_skip", "symlink_or_skip", "pytester.makepyfile", "pytester.runpytest", "result.stdout.fnmatch_lines", "pytester.runpytest", "pytester.path.joinpath", "pytester.path.joinpath", "textwrap.dedent"], "code_location": {"file": "test_conftest.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 315, "end_line": 357}, "code_snippet": "def test_conftest_symlink(pytester: Pytester) -> None:\n    \"\"\"`conftest.py` discovery follows normal path resolution and does not resolve symlinks.\"\"\"\n    # Structure:\n    # /real\n    # /real/conftest.py\n    # /real/app\n    # /real/app/tests\n    # /real/app/tests/test_foo.py\n\n    # Links:\n    # /symlinktests -> /real/app/tests (running at symlinktests should fail)\n    # /symlink -> /real (running at /symlink should work)\n\n    real = pytester.mkdir(\"real\")\n    realtests = real.joinpath(\"app/tests\")\n    realtests.mkdir(parents=True)\n    symlink_or_skip(realtests, pytester.path.joinpath(\"symlinktests\"))\n    symlink_or_skip(real, pytester.path.joinpath(\"symlink\"))\n    pytester.makepyfile(\n        **{\n            \"real/app/tests/test_foo.py\": \"def test1(fixture): pass\",\n            \"real/conftest.py\": textwrap.dedent(\n                \"\"\"\n                import pytest\n\n                print(\"conftest_loaded\")\n\n                @pytest.fixture\n                def fixture():\n                    print(\"fixture_used\")\n                \"\"\"\n            ),\n        }\n    )\n\n    # Should fail because conftest cannot be found from the link structure.\n    result = pytester.runpytest(\"-vs\", \"symlinktests\")\n    result.stdout.fnmatch_lines([\"*fixture 'fixture' not found*\"])\n    assert result.ret == ExitCode.TESTS_FAILED\n\n    # Should not cause \"ValueError: Plugin already registered\" (#4174).\n    result = pytester.runpytest(\"-vs\", \"symlink\")\n    assert result.ret == ExitCode.OK\n", "type": "function"}, {"name": "error_pytester", "is_method": false, "class_name": null, "parameters": ["pytester"], "calls": ["pytester.makepyfile"], "code_location": {"file": "test_stepwise.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 67, "end_line": 78}, "code_snippet": "def error_pytester(pytester: Pytester) -> Pytester:\n    pytester.makepyfile(\n        test_a=\"\"\"\ndef test_error(nonexisting_fixture):\n    assert 1\n\ndef test_success_after_fail():\n    assert 1\n\"\"\"\n    )\n\n    return pytester\n", "type": "function"}, {"name": "_get_active_fixturedef", "is_method": true, "class_name": "FixtureRequest", "parameters": ["self", "argname"], "calls": ["self._fixture_defs.get", "self._arg2fixturedefs.get", "self._iter_chain", "self._check_scope", "SubRequest", "fixturedef.execute", "PseudoFixtureDef", "self._check_scope", "self._fixturemanager.getfixturedefs", "FixtureLookupError", "FixtureLookupError", "len", "FixtureLookupError", "self._check_fixturedef_without_param"], "code_location": {"file": "fixtures.py", "path": "/data3/pwh/swebench-repos/pytest/src/_pytest", "start_line": 566, "end_line": 643}, "code_snippet": "    def _get_active_fixturedef(\n        self, argname: str\n    ) -> FixtureDef[object] | PseudoFixtureDef[object]:\n        if argname == \"request\":\n            cached_result = (self, [0], None)\n            return PseudoFixtureDef(cached_result, Scope.Function)\n\n        # If we already finished computing a fixture by this name in this item,\n        # return it.\n        fixturedef = self._fixture_defs.get(argname)\n        if fixturedef is not None:\n            self._check_scope(fixturedef, fixturedef._scope)\n            return fixturedef\n\n        # Find the appropriate fixturedef.\n        fixturedefs = self._arg2fixturedefs.get(argname, None)\n        if fixturedefs is None:\n            # We arrive here because of a dynamic call to\n            # getfixturevalue(argname) which was naturally\n            # not known at parsing/collection time.\n            fixturedefs = self._fixturemanager.getfixturedefs(argname, self._pyfuncitem)\n            if fixturedefs is not None:\n                self._arg2fixturedefs[argname] = fixturedefs\n        # No fixtures defined with this name.\n        if fixturedefs is None:\n            raise FixtureLookupError(argname, self)\n        # The are no fixtures with this name applicable for the function.\n        if not fixturedefs:\n            raise FixtureLookupError(argname, self)\n\n        # A fixture may override another fixture with the same name, e.g. a\n        # fixture in a module can override a fixture in a conftest, a fixture in\n        # a class can override a fixture in the module, and so on.\n        # An overriding fixture can request its own name (possibly indirectly);\n        # in this case it gets the value of the fixture it overrides, one level\n        # up.\n        # Check how many `argname`s deep we are, and take the next one.\n        # `fixturedefs` is sorted from furthest to closest, so use negative\n        # indexing to go in reverse.\n        index = -1\n        for request in self._iter_chain():\n            if request.fixturename == argname:\n                index -= 1\n        # If already consumed all of the available levels, fail.\n        if -index > len(fixturedefs):\n            raise FixtureLookupError(argname, self)\n        fixturedef = fixturedefs[index]\n\n        # Prepare a SubRequest object for calling the fixture.\n        try:\n            callspec = self._pyfuncitem.callspec\n        except AttributeError:\n            callspec = None\n        if callspec is not None and argname in callspec.params:\n            param = callspec.params[argname]\n            param_index = callspec.indices[argname]\n            # The parametrize invocation scope overrides the fixture's scope.\n            scope = callspec._arg2scope[argname]\n        else:\n            param = NOTSET\n            param_index = 0\n            scope = fixturedef._scope\n            self._check_fixturedef_without_param(fixturedef)\n        # The parametrize invocation scope only controls caching behavior while\n        # allowing wider-scoped fixtures to keep depending on the parametrized\n        # fixture. Scope control is enforced for parametrized fixtures\n        # by recreating the whole fixture tree on parameter change.\n        # Hence `fixturedef._scope`, not `scope`.\n        self._check_scope(fixturedef, fixturedef._scope)\n        subrequest = SubRequest(\n            self, scope, param, param_index, fixturedef, _ispytest=True\n        )\n\n        # Make sure the fixture value is cached, running it if it isn't\n        fixturedef.execute(request=subrequest)\n\n        self._fixture_defs[argname] = fixturedef\n        return fixturedef\n", "type": "function"}, {"name": "test_parsefactories_conftest_and_module_and_class", "is_method": true, "class_name": "TestFixtureManagerParseFactories", "parameters": ["self", "pytester"], "calls": ["pytester.makepyfile", "pytester.inline_run", "reprec.assertoutcome"], "code_location": {"file": "fixtures.py", "path": "/data3/pwh/swebench-repos/pytest/testing/python", "start_line": 1735, "end_line": 1760}, "code_snippet": "    def test_parsefactories_conftest_and_module_and_class(\n        self, pytester: Pytester\n    ) -> None:\n        pytester.makepyfile(\n            \"\"\"\\\n            import pytest\n\n            @pytest.fixture\n            def hello(request):\n                return \"module\"\n            class TestClass(object):\n                @pytest.fixture\n                def hello(self, request):\n                    return \"class\"\n                def test_hello(self, item, fm):\n                    faclist = fm.getfixturedefs(\"hello\", item)\n                    print(faclist)\n                    assert len(faclist) == 3\n\n                    assert faclist[0].func(item._request) == \"conftest\"\n                    assert faclist[1].func(item._request) == \"module\"\n                    assert faclist[2].func(item._request) == \"class\"\n            \"\"\"\n        )\n        reprec = pytester.inline_run(\"-s\")\n        reprec.assertoutcome(passed=1)\n", "type": "function"}, {"name": "_check_scope", "is_method": true, "class_name": "SubRequest", "parameters": ["self", "requested_fixturedef", "requested_scope"], "calls": ["isinstance", "join", "self._format_fixturedef_line", "fail", "self._format_fixturedef_line", "self._get_fixturestack"], "code_location": {"file": "fixtures.py", "path": "/data3/pwh/swebench-repos/pytest/src/_pytest", "start_line": 780, "end_line": 801}, "code_snippet": "    def _check_scope(\n        self,\n        requested_fixturedef: FixtureDef[object] | PseudoFixtureDef[object],\n        requested_scope: Scope,\n    ) -> None:\n        if isinstance(requested_fixturedef, PseudoFixtureDef):\n            return\n        if self._scope > requested_scope:\n            # Try to report something helpful.\n            argname = requested_fixturedef.argname\n            fixture_stack = \"\\n\".join(\n                self._format_fixturedef_line(fixturedef)\n                for fixturedef in self._get_fixturestack()\n            )\n            requested_fixture = self._format_fixturedef_line(requested_fixturedef)\n            fail(\n                f\"ScopeMismatch: You tried to access the {requested_scope.value} scoped \"\n                f\"fixture {argname} with a {self._scope.value} scoped request object. \"\n                f\"Requesting fixture stack:\\n{fixture_stack}\\n\"\n                f\"Requested fixture:\\n{requested_fixture}\",\n                pytrace=False,\n            )\n", "type": "function"}, {"name": "test_funcarg_lookupfails", "is_method": true, "class_name": "TestFillFixtures", "parameters": ["self", "pytester"], "calls": ["pytester.copy_example", "pytester.runpytest", "result.stdout.fnmatch_lines"], "code_location": {"file": "fixtures.py", "path": "/data3/pwh/swebench-repos/pytest/testing/python", "start_line": 135, "end_line": 145}, "code_snippet": "    def test_funcarg_lookupfails(self, pytester: Pytester) -> None:\n        pytester.copy_example()\n        result = pytester.runpytest()  # \"--collect-only\")\n        assert result.ret != 0\n        result.stdout.fnmatch_lines(\n            \"\"\"\n            *def test_func(some)*\n            *fixture*some*not found*\n            *xyzsomething*\n            \"\"\"\n        )\n", "type": "function"}], "retrieved_count": 10, "cost_time": 1.0781793594360352}
{"question": "What is the impact of the tmpdir fixture's conversion from Path to LEGACY_PATH through legacy_path() on the fixture's dependency chain, and what would be the cascading impact on test isolation if the conversion were to fail silently?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"name": "test_tmpdir_equals_tmp_path", "is_method": false, "class_name": null, "parameters": ["tmpdir", "tmp_path"], "calls": ["Path"], "code_location": {"file": "test_legacypath.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 68, "end_line": 69}, "code_snippet": "def test_tmpdir_equals_tmp_path(tmpdir: LEGACY_PATH, tmp_path: Path) -> None:\n    assert Path(tmpdir) == tmp_path\n", "type": "function"}, {"name": "tmpdir", "is_method": true, "class_name": "LegacyTmpdirPlugin", "parameters": ["tmp_path"], "calls": ["legacy_path"], "code_location": {"file": "legacypath.py", "path": "/data3/pwh/swebench-repos/pytest/src/_pytest", "start_line": 306, "end_line": 320}, "code_snippet": "    def tmpdir(tmp_path: Path) -> LEGACY_PATH:\n        \"\"\"Return a temporary directory (as `legacy_path`_ object)\n        which is unique to each test function invocation.\n        The temporary directory is created as a subdirectory\n        of the base temporary directory, with configurable retention,\n        as discussed in :ref:`temporary directory location and retention`.\n\n        .. note::\n            These days, it is preferred to use ``tmp_path``.\n\n            :ref:`About the tmpdir and tmpdir_factory fixtures<tmpdir and tmpdir_factory>`.\n\n        .. _legacy_path: https://py.readthedocs.io/en/latest/path.html\n        \"\"\"\n        return legacy_path(tmp_path)\n", "type": "function"}, {"name": "test_tmproot", "is_method": true, "class_name": "Testdir", "parameters": ["self"], "calls": ["legacy_path"], "code_location": {"file": "legacypath.py", "path": "/data3/pwh/swebench-repos/pytest/src/_pytest", "start_line": 65, "end_line": 66}, "code_snippet": "    def test_tmproot(self) -> LEGACY_PATH:\n        return legacy_path(self._pytester._test_tmproot)\n", "type": "function"}, {"name": "Testdir", "docstring": "Similar to :class:`Pytester`, but this class works with legacy legacy_path objects instead.\n\nAll methods just forward to an internal :class:`Pytester` instance, converting results\nto `legacy_path` objects as necessary.", "methods": ["__init__", "tmpdir", "test_tmproot", "request", "plugins", "plugins", "monkeypatch", "make_hook_recorder", "chdir", "finalize", "makefile", "makeconftest", "makeini", "getinicfg", "makepyprojecttoml", "makepyfile", "maketxtfile", "syspathinsert", "mkdir", "mkpydir", "copy_example", "getnode", "getpathnode", "genitems", "runitem", "inline_runsource", "inline_genitems", "inline_run", "runpytest_inprocess", "runpytest", "parseconfig", "parseconfigure", "getitem", "getitems", "getmodulecol", "collect_by_name", "popen", "run", "runpython", "runpython_c", "runpytest_subprocess", "spawn_pytest", "spawn", "__repr__", "__str__"], "attributes": ["__test__"], "code_location": {"file": "legacypath.py", "path": "/data3/pwh/swebench-repos/pytest/src/_pytest", "start_line": 42, "end_line": 250}, "type": "class"}, {"name": "__init__", "is_method": true, "class_name": "TempdirFactory", "parameters": ["self", "tmppath_factory"], "calls": ["check_ispytest"], "code_location": {"file": "legacypath.py", "path": "/data3/pwh/swebench-repos/pytest/src/_pytest", "start_line": 281, "end_line": 285}, "code_snippet": "    def __init__(\n        self, tmppath_factory: TempPathFactory, *, _ispytest: bool = False\n    ) -> None:\n        check_ispytest(_ispytest)\n        self._tmppath_factory = tmppath_factory\n", "type": "function"}, {"name": "test_hookproxy_warnings_for_pathlib", "is_method": false, "class_name": null, "parameters": ["tmp_path", "hooktype", "request"], "calls": ["pytest.mark.parametrize", "legacy_path", "hooks.pytest_ignore_collect", "pytest.warns", "hooks.pytest_ignore_collect", "pytest.raises", "sys._getframe", "sys._getframe", "pytest.warns", "hooks.pytest_ignore_collect", "Path"], "code_location": {"file": "deprecated_test.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 96, "end_line": 123}, "code_snippet": "def test_hookproxy_warnings_for_pathlib(tmp_path, hooktype, request):\n    path = legacy_path(tmp_path)\n\n    PATH_WARN_MATCH = r\".*path: py\\.path\\.local\\) argument is deprecated, please use \\(collection_path: pathlib\\.Path.*\"\n    if hooktype == \"ihook\":\n        hooks = request.node.ihook\n    else:\n        hooks = request.config.hook\n\n    with pytest.warns(PytestDeprecationWarning, match=PATH_WARN_MATCH) as r:\n        l1 = sys._getframe().f_lineno\n        hooks.pytest_ignore_collect(\n            config=request.config, path=path, collection_path=tmp_path\n        )\n        l2 = sys._getframe().f_lineno\n\n    (record,) = r\n    assert record.filename == __file__\n    assert l1 < record.lineno < l2\n\n    hooks.pytest_ignore_collect(config=request.config, collection_path=tmp_path)\n\n    # Passing entirely *different* paths is an outright error.\n    with pytest.raises(ValueError, match=r\"path.*fspath.*need to be equal\"):\n        with pytest.warns(PytestDeprecationWarning, match=PATH_WARN_MATCH) as r:\n            hooks.pytest_ignore_collect(\n                config=request.config, path=path, collection_path=Path(\"/bla/bla\")\n            )\n", "type": "function"}, {"name": "test_tmp_path_fixture", "is_method": false, "class_name": null, "parameters": ["pytester"], "calls": ["pytester.copy_example", "pytester.runpytest", "results.stdout.fnmatch_lines"], "code_location": {"file": "test_tmpdir.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 29, "end_line": 32}, "code_snippet": "def test_tmp_path_fixture(pytester: Pytester) -> None:\n    p = pytester.copy_example(\"tmpdir/tmp_path_fixture.py\")\n    results = pytester.runpytest(p)\n    results.stdout.fnmatch_lines([\"*1 passed*\"])\n", "type": "function"}, {"name": "pytest_configure", "is_method": false, "class_name": null, "parameters": ["config"], "calls": ["config.pluginmanager.has_plugin", "MonkeyPatch", "config.add_cleanup", "config.pluginmanager.register", "TempdirFactory", "mp.setattr"], "code_location": {"file": "legacypath.py", "path": "/data3/pwh/swebench-repos/pytest/src/_pytest", "start_line": 440, "end_line": 459}, "code_snippet": "def pytest_configure(config: Config) -> None:\n    \"\"\"Installs the LegacyTmpdirPlugin if the ``tmpdir`` plugin is also installed.\"\"\"\n    if config.pluginmanager.has_plugin(\"tmpdir\"):\n        mp = MonkeyPatch()\n        config.add_cleanup(mp.undo)\n        # Create TmpdirFactory and attach it to the config object.\n        #\n        # This is to comply with existing plugins which expect the handler to be\n        # available at pytest_configure time, but ideally should be moved entirely\n        # to the tmpdir_factory session fixture.\n        try:\n            tmp_path_factory = config._tmp_path_factory  # type: ignore[attr-defined]\n        except AttributeError:\n            # tmpdir plugin is blocked.\n            pass\n        else:\n            _tmpdirhandler = TempdirFactory(tmp_path_factory, _ispytest=True)\n            mp.setattr(config, \"_tmpdirhandler\", _tmpdirhandler, raising=False)\n\n        config.pluginmanager.register(LegacyTmpdirPlugin, \"legacypath-tmpdir\")\n", "type": "function"}, {"name": "test_tmpdir_factory", "is_method": false, "class_name": null, "parameters": ["tmpdir_factory", "tmp_path_factory"], "calls": ["tmpdir_factory.mktemp", "dir.exists", "str", "str", "tmpdir_factory.getbasetemp", "tmp_path_factory.getbasetemp"], "code_location": {"file": "test_legacypath.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 59, "end_line": 65}, "code_snippet": "def test_tmpdir_factory(\n    tmpdir_factory: TempdirFactory,\n    tmp_path_factory: pytest.TempPathFactory,\n) -> None:\n    assert str(tmpdir_factory.getbasetemp()) == str(tmp_path_factory.getbasetemp())\n    dir = tmpdir_factory.mktemp(\"foo\")\n    assert dir.exists()\n", "type": "function"}, {"name": "TempdirFactory", "docstring": "Backward compatibility wrapper that implements ``py.path.local``\nfor :class:`TempPathFactory`.\n\n.. note::\n    These days, it is preferred to use ``tmp_path_factory``.\n\n    :ref:`About the tmpdir and tmpdir_factory fixtures<tmpdir and tmpdir_factory>`.", "methods": ["__init__", "mktemp", "getbasetemp"], "attributes": [], "code_location": {"file": "legacypath.py", "path": "/data3/pwh/swebench-repos/pytest/src/_pytest", "start_line": 268, "end_line": 293}, "type": "class"}], "retrieved_count": 10, "cost_time": 1.0702431201934814}
{"question": "What is the validation logic in the FixtureFunctionMarker.__call__ method that prevents double-decoration of fixture functions, and what is the semantic difference between detecting a FixtureFunctionDefinition instance versus checking for pytestmark attributes?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"name": "__call__", "is_method": true, "class_name": "FixtureFunctionMarker", "parameters": ["self", "function"], "calls": ["inspect.isclass", "isinstance", "hasattr", "FixtureFunctionDefinition", "ValueError", "ValueError", "warnings.warn", "getlocation", "fail"], "code_location": {"file": "fixtures.py", "path": "/data3/pwh/swebench-repos/pytest/src/_pytest", "start_line": 1224, "end_line": 1248}, "code_snippet": "    def __call__(self, function: FixtureFunction) -> FixtureFunctionDefinition:\n        if inspect.isclass(function):\n            raise ValueError(\"class fixtures not supported (maybe in the future)\")\n\n        if isinstance(function, FixtureFunctionDefinition):\n            raise ValueError(\n                f\"@pytest.fixture is being applied more than once to the same function {function.__name__!r}\"\n            )\n\n        if hasattr(function, \"pytestmark\"):\n            warnings.warn(MARKED_FIXTURE, stacklevel=2)\n\n        fixture_definition = FixtureFunctionDefinition(\n            function=function, fixture_function_marker=self, _ispytest=True\n        )\n\n        name = self.name or function.__name__\n        if name == \"request\":\n            location = getlocation(function)\n            fail(\n                f\"'request' is a reserved word for fixtures, use another name:\\n  {location}\",\n                pytrace=False,\n            )\n\n        return fixture_definition\n", "type": "function"}, {"name": "__init__", "is_method": true, "class_name": "FixtureFunctionDefinition", "parameters": ["self"], "calls": ["check_ispytest", "functools.update_wrapper", "cast", "function.__get__"], "code_location": {"file": "fixtures.py", "path": "/data3/pwh/swebench-repos/pytest/src/_pytest", "start_line": 1253, "end_line": 1273}, "code_snippet": "    def __init__(\n        self,\n        *,\n        function: Callable[..., Any],\n        fixture_function_marker: FixtureFunctionMarker,\n        instance: object | None = None,\n        _ispytest: bool = False,\n    ) -> None:\n        check_ispytest(_ispytest)\n        self.name = fixture_function_marker.name or function.__name__\n        # In order to show the function that this fixture contains in messages.\n        # Set the __name__ to be same as the function __name__ or the given fixture name.\n        self.__name__ = self.name\n        self._fixture_function_marker = fixture_function_marker\n        if instance is not None:\n            self._fixture_function = cast(\n                Callable[..., Any], function.__get__(instance)\n            )\n        else:\n            self._fixture_function = function\n        functools.update_wrapper(self, function)\n", "type": "function"}, {"name": "fixture", "is_method": false, "class_name": null, "parameters": ["fixture_function"], "calls": ["FixtureFunctionMarker", "fixture_marker", "tuple", "callable", "tuple"], "code_location": {"file": "fixtures.py", "path": "/data3/pwh/swebench-repos/pytest/src/_pytest", "start_line": 1324, "end_line": 1396}, "code_snippet": "def fixture(\n    fixture_function: FixtureFunction | None = None,\n    *,\n    scope: _ScopeName | Callable[[str, Config], _ScopeName] = \"function\",\n    params: Iterable[object] | None = None,\n    autouse: bool = False,\n    ids: Sequence[object | None] | Callable[[Any], object | None] | None = None,\n    name: str | None = None,\n) -> FixtureFunctionMarker | FixtureFunctionDefinition:\n    \"\"\"Decorator to mark a fixture factory function.\n\n    This decorator can be used, with or without parameters, to define a\n    fixture function.\n\n    The name of the fixture function can later be referenced to cause its\n    invocation ahead of running tests: test modules or classes can use the\n    ``pytest.mark.usefixtures(fixturename)`` marker.\n\n    Test functions can directly use fixture names as input arguments in which\n    case the fixture instance returned from the fixture function will be\n    injected.\n\n    Fixtures can provide their values to test functions using ``return`` or\n    ``yield`` statements. When using ``yield`` the code block after the\n    ``yield`` statement is executed as teardown code regardless of the test\n    outcome, and must yield exactly once.\n\n    :param scope:\n        The scope for which this fixture is shared; one of ``\"function\"``\n        (default), ``\"class\"``, ``\"module\"``, ``\"package\"`` or ``\"session\"``.\n\n        This parameter may also be a callable which receives ``(fixture_name, config)``\n        as parameters, and must return a ``str`` with one of the values mentioned above.\n\n        See :ref:`dynamic scope` in the docs for more information.\n\n    :param params:\n        An optional list of parameters which will cause multiple invocations\n        of the fixture function and all of the tests using it. The current\n        parameter is available in ``request.param``.\n\n    :param autouse:\n        If True, the fixture func is activated for all tests that can see it.\n        If False (the default), an explicit reference is needed to activate\n        the fixture.\n\n    :param ids:\n        Sequence of ids each corresponding to the params so that they are\n        part of the test id. If no ids are provided they will be generated\n        automatically from the params.\n\n    :param name:\n        The name of the fixture. This defaults to the name of the decorated\n        function. If a fixture is used in the same module in which it is\n        defined, the function name of the fixture will be shadowed by the\n        function arg that requests the fixture; one way to resolve this is to\n        name the decorated function ``fixture_<fixturename>`` and then use\n        ``@pytest.fixture(name='<fixturename>')``.\n    \"\"\"\n    fixture_marker = FixtureFunctionMarker(\n        scope=scope,\n        params=tuple(params) if params is not None else None,\n        autouse=autouse,\n        ids=None if ids is None else ids if callable(ids) else tuple(ids),\n        name=name,\n        _ispytest=True,\n    )\n\n    # Direct decoration.\n    if fixture_function:\n        return fixture_marker(fixture_function)\n\n    return fixture_marker\n", "type": "function"}, {"name": "test_fixture_double_decorator", "is_method": false, "class_name": null, "parameters": ["pytester"], "calls": ["pytester.makepyfile", "pytester.runpytest", "result.assert_outcomes", "result.stdout.fnmatch_lines"], "code_location": {"file": "fixtures.py", "path": "/data3/pwh/swebench-repos/pytest/testing/python", "start_line": 4577, "end_line": 4595}, "code_snippet": "def test_fixture_double_decorator(pytester: Pytester) -> None:\n    \"\"\"Check if an error is raised when using @pytest.fixture twice.\"\"\"\n    pytester.makepyfile(\n        \"\"\"\n        import pytest\n\n        @pytest.fixture\n        @pytest.fixture\n        def fixt():\n            pass\n        \"\"\"\n    )\n    result = pytester.runpytest()\n    result.assert_outcomes(errors=1)\n    result.stdout.fnmatch_lines(\n        [\n            \"E * ValueError: @pytest.fixture is being applied more than once to the same function 'fixt'\"\n        ]\n    )\n", "type": "function"}, {"name": "test_fixture_disallow_on_marked_functions", "is_method": false, "class_name": null, "parameters": [], "calls": ["pytest.warns", "pytest.mark.parametrize", "pytest.mark.usefixtures", "len", "NotImplementedError"], "code_location": {"file": "deprecated_test.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 171, "end_line": 187}, "code_snippet": "def test_fixture_disallow_on_marked_functions():\n    \"\"\"Test that applying @pytest.fixture to a marked function warns (#3364).\"\"\"\n    with pytest.warns(\n        pytest.PytestRemovedIn9Warning,\n        match=r\"Marks applied to fixtures have no effect\",\n    ) as record:\n\n        @pytest.fixture\n        @pytest.mark.parametrize(\"example\", [\"hello\"])\n        @pytest.mark.usefixtures(\"tmp_path\")\n        def foo():\n            raise NotImplementedError()\n\n    # it's only possible to get one warning here because you're already prevented\n    # from applying @fixture twice\n    # ValueError(\"fixture is being applied more than once to the same function\")\n    assert len(record) == 1\n", "type": "function"}, {"name": "__init__", "is_method": true, "class_name": "Function", "parameters": ["self", "name", "parent", "config", "callspec", "callobj", "keywords", "session", "fixtureinfo", "originalname"], "calls": ["__init__", "self.own_markers.extend", "self.keywords.update", "self.keywords.update", "self._initrequest", "getattr", "get_unpacked_marks", "self.own_markers.extend", "self.keywords.update", "fm.getfixtureinfo", "super"], "code_location": {"file": "python.py", "path": "/data3/pwh/swebench-repos/pytest/src/_pytest", "start_line": 1570, "end_line": 1619}, "code_snippet": "    def __init__(\n        self,\n        name: str,\n        parent,\n        config: Config | None = None,\n        callspec: CallSpec2 | None = None,\n        callobj=NOTSET,\n        keywords: Mapping[str, Any] | None = None,\n        session: Session | None = None,\n        fixtureinfo: FuncFixtureInfo | None = None,\n        originalname: str | None = None,\n    ) -> None:\n        super().__init__(name, parent, config=config, session=session)\n\n        if callobj is not NOTSET:\n            self._obj = callobj\n            self._instance = getattr(callobj, \"__self__\", None)\n\n        #: Original function name, without any decorations (for example\n        #: parametrization adds a ``\"[...]\"`` suffix to function names), used to access\n        #: the underlying function object from ``parent`` (in case ``callobj`` is not given\n        #: explicitly).\n        #:\n        #: .. versionadded:: 3.0\n        self.originalname = originalname or name\n\n        # Note: when FunctionDefinition is introduced, we should change ``originalname``\n        # to a readonly property that returns FunctionDefinition.name.\n\n        self.own_markers.extend(get_unpacked_marks(self.obj))\n        if callspec:\n            self.callspec = callspec\n            self.own_markers.extend(callspec.marks)\n\n        # todo: this is a hell of a hack\n        # https://github.com/pytest-dev/pytest/issues/4569\n        # Note: the order of the updates is important here; indicates what\n        # takes priority (ctor argument over function attributes over markers).\n        # Take own_markers only; NodeKeywords handles parent traversal on its own.\n        self.keywords.update((mark.name, mark) for mark in self.own_markers)\n        self.keywords.update(self.obj.__dict__)\n        if keywords:\n            self.keywords.update(keywords)\n\n        if fixtureinfo is None:\n            fm = self.session._fixturemanager\n            fixtureinfo = fm.getfixtureinfo(self, self.obj, self.cls)\n        self._fixtureinfo: FuncFixtureInfo = fixtureinfo\n        self.fixturenames = fixtureinfo.names_closure\n        self._initrequest()\n", "type": "function"}, {"name": "test_usefixtures_marker", "is_method": true, "class_name": "TestFixtureUsages", "parameters": ["self", "pytester"], "calls": ["pytester.makepyfile", "pytester.inline_run", "reprec.assertoutcome"], "code_location": {"file": "fixtures.py", "path": "/data3/pwh/swebench-repos/pytest/testing/python", "start_line": 1429, "end_line": 1452}, "code_snippet": "    def test_usefixtures_marker(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n\n            values = []\n\n            @pytest.fixture(scope=\"class\")\n            def myfix(request):\n                request.cls.hello = \"world\"\n                values.append(1)\n\n            class TestClass(object):\n                def test_one(self):\n                    assert self.hello == \"world\"\n                    assert len(values) == 1\n                def test_two(self):\n                    assert self.hello == \"world\"\n                    assert len(values) == 1\n            pytest.mark.usefixtures(\"myfix\")(TestClass)\n        \"\"\"\n        )\n        reprec = pytester.inline_run()\n        reprec.assertoutcome(passed=2)\n", "type": "function"}, {"name": "fixture", "is_method": false, "class_name": null, "parameters": ["fixture_function"], "calls": [], "code_location": {"file": "fixtures.py", "path": "/data3/pwh/swebench-repos/pytest/src/_pytest", "start_line": 1313, "end_line": 1321}, "code_snippet": "def fixture(\n    fixture_function: None = ...,\n    *,\n    scope: _ScopeName | Callable[[str, Config], _ScopeName] = ...,\n    params: Iterable[object] | None = ...,\n    autouse: bool = ...,\n    ids: Sequence[object | None] | Callable[[Any], object | None] | None = ...,\n    name: str | None = None,\n) -> FixtureFunctionMarker: ...\n", "type": "function"}, {"name": "test_call_fixture_function_error", "is_method": false, "class_name": null, "parameters": [], "calls": ["NotImplementedError", "pytest.raises", "fix"], "code_location": {"file": "fixtures.py", "path": "/data3/pwh/swebench-repos/pytest/testing/python", "start_line": 4566, "end_line": 4574}, "code_snippet": "def test_call_fixture_function_error():\n    \"\"\"Check if an error is raised if a fixture function is called directly (#4545)\"\"\"\n\n    @pytest.fixture\n    def fix():\n        raise NotImplementedError()\n\n    with pytest.raises(pytest.fail.Exception):\n        assert fix() == 1\n", "type": "function"}, {"name": "test_applymarker", "is_method": true, "class_name": "TestRequestMarking", "parameters": ["self", "pytester"], "calls": ["pytester.getitems", "isinstance", "TopRequest", "req1.applymarker", "req1.applymarker", "pytest.raises", "req1.applymarker"], "code_location": {"file": "fixtures.py", "path": "/data3/pwh/swebench-repos/pytest/testing/python", "start_line": 1151, "end_line": 1175}, "code_snippet": "    def test_applymarker(self, pytester: Pytester) -> None:\n        item1, item2 = pytester.getitems(\n            \"\"\"\n            import pytest\n\n            @pytest.fixture\n            def something(request):\n                pass\n            class TestClass(object):\n                def test_func1(self, something):\n                    pass\n                def test_func2(self, something):\n                    pass\n        \"\"\"\n        )\n        assert isinstance(item1, Function)\n        req1 = TopRequest(item1, _ispytest=True)\n        assert \"xfail\" not in item1.keywords\n        req1.applymarker(pytest.mark.xfail)\n        assert \"xfail\" in item1.keywords\n        assert \"skipif\" not in item1.keywords\n        req1.applymarker(pytest.mark.skipif)\n        assert \"skipif\" in item1.keywords\n        with pytest.raises(ValueError):\n            req1.applymarker(42)  # type: ignore[arg-type]\n", "type": "function"}], "retrieved_count": 10, "cost_time": 1.0847744941711426}
{"question": "What is the defensive layering pattern established by the exception handling architecture in _format_repr_exception to prevent cascading failures when repr() operations fail during error reporting?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"name": "_format_repr_exception", "is_method": false, "class_name": null, "parameters": ["exc", "obj"], "calls": ["_try_repr_or_str", "id", "type", "_try_repr_or_str"], "code_location": {"file": "saferepr.py", "path": "/data3/pwh/swebench-repos/pytest/src/_pytest/_io", "start_line": 16, "end_line": 25}, "code_snippet": "def _format_repr_exception(exc: BaseException, obj: object) -> str:\n    try:\n        exc_info = _try_repr_or_str(exc)\n    except (KeyboardInterrupt, SystemExit):\n        raise\n    except BaseException as inner_exc:\n        exc_info = f\"unpresentable exception ({_try_repr_or_str(inner_exc)})\"\n    return (\n        f\"<[{exc_info} raised in repr()] {type(obj).__name__} object at 0x{id(obj):x}>\"\n    )\n", "type": "function"}, {"name": "_try_repr_or_str", "is_method": false, "class_name": null, "parameters": ["obj"], "calls": ["repr", "type"], "code_location": {"file": "saferepr.py", "path": "/data3/pwh/swebench-repos/pytest/src/_pytest/_io", "start_line": 7, "end_line": 13}, "code_snippet": "def _try_repr_or_str(obj: object) -> str:\n    try:\n        return repr(obj)\n    except (KeyboardInterrupt, SystemExit):\n        raise\n    except BaseException:\n        return f'{type(obj).__name__}(\"{obj}\")'\n", "type": "function"}, {"name": "repr", "is_method": true, "class_name": "SafeRepr", "parameters": ["self", "x"], "calls": ["_ellipsize", "ascii", "repr", "_format_repr_exception", "super"], "code_location": {"file": "saferepr.py", "path": "/data3/pwh/swebench-repos/pytest/src/_pytest/_io", "start_line": 57, "end_line": 69}, "code_snippet": "    def repr(self, x: object) -> str:\n        try:\n            if self.use_ascii:\n                s = ascii(x)\n            else:\n                s = super().repr(x)\n        except (KeyboardInterrupt, SystemExit):\n            raise\n        except BaseException as exc:\n            s = _format_repr_exception(exc, x)\n        if self.maxsize is not None:\n            s = _ellipsize(s, self.maxsize)\n        return s\n", "type": "function"}, {"name": "repr_instance", "is_method": true, "class_name": "SafeRepr", "parameters": ["self", "x", "level"], "calls": ["repr", "_ellipsize", "_format_repr_exception"], "code_location": {"file": "saferepr.py", "path": "/data3/pwh/swebench-repos/pytest/src/_pytest/_io", "start_line": 71, "end_line": 80}, "code_snippet": "    def repr_instance(self, x: object, level: int) -> str:\n        try:\n            s = repr(x)\n        except (KeyboardInterrupt, SystemExit):\n            raise\n        except BaseException as exc:\n            s = _format_repr_exception(exc, x)\n        if self.maxsize is not None:\n            s = _ellipsize(s, self.maxsize)\n        return s\n", "type": "function"}, {"name": "SafeRepr", "docstring": "repr.Repr that limits the resulting size of repr() and includes\ninformation on exceptions raised during the call.", "methods": ["__init__", "repr", "repr_instance"], "attributes": [], "code_location": {"file": "saferepr.py", "path": "/data3/pwh/swebench-repos/pytest/src/_pytest/_io", "start_line": 36, "end_line": 80}, "type": "class"}, {"name": "test_exceptions", "is_method": false, "class_name": null, "parameters": [], "calls": ["saferepr", "BrokenRepr", "saferepr", "saferepr", "BrokenReprException", "saferepr", "none", "BrokenReprException", "BrokenRepr", "BrokenRepr", "repr", "Exception", "id"], "code_location": {"file": "test_saferepr.py", "path": "/data3/pwh/swebench-repos/pytest/testing/io", "start_line": 39, "end_line": 65}, "code_snippet": "def test_exceptions() -> None:\n    class BrokenRepr:\n        def __init__(self, ex):\n            self.ex = ex\n\n        def __repr__(self):\n            raise self.ex\n\n    class BrokenReprException(Exception):\n        __str__ = None  # type: ignore[assignment]\n        __repr__ = None  # type: ignore[assignment]\n\n    assert \"Exception\" in saferepr(BrokenRepr(Exception(\"broken\")))\n    s = saferepr(BrokenReprException(\"really broken\"))\n    assert \"TypeError\" in s\n    assert \"TypeError\" in saferepr(BrokenRepr(\"string\"))\n\n    none = None\n    try:\n        none()  # type: ignore[misc]\n    except BaseException as exc:\n        exp_exc = repr(exc)\n    obj = BrokenRepr(BrokenReprException(\"omg even worse\"))\n    s2 = saferepr(obj)\n    assert s2 == (\n        f\"<[unpresentable exception ({exp_exc!s}) raised in repr()] BrokenRepr object at 0x{id(obj):x}>\"\n    )\n", "type": "function"}, {"name": "repr_excinfo", "is_method": true, "class_name": "FormattedExcinfo", "parameters": ["self", "excinfo"], "calls": ["set", "repr_chain.reverse", "ExceptionChainRepr", "seen.add", "id", "id", "isinstance", "excinfo_._getreprcrash", "ReprTracebackNative", "filter_excinfo_traceback", "ReprTracebackNative", "self.repr_traceback", "format_exception", "ExceptionInfo.from_exception", "format_exception", "type", "ExceptionInfo.from_exception", "type"], "code_location": {"file": "code.py", "path": "/data3/pwh/swebench-repos/pytest/src/_pytest/_code", "start_line": 1177, "end_line": 1224}, "code_snippet": "    def repr_excinfo(self, excinfo: ExceptionInfo[BaseException]) -> ExceptionChainRepr:\n        repr_chain: list[tuple[ReprTraceback, ReprFileLocation | None, str | None]] = []\n        e: BaseException | None = excinfo.value\n        excinfo_: ExceptionInfo[BaseException] | None = excinfo\n        descr = None\n        seen: set[int] = set()\n        while e is not None and id(e) not in seen:\n            seen.add(id(e))\n\n            if excinfo_:\n                # Fall back to native traceback as a temporary workaround until\n                # full support for exception groups added to ExceptionInfo.\n                # See https://github.com/pytest-dev/pytest/issues/9159\n                reprtraceback: ReprTraceback | ReprTracebackNative\n                if isinstance(e, BaseExceptionGroup):\n                    # don't filter any sub-exceptions since they shouldn't have any internal frames\n                    traceback = filter_excinfo_traceback(self.tbfilter, excinfo)\n                    reprtraceback = ReprTracebackNative(\n                        format_exception(\n                            type(excinfo.value),\n                            excinfo.value,\n                            traceback[0]._rawentry,\n                        )\n                    )\n                else:\n                    reprtraceback = self.repr_traceback(excinfo_)\n                reprcrash = excinfo_._getreprcrash()\n            else:\n                # Fallback to native repr if the exception doesn't have a traceback:\n                # ExceptionInfo objects require a full traceback to work.\n                reprtraceback = ReprTracebackNative(format_exception(type(e), e, None))\n                reprcrash = None\n            repr_chain += [(reprtraceback, reprcrash, descr)]\n\n            if e.__cause__ is not None and self.chain:\n                e = e.__cause__\n                excinfo_ = ExceptionInfo.from_exception(e) if e.__traceback__ else None\n                descr = \"The above exception was the direct cause of the following exception:\"\n            elif (\n                e.__context__ is not None and not e.__suppress_context__ and self.chain\n            ):\n                e = e.__context__\n                excinfo_ = ExceptionInfo.from_exception(e) if e.__traceback__ else None\n                descr = \"During handling of the above exception, another exception occurred:\"\n            else:\n                e = None\n        repr_chain.reverse()\n        return ExceptionChainRepr(repr_chain)\n", "type": "function"}, {"name": "test_repr_local_with_error", "is_method": true, "class_name": "TestFormattedExcinfo", "parameters": ["self"], "calls": ["FormattedExcinfo", "p.repr_locals", "ObjWithErrorInRepr"], "code_location": {"file": "test_excinfo.py", "path": "/data3/pwh/swebench-repos/pytest/testing/code", "start_line": 704, "end_line": 715}, "code_snippet": "    def test_repr_local_with_error(self) -> None:\n        class ObjWithErrorInRepr:\n            def __repr__(self):\n                raise NotImplementedError\n\n        p = FormattedExcinfo(showlocals=True, truncate_locals=False)\n        loc = {\"x\": ObjWithErrorInRepr(), \"__builtins__\": {}}\n        reprlocals = p.repr_locals(loc)\n        assert reprlocals is not None\n        assert reprlocals.lines\n        assert reprlocals.lines[0] == \"__builtins__ = <builtins>\"\n        assert \"[NotImplementedError() raised in repr()]\" in reprlocals.lines[1]\n", "type": "function"}, {"name": "_repr", "is_method": true, "class_name": "PrettyPrinter", "parameters": ["self", "object", "context", "level"], "calls": ["self._safe_repr", "context.copy"], "code_location": {"file": "pprint.py", "path": "/data3/pwh/swebench-repos/pytest/src/_pytest/_io", "start_line": 473, "end_line": 474}, "code_snippet": "    def _repr(self, object: Any, context: set[int], level: int) -> str:\n        return self._safe_repr(object, context.copy(), self._depth, level)\n", "type": "function"}, {"name": "test_buggy_builtin_repr", "is_method": false, "class_name": null, "parameters": [], "calls": ["saferepr", "ValueError", "int"], "code_location": {"file": "test_saferepr.py", "path": "/data3/pwh/swebench-repos/pytest/testing/io", "start_line": 129, "end_line": 137}, "code_snippet": "def test_buggy_builtin_repr():\n    # Simulate a case where a repr for a builtin raises.\n    # reprlib dispatches by type name, so use \"int\".\n\n    class int:\n        def __repr__(self):\n            raise ValueError(\"Buggy repr!\")\n\n    assert \"Buggy\" in saferepr(int())\n", "type": "function"}], "retrieved_count": 10, "cost_time": 1.0835232734680176}
{"question": "What is the conditional logic in write_captured_output that determines which captured output streams are written to the XML report, and what is the semantic difference between the 'all' logging mode and the combination of 'system-out' and 'system-err' modes in terms of content aggregation?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"name": "write_captured_output", "is_method": true, "class_name": "_NodeReporter", "parameters": ["self", "report"], "calls": ["self._prepare_content", "self._prepare_content", "self._write_content", "self._prepare_content", "self._write_content", "self._write_content"], "code_location": {"file": "junitxml.py", "path": "/data3/pwh/swebench-repos/pytest/src/_pytest", "start_line": 159, "end_line": 180}, "code_snippet": "    def write_captured_output(self, report: TestReport) -> None:\n        if not self.xml.log_passing_tests and report.passed:\n            return\n\n        content_out = report.capstdout\n        content_log = report.caplog\n        content_err = report.capstderr\n        if self.xml.logging == \"no\":\n            return\n        content_all = \"\"\n        if self.xml.logging in [\"log\", \"all\"]:\n            content_all = self._prepare_content(content_log, \" Captured Log \")\n        if self.xml.logging in [\"system-out\", \"out-err\", \"all\"]:\n            content_all += self._prepare_content(content_out, \" Captured Out \")\n            self._write_content(report, content_all, \"system-out\")\n            content_all = \"\"\n        if self.xml.logging in [\"system-err\", \"out-err\", \"all\"]:\n            content_all += self._prepare_content(content_err, \" Captured Err \")\n            self._write_content(report, content_all, \"system-err\")\n            content_all = \"\"\n        if content_all:\n            self._write_content(report, content_all, \"system-out\")\n", "type": "function"}, {"name": "test_xfail_captures_output_once", "is_method": true, "class_name": "TestPython", "parameters": ["self", "pytester", "junit_logging", "run_and_parse"], "calls": ["pytest.mark.parametrize", "pytester.makepyfile", "run_and_parse", "dom.get_first_by_tag", "node.get_first_by_tag", "len", "len", "tnode.find_by_tag", "tnode.find_by_tag"], "code_location": {"file": "test_junitxml.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 741, "end_line": 767}, "code_snippet": "    def test_xfail_captures_output_once(\n        self, pytester: Pytester, junit_logging: str, run_and_parse: RunAndParse\n    ) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            import sys\n            import pytest\n\n            @pytest.mark.xfail()\n            def test_fail():\n                sys.stdout.write('XFAIL This is stdout')\n                sys.stderr.write('XFAIL This is stderr')\n                assert 0\n        \"\"\"\n        )\n        result, dom = run_and_parse(\"-o\", f\"junit_logging={junit_logging}\")\n        node = dom.get_first_by_tag(\"testsuite\")\n        tnode = node.get_first_by_tag(\"testcase\")\n\n        has_err_logging = junit_logging in [\"system-err\", \"out-err\", \"all\"]\n        expected_err_output_len = 1 if has_err_logging else 0\n        assert len(tnode.find_by_tag(\"system-err\")) == expected_err_output_len\n\n        has_out_logigng = junit_logging in (\"log\", \"system-out\", \"out-err\", \"all\")\n        expected_out_output_len = 1 if has_out_logigng else 0\n\n        assert len(tnode.find_by_tag(\"system-out\")) == expected_out_output_len\n", "type": "function"}, {"name": "test_pass_captures_stderr", "is_method": true, "class_name": "TestPython", "parameters": ["self", "pytester", "run_and_parse", "junit_logging"], "calls": ["pytest.mark.parametrize", "pytester.makepyfile", "run_and_parse", "dom.get_first_by_tag", "node.get_first_by_tag", "pnode.get_first_by_tag", "node.find_by_tag", "systemerr.toxml"], "code_location": {"file": "test_junitxml.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 880, "end_line": 901}, "code_snippet": "    def test_pass_captures_stderr(\n        self, pytester: Pytester, run_and_parse: RunAndParse, junit_logging: str\n    ) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            import sys\n            def test_pass():\n                sys.stderr.write('hello-stderr')\n        \"\"\"\n        )\n        result, dom = run_and_parse(\"-o\", f\"junit_logging={junit_logging}\")\n        node = dom.get_first_by_tag(\"testsuite\")\n        pnode = node.get_first_by_tag(\"testcase\")\n        if junit_logging == \"no\":\n            assert not node.find_by_tag(\"system-err\"), (\n                \"system-err should not be generated\"\n            )\n        if junit_logging == \"system-err\":\n            systemerr = pnode.get_first_by_tag(\"system-err\")\n            assert \"hello-stderr\" in systemerr.toxml(), (\n                \"'hello-stderr' should be in system-err\"\n            )\n", "type": "function"}, {"name": "test_pass_captures_stdout", "is_method": true, "class_name": "TestPython", "parameters": ["self", "pytester", "run_and_parse", "junit_logging"], "calls": ["pytest.mark.parametrize", "pytester.makepyfile", "run_and_parse", "dom.get_first_by_tag", "node.get_first_by_tag", "pnode.get_first_by_tag", "node.find_by_tag", "systemout.toxml"], "code_location": {"file": "test_junitxml.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 857, "end_line": 877}, "code_snippet": "    def test_pass_captures_stdout(\n        self, pytester: Pytester, run_and_parse: RunAndParse, junit_logging: str\n    ) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            def test_pass():\n                print('hello-stdout')\n        \"\"\"\n        )\n        result, dom = run_and_parse(\"-o\", f\"junit_logging={junit_logging}\")\n        node = dom.get_first_by_tag(\"testsuite\")\n        pnode = node.get_first_by_tag(\"testcase\")\n        if junit_logging == \"no\":\n            assert not node.find_by_tag(\"system-out\"), (\n                \"system-out should not be generated\"\n            )\n        if junit_logging == \"system-out\":\n            systemout = pnode.get_first_by_tag(\"system-out\")\n            assert \"hello-stdout\" in systemout.toxml(), (\n                \"'hello-stdout' should be in system-out\"\n            )\n", "type": "function"}, {"name": "test_setup_error_captures_stdout", "is_method": true, "class_name": "TestPython", "parameters": ["self", "pytester", "run_and_parse", "junit_logging"], "calls": ["pytest.mark.parametrize", "pytester.makepyfile", "run_and_parse", "dom.get_first_by_tag", "node.get_first_by_tag", "pnode.get_first_by_tag", "node.find_by_tag", "systemout.toxml"], "code_location": {"file": "test_junitxml.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 904, "end_line": 930}, "code_snippet": "    def test_setup_error_captures_stdout(\n        self, pytester: Pytester, run_and_parse: RunAndParse, junit_logging: str\n    ) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n\n            @pytest.fixture\n            def arg(request):\n                print('hello-stdout')\n                raise ValueError()\n            def test_function(arg):\n                pass\n        \"\"\"\n        )\n        result, dom = run_and_parse(\"-o\", f\"junit_logging={junit_logging}\")\n        node = dom.get_first_by_tag(\"testsuite\")\n        pnode = node.get_first_by_tag(\"testcase\")\n        if junit_logging == \"no\":\n            assert not node.find_by_tag(\"system-out\"), (\n                \"system-out should not be generated\"\n            )\n        if junit_logging == \"system-out\":\n            systemout = pnode.get_first_by_tag(\"system-out\")\n            assert \"hello-stdout\" in systemout.toxml(), (\n                \"'hello-stdout' should be in system-out\"\n            )\n", "type": "function"}, {"name": "test_setup_error_captures_stderr", "is_method": true, "class_name": "TestPython", "parameters": ["self", "pytester", "run_and_parse", "junit_logging"], "calls": ["pytest.mark.parametrize", "pytester.makepyfile", "run_and_parse", "dom.get_first_by_tag", "node.get_first_by_tag", "pnode.get_first_by_tag", "node.find_by_tag", "systemerr.toxml"], "code_location": {"file": "test_junitxml.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 933, "end_line": 960}, "code_snippet": "    def test_setup_error_captures_stderr(\n        self, pytester: Pytester, run_and_parse: RunAndParse, junit_logging: str\n    ) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            import sys\n            import pytest\n\n            @pytest.fixture\n            def arg(request):\n                sys.stderr.write('hello-stderr')\n                raise ValueError()\n            def test_function(arg):\n                pass\n        \"\"\"\n        )\n        result, dom = run_and_parse(\"-o\", f\"junit_logging={junit_logging}\")\n        node = dom.get_first_by_tag(\"testsuite\")\n        pnode = node.get_first_by_tag(\"testcase\")\n        if junit_logging == \"no\":\n            assert not node.find_by_tag(\"system-err\"), (\n                \"system-err should not be generated\"\n            )\n        if junit_logging == \"system-err\":\n            systemerr = pnode.get_first_by_tag(\"system-err\")\n            assert \"hello-stderr\" in systemerr.toxml(), (\n                \"'hello-stderr' should be in system-err\"\n            )\n", "type": "function"}, {"name": "test_avoid_double_stdout", "is_method": true, "class_name": "TestPython", "parameters": ["self", "pytester", "run_and_parse", "junit_logging"], "calls": ["pytest.mark.parametrize", "pytester.makepyfile", "run_and_parse", "dom.get_first_by_tag", "node.get_first_by_tag", "pnode.get_first_by_tag", "node.find_by_tag", "systemout.toxml", "systemout.toxml"], "code_location": {"file": "test_junitxml.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 963, "end_line": 990}, "code_snippet": "    def test_avoid_double_stdout(\n        self, pytester: Pytester, run_and_parse: RunAndParse, junit_logging: str\n    ) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            import sys\n            import pytest\n\n            @pytest.fixture\n            def arg(request):\n                yield\n                sys.stdout.write('hello-stdout teardown')\n                raise ValueError()\n            def test_function(arg):\n                sys.stdout.write('hello-stdout call')\n        \"\"\"\n        )\n        result, dom = run_and_parse(\"-o\", f\"junit_logging={junit_logging}\")\n        node = dom.get_first_by_tag(\"testsuite\")\n        pnode = node.get_first_by_tag(\"testcase\")\n        if junit_logging == \"no\":\n            assert not node.find_by_tag(\"system-out\"), (\n                \"system-out should not be generated\"\n            )\n        if junit_logging == \"system-out\":\n            systemout = pnode.get_first_by_tag(\"system-out\")\n            assert \"hello-stdout call\" in systemout.toxml()\n            assert \"hello-stdout teardown\" in systemout.toxml()\n", "type": "function"}, {"name": "test_failure_function", "is_method": true, "class_name": "TestPython", "parameters": ["self", "pytester", "junit_logging", "run_and_parse", "xunit_family"], "calls": ["pytest.mark.parametrize", "pytester.makepyfile", "run_and_parse", "dom.get_first_by_tag", "node.assert_attr", "node.get_first_by_tag", "tnode.assert_attr", "tnode.get_first_by_tag", "fnode.assert_attr", "fnode.toxml", "tnode.get_first_by_tag", "logdata.toxml", "tnode.get_first_by_tag", "systemout.toxml", "tnode.get_first_by_tag", "systemerr.toxml", "tnode.find_by_tag", "tnode.find_by_tag", "tnode.find_by_tag"], "code_location": {"file": "test_junitxml.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 560, "end_line": 625}, "code_snippet": "    def test_failure_function(\n        self,\n        pytester: Pytester,\n        junit_logging: str,\n        run_and_parse: RunAndParse,\n        xunit_family: str,\n    ) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            import logging\n            import sys\n\n            def test_fail():\n                print(\"hello-stdout\")\n                sys.stderr.write(\"hello-stderr\\\\n\")\n                logging.info('info msg')\n                logging.warning('warning msg')\n                raise ValueError(42)\n        \"\"\"\n        )\n\n        result, dom = run_and_parse(\n            \"-o\", f\"junit_logging={junit_logging}\", family=xunit_family\n        )\n        assert result.ret, \"Expected ret > 0\"\n        node = dom.get_first_by_tag(\"testsuite\")\n        node.assert_attr(failures=1, tests=1)\n        tnode = node.get_first_by_tag(\"testcase\")\n        tnode.assert_attr(classname=\"test_failure_function\", name=\"test_fail\")\n        fnode = tnode.get_first_by_tag(\"failure\")\n        fnode.assert_attr(message=\"ValueError: 42\")\n        assert \"ValueError\" in fnode.toxml(), \"ValueError not included\"\n\n        if junit_logging in [\"log\", \"all\"]:\n            logdata = tnode.get_first_by_tag(\"system-out\")\n            log_xml = logdata.toxml()\n            assert logdata.tag == \"system-out\", \"Expected tag: system-out\"\n            assert \"info msg\" not in log_xml, \"Unexpected INFO message\"\n            assert \"warning msg\" in log_xml, \"Missing WARN message\"\n        if junit_logging in [\"system-out\", \"out-err\", \"all\"]:\n            systemout = tnode.get_first_by_tag(\"system-out\")\n            systemout_xml = systemout.toxml()\n            assert systemout.tag == \"system-out\", \"Expected tag: system-out\"\n            assert \"info msg\" not in systemout_xml, \"INFO message found in system-out\"\n            assert \"hello-stdout\" in systemout_xml, (\n                \"Missing 'hello-stdout' in system-out\"\n            )\n        if junit_logging in [\"system-err\", \"out-err\", \"all\"]:\n            systemerr = tnode.get_first_by_tag(\"system-err\")\n            systemerr_xml = systemerr.toxml()\n            assert systemerr.tag == \"system-err\", \"Expected tag: system-err\"\n            assert \"info msg\" not in systemerr_xml, \"INFO message found in system-err\"\n            assert \"hello-stderr\" in systemerr_xml, (\n                \"Missing 'hello-stderr' in system-err\"\n            )\n            assert \"warning msg\" not in systemerr_xml, (\n                \"WARN message found in system-err\"\n            )\n        if junit_logging == \"no\":\n            assert not tnode.find_by_tag(\"log\"), \"Found unexpected content: log\"\n            assert not tnode.find_by_tag(\"system-out\"), (\n                \"Found unexpected content: system-out\"\n            )\n            assert not tnode.find_by_tag(\"system-err\"), (\n                \"Found unexpected content: system-err\"\n            )\n", "type": "function"}, {"name": "test_tee_stdio_captures_and_live_prints", "is_method": false, "class_name": null, "parameters": ["pytester"], "calls": ["pytester.makepyfile", "pytester.runpytest_subprocess", "result.stdout.fnmatch_lines", "result.stderr.fnmatch_lines", "read_text", "pytester.path.joinpath"], "code_location": {"file": "acceptance_test.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 1444, "end_line": 1468}, "code_snippet": "def test_tee_stdio_captures_and_live_prints(pytester: Pytester) -> None:\n    testpath = pytester.makepyfile(\n        \"\"\"\n        import sys\n        def test_simple():\n            print (\"@this is stdout@\")\n            print (\"@this is stderr@\", file=sys.stderr)\n    \"\"\"\n    )\n    result = pytester.runpytest_subprocess(\n        testpath,\n        \"--capture=tee-sys\",\n        \"--junitxml=output.xml\",\n        \"-o\",\n        \"junit_logging=all\",\n    )\n\n    # ensure stdout/stderr were 'live printed'\n    result.stdout.fnmatch_lines([\"*@this is stdout@*\"])\n    result.stderr.fnmatch_lines([\"*@this is stderr@*\"])\n\n    # now ensure the output is in the junitxml\n    fullXml = pytester.path.joinpath(\"output.xml\").read_text(encoding=\"utf-8\")\n    assert \"@this is stdout@\\n\" in fullXml\n    assert \"@this is stderr@\\n\" in fullXml\n", "type": "function"}, {"name": "test_nullbyte", "is_method": false, "class_name": null, "parameters": ["pytester", "junit_logging"], "calls": ["pytest.mark.parametrize", "pytester.makepyfile", "pytester.path.joinpath", "pytester.runpytest", "xmlf.read_text"], "code_location": {"file": "test_junitxml.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 1062, "end_line": 1080}, "code_snippet": "def test_nullbyte(pytester: Pytester, junit_logging: str) -> None:\n    # A null byte cannot occur in XML (see section 2.2 of the spec)\n    pytester.makepyfile(\n        \"\"\"\n        import sys\n        def test_print_nullbyte():\n            sys.stdout.write('Here the null -->' + chr(0) + '<--')\n            sys.stdout.write('In repr form -->' + repr(chr(0)) + '<--')\n            assert False\n    \"\"\"\n    )\n    xmlf = pytester.path.joinpath(\"junit.xml\")\n    pytester.runpytest(f\"--junitxml={xmlf}\", \"-o\", f\"junit_logging={junit_logging}\")\n    text = xmlf.read_text(encoding=\"utf-8\")\n    assert \"\\x00\" not in text\n    if junit_logging == \"system-out\":\n        assert \"#x00\" in text\n    if junit_logging == \"no\":\n        assert \"#x00\" not in text\n", "type": "function"}], "retrieved_count": 10, "cost_time": 1.0825107097625732}
{"question": "What external dependencies and context must be available for TestEvaluation test methods to correctly evaluate skipif conditions that reference module attributes like os.sep?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"name": "test_skipif_class", "is_method": true, "class_name": "TestEvaluation", "parameters": ["self", "pytester"], "calls": ["pytester.getitems", "evaluate_skip_marks"], "code_location": {"file": "test_skipping.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 146, "end_line": 159}, "code_snippet": "    def test_skipif_class(self, pytester: Pytester) -> None:\n        (item,) = pytester.getitems(\n            \"\"\"\n            import pytest\n            class TestClass(object):\n                pytestmark = pytest.mark.skipif(\"config._hackxyz\")\n                def test_func(self):\n                    pass\n        \"\"\"\n        )\n        item.config._hackxyz = 3  # type: ignore[attr-defined]\n        skipped = evaluate_skip_marks(item)\n        assert skipped\n        assert skipped.reason == \"condition: config._hackxyz\"\n", "type": "function"}, {"name": "test_skipif_markeval_namespace", "is_method": true, "class_name": "TestEvaluation", "parameters": ["self", "pytester"], "calls": ["pytester.makeconftest", "pytester.makepyfile", "pytester.runpytest", "res.stdout.fnmatch_lines", "res.stdout.fnmatch_lines"], "code_location": {"file": "test_skipping.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 161, "end_line": 186}, "code_snippet": "    def test_skipif_markeval_namespace(self, pytester: Pytester) -> None:\n        pytester.makeconftest(\n            \"\"\"\n            import pytest\n\n            def pytest_markeval_namespace():\n                return {\"color\": \"green\"}\n            \"\"\"\n        )\n        p = pytester.makepyfile(\n            \"\"\"\n            import pytest\n\n            @pytest.mark.skipif(\"color == 'green'\")\n            def test_1():\n                assert True\n\n            @pytest.mark.skipif(\"color == 'red'\")\n            def test_2():\n                assert True\n        \"\"\"\n        )\n        res = pytester.runpytest(p)\n        assert res.ret == 0\n        res.stdout.fnmatch_lines([\"*1 skipped*\"])\n        res.stdout.fnmatch_lines([\"*1 passed*\"])\n", "type": "function"}, {"name": "test_skipif_conditional", "is_method": true, "class_name": "TestSkipif", "parameters": ["self", "pytester"], "calls": ["pytester.getitem", "pytest.raises", "pytest_runtest_setup"], "code_location": {"file": "test_skipping.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 885, "end_line": 895}, "code_snippet": "    def test_skipif_conditional(self, pytester: Pytester) -> None:\n        item = pytester.getitem(\n            \"\"\"\n            import pytest\n            @pytest.mark.skipif(\"hasattr(os, 'sep')\")\n            def test_func():\n                pass\n        \"\"\"\n        )\n        x = pytest.raises(pytest.skip.Exception, lambda: pytest_runtest_setup(item))\n        assert x.value.msg == \"condition: hasattr(os, 'sep')\"\n", "type": "function"}, {"name": "test_skipif_using_platform", "is_method": true, "class_name": "TestSkipif", "parameters": ["self", "pytester"], "calls": ["pytester.getitem", "pytest.raises", "pytest_runtest_setup"], "code_location": {"file": "test_skipping.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 913, "end_line": 922}, "code_snippet": "    def test_skipif_using_platform(self, pytester: Pytester) -> None:\n        item = pytester.getitem(\n            \"\"\"\n            import pytest\n            @pytest.mark.skipif(\"platform.platform() == platform.platform()\")\n            def test_func():\n                pass\n        \"\"\"\n        )\n        pytest.raises(pytest.skip.Exception, lambda: pytest_runtest_setup(item))\n", "type": "function"}, {"name": "test_marked_one_arg", "is_method": true, "class_name": "TestEvaluation", "parameters": ["self", "pytester"], "calls": ["pytester.getitem", "evaluate_skip_marks"], "code_location": {"file": "test_skipping.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 48, "end_line": 59}, "code_snippet": "    def test_marked_one_arg(self, pytester: Pytester) -> None:\n        item = pytester.getitem(\n            \"\"\"\n            import pytest\n            @pytest.mark.skipif(\"hasattr(os, 'sep')\")\n            def test_func():\n                pass\n        \"\"\"\n        )\n        skipped = evaluate_skip_marks(item)\n        assert skipped\n        assert skipped.reason == \"condition: hasattr(os, 'sep')\"\n", "type": "function"}, {"name": "test_importorskip_imports_last_module_part", "is_method": false, "class_name": null, "parameters": [], "calls": ["pytest.importorskip"], "code_location": {"file": "test_runner.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 796, "end_line": 798}, "code_snippet": "def test_importorskip_imports_last_module_part() -> None:\n    ospath = pytest.importorskip(\"os.path\")\n    assert os.path == ospath\n", "type": "function"}, {"name": "test_importorskip", "is_method": false, "class_name": null, "parameters": ["monkeypatch"], "calls": ["importorskip", "importorskip", "pytest.raises", "excinfo.getrepr", "Path", "pytest.raises", "pytest.raises", "types.ModuleType", "monkeypatch.setitem", "pytest.importorskip", "pytest.raises", "pytest.importorskip", "ExceptionInfo.from_current"], "code_location": {"file": "test_runner.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 763, "end_line": 793}, "code_snippet": "def test_importorskip(monkeypatch) -> None:\n    importorskip = pytest.importorskip\n\n    def f():\n        importorskip(\"asdlkj\")\n\n    try:\n        sysmod = importorskip(\"sys\")\n        assert sysmod is sys\n        # path = pytest.importorskip(\"os.path\")\n        # assert path == os.path\n        excinfo = pytest.raises(pytest.skip.Exception, f)\n        assert excinfo is not None\n        excrepr = excinfo.getrepr()\n        assert excrepr is not None\n        assert excrepr.reprcrash is not None\n        path = Path(excrepr.reprcrash.path)\n        # check that importorskip reports the actual call\n        # in this test the test_runner.py file\n        assert path.stem == \"test_runner\"\n        pytest.raises(SyntaxError, pytest.importorskip, \"x y z\")\n        pytest.raises(SyntaxError, pytest.importorskip, \"x=y\")\n        mod = types.ModuleType(\"hello123\")\n        mod.__version__ = \"1.3\"  # type: ignore\n        monkeypatch.setitem(sys.modules, \"hello123\", mod)\n        with pytest.raises(pytest.skip.Exception):\n            pytest.importorskip(\"hello123\", minversion=\"1.3.1\")\n        mod2 = pytest.importorskip(\"hello123\", minversion=\"1.3\")\n        assert mod2 == mod\n    except pytest.skip.Exception:  # pragma: no cover\n        assert False, f\"spurious skip: {ExceptionInfo.from_current()}\"\n", "type": "function"}, {"name": "test_skipif_markeval_namespace_ValueError", "is_method": true, "class_name": "TestEvaluation", "parameters": ["self", "pytester"], "calls": ["pytester.makeconftest", "pytester.makepyfile", "pytester.runpytest", "res.stdout.fnmatch_lines"], "code_location": {"file": "test_skipping.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 271, "end_line": 295}, "code_snippet": "    def test_skipif_markeval_namespace_ValueError(self, pytester: Pytester) -> None:\n        pytester.makeconftest(\n            \"\"\"\n            import pytest\n\n            def pytest_markeval_namespace():\n                return True\n            \"\"\"\n        )\n        p = pytester.makepyfile(\n            \"\"\"\n            import pytest\n\n            @pytest.mark.skipif(\"color == 'green'\")\n            def test_1():\n                assert True\n        \"\"\"\n        )\n        res = pytester.runpytest(p)\n        assert res.ret == 1\n        res.stdout.fnmatch_lines(\n            [\n                \"*ValueError: pytest_markeval_namespace() needs to return a dict, got True*\"\n            ]\n        )\n", "type": "function"}, {"name": "test_marked_skipif_with_invalid_boolean", "is_method": true, "class_name": "TestEvaluation", "parameters": ["self", "pytester"], "calls": ["pytester.getitem", "pytest.raises", "evaluate_skip_marks"], "code_location": {"file": "test_skipping.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 126, "end_line": 144}, "code_snippet": "    def test_marked_skipif_with_invalid_boolean(self, pytester: Pytester) -> None:\n        item = pytester.getitem(\n            \"\"\"\n            import pytest\n\n            class InvalidBool:\n                def __bool__(self):\n                    raise TypeError(\"INVALID\")\n\n            @pytest.mark.skipif(InvalidBool(), reason=\"xxx\")\n            def test_func():\n                pass\n        \"\"\"\n        )\n        with pytest.raises(pytest.fail.Exception) as excinfo:\n            evaluate_skip_marks(item)\n        assert excinfo.value.msg is not None\n        assert \"Error evaluating 'skipif' condition as a boolean\" in excinfo.value.msg\n        assert \"INVALID\" in excinfo.value.msg\n", "type": "function"}, {"name": "test_marked_one_arg_twice2", "is_method": true, "class_name": "TestEvaluation", "parameters": ["self", "pytester"], "calls": ["pytester.getitem", "evaluate_skip_marks"], "code_location": {"file": "test_skipping.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 93, "end_line": 105}, "code_snippet": "    def test_marked_one_arg_twice2(self, pytester: Pytester) -> None:\n        item = pytester.getitem(\n            \"\"\"\n            import pytest\n            @pytest.mark.skipif(\"hasattr(os, 'murks')\")\n            @pytest.mark.skipif(\"not hasattr(os, 'murks')\")\n            def test_func():\n                pass\n        \"\"\"\n        )\n        skipped = evaluate_skip_marks(item)\n        assert skipped\n        assert skipped.reason == \"condition: not hasattr(os, 'murks')\"\n", "type": "function"}], "retrieved_count": 10, "cost_time": 1.0892367362976074}
{"question": "What is the dependency relationship between evaluate_skip_marks function and the pytester fixture's getitem method in terms of test item creation and mark evaluation?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"name": "test_skipif_class", "is_method": true, "class_name": "TestEvaluation", "parameters": ["self", "pytester"], "calls": ["pytester.getitems", "evaluate_skip_marks"], "code_location": {"file": "test_skipping.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 146, "end_line": 159}, "code_snippet": "    def test_skipif_class(self, pytester: Pytester) -> None:\n        (item,) = pytester.getitems(\n            \"\"\"\n            import pytest\n            class TestClass(object):\n                pytestmark = pytest.mark.skipif(\"config._hackxyz\")\n                def test_func(self):\n                    pass\n        \"\"\"\n        )\n        item.config._hackxyz = 3  # type: ignore[attr-defined]\n        skipped = evaluate_skip_marks(item)\n        assert skipped\n        assert skipped.reason == \"condition: config._hackxyz\"\n", "type": "function"}, {"name": "test_no_marker", "is_method": true, "class_name": "TestEvaluation", "parameters": ["self", "pytester"], "calls": ["pytester.getitem", "evaluate_skip_marks"], "code_location": {"file": "test_skipping.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 16, "end_line": 19}, "code_snippet": "    def test_no_marker(self, pytester: Pytester) -> None:\n        item = pytester.getitem(\"def test_func(): pass\")\n        skipped = evaluate_skip_marks(item)\n        assert not skipped\n", "type": "function"}, {"name": "test_marked_skipif_with_invalid_boolean", "is_method": true, "class_name": "TestEvaluation", "parameters": ["self", "pytester"], "calls": ["pytester.getitem", "pytest.raises", "evaluate_skip_marks"], "code_location": {"file": "test_skipping.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 126, "end_line": 144}, "code_snippet": "    def test_marked_skipif_with_invalid_boolean(self, pytester: Pytester) -> None:\n        item = pytester.getitem(\n            \"\"\"\n            import pytest\n\n            class InvalidBool:\n                def __bool__(self):\n                    raise TypeError(\"INVALID\")\n\n            @pytest.mark.skipif(InvalidBool(), reason=\"xxx\")\n            def test_func():\n                pass\n        \"\"\"\n        )\n        with pytest.raises(pytest.fail.Exception) as excinfo:\n            evaluate_skip_marks(item)\n        assert excinfo.value.msg is not None\n        assert \"Error evaluating 'skipif' condition as a boolean\" in excinfo.value.msg\n        assert \"INVALID\" in excinfo.value.msg\n", "type": "function"}, {"name": "test_marked_skipif_no_args", "is_method": true, "class_name": "TestEvaluation", "parameters": ["self", "pytester"], "calls": ["pytester.getitem", "evaluate_skip_marks"], "code_location": {"file": "test_skipping.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 35, "end_line": 46}, "code_snippet": "    def test_marked_skipif_no_args(self, pytester: Pytester) -> None:\n        item = pytester.getitem(\n            \"\"\"\n            import pytest\n            @pytest.mark.skipif\n            def test_func():\n                pass\n        \"\"\"\n        )\n        skipped = evaluate_skip_marks(item)\n        assert skipped\n        assert skipped.reason == \"\"\n", "type": "function"}, {"name": "test_marked_one_arg", "is_method": true, "class_name": "TestEvaluation", "parameters": ["self", "pytester"], "calls": ["pytester.getitem", "evaluate_skip_marks"], "code_location": {"file": "test_skipping.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 48, "end_line": 59}, "code_snippet": "    def test_marked_one_arg(self, pytester: Pytester) -> None:\n        item = pytester.getitem(\n            \"\"\"\n            import pytest\n            @pytest.mark.skipif(\"hasattr(os, 'sep')\")\n            def test_func():\n                pass\n        \"\"\"\n        )\n        skipped = evaluate_skip_marks(item)\n        assert skipped\n        assert skipped.reason == \"condition: hasattr(os, 'sep')\"\n", "type": "function"}, {"name": "test_marked_one_arg_twice", "is_method": true, "class_name": "TestEvaluation", "parameters": ["self", "pytester"], "calls": ["range", "pytester.getitem", "evaluate_skip_marks"], "code_location": {"file": "test_skipping.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 74, "end_line": 91}, "code_snippet": "    def test_marked_one_arg_twice(self, pytester: Pytester) -> None:\n        lines = [\n            \"\"\"@pytest.mark.skipif(\"not hasattr(os, 'murks')\")\"\"\",\n            \"\"\"@pytest.mark.skipif(condition=\"hasattr(os, 'murks')\")\"\"\",\n        ]\n        for i in range(2):\n            item = pytester.getitem(\n                f\"\"\"\n                import pytest\n                {lines[i]}\n                {lines[(i + 1) % 2]}\n                def test_func():\n                    pass\n            \"\"\"\n            )\n            skipped = evaluate_skip_marks(item)\n            assert skipped\n            assert skipped.reason == \"condition: not hasattr(os, 'murks')\"\n", "type": "function"}, {"name": "test_marked_one_arg_twice2", "is_method": true, "class_name": "TestEvaluation", "parameters": ["self", "pytester"], "calls": ["pytester.getitem", "evaluate_skip_marks"], "code_location": {"file": "test_skipping.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 93, "end_line": 105}, "code_snippet": "    def test_marked_one_arg_twice2(self, pytester: Pytester) -> None:\n        item = pytester.getitem(\n            \"\"\"\n            import pytest\n            @pytest.mark.skipif(\"hasattr(os, 'murks')\")\n            @pytest.mark.skipif(\"not hasattr(os, 'murks')\")\n            def test_func():\n                pass\n        \"\"\"\n        )\n        skipped = evaluate_skip_marks(item)\n        assert skipped\n        assert skipped.reason == \"condition: not hasattr(os, 'murks')\"\n", "type": "function"}, {"name": "test_marked_one_arg_with_reason", "is_method": true, "class_name": "TestEvaluation", "parameters": ["self", "pytester"], "calls": ["pytester.getitem", "evaluate_skip_marks"], "code_location": {"file": "test_skipping.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 61, "end_line": 72}, "code_snippet": "    def test_marked_one_arg_with_reason(self, pytester: Pytester) -> None:\n        item = pytester.getitem(\n            \"\"\"\n            import pytest\n            @pytest.mark.skipif(\"hasattr(os, 'sep')\", attr=2, reason=\"hello world\")\n            def test_func():\n                pass\n        \"\"\"\n        )\n        skipped = evaluate_skip_marks(item)\n        assert skipped\n        assert skipped.reason == \"hello world\"\n", "type": "function"}, {"name": "test_marked_skipif_with_boolean_without_reason", "is_method": true, "class_name": "TestEvaluation", "parameters": ["self", "pytester"], "calls": ["pytester.getitem", "pytest.raises", "evaluate_skip_marks"], "code_location": {"file": "test_skipping.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 107, "end_line": 124}, "code_snippet": "    def test_marked_skipif_with_boolean_without_reason(\n        self, pytester: Pytester\n    ) -> None:\n        item = pytester.getitem(\n            \"\"\"\n            import pytest\n            @pytest.mark.skipif(False)\n            def test_func():\n                pass\n        \"\"\"\n        )\n        with pytest.raises(pytest.fail.Exception) as excinfo:\n            evaluate_skip_marks(item)\n        assert excinfo.value.msg is not None\n        assert (\n            \"\"\"Error evaluating 'skipif': you need to specify reason=STRING when using booleans as conditions.\"\"\"\n            in excinfo.value.msg\n        )\n", "type": "function"}, {"name": "pytest_runtest_setup", "is_method": false, "class_name": null, "parameters": ["item"], "calls": ["hookimpl", "evaluate_skip_marks", "evaluate_xfail_marks", "skip.Exception", "xfail"], "code_location": {"file": "skipping.py", "path": "/data3/pwh/swebench-repos/pytest/src/_pytest", "start_line": 243, "end_line": 250}, "code_snippet": "def pytest_runtest_setup(item: Item) -> None:\n    skipped = evaluate_skip_marks(item)\n    if skipped:\n        raise skip.Exception(skipped.reason, _use_item_location=True)\n\n    item.stash[xfailed_key] = xfailed = evaluate_xfail_marks(item)\n    if xfailed and not item.config.option.runxfail and not xfailed.run:\n        xfail(\"[NOTRUN] \" + xfailed.reason)\n", "type": "function"}], "retrieved_count": 10, "cost_time": 1.084747552871704}
{"question": "How does the TestReadme class separate the concerns of cache directory verification from test execution orchestration to maintain architectural layering between test setup, execution, and assertion phases?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"name": "check_readme", "is_method": true, "class_name": "TestReadme", "parameters": ["self", "pytester"], "calls": ["pytester.parseconfigure", "config.cache._cachedir.joinpath", "readme.is_file"], "code_location": {"file": "test_cacheprovider.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 1264, "end_line": 1268}, "code_snippet": "    def check_readme(self, pytester: Pytester) -> bool:\n        config = pytester.parseconfigure()\n        assert config.cache is not None\n        readme = config.cache._cachedir.joinpath(\"README.md\")\n        return readme.is_file()\n", "type": "function"}, {"name": "test_does_not_create_boilerplate_in_existing_dirs", "is_method": false, "class_name": null, "parameters": ["pytester"], "calls": ["pytester.makeini", "pytester.parseconfig", "Cache.for_config", "cache.set", "os.path.isdir", "os.path.exists", "os.path.exists"], "code_location": {"file": "test_cacheprovider.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 1330, "end_line": 1345}, "code_snippet": "def test_does_not_create_boilerplate_in_existing_dirs(pytester: Pytester) -> None:\n    from _pytest.cacheprovider import Cache\n\n    pytester.makeini(\n        \"\"\"\n        [pytest]\n        cache_dir = .\n        \"\"\"\n    )\n    config = pytester.parseconfig()\n    cache = Cache.for_config(config, _ispytest=True)\n    cache.set(\"foo\", \"bar\")\n\n    assert os.path.isdir(\"v\")  # cache contents\n    assert not os.path.exists(\".gitignore\")\n    assert not os.path.exists(\"README.md\")\n", "type": "function"}, {"name": "test_readme_passed", "is_method": true, "class_name": "TestReadme", "parameters": ["self", "pytester"], "calls": ["pytester.makepyfile", "pytester.runpytest", "self.check_readme"], "code_location": {"file": "test_cacheprovider.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 1270, "end_line": 1273}, "code_snippet": "    def test_readme_passed(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\"def test_always_passes(): pass\")\n        pytester.runpytest()\n        assert self.check_readme(pytester) is True\n", "type": "function"}, {"name": "TestPyCacheDir", "docstring": "", "methods": ["test_get_cache_dir", "test_sys_pycache_prefix_integration"], "attributes": [], "code_location": {"file": "test_assertrewrite.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 2250, "end_line": 2304}, "type": "class"}, {"name": "test_custom_abs_cache_dir", "is_method": true, "class_name": "TestNewAPI", "parameters": ["self", "pytester", "tmp_path_factory"], "calls": ["tmp_path_factory.mktemp", "pytester.makeini", "pytester.makepyfile", "pytester.runpytest", "abs_cache_dir.is_dir"], "code_location": {"file": "test_cacheprovider.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 167, "end_line": 180}, "code_snippet": "    def test_custom_abs_cache_dir(\n        self, pytester: Pytester, tmp_path_factory: TempPathFactory\n    ) -> None:\n        tmp = tmp_path_factory.mktemp(\"tmp\")\n        abs_cache_dir = tmp / \"custom_cache_dir\"\n        pytester.makeini(\n            f\"\"\"\n            [pytest]\n            cache_dir = {abs_cache_dir}\n        \"\"\"\n        )\n        pytester.makepyfile(test_errored=\"def test_error():\\n    assert False\")\n        pytester.runpytest()\n        assert abs_cache_dir.is_dir()\n", "type": "function"}, {"name": "test_cache_makedir", "is_method": false, "class_name": null, "parameters": ["cache"], "calls": ["cache.makedir", "dir.exists", "dir.remove"], "code_location": {"file": "test_legacypath.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 88, "end_line": 91}, "code_snippet": "def test_cache_makedir(cache: pytest.Cache) -> None:\n    dir = cache.makedir(\"foo\")  # type: ignore[attr-defined]\n    assert dir.exists()\n    dir.remove()\n", "type": "function"}, {"name": "test_cache_dir_permissions", "is_method": true, "class_name": "TestNewAPI", "parameters": ["self", "pytester"], "calls": ["pytester.makeini", "pytester.parseconfigure", "config.cache.mkdir", "p.is_dir", "p.parent.stat", "p.stat"], "code_location": {"file": "test_cacheprovider.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 34, "end_line": 47}, "code_snippet": "    def test_cache_dir_permissions(self, pytester: Pytester) -> None:\n        \"\"\"The .pytest_cache directory should have world-readable permissions\n        (depending on umask).\n\n        Regression test for #12308.\n        \"\"\"\n        pytester.makeini(\"[pytest]\")\n        config = pytester.parseconfigure()\n        assert config.cache is not None\n        p = config.cache.mkdir(\"name\")\n        assert p.is_dir()\n        # Instead of messing with umask, make sure .pytest_cache has the same\n        # permissions as the default that `mkdir` gives `p`.\n        assert (p.parent.stat().st_mode & 0o777) == (p.stat().st_mode & 0o777)\n", "type": "function"}, {"name": "test_custom_rel_cache_dir", "is_method": true, "class_name": "TestNewAPI", "parameters": ["self", "pytester"], "calls": ["os.path.join", "pytester.makeini", "pytester.makepyfile", "pytester.runpytest", "is_dir", "pytester.path.joinpath"], "code_location": {"file": "test_cacheprovider.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 155, "end_line": 165}, "code_snippet": "    def test_custom_rel_cache_dir(self, pytester: Pytester) -> None:\n        rel_cache_dir = os.path.join(\"custom_cache_dir\", \"subdir\")\n        pytester.makeini(\n            f\"\"\"\n            [pytest]\n            cache_dir = {rel_cache_dir}\n        \"\"\"\n        )\n        pytester.makepyfile(test_errored=\"def test_error():\\n    assert False\")\n        pytester.runpytest()\n        assert pytester.path.joinpath(rel_cache_dir).is_dir()\n", "type": "function"}, {"name": "test_config_cache_mkdir", "is_method": true, "class_name": "TestNewAPI", "parameters": ["self", "pytester"], "calls": ["pytester.makeini", "pytester.parseconfigure", "config.cache.mkdir", "p.is_dir", "pytest.raises", "config.cache.mkdir"], "code_location": {"file": "test_cacheprovider.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 24, "end_line": 32}, "code_snippet": "    def test_config_cache_mkdir(self, pytester: Pytester) -> None:\n        pytester.makeini(\"[pytest]\")\n        config = pytester.parseconfigure()\n        assert config.cache is not None\n        with pytest.raises(ValueError):\n            config.cache.mkdir(\"key/name\")\n\n        p = config.cache.mkdir(\"name\")\n        assert p.is_dir()\n", "type": "function"}, {"name": "test_cache_reportheader", "is_method": false, "class_name": null, "parameters": ["env", "pytester", "monkeypatch"], "calls": ["pytest.mark.parametrize", "pytester.makepyfile", "pytester.runpytest", "result.stdout.fnmatch_lines", "monkeypatch.setenv", "os.path.join", "monkeypatch.delenv"], "code_location": {"file": "test_cacheprovider.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 198, "end_line": 209}, "code_snippet": "def test_cache_reportheader(\n    env: Sequence[str], pytester: Pytester, monkeypatch: MonkeyPatch\n) -> None:\n    pytester.makepyfile(\"\"\"def test_foo(): pass\"\"\")\n    if env:\n        monkeypatch.setenv(*env)\n        expected = os.path.join(env[1], \".pytest_cache\")\n    else:\n        monkeypatch.delenv(\"TOX_ENV_DIR\", raising=False)\n        expected = \".pytest_cache\"\n    result = pytester.runpytest(\"-v\")\n    result.stdout.fnmatch_lines([f\"cachedir: {expected}\"])\n", "type": "function"}], "retrieved_count": 10, "cost_time": 1.1023094654083252}
{"question": "How does the Skip class integrate with pytest's mark evaluation framework to determine when a test should be skipped, and what is the relationship between the reason attribute and the evaluate_skip_marks() function that produces Skip instances?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"name": "test_marked_skipif_with_boolean_without_reason", "is_method": true, "class_name": "TestEvaluation", "parameters": ["self", "pytester"], "calls": ["pytester.getitem", "pytest.raises", "evaluate_skip_marks"], "code_location": {"file": "test_skipping.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 107, "end_line": 124}, "code_snippet": "    def test_marked_skipif_with_boolean_without_reason(\n        self, pytester: Pytester\n    ) -> None:\n        item = pytester.getitem(\n            \"\"\"\n            import pytest\n            @pytest.mark.skipif(False)\n            def test_func():\n                pass\n        \"\"\"\n        )\n        with pytest.raises(pytest.fail.Exception) as excinfo:\n            evaluate_skip_marks(item)\n        assert excinfo.value.msg is not None\n        assert (\n            \"\"\"Error evaluating 'skipif': you need to specify reason=STRING when using booleans as conditions.\"\"\"\n            in excinfo.value.msg\n        )\n", "type": "function"}, {"name": "evaluate_skip_marks", "is_method": false, "class_name": null, "parameters": ["item"], "calls": ["item.iter_markers", "item.iter_markers", "mark.kwargs.get", "Skip", "evaluate_condition", "Skip", "Skip", "TypeError", "str"], "code_location": {"file": "skipping.py", "path": "/data3/pwh/swebench-repos/pytest/src/_pytest", "start_line": 168, "end_line": 193}, "code_snippet": "def evaluate_skip_marks(item: Item) -> Skip | None:\n    \"\"\"Evaluate skip and skipif marks on item, returning Skip if triggered.\"\"\"\n    for mark in item.iter_markers(name=\"skipif\"):\n        if \"condition\" not in mark.kwargs:\n            conditions = mark.args\n        else:\n            conditions = (mark.kwargs[\"condition\"],)\n\n        # Unconditional.\n        if not conditions:\n            reason = mark.kwargs.get(\"reason\", \"\")\n            return Skip(reason)\n\n        # If any of the conditions are true.\n        for condition in conditions:\n            result, reason = evaluate_condition(item, mark, condition)\n            if result:\n                return Skip(reason)\n\n    for mark in item.iter_markers(name=\"skip\"):\n        try:\n            return Skip(*mark.args, **mark.kwargs)\n        except TypeError as e:\n            raise TypeError(str(e) + \" - maybe you meant pytest.mark.skipif?\") from None\n\n    return None\n", "type": "function"}, {"name": "test_skipif_class", "is_method": true, "class_name": "TestEvaluation", "parameters": ["self", "pytester"], "calls": ["pytester.getitems", "evaluate_skip_marks"], "code_location": {"file": "test_skipping.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 146, "end_line": 159}, "code_snippet": "    def test_skipif_class(self, pytester: Pytester) -> None:\n        (item,) = pytester.getitems(\n            \"\"\"\n            import pytest\n            class TestClass(object):\n                pytestmark = pytest.mark.skipif(\"config._hackxyz\")\n                def test_func(self):\n                    pass\n        \"\"\"\n        )\n        item.config._hackxyz = 3  # type: ignore[attr-defined]\n        skipped = evaluate_skip_marks(item)\n        assert skipped\n        assert skipped.reason == \"condition: config._hackxyz\"\n", "type": "function"}, {"name": "test_marked_skipif_with_invalid_boolean", "is_method": true, "class_name": "TestEvaluation", "parameters": ["self", "pytester"], "calls": ["pytester.getitem", "pytest.raises", "evaluate_skip_marks"], "code_location": {"file": "test_skipping.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 126, "end_line": 144}, "code_snippet": "    def test_marked_skipif_with_invalid_boolean(self, pytester: Pytester) -> None:\n        item = pytester.getitem(\n            \"\"\"\n            import pytest\n\n            class InvalidBool:\n                def __bool__(self):\n                    raise TypeError(\"INVALID\")\n\n            @pytest.mark.skipif(InvalidBool(), reason=\"xxx\")\n            def test_func():\n                pass\n        \"\"\"\n        )\n        with pytest.raises(pytest.fail.Exception) as excinfo:\n            evaluate_skip_marks(item)\n        assert excinfo.value.msg is not None\n        assert \"Error evaluating 'skipif' condition as a boolean\" in excinfo.value.msg\n        assert \"INVALID\" in excinfo.value.msg\n", "type": "function"}, {"name": "test_marked_one_arg_with_reason", "is_method": true, "class_name": "TestEvaluation", "parameters": ["self", "pytester"], "calls": ["pytester.getitem", "evaluate_skip_marks"], "code_location": {"file": "test_skipping.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 61, "end_line": 72}, "code_snippet": "    def test_marked_one_arg_with_reason(self, pytester: Pytester) -> None:\n        item = pytester.getitem(\n            \"\"\"\n            import pytest\n            @pytest.mark.skipif(\"hasattr(os, 'sep')\", attr=2, reason=\"hello world\")\n            def test_func():\n                pass\n        \"\"\"\n        )\n        skipped = evaluate_skip_marks(item)\n        assert skipped\n        assert skipped.reason == \"hello world\"\n", "type": "function"}, {"name": "test_marked_skipif_no_args", "is_method": true, "class_name": "TestEvaluation", "parameters": ["self", "pytester"], "calls": ["pytester.getitem", "evaluate_skip_marks"], "code_location": {"file": "test_skipping.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 35, "end_line": 46}, "code_snippet": "    def test_marked_skipif_no_args(self, pytester: Pytester) -> None:\n        item = pytester.getitem(\n            \"\"\"\n            import pytest\n            @pytest.mark.skipif\n            def test_func():\n                pass\n        \"\"\"\n        )\n        skipped = evaluate_skip_marks(item)\n        assert skipped\n        assert skipped.reason == \"\"\n", "type": "function"}, {"name": "test_skip_no_reason", "is_method": true, "class_name": "TestSkip", "parameters": ["self", "pytester"], "calls": ["pytester.makepyfile", "pytester.runpytest", "result.stdout.fnmatch_lines"], "code_location": {"file": "test_skipping.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 813, "end_line": 823}, "code_snippet": "    def test_skip_no_reason(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n            @pytest.mark.skip\n            def test_foo():\n                pass\n        \"\"\"\n        )\n        result = pytester.runpytest(\"-rs\")\n        result.stdout.fnmatch_lines([\"*unconditional skip*\", \"*1 skipped*\"])\n", "type": "function"}, {"name": "test_skip_with_reason", "is_method": true, "class_name": "TestSkip", "parameters": ["self", "pytester"], "calls": ["pytester.makepyfile", "pytester.runpytest", "result.stdout.fnmatch_lines"], "code_location": {"file": "test_skipping.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 825, "end_line": 835}, "code_snippet": "    def test_skip_with_reason(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n            @pytest.mark.skip(reason=\"for lolz\")\n            def test_bar():\n                pass\n        \"\"\"\n        )\n        result = pytester.runpytest(\"-rs\")\n        result.stdout.fnmatch_lines([\"*for lolz*\", \"*1 skipped*\"])\n", "type": "function"}, {"name": "test_skipif_noreason", "is_method": true, "class_name": "TestBooleanCondition", "parameters": ["self", "pytester"], "calls": ["pytester.makepyfile", "pytester.runpytest", "result.stdout.fnmatch_lines"], "code_location": {"file": "test_skipping.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 1267, "end_line": 1281}, "code_snippet": "    def test_skipif_noreason(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n            @pytest.mark.skipif(True)\n            def test_func():\n                pass\n        \"\"\"\n        )\n        result = pytester.runpytest(\"-rs\")\n        result.stdout.fnmatch_lines(\n            \"\"\"\n            *1 error*\n        \"\"\"\n        )\n", "type": "function"}, {"name": "addSkip", "is_method": true, "class_name": "TestCaseFunction", "parameters": ["self", "testcase", "reason"], "calls": ["pytest.skip.Exception", "self._addexcinfo", "sys.exc_info"], "code_location": {"file": "unittest.py", "path": "/data3/pwh/swebench-repos/pytest/src/_pytest", "start_line": 282, "end_line": 286}, "code_snippet": "    def addSkip(self, testcase: unittest.TestCase, reason: str) -> None:\n        try:\n            raise pytest.skip.Exception(reason, _use_item_location=True)\n        except skip.Exception:\n            self._addexcinfo(sys.exc_info())\n", "type": "function"}], "retrieved_count": 10, "cost_time": 1.1232197284698486}
{"question": "How does the FastFilesCompleter.__call__ method reconcile the dual glob expansion strategies for handling hidden files versus wildcard patterns, and what is the algorithmic consequence of applying prefix_dir stripping after sorting?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"name": "__call__", "is_method": true, "class_name": "FastFilesCompleter", "parameters": ["self", "prefix"], "calls": ["globbed.extend", "sorted", "len", "glob", "os.path.isdir", "completion.append", "globbed.extend", "os.path.dirname", "glob"], "code_location": {"file": "_argcomplete.py", "path": "/data3/pwh/swebench-repos/pytest/src/_pytest", "start_line": 80, "end_line": 99}, "code_snippet": "    def __call__(self, prefix: str, **kwargs: Any) -> list[str]:\n        # Only called on non option completions.\n        if os.sep in prefix[1:]:\n            prefix_dir = len(os.path.dirname(prefix) + os.sep)\n        else:\n            prefix_dir = 0\n        completion = []\n        globbed = []\n        if \"*\" not in prefix and \"?\" not in prefix:\n            # We are on unix, otherwise no bash.\n            if not prefix or prefix[-1] == os.sep:\n                globbed.extend(glob(prefix + \".*\"))\n            prefix += \"*\"\n        globbed.extend(glob(prefix))\n        for x in sorted(globbed):\n            if os.path.isdir(x):\n                x += \"/\"\n            # Append stripping the prefix (like bash, not like compgen).\n            completion.append(x[prefix_dir:])\n        return completion\n", "type": "function"}, {"name": "__call__", "is_method": true, "class_name": "FilesCompleter", "parameters": ["self", "prefix"], "calls": ["_wrapcall", "_wrapcall", "list", "_wrapcall", "_wrapcall", "set", "set"], "code_location": {"file": "test_argcomplete.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 50, "end_line": 69}, "code_snippet": "    def __call__(self, prefix, **kwargs):\n        completion = []\n        if self.allowednames:\n            if self.directories:\n                files = _wrapcall([\"bash\", \"-c\", f\"compgen -A directory -- '{prefix}'\"])\n                completion += [f + \"/\" for f in files]\n            for x in self.allowednames:\n                completion += _wrapcall(\n                    [\"bash\", \"-c\", f\"compgen -A file -X '!*.{x}' -- '{prefix}'\"]\n                )\n        else:\n            completion += _wrapcall([\"bash\", \"-c\", f\"compgen -A file -- '{prefix}'\"])\n\n            anticomp = _wrapcall([\"bash\", \"-c\", f\"compgen -A directory -- '{prefix}'\"])\n\n            completion = list(set(completion) - set(anticomp))\n\n            if self.directories:\n                completion += [f + \"/\" for f in anticomp]\n        return completion\n", "type": "function"}, {"name": "test_remove_dir_prefix", "is_method": true, "class_name": "TestArgComplete", "parameters": ["self"], "calls": ["pytest.mark.skipif", "FastFilesCompleter", "FilesCompleter", "split", "equal_with_bash"], "code_location": {"file": "test_argcomplete.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 92, "end_line": 99}, "code_snippet": "    def test_remove_dir_prefix(self):\n        \"\"\"This is not compatible with compgen but it is with bash itself: ls /usr/<TAB>.\"\"\"\n        from _pytest._argcomplete import FastFilesCompleter\n\n        ffc = FastFilesCompleter()\n        fc = FilesCompleter()\n        for x in \"/usr/\".split():\n            assert not equal_with_bash(x, ffc, fc, out=sys.stdout)\n", "type": "function"}, {"name": "test_compare_with_compgen", "is_method": true, "class_name": "TestArgComplete", "parameters": ["self", "tmp_path", "monkeypatch"], "calls": ["pytest.mark.skipif", "FastFilesCompleter", "FilesCompleter", "monkeypatch.chdir", "equal_with_bash", "touch", "equal_with_bash", "joinpath", "tmp_path.cwd"], "code_location": {"file": "test_argcomplete.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 74, "end_line": 89}, "code_snippet": "    def test_compare_with_compgen(\n        self, tmp_path: Path, monkeypatch: MonkeyPatch\n    ) -> None:\n        from _pytest._argcomplete import FastFilesCompleter\n\n        ffc = FastFilesCompleter()\n        fc = FilesCompleter()\n\n        monkeypatch.chdir(tmp_path)\n\n        assert equal_with_bash(\"\", ffc, fc, out=sys.stdout)\n\n        tmp_path.cwd().joinpath(\"data\").touch()\n\n        for x in [\"d\", \"data\", \"doesnotexist\", \"\"]:\n            assert equal_with_bash(x, ffc, fc, out=sys.stdout)\n", "type": "function"}, {"name": "__init__", "is_method": true, "class_name": "Visitor", "parameters": ["self", "fil", "rec", "ignore", "bf", "sort"], "calls": ["isinstance", "isinstance", "FNMatcher", "FNMatcher", "cast", "hasattr"], "code_location": {"file": "path.py", "path": "/data3/pwh/swebench-repos/pytest/src/_pytest/_py", "start_line": 139, "end_line": 151}, "code_snippet": "    def __init__(self, fil, rec, ignore, bf, sort):\n        if isinstance(fil, str):\n            fil = FNMatcher(fil)\n        if isinstance(rec, str):\n            self.rec: Callable[[LocalPath], bool] = FNMatcher(rec)\n        elif not hasattr(rec, \"__call__\") and rec:\n            self.rec = lambda path: True\n        else:\n            self.rec = rec\n        self.fil = fil\n        self.ignore = ignore\n        self.breadthfirst = bf\n        self.optsort = cast(Callable[[Any], Any], sorted) if sort else (lambda x: x)\n", "type": "function"}, {"name": "__call__", "is_method": true, "class_name": "FNMatcher", "parameters": ["self", "path"], "calls": ["fnmatch.fnmatch", "pattern.replace", "pattern.find", "str", "pattern.find", "pattern.find", "os.path.isabs"], "code_location": {"file": "path.py", "path": "/data3/pwh/swebench-repos/pytest/src/_pytest/_py", "start_line": 177, "end_line": 196}, "code_snippet": "    def __call__(self, path):\n        pattern = self.pattern\n\n        if (\n            pattern.find(path.sep) == -1\n            and iswin32\n            and pattern.find(posixpath.sep) != -1\n        ):\n            # Running on Windows, the pattern has no Windows path separators,\n            # and the pattern has one or more Posix path separators. Replace\n            # the Posix path separators with the Windows path separator.\n            pattern = pattern.replace(posixpath.sep, path.sep)\n\n        if pattern.find(path.sep) == -1:\n            name = path.basename\n        else:\n            name = str(path)  # path.strpath # XXX svn?\n            if not os.path.isabs(pattern):\n                pattern = \"*\" + path.sep + pattern\n        return fnmatch.fnmatch(name, pattern)\n", "type": "function"}, {"name": "test_visit_rec_fnmatch", "is_method": true, "class_name": "TestLocalPath", "parameters": ["self", "tmpdir"], "calls": ["tmpdir.ensure", "tmpdir.ensure", "list", "tmpdir.visit", "len"], "code_location": {"file": "test_local.py", "path": "/data3/pwh/swebench-repos/pytest/testing/_py", "start_line": 843, "end_line": 849}, "code_snippet": "    def test_visit_rec_fnmatch(self, tmpdir):\n        p1 = tmpdir.ensure(\"a\", \"123\")\n        tmpdir.ensure(\".b\", \"345\")\n        lst = list(tmpdir.visit(\"???\", rec=\"[!.]*\"))\n        assert len(lst) == 1\n        # check that breadth comes last\n        assert lst[0] == p1\n", "type": "function"}, {"name": "collect", "is_method": true, "class_name": "Package", "parameters": ["self"], "calls": ["scandir", "direntry.is_dir", "Path", "ihook.pytest_collect_directory", "direntry.is_file", "self.session.isinitpath", "ihook.pytest_ignore_collect", "Path", "ihook.pytest_collect_file", "self.session.isinitpath", "ihook.pytest_ignore_collect"], "code_location": {"file": "python.py", "path": "/data3/pwh/swebench-repos/pytest/src/_pytest", "start_line": 685, "end_line": 710}, "code_snippet": "    def collect(self) -> Iterable[nodes.Item | nodes.Collector]:\n        # Always collect __init__.py first.\n        def sort_key(entry: os.DirEntry[str]) -> object:\n            return (entry.name != \"__init__.py\", entry.name)\n\n        config = self.config\n        col: nodes.Collector | None\n        cols: Sequence[nodes.Collector]\n        ihook = self.ihook\n        for direntry in scandir(self.path, sort_key):\n            if direntry.is_dir():\n                path = Path(direntry.path)\n                if not self.session.isinitpath(path, with_parents=True):\n                    if ihook.pytest_ignore_collect(collection_path=path, config=config):\n                        continue\n                col = ihook.pytest_collect_directory(path=path, parent=self)\n                if col is not None:\n                    yield col\n\n            elif direntry.is_file():\n                path = Path(direntry.path)\n                if not self.session.isinitpath(path):\n                    if ihook.pytest_ignore_collect(collection_path=path, config=config):\n                        continue\n                cols = ihook.pytest_collect_file(file_path=path, parent=self)\n                yield from cols\n", "type": "function"}, {"name": "pytest_make_collect_report", "is_method": true, "class_name": "LFPluginCollWrapper", "parameters": ["self", "collector"], "calls": ["hookimpl", "isinstance", "sorted", "isinstance", "self.lfplugin.config.pluginmanager.register", "any", "LFPluginCollSkipfiles", "session.isinitpath", "isinstance"], "code_location": {"file": "cacheprovider.py", "path": "/data3/pwh/swebench-repos/pytest/src/_pytest", "start_line": 255, "end_line": 298}, "code_snippet": "    def pytest_make_collect_report(\n        self, collector: nodes.Collector\n    ) -> Generator[None, CollectReport, CollectReport]:\n        res = yield\n        if isinstance(collector, (Session, Directory)):\n            # Sort any lf-paths to the beginning.\n            lf_paths = self.lfplugin._last_failed_paths\n\n            # Use stable sort to prioritize last failed.\n            def sort_key(node: nodes.Item | nodes.Collector) -> bool:\n                return node.path in lf_paths\n\n            res.result = sorted(\n                res.result,\n                key=sort_key,\n                reverse=True,\n            )\n\n        elif isinstance(collector, File):\n            if collector.path in self.lfplugin._last_failed_paths:\n                result = res.result\n                lastfailed = self.lfplugin.lastfailed\n\n                # Only filter with known failures.\n                if not self._collected_at_least_one_failure:\n                    if not any(x.nodeid in lastfailed for x in result):\n                        return res\n                    self.lfplugin.config.pluginmanager.register(\n                        LFPluginCollSkipfiles(self.lfplugin), \"lfplugin-collskip\"\n                    )\n                    self._collected_at_least_one_failure = True\n\n                session = collector.session\n                result[:] = [\n                    x\n                    for x in result\n                    if x.nodeid in lastfailed\n                    # Include any passed arguments (not trivial to filter).\n                    or session.isinitpath(x.path)\n                    # Keep all sub-collectors.\n                    or isinstance(x, nodes.Collector)\n                ]\n\n        return res\n", "type": "function"}, {"name": "collect", "is_method": true, "class_name": "Session", "parameters": ["self"], "calls": ["self.trace", "argpath.is_dir", "module_name.split", "enumerate", "work.pop", "isinstance", "reversed", "join", "self._notfound.append", "paths.insert", "paths.insert", "isinstance", "isinstance", "matchnode._collect_path", "self._collect_one_node", "isinstance", "notfound_collectors.append", "pm._is_in_confcutdir", "matchnode.ihook.pytest_collectreport", "work.append", "str", "len", "isinstance", "is_file", "os.path.samefile", "len", "os.path.islink", "os.path.islink", "node.name.split"], "code_location": {"file": "main.py", "path": "/data3/pwh/swebench-repos/pytest/src/_pytest", "start_line": 847, "end_line": 966}, "code_snippet": "    def collect(self) -> Iterator[nodes.Item | nodes.Collector]:\n        # This is a cache for the root directories of the initial paths.\n        # We can't use collection_cache for Session because of its special\n        # role as the bootstrapping collector.\n        path_cache: dict[Path, Sequence[nodes.Collector]] = {}\n\n        pm = self.config.pluginmanager\n\n        for collection_argument in self._initial_parts:\n            self.trace(\"processing argument\", collection_argument)\n            self.trace.root.indent += 1\n\n            argpath = collection_argument.path\n            names = collection_argument.parts\n            module_name = collection_argument.module_name\n\n            # resolve_collection_argument() ensures this.\n            if argpath.is_dir():\n                assert not names, f\"invalid arg {(argpath, names)!r}\"\n\n            paths = [argpath]\n            # Add relevant parents of the path, from the root, e.g.\n            #   /a/b/c.py -> [/, /a, /a/b, /a/b/c.py]\n            if module_name is None:\n                # Paths outside of the confcutdir should not be considered.\n                for path in argpath.parents:\n                    if not pm._is_in_confcutdir(path):\n                        break\n                    paths.insert(0, path)\n            else:\n                # For --pyargs arguments, only consider paths matching the module\n                # name. Paths beyond the package hierarchy are not included.\n                module_name_parts = module_name.split(\".\")\n                for i, path in enumerate(argpath.parents, 2):\n                    if i > len(module_name_parts) or path.stem != module_name_parts[-i]:\n                        break\n                    paths.insert(0, path)\n\n            # Start going over the parts from the root, collecting each level\n            # and discarding all nodes which don't match the level's part.\n            any_matched_in_initial_part = False\n            notfound_collectors = []\n            work: list[tuple[nodes.Collector | nodes.Item, list[Path | str]]] = [\n                (self, [*paths, *names])\n            ]\n            while work:\n                matchnode, matchparts = work.pop()\n\n                # Pop'd all of the parts, this is a match.\n                if not matchparts:\n                    yield matchnode\n                    any_matched_in_initial_part = True\n                    continue\n\n                # Should have been matched by now, discard.\n                if not isinstance(matchnode, nodes.Collector):\n                    continue\n\n                # Collect this level of matching.\n                # Collecting Session (self) is done directly to avoid endless\n                # recursion to this function.\n                subnodes: Sequence[nodes.Collector | nodes.Item]\n                if isinstance(matchnode, Session):\n                    assert isinstance(matchparts[0], Path)\n                    subnodes = matchnode._collect_path(matchparts[0], path_cache)\n                else:\n                    # For backward compat, files given directly multiple\n                    # times on the command line should not be deduplicated.\n                    handle_dupes = not (\n                        len(matchparts) == 1\n                        and isinstance(matchparts[0], Path)\n                        and matchparts[0].is_file()\n                    )\n                    rep, duplicate = self._collect_one_node(matchnode, handle_dupes)\n                    if not duplicate and not rep.passed:\n                        # Report collection failures here to avoid failing to\n                        # run some test specified in the command line because\n                        # the module could not be imported (#134).\n                        matchnode.ihook.pytest_collectreport(report=rep)\n                    if not rep.passed:\n                        continue\n                    subnodes = rep.result\n\n                # Prune this level.\n                any_matched_in_collector = False\n                for node in reversed(subnodes):\n                    # Path part e.g. `/a/b/` in `/a/b/test_file.py::TestIt::test_it`.\n                    if isinstance(matchparts[0], Path):\n                        is_match = node.path == matchparts[0]\n                        if sys.platform == \"win32\" and not is_match:\n                            # In case the file paths do not match, fallback to samefile() to\n                            # account for short-paths on Windows (#11895).\n                            same_file = os.path.samefile(node.path, matchparts[0])\n                            # We don't want to match links to the current node,\n                            # otherwise we would match the same file more than once (#12039).\n                            is_match = same_file and (\n                                os.path.islink(node.path)\n                                == os.path.islink(matchparts[0])\n                            )\n\n                    # Name part e.g. `TestIt` in `/a/b/test_file.py::TestIt::test_it`.\n                    else:\n                        # TODO: Remove parametrized workaround once collection structure contains\n                        # parametrization.\n                        is_match = (\n                            node.name == matchparts[0]\n                            or node.name.split(\"[\")[0] == matchparts[0]\n                        )\n                    if is_match:\n                        work.append((node, matchparts[1:]))\n                        any_matched_in_collector = True\n\n                if not any_matched_in_collector:\n                    notfound_collectors.append(matchnode)\n\n            if not any_matched_in_initial_part:\n                report_arg = \"::\".join((str(argpath), *names))\n                self._notfound.append((report_arg, notfound_collectors))\n\n            self.trace.root.indent -= 1\n", "type": "function"}], "retrieved_count": 10, "cost_time": 1.123361349105835}
{"question": "What is the failure mechanism when the parametrize method's validation of indirect parameter names detects that an indirect parameter references a non-existent function argument, and how does this depend on the function signature?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"name": "test_parametrize_indirect_wrong_type", "is_method": true, "class_name": "TestMetafunc", "parameters": ["self"], "calls": ["self.Metafunc", "pytest.raises", "metafunc.parametrize"], "code_location": {"file": "metafunc.py", "path": "/data3/pwh/swebench-repos/pytest/testing/python", "start_line": 807, "end_line": 816}, "code_snippet": "    def test_parametrize_indirect_wrong_type(self) -> None:\n        def func(x, y):\n            pass\n\n        metafunc = self.Metafunc(func)\n        with pytest.raises(\n            fail.Exception,\n            match=\"In func: expected Sequence or boolean for indirect, got dict\",\n        ):\n            metafunc.parametrize(\"x, y\", [(\"a\", \"b\")], indirect={})  # type: ignore[arg-type]\n", "type": "function"}, {"name": "test_parametrize_onearg_indirect", "is_method": true, "class_name": "TestMetafunc", "parameters": ["self"], "calls": ["self.Metafunc", "metafunc.parametrize", "dict", "dict"], "code_location": {"file": "metafunc.py", "path": "/data3/pwh/swebench-repos/pytest/testing/python", "start_line": 1004, "end_line": 1010}, "code_snippet": "    def test_parametrize_onearg_indirect(self) -> None:\n        metafunc = self.Metafunc(lambda x: None)\n        metafunc.parametrize(\"x\", [1, 2], indirect=True)\n        assert metafunc._calls[0].params == dict(x=1)\n        assert metafunc._calls[0].id == \"1\"\n        assert metafunc._calls[1].params == dict(x=2)\n        assert metafunc._calls[1].id == \"2\"\n", "type": "function"}, {"name": "test_parametrize_and_inner_getfixturevalue", "is_method": true, "class_name": "TestMetafuncFunctional", "parameters": ["self", "pytester"], "calls": ["pytester.makepyfile", "pytester.runpytest", "result.stdout.fnmatch_lines"], "code_location": {"file": "metafunc.py", "path": "/data3/pwh/swebench-repos/pytest/testing/python", "start_line": 1258, "end_line": 1280}, "code_snippet": "    def test_parametrize_and_inner_getfixturevalue(self, pytester: Pytester) -> None:\n        p = pytester.makepyfile(\n            \"\"\"\n            def pytest_generate_tests(metafunc):\n                metafunc.parametrize(\"arg1\", [1], indirect=True)\n                metafunc.parametrize(\"arg2\", [10], indirect=True)\n\n            import pytest\n            @pytest.fixture\n            def arg1(request):\n                x = request.getfixturevalue(\"arg2\")\n                return x + request.param\n\n            @pytest.fixture\n            def arg2(request):\n                return request.param\n\n            def test_func1(arg1, arg2):\n                assert arg1 == 11\n        \"\"\"\n        )\n        result = pytester.runpytest(\"-v\", p)\n        result.stdout.fnmatch_lines([\"*test_func1*1*PASS*\", \"*1 passed*\"])\n", "type": "function"}, {"name": "test_parametrize_on_setup_arg", "is_method": true, "class_name": "TestMetafuncFunctional", "parameters": ["self", "pytester"], "calls": ["pytester.makepyfile", "pytester.runpytest", "result.stdout.fnmatch_lines"], "code_location": {"file": "metafunc.py", "path": "/data3/pwh/swebench-repos/pytest/testing/python", "start_line": 1282, "end_line": 1303}, "code_snippet": "    def test_parametrize_on_setup_arg(self, pytester: Pytester) -> None:\n        p = pytester.makepyfile(\n            \"\"\"\n            def pytest_generate_tests(metafunc):\n                assert \"arg1\" in metafunc.fixturenames\n                metafunc.parametrize(\"arg1\", [1], indirect=True)\n\n            import pytest\n            @pytest.fixture\n            def arg1(request):\n                return request.param\n\n            @pytest.fixture\n            def arg2(request, arg1):\n                return 10 * arg1\n\n            def test_func(arg2):\n                assert arg2 == 10\n        \"\"\"\n        )\n        result = pytester.runpytest(\"-v\", p)\n        result.stdout.fnmatch_lines([\"*test_func*1*PASS*\", \"*1 passed*\"])\n", "type": "function"}, {"name": "_resolve_args_directness", "is_method": true, "class_name": "Metafunc", "parameters": ["self", "argnames", "indirect"], "calls": ["isinstance", "dict.fromkeys", "isinstance", "dict.fromkeys", "fail", "fail", "type"], "code_location": {"file": "python.py", "path": "/data3/pwh/swebench-repos/pytest/src/_pytest", "start_line": 1417, "end_line": 1454}, "code_snippet": "    def _resolve_args_directness(\n        self,\n        argnames: Sequence[str],\n        indirect: bool | Sequence[str],\n    ) -> dict[str, Literal[\"indirect\", \"direct\"]]:\n        \"\"\"Resolve if each parametrized argument must be considered an indirect\n        parameter to a fixture of the same name, or a direct parameter to the\n        parametrized function, based on the ``indirect`` parameter of the\n        parametrized() call.\n\n        :param argnames:\n            List of argument names passed to ``parametrize()``.\n        :param indirect:\n            Same as the ``indirect`` parameter of ``parametrize()``.\n        :returns\n            A dict mapping each arg name to either \"indirect\" or \"direct\".\n        \"\"\"\n        arg_directness: dict[str, Literal[\"indirect\", \"direct\"]]\n        if isinstance(indirect, bool):\n            arg_directness = dict.fromkeys(\n                argnames, \"indirect\" if indirect else \"direct\"\n            )\n        elif isinstance(indirect, Sequence):\n            arg_directness = dict.fromkeys(argnames, \"direct\")\n            for arg in indirect:\n                if arg not in argnames:\n                    fail(\n                        f\"In {self.function.__name__}: indirect fixture '{arg}' doesn't exist\",\n                        pytrace=False,\n                    )\n                arg_directness[arg] = \"indirect\"\n        else:\n            fail(\n                f\"In {self.function.__name__}: expected Sequence or boolean\"\n                f\" for indirect, got {type(indirect).__name__}\",\n                pytrace=False,\n            )\n        return arg_directness\n", "type": "function"}, {"name": "test_parametrize_error", "is_method": true, "class_name": "TestMetafunc", "parameters": ["self"], "calls": ["self.Metafunc", "metafunc.parametrize", "metafunc.parametrize", "pytest.raises", "metafunc.parametrize", "pytest.raises", "metafunc.parametrize", "pytest.raises", "metafunc.parametrize", "pytest.raises", "metafunc.parametrize", "pytest.raises", "metafunc.parametrize"], "code_location": {"file": "metafunc.py", "path": "/data3/pwh/swebench-repos/pytest/testing/python", "start_line": 79, "end_line": 96}, "code_snippet": "    def test_parametrize_error(self) -> None:\n        def func(x, y):\n            pass\n\n        metafunc = self.Metafunc(func)\n        metafunc.parametrize(\"x\", [1, 2])\n        with pytest.raises(pytest.Collector.CollectError):\n            metafunc.parametrize(\"x\", [5, 6])\n        with pytest.raises(pytest.Collector.CollectError):\n            metafunc.parametrize(\"x\", [5, 6])\n        metafunc.parametrize(\"y\", [1, 2])\n        with pytest.raises(pytest.Collector.CollectError):\n            metafunc.parametrize(\"y\", [5, 6])\n        with pytest.raises(pytest.Collector.CollectError):\n            metafunc.parametrize(\"y\", [5, 6])\n\n        with pytest.raises(TypeError, match=\"^ids must be a callable or an iterable$\"):\n            metafunc.parametrize(\"y\", [5, 6], ids=42)  # type: ignore[arg-type]\n", "type": "function"}, {"name": "test_fixture_param_shadowing", "is_method": false, "class_name": null, "parameters": ["pytester"], "calls": ["pytester.makepyfile", "pytester.runpytest", "result.assert_outcomes", "result.stdout.fnmatch_lines", "result.stdout.fnmatch_lines", "result.stdout.fnmatch_lines", "result.stdout.fnmatch_lines"], "code_location": {"file": "fixtures.py", "path": "/data3/pwh/swebench-repos/pytest/testing/python", "start_line": 4613, "end_line": 4653}, "code_snippet": "def test_fixture_param_shadowing(pytester: Pytester) -> None:\n    \"\"\"Parametrized arguments would be shadowed if a fixture with the same name also exists (#5036)\"\"\"\n    pytester.makepyfile(\n        \"\"\"\n        import pytest\n\n        @pytest.fixture(params=['a', 'b'])\n        def argroot(request):\n            return request.param\n\n        @pytest.fixture\n        def arg(argroot):\n            return argroot\n\n        # This should only be parametrized directly\n        @pytest.mark.parametrize(\"arg\", [1])\n        def test_direct(arg):\n            assert arg == 1\n\n        # This should be parametrized based on the fixtures\n        def test_normal_fixture(arg):\n            assert isinstance(arg, str)\n\n        # Indirect should still work:\n\n        @pytest.fixture\n        def arg2(request):\n            return 2*request.param\n\n        @pytest.mark.parametrize(\"arg2\", [1], indirect=True)\n        def test_indirect(arg2):\n            assert arg2 == 2\n    \"\"\"\n    )\n    # Only one test should have run\n    result = pytester.runpytest(\"-v\")\n    result.assert_outcomes(passed=4)\n    result.stdout.fnmatch_lines([\"*::test_direct[[]1[]]*\"])\n    result.stdout.fnmatch_lines([\"*::test_normal_fixture[[]a[]]*\"])\n    result.stdout.fnmatch_lines([\"*::test_normal_fixture[[]b[]]*\"])\n    result.stdout.fnmatch_lines([\"*::test_indirect[[]1[]]*\"])\n", "type": "function"}, {"name": "test_parametrize_gives_indicative_error_on_function_with_default_argument", "is_method": true, "class_name": "TestMetafunc", "parameters": ["self", "pytester"], "calls": ["pytester.makepyfile", "pytester.runpytest", "result.stdout.fnmatch_lines"], "code_location": {"file": "metafunc.py", "path": "/data3/pwh/swebench-repos/pytest/testing/python", "start_line": 957, "end_line": 972}, "code_snippet": "    def test_parametrize_gives_indicative_error_on_function_with_default_argument(\n        self, pytester: Pytester\n    ) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n\n            @pytest.mark.parametrize('x, y', [('a', 'b')])\n            def test_simple(x, y=1):\n                assert len(x) == 1\n        \"\"\"\n        )\n        result = pytester.runpytest(\"--collect-only\")\n        result.stdout.fnmatch_lines(\n            [\"*already takes an argument 'y' with a default value\"]\n        )\n", "type": "function"}, {"name": "test_parametrize_overrides_indirect_dependency_fixture", "is_method": true, "class_name": "TestFunction", "parameters": ["self", "pytester"], "calls": ["pytester.makepyfile", "pytester.inline_run", "rec.assertoutcome"], "code_location": {"file": "collect.py", "path": "/data3/pwh/swebench-repos/pytest/testing/python", "start_line": 527, "end_line": 558}, "code_snippet": "    def test_parametrize_overrides_indirect_dependency_fixture(\n        self, pytester: Pytester\n    ) -> None:\n        \"\"\"Test parametrization when parameter overrides a fixture that a test indirectly depends on\"\"\"\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n\n            fix3_instantiated = False\n\n            @pytest.fixture\n            def fix1(fix2):\n               return fix2 + '1'\n\n            @pytest.fixture\n            def fix2(fix3):\n               return fix3 + '2'\n\n            @pytest.fixture\n            def fix3():\n               global fix3_instantiated\n               fix3_instantiated = True\n               return '3'\n\n            @pytest.mark.parametrize('fix2', ['2'])\n            def test_it(fix1):\n               assert fix1 == '21'\n               assert not fix3_instantiated\n        \"\"\"\n        )\n        rec = pytester.inline_run()\n        rec.assertoutcome(passed=1)\n", "type": "function"}, {"name": "test_parametrize_auto_scope_indirect", "is_method": true, "class_name": "TestMetafuncFunctionalAuto", "parameters": ["self", "pytester"], "calls": ["pytester.makepyfile", "pytester.runpytest", "result.stdout.fnmatch_lines"], "code_location": {"file": "metafunc.py", "path": "/data3/pwh/swebench-repos/pytest/testing/python", "start_line": 1712, "end_line": 1733}, "code_snippet": "    def test_parametrize_auto_scope_indirect(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n\n            @pytest.fixture(scope='session')\n            def echo(request):\n                return request.param\n\n            @pytest.mark.parametrize('animal, echo', [(\"dog\", 1), (\"cat\", 2)], indirect=['echo'])\n            def test_1(animal, echo):\n                assert animal in ('dog', 'cat')\n                assert echo in (1, 2, 3)\n\n            @pytest.mark.parametrize('animal, echo', [('fish', 3)], indirect=['echo'])\n            def test_2(animal, echo):\n                assert animal == 'fish'\n                assert echo in (1, 2, 3)\n        \"\"\"\n        )\n        result = pytester.runpytest()\n        result.stdout.fnmatch_lines([\"* 3 passed *\"])\n", "type": "function"}], "retrieved_count": 10, "cost_time": 1.1312894821166992}
{"question": "How does pytest's indirect parametrization mechanism resolve non-hashable dictionary items through fixture request parameters, and what internal transformations occur when parametrize decorators process mutable objects that cannot be used as cache keys?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"name": "test_parametrize_with_non_hashable_values_indirect", "is_method": true, "class_name": "TestFunction", "parameters": ["self", "pytester"], "calls": ["pytester.makepyfile", "pytester.inline_run", "rec.assertoutcome"], "code_location": {"file": "collect.py", "path": "/data3/pwh/swebench-repos/pytest/testing/python", "start_line": 446, "end_line": 475}, "code_snippet": "    def test_parametrize_with_non_hashable_values_indirect(\n        self, pytester: Pytester\n    ) -> None:\n        \"\"\"Test parametrization with non-hashable values with indirect parametrization.\"\"\"\n        pytester.makepyfile(\n            \"\"\"\n            archival_mapping = {\n                '1.0': {'tag': '1.0'},\n                '1.2.2a1': {'tag': 'release-1.2.2a1'},\n            }\n\n            import pytest\n\n            @pytest.fixture\n            def key(request):\n                return request.param\n\n            @pytest.fixture\n            def value(request):\n                return request.param\n\n            @pytest.mark.parametrize('key value'.split(),\n                                     archival_mapping.items(), indirect=True)\n            def test_archival_to_version(key, value):\n                assert key in archival_mapping\n                assert value == archival_mapping[key]\n        \"\"\"\n        )\n        rec = pytester.inline_run()\n        rec.assertoutcome(passed=2)\n", "type": "function"}, {"name": "test_parametrize_auto_scope_indirect", "is_method": true, "class_name": "TestMetafuncFunctionalAuto", "parameters": ["self", "pytester"], "calls": ["pytester.makepyfile", "pytester.runpytest", "result.stdout.fnmatch_lines"], "code_location": {"file": "metafunc.py", "path": "/data3/pwh/swebench-repos/pytest/testing/python", "start_line": 1712, "end_line": 1733}, "code_snippet": "    def test_parametrize_auto_scope_indirect(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n\n            @pytest.fixture(scope='session')\n            def echo(request):\n                return request.param\n\n            @pytest.mark.parametrize('animal, echo', [(\"dog\", 1), (\"cat\", 2)], indirect=['echo'])\n            def test_1(animal, echo):\n                assert animal in ('dog', 'cat')\n                assert echo in (1, 2, 3)\n\n            @pytest.mark.parametrize('animal, echo', [('fish', 3)], indirect=['echo'])\n            def test_2(animal, echo):\n                assert animal == 'fish'\n                assert echo in (1, 2, 3)\n        \"\"\"\n        )\n        result = pytester.runpytest()\n        result.stdout.fnmatch_lines([\"* 3 passed *\"])\n", "type": "function"}, {"name": "test_parametrize_and_inner_getfixturevalue", "is_method": true, "class_name": "TestMetafuncFunctional", "parameters": ["self", "pytester"], "calls": ["pytester.makepyfile", "pytester.runpytest", "result.stdout.fnmatch_lines"], "code_location": {"file": "metafunc.py", "path": "/data3/pwh/swebench-repos/pytest/testing/python", "start_line": 1258, "end_line": 1280}, "code_snippet": "    def test_parametrize_and_inner_getfixturevalue(self, pytester: Pytester) -> None:\n        p = pytester.makepyfile(\n            \"\"\"\n            def pytest_generate_tests(metafunc):\n                metafunc.parametrize(\"arg1\", [1], indirect=True)\n                metafunc.parametrize(\"arg2\", [10], indirect=True)\n\n            import pytest\n            @pytest.fixture\n            def arg1(request):\n                x = request.getfixturevalue(\"arg2\")\n                return x + request.param\n\n            @pytest.fixture\n            def arg2(request):\n                return request.param\n\n            def test_func1(arg1, arg2):\n                assert arg1 == 11\n        \"\"\"\n        )\n        result = pytester.runpytest(\"-v\", p)\n        result.stdout.fnmatch_lines([\"*test_func1*1*PASS*\", \"*1 passed*\"])\n", "type": "function"}, {"name": "test_parametrize_all_indirects", "is_method": true, "class_name": "TestMetafuncFunctionalAuto", "parameters": ["self", "pytester"], "calls": ["pytester.makepyfile", "pytester.runpytest", "result.stdout.fnmatch_lines"], "code_location": {"file": "metafunc.py", "path": "/data3/pwh/swebench-repos/pytest/testing/python", "start_line": 1752, "end_line": 1777}, "code_snippet": "    def test_parametrize_all_indirects(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n\n            @pytest.fixture()\n            def animal(request):\n                return request.param\n\n            @pytest.fixture(scope='session')\n            def echo(request):\n                return request.param\n\n            @pytest.mark.parametrize('animal, echo', [(\"dog\", 1), (\"cat\", 2)], indirect=True)\n            def test_1(animal, echo):\n                assert animal in ('dog', 'cat')\n                assert echo in (1, 2, 3)\n\n            @pytest.mark.parametrize('animal, echo', [(\"fish\", 3)], indirect=True)\n            def test_2(animal, echo):\n                assert animal == 'fish'\n                assert echo in (1, 2, 3)\n        \"\"\"\n        )\n        result = pytester.runpytest()\n        result.stdout.fnmatch_lines([\"* 3 passed *\"])\n", "type": "function"}, {"name": "test_parametrize_with_non_hashable_values", "is_method": true, "class_name": "TestFunction", "parameters": ["self", "pytester"], "calls": ["pytester.makepyfile", "pytester.inline_run", "rec.assertoutcome"], "code_location": {"file": "collect.py", "path": "/data3/pwh/swebench-repos/pytest/testing/python", "start_line": 426, "end_line": 444}, "code_snippet": "    def test_parametrize_with_non_hashable_values(self, pytester: Pytester) -> None:\n        \"\"\"Test parametrization with non-hashable values.\"\"\"\n        pytester.makepyfile(\n            \"\"\"\n            archival_mapping = {\n                '1.0': {'tag': '1.0'},\n                '1.2.2a1': {'tag': 'release-1.2.2a1'},\n            }\n\n            import pytest\n            @pytest.mark.parametrize('key value'.split(),\n                                     archival_mapping.items())\n            def test_archival_to_version(key, value):\n                assert key in archival_mapping\n                assert value == archival_mapping[key]\n        \"\"\"\n        )\n        rec = pytester.inline_run()\n        rec.assertoutcome(passed=2)\n", "type": "function"}, {"name": "test_parametrize_onearg_indirect", "is_method": true, "class_name": "TestMetafunc", "parameters": ["self"], "calls": ["self.Metafunc", "metafunc.parametrize", "dict", "dict"], "code_location": {"file": "metafunc.py", "path": "/data3/pwh/swebench-repos/pytest/testing/python", "start_line": 1004, "end_line": 1010}, "code_snippet": "    def test_parametrize_onearg_indirect(self) -> None:\n        metafunc = self.Metafunc(lambda x: None)\n        metafunc.parametrize(\"x\", [1, 2], indirect=True)\n        assert metafunc._calls[0].params == dict(x=1)\n        assert metafunc._calls[0].id == \"1\"\n        assert metafunc._calls[1].params == dict(x=2)\n        assert metafunc._calls[1].id == \"2\"\n", "type": "function"}, {"name": "test_parametrize_indirect_wrong_type", "is_method": true, "class_name": "TestMetafunc", "parameters": ["self"], "calls": ["self.Metafunc", "pytest.raises", "metafunc.parametrize"], "code_location": {"file": "metafunc.py", "path": "/data3/pwh/swebench-repos/pytest/testing/python", "start_line": 807, "end_line": 816}, "code_snippet": "    def test_parametrize_indirect_wrong_type(self) -> None:\n        def func(x, y):\n            pass\n\n        metafunc = self.Metafunc(func)\n        with pytest.raises(\n            fail.Exception,\n            match=\"In func: expected Sequence or boolean for indirect, got dict\",\n        ):\n            metafunc.parametrize(\"x, y\", [(\"a\", \"b\")], indirect={})  # type: ignore[arg-type]\n", "type": "function"}, {"name": "test_parametrize_ids_returns_non_string", "is_method": true, "class_name": "TestMetafunc", "parameters": ["self", "pytester"], "calls": ["pytester.makepyfile", "pytester.runpytest", "result.stdout.fnmatch_lines"], "code_location": {"file": "metafunc.py", "path": "/data3/pwh/swebench-repos/pytest/testing/python", "start_line": 695, "end_line": 721}, "code_snippet": "    def test_parametrize_ids_returns_non_string(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            \"\"\"\\\n            import pytest\n\n            def ids(d):\n                return d\n\n            @pytest.mark.parametrize(\"arg\", ({1: 2}, {3, 4}), ids=ids)\n            def test(arg):\n                assert arg\n\n            @pytest.mark.parametrize(\"arg\", (1, 2.0, True), ids=ids)\n            def test_int(arg):\n                assert arg\n            \"\"\"\n        )\n        result = pytester.runpytest(\"-vv\", \"-s\")\n        result.stdout.fnmatch_lines(\n            [\n                \"test_parametrize_ids_returns_non_string.py::test[arg0] PASSED\",\n                \"test_parametrize_ids_returns_non_string.py::test[arg1] PASSED\",\n                \"test_parametrize_ids_returns_non_string.py::test_int[1] PASSED\",\n                \"test_parametrize_ids_returns_non_string.py::test_int[2.0] PASSED\",\n                \"test_parametrize_ids_returns_non_string.py::test_int[True] PASSED\",\n            ]\n        )\n", "type": "function"}, {"name": "test_parametrize_on_setup_arg", "is_method": true, "class_name": "TestMetafuncFunctional", "parameters": ["self", "pytester"], "calls": ["pytester.makepyfile", "pytester.runpytest", "result.stdout.fnmatch_lines"], "code_location": {"file": "metafunc.py", "path": "/data3/pwh/swebench-repos/pytest/testing/python", "start_line": 1282, "end_line": 1303}, "code_snippet": "    def test_parametrize_on_setup_arg(self, pytester: Pytester) -> None:\n        p = pytester.makepyfile(\n            \"\"\"\n            def pytest_generate_tests(metafunc):\n                assert \"arg1\" in metafunc.fixturenames\n                metafunc.parametrize(\"arg1\", [1], indirect=True)\n\n            import pytest\n            @pytest.fixture\n            def arg1(request):\n                return request.param\n\n            @pytest.fixture\n            def arg2(request, arg1):\n                return 10 * arg1\n\n            def test_func(arg2):\n                assert arg2 == 10\n        \"\"\"\n        )\n        result = pytester.runpytest(\"-v\", p)\n        result.stdout.fnmatch_lines([\"*test_func*1*PASS*\", \"*1 passed*\"])\n", "type": "function"}, {"name": "test_parametrize_functional", "is_method": true, "class_name": "TestMetafunc", "parameters": ["self", "pytester"], "calls": ["pytester.makepyfile", "pytester.runpytest", "result.stdout.fnmatch_lines"], "code_location": {"file": "metafunc.py", "path": "/data3/pwh/swebench-repos/pytest/testing/python", "start_line": 974, "end_line": 993}, "code_snippet": "    def test_parametrize_functional(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n            def pytest_generate_tests(metafunc):\n                metafunc.parametrize('x', [1,2], indirect=True)\n                metafunc.parametrize('y', [2])\n            @pytest.fixture\n            def x(request):\n                return request.param * 10\n\n            def test_simple(x,y):\n                assert x in (10,20)\n                assert y == 2\n        \"\"\"\n        )\n        result = pytester.runpytest(\"-v\")\n        result.stdout.fnmatch_lines(\n            [\"*test_simple*1-2*\", \"*test_simple*2-2*\", \"*2 passed*\"]\n        )\n", "type": "function"}], "retrieved_count": 10, "cost_time": 1.1146302223205566}
{"question": "How does the pytest_internalerror method iterate through split lines instead of directly passing the exception representation to write_line, and what control flow optimization could be applied if the exception representation format were guaranteed to be single-line?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"name": "pytest_internalerror", "is_method": true, "class_name": "TerminalReporter", "parameters": ["self", "excrepr"], "calls": ["split", "self.write_line", "str"], "code_location": {"file": "terminal.py", "path": "/data3/pwh/swebench-repos/pytest/src/_pytest", "start_line": 560, "end_line": 563}, "code_snippet": "    def pytest_internalerror(self, excrepr: ExceptionRepr) -> bool:\n        for line in str(excrepr).split(\"\\n\"):\n            self.write_line(\"INTERNALERROR> \" + line)\n        return True\n", "type": "function"}, {"name": "test_internalerror", "is_method": true, "class_name": "TestTerminal", "parameters": ["self", "pytester", "linecomp"], "calls": ["pytester.getmodulecol", "TerminalReporter", "rep.pytest_internalerror", "linecomp.assert_contains_lines", "pytest.raises", "ValueError", "excinfo.getrepr"], "code_location": {"file": "test_terminal.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 140, "end_line": 146}, "code_snippet": "    def test_internalerror(self, pytester: Pytester, linecomp) -> None:\n        modcol = pytester.getmodulecol(\"def test_one(): pass\")\n        rep = TerminalReporter(modcol.config, file=linecomp.stringio)\n        with pytest.raises(ValueError) as excinfo:\n            raise ValueError(\"hello\")\n        rep.pytest_internalerror(excinfo.getrepr())\n        linecomp.assert_contains_lines([\"INTERNALERROR> *ValueError*hello*\"])\n", "type": "function"}, {"name": "pytest_internalerror", "is_method": true, "class_name": "LogXML", "parameters": ["self", "excrepr"], "calls": ["self.node_reporter", "reporter.attrs.update", "reporter._add_simple", "str"], "code_location": {"file": "junitxml.py", "path": "/data3/pwh/swebench-repos/pytest/src/_pytest", "start_line": 631, "end_line": 634}, "code_snippet": "    def pytest_internalerror(self, excrepr: ExceptionRepr) -> None:\n        reporter = self.node_reporter(\"internal\")\n        reporter.attrs.update(classname=\"pytest\", name=\"internal\")\n        reporter._add_simple(\"error\", \"internal error\", str(excrepr))\n", "type": "function"}, {"name": "notify_exception", "is_method": true, "class_name": "Config", "parameters": ["self", "excinfo", "option"], "calls": ["excinfo.getrepr", "self.hook.pytest_internalerror", "getattr", "any", "split", "getattr", "sys.stderr.write", "sys.stderr.flush", "str"], "code_location": {"file": "__init__.py", "path": "/data3/pwh/swebench-repos/pytest/src/_pytest/config", "start_line": 1167, "end_line": 1183}, "code_snippet": "    def notify_exception(\n        self,\n        excinfo: ExceptionInfo[BaseException],\n        option: argparse.Namespace | None = None,\n    ) -> None:\n        if option and getattr(option, \"fulltrace\", False):\n            style: TracebackStyle = \"long\"\n        else:\n            style = \"native\"\n        excrepr = excinfo.getrepr(\n            funcargs=True, showlocals=getattr(option, \"showlocals\", False), style=style\n        )\n        res = self.hook.pytest_internalerror(excrepr=excrepr, excinfo=excinfo)\n        if not any(res):\n            for line in str(excrepr).split(\"\\n\"):\n                sys.stderr.write(f\"INTERNALERROR> {line}\\n\")\n                sys.stderr.flush()\n", "type": "function"}, {"name": "test_writeline", "is_method": true, "class_name": "TestTerminal", "parameters": ["self", "pytester", "linecomp"], "calls": ["pytester.getmodulecol", "TerminalReporter", "rep.write_fspath_result", "rep.write_line", "split", "endswith", "linecomp.stringio.getvalue"], "code_location": {"file": "test_terminal.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 148, "end_line": 156}, "code_snippet": "    def test_writeline(self, pytester: Pytester, linecomp) -> None:\n        modcol = pytester.getmodulecol(\"def test_one(): pass\")\n        rep = TerminalReporter(modcol.config, file=linecomp.stringio)\n        rep.write_fspath_result(modcol.nodeid, \".\")\n        rep.write_line(\"hello world\")\n        lines = linecomp.stringio.getvalue().split(\"\\n\")\n        assert not lines[0]\n        assert lines[1].endswith(modcol.name + \" .\")\n        assert lines[2] == \"hello world\"\n", "type": "function"}, {"name": "test_line_with_reprcrash", "is_method": false, "class_name": null, "parameters": ["monkeypatch"], "calls": ["monkeypatch.setattr", "check", "check", "check", "check", "check", "check", "check", "check", "check", "check", "check", "check", "check", "check", "check", "check", "check", "check", "check", "check", "check", "_get_line_with_reprcrash_message", "self.__dict__.update", "Namespace", "config", "rep", "DummyTerminalWriter", "len", "wcswidth"], "code_location": {"file": "test_terminal.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 2538, "end_line": 2616}, "code_snippet": "def test_line_with_reprcrash(monkeypatch: MonkeyPatch) -> None:\n    mocked_verbose_word = \"FAILED\"\n\n    mocked_pos = \"some::nodeid\"\n\n    def mock_get_pos(*args):\n        return mocked_pos\n\n    monkeypatch.setattr(_pytest.terminal, \"_get_node_id_with_markup\", mock_get_pos)\n\n    class Namespace:\n        def __init__(self, **kwargs):\n            self.__dict__.update(kwargs)\n\n    class config:\n        def __init__(self):\n            self.option = Namespace(verbose=0)\n\n    class rep:\n        def _get_verbose_word_with_markup(self, *args):\n            return mocked_verbose_word, {}\n\n        class longrepr:\n            class reprcrash:\n                pass\n\n    def check(msg, width, expected):\n        class DummyTerminalWriter:\n            fullwidth = width\n\n            def markup(self, word: str, **markup: str):\n                return word\n\n        __tracebackhide__ = True\n        if msg:\n            rep.longrepr.reprcrash.message = msg  # type: ignore\n        actual = _get_line_with_reprcrash_message(\n            config(),  # type: ignore[arg-type]\n            rep(),  # type: ignore[arg-type]\n            DummyTerminalWriter(),  # type: ignore[arg-type]\n            {},\n        )\n\n        assert actual == expected\n        if actual != f\"{mocked_verbose_word} {mocked_pos}\":\n            assert len(actual) <= width\n            assert wcswidth(actual) <= width\n\n    # AttributeError with message\n    check(None, 80, \"FAILED some::nodeid\")\n\n    check(\"msg\", 80, \"FAILED some::nodeid - msg\")\n    check(\"msg\", 3, \"FAILED some::nodeid\")\n\n    check(\"msg\", 24, \"FAILED some::nodeid\")\n    check(\"msg\", 25, \"FAILED some::nodeid - msg\")\n\n    check(\"some longer msg\", 24, \"FAILED some::nodeid\")\n    check(\"some longer msg\", 25, \"FAILED some::nodeid - ...\")\n    check(\"some longer msg\", 26, \"FAILED some::nodeid - s...\")\n\n    check(\"some\\nmessage\", 25, \"FAILED some::nodeid - ...\")\n    check(\"some\\nmessage\", 26, \"FAILED some::nodeid - some\")\n    check(\"some\\nmessage\", 80, \"FAILED some::nodeid - some\")\n\n    # Test unicode safety.\n    check(\"\\n2nd line\", 25, \"FAILED some::nodeid - ...\")\n    check(\"\\n2nd line\", 26, \"FAILED some::nodeid - ...\")\n    check(\"\\n2nd line\", 27, \"FAILED some::nodeid - ...\")\n    check(\"\\n2nd line\", 28, \"FAILED some::nodeid - ...\")\n    check(\"\\n2nd line\", 29, \"FAILED some::nodeid - ...\")\n\n    # NOTE: constructed, not sure if this is supported.\n    mocked_pos = \"nodeid::::withunicode\"\n    check(\"\\n2nd line\", 29, \"FAILED nodeid::::withunicode\")\n    check(\"\\n2nd line\", 40, \"FAILED nodeid::::withunicode - ...\")\n    check(\"\\n2nd line\", 41, \"FAILED nodeid::::withunicode - ...\")\n    check(\"\\n2nd line\", 42, \"FAILED nodeid::::withunicode - ...\")\n    check(\"\\n2nd line\", 80, \"FAILED nodeid::::withunicode - \")\n", "type": "function"}, {"name": "_repr_failure_py", "is_method": true, "class_name": "Node", "parameters": ["self", "excinfo", "style"], "calls": ["isinstance", "isinstance", "isinstance", "self.config.getoption", "excinfo.getrepr", "ExceptionInfo.from_exception", "excinfo.value.formatrepr", "self.config.get_verbosity", "self.config.getoption", "self.config.get_verbosity", "Path", "self.config.getoption", "os.getcwd"], "code_location": {"file": "nodes.py", "path": "/data3/pwh/swebench-repos/pytest/src/_pytest", "start_line": 408, "end_line": 464}, "code_snippet": "    def _repr_failure_py(\n        self,\n        excinfo: ExceptionInfo[BaseException],\n        style: TracebackStyle | None = None,\n    ) -> TerminalRepr:\n        from _pytest.fixtures import FixtureLookupError\n\n        if isinstance(excinfo.value, ConftestImportFailure):\n            excinfo = ExceptionInfo.from_exception(excinfo.value.cause)\n        if isinstance(excinfo.value, fail.Exception):\n            if not excinfo.value.pytrace:\n                style = \"value\"\n        if isinstance(excinfo.value, FixtureLookupError):\n            return excinfo.value.formatrepr()\n\n        tbfilter: bool | Callable[[ExceptionInfo[BaseException]], Traceback]\n        if self.config.getoption(\"fulltrace\", False):\n            style = \"long\"\n            tbfilter = False\n        else:\n            tbfilter = self._traceback_filter\n            if style == \"auto\":\n                style = \"long\"\n        # XXX should excinfo.getrepr record all data and toterminal() process it?\n        if style is None:\n            if self.config.getoption(\"tbstyle\", \"auto\") == \"short\":\n                style = \"short\"\n            else:\n                style = \"long\"\n\n        if self.config.get_verbosity() > 1:\n            truncate_locals = False\n        else:\n            truncate_locals = True\n\n        truncate_args = False if self.config.get_verbosity() > 2 else True\n\n        # excinfo.getrepr() formats paths relative to the CWD if `abspath` is False.\n        # It is possible for a fixture/test to change the CWD while this code runs, which\n        # would then result in the user seeing confusing paths in the failure message.\n        # To fix this, if the CWD changed, always display the full absolute path.\n        # It will be better to just always display paths relative to invocation_dir, but\n        # this requires a lot of plumbing (#6428).\n        try:\n            abspath = Path(os.getcwd()) != self.config.invocation_params.dir\n        except OSError:\n            abspath = True\n\n        return excinfo.getrepr(\n            funcargs=True,\n            abspath=abspath,\n            showlocals=self.config.getoption(\"showlocals\", False),\n            style=style,\n            tbfilter=tbfilter,\n            truncate_locals=truncate_locals,\n            truncate_args=truncate_args,\n        )\n", "type": "function"}, {"name": "toterminal", "is_method": true, "class_name": "FixtureLookupErrorRepr", "parameters": ["self", "tw"], "calls": ["self.errorstring.split", "tw.line", "tw.line", "tw.line", "tw.line", "tbline.rstrip", "tw.line", "os.fspath", "strip", "line.strip"], "code_location": {"file": "fixtures.py", "path": "/data3/pwh/swebench-repos/pytest/src/_pytest", "start_line": 897, "end_line": 913}, "code_snippet": "    def toterminal(self, tw: TerminalWriter) -> None:\n        # tw.line(\"FixtureLookupError: %s\" %(self.argname), red=True)\n        for tbline in self.tblines:\n            tw.line(tbline.rstrip())\n        lines = self.errorstring.split(\"\\n\")\n        if lines:\n            tw.line(\n                f\"{FormattedExcinfo.fail_marker}       {lines[0].strip()}\",\n                red=True,\n            )\n            for line in lines[1:]:\n                tw.line(\n                    f\"{FormattedExcinfo.flow_marker}       {line.strip()}\",\n                    red=True,\n                )\n        tw.line()\n        tw.line(f\"{os.fspath(self.filename)}:{self.firstlineno + 1}\")\n", "type": "function"}, {"name": "repr_excinfo", "is_method": true, "class_name": "FormattedExcinfo", "parameters": ["self", "excinfo"], "calls": ["set", "repr_chain.reverse", "ExceptionChainRepr", "seen.add", "id", "id", "isinstance", "excinfo_._getreprcrash", "ReprTracebackNative", "filter_excinfo_traceback", "ReprTracebackNative", "self.repr_traceback", "format_exception", "ExceptionInfo.from_exception", "format_exception", "type", "ExceptionInfo.from_exception", "type"], "code_location": {"file": "code.py", "path": "/data3/pwh/swebench-repos/pytest/src/_pytest/_code", "start_line": 1177, "end_line": 1224}, "code_snippet": "    def repr_excinfo(self, excinfo: ExceptionInfo[BaseException]) -> ExceptionChainRepr:\n        repr_chain: list[tuple[ReprTraceback, ReprFileLocation | None, str | None]] = []\n        e: BaseException | None = excinfo.value\n        excinfo_: ExceptionInfo[BaseException] | None = excinfo\n        descr = None\n        seen: set[int] = set()\n        while e is not None and id(e) not in seen:\n            seen.add(id(e))\n\n            if excinfo_:\n                # Fall back to native traceback as a temporary workaround until\n                # full support for exception groups added to ExceptionInfo.\n                # See https://github.com/pytest-dev/pytest/issues/9159\n                reprtraceback: ReprTraceback | ReprTracebackNative\n                if isinstance(e, BaseExceptionGroup):\n                    # don't filter any sub-exceptions since they shouldn't have any internal frames\n                    traceback = filter_excinfo_traceback(self.tbfilter, excinfo)\n                    reprtraceback = ReprTracebackNative(\n                        format_exception(\n                            type(excinfo.value),\n                            excinfo.value,\n                            traceback[0]._rawentry,\n                        )\n                    )\n                else:\n                    reprtraceback = self.repr_traceback(excinfo_)\n                reprcrash = excinfo_._getreprcrash()\n            else:\n                # Fallback to native repr if the exception doesn't have a traceback:\n                # ExceptionInfo objects require a full traceback to work.\n                reprtraceback = ReprTracebackNative(format_exception(type(e), e, None))\n                reprcrash = None\n            repr_chain += [(reprtraceback, reprcrash, descr)]\n\n            if e.__cause__ is not None and self.chain:\n                e = e.__cause__\n                excinfo_ = ExceptionInfo.from_exception(e) if e.__traceback__ else None\n                descr = \"The above exception was the direct cause of the following exception:\"\n            elif (\n                e.__context__ is not None and not e.__suppress_context__ and self.chain\n            ):\n                e = e.__context__\n                excinfo_ = ExceptionInfo.from_exception(e) if e.__traceback__ else None\n                descr = \"During handling of the above exception, another exception occurred:\"\n            else:\n                e = None\n        repr_chain.reverse()\n        return ExceptionChainRepr(repr_chain)\n", "type": "function"}, {"name": "test_toterminal_long", "is_method": true, "class_name": "TestFormattedExcinfo", "parameters": ["self", "importasmod", "tw_mock"], "calls": ["importasmod", "pytest.raises", "excinfo.traceback.filter", "excinfo.getrepr", "repr.toterminal", "tw_mock.lines.pop", "tw_mock.get_write_msg", "line.endswith", "tw_mock.get_write_msg", "line.endswith"], "code_location": {"file": "test_excinfo.py", "path": "/data3/pwh/swebench-repos/pytest/testing/code", "start_line": 1140, "end_line": 1169}, "code_snippet": "    def test_toterminal_long(self, importasmod, tw_mock):\n        mod = importasmod(\n            \"\"\"\n            def g(x):\n                raise ValueError(x)\n            def f():\n                g(3)\n        \"\"\"\n        )\n        excinfo = pytest.raises(ValueError, mod.f)\n        excinfo.traceback = excinfo.traceback.filter(excinfo)\n        repr = excinfo.getrepr()\n        repr.toterminal(tw_mock)\n        assert tw_mock.lines[0] == \"\"\n        tw_mock.lines.pop(0)\n        assert tw_mock.lines[0] == \"    def f():\"\n        assert tw_mock.lines[1] == \">       g(3)\"\n        assert tw_mock.lines[2] == \"\"\n        line = tw_mock.get_write_msg(3)\n        assert line.endswith(\"mod.py\")\n        assert tw_mock.lines[4] == (\":5: \")\n        assert tw_mock.lines[5] == (\"_ \", None)\n        assert tw_mock.lines[6] == \"\"\n        assert tw_mock.lines[7] == \"    def g(x):\"\n        assert tw_mock.lines[8] == \">       raise ValueError(x)\"\n        assert tw_mock.lines[9] == \"E       ValueError: 3\"\n        assert tw_mock.lines[10] == \"\"\n        line = tw_mock.get_write_msg(11)\n        assert line.endswith(\"mod.py\")\n        assert tw_mock.lines[12] == \":3: ValueError\"\n", "type": "function"}], "retrieved_count": 10, "cost_time": 1.125891923904419}
{"question": "How does the pytest capture framework ensure that stdout and stderr captured during setup and teardown phases are correctly isolated and reported separately from the test execution phase, particularly when multiple fixtures at different scopes are involved?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"name": "test_capture_scope_cache", "is_method": true, "class_name": "TestPerTestCapturing", "parameters": ["self", "pytester"], "calls": ["pytest.mark.xfail", "pytester.makepyfile", "pytester.runpytest", "result.stdout.fnmatch_lines"], "code_location": {"file": "test_capture.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 182, "end_line": 207}, "code_snippet": "    def test_capture_scope_cache(self, pytester: Pytester) -> None:\n        p = pytester.makepyfile(\n            \"\"\"\n            import sys\n            def setup_module(func):\n                print(\"module-setup\")\n            def setup_function(func):\n                print(\"function-setup\")\n            def test_func():\n                print(\"in function\")\n                assert 0\n            def teardown_function(func):\n                print(\"in teardown\")\n        \"\"\"\n        )\n        result = pytester.runpytest(p)\n        result.stdout.fnmatch_lines(\n            [\n                \"*test_func():*\",\n                \"*Captured stdout during setup*\",\n                \"module-setup*\",\n                \"function-setup*\",\n                \"*Captured stdout*\",\n                \"in teardown*\",\n            ]\n        )\n", "type": "function"}, {"name": "test_capturing", "is_method": false, "class_name": null, "parameters": ["pytester"], "calls": ["pytester.makepyfile", "pytester.runpytest", "result.stdout.fnmatch_lines"], "code_location": {"file": "test_setuponly.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 240, "end_line": 259}, "code_snippet": "def test_capturing(pytester: Pytester) -> None:\n    p = pytester.makepyfile(\n        \"\"\"\n        import pytest, sys\n        @pytest.fixture()\n        def one():\n            sys.stdout.write('this should be captured')\n            sys.stderr.write('this should also be captured')\n        @pytest.fixture()\n        def two(one):\n            assert 0\n        def test_capturing(two):\n            pass\n    \"\"\"\n    )\n\n    result = pytester.runpytest(\"--setup-only\", p)\n    result.stdout.fnmatch_lines(\n        [\"this should be captured\", \"this should also be captured\"]\n    )\n", "type": "function"}, {"name": "test_captured_text", "is_method": true, "class_name": "TestReportContents", "parameters": ["self", "pytester"], "calls": ["pytester.runitem"], "code_location": {"file": "test_runner.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 1134, "end_line": 1162}, "code_snippet": "    def test_captured_text(self, pytester: Pytester) -> None:\n        reports = pytester.runitem(\n            \"\"\"\n            import pytest\n            import sys\n\n            @pytest.fixture\n            def fix():\n                sys.stdout.write('setup: stdout\\\\n')\n                sys.stderr.write('setup: stderr\\\\n')\n                yield\n                sys.stdout.write('teardown: stdout\\\\n')\n                sys.stderr.write('teardown: stderr\\\\n')\n                assert 0\n\n            def test_func(fix):\n                sys.stdout.write('call: stdout\\\\n')\n                sys.stderr.write('call: stderr\\\\n')\n                assert 0\n        \"\"\"\n        )\n        setup, call, teardown = reports\n        assert setup.capstdout == \"setup: stdout\\n\"\n        assert call.capstdout == \"setup: stdout\\ncall: stdout\\n\"\n        assert teardown.capstdout == \"setup: stdout\\ncall: stdout\\nteardown: stdout\\n\"\n\n        assert setup.capstderr == \"setup: stderr\\n\"\n        assert call.capstderr == \"setup: stderr\\ncall: stderr\\n\"\n        assert teardown.capstderr == \"setup: stderr\\ncall: stderr\\nteardown: stderr\\n\"\n", "type": "function"}, {"name": "test_capture_and_fixtures", "is_method": true, "class_name": "TestPerTestCapturing", "parameters": ["self", "pytester"], "calls": ["pytester.makepyfile", "pytester.runpytest", "result.stdout.fnmatch_lines"], "code_location": {"file": "test_capture.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 155, "end_line": 179}, "code_snippet": "    def test_capture_and_fixtures(self, pytester: Pytester) -> None:\n        p = pytester.makepyfile(\n            \"\"\"\n            def setup_module(mod):\n                print(\"setup module\")\n            def setup_function(function):\n                print(\"setup \" + function.__name__)\n            def test_func1():\n                print(\"in func1\")\n                assert 0\n            def test_func2():\n                print(\"in func2\")\n                assert 0\n        \"\"\"\n        )\n        result = pytester.runpytest(p)\n        result.stdout.fnmatch_lines(\n            [\n                \"setup module*\",\n                \"setup test_func1*\",\n                \"in func1*\",\n                \"setup test_func2*\",\n                \"in func2*\",\n            ]\n        )\n", "type": "function"}, {"name": "test_logging_and_crossscope_fixtures", "is_method": true, "class_name": "TestLoggingInteraction", "parameters": ["self", "pytester"], "calls": ["pytester.makepyfile", "print", "pytester.runpytest_subprocess", "result.stdout.str", "result.stdout.fnmatch_lines"], "code_location": {"file": "test_capture.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 338, "end_line": 362}, "code_snippet": "    def test_logging_and_crossscope_fixtures(self, pytester: Pytester) -> None:\n        p = pytester.makepyfile(\n            \"\"\"\\\n            import logging\n            def setup_module(function):\n                logging.warning(\"hello1\")\n\n            def test_logging():\n                logging.warning(\"hello2\")\n                assert 0\n\n            def teardown_module(function):\n                logging.warning(\"hello3\")\n                assert 0\n            \"\"\"\n        )\n        for optargs in ((\"--capture=sys\",), (\"--capture=fd\",)):\n            print(optargs)\n            result = pytester.runpytest_subprocess(p, *optargs)\n            s = result.stdout.str()\n            result.stdout.fnmatch_lines(\n                [\"*WARN*hello3\", \"*WARN*hello1\", \"*WARN*hello2\"]  # errors come first\n            )\n            # verify proper termination\n            assert \"closed\" not in s\n", "type": "function"}, {"name": "test_teardown_capturing", "is_method": true, "class_name": "TestPerTestCapturing", "parameters": ["self", "pytester"], "calls": ["pytester.makepyfile", "pytester.runpytest", "result.stdout.fnmatch_lines"], "code_location": {"file": "test_capture.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 224, "end_line": 247}, "code_snippet": "    def test_teardown_capturing(self, pytester: Pytester) -> None:\n        p = pytester.makepyfile(\n            \"\"\"\n            def setup_function(function):\n                print(\"setup func1\")\n            def teardown_function(function):\n                print(\"teardown func1\")\n                assert 0\n            def test_func1():\n                print(\"in func1\")\n                pass\n        \"\"\"\n        )\n        result = pytester.runpytest(p)\n        result.stdout.fnmatch_lines(\n            [\n                \"*teardown_function*\",\n                \"*Captured stdout*\",\n                \"setup func1*\",\n                \"in func1*\",\n                \"teardown func1*\",\n                # \"*1 fixture failure*\"\n            ]\n        )\n", "type": "function"}, {"name": "test_global_capture_with_live_logging", "is_method": false, "class_name": null, "parameters": ["pytester"], "calls": ["pytester.makeconftest", "pytester.makepyfile", "pytester.runpytest_subprocess", "open", "f.read", "open", "f.read"], "code_location": {"file": "test_capture.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 1544, "end_line": 1599}, "code_snippet": "def test_global_capture_with_live_logging(pytester: Pytester) -> None:\n    # Issue 3819\n    # capture should work with live cli logging\n\n    # Teardown report seems to have the capture for the whole process (setup, capture, teardown)\n    pytester.makeconftest(\n        \"\"\"\n        def pytest_runtest_logreport(report):\n            if \"test_global\" in report.nodeid:\n                if report.when == \"teardown\":\n                    with open(\"caplog\", \"w\", encoding=\"utf-8\") as f:\n                        f.write(report.caplog)\n                    with open(\"capstdout\", \"w\", encoding=\"utf-8\") as f:\n                        f.write(report.capstdout)\n        \"\"\"\n    )\n\n    pytester.makepyfile(\n        \"\"\"\n        import logging\n        import sys\n        import pytest\n\n        logger = logging.getLogger(__name__)\n\n        @pytest.fixture\n        def fix1():\n            print(\"fix setup\")\n            logging.info(\"fix setup\")\n            yield\n            logging.info(\"fix teardown\")\n            print(\"fix teardown\")\n\n        def test_global(fix1):\n            print(\"begin test\")\n            logging.info(\"something in test\")\n            print(\"end test\")\n        \"\"\"\n    )\n    result = pytester.runpytest_subprocess(\"--log-cli-level=INFO\")\n    assert result.ret == 0\n\n    with open(\"caplog\", encoding=\"utf-8\") as f:\n        caplog = f.read()\n\n    assert \"fix setup\" in caplog\n    assert \"something in test\" in caplog\n    assert \"fix teardown\" in caplog\n\n    with open(\"capstdout\", encoding=\"utf-8\") as f:\n        capstdout = f.read()\n\n    assert \"fix setup\" in capstdout\n    assert \"begin test\" in capstdout\n    assert \"end test\" in capstdout\n    assert \"fix teardown\" in capstdout\n", "type": "function"}, {"name": "test_logging_and_immediate_setupteardown", "is_method": true, "class_name": "TestLoggingInteraction", "parameters": ["self", "pytester"], "calls": ["pytester.makepyfile", "print", "pytester.runpytest_subprocess", "result.stdout.str", "result.stdout.fnmatch_lines"], "code_location": {"file": "test_capture.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 312, "end_line": 336}, "code_snippet": "    def test_logging_and_immediate_setupteardown(self, pytester: Pytester) -> None:\n        p = pytester.makepyfile(\n            \"\"\"\\\n            import logging\n            def setup_function(function):\n                logging.warning(\"hello1\")\n\n            def test_logging():\n                logging.warning(\"hello2\")\n                assert 0\n\n            def teardown_function(function):\n                logging.warning(\"hello3\")\n                assert 0\n            \"\"\"\n        )\n        for optargs in ((\"--capture=sys\",), (\"--capture=fd\",)):\n            print(optargs)\n            result = pytester.runpytest_subprocess(p, *optargs)\n            s = result.stdout.str()\n            result.stdout.fnmatch_lines(\n                [\"*WARN*hello3\", \"*WARN*hello1\", \"*WARN*hello2\"]  # errors show first!\n            )\n            # verify proper termination\n            assert \"closed\" not in s\n", "type": "function"}, {"name": "test_teardown_capturing_final", "is_method": true, "class_name": "TestPerTestCapturing", "parameters": ["self", "pytester"], "calls": ["pytester.makepyfile", "pytester.runpytest", "result.stdout.fnmatch_lines"], "code_location": {"file": "test_capture.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 249, "end_line": 267}, "code_snippet": "    def test_teardown_capturing_final(self, pytester: Pytester) -> None:\n        p = pytester.makepyfile(\n            \"\"\"\n            def teardown_module(mod):\n                print(\"teardown module\")\n                assert 0\n            def test_func():\n                pass\n        \"\"\"\n        )\n        result = pytester.runpytest(p)\n        result.stdout.fnmatch_lines(\n            [\n                \"*def teardown_module(mod):*\",\n                \"*Captured stdout*\",\n                \"*teardown module*\",\n                \"*1 error*\",\n            ]\n        )\n", "type": "function"}, {"name": "test_fixture_use_by_other_fixtures", "is_method": true, "class_name": "TestCaptureFixture", "parameters": ["self", "pytester", "fixture"], "calls": ["pytest.mark.parametrize", "pytester.makepyfile", "pytester.runpytest_subprocess", "result.stdout.fnmatch_lines", "result.stdout.no_fnmatch_line", "result.stdout.no_fnmatch_line"], "code_location": {"file": "test_capture.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 711, "end_line": 742}, "code_snippet": "    def test_fixture_use_by_other_fixtures(self, pytester: Pytester, fixture) -> None:\n        \"\"\"Ensure that capsys and capfd can be used by other fixtures during\n        setup and teardown.\"\"\"\n        pytester.makepyfile(\n            f\"\"\"\\\n            import sys\n            import pytest\n\n            @pytest.fixture\n            def captured_print({fixture}):\n                print('stdout contents begin')\n                print('stderr contents begin', file=sys.stderr)\n                out, err = {fixture}.readouterr()\n\n                yield out, err\n\n                print('stdout contents end')\n                print('stderr contents end', file=sys.stderr)\n                out, err = {fixture}.readouterr()\n                assert out == 'stdout contents end\\\\n'\n                assert err == 'stderr contents end\\\\n'\n\n            def test_captured_print(captured_print):\n                out, err = captured_print\n                assert out == 'stdout contents begin\\\\n'\n                assert err == 'stderr contents begin\\\\n'\n        \"\"\"\n        )\n        result = pytester.runpytest_subprocess()\n        result.stdout.fnmatch_lines([\"*1 passed*\"])\n        result.stdout.no_fnmatch_line(\"*stdout contents begin*\")\n        result.stdout.no_fnmatch_line(\"*stderr contents begin*\")\n", "type": "function"}], "retrieved_count": 10, "cost_time": 1.1216187477111816}
{"question": "What is the sentinel value abstraction pattern that NotSetType implements within the pytest compatibility layer to decouple internal state representation from external API contracts?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"name": "__init__", "is_method": true, "class_name": "Mark", "parameters": ["self", "name", "args", "kwargs", "param_ids_from", "param_ids_generated"], "calls": ["check_ispytest", "object.__setattr__", "object.__setattr__", "object.__setattr__", "object.__setattr__", "object.__setattr__"], "code_location": {"file": "structures.py", "path": "/data3/pwh/swebench-repos/pytest/src/_pytest/mark", "start_line": 252, "end_line": 269}, "code_snippet": "    def __init__(\n        self,\n        name: str,\n        args: tuple[Any, ...],\n        kwargs: Mapping[str, Any],\n        param_ids_from: Mark | None = None,\n        param_ids_generated: Sequence[str] | None = None,\n        *,\n        _ispytest: bool = False,\n    ) -> None:\n        \"\"\":meta private:\"\"\"\n        check_ispytest(_ispytest)\n        # Weirdness to bypass frozen=True.\n        object.__setattr__(self, \"name\", name)\n        object.__setattr__(self, \"args\", args)\n        object.__setattr__(self, \"kwargs\", kwargs)\n        object.__setattr__(self, \"_param_ids_from\", param_ids_from)\n        object.__setattr__(self, \"_param_ids_generated\", param_ids_generated)\n", "type": "function"}, {"name": "__init__", "is_method": true, "class_name": "MarkGenerator", "parameters": ["self"], "calls": ["check_ispytest", "set"], "code_location": {"file": "structures.py", "path": "/data3/pwh/swebench-repos/pytest/src/_pytest/mark", "start_line": 559, "end_line": 562}, "code_snippet": "    def __init__(self, *, _ispytest: bool = False) -> None:\n        check_ispytest(_ispytest)\n        self._config: Config | None = None\n        self._markers: set[str] = set()\n", "type": "function"}, {"name": "__init__", "is_method": true, "class_name": "TopRequest", "parameters": ["self", "pyfuncitem"], "calls": ["__init__", "super", "pyfuncitem._fixtureinfo.name2fixturedefs.copy"], "code_location": {"file": "fixtures.py", "path": "/data3/pwh/swebench-repos/pytest/src/_pytest", "start_line": 688, "end_line": 695}, "code_snippet": "    def __init__(self, pyfuncitem: Function, *, _ispytest: bool = False) -> None:\n        super().__init__(\n            fixturename=None,\n            pyfuncitem=pyfuncitem,\n            arg2fixturedefs=pyfuncitem._fixtureinfo.name2fixturedefs.copy(),\n            fixture_defs={},\n            _ispytest=_ispytest,\n        )\n", "type": "function"}, {"name": "__init__", "is_method": true, "class_name": "MarkDecorator", "parameters": ["self", "mark"], "calls": ["check_ispytest"], "code_location": {"file": "structures.py", "path": "/data3/pwh/swebench-repos/pytest/src/_pytest/mark", "start_line": 346, "end_line": 349}, "code_snippet": "    def __init__(self, mark: Mark, *, _ispytest: bool = False) -> None:\n        \"\"\":meta private:\"\"\"\n        check_ispytest(_ispytest)\n        self.mark = mark\n", "type": "function"}, {"name": "__post_init__", "is_method": true, "class_name": "FixtureFunctionMarker", "parameters": ["self", "_ispytest"], "calls": ["check_ispytest"], "code_location": {"file": "fixtures.py", "path": "/data3/pwh/swebench-repos/pytest/src/_pytest", "start_line": 1221, "end_line": 1222}, "code_snippet": "    def __post_init__(self, _ispytest: bool) -> None:\n        check_ispytest(_ispytest)\n", "type": "function"}, {"name": "__init__", "is_method": true, "class_name": "Testdir", "parameters": ["self", "pytester"], "calls": ["check_ispytest"], "code_location": {"file": "legacypath.py", "path": "/data3/pwh/swebench-repos/pytest/src/_pytest", "start_line": 55, "end_line": 57}, "code_snippet": "    def __init__(self, pytester: Pytester, *, _ispytest: bool = False) -> None:\n        check_ispytest(_ispytest)\n        self._pytester = pytester\n", "type": "function"}, {"name": "__init__", "is_method": true, "class_name": "PytestPluginManager", "parameters": ["self"], "calls": ["__init__", "set", "self.add_hookspecs", "self.register", "os.environ.get", "DummyRewriteHook", "lru_cache", "getattr", "self.trace.root.setwriter", "self.enable_tracing", "super", "open", "os.dup", "err.fileno"], "code_location": {"file": "__init__.py", "path": "/data3/pwh/swebench-repos/pytest/src/_pytest/config", "start_line": 401, "end_line": 451}, "code_snippet": "    def __init__(self) -> None:\n        from _pytest.assertion import DummyRewriteHook\n        from _pytest.assertion import RewriteHook\n\n        super().__init__(\"pytest\")\n\n        # -- State related to local conftest plugins.\n        # All loaded conftest modules.\n        self._conftest_plugins: set[types.ModuleType] = set()\n        # All conftest modules applicable for a directory.\n        # This includes the directory's own conftest modules as well\n        # as those of its parent directories.\n        self._dirpath2confmods: dict[pathlib.Path, list[types.ModuleType]] = {}\n        # Cutoff directory above which conftests are no longer discovered.\n        self._confcutdir: pathlib.Path | None = None\n        # If set, conftest loading is skipped.\n        self._noconftest = False\n\n        # _getconftestmodules()'s call to _get_directory() causes a stat\n        # storm when it's called potentially thousands of times in a test\n        # session (#9478), often with the same path, so cache it.\n        self._get_directory = lru_cache(256)(_get_directory)\n\n        # plugins that were explicitly skipped with pytest.skip\n        # list of (module name, skip reason)\n        # previously we would issue a warning when a plugin was skipped, but\n        # since we refactored warnings as first citizens of Config, they are\n        # just stored here to be used later.\n        self.skipped_plugins: list[tuple[str, str]] = []\n\n        self.add_hookspecs(_pytest.hookspec)\n        self.register(self)\n        if os.environ.get(\"PYTEST_DEBUG\"):\n            err: IO[str] = sys.stderr\n            encoding: str = getattr(err, \"encoding\", \"utf8\")\n            try:\n                err = open(\n                    os.dup(err.fileno()),\n                    mode=err.mode,\n                    buffering=1,\n                    encoding=encoding,\n                )\n            except Exception:\n                pass\n            self.trace.root.setwriter(err.write)\n            self.enable_tracing()\n\n        # Config._consider_importhook will set a real object if required.\n        self.rewrite_hook: RewriteHook = DummyRewriteHook()\n        # Used to know when we are importing conftests after the pytest_configure stage.\n        self._configured = False\n", "type": "function"}, {"name": "__init__", "is_method": true, "class_name": "TempPathFactory", "parameters": ["self", "given_basetemp", "retention_count", "retention_policy", "trace", "basetemp"], "calls": ["check_ispytest", "Path", "os.path.abspath", "str"], "code_location": {"file": "tmpdir.py", "path": "/data3/pwh/swebench-repos/pytest/src/_pytest", "start_line": 54, "end_line": 75}, "code_snippet": "    def __init__(\n        self,\n        given_basetemp: Path | None,\n        retention_count: int,\n        retention_policy: RetentionType,\n        trace,\n        basetemp: Path | None = None,\n        *,\n        _ispytest: bool = False,\n    ) -> None:\n        check_ispytest(_ispytest)\n        if given_basetemp is None:\n            self._given_basetemp = None\n        else:\n            # Use os.path.abspath() to get absolute path instead of resolve() as it\n            # does not work the same in all platforms (see #4427).\n            # Path.absolute() exists, but it is not public (see https://bugs.python.org/issue25012).\n            self._given_basetemp = Path(os.path.abspath(str(given_basetemp)))\n        self._trace = trace\n        self._retention_count = retention_count\n        self._retention_policy = retention_policy\n        self._basetemp = basetemp\n", "type": "function"}, {"name": "conftest_setinitial", "is_method": false, "class_name": null, "parameters": ["conftest", "args", "confcutdir"], "calls": ["conftest._set_initial_conftests", "Path", "Path.cwd"], "code_location": {"file": "test_conftest.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 26, "end_line": 40}, "code_snippet": "def conftest_setinitial(\n    conftest: PytestPluginManager,\n    args: Sequence[str | Path],\n    confcutdir: Path | None = None,\n) -> None:\n    conftest._set_initial_conftests(\n        args=args,\n        pyargs=False,\n        noconftest=False,\n        rootpath=Path(args[0]),\n        confcutdir=confcutdir,\n        invocation_dir=Path.cwd(),\n        importmode=\"prepend\",\n        consider_namespace_packages=False,\n    )\n", "type": "function"}, {"name": "test_getreportopt", "is_method": false, "class_name": null, "parameters": [], "calls": ["cast", "Option", "FakeConfig", "getreportopt", "getreportopt", "getreportopt", "getreportopt", "getreportopt", "getreportopt", "getreportopt", "getreportopt", "getreportopt", "getreportopt", "getreportopt", "getreportopt", "getreportopt", "getreportopt"], "code_location": {"file": "test_terminal.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 1400, "end_line": 1456}, "code_snippet": "def test_getreportopt() -> None:\n    from _pytest.terminal import _REPORTCHARS_DEFAULT\n\n    class FakeConfig:\n        class Option:\n            reportchars = _REPORTCHARS_DEFAULT\n            disable_warnings = False\n\n        option = Option()\n\n    config = cast(Config, FakeConfig())\n\n    assert _REPORTCHARS_DEFAULT == \"fE\"\n\n    # Default.\n    assert getreportopt(config) == \"wfE\"\n\n    config.option.reportchars = \"sf\"\n    assert getreportopt(config) == \"wsf\"\n\n    config.option.reportchars = \"sfxw\"\n    assert getreportopt(config) == \"sfxw\"\n\n    config.option.reportchars = \"a\"\n    assert getreportopt(config) == \"wsxXEf\"\n\n    config.option.reportchars = \"N\"\n    assert getreportopt(config) == \"w\"\n\n    config.option.reportchars = \"NwfE\"\n    assert getreportopt(config) == \"wfE\"\n\n    config.option.reportchars = \"NfENx\"\n    assert getreportopt(config) == \"wx\"\n\n    # Now with --disable-warnings.\n    config.option.disable_warnings = True\n    config.option.reportchars = \"a\"\n    assert getreportopt(config) == \"sxXEf\"\n\n    config.option.reportchars = \"sfx\"\n    assert getreportopt(config) == \"sfx\"\n\n    config.option.reportchars = \"sfxw\"\n    assert getreportopt(config) == \"sfx\"\n\n    config.option.reportchars = \"a\"\n    assert getreportopt(config) == \"sxXEf\"\n\n    config.option.reportchars = \"A\"\n    assert getreportopt(config) == \"PpsxXEf\"\n\n    config.option.reportchars = \"AN\"\n    assert getreportopt(config) == \"\"\n\n    config.option.reportchars = \"NwfE\"\n    assert getreportopt(config) == \"fE\"\n", "type": "function"}], "retrieved_count": 10, "cost_time": 1.146622896194458}
{"question": "How does the import_path API framework resolve module identity and ensure module caching consistency when the same file path is imported multiple times through different sys.path configurations?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"name": "test_import_path_imports_correct_file", "is_method": true, "class_name": "TestImportLibMode", "parameters": ["self", "pytester", "ns_param"], "calls": ["pytester.syspathinsert", "x_at_root.write_text", "x_in_sub_folder.parent.mkdir", "x_in_sub_folder.write_text", "import_path", "import_path", "pytest.raises", "import_path", "Path"], "code_location": {"file": "test_pathlib.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 1165, "end_line": 1211}, "code_snippet": "    def test_import_path_imports_correct_file(\n        self, pytester: Pytester, ns_param: bool\n    ) -> None:\n        \"\"\"\n        Import the module by the given path, even if other module with the same name\n        is reachable from sys.path.\n        \"\"\"\n        pytester.syspathinsert()\n        # Create a 'x.py' module reachable from sys.path that raises AssertionError\n        # if imported.\n        x_at_root = pytester.path / \"x.py\"\n        x_at_root.write_text(\"raise AssertionError('x at root')\", encoding=\"ascii\")\n\n        # Create another x.py module, but in some subdirectories to ensure it is not\n        # accessible from sys.path.\n        x_in_sub_folder = pytester.path / \"a/b/x.py\"\n        x_in_sub_folder.parent.mkdir(parents=True)\n        x_in_sub_folder.write_text(\"X = 'a/b/x'\", encoding=\"ascii\")\n\n        # Import our x.py module from the subdirectories.\n        # The 'x.py' module from sys.path was not imported for sure because\n        # otherwise we would get an AssertionError.\n        mod = import_path(\n            x_in_sub_folder,\n            mode=ImportMode.importlib,\n            root=pytester.path,\n            consider_namespace_packages=ns_param,\n        )\n        assert mod.__file__ and Path(mod.__file__) == x_in_sub_folder\n        assert mod.X == \"a/b/x\"\n\n        mod2 = import_path(\n            x_in_sub_folder,\n            mode=ImportMode.importlib,\n            root=pytester.path,\n            consider_namespace_packages=ns_param,\n        )\n        assert mod is mod2\n\n        # Attempt to import root 'x.py'.\n        with pytest.raises(AssertionError, match=\"x at root\"):\n            _ = import_path(\n                x_at_root,\n                mode=ImportMode.importlib,\n                root=pytester.path,\n                consider_namespace_packages=ns_param,\n            )\n", "type": "function"}, {"name": "test_import_using_normal_mechanism_first", "is_method": true, "class_name": "TestImportLibMode", "parameters": ["self", "monkeypatch", "pytester", "ns_param"], "calls": ["self.create_installed_doctests_and_tests_dir", "import_path", "import_path", "import_path", "import_path", "import_path", "import_path", "Path"], "code_location": {"file": "test_pathlib.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 1068, "end_line": 1133}, "code_snippet": "    def test_import_using_normal_mechanism_first(\n        self, monkeypatch: MonkeyPatch, pytester: Pytester, ns_param: bool\n    ) -> None:\n        \"\"\"\n        Test import_path imports from the canonical location when possible first, only\n        falling back to its normal flow when the module being imported is not reachable via sys.path (#11475).\n        \"\"\"\n        core_py, test_path1, test_path2 = self.create_installed_doctests_and_tests_dir(\n            pytester.path, monkeypatch\n        )\n\n        # core_py is reached from sys.path, so should be imported normally.\n        mod = import_path(\n            core_py,\n            mode=\"importlib\",\n            root=pytester.path,\n            consider_namespace_packages=ns_param,\n        )\n        assert mod.__name__ == \"app.core\"\n        assert mod.__file__ and Path(mod.__file__) == core_py\n\n        # Ensure we do not import the same module again (#11475).\n        mod2 = import_path(\n            core_py,\n            mode=\"importlib\",\n            root=pytester.path,\n            consider_namespace_packages=ns_param,\n        )\n        assert mod is mod2\n\n        # tests are not reachable from sys.path, so they are imported as a standalone modules.\n        # Instead of '.tests.a.test_core', we import as \"_tests.a.test_core\" because\n        # importlib considers module names starting with '.' to be local imports.\n        mod = import_path(\n            test_path1,\n            mode=\"importlib\",\n            root=pytester.path,\n            consider_namespace_packages=ns_param,\n        )\n        assert mod.__name__ == \"_tests.a.test_core\"\n\n        # Ensure we do not import the same module again (#11475).\n        mod2 = import_path(\n            test_path1,\n            mode=\"importlib\",\n            root=pytester.path,\n            consider_namespace_packages=ns_param,\n        )\n        assert mod is mod2\n\n        mod = import_path(\n            test_path2,\n            mode=\"importlib\",\n            root=pytester.path,\n            consider_namespace_packages=ns_param,\n        )\n        assert mod.__name__ == \"_tests.b.test_core\"\n\n        # Ensure we do not import the same module again (#11475).\n        mod2 = import_path(\n            test_path2,\n            mode=\"importlib\",\n            root=pytester.path,\n            consider_namespace_packages=ns_param,\n        )\n        assert mod is mod2\n", "type": "function"}, {"name": "test_check_filepath_consistency", "is_method": true, "class_name": "TestImportPath", "parameters": ["self", "monkeypatch", "tmp_path", "ns_param"], "calls": ["tmp_path.joinpath", "p.touch", "ModuleType", "tmp_path.joinpath", "pseudopath.touch", "str", "monkeypatch.setitem", "issubclass", "monkeypatch.context", "pytest.raises", "import_path", "str", "ModuleType", "tmp_path.joinpath", "pseudopath.touch", "str", "mp.setitem", "import_path"], "code_location": {"file": "test_pathlib.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 298, "end_line": 326}, "code_snippet": "    def test_check_filepath_consistency(\n        self, monkeypatch: MonkeyPatch, tmp_path: Path, ns_param: bool\n    ) -> None:\n        name = \"pointsback123\"\n        p = tmp_path.joinpath(name + \".py\")\n        p.touch()\n        with monkeypatch.context() as mp:\n            for ending in (\".pyc\", \".pyo\"):\n                mod = ModuleType(name)\n                pseudopath = tmp_path.joinpath(name + ending)\n                pseudopath.touch()\n                mod.__file__ = str(pseudopath)\n                mp.setitem(sys.modules, name, mod)\n                newmod = import_path(\n                    p, root=tmp_path, consider_namespace_packages=ns_param\n                )\n                assert mod == newmod\n        mod = ModuleType(name)\n        pseudopath = tmp_path.joinpath(name + \"123.py\")\n        pseudopath.touch()\n        mod.__file__ = str(pseudopath)\n        monkeypatch.setitem(sys.modules, name, mod)\n        with pytest.raises(ImportPathMismatchError) as excinfo:\n            import_path(p, root=tmp_path, consider_namespace_packages=ns_param)\n        modname, modfile, orig = excinfo.value.args\n        assert modname == name\n        assert modfile == str(pseudopath)\n        assert orig == p\n        assert issubclass(ImportPathMismatchError, ImportError)\n", "type": "function"}, {"name": "test_pyimport_check_filepath_consistency", "is_method": true, "class_name": "TestImport", "parameters": ["self", "monkeypatch", "tmpdir"], "calls": ["type", "tmpdir.ensure", "ModuleType", "tmpdir.ensure", "str", "monkeypatch.setitem", "pytest.raises", "issubclass", "monkeypatch.context", "ModuleType", "tmpdir.ensure", "str", "mp.setitem", "p.pyimport"], "code_location": {"file": "test_local.py", "path": "/data3/pwh/swebench-repos/pytest/testing/_py", "start_line": 1086, "end_line": 1107}, "code_snippet": "    def test_pyimport_check_filepath_consistency(self, monkeypatch, tmpdir):\n        name = \"pointsback123\"\n        ModuleType = type(os)\n        p = tmpdir.ensure(name + \".py\")\n        with monkeypatch.context() as mp:\n            for ending in (\".pyc\", \"$py.class\", \".pyo\"):\n                mod = ModuleType(name)\n                pseudopath = tmpdir.ensure(name + ending)\n                mod.__file__ = str(pseudopath)\n                mp.setitem(sys.modules, name, mod)\n                newmod = p.pyimport()\n                assert mod == newmod\n        mod = ModuleType(name)\n        pseudopath = tmpdir.ensure(name + \"123.py\")\n        mod.__file__ = str(pseudopath)\n        monkeypatch.setitem(sys.modules, name, mod)\n        excinfo = pytest.raises(pseudopath.ImportMismatchError, p.pyimport)\n        modname, modfile, orig = excinfo.value.args\n        assert modname == name\n        assert modfile == pseudopath\n        assert orig == p\n        assert issubclass(pseudopath.ImportMismatchError, ImportError)\n", "type": "function"}, {"name": "import_path", "is_method": false, "class_name": null, "parameters": ["path"], "calls": ["Path", "ImportMode", "importlib.import_module", "os.environ.get", "path.exists", "ImportError", "module_name_from_path", "_import_module_using_spec", "resolve_pkg_root_and_module_name", "module_file.endswith", "module_file.endswith", "resolve_pkg_root_and_module_name", "_import_module_using_spec", "contextlib.suppress", "ImportError", "str", "sys.path.append", "assert_never", "ImportPathMismatchError", "_is_same", "ImportPathMismatchError", "contextlib.suppress", "str", "str", "sys.path.insert", "str", "str", "len"], "code_location": {"file": "pathlib.py", "path": "/data3/pwh/swebench-repos/pytest/src/_pytest", "start_line": 489, "end_line": 612}, "code_snippet": "def import_path(\n    path: str | os.PathLike[str],\n    *,\n    mode: str | ImportMode = ImportMode.prepend,\n    root: Path,\n    consider_namespace_packages: bool,\n) -> ModuleType:\n    \"\"\"\n    Import and return a module from the given path, which can be a file (a module) or\n    a directory (a package).\n\n    :param path:\n        Path to the file to import.\n\n    :param mode:\n        Controls the underlying import mechanism that will be used:\n\n        * ImportMode.prepend: the directory containing the module (or package, taking\n          `__init__.py` files into account) will be put at the *start* of `sys.path` before\n          being imported with `importlib.import_module`.\n\n        * ImportMode.append: same as `prepend`, but the directory will be appended\n          to the end of `sys.path`, if not already in `sys.path`.\n\n        * ImportMode.importlib: uses more fine control mechanisms provided by `importlib`\n          to import the module, which avoids having to muck with `sys.path` at all. It effectively\n          allows having same-named test modules in different places.\n\n    :param root:\n        Used as an anchor when mode == ImportMode.importlib to obtain\n        a unique name for the module being imported so it can safely be stored\n        into ``sys.modules``.\n\n    :param consider_namespace_packages:\n        If True, consider namespace packages when resolving module names.\n\n    :raises ImportPathMismatchError:\n        If after importing the given `path` and the module `__file__`\n        are different. Only raised in `prepend` and `append` modes.\n    \"\"\"\n    path = Path(path)\n    mode = ImportMode(mode)\n\n    if not path.exists():\n        raise ImportError(path)\n\n    if mode is ImportMode.importlib:\n        # Try to import this module using the standard import mechanisms, but\n        # without touching sys.path.\n        try:\n            pkg_root, module_name = resolve_pkg_root_and_module_name(\n                path, consider_namespace_packages=consider_namespace_packages\n            )\n        except CouldNotResolvePathError:\n            pass\n        else:\n            # If the given module name is already in sys.modules, do not import it again.\n            with contextlib.suppress(KeyError):\n                return sys.modules[module_name]\n\n            mod = _import_module_using_spec(\n                module_name, path, pkg_root, insert_modules=False\n            )\n            if mod is not None:\n                return mod\n\n        # Could not import the module with the current sys.path, so we fall back\n        # to importing the file as a single module, not being a part of a package.\n        module_name = module_name_from_path(path, root)\n        with contextlib.suppress(KeyError):\n            return sys.modules[module_name]\n\n        mod = _import_module_using_spec(\n            module_name, path, path.parent, insert_modules=True\n        )\n        if mod is None:\n            raise ImportError(f\"Can't find module {module_name} at location {path}\")\n        return mod\n\n    try:\n        pkg_root, module_name = resolve_pkg_root_and_module_name(\n            path, consider_namespace_packages=consider_namespace_packages\n        )\n    except CouldNotResolvePathError:\n        pkg_root, module_name = path.parent, path.stem\n\n    # Change sys.path permanently: restoring it at the end of this function would cause surprising\n    # problems because of delayed imports: for example, a conftest.py file imported by this function\n    # might have local imports, which would fail at runtime if we restored sys.path.\n    if mode is ImportMode.append:\n        if str(pkg_root) not in sys.path:\n            sys.path.append(str(pkg_root))\n    elif mode is ImportMode.prepend:\n        if str(pkg_root) != sys.path[0]:\n            sys.path.insert(0, str(pkg_root))\n    else:\n        assert_never(mode)\n\n    importlib.import_module(module_name)\n\n    mod = sys.modules[module_name]\n    if path.name == \"__init__.py\":\n        return mod\n\n    ignore = os.environ.get(\"PY_IGNORE_IMPORTMISMATCH\", \"\")\n    if ignore != \"1\":\n        module_file = mod.__file__\n        if module_file is None:\n            raise ImportPathMismatchError(module_name, module_file, path)\n\n        if module_file.endswith((\".pyc\", \".pyo\")):\n            module_file = module_file[:-1]\n        if module_file.endswith(os.sep + \"__init__.py\"):\n            module_file = module_file[: -(len(os.sep + \"__init__.py\"))]\n\n        try:\n            is_same = _is_same(str(path), module_file)\n        except FileNotFoundError:\n            is_same = False\n\n        if not is_same:\n            raise ImportPathMismatchError(module_name, module_file, path)\n\n    return mod\n", "type": "function"}, {"name": "test_samefile_false_negatives", "is_method": false, "class_name": null, "parameters": ["tmp_path", "monkeypatch"], "calls": ["pytest.mark.skipif", "tmp_path.joinpath", "module_path.write_text", "monkeypatch.syspath_prepend", "monkeypatch.context", "mp.setattr", "import_path", "sys.platform.startswith", "getattr"], "code_location": {"file": "test_pathlib.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 552, "end_line": 570}, "code_snippet": "def test_samefile_false_negatives(tmp_path: Path, monkeypatch: MonkeyPatch) -> None:\n    \"\"\"\n    import_file() should not raise ImportPathMismatchError if the paths are exactly\n    equal on Windows. It seems directories mounted as UNC paths make os.path.samefile\n    return False, even when they are clearly equal.\n    \"\"\"\n    module_path = tmp_path.joinpath(\"my_module.py\")\n    module_path.write_text(\"def foo(): return 42\", encoding=\"utf-8\")\n    monkeypatch.syspath_prepend(tmp_path)\n\n    with monkeypatch.context() as mp:\n        # Forcibly make os.path.samefile() return False here to ensure we are comparing\n        # the paths too. Using a context to narrow the patch as much as possible given\n        # this is an important system function.\n        mp.setattr(os.path, \"samefile\", lambda x, y: False)\n        module = import_path(\n            module_path, root=tmp_path, consider_namespace_packages=False\n        )\n    assert getattr(module, \"foo\")() == 42\n", "type": "function"}, {"name": "test_remembers_previous_imports", "is_method": true, "class_name": "TestImportPath", "parameters": ["self", "simple_module", "tmp_path", "ns_param"], "calls": ["import_path", "import_path"], "code_location": {"file": "test_pathlib.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 381, "end_line": 397}, "code_snippet": "    def test_remembers_previous_imports(\n        self, simple_module: Path, tmp_path: Path, ns_param: bool\n    ) -> None:\n        \"\"\"`importlib` mode called remembers previous module (#10341, #10811).\"\"\"\n        module1 = import_path(\n            simple_module,\n            mode=\"importlib\",\n            root=tmp_path,\n            consider_namespace_packages=ns_param,\n        )\n        module2 = import_path(\n            simple_module,\n            mode=\"importlib\",\n            root=tmp_path,\n            consider_namespace_packages=ns_param,\n        )\n        assert module1 is module2\n", "type": "function"}, {"name": "test_import_after", "is_method": true, "class_name": "TestImportPath", "parameters": ["self", "tmp_path", "ns_param"], "calls": ["mkdir", "touch", "tmp_path.joinpath", "mod1path.touch", "import_path", "tmp_path.joinpath", "tmp_path.joinpath"], "code_location": {"file": "test_pathlib.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 285, "end_line": 296}, "code_snippet": "    def test_import_after(self, tmp_path: Path, ns_param: bool) -> None:\n        tmp_path.joinpath(\"xxxpackage\").mkdir()\n        tmp_path.joinpath(\"xxxpackage\", \"__init__.py\").touch()\n        mod1path = tmp_path.joinpath(\"xxxpackage\", \"module1.py\")\n        mod1path.touch()\n        mod1 = import_path(\n            mod1path, root=tmp_path, consider_namespace_packages=ns_param\n        )\n        assert mod1.__name__ == \"xxxpackage.module1\"\n        from xxxpackage import module1\n\n        assert module1 is mod1\n", "type": "function"}, {"name": "test_honors_pep_235", "is_method": true, "class_name": "TestAssertionRewrite", "parameters": ["self", "pytester", "monkeypatch"], "calls": ["pytester.makepyfile", "pytester.mkdir", "pytester.mkpydir", "write_text", "pytester.makepyfile", "monkeypatch.syspath_prepend", "assert_outcomes", "str", "str", "xdir.joinpath", "joinpath", "pytester.runpytest", "xdir.joinpath"], "code_location": {"file": "test_assertrewrite.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 375, "end_line": 392}, "code_snippet": "    def test_honors_pep_235(self, pytester: Pytester, monkeypatch) -> None:\n        # note: couldn't make it fail on macos with a single `sys.path` entry\n        # note: these modules are named `test_*` to trigger rewriting\n        pytester.makepyfile(test_y=\"x = 1\")\n        xdir = pytester.mkdir(\"x\")\n        pytester.mkpydir(str(xdir.joinpath(\"test_Y\")))\n        xdir.joinpath(\"test_Y\").joinpath(\"__init__.py\").write_text(\n            \"x = 2\", encoding=\"utf-8\"\n        )\n        pytester.makepyfile(\n            \"import test_y\\n\"\n            \"import test_Y\\n\"\n            \"def test():\\n\"\n            \"    assert test_y.x == 1\\n\"\n            \"    assert test_Y.x == 2\\n\"\n        )\n        monkeypatch.syspath_prepend(str(xdir))\n        pytester.runpytest().assert_outcomes(passed=1)\n", "type": "function"}, {"name": "test_import_submodule_not_namespace", "is_method": false, "class_name": null, "parameters": ["pytester"], "calls": ["pytester.syspathinsert", "mkdir", "pytester.path.joinpath", "foo_path.touch", "pytester.path.joinpath", "bar_path.touch", "mkdir", "import_path", "import_path", "Path", "Path", "pytester.path.joinpath", "pytester.path.joinpath"], "code_location": {"file": "test_pathlib.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 1336, "end_line": 1373}, "code_snippet": "def test_import_submodule_not_namespace(pytester: Pytester) -> None:\n    \"\"\"\n    Regression test for importing a submodule 'foo.bar' while there is a 'bar' directory\n    reachable from sys.path -- ensuring the top-level module does not end up imported as a namespace\n    package.\n\n    #12194\n    https://github.com/pytest-dev/pytest/pull/12208#issuecomment-2056458432\n    \"\"\"\n    pytester.syspathinsert()\n    # Create package 'foo' with a submodule 'bar'.\n    pytester.path.joinpath(\"foo\").mkdir()\n    foo_path = pytester.path.joinpath(\"foo/__init__.py\")\n    foo_path.touch()\n    bar_path = pytester.path.joinpath(\"foo/bar.py\")\n    bar_path.touch()\n    # Create top-level directory in `sys.path` with the same name as that submodule.\n    pytester.path.joinpath(\"bar\").mkdir()\n\n    # Import `foo`, then `foo.bar`, and check they were imported from the correct location.\n    foo = import_path(\n        foo_path,\n        mode=ImportMode.importlib,\n        root=pytester.path,\n        consider_namespace_packages=False,\n    )\n    bar = import_path(\n        bar_path,\n        mode=ImportMode.importlib,\n        root=pytester.path,\n        consider_namespace_packages=False,\n    )\n    assert foo.__name__ == \"foo\"\n    assert bar.__name__ == \"foo.bar\"\n    assert foo.__file__ is not None\n    assert bar.__file__ is not None\n    assert Path(foo.__file__) == foo_path\n    assert Path(bar.__file__) == bar_path\n", "type": "function"}], "retrieved_count": 10, "cost_time": 1.1574294567108154}
{"question": "Why does the test design rely on injecting the TerminalReporter through a fixture request rather than directly instantiating it, and what architectural principle does this reflect about pytest's plugin system?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"name": "tr", "is_method": false, "class_name": null, "parameters": [], "calls": ["pytest.fixture", "_pytest.config._prepareconfig", "TerminalReporter"], "code_location": {"file": "test_terminal.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 1866, "end_line": 1868}, "code_snippet": "def tr() -> TerminalReporter:\n    config = _pytest.config._prepareconfig([])\n    return TerminalReporter(config)\n", "type": "function"}, {"name": "test_getreportopt", "is_method": false, "class_name": null, "parameters": [], "calls": ["cast", "Option", "FakeConfig", "getreportopt", "getreportopt", "getreportopt", "getreportopt", "getreportopt", "getreportopt", "getreportopt", "getreportopt", "getreportopt", "getreportopt", "getreportopt", "getreportopt", "getreportopt", "getreportopt"], "code_location": {"file": "test_terminal.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 1400, "end_line": 1456}, "code_snippet": "def test_getreportopt() -> None:\n    from _pytest.terminal import _REPORTCHARS_DEFAULT\n\n    class FakeConfig:\n        class Option:\n            reportchars = _REPORTCHARS_DEFAULT\n            disable_warnings = False\n\n        option = Option()\n\n    config = cast(Config, FakeConfig())\n\n    assert _REPORTCHARS_DEFAULT == \"fE\"\n\n    # Default.\n    assert getreportopt(config) == \"wfE\"\n\n    config.option.reportchars = \"sf\"\n    assert getreportopt(config) == \"wsf\"\n\n    config.option.reportchars = \"sfxw\"\n    assert getreportopt(config) == \"sfxw\"\n\n    config.option.reportchars = \"a\"\n    assert getreportopt(config) == \"wsxXEf\"\n\n    config.option.reportchars = \"N\"\n    assert getreportopt(config) == \"w\"\n\n    config.option.reportchars = \"NwfE\"\n    assert getreportopt(config) == \"wfE\"\n\n    config.option.reportchars = \"NfENx\"\n    assert getreportopt(config) == \"wx\"\n\n    # Now with --disable-warnings.\n    config.option.disable_warnings = True\n    config.option.reportchars = \"a\"\n    assert getreportopt(config) == \"sxXEf\"\n\n    config.option.reportchars = \"sfx\"\n    assert getreportopt(config) == \"sfx\"\n\n    config.option.reportchars = \"sfxw\"\n    assert getreportopt(config) == \"sfx\"\n\n    config.option.reportchars = \"a\"\n    assert getreportopt(config) == \"sxXEf\"\n\n    config.option.reportchars = \"A\"\n    assert getreportopt(config) == \"PpsxXEf\"\n\n    config.option.reportchars = \"AN\"\n    assert getreportopt(config) == \"\"\n\n    config.option.reportchars = \"NwfE\"\n    assert getreportopt(config) == \"fE\"\n", "type": "function"}, {"name": "pytest_configure", "is_method": false, "class_name": null, "parameters": ["config"], "calls": ["TerminalReporter", "config.pluginmanager.register", "config.trace.root.setprocessor", "join", "reporter.write_line", "map"], "code_location": {"file": "terminal.py", "path": "/data3/pwh/swebench-repos/pytest/src/_pytest", "start_line": 287, "end_line": 296}, "code_snippet": "def pytest_configure(config: Config) -> None:\n    reporter = TerminalReporter(config, sys.stdout)\n    config.pluginmanager.register(reporter, \"terminalreporter\")\n    if config.option.debug or config.option.traceconfig:\n\n        def mywriter(tags, args):\n            msg = \" \".join(map(str, args))\n            reporter.write_line(\"[traceconfig] \" + msg)\n\n        config.trace.root.setprocessor(\"pytest:config\", mywriter)\n", "type": "function"}, {"name": "test_terminal_summary", "is_method": false, "class_name": null, "parameters": ["pytester"], "calls": ["pytester.makeconftest", "pytester.runpytest", "result.stdout.fnmatch_lines"], "code_location": {"file": "test_terminal.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 1768, "end_line": 1785}, "code_snippet": "def test_terminal_summary(pytester: Pytester) -> None:\n    pytester.makeconftest(\n        \"\"\"\n        def pytest_terminal_summary(terminalreporter, exitstatus):\n            w = terminalreporter\n            w.section(\"hello\")\n            w.line(\"world\")\n            w.line(\"exitstatus: {0}\".format(exitstatus))\n    \"\"\"\n    )\n    result = pytester.runpytest()\n    result.stdout.fnmatch_lines(\n        \"\"\"\n        *==== hello ====*\n        world\n        exitstatus: 5\n    \"\"\"\n    )\n", "type": "function"}, {"name": "__init__", "is_method": true, "class_name": "_LiveLoggingStreamHandler", "parameters": ["self", "terminal_reporter", "capture_manager"], "calls": ["__init__", "self.reset", "self.set_when", "super"], "code_location": {"file": "logging.py", "path": "/data3/pwh/swebench-repos/pytest/src/_pytest", "start_line": 903, "end_line": 912}, "code_snippet": "    def __init__(\n        self,\n        terminal_reporter: TerminalReporter,\n        capture_manager: CaptureManager | None,\n    ) -> None:\n        super().__init__(stream=terminal_reporter)  # type: ignore[arg-type]\n        self.capture_manager = capture_manager\n        self.reset()\n        self.set_when(None)\n        self._test_outcome_written = False\n", "type": "function"}, {"name": "test_make_hook_recorder", "is_method": false, "class_name": null, "parameters": ["pytester"], "calls": ["pytester.getitem", "pytester.make_hook_recorder", "recorder.hook.pytest_runtest_logreport", "recorder.getfailures", "recorder.getfailures", "recorder.hook.pytest_runtest_logreport", "pytester.getmodulecol", "modcol.config.hook.pytest_make_collect_report", "recorder.hook.pytest_collectreport", "recorder.listoutcomes", "recorder.countoutcomes", "recorder.unregister", "recorder.clear", "recorder.hook.pytest_runtest_logreport", "pytest.raises", "recorder.getfailures", "pytest.xfail", "len", "recorder.getfailedcollections"], "code_location": {"file": "test_pytester.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 22, "end_line": 74}, "code_snippet": "def test_make_hook_recorder(pytester: Pytester) -> None:\n    item = pytester.getitem(\"def test_func(): pass\")\n    recorder = pytester.make_hook_recorder(item.config.pluginmanager)\n    assert not recorder.getfailures()\n\n    # (The silly condition is to fool mypy that the code below this is reachable)\n    if 1 + 1 == 2:\n        pytest.xfail(\"internal reportrecorder tests need refactoring\")\n\n    class rep:\n        excinfo = None\n        passed = False\n        failed = True\n        skipped = False\n        when = \"call\"\n\n    recorder.hook.pytest_runtest_logreport(report=rep)  # type: ignore[attr-defined]\n    failures = recorder.getfailures()\n    assert failures == [rep]  # type: ignore[comparison-overlap]\n    failures = recorder.getfailures()\n    assert failures == [rep]  # type: ignore[comparison-overlap]\n\n    class rep2:\n        excinfo = None\n        passed = False\n        failed = False\n        skipped = True\n        when = \"call\"\n\n    rep2.passed = False\n    rep2.skipped = True\n    recorder.hook.pytest_runtest_logreport(report=rep2)  # type: ignore[attr-defined]\n\n    modcol = pytester.getmodulecol(\"\")\n    rep3 = modcol.config.hook.pytest_make_collect_report(collector=modcol)\n    rep3.passed = False\n    rep3.failed = True\n    rep3.skipped = False\n    recorder.hook.pytest_collectreport(report=rep3)  # type: ignore[attr-defined]\n\n    passed, skipped, failed = recorder.listoutcomes()\n    assert not passed and skipped and failed\n\n    numpassed, numskipped, numfailed = recorder.countoutcomes()\n    assert numpassed == 0\n    assert numskipped == 1\n    assert numfailed == 1\n    assert len(recorder.getfailedcollections()) == 1\n\n    recorder.unregister()  # type: ignore[attr-defined]\n    recorder.clear()\n    recorder.hook.pytest_runtest_logreport(report=rep3)  # type: ignore[attr-defined]\n    pytest.raises(ValueError, recorder.getfailures)\n", "type": "function"}, {"name": "test_internalerror", "is_method": true, "class_name": "TestTerminal", "parameters": ["self", "pytester", "linecomp"], "calls": ["pytester.getmodulecol", "TerminalReporter", "rep.pytest_internalerror", "linecomp.assert_contains_lines", "pytest.raises", "ValueError", "excinfo.getrepr"], "code_location": {"file": "test_terminal.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 140, "end_line": 146}, "code_snippet": "    def test_internalerror(self, pytester: Pytester, linecomp) -> None:\n        modcol = pytester.getmodulecol(\"def test_one(): pass\")\n        rep = TerminalReporter(modcol.config, file=linecomp.stringio)\n        with pytest.raises(ValueError) as excinfo:\n            raise ValueError(\"hello\")\n        rep.pytest_internalerror(excinfo.getrepr())\n        linecomp.assert_contains_lines([\"INTERNALERROR> *ValueError*hello*\"])\n", "type": "function"}, {"name": "test_no_terminal_plugin", "is_method": false, "class_name": null, "parameters": ["pytester"], "calls": ["pytester.makepyfile", "pytester.runpytest"], "code_location": {"file": "acceptance_test.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 1604, "end_line": 1608}, "code_snippet": "def test_no_terminal_plugin(pytester: Pytester) -> None:\n    \"\"\"Smoke test to ensure pytest can execute without the terminal plugin (#9422).\"\"\"\n    pytester.makepyfile(\"def test(): assert 1 == 2\")\n    result = pytester.runpytest(\"-pno:terminal\", \"-s\")\n    assert result.ret == ExitCode.TESTS_FAILED\n", "type": "function"}, {"name": "test_pass_extra_reporting", "is_method": false, "class_name": null, "parameters": ["pytester"], "calls": ["pytester.makepyfile", "pytester.runpytest", "result.stdout.no_fnmatch_line", "pytester.runpytest", "result.stdout.fnmatch_lines"], "code_location": {"file": "test_terminal.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 1257, "end_line": 1262}, "code_snippet": "def test_pass_extra_reporting(pytester: Pytester) -> None:\n    pytester.makepyfile(\"def test_this(): assert 1\")\n    result = pytester.runpytest()\n    result.stdout.no_fnmatch_line(\"*short test summary*\")\n    result = pytester.runpytest(\"-rp\")\n    result.stdout.fnmatch_lines([\"*test summary*\", \"PASS*test_pass_extra_reporting*\"])\n", "type": "function"}, {"name": "test_terminal_report_failedfirst", "is_method": true, "class_name": "TestLastFailed", "parameters": ["self", "pytester"], "calls": ["pytester.makepyfile", "pytester.runpytest", "result.stdout.fnmatch_lines", "pytester.runpytest", "result.stdout.fnmatch_lines"], "code_location": {"file": "test_cacheprovider.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 499, "end_line": 516}, "code_snippet": "    def test_terminal_report_failedfirst(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            test_a=\"\"\"\n            def test_a1(): assert 0\n            def test_a2(): pass\n        \"\"\"\n        )\n        result = pytester.runpytest()\n        result.stdout.fnmatch_lines([\"collected 2 items\", \"*1 failed, 1 passed in*\"])\n\n        result = pytester.runpytest(\"--ff\")\n        result.stdout.fnmatch_lines(\n            [\n                \"collected 2 items\",\n                \"run-last-failure: rerun previous 1 failure first\",\n                \"*1 failed, 1 passed in*\",\n            ]\n        )\n", "type": "function"}], "retrieved_count": 10, "cost_time": 1.1515181064605713}
{"question": "How should the `isnosetest` method be refactored to separate the concern of attribute validation from test detection logic, and what design pattern would enable this separation while maintaining backward compatibility with nose-style test markers across the PyCollector hierarchy?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"name": "isnosetest", "is_method": true, "class_name": "PyCollector", "parameters": ["self", "obj"], "calls": ["safe_getattr"], "code_location": {"file": "python.py", "path": "/data3/pwh/swebench-repos/pytest/src/_pytest", "start_line": 347, "end_line": 354}, "code_snippet": "    def isnosetest(self, obj: object) -> bool:\n        \"\"\"Look for the __test__ attribute, which is applied by the\n        @nose.tools.istest decorator.\n        \"\"\"\n        # We explicitly check for \"is True\" here to not mistakenly treat\n        # classes with a custom __getattr__ returning something truthy (like a\n        # function) as test classes.\n        return safe_getattr(obj, \"__test__\", False) is True\n", "type": "function"}, {"name": "test_isclasscheck_issue53", "is_method": false, "class_name": null, "parameters": ["pytester"], "calls": ["pytester.makepyfile", "pytester.runpytest"], "code_location": {"file": "test_unittest.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 52, "end_line": 63}, "code_snippet": "def test_isclasscheck_issue53(pytester: Pytester) -> None:\n    testpath = pytester.makepyfile(\n        \"\"\"\n        import unittest\n        class _E(object):\n            def __getattr__(self, tag):\n                pass\n        E = _E()\n    \"\"\"\n    )\n    result = pytester.runpytest(testpath)\n    assert result.ret == ExitCode.NO_TESTS_COLLECTED\n", "type": "function"}, {"name": "pytest_pycollect_makeitem", "is_method": false, "class_name": null, "parameters": ["collector", "name", "obj"], "calls": ["hookimpl", "isinstance", "type", "safe_isclass", "collector.istestclass", "collector.istestfunction", "Class.from_parent", "getattr", "getfslineno", "warnings.warn_explicit", "getattr", "inspect.isfunction", "inspect.isfunction", "inspect.isgeneratorfunction", "list", "get_real_func", "PytestCollectionWarning", "str", "fail", "collector._genfunctions"], "code_location": {"file": "python.py", "path": "/data3/pwh/swebench-repos/pytest/src/_pytest", "start_line": 210, "end_line": 242}, "code_snippet": "def pytest_pycollect_makeitem(\n    collector: Module | Class, name: str, obj: object\n) -> None | nodes.Item | nodes.Collector | list[nodes.Item | nodes.Collector]:\n    assert isinstance(collector, (Class, Module)), type(collector)\n    # Nothing was collected elsewhere, let's do it here.\n    if safe_isclass(obj):\n        if collector.istestclass(obj, name):\n            return Class.from_parent(collector, name=name, obj=obj)\n    elif collector.istestfunction(obj, name):\n        # mock seems to store unbound methods (issue473), normalize it.\n        obj = getattr(obj, \"__func__\", obj)\n        # We need to try and unwrap the function if it's a functools.partial\n        # or a functools.wrapped.\n        # We mustn't if it's been wrapped with mock.patch (python 2 only).\n        if not (inspect.isfunction(obj) or inspect.isfunction(get_real_func(obj))):\n            filename, lineno = getfslineno(obj)\n            warnings.warn_explicit(\n                message=PytestCollectionWarning(\n                    f\"cannot collect {name!r} because it is not a function.\"\n                ),\n                category=None,\n                filename=str(filename),\n                lineno=lineno + 1,\n            )\n        elif getattr(obj, \"__test__\", True):\n            if inspect.isgeneratorfunction(obj):\n                fail(\n                    f\"'yield' keyword is allowed in fixtures, but not in tests ({name})\",\n                    pytrace=False,\n                )\n            return list(collector._genfunctions(name, obj))\n        return None\n    return None\n", "type": "function"}, {"name": "test_collect_protocol_method", "is_method": true, "class_name": "TestSession", "parameters": ["self", "pytester"], "calls": ["pytester.makepyfile", "pytester.inline_genitems", "len", "self.get_reported_items"], "code_location": {"file": "test_collection.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 546, "end_line": 562}, "code_snippet": "    def test_collect_protocol_method(self, pytester: Pytester) -> None:\n        p = pytester.makepyfile(\n            \"\"\"\n            class TestClass(object):\n                def test_method(self):\n                    pass\n        \"\"\"\n        )\n        normid = p.name + \"::TestClass::test_method\"\n        for id in [p.name, p.name + \"::TestClass\", normid]:\n            items, hookrec = pytester.inline_genitems(id)\n            assert len(items) == 1\n            assert items[0].name == \"test_method\"\n            newid = items[0].nodeid\n            assert newid == normid\n            # ensure we are reporting the collection of the single test item (#2464)\n            assert [x.name for x in self.get_reported_items(hookrec)] == [\"test_method\"]\n", "type": "function"}, {"name": "test_early_ignored_attributes", "is_method": true, "class_name": "TestConftestCustomization", "parameters": ["self", "pytester"], "calls": ["pytester.makeini", "pytester.makepyfile", "pytester.inline_genitems", "len"], "code_location": {"file": "collect.py", "path": "/data3/pwh/swebench-repos/pytest/testing/python", "start_line": 1001, "end_line": 1027}, "code_snippet": "    def test_early_ignored_attributes(self, pytester: Pytester) -> None:\n        \"\"\"Builtin attributes should be ignored early on, even if\n        configuration would otherwise allow them.\n\n        This tests a performance optimization, not correctness, really,\n        although it tests PytestCollectionWarning is not raised, while\n        it would have been raised otherwise.\n        \"\"\"\n        pytester.makeini(\n            \"\"\"\n            [pytest]\n            python_classes=*\n            python_functions=*\n        \"\"\"\n        )\n        pytester.makepyfile(\n            \"\"\"\n            class TestEmpty:\n                pass\n            test_empty = TestEmpty()\n            def test_real():\n                pass\n        \"\"\"\n        )\n        items, rec = pytester.inline_genitems()\n        assert rec.ret == 0\n        assert len(items) == 1\n", "type": "function"}, {"name": "pytest_pycollect_makeitem", "is_method": false, "class_name": null, "parameters": ["collector", "name", "obj"], "calls": ["inspect.isabstract", "UnitTestCase.from_parent", "issubclass"], "code_location": {"file": "unittest.py", "path": "/data3/pwh/swebench-repos/pytest/src/_pytest", "start_line": 52, "end_line": 69}, "code_snippet": "def pytest_pycollect_makeitem(\n    collector: Module | Class, name: str, obj: object\n) -> UnitTestCase | None:\n    try:\n        # Has unittest been imported?\n        ut = sys.modules[\"unittest\"]\n        # Is obj a subclass of unittest.TestCase?\n        # Type ignored because `ut` is an opaque module.\n        if not issubclass(obj, ut.TestCase):  # type: ignore\n            return None\n    except Exception:\n        return None\n    # Is obj a concrete class?\n    # Abstract classes can't be instantiated so no point collecting them.\n    if inspect.isabstract(obj):\n        return None\n    # Yes, so let's collect it.\n    return UnitTestCase.from_parent(collector, name=name, obj=obj)\n", "type": "function"}, {"name": "collect", "is_method": true, "class_name": "Class", "parameters": ["self"], "calls": ["hasinit", "self._register_setup_class_fixture", "self._register_setup_method_fixture", "self.session._fixturemanager.parsefactories", "collect", "safe_getattr", "self.warn", "hasnew", "self.newinstance", "PytestCollectionWarning", "self.warn", "super", "PytestCollectionWarning"], "code_location": {"file": "python.py", "path": "/data3/pwh/swebench-repos/pytest/src/_pytest", "start_line": 747, "end_line": 774}, "code_snippet": "    def collect(self) -> Iterable[nodes.Item | nodes.Collector]:\n        if not safe_getattr(self.obj, \"__test__\", True):\n            return []\n        if hasinit(self.obj):\n            assert self.parent is not None\n            self.warn(\n                PytestCollectionWarning(\n                    f\"cannot collect test class {self.obj.__name__!r} because it has a \"\n                    f\"__init__ constructor (from: {self.parent.nodeid})\"\n                )\n            )\n            return []\n        elif hasnew(self.obj):\n            assert self.parent is not None\n            self.warn(\n                PytestCollectionWarning(\n                    f\"cannot collect test class {self.obj.__name__!r} because it has a \"\n                    f\"__new__ constructor (from: {self.parent.nodeid})\"\n                )\n            )\n            return []\n\n        self._register_setup_class_fixture()\n        self._register_setup_method_fixture()\n\n        self.session._fixturemanager.parsefactories(self.newinstance(), self.nodeid)\n\n        return super().collect()\n", "type": "function"}, {"name": "collect", "is_method": true, "class_name": "PyCollector", "parameters": ["self"], "calls": ["isinstance", "set", "self.session.config.getini", "reversed", "getattr", "getattr", "list", "dict_values.append", "result.extend", "dicts.append", "dic.items", "seen.add", "ihook.pytest_pycollect_makeitem", "isinstance", "isinstance", "inspect.isfunction", "inspect.isclass", "values.extend", "values.append", "self._getobj"], "code_location": {"file": "python.py", "path": "/data3/pwh/swebench-repos/pytest/src/_pytest", "start_line": 390, "end_line": 439}, "code_snippet": "    def collect(self) -> Iterable[nodes.Item | nodes.Collector]:\n        if not getattr(self.obj, \"__test__\", True):\n            return []\n\n        # Avoid random getattrs and peek in the __dict__ instead.\n        dicts = [getattr(self.obj, \"__dict__\", {})]\n        if isinstance(self.obj, type):\n            for basecls in self.obj.__mro__:\n                dicts.append(basecls.__dict__)\n\n        # In each class, nodes should be definition ordered.\n        # __dict__ is definition ordered.\n        seen: set[str] = set()\n        dict_values: list[list[nodes.Item | nodes.Collector]] = []\n        collect_imported_tests = self.session.config.getini(\"collect_imported_tests\")\n        ihook = self.ihook\n        for dic in dicts:\n            values: list[nodes.Item | nodes.Collector] = []\n            # Note: seems like the dict can change during iteration -\n            # be careful not to remove the list() without consideration.\n            for name, obj in list(dic.items()):\n                if name in IGNORED_ATTRIBUTES:\n                    continue\n                if name in seen:\n                    continue\n                seen.add(name)\n\n                if not collect_imported_tests and isinstance(self, Module):\n                    # Do not collect functions and classes from other modules.\n                    if inspect.isfunction(obj) or inspect.isclass(obj):\n                        if obj.__module__ != self._getobj().__name__:\n                            continue\n\n                res = ihook.pytest_pycollect_makeitem(\n                    collector=self, name=name, obj=obj\n                )\n                if res is None:\n                    continue\n                elif isinstance(res, list):\n                    values.extend(res)\n                else:\n                    values.append(res)\n            dict_values.append(values)\n\n        # Between classes in the class hierarchy, reverse-MRO order -- nodes\n        # inherited from base classes should come before subclasses.\n        result = []\n        for values in reversed(dict_values):\n            result.extend(values)\n        return result\n", "type": "function"}, {"name": "test_collect_versus_item", "is_method": true, "class_name": "TestCollector", "parameters": ["self"], "calls": ["issubclass", "issubclass"], "code_location": {"file": "test_collection.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 34, "end_line": 39}, "code_snippet": "    def test_collect_versus_item(self) -> None:\n        from pytest import Collector\n        from pytest import Item\n\n        assert not issubclass(Collector, Item)\n        assert not issubclass(Item, Collector)\n", "type": "function"}, {"name": "test_issue2234_property", "is_method": true, "class_name": "TestClass", "parameters": ["self", "pytester"], "calls": ["pytester.makepyfile", "pytester.runpytest"], "code_location": {"file": "collect.py", "path": "/data3/pwh/swebench-repos/pytest/testing/python", "start_line": 254, "end_line": 264}, "code_snippet": "    def test_issue2234_property(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            class TestCase(object):\n                @property\n                def prop(self):\n                    raise NotImplementedError()\n        \"\"\"\n        )\n        result = pytester.runpytest()\n        assert result.ret == ExitCode.NO_TESTS_COLLECTED\n", "type": "function"}], "retrieved_count": 10, "cost_time": 1.177116870880127}
{"question": "Why would caching the Source object initialization in setup_class impact the performance characteristics of the TestAccesses test suite when executed repeatedly across multiple test runs?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"name": "setup_class", "is_method": true, "class_name": "TestAccesses", "parameters": ["self"], "calls": ["Source"], "code_location": {"file": "test_source.py", "path": "/data3/pwh/swebench-repos/pytest/testing/code", "start_line": 77, "end_line": 85}, "code_snippet": "    def setup_class(self) -> None:\n        self.source = Source(\n            \"\"\"\\\n            def f(x):\n                pass\n            def g(x):\n                pass\n        \"\"\"\n        )\n", "type": "function"}, {"name": "setup_class", "is_method": true, "class_name": "TestSourceParsing", "parameters": ["self"], "calls": ["strip", "Source"], "code_location": {"file": "test_source.py", "path": "/data3/pwh/swebench-repos/pytest/testing/code", "start_line": 109, "end_line": 117}, "code_snippet": "    def setup_class(self) -> None:\n        self.source = Source(\n            \"\"\"\\\n            def f(x):\n                assert (x ==\n                        3 +\n                        4)\n        \"\"\"\n        ).strip()\n", "type": "function"}, {"name": "TestAccesses", "docstring": "", "methods": ["setup_class", "test_getrange", "test_getrange_step_not_supported", "test_getline", "test_len", "test_iter"], "attributes": [], "code_location": {"file": "test_source.py", "path": "/data3/pwh/swebench-repos/pytest/testing/code", "start_line": 76, "end_line": 105}, "type": "class"}, {"name": "test_scoped_fixture_caching", "is_method": false, "class_name": null, "parameters": ["pytester"], "calls": ["pytester.makepyfile", "pytester.runpytest"], "code_location": {"file": "fixtures.py", "path": "/data3/pwh/swebench-repos/pytest/testing/python", "start_line": 4845, "end_line": 4876}, "code_snippet": "def test_scoped_fixture_caching(pytester: Pytester) -> None:\n    \"\"\"Make sure setup and finalization is only run once when using scoped fixture\n    multiple times.\"\"\"\n    pytester.makepyfile(\n        \"\"\"\n        from __future__ import annotations\n\n        from typing import Generator\n\n        import pytest\n        executed: list[str] = []\n        @pytest.fixture(scope=\"class\")\n        def fixture_1() -> Generator[None, None, None]:\n            executed.append(\"fix setup\")\n            yield\n            executed.append(\"fix teardown\")\n\n\n        class TestFixtureCaching:\n            def test_1(self, fixture_1: None) -> None:\n                assert executed == [\"fix setup\"]\n\n            def test_2(self, fixture_1: None) -> None:\n                assert executed == [\"fix setup\"]\n\n\n        def test_expected_setup_and_teardown() -> None:\n            assert executed == [\"fix setup\", \"fix teardown\"]\n        \"\"\"\n    )\n    result = pytester.runpytest()\n    assert result.ret == 0\n", "type": "function"}, {"name": "test_source_from_lines", "is_method": false, "class_name": null, "parameters": [], "calls": ["Source"], "code_location": {"file": "test_source.py", "path": "/data3/pwh/swebench-repos/pytest/testing/code", "start_line": 48, "end_line": 51}, "code_snippet": "def test_source_from_lines() -> None:\n    lines = [\"a \\n\", \"b\\n\", \"c\"]\n    source = Source(lines)\n    assert source.lines == [\"a \", \"b\", \"c\"]\n", "type": "function"}, {"name": "TestSourceParsing", "docstring": "", "methods": ["setup_class", "test_getstatement", "test_getstatementrange_triple_quoted", "test_getstatementrange_within_constructs", "test_getstatementrange_bug", "test_getstatementrange_bug2", "test_getstatementrange_ast_issue58", "test_getstatementrange_out_of_bounds_py3", "test_getstatementrange_with_syntaxerror_issue7"], "attributes": [], "code_location": {"file": "test_source.py", "path": "/data3/pwh/swebench-repos/pytest/testing/code", "start_line": 108, "end_line": 213}, "type": "class"}, {"name": "test_source_of_class_at_eof_without_newline", "is_method": false, "class_name": null, "parameters": ["_sys_snapshot", "tmp_path"], "calls": ["Source", "tmp_path.joinpath", "path.write_text", "import_path", "Source", "str", "strip", "strip", "str", "str"], "code_location": {"file": "test_source.py", "path": "/data3/pwh/swebench-repos/pytest/testing/code", "start_line": 285, "end_line": 299}, "code_snippet": "def test_source_of_class_at_eof_without_newline(_sys_snapshot, tmp_path: Path) -> None:\n    # this test fails because the implicit inspect.getsource(A) below\n    # does not return the \"x = 1\" last line.\n    source = Source(\n        \"\"\"\n        class A:\n            def method(self):\n                x = 1\n    \"\"\"\n    )\n    path = tmp_path.joinpath(\"a.py\")\n    path.write_text(str(source), encoding=\"utf-8\")\n    mod: Any = import_path(path, root=tmp_path, consider_namespace_packages=False)\n    s2 = Source(mod.A)\n    assert str(source).strip() == str(s2).strip()\n", "type": "function"}, {"name": "test_source_from_method", "is_method": false, "class_name": null, "parameters": [], "calls": ["Source", "TestClass"], "code_location": {"file": "test_source.py", "path": "/data3/pwh/swebench-repos/pytest/testing/code", "start_line": 39, "end_line": 45}, "code_snippet": "def test_source_from_method() -> None:\n    class TestClass:\n        def test_method(self):\n            pass\n\n    source = Source(TestClass().test_method)\n    assert source.lines == [\"def test_method(self):\", \"    pass\"]\n", "type": "function"}, {"name": "setup_class", "is_method": true, "class_name": "TestTry", "parameters": ["self"], "calls": [], "code_location": {"file": "test_source.py", "path": "/data3/pwh/swebench-repos/pytest/testing/code", "start_line": 522, "end_line": 530}, "code_snippet": "    def setup_class(self) -> None:\n        self.source = \"\"\"\\\ntry:\n    raise ValueError\nexcept Something:\n    raise IndexError(1)\nelse:\n    raise KeyError()\n\"\"\"\n", "type": "function"}, {"name": "Source", "docstring": "An immutable object holding a source code fragment.\n\nWhen using Source(...), the source lines are deindented.", "methods": ["__init__", "__eq__", "__getitem__", "__getitem__", "__getitem__", "__iter__", "__len__", "strip", "indent", "getstatement", "getstatementrange", "deindent", "__str__"], "attributes": ["__hash__"], "code_location": {"file": "source.py", "path": "/data3/pwh/swebench-repos/pytest/src/_pytest/_code", "start_line": 16, "end_line": 117}, "type": "class"}], "retrieved_count": 10, "cost_time": 1.1729605197906494}
{"question": "How does the RunAndParse class decouple the concerns of test execution orchestration from XML schema validation and document parsing to maintain separation of responsibilities?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"name": "run_and_parse", "is_method": false, "class_name": null, "parameters": ["pytester", "schema"], "calls": ["RunAndParse"], "code_location": {"file": "test_junitxml.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 56, "end_line": 63}, "code_snippet": "def run_and_parse(pytester: Pytester, schema: xmlschema.XMLSchema) -> RunAndParse:\n    \"\"\"Fixture that returns a function that can be used to execute pytest and\n    return the parsed ``DomNode`` of the root xml node.\n\n    The ``family`` parameter is used to configure the ``junit_family`` of the written report.\n    \"xunit2\" is also automatically validated against the schema.\n    \"\"\"\n    return RunAndParse(pytester, schema)\n", "type": "function"}, {"name": "__call__", "is_method": true, "class_name": "RunAndParse", "parameters": ["self"], "calls": ["self.pytester.path.joinpath", "self.pytester.runpytest", "minidom.parse", "str", "DomDocument", "xml_path.open", "self.schema.validate"], "code_location": {"file": "test_junitxml.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 41, "end_line": 52}, "code_snippet": "    def __call__(\n        self, *args: str | os.PathLike[str], family: str | None = \"xunit1\"\n    ) -> tuple[RunResult, DomDocument]:\n        if family:\n            args = (\"-o\", \"junit_family=\" + family, *args)\n        xml_path = self.pytester.path.joinpath(\"junit.xml\")\n        result = self.pytester.runpytest(f\"--junitxml={xml_path}\", *args)\n        if family == \"xunit2\":\n            with xml_path.open(encoding=\"utf-8\") as f:\n                self.schema.validate(f)\n        xmldoc = minidom.parse(str(xml_path))\n        return result, DomDocument(xmldoc)\n", "type": "function"}, {"name": "test_runs_twice", "is_method": false, "class_name": null, "parameters": ["pytester", "run_and_parse"], "calls": ["pytester.makepyfile", "run_and_parse", "result.stdout.no_fnmatch_line", "dom.find_by_tag"], "code_location": {"file": "test_junitxml.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 1463, "end_line": 1474}, "code_snippet": "def test_runs_twice(pytester: Pytester, run_and_parse: RunAndParse) -> None:\n    f = pytester.makepyfile(\n        \"\"\"\n        def test_pass():\n            pass\n    \"\"\"\n    )\n\n    result, dom = run_and_parse(f, f)\n    result.stdout.no_fnmatch_line(\"*INTERNALERROR*\")\n    first, second = (x[\"classname\"] for x in dom.find_by_tag(\"testcase\"))\n    assert first == second\n", "type": "function"}, {"name": "test_runs_twice_xdist", "is_method": false, "class_name": null, "parameters": ["pytester", "monkeypatch", "run_and_parse"], "calls": ["pytest.importorskip", "monkeypatch.delenv", "pytester.makepyfile", "run_and_parse", "result.stdout.no_fnmatch_line", "dom.find_by_tag"], "code_location": {"file": "test_junitxml.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 1477, "end_line": 1492}, "code_snippet": "def test_runs_twice_xdist(\n    pytester: Pytester, monkeypatch: MonkeyPatch, run_and_parse: RunAndParse\n) -> None:\n    pytest.importorskip(\"xdist\")\n    monkeypatch.delenv(\"PYTEST_DISABLE_PLUGIN_AUTOLOAD\")\n    f = pytester.makepyfile(\n        \"\"\"\n        def test_pass():\n            pass\n    \"\"\"\n    )\n\n    result, dom = run_and_parse(f, \"--dist\", \"each\", \"--tx\", \"2*popen\")\n    result.stdout.no_fnmatch_line(\"*INTERNALERROR*\")\n    first, second = (x[\"classname\"] for x in dom.find_by_tag(\"testcase\"))\n    assert first == second\n", "type": "function"}, {"name": "test_timestamp_in_xml", "is_method": true, "class_name": "TestPython", "parameters": ["self", "pytester", "run_and_parse", "xunit_family"], "calls": ["pytester.makepyfile", "datetime.now", "run_and_parse", "dom.get_first_by_tag", "datetime.fromisoformat", "datetime.now"], "code_location": {"file": "test_junitxml.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 269, "end_line": 282}, "code_snippet": "    def test_timestamp_in_xml(\n        self, pytester: Pytester, run_and_parse: RunAndParse, xunit_family: str\n    ) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            def test_pass():\n                pass\n        \"\"\"\n        )\n        start_time = datetime.now(timezone.utc)\n        result, dom = run_and_parse(family=xunit_family)\n        node = dom.get_first_by_tag(\"testsuite\")\n        timestamp = datetime.fromisoformat(node[\"timestamp\"])\n        assert start_time <= timestamp < datetime.now(timezone.utc)\n", "type": "function"}, {"name": "test_root_testsuites_tag", "is_method": false, "class_name": null, "parameters": ["pytester", "run_and_parse", "xunit_family"], "calls": ["pytester.makepyfile", "run_and_parse", "root.assert_attr"], "code_location": {"file": "test_junitxml.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 1446, "end_line": 1460}, "code_snippet": "def test_root_testsuites_tag(\n    pytester: Pytester, run_and_parse: RunAndParse, xunit_family: str\n) -> None:\n    pytester.makepyfile(\n        \"\"\"\n        def test_x():\n            pass\n    \"\"\"\n    )\n    _, dom = run_and_parse(family=xunit_family)\n    root = dom.get_unique_child\n    assert root.tag == \"testsuites\"\n    root.assert_attr(name=\"pytest tests\")\n    suite_node = root.get_unique_child\n    assert suite_node.tag == \"testsuite\"\n", "type": "function"}, {"name": "test_hostname_in_xml", "is_method": true, "class_name": "TestPython", "parameters": ["self", "pytester", "run_and_parse", "xunit_family"], "calls": ["pytester.makepyfile", "run_and_parse", "dom.get_first_by_tag", "node.assert_attr", "platform.node"], "code_location": {"file": "test_junitxml.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 255, "end_line": 266}, "code_snippet": "    def test_hostname_in_xml(\n        self, pytester: Pytester, run_and_parse: RunAndParse, xunit_family: str\n    ) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            def test_pass():\n                pass\n        \"\"\"\n        )\n        result, dom = run_and_parse(family=xunit_family)\n        node = dom.get_first_by_tag(\"testsuite\")\n        node.assert_attr(hostname=platform.node())\n", "type": "function"}, {"name": "TestExecution", "docstring": "", "methods": ["test_sysfind_no_permission_ignored", "test_sysfind_absolute", "test_sysfind_multiple", "test_sysexec", "test_sysexec_failing", "test_make_numbered_dir", "test_make_numbered_dir_case", "test_make_numbered_dir_NotImplemented_Error", "test_locked_make_numbered_dir", "test_error_preservation"], "attributes": ["pytestmark"], "code_location": {"file": "test_local.py", "path": "/data3/pwh/swebench-repos/pytest/testing/_py", "start_line": 900, "end_line": 1002}, "type": "class"}, {"name": "TestParser", "docstring": "", "methods": ["test_no_help_by_default", "test_custom_prog", "test_argument", "test_argument_type", "test_argument_processopt", "test_group_add_and_get", "test_getgroup_simple", "test_group_ordering", "test_group_addoption", "test_group_addoption_conflict", "test_group_shortopt_lowercase", "test_parser_addoption", "test_parse", "test_parse2", "test_parse_from_file", "test_parse_known_args", "test_parse_known_and_unknown_args", "test_parse_will_set_default", "test_parse_setoption", "test_parse_special_destination", "test_parse_split_positional_arguments", "test_parse_defaultgetter", "test_drop_short_helper", "test_drop_short_0", "test_drop_short_2", "test_drop_short_3", "test_drop_short_help0", "test_drop_short_help1", "test_multiple_metavar_help"], "attributes": [], "code_location": {"file": "test_parseopt.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 24, "end_line": 300}, "type": "class"}, {"name": "test_random_report_log_xdist", "is_method": false, "class_name": null, "parameters": ["pytester", "monkeypatch", "run_and_parse"], "calls": ["pytest.importorskip", "monkeypatch.delenv", "pytester.makepyfile", "run_and_parse", "dom.get_first_by_tag", "suite_node.find_by_tag", "case_node.find_first_by_tag", "failed.append"], "code_location": {"file": "test_junitxml.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 1419, "end_line": 1442}, "code_snippet": "def test_random_report_log_xdist(\n    pytester: Pytester, monkeypatch: MonkeyPatch, run_and_parse: RunAndParse\n) -> None:\n    \"\"\"`xdist` calls pytest_runtest_logreport as they are executed by the workers,\n    with nodes from several nodes overlapping, so junitxml must cope with that\n    to produce correct reports (#1064).\"\"\"\n    pytest.importorskip(\"xdist\")\n    monkeypatch.delenv(\"PYTEST_DISABLE_PLUGIN_AUTOLOAD\", raising=False)\n    pytester.makepyfile(\n        \"\"\"\n        import pytest, time\n        @pytest.mark.parametrize('i', list(range(30)))\n        def test_x(i):\n            assert i != 22\n    \"\"\"\n    )\n    _, dom = run_and_parse(\"-n2\")\n    suite_node = dom.get_first_by_tag(\"testsuite\")\n    failed = []\n    for case_node in suite_node.find_by_tag(\"testcase\"):\n        if case_node.find_first_by_tag(\"failure\"):\n            failed.append(case_node[\"name\"])\n\n    assert failed == [\"test_x[22]\"]\n", "type": "function"}], "retrieved_count": 10, "cost_time": 1.1907603740692139}
{"question": "Why does the _bestrelpath_cache class leverage Python's dictionary protocol to implement lazy computation and caching of relative path transformations?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"name": "__missing__", "is_method": true, "class_name": "_bestrelpath_cache", "parameters": ["self", "path"], "calls": ["bestrelpath"], "code_location": {"file": "main.py", "path": "/data3/pwh/swebench-repos/pytest/src/_pytest", "start_line": 489, "end_line": 492}, "code_snippet": "    def __missing__(self, path: Path) -> str:\n        r = bestrelpath(self.path, path)\n        self[path] = r\n        return r\n", "type": "function"}, {"name": "_node_location_to_relpath", "is_method": true, "class_name": "Session", "parameters": ["self", "node_path"], "calls": [], "code_location": {"file": "main.py", "path": "/data3/pwh/swebench-repos/pytest/src/_pytest", "start_line": 645, "end_line": 647}, "code_snippet": "    def _node_location_to_relpath(self, node_path: Path) -> str:\n        # bestrelpath is a quite slow function.\n        return self._bestrelpathcache[node_path]\n", "type": "function"}, {"name": "test_bestrelpath", "is_method": true, "class_name": "CommonFSTests", "parameters": ["self", "path1"], "calls": ["curdir.bestrelpath", "curdir.bestrelpath", "curdir.bestrelpath", "curdir.join", "join", "curdir.bestrelpath", "curdir.bestrelpath", "curdir.dirpath", "curdir.dirpath"], "code_location": {"file": "test_local.py", "path": "/data3/pwh/swebench-repos/pytest/testing/_py", "start_line": 153, "end_line": 165}, "code_snippet": "    def test_bestrelpath(self, path1):\n        curdir = path1\n        sep = curdir.sep\n        s = curdir.bestrelpath(curdir)\n        assert s == \".\"\n        s = curdir.bestrelpath(curdir.join(\"hello\", \"world\"))\n        assert s == \"hello\" + sep + \"world\"\n\n        s = curdir.bestrelpath(curdir.dirpath().join(\"sister\"))\n        assert s == \"..\" + sep + \"sister\"\n        assert curdir.bestrelpath(curdir.dirpath()) == \"..\"\n\n        assert curdir.bestrelpath(\"hello\") == \"hello\"\n", "type": "function"}, {"name": "test_bestrelpath", "is_method": false, "class_name": null, "parameters": [], "calls": ["Path", "bestrelpath", "bestrelpath", "bestrelpath", "bestrelpath", "bestrelpath", "Path"], "code_location": {"file": "test_pathlib.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 523, "end_line": 529}, "code_snippet": "def test_bestrelpath() -> None:\n    curdir = Path(\"/foo/bar/baz/path\")\n    assert bestrelpath(curdir, curdir) == \".\"\n    assert bestrelpath(curdir, curdir / \"hello\" / \"world\") == \"hello\" + os.sep + \"world\"\n    assert bestrelpath(curdir, curdir.parent / \"sister\") == \"..\" + os.sep + \"sister\"\n    assert bestrelpath(curdir, curdir.parent) == \"..\"\n    assert bestrelpath(curdir, Path(\"hello\")) == \"hello\"\n", "type": "function"}, {"name": "bestrelpath", "is_method": true, "class_name": "LocalPath", "parameters": ["self", "dest"], "calls": ["self.common", "self.relto", "dest.relto", "dest.sep.join", "str", "lst.append", "str", "self2base.count"], "code_location": {"file": "path.py", "path": "/data3/pwh/swebench-repos/pytest/src/_pytest/_py", "start_line": 454, "end_line": 478}, "code_snippet": "    def bestrelpath(self, dest):\n        \"\"\"Return a string which is a relative path from self\n        (assumed to be a directory) to dest such that\n        self.join(bestrelpath) == dest and if not such\n        path can be determined return dest.\n        \"\"\"\n        try:\n            if self == dest:\n                return os.curdir\n            base = self.common(dest)\n            if not base:  # can be the case on windows\n                return str(dest)\n            self2base = self.relto(base)\n            reldest = dest.relto(base)\n            if self2base:\n                n = self2base.count(self.sep) + 1\n            else:\n                n = 0\n            lst = [os.pardir] * n\n            if reldest:\n                lst.append(reldest)\n            target = dest.sep.join(lst)\n            return target\n        except AttributeError:\n            return str(dest)\n", "type": "function"}, {"name": "relto", "is_method": true, "class_name": "Checkers", "parameters": ["self", "arg"], "calls": ["self.path.relto"], "code_location": {"file": "path.py", "path": "/data3/pwh/swebench-repos/pytest/src/_pytest/_py", "start_line": 61, "end_line": 62}, "code_snippet": "    def relto(self, arg):\n        return self.path.relto(arg)\n", "type": "function"}, {"name": "_check_initialpaths_for_relpath", "is_method": false, "class_name": null, "parameters": ["initial_paths", "path"], "calls": ["lru_cache", "str", "path.relative_to"], "code_location": {"file": "nodes.py", "path": "/data3/pwh/swebench-repos/pytest/src/_pytest", "start_line": 547, "end_line": 557}, "code_snippet": "def _check_initialpaths_for_relpath(\n    initial_paths: frozenset[Path], path: Path\n) -> str | None:\n    if path in initial_paths:\n        return \"\"\n\n    for parent in path.parents:\n        if parent in initial_paths:\n            return str(path.relative_to(parent))\n\n    return None\n", "type": "function"}, {"name": "_makepath", "is_method": true, "class_name": "FormattedExcinfo", "parameters": ["self", "path"], "calls": ["str", "isinstance", "bestrelpath", "len", "len", "Path.cwd", "str", "str"], "code_location": {"file": "code.py", "path": "/data3/pwh/swebench-repos/pytest/src/_pytest/_code", "start_line": 1105, "end_line": 1113}, "code_snippet": "    def _makepath(self, path: Path | str) -> str:\n        if not self.abspath and isinstance(path, Path):\n            try:\n                np = bestrelpath(Path.cwd(), path)\n            except OSError:\n                return str(path)\n            if len(np) < len(str(path)):\n                return np\n        return str(path)\n", "type": "function"}, {"name": "bestrelpath", "is_method": false, "class_name": null, "parameters": ["directory", "dest"], "calls": ["isinstance", "isinstance", "commonpath", "directory.relative_to", "dest.relative_to", "os.path.join", "str", "len"], "code_location": {"file": "pathlib.py", "path": "/data3/pwh/swebench-repos/pytest/src/_pytest", "start_line": 1019, "end_line": 1045}, "code_snippet": "def bestrelpath(directory: Path, dest: Path) -> str:\n    \"\"\"Return a string which is a relative path from directory to dest such\n    that directory/bestrelpath == dest.\n\n    The paths must be either both absolute or both relative.\n\n    If no such path can be determined, returns dest.\n    \"\"\"\n    assert isinstance(directory, Path)\n    assert isinstance(dest, Path)\n    if dest == directory:\n        return os.curdir\n    # Find the longest common directory.\n    base = commonpath(directory, dest)\n    # Can be the case on Windows for two absolute paths on different drives.\n    # Can be the case for two relative paths without common prefix.\n    # Can be the case for a relative path and an absolute path.\n    if not base:\n        return str(dest)\n    reldirectory = directory.relative_to(base)\n    reldest = dest.relative_to(base)\n    return os.path.join(\n        # Back from directory to base.\n        *([os.pardir] * len(reldirectory.parts)),\n        # Forward from base to dest.\n        *reldest.parts,\n    )\n", "type": "function"}, {"name": "cwd_relative_nodeid", "is_method": true, "class_name": "Config", "parameters": ["self", "nodeid"], "calls": ["nodeid.split", "bestrelpath", "join"], "code_location": {"file": "__init__.py", "path": "/data3/pwh/swebench-repos/pytest/src/_pytest/config", "start_line": 1185, "end_line": 1194}, "code_snippet": "    def cwd_relative_nodeid(self, nodeid: str) -> str:\n        # nodeid's are relative to the rootpath, compute relative to cwd.\n        if self.invocation_params.dir != self.rootpath:\n            base_path_part, *nodeid_part = nodeid.split(\"::\")\n            # Only process path part\n            fullpath = self.rootpath / base_path_part\n            relative_path = bestrelpath(self.invocation_params.dir, fullpath)\n\n            nodeid = \"::\".join([relative_path, *nodeid_part])\n        return nodeid\n", "type": "function"}], "retrieved_count": 10, "cost_time": 1.1678462028503418}
{"question": "How should the plugin manager architecture be redesigned to enforce plugin registration policies at the system level rather than relying on runtime assertion checks in individual test cases?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"name": "test_plugin_prevent_register_unregistered_already_registered", "is_method": true, "class_name": "TestPytestPluginManagerBootstrapping", "parameters": ["self", "pytestpm"], "calls": ["pytestpm.register", "pytestpm.get_plugins", "pytestpm.consider_preparse", "pytestpm.get_plugins"], "code_location": {"file": "test_pluginmanager.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 450, "end_line": 458}, "code_snippet": "    def test_plugin_prevent_register_unregistered_already_registered(\n        self, pytestpm: PytestPluginManager\n    ) -> None:\n        pytestpm.register(42, name=\"abc\")\n        l1 = pytestpm.get_plugins()\n        assert 42 in l1\n        pytestpm.consider_preparse([\"xyz\", \"-p\", \"no:abc\"])\n        l2 = pytestpm.get_plugins()\n        assert 42 not in l2\n", "type": "function"}, {"name": "test_plugin_prevent_register", "is_method": true, "class_name": "TestPytestPluginManagerBootstrapping", "parameters": ["self", "pytestpm"], "calls": ["pytestpm.consider_preparse", "pytestpm.get_plugins", "pytestpm.register", "pytestpm.get_plugins", "len", "len"], "code_location": {"file": "test_pluginmanager.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 442, "end_line": 448}, "code_snippet": "    def test_plugin_prevent_register(self, pytestpm: PytestPluginManager) -> None:\n        pytestpm.consider_preparse([\"xyz\", \"-p\", \"no:abc\"])\n        l1 = pytestpm.get_plugins()\n        pytestpm.register(42, name=\"abc\")\n        l2 = pytestpm.get_plugins()\n        assert len(l2) == len(l1)\n        assert 42 not in l2\n", "type": "function"}, {"name": "pytest_plugin_registered", "is_method": false, "class_name": null, "parameters": ["plugin", "manager"], "calls": ["manager.get_plugin", "manager.register", "manager.is_registered"], "code_location": {"file": "legacypath.py", "path": "/data3/pwh/swebench-repos/pytest/src/_pytest", "start_line": 463, "end_line": 468}, "code_snippet": "def pytest_plugin_registered(plugin: object, manager: PytestPluginManager) -> None:\n    # pytester is not loaded by default and is commonly loaded from a conftest,\n    # so checking for it in `pytest_configure` is not enough.\n    is_pytester = plugin is manager.get_plugin(\"pytester\")\n    if is_pytester and not manager.is_registered(LegacyTestdirPlugin):\n        manager.register(LegacyTestdirPlugin, \"legacypath-pytester\")\n", "type": "function"}, {"name": "test_register_imported_modules", "is_method": true, "class_name": "TestPytestPluginManager", "parameters": ["self"], "calls": ["PytestPluginManager", "types.ModuleType", "pm.register", "pm.is_registered", "pm.get_plugins", "pytest.raises", "pytest.raises", "pm.get_plugins", "pm.register"], "code_location": {"file": "test_pluginmanager.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 264, "end_line": 274}, "code_snippet": "    def test_register_imported_modules(self) -> None:\n        pm = PytestPluginManager()\n        mod = types.ModuleType(\"x.y.pytest_hello\")\n        pm.register(mod)\n        assert pm.is_registered(mod)\n        values = pm.get_plugins()\n        assert mod in values\n        pytest.raises(ValueError, pm.register, mod)\n        pytest.raises(ValueError, lambda: pm.register(mod))\n        # assert not pm.is_registered(mod2)\n        assert pm.get_plugins() == values\n", "type": "function"}, {"name": "TestPytestPluginManagerBootstrapping", "docstring": "", "methods": ["test_preparse_args", "test_plugin_prevent_register", "test_plugin_prevent_register_unregistered_already_registered", "test_plugin_prevent_register_stepwise_on_cacheprovider_unregister", "test_blocked_plugin_can_be_used"], "attributes": [], "code_location": {"file": "test_pluginmanager.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 424, "end_line": 483}, "type": "class"}, {"name": "register", "is_method": true, "class_name": "PytestPluginManager", "parameters": ["self", "plugin", "name"], "calls": ["register", "warnings.warn", "self.hook.pytest_plugin_registered.call_historic", "isinstance", "PytestConfigWarning", "super", "self.consider_module", "format", "dict", "name.replace"], "code_location": {"file": "__init__.py", "path": "/data3/pwh/swebench-repos/pytest/src/_pytest/config", "start_line": 492, "end_line": 515}, "code_snippet": "    def register(self, plugin: _PluggyPlugin, name: str | None = None) -> str | None:\n        if name in _pytest.deprecated.DEPRECATED_EXTERNAL_PLUGINS:\n            warnings.warn(\n                PytestConfigWarning(\n                    \"{} plugin has been merged into the core, \"\n                    \"please remove it from your requirements.\".format(\n                        name.replace(\"_\", \"-\")\n                    )\n                )\n            )\n            return None\n        plugin_name = super().register(plugin, name)\n        if plugin_name is not None:\n            self.hook.pytest_plugin_registered.call_historic(\n                kwargs=dict(\n                    plugin=plugin,\n                    plugin_name=plugin_name,\n                    manager=self,\n                )\n            )\n\n            if isinstance(plugin, types.ModuleType):\n                self.consider_module(plugin)\n        return plugin_name\n", "type": "function"}, {"name": "test_has_plugin", "is_method": true, "class_name": "TestInvocationVariants", "parameters": ["self", "request"], "calls": ["request.config.pluginmanager.hasplugin"], "code_location": {"file": "acceptance_test.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 937, "end_line": 939}, "code_snippet": "    def test_has_plugin(self, request) -> None:\n        \"\"\"Test hasplugin function of the plugin manager (#932).\"\"\"\n        assert request.config.pluginmanager.hasplugin(\"python\")\n", "type": "function"}, {"name": "pytestpm", "is_method": false, "class_name": null, "parameters": [], "calls": ["PytestPluginManager"], "code_location": {"file": "test_pluginmanager.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 21, "end_line": 22}, "code_snippet": "def pytestpm() -> PytestPluginManager:\n    return PytestPluginManager()\n", "type": "function"}, {"name": "test_canonical_import", "is_method": true, "class_name": "TestPytestPluginManager", "parameters": ["self", "monkeypatch"], "calls": ["types.ModuleType", "monkeypatch.setitem", "PytestPluginManager", "pm.import_plugin", "pm.is_registered", "pm.get_plugin"], "code_location": {"file": "test_pluginmanager.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 276, "end_line": 282}, "code_snippet": "    def test_canonical_import(self, monkeypatch):\n        mod = types.ModuleType(\"pytest_xyz\")\n        monkeypatch.setitem(sys.modules, \"pytest_xyz\", mod)\n        pm = PytestPluginManager()\n        pm.import_plugin(\"pytest_xyz\")\n        assert pm.get_plugin(\"pytest_xyz\") == mod\n        assert pm.is_registered(mod)\n", "type": "function"}, {"name": "test_module_considers_pluginmanager_at_import", "is_method": true, "class_name": "TestModule", "parameters": ["self", "pytester"], "calls": ["pytester.getmodulecol", "pytest.raises"], "code_location": {"file": "collect.py", "path": "/data3/pwh/swebench-repos/pytest/testing/python", "start_line": 78, "end_line": 80}, "code_snippet": "    def test_module_considers_pluginmanager_at_import(self, pytester: Pytester) -> None:\n        modcol = pytester.getmodulecol(\"pytest_plugins='xasdlkj',\")\n        pytest.raises(ImportError, lambda: modcol.obj)\n", "type": "function"}], "retrieved_count": 10, "cost_time": 1.2068781852722168}
{"question": "Why does the repeated instantiation of FNMatcher objects in the Visitor.__init__ method impact memory consumption and traversal performance when processing large directory trees with complex filtering patterns?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"name": "__init__", "is_method": true, "class_name": "Visitor", "parameters": ["self", "fil", "rec", "ignore", "bf", "sort"], "calls": ["isinstance", "isinstance", "FNMatcher", "FNMatcher", "cast", "hasattr"], "code_location": {"file": "path.py", "path": "/data3/pwh/swebench-repos/pytest/src/_pytest/_py", "start_line": 139, "end_line": 151}, "code_snippet": "    def __init__(self, fil, rec, ignore, bf, sort):\n        if isinstance(fil, str):\n            fil = FNMatcher(fil)\n        if isinstance(rec, str):\n            self.rec: Callable[[LocalPath], bool] = FNMatcher(rec)\n        elif not hasattr(rec, \"__call__\") and rec:\n            self.rec = lambda path: True\n        else:\n            self.rec = rec\n        self.fil = fil\n        self.ignore = ignore\n        self.breadthfirst = bf\n        self.optsort = cast(Callable[[Any], Any], sorted) if sort else (lambda x: x)\n", "type": "function"}, {"name": "test_visit_rec_fnmatch", "is_method": true, "class_name": "TestLocalPath", "parameters": ["self", "tmpdir"], "calls": ["tmpdir.ensure", "tmpdir.ensure", "list", "tmpdir.visit", "len"], "code_location": {"file": "test_local.py", "path": "/data3/pwh/swebench-repos/pytest/testing/_py", "start_line": 843, "end_line": 849}, "code_snippet": "    def test_visit_rec_fnmatch(self, tmpdir):\n        p1 = tmpdir.ensure(\"a\", \"123\")\n        tmpdir.ensure(\".b\", \"345\")\n        lst = list(tmpdir.visit(\"???\", rec=\"[!.]*\"))\n        assert len(lst) == 1\n        # check that breadth comes last\n        assert lst[0] == p1\n", "type": "function"}, {"name": "__call__", "is_method": true, "class_name": "FNMatcher", "parameters": ["self", "path"], "calls": ["fnmatch.fnmatch", "pattern.replace", "pattern.find", "str", "pattern.find", "pattern.find", "os.path.isabs"], "code_location": {"file": "path.py", "path": "/data3/pwh/swebench-repos/pytest/src/_pytest/_py", "start_line": 177, "end_line": 196}, "code_snippet": "    def __call__(self, path):\n        pattern = self.pattern\n\n        if (\n            pattern.find(path.sep) == -1\n            and iswin32\n            and pattern.find(posixpath.sep) != -1\n        ):\n            # Running on Windows, the pattern has no Windows path separators,\n            # and the pattern has one or more Posix path separators. Replace\n            # the Posix path separators with the Windows path separator.\n            pattern = pattern.replace(posixpath.sep, path.sep)\n\n        if pattern.find(path.sep) == -1:\n            name = path.basename\n        else:\n            name = str(path)  # path.strpath # XXX svn?\n            if not os.path.isabs(pattern):\n                pattern = \"*\" + path.sep + pattern\n        return fnmatch.fnmatch(name, pattern)\n", "type": "function"}, {"name": "collect", "is_method": true, "class_name": "Session", "parameters": ["self"], "calls": ["self.trace", "argpath.is_dir", "module_name.split", "enumerate", "work.pop", "isinstance", "reversed", "join", "self._notfound.append", "paths.insert", "paths.insert", "isinstance", "isinstance", "matchnode._collect_path", "self._collect_one_node", "isinstance", "notfound_collectors.append", "pm._is_in_confcutdir", "matchnode.ihook.pytest_collectreport", "work.append", "str", "len", "isinstance", "is_file", "os.path.samefile", "len", "os.path.islink", "os.path.islink", "node.name.split"], "code_location": {"file": "main.py", "path": "/data3/pwh/swebench-repos/pytest/src/_pytest", "start_line": 847, "end_line": 966}, "code_snippet": "    def collect(self) -> Iterator[nodes.Item | nodes.Collector]:\n        # This is a cache for the root directories of the initial paths.\n        # We can't use collection_cache for Session because of its special\n        # role as the bootstrapping collector.\n        path_cache: dict[Path, Sequence[nodes.Collector]] = {}\n\n        pm = self.config.pluginmanager\n\n        for collection_argument in self._initial_parts:\n            self.trace(\"processing argument\", collection_argument)\n            self.trace.root.indent += 1\n\n            argpath = collection_argument.path\n            names = collection_argument.parts\n            module_name = collection_argument.module_name\n\n            # resolve_collection_argument() ensures this.\n            if argpath.is_dir():\n                assert not names, f\"invalid arg {(argpath, names)!r}\"\n\n            paths = [argpath]\n            # Add relevant parents of the path, from the root, e.g.\n            #   /a/b/c.py -> [/, /a, /a/b, /a/b/c.py]\n            if module_name is None:\n                # Paths outside of the confcutdir should not be considered.\n                for path in argpath.parents:\n                    if not pm._is_in_confcutdir(path):\n                        break\n                    paths.insert(0, path)\n            else:\n                # For --pyargs arguments, only consider paths matching the module\n                # name. Paths beyond the package hierarchy are not included.\n                module_name_parts = module_name.split(\".\")\n                for i, path in enumerate(argpath.parents, 2):\n                    if i > len(module_name_parts) or path.stem != module_name_parts[-i]:\n                        break\n                    paths.insert(0, path)\n\n            # Start going over the parts from the root, collecting each level\n            # and discarding all nodes which don't match the level's part.\n            any_matched_in_initial_part = False\n            notfound_collectors = []\n            work: list[tuple[nodes.Collector | nodes.Item, list[Path | str]]] = [\n                (self, [*paths, *names])\n            ]\n            while work:\n                matchnode, matchparts = work.pop()\n\n                # Pop'd all of the parts, this is a match.\n                if not matchparts:\n                    yield matchnode\n                    any_matched_in_initial_part = True\n                    continue\n\n                # Should have been matched by now, discard.\n                if not isinstance(matchnode, nodes.Collector):\n                    continue\n\n                # Collect this level of matching.\n                # Collecting Session (self) is done directly to avoid endless\n                # recursion to this function.\n                subnodes: Sequence[nodes.Collector | nodes.Item]\n                if isinstance(matchnode, Session):\n                    assert isinstance(matchparts[0], Path)\n                    subnodes = matchnode._collect_path(matchparts[0], path_cache)\n                else:\n                    # For backward compat, files given directly multiple\n                    # times on the command line should not be deduplicated.\n                    handle_dupes = not (\n                        len(matchparts) == 1\n                        and isinstance(matchparts[0], Path)\n                        and matchparts[0].is_file()\n                    )\n                    rep, duplicate = self._collect_one_node(matchnode, handle_dupes)\n                    if not duplicate and not rep.passed:\n                        # Report collection failures here to avoid failing to\n                        # run some test specified in the command line because\n                        # the module could not be imported (#134).\n                        matchnode.ihook.pytest_collectreport(report=rep)\n                    if not rep.passed:\n                        continue\n                    subnodes = rep.result\n\n                # Prune this level.\n                any_matched_in_collector = False\n                for node in reversed(subnodes):\n                    # Path part e.g. `/a/b/` in `/a/b/test_file.py::TestIt::test_it`.\n                    if isinstance(matchparts[0], Path):\n                        is_match = node.path == matchparts[0]\n                        if sys.platform == \"win32\" and not is_match:\n                            # In case the file paths do not match, fallback to samefile() to\n                            # account for short-paths on Windows (#11895).\n                            same_file = os.path.samefile(node.path, matchparts[0])\n                            # We don't want to match links to the current node,\n                            # otherwise we would match the same file more than once (#12039).\n                            is_match = same_file and (\n                                os.path.islink(node.path)\n                                == os.path.islink(matchparts[0])\n                            )\n\n                    # Name part e.g. `TestIt` in `/a/b/test_file.py::TestIt::test_it`.\n                    else:\n                        # TODO: Remove parametrized workaround once collection structure contains\n                        # parametrization.\n                        is_match = (\n                            node.name == matchparts[0]\n                            or node.name.split(\"[\")[0] == matchparts[0]\n                        )\n                    if is_match:\n                        work.append((node, matchparts[1:]))\n                        any_matched_in_collector = True\n\n                if not any_matched_in_collector:\n                    notfound_collectors.append(matchnode)\n\n            if not any_matched_in_initial_part:\n                report_arg = \"::\".join((str(argpath), *names))\n                self._notfound.append((report_arg, notfound_collectors))\n\n            self.trace.root.indent -= 1\n", "type": "function"}, {"name": "test_visit_filterfunc_is_string", "is_method": true, "class_name": "CommonFSTests", "parameters": ["self", "path1", "fil"], "calls": ["pytest.mark.parametrize", "path1.visit", "len", "lst.append", "i.relto", "pytest.mark.skip"], "code_location": {"file": "test_local.py", "path": "/data3/pwh/swebench-repos/pytest/testing/_py", "start_line": 214, "end_line": 220}, "code_snippet": "    def test_visit_filterfunc_is_string(self, path1, fil):\n        lst = []\n        for i in path1.visit(fil):\n            lst.append(i.relto(path1))\n        assert len(lst), 2  # noqa: PLC1802,RUF040\n        assert \"sampledir\" in lst\n        assert \"otherdir\" in lst\n", "type": "function"}, {"name": "fnmatch_ex", "is_method": false, "class_name": null, "parameters": ["pattern", "path"], "calls": ["PurePath", "sys.platform.startswith", "fnmatch.fnmatch", "pattern.replace", "str", "path.is_absolute", "os.path.isabs"], "code_location": {"file": "pathlib.py", "path": "/data3/pwh/swebench-repos/pytest/src/_pytest", "start_line": 419, "end_line": 452}, "code_snippet": "def fnmatch_ex(pattern: str, path: str | os.PathLike[str]) -> bool:\n    \"\"\"A port of FNMatcher from py.path.common which works with PurePath() instances.\n\n    The difference between this algorithm and PurePath.match() is that the\n    latter matches \"**\" glob expressions for each part of the path, while\n    this algorithm uses the whole path instead.\n\n    For example:\n        \"tests/foo/bar/doc/test_foo.py\" matches pattern \"tests/**/doc/test*.py\"\n        with this algorithm, but not with PurePath.match().\n\n    This algorithm was ported to keep backward-compatibility with existing\n    settings which assume paths match according this logic.\n\n    References:\n    * https://bugs.python.org/issue29249\n    * https://bugs.python.org/issue34731\n    \"\"\"\n    path = PurePath(path)\n    iswin32 = sys.platform.startswith(\"win\")\n\n    if iswin32 and sep not in pattern and posix_sep in pattern:\n        # Running on Windows, the pattern has no Windows path separators,\n        # and the pattern has one or more Posix path separators. Replace\n        # the Posix path separators with the Windows path separator.\n        pattern = pattern.replace(posix_sep, sep)\n\n    if sep not in pattern:\n        name = path.name\n    else:\n        name = str(path)\n        if path.is_absolute() and not os.path.isabs(pattern):\n            pattern = f\"*{os.sep}{pattern}\"\n    return fnmatch.fnmatch(name, pattern)\n", "type": "function"}, {"name": "fnmatch", "is_method": true, "class_name": "Checkers", "parameters": ["self", "arg"], "calls": ["self.path.fnmatch"], "code_location": {"file": "path.py", "path": "/data3/pwh/swebench-repos/pytest/src/_pytest/_py", "start_line": 64, "end_line": 65}, "code_snippet": "    def fnmatch(self, arg):\n        return self.path.fnmatch(arg)\n", "type": "function"}, {"name": "test_visit_depth_first", "is_method": true, "class_name": "TestLocalPath", "parameters": ["self", "tmpdir"], "calls": ["tmpdir.ensure", "tmpdir.ensure", "tmpdir.ensure", "list", "tmpdir.visit", "len", "x.check"], "code_location": {"file": "test_local.py", "path": "/data3/pwh/swebench-repos/pytest/testing/_py", "start_line": 834, "end_line": 841}, "code_snippet": "    def test_visit_depth_first(self, tmpdir):\n        tmpdir.ensure(\"a\", \"1\")\n        tmpdir.ensure(\"b\", \"2\")\n        p3 = tmpdir.ensure(\"breadth\")\n        lst = list(tmpdir.visit(lambda x: x.check(file=1)))\n        assert len(lst) == 3\n        # check that breadth comes last\n        assert lst[2] == p3\n", "type": "function"}, {"name": "test_visit_norecurse", "is_method": true, "class_name": "CommonFSTests", "parameters": ["self", "path1"], "calls": ["path1.visit", "lst.append", "path1.sep.join", "i.relto"], "code_location": {"file": "test_local.py", "path": "/data3/pwh/swebench-repos/pytest/testing/_py", "start_line": 203, "end_line": 208}, "code_snippet": "    def test_visit_norecurse(self, path1):\n        lst = []\n        for i in path1.visit(None, lambda x: x.basename != \"sampledir\"):\n            lst.append(i.relto(path1))\n        assert \"sampledir\" in lst\n        assert path1.sep.join([\"sampledir\", \"otherfile\"]) not in lst\n", "type": "function"}, {"name": "test_visit_nofilter", "is_method": true, "class_name": "CommonFSTests", "parameters": ["self", "path1"], "calls": ["path1.visit", "lst.append", "path1.sep.join", "i.relto"], "code_location": {"file": "test_local.py", "path": "/data3/pwh/swebench-repos/pytest/testing/_py", "start_line": 196, "end_line": 201}, "code_snippet": "    def test_visit_nofilter(self, path1):\n        lst = []\n        for i in path1.visit():\n            lst.append(i.relto(path1))\n        assert \"sampledir\" in lst\n        assert path1.sep.join([\"sampledir\", \"otherfile\"]) in lst\n", "type": "function"}], "retrieved_count": 10, "cost_time": 1.1964316368103027}
{"question": "Why does the TestImportHookInstallation class employ subprocess-based testing through pytester.runpytest_subprocess() rather than inline test execution, and what design constraints does this impose on the assertion rewrite hook installation verification?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"name": "test_rewrite_warning", "is_method": true, "class_name": "TestRewriteOnImport", "parameters": ["self", "pytester"], "calls": ["pytester.makeconftest", "pytester.runpytest_subprocess", "result.stdout.fnmatch_lines"], "code_location": {"file": "test_assertrewrite.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 1191, "end_line": 1200}, "code_snippet": "    def test_rewrite_warning(self, pytester: Pytester) -> None:\n        pytester.makeconftest(\n            \"\"\"\n            import pytest\n            pytest.register_assert_rewrite(\"_pytest\")\n        \"\"\"\n        )\n        # needs to be a subprocess because pytester explicitly disables this warning\n        result = pytester.runpytest_subprocess()\n        result.stdout.fnmatch_lines([\"*Module already imported*; _pytest\"])\n", "type": "function"}, {"name": "test_rewrite_module_imported_from_conftest", "is_method": true, "class_name": "TestRewriteOnImport", "parameters": ["self", "pytester"], "calls": ["pytester.makeconftest", "pytester.makepyfile", "pytester.runpytest_subprocess"], "code_location": {"file": "test_assertrewrite.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 1218, "end_line": 1230}, "code_snippet": "    def test_rewrite_module_imported_from_conftest(self, pytester: Pytester) -> None:\n        pytester.makeconftest(\n            \"\"\"\n            import test_rewrite_module_imported\n        \"\"\"\n        )\n        pytester.makepyfile(\n            test_rewrite_module_imported=\"\"\"\n            def test_rewritten():\n                assert \"@py_builtins\" in globals()\n        \"\"\"\n        )\n        assert pytester.runpytest_subprocess().ret == 0\n", "type": "function"}, {"name": "_consider_importhook", "is_method": true, "class_name": "Config", "parameters": ["self", "args"], "calls": ["self._parser.parse_known_and_unknown_args", "getattr", "self._warn_about_missing_assertion", "getattr", "bool", "os.environ.get", "_pytest.assertion.install_importhook", "self._mark_plugins_for_rewrite"], "code_location": {"file": "__init__.py", "path": "/data3/pwh/swebench-repos/pytest/src/_pytest/config", "start_line": 1269, "end_line": 1291}, "code_snippet": "    def _consider_importhook(self, args: Sequence[str]) -> None:\n        \"\"\"Install the PEP 302 import hook if using assertion rewriting.\n\n        Needs to parse the --assert=<mode> option from the commandline\n        and find all the installed plugins to mark them for rewriting\n        by the importhook.\n        \"\"\"\n        ns, unknown_args = self._parser.parse_known_and_unknown_args(args)\n        mode = getattr(ns, \"assertmode\", \"plain\")\n\n        disable_autoload = getattr(ns, \"disable_plugin_autoload\", False) or bool(\n            os.environ.get(\"PYTEST_DISABLE_PLUGIN_AUTOLOAD\")\n        )\n        if mode == \"rewrite\":\n            import _pytest.assertion\n\n            try:\n                hook = _pytest.assertion.install_importhook(self)\n            except SystemError:\n                mode = \"plain\"\n            else:\n                self._mark_plugins_for_rewrite(hook, disable_autoload)\n        self._warn_about_missing_assertion(mode)\n", "type": "function"}, {"name": "test_assertion_rewrite", "is_method": true, "class_name": "TestGeneralUsage", "parameters": ["self", "pytester", "import_mode"], "calls": ["pytest.mark.parametrize", "pytester.makepyfile", "pytester.runpytest", "result.stdout.fnmatch_lines"], "code_location": {"file": "acceptance_test.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 159, "end_line": 169}, "code_snippet": "    def test_assertion_rewrite(self, pytester: Pytester, import_mode) -> None:\n        p = pytester.makepyfile(\n            \"\"\"\n            def test_this():\n                x = 0\n                assert x\n        \"\"\"\n        )\n        result = pytester.runpytest(p, f\"--import-mode={import_mode}\")\n        result.stdout.fnmatch_lines([\">       assert x\", \"E       assert 0\"])\n        assert result.ret == 1\n", "type": "function"}, {"name": "test_rewrite_ast", "is_method": true, "class_name": "TestImportHookInstallation", "parameters": ["self", "pytester"], "calls": ["pytester.mkdir", "pytester.makepyfile", "pytester.runpytest_subprocess", "result.stdout.fnmatch_lines"], "code_location": {"file": "test_assertion.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 328, "end_line": 371}, "code_snippet": "    def test_rewrite_ast(self, pytester: Pytester) -> None:\n        pytester.mkdir(\"pkg\")\n        contents = {\n            \"pkg/__init__.py\": \"\"\"\n                import pytest\n                pytest.register_assert_rewrite('pkg.helper')\n            \"\"\",\n            \"pkg/helper.py\": \"\"\"\n                def tool():\n                    a, b = 2, 3\n                    assert a == b\n            \"\"\",\n            \"pkg/plugin.py\": \"\"\"\n                import pytest, pkg.helper\n                @pytest.fixture\n                def tool():\n                    return pkg.helper.tool\n            \"\"\",\n            \"pkg/other.py\": \"\"\"\n                values = [3, 2]\n                def tool():\n                    assert values.pop() == 3\n            \"\"\",\n            \"conftest.py\": \"\"\"\n                pytest_plugins = ['pkg.plugin']\n            \"\"\",\n            \"test_pkg.py\": \"\"\"\n                import pkg.other\n                def test_tool(tool):\n                    tool()\n                def test_other():\n                    pkg.other.tool()\n            \"\"\",\n        }\n        pytester.makepyfile(**contents)\n        result = pytester.runpytest_subprocess(\"--assert=rewrite\")\n        result.stdout.fnmatch_lines(\n            [\n                \">*assert a == b*\",\n                \"E*assert 2 == 3*\",\n                \">*assert values.pop() == 3*\",\n                \"E*AssertionError\",\n            ]\n        )\n", "type": "function"}, {"name": "test_installed_plugin_rewrite", "is_method": true, "class_name": "TestImportHookInstallation", "parameters": ["self", "pytester", "mode", "monkeypatch", "disable_plugin_autoload", "explicit_specify"], "calls": ["pytest.mark.parametrize", "pytest.mark.parametrize", "pytest.mark.parametrize", "pytester.mkdir", "pytester.makepyfile", "pytester.run", "monkeypatch.setenv", "monkeypatch.setenv", "result.assert_outcomes", "result.stdout.fnmatch_lines", "result.assert_outcomes", "result.stdout.fnmatch_lines", "monkeypatch.delenv", "args.append", "monkeypatch.delenv", "args.append", "args.append"], "code_location": {"file": "test_assertion.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 223, "end_line": 326}, "code_snippet": "    def test_installed_plugin_rewrite(\n        self,\n        pytester: Pytester,\n        mode: str,\n        monkeypatch: pytest.MonkeyPatch,\n        disable_plugin_autoload: str,\n        explicit_specify: str,\n    ) -> None:\n        args = [\"mainwrapper.py\", \"-s\", f\"--assert={mode}\"]\n        if disable_plugin_autoload == \"env_var\":\n            monkeypatch.setenv(\"PYTEST_DISABLE_PLUGIN_AUTOLOAD\", \"1\")\n        elif disable_plugin_autoload == \"cli\":\n            monkeypatch.delenv(\"PYTEST_DISABLE_PLUGIN_AUTOLOAD\", raising=False)\n            args.append(\"--disable-plugin-autoload\")\n        else:\n            assert disable_plugin_autoload == \"\"\n            monkeypatch.delenv(\"PYTEST_DISABLE_PLUGIN_AUTOLOAD\", raising=False)\n\n        name = \"spamplugin\"\n\n        if explicit_specify == \"env_var\":\n            monkeypatch.setenv(\"PYTEST_PLUGINS\", name)\n        elif explicit_specify == \"cli\":\n            args.append(\"-p\")\n            args.append(name)\n        else:\n            assert explicit_specify == \"\"\n\n        # Make sure the hook is installed early enough so that plugins\n        # installed via distribution package are rewritten.\n        pytester.mkdir(\"hampkg\")\n        contents = {\n            \"hampkg/__init__.py\": \"\"\"\\\n                import pytest\n\n                @pytest.fixture\n                def check_first2():\n                    def check(values, value):\n                        assert values.pop(0) == value\n                    return check\n            \"\"\",\n            \"spamplugin.py\": \"\"\"\\\n            import pytest\n            from hampkg import check_first2\n\n            @pytest.fixture\n            def check_first():\n                def check(values, value):\n                    assert values.pop(0) == value\n                return check\n            \"\"\",\n            \"mainwrapper.py\": \"\"\"\\\n            import importlib.metadata\n            import pytest\n\n            class DummyEntryPoint(object):\n                name = 'spamplugin'\n                module_name = 'spam.py'\n                group = 'pytest11'\n\n                def load(self):\n                    import spamplugin\n                    return spamplugin\n\n            class DummyDistInfo(object):\n                version = '1.0'\n                files = ('spamplugin.py', 'hampkg/__init__.py')\n                entry_points = (DummyEntryPoint(),)\n                metadata = {'name': 'foo'}\n\n            def distributions():\n                return (DummyDistInfo(),)\n\n            importlib.metadata.distributions = distributions\n            pytest.main()\n            \"\"\",\n            \"test_foo.py\": \"\"\"\\\n            def test(check_first):\n                check_first([10, 30], 30)\n\n            def test2(check_first2):\n                check_first2([10, 30], 30)\n            \"\"\",\n        }\n        pytester.makepyfile(**contents)\n        result = pytester.run(sys.executable, *args)\n        if mode == \"plain\":\n            expected = \"E       AssertionError\"\n        elif mode == \"rewrite\":\n            expected = \"*assert 10 == 30*\"\n        else:\n            assert 0\n\n        if not disable_plugin_autoload or explicit_specify:\n            result.assert_outcomes(failed=2)\n            result.stdout.fnmatch_lines([expected, expected])\n        else:\n            result.assert_outcomes(errors=2)\n            result.stdout.fnmatch_lines(\n                [\n                    \"E       fixture 'check_first' not found\",\n                    \"E       fixture 'check_first2' not found\",\n                ]\n            )\n", "type": "function"}, {"name": "test_rewrite_infinite_recursion", "is_method": false, "class_name": null, "parameters": ["pytester", "pytestconfig", "monkeypatch"], "calls": ["pytester.syspathinsert", "pytester.makepyfile", "pytester.makepyfile", "monkeypatch.setattr", "monkeypatch.setattr", "AssertionRewritingHook", "hook.find_spec", "importlib.util.module_from_spec", "hook.exec_module", "write_pyc_called.append", "original_write_pyc", "len", "hook.find_spec"], "code_location": {"file": "test_assertrewrite.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 1857, "end_line": 1888}, "code_snippet": "def test_rewrite_infinite_recursion(\n    pytester: Pytester, pytestconfig, monkeypatch\n) -> None:\n    \"\"\"Fix infinite recursion when writing pyc files: if an import happens to be triggered when writing the pyc\n    file, this would cause another call to the hook, which would trigger another pyc writing, which could\n    trigger another import, and so on. (#3506)\"\"\"\n    from _pytest.assertion import rewrite as rewritemod\n\n    pytester.syspathinsert()\n    pytester.makepyfile(test_foo=\"def test_foo(): pass\")\n    pytester.makepyfile(test_bar=\"def test_bar(): pass\")\n\n    original_write_pyc = rewritemod._write_pyc\n\n    write_pyc_called = []\n\n    def spy_write_pyc(*args, **kwargs):\n        # make a note that we have called _write_pyc\n        write_pyc_called.append(True)\n        # try to import a module at this point: we should not try to rewrite this module\n        assert hook.find_spec(\"test_bar\") is None\n        return original_write_pyc(*args, **kwargs)\n\n    monkeypatch.setattr(rewritemod, \"_write_pyc\", spy_write_pyc)\n    monkeypatch.setattr(sys, \"dont_write_bytecode\", False)\n\n    hook = AssertionRewritingHook(pytestconfig)\n    spec = hook.find_spec(\"test_foo\")\n    assert spec is not None\n    module = importlib.util.module_from_spec(spec)\n    hook.exec_module(module)\n    assert len(write_pyc_called) == 1\n", "type": "function"}, {"name": "test_pdb_can_be_rewritten", "is_method": false, "class_name": null, "parameters": ["pytester"], "calls": ["pytester.makepyfile", "pytester.runpytest_subprocess", "result.stdout.fnmatch_lines"], "code_location": {"file": "acceptance_test.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 1409, "end_line": 1441}, "code_snippet": "def test_pdb_can_be_rewritten(pytester: Pytester) -> None:\n    pytester.makepyfile(\n        **{\n            \"conftest.py\": \"\"\"\n                import pytest\n                pytest.register_assert_rewrite(\"pdb\")\n                \"\"\",\n            \"__init__.py\": \"\",\n            \"pdb.py\": \"\"\"\n                def check():\n                    assert 1 == 2\n                \"\"\",\n            \"test_pdb.py\": \"\"\"\n                def test():\n                    import pdb\n                    assert pdb.check()\n                \"\"\",\n        }\n    )\n    # Disable debugging plugin itself to avoid:\n    # > INTERNALERROR> AttributeError: module 'pdb' has no attribute 'set_trace'\n    result = pytester.runpytest_subprocess(\"-p\", \"no:debugging\", \"-vv\")\n    result.stdout.fnmatch_lines(\n        [\n            \"    def check():\",\n            \">       assert 1 == 2\",\n            \"E       assert 1 == 2\",\n            \"\",\n            \"pdb.py:2: AssertionError\",\n            \"*= 1 failed in *\",\n        ]\n    )\n    assert result.ret == 1\n", "type": "function"}, {"name": "test_rewrite_warning_ignore", "is_method": true, "class_name": "TestRewriteOnImport", "parameters": ["self", "pytester"], "calls": ["pytester.makeconftest", "pytester.runpytest_subprocess", "result.stdout.no_fnmatch_line", "strip", "result.stderr.str"], "code_location": {"file": "test_assertrewrite.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 1202, "end_line": 1216}, "code_snippet": "    def test_rewrite_warning_ignore(self, pytester: Pytester) -> None:\n        pytester.makeconftest(\n            \"\"\"\n            import pytest\n            pytest.register_assert_rewrite(\"_pytest\")\n        \"\"\"\n        )\n        # needs to be a subprocess because pytester explicitly disables this warning\n        result = pytester.runpytest_subprocess(\n            \"-W\",\n            \"ignore:Module already imported so cannot be rewritten; _pytest:pytest.PytestAssertRewriteWarning\",\n        )\n        # Previously, when the message pattern used to contain an extra `:`, an error was raised.\n        assert not result.stderr.str().strip()\n        result.stdout.no_fnmatch_line(\"*Module already imported*; _pytest\")\n", "type": "function"}, {"name": "test_pytest_plugins_rewrite", "is_method": true, "class_name": "TestImportHookInstallation", "parameters": ["self", "pytester", "mode"], "calls": ["pytest.mark.parametrize", "pytester.makepyfile", "pytester.runpytest_subprocess", "result.stdout.fnmatch_lines"], "code_location": {"file": "test_assertion.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 147, "end_line": 173}, "code_snippet": "    def test_pytest_plugins_rewrite(self, pytester: Pytester, mode) -> None:\n        contents = {\n            \"conftest.py\": \"\"\"\n                pytest_plugins = ['ham']\n            \"\"\",\n            \"ham.py\": \"\"\"\n                import pytest\n                @pytest.fixture\n                def check_first():\n                    def check(values, value):\n                        assert values.pop(0) == value\n                    return check\n            \"\"\",\n            \"test_foo.py\": \"\"\"\n                def test_foo(check_first):\n                    check_first([10, 30], 30)\n            \"\"\",\n        }\n        pytester.makepyfile(**contents)\n        result = pytester.runpytest_subprocess(f\"--assert={mode}\")\n        if mode == \"plain\":\n            expected = \"E       AssertionError\"\n        elif mode == \"rewrite\":\n            expected = \"*assert 10 == 30*\"\n        else:\n            assert 0\n        result.stdout.fnmatch_lines([expected])\n", "type": "function"}], "retrieved_count": 10, "cost_time": 1.2049696445465088}
{"question": "Why does test_rewrite_ast employ pytest.register_assert_rewrite() in the package's __init__.py rather than relying solely on the automatic conftest-based rewriting mechanism, and what does this reveal about the design architecture?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"name": "test_rewrite_ast", "is_method": true, "class_name": "TestImportHookInstallation", "parameters": ["self", "pytester"], "calls": ["pytester.mkdir", "pytester.makepyfile", "pytester.runpytest_subprocess", "result.stdout.fnmatch_lines"], "code_location": {"file": "test_assertion.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 328, "end_line": 371}, "code_snippet": "    def test_rewrite_ast(self, pytester: Pytester) -> None:\n        pytester.mkdir(\"pkg\")\n        contents = {\n            \"pkg/__init__.py\": \"\"\"\n                import pytest\n                pytest.register_assert_rewrite('pkg.helper')\n            \"\"\",\n            \"pkg/helper.py\": \"\"\"\n                def tool():\n                    a, b = 2, 3\n                    assert a == b\n            \"\"\",\n            \"pkg/plugin.py\": \"\"\"\n                import pytest, pkg.helper\n                @pytest.fixture\n                def tool():\n                    return pkg.helper.tool\n            \"\"\",\n            \"pkg/other.py\": \"\"\"\n                values = [3, 2]\n                def tool():\n                    assert values.pop() == 3\n            \"\"\",\n            \"conftest.py\": \"\"\"\n                pytest_plugins = ['pkg.plugin']\n            \"\"\",\n            \"test_pkg.py\": \"\"\"\n                import pkg.other\n                def test_tool(tool):\n                    tool()\n                def test_other():\n                    pkg.other.tool()\n            \"\"\",\n        }\n        pytester.makepyfile(**contents)\n        result = pytester.runpytest_subprocess(\"--assert=rewrite\")\n        result.stdout.fnmatch_lines(\n            [\n                \">*assert a == b*\",\n                \"E*assert 2 == 3*\",\n                \">*assert values.pop() == 3*\",\n                \"E*AssertionError\",\n            ]\n        )\n", "type": "function"}, {"name": "test_rewrite_warning", "is_method": true, "class_name": "TestRewriteOnImport", "parameters": ["self", "pytester"], "calls": ["pytester.makeconftest", "pytester.runpytest_subprocess", "result.stdout.fnmatch_lines"], "code_location": {"file": "test_assertrewrite.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 1191, "end_line": 1200}, "code_snippet": "    def test_rewrite_warning(self, pytester: Pytester) -> None:\n        pytester.makeconftest(\n            \"\"\"\n            import pytest\n            pytest.register_assert_rewrite(\"_pytest\")\n        \"\"\"\n        )\n        # needs to be a subprocess because pytester explicitly disables this warning\n        result = pytester.runpytest_subprocess()\n        result.stdout.fnmatch_lines([\"*Module already imported*; _pytest\"])\n", "type": "function"}, {"name": "test_rewrites_plugin_as_a_package", "is_method": true, "class_name": "TestAssertionRewrite", "parameters": ["self", "pytester"], "calls": ["pytester.mkpydir", "write_text", "pytester.makeconftest", "pytester.makepyfile", "pytester.runpytest", "result.stdout.fnmatch_lines", "pkgdir.joinpath"], "code_location": {"file": "test_assertrewrite.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 359, "end_line": 373}, "code_snippet": "    def test_rewrites_plugin_as_a_package(self, pytester: Pytester) -> None:\n        pkgdir = pytester.mkpydir(\"plugin\")\n        pkgdir.joinpath(\"__init__.py\").write_text(\n            \"import pytest\\n\"\n            \"@pytest.fixture\\n\"\n            \"def special_asserter():\\n\"\n            \"    def special_assert(x, y):\\n\"\n            \"        assert x == y\\n\"\n            \"    return special_assert\\n\",\n            encoding=\"utf-8\",\n        )\n        pytester.makeconftest('pytest_plugins = [\"plugin\"]')\n        pytester.makepyfile(\"def test(special_asserter): special_asserter(1, 2)\\n\")\n        result = pytester.runpytest()\n        result.stdout.fnmatch_lines([\"*assert 1 == 2*\"])\n", "type": "function"}, {"name": "test_installed_plugin_rewrite", "is_method": true, "class_name": "TestImportHookInstallation", "parameters": ["self", "pytester", "mode", "monkeypatch", "disable_plugin_autoload", "explicit_specify"], "calls": ["pytest.mark.parametrize", "pytest.mark.parametrize", "pytest.mark.parametrize", "pytester.mkdir", "pytester.makepyfile", "pytester.run", "monkeypatch.setenv", "monkeypatch.setenv", "result.assert_outcomes", "result.stdout.fnmatch_lines", "result.assert_outcomes", "result.stdout.fnmatch_lines", "monkeypatch.delenv", "args.append", "monkeypatch.delenv", "args.append", "args.append"], "code_location": {"file": "test_assertion.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 223, "end_line": 326}, "code_snippet": "    def test_installed_plugin_rewrite(\n        self,\n        pytester: Pytester,\n        mode: str,\n        monkeypatch: pytest.MonkeyPatch,\n        disable_plugin_autoload: str,\n        explicit_specify: str,\n    ) -> None:\n        args = [\"mainwrapper.py\", \"-s\", f\"--assert={mode}\"]\n        if disable_plugin_autoload == \"env_var\":\n            monkeypatch.setenv(\"PYTEST_DISABLE_PLUGIN_AUTOLOAD\", \"1\")\n        elif disable_plugin_autoload == \"cli\":\n            monkeypatch.delenv(\"PYTEST_DISABLE_PLUGIN_AUTOLOAD\", raising=False)\n            args.append(\"--disable-plugin-autoload\")\n        else:\n            assert disable_plugin_autoload == \"\"\n            monkeypatch.delenv(\"PYTEST_DISABLE_PLUGIN_AUTOLOAD\", raising=False)\n\n        name = \"spamplugin\"\n\n        if explicit_specify == \"env_var\":\n            monkeypatch.setenv(\"PYTEST_PLUGINS\", name)\n        elif explicit_specify == \"cli\":\n            args.append(\"-p\")\n            args.append(name)\n        else:\n            assert explicit_specify == \"\"\n\n        # Make sure the hook is installed early enough so that plugins\n        # installed via distribution package are rewritten.\n        pytester.mkdir(\"hampkg\")\n        contents = {\n            \"hampkg/__init__.py\": \"\"\"\\\n                import pytest\n\n                @pytest.fixture\n                def check_first2():\n                    def check(values, value):\n                        assert values.pop(0) == value\n                    return check\n            \"\"\",\n            \"spamplugin.py\": \"\"\"\\\n            import pytest\n            from hampkg import check_first2\n\n            @pytest.fixture\n            def check_first():\n                def check(values, value):\n                    assert values.pop(0) == value\n                return check\n            \"\"\",\n            \"mainwrapper.py\": \"\"\"\\\n            import importlib.metadata\n            import pytest\n\n            class DummyEntryPoint(object):\n                name = 'spamplugin'\n                module_name = 'spam.py'\n                group = 'pytest11'\n\n                def load(self):\n                    import spamplugin\n                    return spamplugin\n\n            class DummyDistInfo(object):\n                version = '1.0'\n                files = ('spamplugin.py', 'hampkg/__init__.py')\n                entry_points = (DummyEntryPoint(),)\n                metadata = {'name': 'foo'}\n\n            def distributions():\n                return (DummyDistInfo(),)\n\n            importlib.metadata.distributions = distributions\n            pytest.main()\n            \"\"\",\n            \"test_foo.py\": \"\"\"\\\n            def test(check_first):\n                check_first([10, 30], 30)\n\n            def test2(check_first2):\n                check_first2([10, 30], 30)\n            \"\"\",\n        }\n        pytester.makepyfile(**contents)\n        result = pytester.run(sys.executable, *args)\n        if mode == \"plain\":\n            expected = \"E       AssertionError\"\n        elif mode == \"rewrite\":\n            expected = \"*assert 10 == 30*\"\n        else:\n            assert 0\n\n        if not disable_plugin_autoload or explicit_specify:\n            result.assert_outcomes(failed=2)\n            result.stdout.fnmatch_lines([expected, expected])\n        else:\n            result.assert_outcomes(errors=2)\n            result.stdout.fnmatch_lines(\n                [\n                    \"E       fixture 'check_first' not found\",\n                    \"E       fixture 'check_first2' not found\",\n                ]\n            )\n", "type": "function"}, {"name": "test_package", "is_method": true, "class_name": "TestRewriteOnImport", "parameters": ["self", "pytester"], "calls": ["pytester.path.joinpath", "pkg.mkdir", "pkg.joinpath", "write_text", "pkg.joinpath", "pytester.runpytest"], "code_location": {"file": "test_assertrewrite.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 1167, "end_line": 1177}, "code_snippet": "    def test_package(self, pytester: Pytester) -> None:\n        pkg = pytester.path.joinpath(\"pkg\")\n        pkg.mkdir()\n        pkg.joinpath(\"__init__.py\")\n        pkg.joinpath(\"test_blah.py\").write_text(\n            \"\"\"\ndef test_rewritten():\n    assert \"@py_builtins\" in globals()\"\"\",\n            encoding=\"utf-8\",\n        )\n        assert pytester.runpytest().ret == 0\n", "type": "function"}, {"name": "test_rewrite_warning_ignore", "is_method": true, "class_name": "TestRewriteOnImport", "parameters": ["self", "pytester"], "calls": ["pytester.makeconftest", "pytester.runpytest_subprocess", "result.stdout.no_fnmatch_line", "strip", "result.stderr.str"], "code_location": {"file": "test_assertrewrite.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 1202, "end_line": 1216}, "code_snippet": "    def test_rewrite_warning_ignore(self, pytester: Pytester) -> None:\n        pytester.makeconftest(\n            \"\"\"\n            import pytest\n            pytest.register_assert_rewrite(\"_pytest\")\n        \"\"\"\n        )\n        # needs to be a subprocess because pytester explicitly disables this warning\n        result = pytester.runpytest_subprocess(\n            \"-W\",\n            \"ignore:Module already imported so cannot be rewritten; _pytest:pytest.PytestAssertRewriteWarning\",\n        )\n        # Previously, when the message pattern used to contain an extra `:`, an error was raised.\n        assert not result.stderr.str().strip()\n        result.stdout.no_fnmatch_line(\"*Module already imported*; _pytest\")\n", "type": "function"}, {"name": "test_pytest_plugins_rewrite", "is_method": true, "class_name": "TestImportHookInstallation", "parameters": ["self", "pytester", "mode"], "calls": ["pytest.mark.parametrize", "pytester.makepyfile", "pytester.runpytest_subprocess", "result.stdout.fnmatch_lines"], "code_location": {"file": "test_assertion.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 147, "end_line": 173}, "code_snippet": "    def test_pytest_plugins_rewrite(self, pytester: Pytester, mode) -> None:\n        contents = {\n            \"conftest.py\": \"\"\"\n                pytest_plugins = ['ham']\n            \"\"\",\n            \"ham.py\": \"\"\"\n                import pytest\n                @pytest.fixture\n                def check_first():\n                    def check(values, value):\n                        assert values.pop(0) == value\n                    return check\n            \"\"\",\n            \"test_foo.py\": \"\"\"\n                def test_foo(check_first):\n                    check_first([10, 30], 30)\n            \"\"\",\n        }\n        pytester.makepyfile(**contents)\n        result = pytester.runpytest_subprocess(f\"--assert={mode}\")\n        if mode == \"plain\":\n            expected = \"E       AssertionError\"\n        elif mode == \"rewrite\":\n            expected = \"*assert 10 == 30*\"\n        else:\n            assert 0\n        result.stdout.fnmatch_lines([expected])\n", "type": "function"}, {"name": "test_rewrite_module_imported_from_conftest", "is_method": true, "class_name": "TestRewriteOnImport", "parameters": ["self", "pytester"], "calls": ["pytester.makeconftest", "pytester.makepyfile", "pytester.runpytest_subprocess"], "code_location": {"file": "test_assertrewrite.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 1218, "end_line": 1230}, "code_snippet": "    def test_rewrite_module_imported_from_conftest(self, pytester: Pytester) -> None:\n        pytester.makeconftest(\n            \"\"\"\n            import test_rewrite_module_imported\n        \"\"\"\n        )\n        pytester.makepyfile(\n            test_rewrite_module_imported=\"\"\"\n            def test_rewritten():\n                assert \"@py_builtins\" in globals()\n        \"\"\"\n        )\n        assert pytester.runpytest_subprocess().ret == 0\n", "type": "function"}, {"name": "test_rewritten", "is_method": false, "class_name": null, "parameters": ["pytester"], "calls": ["pytester.makepyfile", "pytester.runpytest"], "code_location": {"file": "test_assertion.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 1551, "end_line": 1558}, "code_snippet": "def test_rewritten(pytester: Pytester) -> None:\n    pytester.makepyfile(\n        \"\"\"\n        def test_rewritten():\n            assert \"@py_builtins\" in globals()\n    \"\"\"\n    )\n    assert pytester.runpytest().ret == 0\n", "type": "function"}, {"name": "test_dont_rewrite", "is_method": true, "class_name": "TestAssertionRewrite", "parameters": ["self"], "calls": ["rewrite", "isinstance", "len"], "code_location": {"file": "test_assertrewrite.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 342, "end_line": 347}, "code_snippet": "    def test_dont_rewrite(self) -> None:\n        s = \"\"\"'PYTEST_DONT_REWRITE'\\nassert 14\"\"\"\n        m = rewrite(s)\n        assert len(m.body) == 2\n        assert isinstance(m.body[1], ast.Assert)\n        assert m.body[1].msg is None\n", "type": "function"}], "retrieved_count": 10, "cost_time": 1.1990931034088135}
{"question": "Why does the TestShowFixtures class employ separate test methods for validating fixture documentation formatting across different contexts (trimmed docs, indented docs, first-line unindented, class-level fixtures) rather than consolidating these variations into parameterized tests?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"name": "test_show_fixtures_indented_doc_first_line_unindented", "is_method": true, "class_name": "TestShowFixtures", "parameters": ["self", "pytester"], "calls": ["pytester.makepyfile", "pytester.runpytest", "result.stdout.fnmatch_lines", "textwrap.dedent", "textwrap.dedent"], "code_location": {"file": "fixtures.py", "path": "/data3/pwh/swebench-repos/pytest/testing/python", "start_line": 3715, "end_line": 3742}, "code_snippet": "    def test_show_fixtures_indented_doc_first_line_unindented(\n        self, pytester: Pytester\n    ) -> None:\n        p = pytester.makepyfile(\n            textwrap.dedent(\n                '''\\\n                import pytest\n                @pytest.fixture\n                def fixture1():\n                    \"\"\"line1\n                    line2\n                        indented line\n                    \"\"\"\n                '''\n            )\n        )\n        result = pytester.runpytest(\"--fixtures\", p)\n        result.stdout.fnmatch_lines(\n            textwrap.dedent(\n                \"\"\"\\\n                * fixtures defined from test_show_fixtures_indented_doc_first_line_unindented *\n                fixture1 -- test_show_fixtures_indented_doc_first_line_unindented.py:3\n                    line1\n                    line2\n                        indented line\n                \"\"\"\n            )\n        )\n", "type": "function"}, {"name": "test_show_fixtures_indented_doc", "is_method": true, "class_name": "TestShowFixtures", "parameters": ["self", "pytester"], "calls": ["pytester.makepyfile", "pytester.runpytest", "result.stdout.fnmatch_lines", "textwrap.dedent", "textwrap.dedent"], "code_location": {"file": "fixtures.py", "path": "/data3/pwh/swebench-repos/pytest/testing/python", "start_line": 3689, "end_line": 3713}, "code_snippet": "    def test_show_fixtures_indented_doc(self, pytester: Pytester) -> None:\n        p = pytester.makepyfile(\n            textwrap.dedent(\n                '''\\\n                import pytest\n                @pytest.fixture\n                def fixture1():\n                    \"\"\"\n                    line1\n                        indented line\n                    \"\"\"\n                '''\n            )\n        )\n        result = pytester.runpytest(\"--fixtures\", p)\n        result.stdout.fnmatch_lines(\n            textwrap.dedent(\n                \"\"\"\\\n                * fixtures defined from test_show_fixtures_indented_doc *\n                fixture1 -- test_show_fixtures_indented_doc.py:3\n                    line1\n                        indented line\n                \"\"\"\n            )\n        )\n", "type": "function"}, {"name": "test_show_fixtures_indented_in_class", "is_method": true, "class_name": "TestShowFixtures", "parameters": ["self", "pytester"], "calls": ["pytester.makepyfile", "pytester.runpytest", "result.stdout.fnmatch_lines", "textwrap.dedent", "textwrap.dedent"], "code_location": {"file": "fixtures.py", "path": "/data3/pwh/swebench-repos/pytest/testing/python", "start_line": 3744, "end_line": 3770}, "code_snippet": "    def test_show_fixtures_indented_in_class(self, pytester: Pytester) -> None:\n        p = pytester.makepyfile(\n            textwrap.dedent(\n                '''\\\n                import pytest\n                class TestClass(object):\n                    @pytest.fixture\n                    def fixture1(self):\n                        \"\"\"line1\n                        line2\n                            indented line\n                        \"\"\"\n                '''\n            )\n        )\n        result = pytester.runpytest(\"--fixtures\", p)\n        result.stdout.fnmatch_lines(\n            textwrap.dedent(\n                \"\"\"\\\n                * fixtures defined from test_show_fixtures_indented_in_class *\n                fixture1 -- test_show_fixtures_indented_in_class.py:4\n                    line1\n                    line2\n                        indented line\n                \"\"\"\n            )\n        )\n", "type": "function"}, {"name": "test_show_fixtures_trimmed_doc", "is_method": true, "class_name": "TestShowFixtures", "parameters": ["self", "pytester"], "calls": ["pytester.makepyfile", "pytester.runpytest", "result.stdout.fnmatch_lines", "textwrap.dedent", "textwrap.dedent"], "code_location": {"file": "fixtures.py", "path": "/data3/pwh/swebench-repos/pytest/testing/python", "start_line": 3652, "end_line": 3687}, "code_snippet": "    def test_show_fixtures_trimmed_doc(self, pytester: Pytester) -> None:\n        p = pytester.makepyfile(\n            textwrap.dedent(\n                '''\\\n                import pytest\n                @pytest.fixture\n                def arg1():\n                    \"\"\"\n                    line1\n                    line2\n\n                    \"\"\"\n                @pytest.fixture\n                def arg2():\n                    \"\"\"\n                    line1\n                    line2\n\n                    \"\"\"\n                '''\n            )\n        )\n        result = pytester.runpytest(\"--fixtures\", p)\n        result.stdout.fnmatch_lines(\n            textwrap.dedent(\n                \"\"\"\\\n                * fixtures defined from test_show_fixtures_trimmed_doc *\n                arg2 -- test_show_fixtures_trimmed_doc.py:10\n                    line1\n                    line2\n                arg1 -- test_show_fixtures_trimmed_doc.py:3\n                    line1\n                    line2\n                \"\"\"\n            )\n        )\n", "type": "function"}, {"name": "TestShowFixtures", "docstring": "", "methods": ["test_funcarg_compat", "test_show_help", "test_show_fixtures", "test_show_fixtures_verbose", "test_show_fixtures_testmodule", "test_show_fixtures_conftest", "test_show_fixtures_trimmed_doc", "test_show_fixtures_indented_doc", "test_show_fixtures_indented_doc_first_line_unindented", "test_show_fixtures_indented_in_class", "test_show_fixtures_different_files", "test_show_fixtures_with_same_name", "test_fixture_disallow_twice"], "attributes": [], "code_location": {"file": "fixtures.py", "path": "/data3/pwh/swebench-repos/pytest/testing/python", "start_line": 3571, "end_line": 3860}, "type": "class"}, {"name": "test_multiline_docstring_in_module", "is_method": false, "class_name": null, "parameters": ["pytester"], "calls": ["pytester.makepyfile", "pytester.runpytest", "result.stdout.fnmatch_lines"], "code_location": {"file": "show_fixtures_per_test.py", "path": "/data3/pwh/swebench-repos/pytest/testing/python", "start_line": 187, "end_line": 218}, "code_snippet": "def test_multiline_docstring_in_module(pytester: Pytester) -> None:\n    p = pytester.makepyfile(\n        '''\n        import pytest\n        @pytest.fixture\n        def arg1():\n            \"\"\"Docstring content that spans across multiple lines,\n            through second line,\n            and through third line.\n\n            Docstring content that extends into a second paragraph.\n\n            Docstring content that extends into a third paragraph.\n            \"\"\"\n        def test_arg1(arg1):\n            pass\n    '''\n    )\n\n    result = pytester.runpytest(\"--fixtures-per-test\", p)\n    assert result.ret == 0\n\n    result.stdout.fnmatch_lines(\n        [\n            \"*fixtures used by test_arg1*\",\n            \"*(test_multiline_docstring_in_module.py:13)*\",\n            \"arg1 -- test_multiline_docstring_in_module.py:3\",\n            \"    Docstring content that spans across multiple lines,\",\n            \"    through second line,\",\n            \"    and through third line.\",\n        ]\n    )\n", "type": "function"}, {"name": "test_show_only_active_fixtures", "is_method": false, "class_name": null, "parameters": ["pytester", "mode", "dummy_yaml_custom_test"], "calls": ["pytester.makepyfile", "pytester.runpytest", "result.stdout.fnmatch_lines", "result.stdout.no_fnmatch_line"], "code_location": {"file": "test_setuponly.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 16, "end_line": 39}, "code_snippet": "def test_show_only_active_fixtures(\n    pytester: Pytester, mode, dummy_yaml_custom_test\n) -> None:\n    pytester.makepyfile(\n        '''\n        import pytest\n        @pytest.fixture\n        def _arg0():\n            \"\"\"hidden arg0 fixture\"\"\"\n        @pytest.fixture\n        def arg1():\n            \"\"\"arg1 docstring\"\"\"\n        def test_arg1(arg1):\n            pass\n    '''\n    )\n\n    result = pytester.runpytest(mode)\n    assert result.ret == 0\n\n    result.stdout.fnmatch_lines(\n        [\"*SETUP    F arg1*\", \"*test_arg1 (fixtures used: arg1)*\", \"*TEARDOWN F arg1*\"]\n    )\n    result.stdout.no_fnmatch_line(\"*_arg0*\")\n", "type": "function"}, {"name": "test_fixtures_setup_setUpClass_issue8394", "is_method": false, "class_name": null, "parameters": ["pytester"], "calls": ["pytester.makepyfile", "pytester.runpytest", "result.stdout.no_fnmatch_line", "pytester.runpytest", "result.stdout.fnmatch_lines"], "code_location": {"file": "test_unittest.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 315, "end_line": 336}, "code_snippet": "def test_fixtures_setup_setUpClass_issue8394(pytester: Pytester) -> None:\n    pytester.makepyfile(\n        \"\"\"\n        import unittest\n        class MyTestCase(unittest.TestCase):\n            @classmethod\n            def setUpClass(cls):\n                pass\n            def test_func1(self):\n                pass\n            @classmethod\n            def tearDownClass(cls):\n                pass\n    \"\"\"\n    )\n    result = pytester.runpytest(\"--fixtures\")\n    assert result.ret == 0\n    result.stdout.no_fnmatch_line(\"*no docstring available*\")\n\n    result = pytester.runpytest(\"--fixtures\", \"-v\")\n    assert result.ret == 0\n    result.stdout.fnmatch_lines([\"*no docstring available*\"])\n", "type": "function"}, {"name": "test_show_fixtures_testmodule", "is_method": true, "class_name": "TestShowFixtures", "parameters": ["self", "pytester"], "calls": ["pytester.makepyfile", "pytester.runpytest", "result.stdout.fnmatch_lines", "result.stdout.no_fnmatch_line"], "code_location": {"file": "fixtures.py", "path": "/data3/pwh/swebench-repos/pytest/testing/python", "start_line": 3602, "end_line": 3623}, "code_snippet": "    def test_show_fixtures_testmodule(self, pytester: Pytester) -> None:\n        p = pytester.makepyfile(\n            '''\n            import pytest\n            @pytest.fixture\n            def _arg0():\n                \"\"\" hidden \"\"\"\n            @pytest.fixture\n            def arg1():\n                \"\"\"  hello world \"\"\"\n        '''\n        )\n        result = pytester.runpytest(\"--fixtures\", p)\n        result.stdout.fnmatch_lines(\n            \"\"\"\n            *tmp_path -- *\n            *fixtures defined from*\n            *arg1 -- test_show_fixtures_testmodule.py:6*\n            *hello world*\n        \"\"\"\n        )\n        result.stdout.no_fnmatch_line(\"*arg0*\")\n", "type": "function"}, {"name": "test_verbose_include_multiline_docstring", "is_method": false, "class_name": null, "parameters": ["pytester"], "calls": ["pytester.makepyfile", "pytester.runpytest", "result.stdout.fnmatch_lines"], "code_location": {"file": "show_fixtures_per_test.py", "path": "/data3/pwh/swebench-repos/pytest/testing/python", "start_line": 221, "end_line": 256}, "code_snippet": "def test_verbose_include_multiline_docstring(pytester: Pytester) -> None:\n    p = pytester.makepyfile(\n        '''\n        import pytest\n        @pytest.fixture\n        def arg1():\n            \"\"\"Docstring content that spans across multiple lines,\n            through second line,\n            and through third line.\n\n            Docstring content that extends into a second paragraph.\n\n            Docstring content that extends into a third paragraph.\n            \"\"\"\n        def test_arg1(arg1):\n            pass\n    '''\n    )\n\n    result = pytester.runpytest(\"--fixtures-per-test\", \"-v\", p)\n    assert result.ret == 0\n\n    result.stdout.fnmatch_lines(\n        [\n            \"*fixtures used by test_arg1*\",\n            \"*(test_verbose_include_multiline_docstring.py:13)*\",\n            \"arg1 -- test_verbose_include_multiline_docstring.py:3\",\n            \"    Docstring content that spans across multiple lines,\",\n            \"    through second line,\",\n            \"    and through third line.\",\n            \"    \",\n            \"    Docstring content that extends into a second paragraph.\",\n            \"    \",\n            \"    Docstring content that extends into a third paragraph.\",\n        ]\n    )\n", "type": "function"}], "retrieved_count": 10, "cost_time": 1.207578182220459}
{"question": "Why does the repeated fixture instantiation and teardown cycle in test_package_fixture_complex impact performance when scaling to hundreds of package-scoped fixtures with autouse dependencies?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"name": "test_package_fixture_complex", "is_method": true, "class_name": "TestFixtureManagerParseFactories", "parameters": ["self", "pytester"], "calls": ["pytester.makepyfile", "pytester.syspathinsert", "pytester.mkdir", "write_text", "write_text", "write_text", "pytester.inline_run", "reprec.assertoutcome", "textwrap.dedent", "textwrap.dedent", "package.joinpath", "package.joinpath", "package.joinpath"], "code_location": {"file": "fixtures.py", "path": "/data3/pwh/swebench-repos/pytest/testing/python", "start_line": 1874, "end_line": 1915}, "code_snippet": "    def test_package_fixture_complex(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            __init__=\"\"\"\\\n            values = []\n        \"\"\"\n        )\n        pytester.syspathinsert(pytester.path.name)\n        package = pytester.mkdir(\"package\")\n        package.joinpath(\"__init__.py\").write_text(\"\", encoding=\"utf-8\")\n        package.joinpath(\"conftest.py\").write_text(\n            textwrap.dedent(\n                \"\"\"\\\n                import pytest\n                from .. import values\n                @pytest.fixture(scope=\"package\")\n                def one():\n                    values.append(\"package\")\n                    yield values\n                    values.pop()\n                @pytest.fixture(scope=\"package\", autouse=True)\n                def two():\n                    values.append(\"package-auto\")\n                    yield values\n                    values.pop()\n                \"\"\"\n            ),\n            encoding=\"utf-8\",\n        )\n        package.joinpath(\"test_x.py\").write_text(\n            textwrap.dedent(\n                \"\"\"\\\n                from .. import values\n                def test_package_autouse():\n                    assert values == [\"package-auto\"]\n                def test_package(one):\n                    assert values == [\"package-auto\", \"package\"]\n                \"\"\"\n            ),\n            encoding=\"utf-8\",\n        )\n        reprec = pytester.inline_run()\n        reprec.assertoutcome(passed=2)\n", "type": "function"}, {"name": "test_multiple_packages", "is_method": true, "class_name": "TestScopeOrdering", "parameters": ["self", "pytester"], "calls": ["pytester.mkdir", "write_text", "root.joinpath", "sub1.mkdir", "touch", "write_text", "write_text", "root.joinpath", "sub2.mkdir", "touch", "write_text", "write_text", "pytester.inline_run", "reprec.assertoutcome", "textwrap.dedent", "textwrap.dedent", "textwrap.dedent", "textwrap.dedent", "root.joinpath", "sub1.joinpath", "sub1.joinpath", "sub1.joinpath", "sub2.joinpath", "sub2.joinpath", "sub2.joinpath"], "code_location": {"file": "fixtures.py", "path": "/data3/pwh/swebench-repos/pytest/testing/python", "start_line": 4459, "end_line": 4531}, "code_snippet": "    def test_multiple_packages(self, pytester: Pytester) -> None:\n        \"\"\"Complex test involving multiple package fixtures. Make sure teardowns\n        are executed in order.\n        .\n         root\n             __init__.py\n             sub1\n                __init__.py\n                conftest.py\n                test_1.py\n             sub2\n                 __init__.py\n                 conftest.py\n                 test_2.py\n        \"\"\"\n        root = pytester.mkdir(\"root\")\n        root.joinpath(\"__init__.py\").write_text(\"values = []\", encoding=\"utf-8\")\n        sub1 = root.joinpath(\"sub1\")\n        sub1.mkdir()\n        sub1.joinpath(\"__init__.py\").touch()\n        sub1.joinpath(\"conftest.py\").write_text(\n            textwrap.dedent(\n                \"\"\"\\\n            import pytest\n            from .. import values\n            @pytest.fixture(scope=\"package\")\n            def fix():\n                values.append(\"pre-sub1\")\n                yield values\n                assert values.pop() == \"pre-sub1\"\n        \"\"\"\n            ),\n            encoding=\"utf-8\",\n        )\n        sub1.joinpath(\"test_1.py\").write_text(\n            textwrap.dedent(\n                \"\"\"\\\n            from .. import values\n            def test_1(fix):\n                assert values == [\"pre-sub1\"]\n        \"\"\"\n            ),\n            encoding=\"utf-8\",\n        )\n        sub2 = root.joinpath(\"sub2\")\n        sub2.mkdir()\n        sub2.joinpath(\"__init__.py\").touch()\n        sub2.joinpath(\"conftest.py\").write_text(\n            textwrap.dedent(\n                \"\"\"\\\n            import pytest\n            from .. import values\n            @pytest.fixture(scope=\"package\")\n            def fix():\n                values.append(\"pre-sub2\")\n                yield values\n                assert values.pop() == \"pre-sub2\"\n        \"\"\"\n            ),\n            encoding=\"utf-8\",\n        )\n        sub2.joinpath(\"test_2.py\").write_text(\n            textwrap.dedent(\n                \"\"\"\\\n            from .. import values\n            def test_2(fix):\n                assert values == [\"pre-sub2\"]\n        \"\"\"\n            ),\n            encoding=\"utf-8\",\n        )\n        reprec = pytester.inline_run()\n        reprec.assertoutcome(passed=2)\n", "type": "function"}, {"name": "test_package_xunit_fixture", "is_method": true, "class_name": "TestFixtureManagerParseFactories", "parameters": ["self", "pytester"], "calls": ["pytester.makepyfile", "pytester.mkdir", "write_text", "write_text", "pytester.mkdir", "write_text", "write_text", "pytester.inline_run", "reprec.assertoutcome", "textwrap.dedent", "textwrap.dedent", "textwrap.dedent", "textwrap.dedent", "package.joinpath", "package.joinpath", "package.joinpath", "package.joinpath"], "code_location": {"file": "fixtures.py", "path": "/data3/pwh/swebench-repos/pytest/testing/python", "start_line": 1819, "end_line": 1872}, "code_snippet": "    def test_package_xunit_fixture(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            __init__=\"\"\"\\\n            values = []\n        \"\"\"\n        )\n        package = pytester.mkdir(\"package\")\n        package.joinpath(\"__init__.py\").write_text(\n            textwrap.dedent(\n                \"\"\"\\\n                from .. import values\n                def setup_module():\n                    values.append(\"package\")\n                def teardown_module():\n                    values[:] = []\n                \"\"\"\n            ),\n            encoding=\"utf-8\",\n        )\n        package.joinpath(\"test_x.py\").write_text(\n            textwrap.dedent(\n                \"\"\"\\\n                from .. import values\n                def test_x():\n                    assert values == [\"package\"]\n                \"\"\"\n            ),\n            encoding=\"utf-8\",\n        )\n        package = pytester.mkdir(\"package2\")\n        package.joinpath(\"__init__.py\").write_text(\n            textwrap.dedent(\n                \"\"\"\\\n                from .. import values\n                def setup_module():\n                    values.append(\"package2\")\n                def teardown_module():\n                    values[:] = []\n                \"\"\"\n            ),\n            encoding=\"utf-8\",\n        )\n        package.joinpath(\"test_x.py\").write_text(\n            textwrap.dedent(\n                \"\"\"\\\n                from .. import values\n                def test_x():\n                    assert values == [\"package2\"]\n                \"\"\"\n            ),\n            encoding=\"utf-8\",\n        )\n        reprec = pytester.inline_run()\n        reprec.assertoutcome(passed=2)\n", "type": "function"}, {"name": "test_func_closure_all_scopes_complex", "is_method": true, "class_name": "TestScopeOrdering", "parameters": ["self", "pytester"], "calls": ["pytester.makeconftest", "pytester.makepyfile", "pytester.makepyfile", "pytester.inline_genitems", "isinstance", "TopRequest", "split"], "code_location": {"file": "fixtures.py", "path": "/data3/pwh/swebench-repos/pytest/testing/python", "start_line": 4381, "end_line": 4424}, "code_snippet": "    def test_func_closure_all_scopes_complex(self, pytester: Pytester) -> None:\n        \"\"\"Complex test involving all scopes and mixing autouse with normal fixtures\"\"\"\n        pytester.makeconftest(\n            \"\"\"\n            import pytest\n\n            @pytest.fixture(scope='session')\n            def s1(): pass\n\n            @pytest.fixture(scope='package', autouse=True)\n            def p1(): pass\n        \"\"\"\n        )\n        pytester.makepyfile(**{\"__init__.py\": \"\"})\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n\n            @pytest.fixture(scope='module', autouse=True)\n            def m1(): pass\n\n            @pytest.fixture(scope='module')\n            def m2(s1): pass\n\n            @pytest.fixture(scope='function')\n            def f1(): pass\n\n            @pytest.fixture(scope='function')\n            def f2(): pass\n\n            class Test:\n\n                @pytest.fixture(scope='class', autouse=True)\n                def c1(self):\n                    pass\n\n                def test_func(self, f2, f1, m2):\n                    pass\n        \"\"\"\n        )\n        items, _ = pytester.inline_genitems()\n        assert isinstance(items[0], Function)\n        request = TopRequest(items[0], _ispytest=True)\n        assert request.fixturenames == \"s1 p1 m1 m2 c1 f2 f1\".split()\n", "type": "function"}, {"name": "many_files", "is_method": true, "class_name": "TestProgressWithTeardown", "parameters": ["self", "pytester", "contest_with_teardown_fixture"], "calls": ["pytester.makepyfile"], "code_location": {"file": "test_terminal.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 2428, "end_line": 2442}, "code_snippet": "    def many_files(self, pytester: Pytester, contest_with_teardown_fixture) -> None:\n        pytester.makepyfile(\n            test_bar=\"\"\"\n                import pytest\n                @pytest.mark.parametrize('i', range(5))\n                def test_bar(fail_teardown, i):\n                    pass\n            \"\"\",\n            test_foo=\"\"\"\n                import pytest\n                @pytest.mark.parametrize('i', range(15))\n                def test_foo(fail_teardown, i):\n                    pass\n            \"\"\",\n        )\n", "type": "function"}, {"name": "test_parametrized_fixture_teardown_order", "is_method": true, "class_name": "TestFixtureMarker", "parameters": ["self", "pytester"], "calls": ["pytester.makepyfile", "pytester.runpytest", "result.stdout.fnmatch_lines"], "code_location": {"file": "fixtures.py", "path": "/data3/pwh/swebench-repos/pytest/testing/python", "start_line": 3049, "end_line": 3088}, "code_snippet": "    def test_parametrized_fixture_teardown_order(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n            @pytest.fixture(params=[1,2], scope=\"class\")\n            def param1(request):\n                return request.param\n\n            values = []\n\n            class TestClass(object):\n                @classmethod\n                @pytest.fixture(scope=\"class\", autouse=True)\n                def setup1(self, request, param1):\n                    values.append(1)\n                    request.addfinalizer(self.teardown1)\n                @classmethod\n                def teardown1(self):\n                    assert values.pop() == 1\n                @pytest.fixture(scope=\"class\", autouse=True)\n                def setup2(self, request, param1):\n                    values.append(2)\n                    request.addfinalizer(self.teardown2)\n                @classmethod\n                def teardown2(self):\n                    assert values.pop() == 2\n                def test(self):\n                    pass\n\n            def test_finish():\n                assert not values\n        \"\"\"\n        )\n        result = pytester.runpytest(\"-v\")\n        result.stdout.fnmatch_lines(\n            \"\"\"\n            *3 passed*\n        \"\"\"\n        )\n        assert result.ret == 0\n", "type": "function"}, {"name": "test_parametrized_package_scope_reordering", "is_method": true, "class_name": "TestScopeOrdering", "parameters": ["self", "pytester"], "calls": ["pytester.makepyfile", "pytester.runpytest", "result.stdout.fnmatch_lines"], "code_location": {"file": "fixtures.py", "path": "/data3/pwh/swebench-repos/pytest/testing/python", "start_line": 4426, "end_line": 4457}, "code_snippet": "    def test_parametrized_package_scope_reordering(self, pytester: Pytester) -> None:\n        \"\"\"A parameterized package-scoped fixture correctly reorders items to\n        minimize setups & teardowns.\n\n        Regression test for #12328.\n        \"\"\"\n        pytester.makepyfile(\n            __init__=\"\",\n            conftest=\"\"\"\n                import pytest\n                @pytest.fixture(scope=\"package\", params=[\"a\", \"b\"])\n                def fix(request):\n                    return request.param\n            \"\"\",\n            test_1=\"def test1(fix): pass\",\n            test_2=\"def test2(fix): pass\",\n        )\n\n        result = pytester.runpytest(\"--setup-plan\")\n        assert result.ret == ExitCode.OK\n        result.stdout.fnmatch_lines(\n            [\n                \"  SETUP    P fix['a']\",\n                \"        test_1.py::test1[a] (fixtures used: fix, request)\",\n                \"        test_2.py::test2[a] (fixtures used: fix, request)\",\n                \"  TEARDOWN P fix['a']\",\n                \"  SETUP    P fix['b']\",\n                \"        test_1.py::test1[b] (fixtures used: fix, request)\",\n                \"        test_2.py::test2[b] (fixtures used: fix, request)\",\n                \"  TEARDOWN P fix['b']\",\n            ],\n        )\n", "type": "function"}, {"name": "test_fixture_dependency", "is_method": false, "class_name": null, "parameters": ["pytester"], "calls": ["pytester.makeconftest", "touch", "pytester.mkdir", "touch", "write_text", "sub.joinpath", "subsub.mkdir", "touch", "write_text", "pytester.runpytest", "result.stdout.fnmatch_lines", "textwrap.dedent", "textwrap.dedent", "pytester.path.joinpath", "sub.joinpath", "sub.joinpath", "subsub.joinpath", "subsub.joinpath"], "code_location": {"file": "test_conftest.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 466, "end_line": 510}, "code_snippet": "def test_fixture_dependency(pytester: Pytester) -> None:\n    pytester.makeconftest(\"\")\n    pytester.path.joinpath(\"__init__.py\").touch()\n    sub = pytester.mkdir(\"sub\")\n    sub.joinpath(\"__init__.py\").touch()\n    sub.joinpath(\"conftest.py\").write_text(\n        textwrap.dedent(\n            \"\"\"\\\n            import pytest\n\n            @pytest.fixture\n            def not_needed():\n                assert False, \"Should not be called!\"\n\n            @pytest.fixture\n            def foo():\n                assert False, \"Should not be called!\"\n\n            @pytest.fixture\n            def bar(foo):\n                return 'bar'\n            \"\"\"\n        ),\n        encoding=\"utf-8\",\n    )\n    subsub = sub.joinpath(\"subsub\")\n    subsub.mkdir()\n    subsub.joinpath(\"__init__.py\").touch()\n    subsub.joinpath(\"test_bar.py\").write_text(\n        textwrap.dedent(\n            \"\"\"\\\n            import pytest\n\n            @pytest.fixture\n            def bar():\n                return 'sub bar'\n\n            def test_event_fixture(bar):\n                assert bar == 'sub bar'\n            \"\"\"\n        ),\n        encoding=\"utf-8\",\n    )\n    result = pytester.runpytest(\"sub\")\n    result.stdout.fnmatch_lines([\"*1 passed*\"])\n", "type": "function"}, {"name": "test_subfixture_teardown_order", "is_method": false, "class_name": null, "parameters": ["pytester"], "calls": ["pytester.makepyfile", "pytester.runpytest"], "code_location": {"file": "fixtures.py", "path": "/data3/pwh/swebench-repos/pytest/testing/python", "start_line": 4974, "end_line": 5023}, "code_snippet": "def test_subfixture_teardown_order(pytester: Pytester) -> None:\n    \"\"\"\n    Make sure fixtures don't re-register their finalization in parent fixtures multiple\n    times, causing ordering failure in their teardowns.\n\n    Regression test for #12135\n    \"\"\"\n    pytester.makepyfile(\n        \"\"\"\n        import pytest\n\n        execution_order = []\n\n        @pytest.fixture(scope=\"class\")\n        def fixture_1():\n            ...\n\n        @pytest.fixture(scope=\"class\")\n        def fixture_2(fixture_1):\n            execution_order.append(\"setup 2\")\n            yield\n            execution_order.append(\"teardown 2\")\n\n        @pytest.fixture(scope=\"class\")\n        def fixture_3(fixture_1):\n            execution_order.append(\"setup 3\")\n            yield\n            execution_order.append(\"teardown 3\")\n\n        class TestFoo:\n            def test_initialize_fixtures(self, fixture_2, fixture_3):\n                ...\n\n            # This would previously reschedule fixture_2's finalizer in the parent fixture,\n            # causing it to be torn down before fixture 3.\n            def test_reschedule_fixture_2(self, fixture_2):\n                ...\n\n            # Force finalization directly on fixture_1\n            # Otherwise the cleanup would sequence 3&2 before 1 as normal.\n            @pytest.mark.parametrize(\"fixture_1\", [None], indirect=[\"fixture_1\"])\n            def test_finalize_fixture_1(self, fixture_1):\n                ...\n\n        def test_result():\n            assert execution_order == [\"setup 2\", \"setup 3\", \"teardown 3\", \"teardown 2\"]\n        \"\"\"\n    )\n    result = pytester.runpytest()\n    assert result.ret == 0\n", "type": "function"}, {"name": "test_teardown_many", "is_method": true, "class_name": "TestProgressWithTeardown", "parameters": ["self", "pytester", "many_files"], "calls": ["pytester.runpytest", "output.stdout.re_match_lines"], "code_location": {"file": "test_terminal.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 2474, "end_line": 2478}, "code_snippet": "    def test_teardown_many(self, pytester: Pytester, many_files) -> None:\n        output = pytester.runpytest()\n        output.stdout.re_match_lines(\n            [r\"test_bar.py (\\.E){5}\\s+\\[ 25%\\]\", r\"test_foo.py (\\.E){15}\\s+\\[100%\\]\"]\n        )\n", "type": "function"}], "retrieved_count": 10, "cost_time": 1.2517366409301758}
{"question": "How would you refactor a minimal test function like test_1 to implement a parameterized testing strategy that maintains backward compatibility while enabling data-driven test execution across multiple input scenarios?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"name": "test_1", "is_method": false, "class_name": null, "parameters": [], "calls": [], "code_location": {"file": "test_first.py", "path": "/data3/pwh/swebench-repos/pytest/testing/example_scripts/customdirectory/tests", "start_line": 6, "end_line": 7}, "code_snippet": "def test_1():\n    pass\n", "type": "function"}, {"name": "test_1", "is_method": false, "class_name": null, "parameters": [], "calls": [], "code_location": {"file": "test_first.py", "path": "/data3/pwh/swebench-repos/pytest/doc/en/example/customdirectory/tests", "start_line": 5, "end_line": 6}, "code_snippet": "def test_1():\n    pass\n", "type": "function"}, {"name": "test_single_tuple_unwraps_values", "is_method": true, "class_name": "TestFunction", "parameters": ["self", "pytester"], "calls": ["pytester.makepyfile", "pytester.inline_run", "reprec.assertoutcome"], "code_location": {"file": "collect.py", "path": "/data3/pwh/swebench-repos/pytest/testing/python", "start_line": 399, "end_line": 409}, "code_snippet": "    def test_single_tuple_unwraps_values(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n            @pytest.mark.parametrize(('arg',), [(1,)])\n            def test_function(arg):\n                assert arg == 1\n        \"\"\"\n        )\n        reprec = pytester.inline_run()\n        reprec.assertoutcome(passed=1)\n", "type": "function"}, {"name": "test_parametrize_onearg", "is_method": true, "class_name": "TestMetafunc", "parameters": ["self"], "calls": ["self.Metafunc", "metafunc.parametrize", "len", "dict", "dict"], "code_location": {"file": "metafunc.py", "path": "/data3/pwh/swebench-repos/pytest/testing/python", "start_line": 995, "end_line": 1002}, "code_snippet": "    def test_parametrize_onearg(self) -> None:\n        metafunc = self.Metafunc(lambda x: None)\n        metafunc.parametrize(\"x\", [1, 2])\n        assert len(metafunc._calls) == 2\n        assert metafunc._calls[0].params == dict(x=1)\n        assert metafunc._calls[0].id == \"1\"\n        assert metafunc._calls[1].params == dict(x=2)\n        assert metafunc._calls[1].id == \"2\"\n", "type": "function"}, {"name": "test_1", "is_method": false, "class_name": null, "parameters": ["arg1"], "calls": [], "code_location": {"file": "test_in_sub1.py", "path": "/data3/pwh/swebench-repos/pytest/testing/example_scripts/fixtures/fill_fixtures/test_conftest_funcargs_only_available_in_subdir/sub1", "start_line": 5, "end_line": 6}, "code_snippet": "def test_1(arg1):\n    pass\n", "type": "function"}, {"name": "test_parametrize_onearg_indirect", "is_method": true, "class_name": "TestMetafunc", "parameters": ["self"], "calls": ["self.Metafunc", "metafunc.parametrize", "dict", "dict"], "code_location": {"file": "metafunc.py", "path": "/data3/pwh/swebench-repos/pytest/testing/python", "start_line": 1004, "end_line": 1010}, "code_snippet": "    def test_parametrize_onearg_indirect(self) -> None:\n        metafunc = self.Metafunc(lambda x: None)\n        metafunc.parametrize(\"x\", [1, 2], indirect=True)\n        assert metafunc._calls[0].params == dict(x=1)\n        assert metafunc._calls[0].id == \"1\"\n        assert metafunc._calls[1].params == dict(x=2)\n        assert metafunc._calls[1].id == \"2\"\n", "type": "function"}, {"name": "test_direct_addressing_selects_duplicates_1", "is_method": true, "class_name": "TestGeneralUsage", "parameters": ["self", "pytester"], "calls": ["pytester.makepyfile", "pytester.runpytest", "result.assert_outcomes"], "code_location": {"file": "acceptance_test.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 366, "end_line": 377}, "code_snippet": "    def test_direct_addressing_selects_duplicates_1(self, pytester: Pytester) -> None:\n        p = pytester.makepyfile(\n            \"\"\"\n            import pytest\n\n            @pytest.mark.parametrize(\"a\", [1, 2, 10, 11, 2, 1, 12, 1_1,2_1])\n            def test_func(a):\n                pass\n            \"\"\"\n        )\n        result = pytester.runpytest(p)\n        result.assert_outcomes(failed=0, passed=9)\n", "type": "function"}, {"name": "test_parametrize_positional_args", "is_method": true, "class_name": "TestMarkersWithParametrization", "parameters": ["self", "pytester"], "calls": ["pytester.makepyfile", "pytester.runpytest", "result.assert_outcomes"], "code_location": {"file": "metafunc.py", "path": "/data3/pwh/swebench-repos/pytest/testing/python", "start_line": 2103, "end_line": 2114}, "code_snippet": "    def test_parametrize_positional_args(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n\n            @pytest.mark.parametrize(\"a\", [1], False)\n            def test_foo(a):\n                pass\n        \"\"\"\n        )\n        result = pytester.runpytest()\n        result.assert_outcomes(passed=1)\n", "type": "function"}, {"name": "test_two_functions", "is_method": true, "class_name": "TestMetafuncFunctional", "parameters": ["self", "pytester"], "calls": ["pytester.makepyfile", "pytester.runpytest", "result.stdout.fnmatch_lines"], "code_location": {"file": "metafunc.py", "path": "/data3/pwh/swebench-repos/pytest/testing/python", "start_line": 1158, "end_line": 1180}, "code_snippet": "    def test_two_functions(self, pytester: Pytester) -> None:\n        p = pytester.makepyfile(\n            \"\"\"\n            def pytest_generate_tests(metafunc):\n                metafunc.parametrize('arg1', [10, 20], ids=['0', '1'])\n\n            def test_func1(arg1):\n                assert arg1 == 10\n\n            def test_func2(arg1):\n                assert arg1 in (10, 20)\n        \"\"\"\n        )\n        result = pytester.runpytest(\"-v\", p)\n        result.stdout.fnmatch_lines(\n            [\n                \"*test_func1*0*PASS*\",\n                \"*test_func1*1*FAIL*\",\n                \"*test_func2*PASS*\",\n                \"*test_func2*PASS*\",\n                \"*1 failed, 3 passed*\",\n            ]\n        )\n", "type": "function"}, {"name": "test_simple_xfail_single_argname", "is_method": true, "class_name": "TestMarkersWithParametrization", "parameters": ["self", "pytester"], "calls": ["pytester.makepyfile", "pytester.inline_run", "reprec.assertoutcome"], "code_location": {"file": "metafunc.py", "path": "/data3/pwh/swebench-repos/pytest/testing/python", "start_line": 1909, "end_line": 1923}, "code_snippet": "    def test_simple_xfail_single_argname(self, pytester: Pytester) -> None:\n        s = \"\"\"\n            import pytest\n\n            @pytest.mark.parametrize(\"n\", [\n                2,\n                pytest.param(3, marks=pytest.mark.xfail),\n                4,\n            ])\n            def test_isEven(n):\n                assert n % 2 == 0\n        \"\"\"\n        pytester.makepyfile(s)\n        reprec = pytester.inline_run()\n        reprec.assertoutcome(passed=2, skipped=1)\n", "type": "function"}], "retrieved_count": 10, "cost_time": 1.2974181175231934}
{"question": "Why would repeated invocations of pytester.getitem() followed by evaluate_xfail_marks() impact test suite performance, and what internal caching mechanisms could mitigate redundant AST parsing and mark evaluation across multiple test evaluations?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"name": "test_marked_xfail_no_args", "is_method": true, "class_name": "TestEvaluation", "parameters": ["self", "pytester"], "calls": ["pytester.getitem", "evaluate_xfail_marks"], "code_location": {"file": "test_skipping.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 21, "end_line": 33}, "code_snippet": "    def test_marked_xfail_no_args(self, pytester: Pytester) -> None:\n        item = pytester.getitem(\n            \"\"\"\n            import pytest\n            @pytest.mark.xfail\n            def test_func():\n                pass\n        \"\"\"\n        )\n        xfailed = evaluate_xfail_marks(item)\n        assert xfailed\n        assert xfailed.reason == \"\"\n        assert xfailed.run\n", "type": "function"}, {"name": "test_xfail_markeval_namespace", "is_method": true, "class_name": "TestXFail", "parameters": ["self", "pytester"], "calls": ["pytester.makeconftest", "pytester.makepyfile", "pytester.runpytest", "res.stdout.fnmatch_lines", "res.stdout.fnmatch_lines"], "code_location": {"file": "test_skipping.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 710, "end_line": 735}, "code_snippet": "    def test_xfail_markeval_namespace(self, pytester: Pytester) -> None:\n        pytester.makeconftest(\n            \"\"\"\n            import pytest\n\n            def pytest_markeval_namespace():\n                return {\"color\": \"green\"}\n            \"\"\"\n        )\n        p = pytester.makepyfile(\n            \"\"\"\n            import pytest\n\n            @pytest.mark.xfail(\"color == 'green'\")\n            def test_1():\n                assert False\n\n            @pytest.mark.xfail(\"color == 'red'\")\n            def test_2():\n                assert False\n        \"\"\"\n        )\n        res = pytester.runpytest(p)\n        assert res.ret == 1\n        res.stdout.fnmatch_lines([\"*1 failed*\"])\n        res.stdout.fnmatch_lines([\"*1 xfailed*\"])\n", "type": "function"}, {"name": "test_xfail_evalfalse_but_fails", "is_method": true, "class_name": "TestXFail", "parameters": ["self", "pytester"], "calls": ["pytester.getitem", "runtestprotocol", "hasattr"], "code_location": {"file": "test_skipping.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 404, "end_line": 417}, "code_snippet": "    def test_xfail_evalfalse_but_fails(self, pytester: Pytester) -> None:\n        item = pytester.getitem(\n            \"\"\"\n            import pytest\n            @pytest.mark.xfail('False')\n            def test_func():\n                assert 0\n        \"\"\"\n        )\n        reports = runtestprotocol(item, log=False)\n        callreport = reports[1]\n        assert callreport.failed\n        assert not hasattr(callreport, \"wasxfail\")\n        assert \"xfail\" in callreport.keywords\n", "type": "function"}, {"name": "test_marked_one_arg_twice", "is_method": true, "class_name": "TestEvaluation", "parameters": ["self", "pytester"], "calls": ["range", "pytester.getitem", "evaluate_skip_marks"], "code_location": {"file": "test_skipping.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 74, "end_line": 91}, "code_snippet": "    def test_marked_one_arg_twice(self, pytester: Pytester) -> None:\n        lines = [\n            \"\"\"@pytest.mark.skipif(\"not hasattr(os, 'murks')\")\"\"\",\n            \"\"\"@pytest.mark.skipif(condition=\"hasattr(os, 'murks')\")\"\"\",\n        ]\n        for i in range(2):\n            item = pytester.getitem(\n                f\"\"\"\n                import pytest\n                {lines[i]}\n                {lines[(i + 1) % 2]}\n                def test_func():\n                    pass\n            \"\"\"\n            )\n            skipped = evaluate_skip_marks(item)\n            assert skipped\n            assert skipped.reason == \"condition: not hasattr(os, 'murks')\"\n", "type": "function"}, {"name": "pytest_runtest_setup", "is_method": false, "class_name": null, "parameters": ["item"], "calls": ["hookimpl", "evaluate_skip_marks", "evaluate_xfail_marks", "skip.Exception", "xfail"], "code_location": {"file": "skipping.py", "path": "/data3/pwh/swebench-repos/pytest/src/_pytest", "start_line": 243, "end_line": 250}, "code_snippet": "def pytest_runtest_setup(item: Item) -> None:\n    skipped = evaluate_skip_marks(item)\n    if skipped:\n        raise skip.Exception(skipped.reason, _use_item_location=True)\n\n    item.stash[xfailed_key] = xfailed = evaluate_xfail_marks(item)\n    if xfailed and not item.config.option.runxfail and not xfailed.run:\n        xfail(\"[NOTRUN] \" + xfailed.reason)\n", "type": "function"}, {"name": "test_xfail_not_considered_failure", "is_method": true, "class_name": "TestLastFailed", "parameters": ["self", "pytester"], "calls": ["pytester.makepyfile", "pytester.runpytest", "result.stdout.fnmatch_lines", "self.get_cached_last_failed"], "code_location": {"file": "test_cacheprovider.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 623, "end_line": 633}, "code_snippet": "    def test_xfail_not_considered_failure(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n            @pytest.mark.xfail\n            def test(): assert 0\n        \"\"\"\n        )\n        result = pytester.runpytest()\n        result.stdout.fnmatch_lines([\"*1 xfailed*\"])\n        assert self.get_cached_last_failed(pytester) == []\n", "type": "function"}, {"name": "test_xfail_strict_considered_failure", "is_method": true, "class_name": "TestLastFailed", "parameters": ["self", "pytester"], "calls": ["pytester.makepyfile", "pytester.runpytest", "result.stdout.fnmatch_lines", "self.get_cached_last_failed"], "code_location": {"file": "test_cacheprovider.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 635, "end_line": 647}, "code_snippet": "    def test_xfail_strict_considered_failure(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n            @pytest.mark.xfail(strict=True)\n            def test(): pass\n        \"\"\"\n        )\n        result = pytester.runpytest()\n        result.stdout.fnmatch_lines([\"*1 failed*\"])\n        assert self.get_cached_last_failed(pytester) == [\n            \"test_xfail_strict_considered_failure.py::test\"\n        ]\n", "type": "function"}, {"name": "test_failed_changed_to_xfail_or_skip", "is_method": true, "class_name": "TestLastFailed", "parameters": ["self", "pytester", "mark"], "calls": ["pytest.mark.parametrize", "pytester.makepyfile", "pytester.runpytest", "pytester.makepyfile", "pytester.runpytest", "self.get_cached_last_failed", "self.get_cached_last_failed"], "code_location": {"file": "test_cacheprovider.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 650, "end_line": 675}, "code_snippet": "    def test_failed_changed_to_xfail_or_skip(\n        self, pytester: Pytester, mark: str\n    ) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n            def test(): assert 0\n        \"\"\"\n        )\n        result = pytester.runpytest()\n        assert self.get_cached_last_failed(pytester) == [\n            \"test_failed_changed_to_xfail_or_skip.py::test\"\n        ]\n        assert result.ret == 1\n\n        pytester.makepyfile(\n            f\"\"\"\n            import pytest\n            @pytest.{mark}\n            def test(): assert 0\n        \"\"\"\n        )\n        result = pytester.runpytest()\n        assert result.ret == 0\n        assert self.get_cached_last_failed(pytester) == []\n        assert result.ret == 0\n", "type": "function"}, {"name": "test_marked_one_arg_twice2", "is_method": true, "class_name": "TestEvaluation", "parameters": ["self", "pytester"], "calls": ["pytester.getitem", "evaluate_skip_marks"], "code_location": {"file": "test_skipping.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 93, "end_line": 105}, "code_snippet": "    def test_marked_one_arg_twice2(self, pytester: Pytester) -> None:\n        item = pytester.getitem(\n            \"\"\"\n            import pytest\n            @pytest.mark.skipif(\"hasattr(os, 'murks')\")\n            @pytest.mark.skipif(\"not hasattr(os, 'murks')\")\n            def test_func():\n                pass\n        \"\"\"\n        )\n        skipped = evaluate_skip_marks(item)\n        assert skipped\n        assert skipped.reason == \"condition: not hasattr(os, 'murks')\"\n", "type": "function"}, {"name": "pytest_runtest_call", "is_method": false, "class_name": null, "parameters": ["item"], "calls": ["hookimpl", "item.stash.get", "evaluate_xfail_marks", "xfail", "item.stash.get", "evaluate_xfail_marks"], "code_location": {"file": "skipping.py", "path": "/data3/pwh/swebench-repos/pytest/src/_pytest", "start_line": 254, "end_line": 268}, "code_snippet": "def pytest_runtest_call(item: Item) -> Generator[None]:\n    xfailed = item.stash.get(xfailed_key, None)\n    if xfailed is None:\n        item.stash[xfailed_key] = xfailed = evaluate_xfail_marks(item)\n\n    if xfailed and not item.config.option.runxfail and not xfailed.run:\n        xfail(\"[NOTRUN] \" + xfailed.reason)\n\n    try:\n        return (yield)\n    finally:\n        # The test run may have added an xfail mark dynamically.\n        xfailed = item.stash.get(xfailed_key, None)\n        if xfailed is None:\n            item.stash[xfailed_key] = xfailed = evaluate_xfail_marks(item)\n", "type": "function"}], "retrieved_count": 10, "cost_time": 0.3345150947570801}
{"question": "Why does the test_parse_from_file method verify that the parser correctly handles file-based argument input through the @ prefix mechanism, and what is the purpose of storing test paths in an external file rather than passing them directly as command-line arguments?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"name": "test_parse_from_file", "is_method": true, "class_name": "TestParser", "parameters": ["self", "parser", "tmp_path"], "calls": ["pytest.mark.filterwarnings", "args_file.write_text", "parser.parse", "join", "getattr", "args_file.absolute"], "code_location": {"file": "test_parseopt.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 134, "end_line": 139}, "code_snippet": "    def test_parse_from_file(self, parser: parseopt.Parser, tmp_path: Path) -> None:\n        tests = [\".\", \"some.py::Test::test_method[param0]\", \"other/test_file.py\"]\n        args_file = tmp_path / \"tests.txt\"\n        args_file.write_text(\"\\n\".join(tests), encoding=\"utf-8\")\n        args = parser.parse([f\"@{args_file.absolute()}\"])\n        assert getattr(args, parseopt.FILE_OR_DIR) == tests\n", "type": "function"}, {"name": "test_command_line_args_from_file", "is_method": true, "class_name": "TestGeneralUsage", "parameters": ["self", "pytester", "tmp_path"], "calls": ["pytest.mark.filterwarnings", "pytester.makepyfile", "pytester.maketxtfile", "pytester.runpytest", "result.assert_outcomes", "join"], "code_location": {"file": "acceptance_test.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 554, "end_line": 574}, "code_snippet": "    def test_command_line_args_from_file(\n        self, pytester: Pytester, tmp_path: Path\n    ) -> None:\n        pytester.makepyfile(\n            test_file=\"\"\"\n            import pytest\n\n            class TestClass:\n                @pytest.mark.parametrize(\"a\", [\"x\",\"y\"])\n                def test_func(self, a):\n                    pass\n            \"\"\"\n        )\n        tests = [\n            \"test_file.py::TestClass::test_func[x]\",\n            \"test_file.py::TestClass::test_func[y]\",\n            \"-q\",\n        ]\n        args_file = pytester.maketxtfile(tests=\"\\n\".join(tests))\n        result = pytester.runpytest(f\"@{args_file}\")\n        result.assert_outcomes(failed=0, passed=2)\n", "type": "function"}, {"name": "test_parse2", "is_method": true, "class_name": "TestParser", "parameters": ["self", "parser"], "calls": ["parser.parse", "Path", "getattr"], "code_location": {"file": "test_parseopt.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 126, "end_line": 128}, "code_snippet": "    def test_parse2(self, parser: parseopt.Parser) -> None:\n        args = parser.parse([Path(\".\")])\n        assert getattr(args, parseopt.FILE_OR_DIR)[0] == \".\"\n", "type": "function"}, {"name": "test_args_source_testpaths", "is_method": true, "class_name": "TestParseIni", "parameters": ["self", "pytester"], "calls": ["pytester.makeini", "pytester.parseconfig"], "code_location": {"file": "test_config.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 545, "end_line": 553}, "code_snippet": "    def test_args_source_testpaths(self, pytester: Pytester):\n        pytester.makeini(\n            \"\"\"\n            [pytest]\n            testpaths=*\n        \"\"\"\n        )\n        config = pytester.parseconfig()\n        assert config.args_source == Config.ArgsSource.TESTPATHS\n", "type": "function"}, {"name": "test_args_source_args", "is_method": true, "class_name": "TestParseIni", "parameters": ["self", "pytester"], "calls": ["pytester.parseconfig"], "code_location": {"file": "test_config.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 537, "end_line": 539}, "code_snippet": "    def test_args_source_args(self, pytester: Pytester):\n        config = pytester.parseconfig(\"--\", \"test_filename.py\")\n        assert config.args_source == Config.ArgsSource.ARGS\n", "type": "function"}, {"name": "test_parse", "is_method": true, "class_name": "TestParser", "parameters": ["self", "parser"], "calls": ["parser.addoption", "parser.parse", "getattr"], "code_location": {"file": "test_parseopt.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 120, "end_line": 124}, "code_snippet": "    def test_parse(self, parser: parseopt.Parser) -> None:\n        parser.addoption(\"--hello\", dest=\"hello\", action=\"store\")\n        args = parser.parse([\"--hello\", \"world\"])\n        assert args.hello == \"world\"\n        assert not getattr(args, parseopt.FILE_OR_DIR)\n", "type": "function"}, {"name": "test_two_dirs", "is_method": false, "class_name": null, "parameters": ["pytester", "file_structure"], "calls": ["pytester.makefile", "pytester.runpytest", "result.assert_outcomes"], "code_location": {"file": "test_python_path.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 57, "end_line": 61}, "code_snippet": "def test_two_dirs(pytester: Pytester, file_structure) -> None:\n    pytester.makefile(\".ini\", pytest=\"[pytest]\\npythonpath=sub sub2\\n\")\n    result = pytester.runpytest(\"test_foo.py\", \"test_bar.py\")\n    assert result.ret == 0\n    result.assert_outcomes(passed=2)\n", "type": "function"}, {"name": "test_absolute_win32_path", "is_method": true, "class_name": "TestConfigCmdlineParsing", "parameters": ["self", "pytester"], "calls": ["pytester.makefile", "normpath", "pytest.main", "pytest.main", "str"], "code_location": {"file": "test_config.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 614, "end_line": 628}, "code_snippet": "    def test_absolute_win32_path(self, pytester: Pytester) -> None:\n        temp_ini_file = pytester.makefile(\n            \".ini\",\n            custom=\"\"\"\n            [pytest]\n            addopts = --version\n        \"\"\",\n        )\n        from os.path import normpath\n\n        temp_ini_file_norm = normpath(str(temp_ini_file))\n        ret = pytest.main([\"-c\", temp_ini_file_norm])\n        assert ret == ExitCode.OK\n        ret = pytest.main([\"--config-file\", temp_ini_file_norm])\n        assert ret == ExitCode.OK\n", "type": "function"}, {"name": "test_parse_known_args", "is_method": true, "class_name": "TestParser", "parameters": ["self", "parser"], "calls": ["parser.parse_known_args", "parser.addoption", "parser.parse_known_args", "Path"], "code_location": {"file": "test_parseopt.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 141, "end_line": 146}, "code_snippet": "    def test_parse_known_args(self, parser: parseopt.Parser) -> None:\n        parser.parse_known_args([Path(\".\")])\n        parser.addoption(\"--hello\", action=\"store_true\")\n        ns = parser.parse_known_args([\"x\", \"--y\", \"--hello\", \"this\"])\n        assert ns.hello\n        assert ns.file_or_dir == [\"x\"]\n", "type": "function"}, {"name": "test_args_source_invocation_dir", "is_method": true, "class_name": "TestParseIni", "parameters": ["self", "pytester"], "calls": ["pytester.parseconfig"], "code_location": {"file": "test_config.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 541, "end_line": 543}, "code_snippet": "    def test_args_source_invocation_dir(self, pytester: Pytester):\n        config = pytester.parseconfig()\n        assert config.args_source == Config.ArgsSource.INVOCATION_DIR\n", "type": "function"}], "retrieved_count": 10, "cost_time": 0.3358941078186035}
{"question": "Why does the ensure_deletable function's resilience mechanism prevent cascading failures when both lock file removal and file status checks fail simultaneously in a concurrent directory cleanup scenario?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"name": "test_suppress_error_removing_lock", "is_method": false, "class_name": null, "parameters": ["tmp_path"], "calls": ["path.mkdir", "get_lock_path", "lock.touch", "lock.is_file", "lock.is_file", "ensure_deletable", "lock.stat", "unittest.mock.patch.object", "unittest.mock.patch.object", "lock.is_file", "ensure_deletable", "ensure_deletable"], "code_location": {"file": "test_pathlib.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 496, "end_line": 520}, "code_snippet": "def test_suppress_error_removing_lock(tmp_path: Path) -> None:\n    \"\"\"ensure_deletable should be resilient if lock file cannot be removed (#5456, #7491)\"\"\"\n    path = tmp_path / \"dir\"\n    path.mkdir()\n    lock = get_lock_path(path)\n    lock.touch()\n    mtime = lock.stat().st_mtime\n\n    with unittest.mock.patch.object(Path, \"unlink\", side_effect=OSError) as m:\n        assert not ensure_deletable(\n            path, consider_lock_dead_if_created_before=mtime + 30\n        )\n        assert m.call_count == 1\n    assert lock.is_file()\n\n    with unittest.mock.patch.object(Path, \"is_file\", side_effect=OSError) as m:\n        assert not ensure_deletable(\n            path, consider_lock_dead_if_created_before=mtime + 30\n        )\n        assert m.call_count == 1\n    assert lock.is_file()\n\n    # check now that we can remove the lock file in normal circumstances\n    assert ensure_deletable(path, consider_lock_dead_if_created_before=mtime + 30)\n    assert not lock.is_file()\n", "type": "function"}, {"name": "test_cleanup_locked", "is_method": true, "class_name": "TestNumberedDir", "parameters": ["self", "tmp_path"], "calls": ["make_numbered_dir", "create_cleanup_lock", "pathlib.ensure_deletable", "pathlib.ensure_deletable", "p.stat", "p.stat"], "code_location": {"file": "test_tmpdir.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 435, "end_line": 445}, "code_snippet": "    def test_cleanup_locked(self, tmp_path):\n        p = make_numbered_dir(root=tmp_path, prefix=self.PREFIX)\n\n        create_cleanup_lock(p)\n\n        assert not pathlib.ensure_deletable(\n            p, consider_lock_dead_if_created_before=p.stat().st_mtime - 1\n        )\n        assert pathlib.ensure_deletable(\n            p, consider_lock_dead_if_created_before=p.stat().st_mtime + 1\n        )\n", "type": "function"}, {"name": "try_cleanup", "is_method": false, "class_name": null, "parameters": ["path", "consider_lock_dead_if_created_before"], "calls": ["ensure_deletable", "maybe_delete_a_numbered_dir"], "code_location": {"file": "pathlib.py", "path": "/data3/pwh/swebench-repos/pytest/src/_pytest", "start_line": 338, "end_line": 341}, "code_snippet": "def try_cleanup(path: Path, consider_lock_dead_if_created_before: float) -> None:\n    \"\"\"Try to cleanup a folder if we can ensure it's deletable.\"\"\"\n    if ensure_deletable(path, consider_lock_dead_if_created_before):\n        maybe_delete_a_numbered_dir(path)\n", "type": "function"}, {"name": "test_removal_accepts_lock", "is_method": true, "class_name": "TestNumberedDir", "parameters": ["self", "tmp_path"], "calls": ["make_numbered_dir", "create_cleanup_lock", "maybe_delete_a_numbered_dir", "folder.is_dir"], "code_location": {"file": "test_tmpdir.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 452, "end_line": 456}, "code_snippet": "    def test_removal_accepts_lock(self, tmp_path):\n        folder = make_numbered_dir(root=tmp_path, prefix=self.PREFIX)\n        create_cleanup_lock(folder)\n        maybe_delete_a_numbered_dir(folder)\n        assert folder.is_dir()\n", "type": "function"}, {"name": "ensure_deletable", "is_method": false, "class_name": null, "parameters": ["path", "consider_lock_dead_if_created_before"], "calls": ["path.is_symlink", "get_lock_path", "lock.is_file", "lock.stat", "contextlib.suppress", "lock.unlink"], "code_location": {"file": "pathlib.py", "path": "/data3/pwh/swebench-repos/pytest/src/_pytest", "start_line": 310, "end_line": 335}, "code_snippet": "def ensure_deletable(path: Path, consider_lock_dead_if_created_before: float) -> bool:\n    \"\"\"Check if `path` is deletable based on whether the lock file is expired.\"\"\"\n    if path.is_symlink():\n        return False\n    lock = get_lock_path(path)\n    try:\n        if not lock.is_file():\n            return True\n    except OSError:\n        # we might not have access to the lock file at all, in this case assume\n        # we don't have access to the entire directory (#7491).\n        return False\n    try:\n        lock_time = lock.stat().st_mtime\n    except Exception:\n        return False\n    else:\n        if lock_time < consider_lock_dead_if_created_before:\n            # We want to ignore any errors while trying to remove the lock such as:\n            # - PermissionDenied, like the file permissions have changed since the lock creation;\n            # - FileNotFoundError, in case another pytest process got here first;\n            # and any other cause of failure.\n            with contextlib.suppress(OSError):\n                lock.unlink()\n                return True\n        return False\n", "type": "function"}, {"name": "test_access_denied_during_cleanup", "is_method": false, "class_name": null, "parameters": ["tmp_path", "monkeypatch"], "calls": ["path.mkdir", "monkeypatch.setattr", "get_lock_path", "maybe_delete_a_numbered_dir", "OSError", "lock_path.is_file"], "code_location": {"file": "test_pathlib.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 458, "end_line": 470}, "code_snippet": "def test_access_denied_during_cleanup(tmp_path: Path, monkeypatch: MonkeyPatch) -> None:\n    \"\"\"Ensure that deleting a numbered dir does not fail because of OSErrors (#4262).\"\"\"\n    path = tmp_path / \"temp-1\"\n    path.mkdir()\n\n    def renamed_failed(*args):\n        raise OSError(\"access denied\")\n\n    monkeypatch.setattr(Path, \"rename\", renamed_failed)\n\n    lock_path = get_lock_path(path)\n    maybe_delete_a_numbered_dir(path)\n    assert not lock_path.is_file()\n", "type": "function"}, {"name": "maybe_delete_a_numbered_dir", "is_method": false, "class_name": null, "parameters": ["path"], "calls": ["ensure_extended_length_path", "create_cleanup_lock", "parent.joinpath", "path.rename", "rm_rf", "lock_path.unlink", "uuid.uuid4"], "code_location": {"file": "pathlib.py", "path": "/data3/pwh/swebench-repos/pytest/src/_pytest", "start_line": 282, "end_line": 307}, "code_snippet": "def maybe_delete_a_numbered_dir(path: Path) -> None:\n    \"\"\"Remove a numbered directory if its lock can be obtained and it does\n    not seem to be in use.\"\"\"\n    path = ensure_extended_length_path(path)\n    lock_path = None\n    try:\n        lock_path = create_cleanup_lock(path)\n        parent = path.parent\n\n        garbage = parent.joinpath(f\"garbage-{uuid.uuid4()}\")\n        path.rename(garbage)\n        rm_rf(garbage)\n    except OSError:\n        #  known races:\n        #  * other process did a cleanup at the same time\n        #  * deletable folder was found\n        #  * process cwd (Windows)\n        return\n    finally:\n        # If we created the lock, ensure we remove it even if we failed\n        # to properly remove the numbered dir.\n        if lock_path is not None:\n            try:\n                lock_path.unlink()\n            except OSError:\n                pass\n", "type": "function"}, {"name": "test_cleanup_lock_create", "is_method": true, "class_name": "TestNumberedDir", "parameters": ["self", "tmp_path"], "calls": ["tmp_path.joinpath", "d.mkdir", "create_cleanup_lock", "lockfile.unlink", "pytest.raises", "create_cleanup_lock"], "code_location": {"file": "test_tmpdir.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 385, "end_line": 392}, "code_snippet": "    def test_cleanup_lock_create(self, tmp_path):\n        d = tmp_path.joinpath(\"test\")\n        d.mkdir()\n        lockfile = create_cleanup_lock(d)\n        with pytest.raises(OSError, match=\"cannot create lockfile in .*\"):\n            create_cleanup_lock(d)\n\n        lockfile.unlink()\n", "type": "function"}, {"name": "test_rm_rf_with_read_only_file", "is_method": true, "class_name": "TestRmRf", "parameters": ["self", "tmp_path"], "calls": ["fn.parent.mkdir", "fn.touch", "self.chmod_r", "rm_rf", "fn.parent.is_dir"], "code_location": {"file": "test_tmpdir.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 474, "end_line": 485}, "code_snippet": "    def test_rm_rf_with_read_only_file(self, tmp_path):\n        \"\"\"Ensure rm_rf can remove directories with read-only files in them (#5524)\"\"\"\n        fn = tmp_path / \"dir/foo.txt\"\n        fn.parent.mkdir()\n\n        fn.touch()\n\n        self.chmod_r(fn)\n\n        rm_rf(fn.parent)\n\n        assert not fn.parent.is_dir()\n", "type": "function"}, {"name": "test_on_rm_rf_error", "is_method": true, "class_name": "TestRmRf", "parameters": ["self", "tmp_path"], "calls": ["adir.mkdir", "fn.touch", "self.chmod_r", "PermissionError", "on_rm_rf_error", "pytest.warns", "on_rm_rf_error", "fn.is_file", "FileNotFoundError", "on_rm_rf_error", "pytest.warns", "on_rm_rf_error", "fn.is_file", "warnings.catch_warnings", "PermissionError", "on_rm_rf_error", "fn.is_file", "str", "fn.is_file", "RuntimeError", "str", "str", "PermissionError", "str", "str"], "code_location": {"file": "test_tmpdir.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 503, "end_line": 539}, "code_snippet": "    def test_on_rm_rf_error(self, tmp_path: Path) -> None:\n        adir = tmp_path / \"dir\"\n        adir.mkdir()\n\n        fn = adir / \"foo.txt\"\n        fn.touch()\n        self.chmod_r(fn)\n\n        # unknown exception\n        with pytest.warns(pytest.PytestWarning):\n            exc_info1 = (RuntimeError, RuntimeError(), None)\n            on_rm_rf_error(os.unlink, str(fn), exc_info1, start_path=tmp_path)\n            assert fn.is_file()\n\n        # we ignore FileNotFoundError\n        exc_info2 = (FileNotFoundError, FileNotFoundError(), None)\n        assert not on_rm_rf_error(None, str(fn), exc_info2, start_path=tmp_path)\n\n        # unknown function\n        with pytest.warns(\n            pytest.PytestWarning,\n            match=r\"^\\(rm_rf\\) unknown function None when removing .*foo.txt:\\n<class 'PermissionError'>: \",\n        ):\n            exc_info3 = (PermissionError, PermissionError(), None)\n            on_rm_rf_error(None, str(fn), exc_info3, start_path=tmp_path)\n            assert fn.is_file()\n\n        # ignored function\n        with warnings.catch_warnings(record=True) as w:\n            exc_info4 = PermissionError()\n            on_rm_rf_error(os.open, str(fn), exc_info4, start_path=tmp_path)\n            assert fn.is_file()\n            assert not [x.message for x in w]\n\n        exc_info5 = PermissionError()\n        on_rm_rf_error(os.unlink, str(fn), exc_info5, start_path=tmp_path)\n        assert not fn.is_file()\n", "type": "function"}], "retrieved_count": 10, "cost_time": 0.33576059341430664}
{"question": "Why does the SysCapture class maintain consistency between its captured buffer state and the original system stream when snap() and writeorg() operations are interleaved during test execution?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"name": "test_writeorg", "is_method": true, "class_name": "TestFDCapture", "parameters": ["self", "tmpfile"], "calls": ["capture.FDCapture", "cap.start", "tmpfile.write", "tmpfile.flush", "cap.writeorg", "cap.snap", "cap.done", "tmpfile.fileno", "data2.decode", "data1.decode", "open", "stmp_file.read"], "code_location": {"file": "test_capture.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 1047, "end_line": 1059}, "code_snippet": "    def test_writeorg(self, tmpfile: BinaryIO) -> None:\n        data1, data2 = b\"foo\", b\"bar\"\n        cap = capture.FDCapture(tmpfile.fileno())\n        cap.start()\n        tmpfile.write(data1)\n        tmpfile.flush()\n        cap.writeorg(data2.decode(\"ascii\"))\n        scap = cap.snap()\n        cap.done()\n        assert scap == data1.decode(\"ascii\")\n        with open(tmpfile.name, \"rb\") as stmp_file:\n            stmp = stmp_file.read()\n            assert stmp == data2\n", "type": "function"}, {"name": "snap", "is_method": true, "class_name": "SysCapture", "parameters": ["self"], "calls": ["self._assert_state", "isinstance", "self.tmpfile.getvalue", "self.tmpfile.seek", "self.tmpfile.truncate"], "code_location": {"file": "capture.py", "path": "/data3/pwh/swebench-repos/pytest/src/_pytest", "start_line": 450, "end_line": 456}, "code_snippet": "    def snap(self) -> str:\n        self._assert_state(\"snap\", (\"started\", \"suspended\"))\n        assert isinstance(self.tmpfile, CaptureIO)\n        res = self.tmpfile.getvalue()\n        self.tmpfile.seek(0)\n        self.tmpfile.truncate()\n        return res\n", "type": "function"}, {"name": "test_capturing_modify_sysouterr_in_between", "is_method": true, "class_name": "TestStdCapture", "parameters": ["self"], "calls": ["self.getcapture", "sys.stdout.write", "sys.stderr.write", "capture.CaptureIO", "capture.CaptureIO", "print", "sys.stderr.write", "cap.readouterr"], "code_location": {"file": "test_capture.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 1167, "end_line": 1181}, "code_snippet": "    def test_capturing_modify_sysouterr_in_between(self) -> None:\n        oldout = sys.stdout\n        olderr = sys.stderr\n        with self.getcapture() as cap:\n            sys.stdout.write(\"hello\")\n            sys.stderr.write(\"world\")\n            sys.stdout = capture.CaptureIO()\n            sys.stderr = capture.CaptureIO()\n            print(\"not seen\")\n            sys.stderr.write(\"not seen\\n\")\n            out, err = cap.readouterr()\n        assert out == \"hello\"\n        assert err == \"world\"\n        assert sys.stdout == oldout\n        assert sys.stderr == olderr\n", "type": "function"}, {"name": "test_simple_resume_suspend", "is_method": true, "class_name": "TestFDCapture", "parameters": ["self"], "calls": ["saved_fd", "capture.FDCapture", "cap.start", "os.write", "sys.stdout.write", "cap.snap", "cap.suspend", "os.write", "sys.stdout.write", "cap.resume", "os.write", "sys.stdout.write", "cap.snap", "cap.suspend", "cap.done", "pytest.raises", "isinstance", "cap.snap", "repr", "repr"], "code_location": {"file": "test_capture.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 1061, "end_line": 1090}, "code_snippet": "    def test_simple_resume_suspend(self) -> None:\n        with saved_fd(1):\n            cap = capture.FDCapture(1)\n            cap.start()\n            data = b\"hello\"\n            os.write(1, data)\n            sys.stdout.write(\"whatever\")\n            s = cap.snap()\n            assert s == \"hellowhatever\"\n            cap.suspend()\n            os.write(1, b\"world\")\n            sys.stdout.write(\"qlwkej\")\n            assert not cap.snap()\n            cap.resume()\n            os.write(1, b\"but now\")\n            sys.stdout.write(\" yes\\n\")\n            s = cap.snap()\n            assert s == \"but now yes\\n\"\n            cap.suspend()\n            cap.done()\n            pytest.raises(AssertionError, cap.suspend)\n\n            assert repr(cap) == (\n                f\"<FDCapture 1 oldfd={cap.targetfd_save} _state='done' tmpfile={cap.tmpfile!r}>\"\n            )\n            # Should not crash with missing \"_old\".\n            assert isinstance(cap.syscapture, capture.SysCapture)\n            assert repr(cap.syscapture) == (\n                f\"<SysCapture stdout _old=<UNSET> _state='done' tmpfile={cap.syscapture.tmpfile!r}>\"\n            )\n", "type": "function"}, {"name": "test_intermingling", "is_method": true, "class_name": "TestStdCaptureFD", "parameters": ["self"], "calls": ["self.getcapture", "os.write", "sys.stdout.write", "sys.stdout.flush", "os.write", "os.write", "sys.stderr.write", "sys.stderr.flush", "os.write", "cap.readouterr", "str"], "code_location": {"file": "test_capture.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 1261, "end_line": 1273}, "code_snippet": "    def test_intermingling(self):\n        with self.getcapture() as cap:\n            os.write(1, b\"1\")\n            sys.stdout.write(str(2))\n            sys.stdout.flush()\n            os.write(1, b\"3\")\n            os.write(2, b\"a\")\n            sys.stderr.write(\"b\")\n            sys.stderr.flush()\n            os.write(2, b\"c\")\n            out, err = cap.readouterr()\n        assert out == \"123\"\n        assert err == \"abc\"\n", "type": "function"}, {"name": "test_stdin_restored", "is_method": true, "class_name": "TestStdCapture", "parameters": ["self"], "calls": ["self.getcapture"], "code_location": {"file": "test_capture.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 1209, "end_line": 1214}, "code_snippet": "    def test_stdin_restored(self) -> None:\n        old = sys.stdin\n        with self.getcapture(in_=True):\n            newstdin = sys.stdin\n        assert newstdin != sys.stdin\n        assert sys.stdin is old\n", "type": "function"}, {"name": "writeorg", "is_method": true, "class_name": "SysCapture", "parameters": ["self", "data"], "calls": ["self._assert_state", "self._old.write", "self._old.flush"], "code_location": {"file": "capture.py", "path": "/data3/pwh/swebench-repos/pytest/src/_pytest", "start_line": 458, "end_line": 461}, "code_snippet": "    def writeorg(self, data: str) -> None:\n        self._assert_state(\"writeorg\", (\"started\", \"suspended\"))\n        self._old.write(data)\n        self._old.flush()\n", "type": "function"}, {"name": "test_fdcapture_invalid_fd_with_fd_reuse", "is_method": true, "class_name": "TestStdCaptureFDinvalidFD", "parameters": ["self", "pytester"], "calls": ["saved_fd", "os.close", "capture.FDCaptureBinary", "cap.start", "os.write", "cap.suspend", "os.write", "cap.resume", "os.write", "cap.done", "cap.snap", "pytest.raises", "os.write"], "code_location": {"file": "test_capture.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 1327, "end_line": 1340}, "code_snippet": "    def test_fdcapture_invalid_fd_with_fd_reuse(self, pytester: Pytester) -> None:\n        with saved_fd(1):\n            os.close(1)\n            cap = capture.FDCaptureBinary(1)\n            cap.start()\n            os.write(1, b\"started\")\n            cap.suspend()\n            os.write(1, b\" suspended\")\n            cap.resume()\n            os.write(1, b\" resumed\")\n            assert cap.snap() == b\"started resumed\"\n            cap.done()\n            with pytest.raises(OSError):\n                os.write(1, b\"done\")\n", "type": "function"}, {"name": "writeorg", "is_method": true, "class_name": "SysCaptureBinary", "parameters": ["self", "data"], "calls": ["self._assert_state", "self._old.flush", "self._old.buffer.write", "self._old.buffer.flush"], "code_location": {"file": "capture.py", "path": "/data3/pwh/swebench-repos/pytest/src/_pytest", "start_line": 440, "end_line": 444}, "code_snippet": "    def writeorg(self, data: bytes) -> None:\n        self._assert_state(\"writeorg\", (\"started\", \"suspended\"))\n        self._old.flush()\n        self._old.buffer.write(data)\n        self._old.buffer.flush()\n", "type": "function"}, {"name": "test_fdcapture_invalid_fd_without_fd_reuse", "is_method": true, "class_name": "TestStdCaptureFDinvalidFD", "parameters": ["self", "pytester"], "calls": ["saved_fd", "saved_fd", "os.close", "os.close", "capture.FDCaptureBinary", "cap.start", "os.write", "cap.suspend", "os.write", "cap.resume", "os.write", "cap.done", "cap.snap", "pytest.raises", "os.write"], "code_location": {"file": "test_capture.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 1342, "end_line": 1356}, "code_snippet": "    def test_fdcapture_invalid_fd_without_fd_reuse(self, pytester: Pytester) -> None:\n        with saved_fd(1), saved_fd(2):\n            os.close(1)\n            os.close(2)\n            cap = capture.FDCaptureBinary(2)\n            cap.start()\n            os.write(2, b\"started\")\n            cap.suspend()\n            os.write(2, b\" suspended\")\n            cap.resume()\n            os.write(2, b\" resumed\")\n            assert cap.snap() == b\"started resumed\"\n            cap.done()\n            with pytest.raises(OSError):\n                os.write(2, b\"done\")\n", "type": "function"}], "retrieved_count": 10, "cost_time": 0.3448193073272705}
{"question": "Where is the precise file location and line range where the DataclassWithOneItem class is defined, and how does its definition relate to the module structure of the pytest testing infrastructure?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"name": "test_dataclasses", "is_method": true, "class_name": "TestAssert_reprcompare_dataclass", "parameters": ["self", "pytester"], "calls": ["pytester.copy_example", "pytester.runpytest", "result.assert_outcomes", "result.stdout.fnmatch_lines"], "code_location": {"file": "test_assertion.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 966, "end_line": 982}, "code_snippet": "    def test_dataclasses(self, pytester: Pytester) -> None:\n        p = pytester.copy_example(\"dataclasses/test_compare_dataclasses.py\")\n        result = pytester.runpytest(p)\n        result.assert_outcomes(failed=1, passed=0)\n        result.stdout.fnmatch_lines(\n            [\n                \"E         Omitting 1 identical items, use -vv to show\",\n                \"E         Differing attributes:\",\n                \"E         ['field_b']\",\n                \"E         \",\n                \"E         Drill down into differing attribute field_b:\",\n                \"E           field_b: 'b' != 'c'\",\n                \"E           - c\",\n                \"E           + b\",\n            ],\n            consecutive=True,\n        )\n", "type": "function"}, {"name": "test_data_classes_with_initvar", "is_method": true, "class_name": "TestAssert_reprcompare_dataclass", "parameters": ["self", "pytester"], "calls": ["pytester.copy_example", "pytester.runpytest", "result.assert_outcomes", "result.stdout.no_re_match_line"], "code_location": {"file": "test_assertion.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 1070, "end_line": 1075}, "code_snippet": "    def test_data_classes_with_initvar(self, pytester: Pytester) -> None:\n        p = pytester.copy_example(\"dataclasses/test_compare_initvar.py\")\n        # issue 9820\n        result = pytester.runpytest(p, \"-vv\")\n        result.assert_outcomes(failed=1, passed=0)\n        result.stdout.no_re_match_line(\".*AttributeError.*\")\n", "type": "function"}, {"name": "test_data_classes_with_custom_eq", "is_method": true, "class_name": "TestAssert_reprcompare_dataclass", "parameters": ["self", "pytester"], "calls": ["pytester.copy_example", "pytester.runpytest", "result.assert_outcomes", "result.stdout.no_re_match_line"], "code_location": {"file": "test_assertion.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 1061, "end_line": 1068}, "code_snippet": "    def test_data_classes_with_custom_eq(self, pytester: Pytester) -> None:\n        p = pytester.copy_example(\n            \"dataclasses/test_compare_dataclasses_with_custom_eq.py\"\n        )\n        # issue 9362\n        result = pytester.runpytest(p, \"-vv\")\n        result.assert_outcomes(failed=1, passed=0)\n        result.stdout.no_re_match_line(\".*Differing attributes.*\")\n", "type": "function"}, {"name": "test_example_items1", "is_method": true, "class_name": "Test_genitems", "parameters": ["self", "pytester"], "calls": ["pytester.makepyfile", "pytester.inline_genitems", "getmodpath", "s.endswith", "print", "len", "getmodpath", "getmodpath", "getmodpath", "getmodpath"], "code_location": {"file": "test_collection.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 743, "end_line": 777}, "code_snippet": "    def test_example_items1(self, pytester: Pytester) -> None:\n        p = pytester.makepyfile(\n            \"\"\"\n            import pytest\n\n            def testone():\n                pass\n\n            class TestX(object):\n                def testmethod_one(self):\n                    pass\n\n            class TestY(TestX):\n                @pytest.mark.parametrize(\"arg0\", [\".[\"])\n                def testmethod_two(self, arg0):\n                    pass\n        \"\"\"\n        )\n        items, reprec = pytester.inline_genitems(p)\n        assert len(items) == 4\n        assert items[0].name == \"testone\"\n        assert items[1].name == \"testmethod_one\"\n        assert items[2].name == \"testmethod_one\"\n        assert items[3].name == \"testmethod_two[.[]\"\n\n        # let's also test getmodpath here\n        assert items[0].getmodpath() == \"testone\"  # type: ignore[attr-defined]\n        assert items[1].getmodpath() == \"TestX.testmethod_one\"  # type: ignore[attr-defined]\n        assert items[2].getmodpath() == \"TestY.testmethod_one\"  # type: ignore[attr-defined]\n        # PR #6202: Fix incorrect result of getmodpath method. (Resolves issue #6189)\n        assert items[3].getmodpath() == \"TestY.testmethod_two[.[]\"  # type: ignore[attr-defined]\n\n        s = items[0].getmodpath(stopatmodule=False)  # type: ignore[attr-defined]\n        assert s.endswith(\"test_example_items1.testone\")\n        print(s)\n", "type": "function"}, {"name": "test_comparing_two_different_data_classes", "is_method": true, "class_name": "TestAssert_reprcompare_dataclass", "parameters": ["self", "pytester"], "calls": ["pytester.copy_example", "pytester.runpytest", "result.assert_outcomes"], "code_location": {"file": "test_assertion.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 1054, "end_line": 1059}, "code_snippet": "    def test_comparing_two_different_data_classes(self, pytester: Pytester) -> None:\n        p = pytester.copy_example(\n            \"dataclasses/test_compare_two_different_dataclasses.py\"\n        )\n        result = pytester.runpytest(p, \"-vv\")\n        result.assert_outcomes(failed=0, passed=1)\n", "type": "function"}, {"name": "test_dataclasses_verbose", "is_method": true, "class_name": "TestAssert_reprcompare_dataclass", "parameters": ["self", "pytester"], "calls": ["pytester.copy_example", "pytester.runpytest", "result.assert_outcomes", "result.stdout.fnmatch_lines"], "code_location": {"file": "test_assertion.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 1032, "end_line": 1043}, "code_snippet": "    def test_dataclasses_verbose(self, pytester: Pytester) -> None:\n        p = pytester.copy_example(\"dataclasses/test_compare_dataclasses_verbose.py\")\n        result = pytester.runpytest(p, \"-vv\")\n        result.assert_outcomes(failed=1, passed=0)\n        result.stdout.fnmatch_lines(\n            [\n                \"*Matching attributes:*\",\n                \"*['field_a']*\",\n                \"*Differing attributes:*\",\n                \"*field_b: 'b' != 'c'*\",\n            ]\n        )\n", "type": "function"}, {"name": "test_class_reportinfo", "is_method": true, "class_name": "TestReportInfo", "parameters": ["self", "pytester"], "calls": ["pytester.getmodulecol", "pytester.collect_by_name", "isinstance", "classcol.reportinfo", "os.fspath", "str"], "code_location": {"file": "collect.py", "path": "/data3/pwh/swebench-repos/pytest/testing/python", "start_line": 1237, "end_line": 1250}, "code_snippet": "    def test_class_reportinfo(self, pytester: Pytester) -> None:\n        modcol = pytester.getmodulecol(\n            \"\"\"\n            # lineno 0\n            class TestClass(object):\n                def test_hello(self): pass\n        \"\"\"\n        )\n        classcol = pytester.collect_by_name(modcol, \"TestClass\")\n        assert isinstance(classcol, Class)\n        path, lineno, msg = classcol.reportinfo()\n        assert os.fspath(path) == str(modcol.path)\n        assert lineno == 1\n        assert msg == \"TestClass\"\n", "type": "function"}, {"name": "test_recursive_dataclasses", "is_method": true, "class_name": "TestAssert_reprcompare_dataclass", "parameters": ["self", "pytester"], "calls": ["pytester.copy_example", "pytester.runpytest", "result.assert_outcomes", "result.stdout.fnmatch_lines"], "code_location": {"file": "test_assertion.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 984, "end_line": 1000}, "code_snippet": "    def test_recursive_dataclasses(self, pytester: Pytester) -> None:\n        p = pytester.copy_example(\"dataclasses/test_compare_recursive_dataclasses.py\")\n        result = pytester.runpytest(p)\n        result.assert_outcomes(failed=1, passed=0)\n        result.stdout.fnmatch_lines(\n            [\n                \"E         Omitting 1 identical items, use -vv to show\",\n                \"E         Differing attributes:\",\n                \"E         ['g', 'h', 'j']\",\n                \"E         \",\n                \"E         Drill down into differing attribute g:\",\n                \"E           g: S(a=10, b='ten') != S(a=20, b='xxx')...\",\n                \"E         \",\n                \"E         ...Full output truncated (51 lines hidden), use '-vv' to show\",\n            ],\n            consecutive=True,\n        )\n", "type": "function"}, {"name": "TestAssert_reprcompare_dataclass", "docstring": "", "methods": ["test_dataclasses", "test_recursive_dataclasses", "test_recursive_dataclasses_verbose", "test_dataclasses_verbose", "test_dataclasses_with_attribute_comparison_off", "test_comparing_two_different_data_classes", "test_data_classes_with_custom_eq", "test_data_classes_with_initvar"], "attributes": [], "code_location": {"file": "test_assertion.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 965, "end_line": 1075}, "type": "class"}, {"name": "test_dataclasses_with_attribute_comparison_off", "is_method": true, "class_name": "TestAssert_reprcompare_dataclass", "parameters": ["self", "pytester"], "calls": ["pytester.copy_example", "pytester.runpytest", "result.assert_outcomes"], "code_location": {"file": "test_assertion.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 1045, "end_line": 1052}, "code_snippet": "    def test_dataclasses_with_attribute_comparison_off(\n        self, pytester: Pytester\n    ) -> None:\n        p = pytester.copy_example(\n            \"dataclasses/test_compare_dataclasses_field_comparison_off.py\"\n        )\n        result = pytester.runpytest(p, \"-vv\")\n        result.assert_outcomes(failed=0, passed=1)\n", "type": "function"}], "retrieved_count": 10, "cost_time": 0.34004783630371094}
{"question": "Where does the data flow of marker information propagate from the autouse fixture in test_accessmarker_dynamic through the request object to multiple test functions, and what control flow mechanism ensures that dynamically applied markers via applymarker are visible to all dependent tests in the same scope?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"name": "test_accessmarker_dynamic", "is_method": true, "class_name": "TestRequestMarking", "parameters": ["self", "pytester"], "calls": ["pytester.makeconftest", "pytester.makepyfile", "pytester.inline_run", "reprec.assertoutcome"], "code_location": {"file": "fixtures.py", "path": "/data3/pwh/swebench-repos/pytest/testing/python", "start_line": 1193, "end_line": 1218}, "code_snippet": "    def test_accessmarker_dynamic(self, pytester: Pytester) -> None:\n        pytester.makeconftest(\n            \"\"\"\n            import pytest\n            @pytest.fixture()\n            def keywords(request):\n                return request.keywords\n\n            @pytest.fixture(scope=\"class\", autouse=True)\n            def marking(request):\n                request.applymarker(pytest.mark.XYZ(\"hello\"))\n        \"\"\"\n        )\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n            def test_fun1(keywords):\n                assert keywords[\"XYZ\"] is not None\n                assert \"abc\" not in keywords\n            def test_fun2(keywords):\n                assert keywords[\"XYZ\"] is not None\n                assert \"abc\" not in keywords\n        \"\"\"\n        )\n        reprec = pytester.inline_run()\n        reprec.assertoutcome(passed=2)\n", "type": "function"}, {"name": "test_dynamic_xfail_set_during_funcarg_setup", "is_method": true, "class_name": "TestXFail", "parameters": ["self", "pytester"], "calls": ["pytester.makepyfile", "pytester.runpytest", "result.stdout.fnmatch_lines"], "code_location": {"file": "test_skipping.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 551, "end_line": 563}, "code_snippet": "    def test_dynamic_xfail_set_during_funcarg_setup(self, pytester: Pytester) -> None:\n        p = pytester.makepyfile(\n            \"\"\"\n            import pytest\n            @pytest.fixture\n            def arg(request):\n                request.applymarker(pytest.mark.xfail)\n            def test_this2(arg):\n                assert 0\n        \"\"\"\n        )\n        result = pytester.runpytest(p)\n        result.stdout.fnmatch_lines([\"*1 xfailed*\"])\n", "type": "function"}, {"name": "test_applymarker", "is_method": true, "class_name": "TestRequestMarking", "parameters": ["self", "pytester"], "calls": ["pytester.getitems", "isinstance", "TopRequest", "req1.applymarker", "req1.applymarker", "pytest.raises", "req1.applymarker"], "code_location": {"file": "fixtures.py", "path": "/data3/pwh/swebench-repos/pytest/testing/python", "start_line": 1151, "end_line": 1175}, "code_snippet": "    def test_applymarker(self, pytester: Pytester) -> None:\n        item1, item2 = pytester.getitems(\n            \"\"\"\n            import pytest\n\n            @pytest.fixture\n            def something(request):\n                pass\n            class TestClass(object):\n                def test_func1(self, something):\n                    pass\n                def test_func2(self, something):\n                    pass\n        \"\"\"\n        )\n        assert isinstance(item1, Function)\n        req1 = TopRequest(item1, _ispytest=True)\n        assert \"xfail\" not in item1.keywords\n        req1.applymarker(pytest.mark.xfail)\n        assert \"xfail\" in item1.keywords\n        assert \"skipif\" not in item1.keywords\n        req1.applymarker(pytest.mark.skipif)\n        assert \"skipif\" in item1.keywords\n        with pytest.raises(ValueError):\n            req1.applymarker(42)  # type: ignore[arg-type]\n", "type": "function"}, {"name": "test_mark_dynamically_in_funcarg", "is_method": true, "class_name": "TestFunctional", "parameters": ["self", "pytester"], "calls": ["pytester.makeconftest", "pytester.makepyfile", "pytester.runpytest", "result.stdout.fnmatch_lines"], "code_location": {"file": "test_mark.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 657, "end_line": 676}, "code_snippet": "    def test_mark_dynamically_in_funcarg(self, pytester: Pytester) -> None:\n        pytester.makeconftest(\n            \"\"\"\n            import pytest\n            @pytest.fixture\n            def arg(request):\n                request.applymarker(pytest.mark.hello)\n            def pytest_terminal_summary(terminalreporter):\n                values = terminalreporter.stats['passed']\n                terminalreporter._tw.line(\"keyword: %s\" % values[0].keywords)\n        \"\"\"\n        )\n        pytester.makepyfile(\n            \"\"\"\n            def test_func(arg):\n                pass\n        \"\"\"\n        )\n        result = pytester.runpytest()\n        result.stdout.fnmatch_lines([\"keyword: *hello*\"])\n", "type": "function"}, {"name": "test_dynamic_xfail_no_run", "is_method": true, "class_name": "TestXFail", "parameters": ["self", "pytester"], "calls": ["pytester.makepyfile", "pytester.runpytest", "result.stdout.fnmatch_lines"], "code_location": {"file": "test_skipping.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 537, "end_line": 549}, "code_snippet": "    def test_dynamic_xfail_no_run(self, pytester: Pytester) -> None:\n        p = pytester.makepyfile(\n            \"\"\"\n            import pytest\n            @pytest.fixture\n            def arg(request):\n                request.applymarker(pytest.mark.xfail(run=False))\n            def test_this(arg):\n                assert 0\n        \"\"\"\n        )\n        result = pytester.runpytest(p, \"-rxX\")\n        result.stdout.fnmatch_lines([\"*XFAIL*test_this*NOTRUN*\"])\n", "type": "function"}, {"name": "test_usefixtures_marker", "is_method": true, "class_name": "TestFixtureUsages", "parameters": ["self", "pytester"], "calls": ["pytester.makepyfile", "pytester.inline_run", "reprec.assertoutcome"], "code_location": {"file": "fixtures.py", "path": "/data3/pwh/swebench-repos/pytest/testing/python", "start_line": 1429, "end_line": 1452}, "code_snippet": "    def test_usefixtures_marker(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n\n            values = []\n\n            @pytest.fixture(scope=\"class\")\n            def myfix(request):\n                request.cls.hello = \"world\"\n                values.append(1)\n\n            class TestClass(object):\n                def test_one(self):\n                    assert self.hello == \"world\"\n                    assert len(values) == 1\n                def test_two(self):\n                    assert self.hello == \"world\"\n                    assert len(values) == 1\n            pytest.mark.usefixtures(\"myfix\")(TestClass)\n        \"\"\"\n        )\n        reprec = pytester.inline_run()\n        reprec.assertoutcome(passed=2)\n", "type": "function"}, {"name": "test_usefixtures_seen_in_showmarkers", "is_method": true, "class_name": "TestFixtureUsages", "parameters": ["self", "pytester"], "calls": ["pytester.runpytest", "result.stdout.fnmatch_lines"], "code_location": {"file": "fixtures.py", "path": "/data3/pwh/swebench-repos/pytest/testing/python", "start_line": 1500, "end_line": 1506}, "code_snippet": "    def test_usefixtures_seen_in_showmarkers(self, pytester: Pytester) -> None:\n        result = pytester.runpytest(\"--markers\")\n        result.stdout.fnmatch_lines(\n            \"\"\"\n            *usefixtures(fixturename1*mark tests*fixtures*\n        \"\"\"\n        )\n", "type": "function"}, {"name": "test_dynamic_fixture_request", "is_method": false, "class_name": null, "parameters": ["pytester"], "calls": ["pytester.makepyfile", "pytester.runpytest", "result.stdout.fnmatch_lines"], "code_location": {"file": "test_setuponly.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 214, "end_line": 237}, "code_snippet": "def test_dynamic_fixture_request(pytester: Pytester) -> None:\n    p = pytester.makepyfile(\n        \"\"\"\n        import pytest\n        @pytest.fixture()\n        def dynamically_requested_fixture():\n            pass\n        @pytest.fixture()\n        def dependent_fixture(request):\n            request.getfixturevalue('dynamically_requested_fixture')\n        def test_dyn(dependent_fixture):\n            pass\n    \"\"\"\n    )\n\n    result = pytester.runpytest(\"--setup-only\", p)\n    assert result.ret == 0\n\n    result.stdout.fnmatch_lines(\n        [\n            \"*SETUP    F dynamically_requested_fixture\",\n            \"*TEARDOWN F dynamically_requested_fixture\",\n        ]\n    )\n", "type": "function"}, {"name": "test", "is_method": false, "class_name": null, "parameters": ["b", "request"], "calls": [], "code_location": {"file": "test_getfixturevalue_dynamic.py", "path": "/data3/pwh/swebench-repos/pytest/testing/example_scripts/fixtures", "start_line": 22, "end_line": 23}, "code_snippet": "def test(b, request):\n    assert request.fixturenames == [\"b\", \"request\", \"a\", \"dynamic\"]\n", "type": "function"}, {"name": "a", "is_method": false, "class_name": null, "parameters": ["request"], "calls": ["request.getfixturevalue"], "code_location": {"file": "test_getfixturevalue_dynamic.py", "path": "/data3/pwh/swebench-repos/pytest/testing/example_scripts/fixtures", "start_line": 13, "end_line": 14}, "code_snippet": "def a(request):\n    request.getfixturevalue(\"dynamic\")\n", "type": "function"}], "retrieved_count": 10, "cost_time": 0.3410637378692627}
{"question": "Where does the `_marked_for_rewrite_cache` dictionary control the data flow through `_is_marked_for_rewrite` to prevent redundant module rewrite decisions across multiple import attempts?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"name": "_is_marked_for_rewrite", "is_method": true, "class_name": "AssertionRewritingHook", "parameters": ["self", "name", "state"], "calls": ["name.startswith", "state.trace"], "code_location": {"file": "rewrite.py", "path": "/data3/pwh/swebench-repos/pytest/src/_pytest/assertion", "start_line": 248, "end_line": 259}, "code_snippet": "    def _is_marked_for_rewrite(self, name: str, state: AssertionState) -> bool:\n        try:\n            return self._marked_for_rewrite_cache[name]\n        except KeyError:\n            for marked in self._must_rewrite:\n                if name == marked or name.startswith(marked + \".\"):\n                    state.trace(f\"matched marked file {name!r} (from {marked!r})\")\n                    self._marked_for_rewrite_cache[name] = True\n                    return True\n\n            self._marked_for_rewrite_cache[name] = False\n            return False\n", "type": "function"}, {"name": "mark_rewrite", "is_method": true, "class_name": "AssertionRewritingHook", "parameters": ["self"], "calls": ["difference", "self._must_rewrite.update", "self._marked_for_rewrite_cache.clear", "intersection", "self._warn_already_imported", "AssertionRewriter.is_rewrite_disabled", "isinstance", "set", "type"], "code_location": {"file": "rewrite.py", "path": "/data3/pwh/swebench-repos/pytest/src/_pytest/assertion", "start_line": 261, "end_line": 277}, "code_snippet": "    def mark_rewrite(self, *names: str) -> None:\n        \"\"\"Mark import names as needing to be rewritten.\n\n        The named module or package as well as any nested modules will\n        be rewritten on import.\n        \"\"\"\n        already_imported = (\n            set(names).intersection(sys.modules).difference(self._rewritten_names)\n        )\n        for name in already_imported:\n            mod = sys.modules[name]\n            if not AssertionRewriter.is_rewrite_disabled(\n                mod.__doc__ or \"\"\n            ) and not isinstance(mod.__loader__, type(self)):\n                self._warn_already_imported(name)\n        self._must_rewrite.update(names)\n        self._marked_for_rewrite_cache.clear()\n", "type": "function"}, {"name": "test_rewrite_warning", "is_method": true, "class_name": "TestRewriteOnImport", "parameters": ["self", "pytester"], "calls": ["pytester.makeconftest", "pytester.runpytest_subprocess", "result.stdout.fnmatch_lines"], "code_location": {"file": "test_assertrewrite.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 1191, "end_line": 1200}, "code_snippet": "    def test_rewrite_warning(self, pytester: Pytester) -> None:\n        pytester.makeconftest(\n            \"\"\"\n            import pytest\n            pytest.register_assert_rewrite(\"_pytest\")\n        \"\"\"\n        )\n        # needs to be a subprocess because pytester explicitly disables this warning\n        result = pytester.runpytest_subprocess()\n        result.stdout.fnmatch_lines([\"*Module already imported*; _pytest\"])\n", "type": "function"}, {"name": "_early_rewrite_bailout", "is_method": true, "class_name": "AssertionRewritingHook", "parameters": ["self", "name", "state"], "calls": ["name.split", "with_suffix", "self._is_marked_for_rewrite", "state.trace", "os.path.dirname", "fnmatch_ex", "split", "self._basenames_to_check_rewrite.add", "PurePath", "str", "os.path.splitext"], "code_location": {"file": "rewrite.py", "path": "/data3/pwh/swebench-repos/pytest/src/_pytest/assertion", "start_line": 188, "end_line": 225}, "code_snippet": "    def _early_rewrite_bailout(self, name: str, state: AssertionState) -> bool:\n        \"\"\"A fast way to get out of rewriting modules.\n\n        Profiling has shown that the call to PathFinder.find_spec (inside of\n        the find_spec from this class) is a major slowdown, so, this method\n        tries to filter what we're sure won't be rewritten before getting to\n        it.\n        \"\"\"\n        if self.session is not None and not self._session_paths_checked:\n            self._session_paths_checked = True\n            for initial_path in self.session._initialpaths:\n                # Make something as c:/projects/my_project/path.py ->\n                #     ['c:', 'projects', 'my_project', 'path.py']\n                parts = str(initial_path).split(os.sep)\n                # add 'path' to basenames to be checked.\n                self._basenames_to_check_rewrite.add(os.path.splitext(parts[-1])[0])\n\n        # Note: conftest already by default in _basenames_to_check_rewrite.\n        parts = name.split(\".\")\n        if parts[-1] in self._basenames_to_check_rewrite:\n            return False\n\n        # For matching the name it must be as if it was a filename.\n        path = PurePath(*parts).with_suffix(\".py\")\n\n        for pat in self.fnpats:\n            # if the pattern contains subdirectories (\"tests/**.py\" for example) we can't bail out based\n            # on the name alone because we need to match against the full path\n            if os.path.dirname(pat):\n                return False\n            if fnmatch_ex(pat, path):\n                return False\n\n        if self._is_marked_for_rewrite(name, state):\n            return False\n\n        state.trace(f\"early skip of rewriting module: {name}\")\n        return True\n", "type": "function"}, {"name": "_should_rewrite", "is_method": true, "class_name": "AssertionRewritingHook", "parameters": ["self", "name", "fn", "state"], "calls": ["PurePath", "self._is_marked_for_rewrite", "os.path.basename", "state.trace", "self.session.isinitpath", "fnmatch_ex", "absolutepath", "state.trace", "state.trace"], "code_location": {"file": "rewrite.py", "path": "/data3/pwh/swebench-repos/pytest/src/_pytest/assertion", "start_line": 227, "end_line": 246}, "code_snippet": "    def _should_rewrite(self, name: str, fn: str, state: AssertionState) -> bool:\n        # always rewrite conftest files\n        if os.path.basename(fn) == \"conftest.py\":\n            state.trace(f\"rewriting conftest file: {fn!r}\")\n            return True\n\n        if self.session is not None:\n            if self.session.isinitpath(absolutepath(fn)):\n                state.trace(f\"matched test file (was specified on cmdline): {fn!r}\")\n                return True\n\n        # modules not passed explicitly on the command line are only\n        # rewritten if they match the naming convention for test files\n        fn_path = PurePath(fn)\n        for pat in self.fnpats:\n            if fnmatch_ex(pat, fn_path):\n                state.trace(f\"matched test file {fn!r}\")\n                return True\n\n        return self._is_marked_for_rewrite(name, state)\n", "type": "function"}, {"name": "test_rewrite_module_imported_from_conftest", "is_method": true, "class_name": "TestRewriteOnImport", "parameters": ["self", "pytester"], "calls": ["pytester.makeconftest", "pytester.makepyfile", "pytester.runpytest_subprocess"], "code_location": {"file": "test_assertrewrite.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 1218, "end_line": 1230}, "code_snippet": "    def test_rewrite_module_imported_from_conftest(self, pytester: Pytester) -> None:\n        pytester.makeconftest(\n            \"\"\"\n            import test_rewrite_module_imported\n        \"\"\"\n        )\n        pytester.makepyfile(\n            test_rewrite_module_imported=\"\"\"\n            def test_rewritten():\n                assert \"@py_builtins\" in globals()\n        \"\"\"\n        )\n        assert pytester.runpytest_subprocess().ret == 0\n", "type": "function"}, {"name": "_warn_already_imported", "is_method": true, "class_name": "AssertionRewritingHook", "parameters": ["self", "name"], "calls": ["self.config.issue_config_time_warning", "PytestAssertRewriteWarning"], "code_location": {"file": "rewrite.py", "path": "/data3/pwh/swebench-repos/pytest/src/_pytest/assertion", "start_line": 279, "end_line": 287}, "code_snippet": "    def _warn_already_imported(self, name: str) -> None:\n        from _pytest.warning_types import PytestAssertRewriteWarning\n\n        self.config.issue_config_time_warning(\n            PytestAssertRewriteWarning(\n                f\"Module already imported so cannot be rewritten; {name}\"\n            ),\n            stacklevel=5,\n        )\n", "type": "function"}, {"name": "find_spec", "is_method": true, "class_name": "AssertionRewritingHook", "parameters": ["self", "name", "path", "target"], "calls": ["self._early_rewrite_bailout", "state.trace", "self._find_spec", "importlib.util.spec_from_file_location", "self._should_rewrite", "importlib.util.spec_from_file_location", "isinstance", "os.path.exists"], "code_location": {"file": "rewrite.py", "path": "/data3/pwh/swebench-repos/pytest/src/_pytest/assertion", "start_line": 91, "end_line": 139}, "code_snippet": "    def find_spec(\n        self,\n        name: str,\n        path: Sequence[str | bytes] | None = None,\n        target: types.ModuleType | None = None,\n    ) -> importlib.machinery.ModuleSpec | None:\n        if self._writing_pyc:\n            return None\n        state = self.config.stash[assertstate_key]\n        if self._early_rewrite_bailout(name, state):\n            return None\n        state.trace(f\"find_module called for: {name}\")\n\n        # Type ignored because mypy is confused about the `self` binding here.\n        spec = self._find_spec(name, path)  # type: ignore\n\n        if spec is None and path is not None:\n            # With --import-mode=importlib, PathFinder cannot find spec without modifying `sys.path`,\n            # causing inability to assert rewriting (#12659).\n            # At this point, try using the file path to find the module spec.\n            for _path_str in path:\n                spec = importlib.util.spec_from_file_location(name, _path_str)\n                if spec is not None:\n                    break\n\n        if (\n            # the import machinery could not find a file to import\n            spec is None\n            # this is a namespace package (without `__init__.py`)\n            # there's nothing to rewrite there\n            or spec.origin is None\n            # we can only rewrite source files\n            or not isinstance(spec.loader, importlib.machinery.SourceFileLoader)\n            # if the file doesn't exist, we can't rewrite it\n            or not os.path.exists(spec.origin)\n        ):\n            return None\n        else:\n            fn = spec.origin\n\n        if not self._should_rewrite(name, fn, state):\n            return None\n\n        return importlib.util.spec_from_file_location(\n            name,\n            fn,\n            loader=self,\n            submodule_search_locations=spec.submodule_search_locations,\n        )\n", "type": "function"}, {"name": "exec_module", "is_method": true, "class_name": "AssertionRewritingHook", "parameters": ["self", "module"], "calls": ["Path", "get_cache_dir", "_read_pyc", "exec", "try_makedirs", "state.trace", "_rewrite_test", "state.trace", "state.trace", "_write_pyc"], "code_location": {"file": "rewrite.py", "path": "/data3/pwh/swebench-repos/pytest/src/_pytest/assertion", "start_line": 146, "end_line": 186}, "code_snippet": "    def exec_module(self, module: types.ModuleType) -> None:\n        assert module.__spec__ is not None\n        assert module.__spec__.origin is not None\n        fn = Path(module.__spec__.origin)\n        state = self.config.stash[assertstate_key]\n\n        self._rewritten_names[module.__name__] = fn\n\n        # The requested module looks like a test file, so rewrite it. This is\n        # the most magical part of the process: load the source, rewrite the\n        # asserts, and load the rewritten source. We also cache the rewritten\n        # module code in a special pyc. We must be aware of the possibility of\n        # concurrent pytest processes rewriting and loading pycs. To avoid\n        # tricky race conditions, we maintain the following invariant: The\n        # cached pyc is always a complete, valid pyc. Operations on it must be\n        # atomic. POSIX's atomic rename comes in handy.\n        write = not sys.dont_write_bytecode\n        cache_dir = get_cache_dir(fn)\n        if write:\n            ok = try_makedirs(cache_dir)\n            if not ok:\n                write = False\n                state.trace(f\"read only directory: {cache_dir}\")\n\n        cache_name = fn.name[:-3] + PYC_TAIL\n        pyc = cache_dir / cache_name\n        # Notice that even if we're in a read-only directory, I'm going\n        # to check for a cached pyc. This may not be optimal...\n        co = _read_pyc(fn, pyc, state.trace)\n        if co is None:\n            state.trace(f\"rewriting {fn!r}\")\n            source_stat, co = _rewrite_test(fn, self.config)\n            if write:\n                self._writing_pyc = True\n                try:\n                    _write_pyc(state, co, source_stat, pyc)\n                finally:\n                    self._writing_pyc = False\n        else:\n            state.trace(f\"found cached rewritten pyc for {fn}\")\n        exec(co, module.__dict__)\n", "type": "function"}, {"name": "test_basic", "is_method": true, "class_name": "TestEarlyRewriteBailout", "parameters": ["self", "pytester", "hook"], "calls": ["pytester.makeconftest", "pytester.makepyfile", "pytester.makepyfile", "pytester.makepyfile", "self.initial_paths.add", "hook.find_spec", "hook.find_spec", "hook.find_spec", "hook.find_spec"], "code_location": {"file": "test_assertrewrite.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 1922, "end_line": 1953}, "code_snippet": "    def test_basic(self, pytester: Pytester, hook: AssertionRewritingHook) -> None:\n        \"\"\"\n        Ensure we avoid calling PathFinder.find_spec when we know for sure a certain\n        module will not be rewritten to optimize assertion rewriting (#3918).\n        \"\"\"\n        pytester.makeconftest(\n            \"\"\"\n            import pytest\n            @pytest.fixture\n            def fix(): return 1\n        \"\"\"\n        )\n        pytester.makepyfile(test_foo=\"def test_foo(): pass\")\n        pytester.makepyfile(bar=\"def bar(): pass\")\n        foobar_path = pytester.makepyfile(foobar=\"def foobar(): pass\")\n        self.initial_paths.add(foobar_path)\n\n        # conftest files should always be rewritten\n        assert hook.find_spec(\"conftest\") is not None\n        assert self.find_spec_calls == [\"conftest\"]\n\n        # files matching \"python_files\" mask should always be rewritten\n        assert hook.find_spec(\"test_foo\") is not None\n        assert self.find_spec_calls == [\"conftest\", \"test_foo\"]\n\n        # file does not match \"python_files\": early bailout\n        assert hook.find_spec(\"bar\") is None\n        assert self.find_spec_calls == [\"conftest\", \"test_foo\"]\n\n        # file is an initial path (passed on the command-line): should be rewritten\n        assert hook.find_spec(\"foobar\") is not None\n        assert self.find_spec_calls == [\"conftest\", \"test_foo\", \"foobar\"]\n", "type": "function"}], "retrieved_count": 10, "cost_time": 0.3431107997894287}
{"question": "Where does the data flow from `_early_rewrite_bailout` through `_basenames_to_check_rewrite` state mutation determine whether `find_spec` will invoke expensive filesystem operations?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"name": "_early_rewrite_bailout", "is_method": true, "class_name": "AssertionRewritingHook", "parameters": ["self", "name", "state"], "calls": ["name.split", "with_suffix", "self._is_marked_for_rewrite", "state.trace", "os.path.dirname", "fnmatch_ex", "split", "self._basenames_to_check_rewrite.add", "PurePath", "str", "os.path.splitext"], "code_location": {"file": "rewrite.py", "path": "/data3/pwh/swebench-repos/pytest/src/_pytest/assertion", "start_line": 188, "end_line": 225}, "code_snippet": "    def _early_rewrite_bailout(self, name: str, state: AssertionState) -> bool:\n        \"\"\"A fast way to get out of rewriting modules.\n\n        Profiling has shown that the call to PathFinder.find_spec (inside of\n        the find_spec from this class) is a major slowdown, so, this method\n        tries to filter what we're sure won't be rewritten before getting to\n        it.\n        \"\"\"\n        if self.session is not None and not self._session_paths_checked:\n            self._session_paths_checked = True\n            for initial_path in self.session._initialpaths:\n                # Make something as c:/projects/my_project/path.py ->\n                #     ['c:', 'projects', 'my_project', 'path.py']\n                parts = str(initial_path).split(os.sep)\n                # add 'path' to basenames to be checked.\n                self._basenames_to_check_rewrite.add(os.path.splitext(parts[-1])[0])\n\n        # Note: conftest already by default in _basenames_to_check_rewrite.\n        parts = name.split(\".\")\n        if parts[-1] in self._basenames_to_check_rewrite:\n            return False\n\n        # For matching the name it must be as if it was a filename.\n        path = PurePath(*parts).with_suffix(\".py\")\n\n        for pat in self.fnpats:\n            # if the pattern contains subdirectories (\"tests/**.py\" for example) we can't bail out based\n            # on the name alone because we need to match against the full path\n            if os.path.dirname(pat):\n                return False\n            if fnmatch_ex(pat, path):\n                return False\n\n        if self._is_marked_for_rewrite(name, state):\n            return False\n\n        state.trace(f\"early skip of rewriting module: {name}\")\n        return True\n", "type": "function"}, {"name": "find_spec", "is_method": true, "class_name": "AssertionRewritingHook", "parameters": ["self", "name", "path", "target"], "calls": ["self._early_rewrite_bailout", "state.trace", "self._find_spec", "importlib.util.spec_from_file_location", "self._should_rewrite", "importlib.util.spec_from_file_location", "isinstance", "os.path.exists"], "code_location": {"file": "rewrite.py", "path": "/data3/pwh/swebench-repos/pytest/src/_pytest/assertion", "start_line": 91, "end_line": 139}, "code_snippet": "    def find_spec(\n        self,\n        name: str,\n        path: Sequence[str | bytes] | None = None,\n        target: types.ModuleType | None = None,\n    ) -> importlib.machinery.ModuleSpec | None:\n        if self._writing_pyc:\n            return None\n        state = self.config.stash[assertstate_key]\n        if self._early_rewrite_bailout(name, state):\n            return None\n        state.trace(f\"find_module called for: {name}\")\n\n        # Type ignored because mypy is confused about the `self` binding here.\n        spec = self._find_spec(name, path)  # type: ignore\n\n        if spec is None and path is not None:\n            # With --import-mode=importlib, PathFinder cannot find spec without modifying `sys.path`,\n            # causing inability to assert rewriting (#12659).\n            # At this point, try using the file path to find the module spec.\n            for _path_str in path:\n                spec = importlib.util.spec_from_file_location(name, _path_str)\n                if spec is not None:\n                    break\n\n        if (\n            # the import machinery could not find a file to import\n            spec is None\n            # this is a namespace package (without `__init__.py`)\n            # there's nothing to rewrite there\n            or spec.origin is None\n            # we can only rewrite source files\n            or not isinstance(spec.loader, importlib.machinery.SourceFileLoader)\n            # if the file doesn't exist, we can't rewrite it\n            or not os.path.exists(spec.origin)\n        ):\n            return None\n        else:\n            fn = spec.origin\n\n        if not self._should_rewrite(name, fn, state):\n            return None\n\n        return importlib.util.spec_from_file_location(\n            name,\n            fn,\n            loader=self,\n            submodule_search_locations=spec.submodule_search_locations,\n        )\n", "type": "function"}, {"name": "test_basic", "is_method": true, "class_name": "TestEarlyRewriteBailout", "parameters": ["self", "pytester", "hook"], "calls": ["pytester.makeconftest", "pytester.makepyfile", "pytester.makepyfile", "pytester.makepyfile", "self.initial_paths.add", "hook.find_spec", "hook.find_spec", "hook.find_spec", "hook.find_spec"], "code_location": {"file": "test_assertrewrite.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 1922, "end_line": 1953}, "code_snippet": "    def test_basic(self, pytester: Pytester, hook: AssertionRewritingHook) -> None:\n        \"\"\"\n        Ensure we avoid calling PathFinder.find_spec when we know for sure a certain\n        module will not be rewritten to optimize assertion rewriting (#3918).\n        \"\"\"\n        pytester.makeconftest(\n            \"\"\"\n            import pytest\n            @pytest.fixture\n            def fix(): return 1\n        \"\"\"\n        )\n        pytester.makepyfile(test_foo=\"def test_foo(): pass\")\n        pytester.makepyfile(bar=\"def bar(): pass\")\n        foobar_path = pytester.makepyfile(foobar=\"def foobar(): pass\")\n        self.initial_paths.add(foobar_path)\n\n        # conftest files should always be rewritten\n        assert hook.find_spec(\"conftest\") is not None\n        assert self.find_spec_calls == [\"conftest\"]\n\n        # files matching \"python_files\" mask should always be rewritten\n        assert hook.find_spec(\"test_foo\") is not None\n        assert self.find_spec_calls == [\"conftest\", \"test_foo\"]\n\n        # file does not match \"python_files\": early bailout\n        assert hook.find_spec(\"bar\") is None\n        assert self.find_spec_calls == [\"conftest\", \"test_foo\"]\n\n        # file is an initial path (passed on the command-line): should be rewritten\n        assert hook.find_spec(\"foobar\") is not None\n        assert self.find_spec_calls == [\"conftest\", \"test_foo\", \"foobar\"]\n", "type": "function"}, {"name": "_is_marked_for_rewrite", "is_method": true, "class_name": "AssertionRewritingHook", "parameters": ["self", "name", "state"], "calls": ["name.startswith", "state.trace"], "code_location": {"file": "rewrite.py", "path": "/data3/pwh/swebench-repos/pytest/src/_pytest/assertion", "start_line": 248, "end_line": 259}, "code_snippet": "    def _is_marked_for_rewrite(self, name: str, state: AssertionState) -> bool:\n        try:\n            return self._marked_for_rewrite_cache[name]\n        except KeyError:\n            for marked in self._must_rewrite:\n                if name == marked or name.startswith(marked + \".\"):\n                    state.trace(f\"matched marked file {name!r} (from {marked!r})\")\n                    self._marked_for_rewrite_cache[name] = True\n                    return True\n\n            self._marked_for_rewrite_cache[name] = False\n            return False\n", "type": "function"}, {"name": "_should_rewrite", "is_method": true, "class_name": "AssertionRewritingHook", "parameters": ["self", "name", "fn", "state"], "calls": ["PurePath", "self._is_marked_for_rewrite", "os.path.basename", "state.trace", "self.session.isinitpath", "fnmatch_ex", "absolutepath", "state.trace", "state.trace"], "code_location": {"file": "rewrite.py", "path": "/data3/pwh/swebench-repos/pytest/src/_pytest/assertion", "start_line": 227, "end_line": 246}, "code_snippet": "    def _should_rewrite(self, name: str, fn: str, state: AssertionState) -> bool:\n        # always rewrite conftest files\n        if os.path.basename(fn) == \"conftest.py\":\n            state.trace(f\"rewriting conftest file: {fn!r}\")\n            return True\n\n        if self.session is not None:\n            if self.session.isinitpath(absolutepath(fn)):\n                state.trace(f\"matched test file (was specified on cmdline): {fn!r}\")\n                return True\n\n        # modules not passed explicitly on the command line are only\n        # rewritten if they match the naming convention for test files\n        fn_path = PurePath(fn)\n        for pat in self.fnpats:\n            if fnmatch_ex(pat, fn_path):\n                state.trace(f\"matched test file {fn!r}\")\n                return True\n\n        return self._is_marked_for_rewrite(name, state)\n", "type": "function"}, {"name": "test_pattern_contains_subdirectories", "is_method": true, "class_name": "TestEarlyRewriteBailout", "parameters": ["self", "pytester", "hook"], "calls": ["pytester.makepyfile", "pytester.syspathinsert", "mock.patch.object", "hook.find_spec"], "code_location": {"file": "test_assertrewrite.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 1955, "end_line": 1972}, "code_snippet": "    def test_pattern_contains_subdirectories(\n        self, pytester: Pytester, hook: AssertionRewritingHook\n    ) -> None:\n        \"\"\"If one of the python_files patterns contain subdirectories (\"tests/**.py\") we can't bailout early\n        because we need to match with the full path, which can only be found by calling PathFinder.find_spec\n        \"\"\"\n        pytester.makepyfile(\n            **{\n                \"tests/file.py\": \"\"\"\\\n                    def test_simple_failure():\n                        assert 1 + 1 == 3\n                \"\"\"\n            }\n        )\n        pytester.syspathinsert(\"tests\")\n        with mock.patch.object(hook, \"fnpats\", [\"tests/**.py\"]):\n            assert hook.find_spec(\"file\") is not None\n            assert self.find_spec_calls == [\"file\"]\n", "type": "function"}, {"name": "test_pytest_plugins_rewrite_module_names_correctly", "is_method": true, "class_name": "TestImportHookInstallation", "parameters": ["self", "pytester"], "calls": ["pytester.makepyfile", "pytester.runpytest_subprocess"], "code_location": {"file": "test_assertion.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 200, "end_line": 218}, "code_snippet": "    def test_pytest_plugins_rewrite_module_names_correctly(\n        self, pytester: Pytester\n    ) -> None:\n        \"\"\"Test that we match files correctly when they are marked for rewriting (#2939).\"\"\"\n        contents = {\n            \"conftest.py\": \"\"\"\\\n                pytest_plugins = \"ham\"\n            \"\"\",\n            \"ham.py\": \"\",\n            \"hamster.py\": \"\",\n            \"test_foo.py\": \"\"\"\\\n                def test_foo(pytestconfig):\n                    assert pytestconfig.pluginmanager.rewrite_hook.find_spec('ham') is not None\n                    assert pytestconfig.pluginmanager.rewrite_hook.find_spec('hamster') is None\n            \"\"\",\n        }\n        pytester.makepyfile(**contents)\n        result = pytester.runpytest_subprocess(\"--assert=rewrite\")\n        assert result.ret == 0\n", "type": "function"}, {"name": "test_pycache_is_a_file", "is_method": true, "class_name": "TestRewriteOnImport", "parameters": ["self", "pytester"], "calls": ["write_text", "pytester.makepyfile", "pytester.path.joinpath", "pytester.runpytest"], "code_location": {"file": "test_assertrewrite.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 997, "end_line": 1004}, "code_snippet": "    def test_pycache_is_a_file(self, pytester: Pytester) -> None:\n        pytester.path.joinpath(\"__pycache__\").write_text(\"Hello\", encoding=\"utf-8\")\n        pytester.makepyfile(\n            \"\"\"\n            def test_rewritten():\n                assert \"@py_builtins\" in globals()\"\"\"\n        )\n        assert pytester.runpytest().ret == 0\n", "type": "function"}, {"name": "exec_module", "is_method": true, "class_name": "AssertionRewritingHook", "parameters": ["self", "module"], "calls": ["Path", "get_cache_dir", "_read_pyc", "exec", "try_makedirs", "state.trace", "_rewrite_test", "state.trace", "state.trace", "_write_pyc"], "code_location": {"file": "rewrite.py", "path": "/data3/pwh/swebench-repos/pytest/src/_pytest/assertion", "start_line": 146, "end_line": 186}, "code_snippet": "    def exec_module(self, module: types.ModuleType) -> None:\n        assert module.__spec__ is not None\n        assert module.__spec__.origin is not None\n        fn = Path(module.__spec__.origin)\n        state = self.config.stash[assertstate_key]\n\n        self._rewritten_names[module.__name__] = fn\n\n        # The requested module looks like a test file, so rewrite it. This is\n        # the most magical part of the process: load the source, rewrite the\n        # asserts, and load the rewritten source. We also cache the rewritten\n        # module code in a special pyc. We must be aware of the possibility of\n        # concurrent pytest processes rewriting and loading pycs. To avoid\n        # tricky race conditions, we maintain the following invariant: The\n        # cached pyc is always a complete, valid pyc. Operations on it must be\n        # atomic. POSIX's atomic rename comes in handy.\n        write = not sys.dont_write_bytecode\n        cache_dir = get_cache_dir(fn)\n        if write:\n            ok = try_makedirs(cache_dir)\n            if not ok:\n                write = False\n                state.trace(f\"read only directory: {cache_dir}\")\n\n        cache_name = fn.name[:-3] + PYC_TAIL\n        pyc = cache_dir / cache_name\n        # Notice that even if we're in a read-only directory, I'm going\n        # to check for a cached pyc. This may not be optimal...\n        co = _read_pyc(fn, pyc, state.trace)\n        if co is None:\n            state.trace(f\"rewriting {fn!r}\")\n            source_stat, co = _rewrite_test(fn, self.config)\n            if write:\n                self._writing_pyc = True\n                try:\n                    _write_pyc(state, co, source_stat, pyc)\n                finally:\n                    self._writing_pyc = False\n        else:\n            state.trace(f\"found cached rewritten pyc for {fn}\")\n        exec(co, module.__dict__)\n", "type": "function"}, {"name": "test_rewrite_module_imported_from_conftest", "is_method": true, "class_name": "TestRewriteOnImport", "parameters": ["self", "pytester"], "calls": ["pytester.makeconftest", "pytester.makepyfile", "pytester.runpytest_subprocess"], "code_location": {"file": "test_assertrewrite.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 1218, "end_line": 1230}, "code_snippet": "    def test_rewrite_module_imported_from_conftest(self, pytester: Pytester) -> None:\n        pytester.makeconftest(\n            \"\"\"\n            import test_rewrite_module_imported\n        \"\"\"\n        )\n        pytester.makepyfile(\n            test_rewrite_module_imported=\"\"\"\n            def test_rewritten():\n                assert \"@py_builtins\" in globals()\n        \"\"\"\n        )\n        assert pytester.runpytest_subprocess().ret == 0\n", "type": "function"}], "retrieved_count": 10, "cost_time": 0.34693121910095215}
{"question": "Where does the data flow from pytester.inline_run() through the test execution pipeline to ultimately validate that tmp_path remains functional when the current process's user id lacks a corresponding valid user entry?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"name": "test_tmp_path_fallback_uid_not_found", "is_method": false, "class_name": null, "parameters": ["pytester"], "calls": ["pytest.mark.usefixtures", "pytest.mark.skipif", "pytester.makepyfile", "pytester.inline_run", "reprec.assertoutcome", "sys.platform.startswith"], "code_location": {"file": "test_tmpdir.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 335, "end_line": 346}, "code_snippet": "def test_tmp_path_fallback_uid_not_found(pytester: Pytester) -> None:\n    \"\"\"Test that tmp_path works even if the current process's user id does not\n    correspond to a valid user.\n    \"\"\"\n    pytester.makepyfile(\n        \"\"\"\n        def test_some(tmp_path):\n            assert tmp_path.is_dir()\n    \"\"\"\n    )\n    reprec = pytester.inline_run()\n    reprec.assertoutcome(passed=1)\n", "type": "function"}, {"name": "test_tmp_path_fallback_tox_env", "is_method": false, "class_name": null, "parameters": ["pytester", "monkeypatch"], "calls": ["monkeypatch.delenv", "monkeypatch.delenv", "pytester.makepyfile", "pytester.inline_run", "reprec.assertoutcome"], "code_location": {"file": "test_tmpdir.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 309, "end_line": 322}, "code_snippet": "def test_tmp_path_fallback_tox_env(pytester: Pytester, monkeypatch) -> None:\n    \"\"\"Test that tmp_path works even if environment variables required by getpass\n    module are missing (#1010).\n    \"\"\"\n    monkeypatch.delenv(\"USER\", raising=False)\n    monkeypatch.delenv(\"USERNAME\", raising=False)\n    pytester.makepyfile(\n        \"\"\"\n        def test_some(tmp_path):\n            assert tmp_path.is_dir()\n    \"\"\"\n    )\n    reprec = pytester.inline_run()\n    reprec.assertoutcome(passed=1)\n", "type": "function"}, {"name": "test_tmp_path_always_is_realpath", "is_method": false, "class_name": null, "parameters": ["pytester", "monkeypatch"], "calls": ["pytester.mkdir", "pytester.path.joinpath", "attempt_symlink_to", "monkeypatch.setenv", "pytester.makepyfile", "pytester.inline_run", "reprec.assertoutcome", "str", "str"], "code_location": {"file": "test_tmpdir.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 260, "end_line": 278}, "code_snippet": "def test_tmp_path_always_is_realpath(pytester: Pytester, monkeypatch) -> None:\n    # the reason why tmp_path should be a realpath is that\n    # when you cd to it and do \"os.getcwd()\" you will anyway\n    # get the realpath.  Using the symlinked path can thus\n    # easily result in path-inequality\n    # XXX if that proves to be a problem, consider using\n    # os.environ[\"PWD\"]\n    realtemp = pytester.mkdir(\"myrealtemp\")\n    linktemp = pytester.path.joinpath(\"symlinktemp\")\n    attempt_symlink_to(linktemp, str(realtemp))\n    monkeypatch.setenv(\"PYTEST_DEBUG_TEMPROOT\", str(linktemp))\n    pytester.makepyfile(\n        \"\"\"\n        def test_1(tmp_path):\n            assert tmp_path.resolve() == tmp_path\n    \"\"\"\n    )\n    reprec = pytester.inline_run()\n    reprec.assertoutcome(passed=1)\n", "type": "function"}, {"name": "test_tmp_path_too_long_on_parametrization", "is_method": false, "class_name": null, "parameters": ["pytester"], "calls": ["pytester.makepyfile", "pytester.inline_run", "reprec.assertoutcome"], "code_location": {"file": "test_tmpdir.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 281, "end_line": 291}, "code_snippet": "def test_tmp_path_too_long_on_parametrization(pytester: Pytester) -> None:\n    pytester.makepyfile(\n        \"\"\"\n        import pytest\n        @pytest.mark.parametrize(\"arg\", [\"1\"*1000])\n        def test_some(arg, tmp_path):\n            tmp_path.joinpath(\"hello\").touch()\n    \"\"\"\n    )\n    reprec = pytester.inline_run()\n    reprec.assertoutcome(passed=1)\n", "type": "function"}, {"name": "test_tmp_path_fixture", "is_method": false, "class_name": null, "parameters": ["pytester"], "calls": ["pytester.copy_example", "pytester.runpytest", "results.stdout.fnmatch_lines"], "code_location": {"file": "test_tmpdir.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 29, "end_line": 32}, "code_snippet": "def test_tmp_path_fixture(pytester: Pytester) -> None:\n    p = pytester.copy_example(\"tmpdir/tmp_path_fixture.py\")\n    results = pytester.runpytest(p)\n    results.stdout.fnmatch_lines([\"*1 passed*\"])\n", "type": "function"}, {"name": "test_tmp_path_factory", "is_method": false, "class_name": null, "parameters": ["pytester"], "calls": ["pytester.makepyfile", "pytester.inline_run", "reprec.assertoutcome"], "code_location": {"file": "test_tmpdir.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 294, "end_line": 306}, "code_snippet": "def test_tmp_path_factory(pytester: Pytester) -> None:\n    pytester.makepyfile(\n        \"\"\"\n        import pytest\n        @pytest.fixture(scope='session')\n        def session_dir(tmp_path_factory):\n            return tmp_path_factory.mktemp('data', numbered=False)\n        def test_some(session_dir):\n            assert session_dir.is_dir()\n    \"\"\"\n    )\n    reprec = pytester.inline_run()\n    reprec.assertoutcome(passed=1)\n", "type": "function"}, {"name": "test_txtfile_with_fixtures", "is_method": true, "class_name": "TestDoctests", "parameters": ["self", "pytester"], "calls": ["pytester.maketxtfile", "pytester.inline_run", "reprec.assertoutcome"], "code_location": {"file": "test_doctest.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 553, "end_line": 562}, "code_snippet": "    def test_txtfile_with_fixtures(self, pytester: Pytester):\n        p = pytester.maketxtfile(\n            \"\"\"\n            >>> p = getfixture('tmp_path')\n            >>> p.is_dir()\n            True\n        \"\"\"\n        )\n        reprec = pytester.inline_run(p)\n        reprec.assertoutcome(passed=1)\n", "type": "function"}, {"name": "test_cwd_deleted", "is_method": false, "class_name": null, "parameters": ["pytester"], "calls": ["pytester.makepyfile", "pytester.runpytest", "result.stdout.fnmatch_lines", "result.stdout.no_fnmatch_line", "result.stderr.no_fnmatch_line"], "code_location": {"file": "test_excinfo.py", "path": "/data3/pwh/swebench-repos/pytest/testing/code", "start_line": 1642, "end_line": 1656}, "code_snippet": "def test_cwd_deleted(pytester: Pytester) -> None:\n    pytester.makepyfile(\n        \"\"\"\n        import os\n\n        def test(tmp_path):\n            os.chdir(tmp_path)\n            tmp_path.unlink()\n            assert False\n    \"\"\"\n    )\n    result = pytester.runpytest()\n    result.stdout.fnmatch_lines([\"* 1 failed in *\"])\n    result.stdout.no_fnmatch_line(\"*INTERNALERROR*\")\n    result.stderr.no_fnmatch_line(\"*INTERNALERROR*\")\n", "type": "function"}, {"name": "test_tmp_path_factory_handles_invalid_dir_characters", "is_method": false, "class_name": null, "parameters": ["tmp_path_factory", "monkeypatch"], "calls": ["monkeypatch.setattr", "monkeypatch.setattr", "monkeypatch.setattr", "tmp_path_factory.getbasetemp", "str"], "code_location": {"file": "test_tmpdir.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 572, "end_line": 580}, "code_snippet": "def test_tmp_path_factory_handles_invalid_dir_characters(\n    tmp_path_factory: TempPathFactory, monkeypatch: MonkeyPatch\n) -> None:\n    monkeypatch.setattr(\"getpass.getuser\", lambda: \"os/<:*?;>agnostic\")\n    # _basetemp / _given_basetemp are cached / set in parallel runs, patch them\n    monkeypatch.setattr(tmp_path_factory, \"_basetemp\", None)\n    monkeypatch.setattr(tmp_path_factory, \"_given_basetemp\", None)\n    p = tmp_path_factory.getbasetemp()\n    assert \"pytest-of-unknown\" in str(p)\n", "type": "function"}, {"name": "test_inline_run_test_module_not_cleaned_up", "is_method": true, "class_name": "TestInlineRunModulesCleanup", "parameters": ["self", "pytester"], "calls": ["pytester.makepyfile", "pytester.inline_run", "test_mod.write_text", "pytester.inline_run", "str", "str"], "code_location": {"file": "test_pytester.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 220, "end_line": 227}, "code_snippet": "    def test_inline_run_test_module_not_cleaned_up(self, pytester: Pytester) -> None:\n        test_mod = pytester.makepyfile(\"def test_foo(): assert True\")\n        result = pytester.inline_run(str(test_mod))\n        assert result.ret == ExitCode.OK\n        # rewrite module, now test should fail if module was re-imported\n        test_mod.write_text(\"def test_foo(): assert False\", encoding=\"utf-8\")\n        result2 = pytester.inline_run(str(test_mod))\n        assert result2.ret == ExitCode.TESTS_FAILED\n", "type": "function"}], "retrieved_count": 10, "cost_time": 0.3395256996154785}
{"question": "Where in the LocalPath class can I locate the code logic responsible for assigning the absolute path value to the strpath attribute during initialization?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"name": "test_dirpath_abs_no_abs", "is_method": true, "class_name": "TestLocalPath", "parameters": ["self", "tmpdir"], "calls": ["tmpdir.join", "p.dirpath", "tmpdir.join", "tmpdir.dirpath", "local"], "code_location": {"file": "test_local.py", "path": "/data3/pwh/swebench-repos/pytest/testing/_py", "start_line": 574, "end_line": 577}, "code_snippet": "    def test_dirpath_abs_no_abs(self, tmpdir):\n        p = tmpdir.join(\"foo\")\n        assert p.dirpath(\"/bar\") == tmpdir.join(\"bar\")\n        assert tmpdir.dirpath(\"/bar\", abs=True) == local(\"/bar\")\n", "type": "function"}, {"name": "__fspath__", "is_method": true, "class_name": "LocalPath", "parameters": ["self"], "calls": [], "code_location": {"file": "path.py", "path": "/data3/pwh/swebench-repos/pytest/src/_pytest/_py", "start_line": 553, "end_line": 554}, "code_snippet": "    def __fspath__(self):\n        return self.strpath\n", "type": "function"}, {"name": "__init__", "is_method": true, "class_name": "LocalPath", "parameters": ["self", "path", "expanduser"], "calls": ["error.checked_call", "abspath", "os.fspath", "os.path.expanduser", "ValueError"], "code_location": {"file": "path.py", "path": "/data3/pwh/swebench-repos/pytest/src/_pytest/_py", "start_line": 275, "end_line": 297}, "code_snippet": "    def __init__(self, path=None, expanduser=False):\n        \"\"\"Initialize and return a local Path instance.\n\n        Path can be relative to the current directory.\n        If path is None it defaults to the current working directory.\n        If expanduser is True, tilde-expansion is performed.\n        Note that Path instances always carry an absolute path.\n        Note also that passing in a local path object will simply return\n        the exact same path object. Use new() to get a new copy.\n        \"\"\"\n        if path is None:\n            self.strpath = error.checked_call(os.getcwd)\n        else:\n            try:\n                path = os.fspath(path)\n            except TypeError:\n                raise ValueError(\n                    \"can only pass None, Path instances \"\n                    \"or non-empty strings to LocalPath\"\n                )\n            if expanduser:\n                path = os.path.expanduser(path)\n            self.strpath = abspath(path)\n", "type": "function"}, {"name": "test_initialize_reldir", "is_method": true, "class_name": "TestLocalPath", "parameters": ["self", "path1"], "calls": ["path1.as_cwd", "local", "p.check"], "code_location": {"file": "test_local.py", "path": "/data3/pwh/swebench-repos/pytest/testing/_py", "start_line": 661, "end_line": 664}, "code_snippet": "    def test_initialize_reldir(self, path1):\n        with path1.as_cwd():\n            p = local(\"samplefile\")\n            assert p.check()\n", "type": "function"}, {"name": "test_fspath_protocol_other_class", "is_method": true, "class_name": "TestLocalPath", "parameters": ["self", "fake_fspath_obj"], "calls": ["local", "fake_fspath_obj.__fspath__", "py_path.check", "os.path.join", "py_path.join"], "code_location": {"file": "test_local.py", "path": "/data3/pwh/swebench-repos/pytest/testing/_py", "start_line": 866, "end_line": 873}, "code_snippet": "    def test_fspath_protocol_other_class(self, fake_fspath_obj):\n        # py.path is always absolute\n        py_path = local(fake_fspath_obj)\n        str_path = fake_fspath_obj.__fspath__()\n        assert py_path.check(endswith=str_path)\n        assert py_path.join(fake_fspath_obj).strpath == os.path.join(\n            py_path.strpath, str_path\n        )\n", "type": "function"}, {"name": "__post_init__", "is_method": true, "class_name": "ReprFileLocation", "parameters": ["self"], "calls": ["str"], "code_location": {"file": "code.py", "path": "/data3/pwh/swebench-repos/pytest/src/_pytest/_code", "start_line": 1431, "end_line": 1432}, "code_snippet": "    def __post_init__(self) -> None:\n        self.path = str(self.path)\n", "type": "function"}, {"name": "test_fspath_protocol_match_strpath", "is_method": true, "class_name": "CommonFSTests", "parameters": ["self", "path1"], "calls": ["path1.__fspath__"], "code_location": {"file": "test_local.py", "path": "/data3/pwh/swebench-repos/pytest/testing/_py", "start_line": 458, "end_line": 459}, "code_snippet": "    def test_fspath_protocol_match_strpath(self, path1):\n        assert path1.__fspath__() == path1.strpath\n", "type": "function"}, {"name": "test_normpath", "is_method": true, "class_name": "TestLocalPath", "parameters": ["self", "path1"], "calls": ["path1.join", "path1.join", "str", "str"], "code_location": {"file": "test_local.py", "path": "/data3/pwh/swebench-repos/pytest/testing/_py", "start_line": 760, "end_line": 763}, "code_snippet": "    def test_normpath(self, path1):\n        new1 = path1.join(\"/otherdir\")\n        new2 = path1.join(\"otherdir\")\n        assert str(new1) == str(new2)\n", "type": "function"}, {"name": "test_fspath_func_match_strpath", "is_method": true, "class_name": "CommonFSTests", "parameters": ["self", "path1"], "calls": ["fspath"], "code_location": {"file": "test_local.py", "path": "/data3/pwh/swebench-repos/pytest/testing/_py", "start_line": 461, "end_line": 464}, "code_snippet": "    def test_fspath_func_match_strpath(self, path1):\n        from os import fspath\n\n        assert fspath(path1) == path1.strpath\n", "type": "function"}, {"name": "test_sysfind_absolute", "is_method": true, "class_name": "TestExecution", "parameters": ["self"], "calls": ["local.sysfind", "x.check", "local.sysfind", "y.check", "str"], "code_location": {"file": "test_local.py", "path": "/data3/pwh/swebench-repos/pytest/testing/_py", "start_line": 912, "end_line": 917}, "code_snippet": "    def test_sysfind_absolute(self):\n        x = local.sysfind(\"test\")\n        assert x.check(file=1)\n        y = local.sysfind(str(x))\n        assert y.check(file=1)\n        assert y == x\n", "type": "function"}], "retrieved_count": 10, "cost_time": 0.344191312789917}
{"question": "Where is the line-wrapping logic that determines when function arguments exceed terminal width implemented in the ReprFuncArgs class?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"name": "repr_args", "is_method": true, "class_name": "FormattedExcinfo", "parameters": ["self", "entry"], "calls": ["entry.frame.getargs", "ReprFuncArgs", "args.append", "saferepr", "saferepr"], "code_location": {"file": "code.py", "path": "/data3/pwh/swebench-repos/pytest/src/_pytest/_code", "start_line": 908, "end_line": 918}, "code_snippet": "    def repr_args(self, entry: TracebackEntry) -> ReprFuncArgs | None:\n        if self.funcargs:\n            args = []\n            for argname, argvalue in entry.frame.getargs(var=True):\n                if self.truncate_args:\n                    str_repr = saferepr(argvalue)\n                else:\n                    str_repr = saferepr(argvalue, maxsize=None)\n                args.append((argname, str_repr))\n            return ReprFuncArgs(args)\n        return None\n", "type": "function"}, {"name": "test_repr_tracebackentry_lines2", "is_method": true, "class_name": "TestFormattedExcinfo", "parameters": ["self", "importasmod", "tw_mock"], "calls": ["importasmod", "pytest.raises", "excinfo.traceback.filter", "FormattedExcinfo", "p.repr_args", "FormattedExcinfo", "p.repr_traceback_entry", "repr_entry.toterminal", "repr", "repr", "repr", "repr"], "code_location": {"file": "test_excinfo.py", "path": "/data3/pwh/swebench-repos/pytest/testing/code", "start_line": 806, "end_line": 831}, "code_snippet": "    def test_repr_tracebackentry_lines2(self, importasmod, tw_mock) -> None:\n        mod = importasmod(\n            \"\"\"\n            def func1(m, x, y, z):\n                raise ValueError(\"hello\\\\nworld\")\n        \"\"\"\n        )\n        excinfo = pytest.raises(ValueError, mod.func1, \"m\" * 90, 5, 13, \"z\" * 120)\n        excinfo.traceback = excinfo.traceback.filter(excinfo)\n        entry = excinfo.traceback[-1]\n        p = FormattedExcinfo(funcargs=True)\n        reprfuncargs = p.repr_args(entry)\n        assert reprfuncargs is not None\n        assert reprfuncargs.args[0] == (\"m\", repr(\"m\" * 90))\n        assert reprfuncargs.args[1] == (\"x\", \"5\")\n        assert reprfuncargs.args[2] == (\"y\", \"13\")\n        assert reprfuncargs.args[3] == (\"z\", repr(\"z\" * 120))\n\n        p = FormattedExcinfo(funcargs=True)\n        repr_entry = p.repr_traceback_entry(entry)\n        assert repr_entry.reprfuncargs is not None\n        assert repr_entry.reprfuncargs.args == reprfuncargs.args\n        repr_entry.toterminal(tw_mock)\n        assert tw_mock.lines[0] == \"m = \" + repr(\"m\" * 90)\n        assert tw_mock.lines[1] == \"x = 5, y = 13\"\n        assert tw_mock.lines[2] == \"z = \" + repr(\"z\" * 120)\n", "type": "function"}, {"name": "_wrap_bytes_repr", "is_method": false, "class_name": null, "parameters": ["object", "width", "allowance"], "calls": ["range", "len", "len", "len", "repr", "repr", "repr"], "code_location": {"file": "pprint.py", "path": "/data3/pwh/swebench-repos/pytest/src/_pytest/_io", "start_line": 658, "end_line": 673}, "code_snippet": "def _wrap_bytes_repr(object: Any, width: int, allowance: int) -> Iterator[str]:\n    current = b\"\"\n    last = len(object) // 4 * 4\n    for i in range(0, len(object), 4):\n        part = object[i : i + 4]\n        candidate = current + part\n        if i == last:\n            width -= allowance\n        if len(repr(candidate)) > width:\n            if current:\n                yield repr(current)\n            current = part\n        else:\n            current = candidate\n    if current:\n        yield repr(current)\n", "type": "function"}, {"name": "test_repr_args_not_truncated", "is_method": true, "class_name": "TestFormattedExcinfo", "parameters": ["self", "importasmod"], "calls": ["importasmod", "pytest.raises", "excinfo.traceback.filter", "FormattedExcinfo", "p.repr_args", "cast", "FormattedExcinfo", "p.repr_args", "len", "cast", "repr"], "code_location": {"file": "test_excinfo.py", "path": "/data3/pwh/swebench-repos/pytest/testing/code", "start_line": 750, "end_line": 771}, "code_snippet": "    def test_repr_args_not_truncated(self, importasmod) -> None:\n        mod = importasmod(\n            \"\"\"\n            def func1(m):\n                raise ValueError(\"hello\\\\nworld\")\n        \"\"\"\n        )\n        excinfo = pytest.raises(ValueError, mod.func1, \"m\" * 500)\n        excinfo.traceback = excinfo.traceback.filter(excinfo)\n        entry = excinfo.traceback[-1]\n        p = FormattedExcinfo(funcargs=True, truncate_args=True)\n        reprfuncargs = p.repr_args(entry)\n        assert reprfuncargs is not None\n        arg1 = cast(str, reprfuncargs.args[0][1])\n        assert len(arg1) < 500\n        assert \"...\" in arg1\n        # again without truncate\n        p = FormattedExcinfo(funcargs=True, truncate_args=False)\n        reprfuncargs = p.repr_args(entry)\n        assert reprfuncargs is not None\n        assert reprfuncargs.args[0] == (\"m\", repr(\"m\" * 500))\n        assert \"...\" not in cast(str, reprfuncargs.args[0][1])\n", "type": "function"}, {"name": "toterminal", "is_method": true, "class_name": "ReprFuncArgs", "parameters": ["self", "tw"], "calls": ["tw.line", "tw.line", "tw.line", "len", "len"], "code_location": {"file": "code.py", "path": "/data3/pwh/swebench-repos/pytest/src/_pytest/_code", "start_line": 1458, "end_line": 1474}, "code_snippet": "    def toterminal(self, tw: TerminalWriter) -> None:\n        if self.args:\n            linesofar = \"\"\n            for name, value in self.args:\n                ns = f\"{name} = {value}\"\n                if len(ns) + len(linesofar) + 2 > tw.fullwidth:\n                    if linesofar:\n                        tw.line(linesofar)\n                    linesofar = ns\n                else:\n                    if linesofar:\n                        linesofar += \", \" + ns\n                    else:\n                        linesofar = ns\n            if linesofar:\n                tw.line(linesofar)\n            tw.line(\"\")\n", "type": "function"}, {"name": "_pprint_str", "is_method": true, "class_name": "PrettyPrinter", "parameters": ["self", "object", "stream", "indent", "allowance", "context", "level"], "calls": ["object.splitlines", "enumerate", "enumerate", "len", "write", "repr", "len", "write", "write", "write", "write", "repr", "len", "chunks.append", "re.findall", "parts.pop", "enumerate", "write", "len", "chunks.append", "len", "repr", "repr", "chunks.append", "len", "len", "repr"], "code_location": {"file": "pprint.py", "path": "/data3/pwh/swebench-repos/pytest/src/_pytest/_io", "start_line": 246, "end_line": 301}, "code_snippet": "    def _pprint_str(\n        self,\n        object: Any,\n        stream: IO[str],\n        indent: int,\n        allowance: int,\n        context: set[int],\n        level: int,\n    ) -> None:\n        write = stream.write\n        if not len(object):\n            write(repr(object))\n            return\n        chunks = []\n        lines = object.splitlines(True)\n        if level == 1:\n            indent += 1\n            allowance += 1\n        max_width1 = max_width = self._width - indent\n        for i, line in enumerate(lines):\n            rep = repr(line)\n            if i == len(lines) - 1:\n                max_width1 -= allowance\n            if len(rep) <= max_width1:\n                chunks.append(rep)\n            else:\n                # A list of alternating (non-space, space) strings\n                parts = re.findall(r\"\\S*\\s*\", line)\n                assert parts\n                assert not parts[-1]\n                parts.pop()  # drop empty last part\n                max_width2 = max_width\n                current = \"\"\n                for j, part in enumerate(parts):\n                    candidate = current + part\n                    if j == len(parts) - 1 and i == len(lines) - 1:\n                        max_width2 -= allowance\n                    if len(repr(candidate)) > max_width2:\n                        if current:\n                            chunks.append(repr(current))\n                        current = part\n                    else:\n                        current = candidate\n                if current:\n                    chunks.append(repr(current))\n        if len(chunks) == 1:\n            write(rep)\n            return\n        if level == 1:\n            write(\"(\")\n        for i, rep in enumerate(chunks):\n            if i > 0:\n                write(\"\\n\" + \" \" * indent)\n            write(rep)\n        if level == 1:\n            write(\")\")\n", "type": "function"}, {"name": "test_not_raise_exception_with_mixed_encoding", "is_method": true, "class_name": "TestReprFuncArgs", "parameters": ["self", "tw_mock"], "calls": ["ReprFuncArgs", "r.toterminal"], "code_location": {"file": "test_code.py", "path": "/data3/pwh/swebench-repos/pytest/testing/code", "start_line": 189, "end_line": 198}, "code_snippet": "    def test_not_raise_exception_with_mixed_encoding(self, tw_mock) -> None:\n        args = [(\"unicode_string\", \"So Paulo\"), (\"utf8_string\", b\"S\\xc3\\xa3o Paulo\")]\n\n        r = ReprFuncArgs(args)\n        r.toterminal(tw_mock)\n\n        assert (\n            tw_mock.lines[0]\n            == r\"unicode_string = So Paulo, utf8_string = b'S\\xc3\\xa3o Paulo'\"\n        )\n", "type": "function"}, {"name": "test_repr_tracebackentry_lines_var_kw_args", "is_method": true, "class_name": "TestFormattedExcinfo", "parameters": ["self", "importasmod", "tw_mock"], "calls": ["importasmod", "pytest.raises", "excinfo.traceback.filter", "FormattedExcinfo", "p.repr_args", "FormattedExcinfo", "p.repr_traceback_entry", "repr_entry.toterminal", "repr", "repr", "repr"], "code_location": {"file": "test_excinfo.py", "path": "/data3/pwh/swebench-repos/pytest/testing/code", "start_line": 833, "end_line": 855}, "code_snippet": "    def test_repr_tracebackentry_lines_var_kw_args(self, importasmod, tw_mock) -> None:\n        mod = importasmod(\n            \"\"\"\n            def func1(x, *y, **z):\n                raise ValueError(\"hello\\\\nworld\")\n        \"\"\"\n        )\n        excinfo = pytest.raises(ValueError, mod.func1, \"a\", \"b\", c=\"d\")\n        excinfo.traceback = excinfo.traceback.filter(excinfo)\n        entry = excinfo.traceback[-1]\n        p = FormattedExcinfo(funcargs=True)\n        reprfuncargs = p.repr_args(entry)\n        assert reprfuncargs is not None\n        assert reprfuncargs.args[0] == (\"x\", repr(\"a\"))\n        assert reprfuncargs.args[1] == (\"y\", repr((\"b\",)))\n        assert reprfuncargs.args[2] == (\"z\", repr({\"c\": \"d\"}))\n\n        p = FormattedExcinfo(funcargs=True)\n        repr_entry = p.repr_traceback_entry(entry)\n        assert repr_entry.reprfuncargs\n        assert repr_entry.reprfuncargs.args == reprfuncargs.args\n        repr_entry.toterminal(tw_mock)\n        assert tw_mock.lines[0] == \"x = 'a', y = ('b',), z = {'c': 'd'}\"\n", "type": "function"}, {"name": "test_line_with_reprcrash", "is_method": false, "class_name": null, "parameters": ["monkeypatch"], "calls": ["monkeypatch.setattr", "check", "check", "check", "check", "check", "check", "check", "check", "check", "check", "check", "check", "check", "check", "check", "check", "check", "check", "check", "check", "check", "_get_line_with_reprcrash_message", "self.__dict__.update", "Namespace", "config", "rep", "DummyTerminalWriter", "len", "wcswidth"], "code_location": {"file": "test_terminal.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 2538, "end_line": 2616}, "code_snippet": "def test_line_with_reprcrash(monkeypatch: MonkeyPatch) -> None:\n    mocked_verbose_word = \"FAILED\"\n\n    mocked_pos = \"some::nodeid\"\n\n    def mock_get_pos(*args):\n        return mocked_pos\n\n    monkeypatch.setattr(_pytest.terminal, \"_get_node_id_with_markup\", mock_get_pos)\n\n    class Namespace:\n        def __init__(self, **kwargs):\n            self.__dict__.update(kwargs)\n\n    class config:\n        def __init__(self):\n            self.option = Namespace(verbose=0)\n\n    class rep:\n        def _get_verbose_word_with_markup(self, *args):\n            return mocked_verbose_word, {}\n\n        class longrepr:\n            class reprcrash:\n                pass\n\n    def check(msg, width, expected):\n        class DummyTerminalWriter:\n            fullwidth = width\n\n            def markup(self, word: str, **markup: str):\n                return word\n\n        __tracebackhide__ = True\n        if msg:\n            rep.longrepr.reprcrash.message = msg  # type: ignore\n        actual = _get_line_with_reprcrash_message(\n            config(),  # type: ignore[arg-type]\n            rep(),  # type: ignore[arg-type]\n            DummyTerminalWriter(),  # type: ignore[arg-type]\n            {},\n        )\n\n        assert actual == expected\n        if actual != f\"{mocked_verbose_word} {mocked_pos}\":\n            assert len(actual) <= width\n            assert wcswidth(actual) <= width\n\n    # AttributeError with message\n    check(None, 80, \"FAILED some::nodeid\")\n\n    check(\"msg\", 80, \"FAILED some::nodeid - msg\")\n    check(\"msg\", 3, \"FAILED some::nodeid\")\n\n    check(\"msg\", 24, \"FAILED some::nodeid\")\n    check(\"msg\", 25, \"FAILED some::nodeid - msg\")\n\n    check(\"some longer msg\", 24, \"FAILED some::nodeid\")\n    check(\"some longer msg\", 25, \"FAILED some::nodeid - ...\")\n    check(\"some longer msg\", 26, \"FAILED some::nodeid - s...\")\n\n    check(\"some\\nmessage\", 25, \"FAILED some::nodeid - ...\")\n    check(\"some\\nmessage\", 26, \"FAILED some::nodeid - some\")\n    check(\"some\\nmessage\", 80, \"FAILED some::nodeid - some\")\n\n    # Test unicode safety.\n    check(\"\\n2nd line\", 25, \"FAILED some::nodeid - ...\")\n    check(\"\\n2nd line\", 26, \"FAILED some::nodeid - ...\")\n    check(\"\\n2nd line\", 27, \"FAILED some::nodeid - ...\")\n    check(\"\\n2nd line\", 28, \"FAILED some::nodeid - ...\")\n    check(\"\\n2nd line\", 29, \"FAILED some::nodeid - ...\")\n\n    # NOTE: constructed, not sure if this is supported.\n    mocked_pos = \"nodeid::::withunicode\"\n    check(\"\\n2nd line\", 29, \"FAILED nodeid::::withunicode\")\n    check(\"\\n2nd line\", 40, \"FAILED nodeid::::withunicode - ...\")\n    check(\"\\n2nd line\", 41, \"FAILED nodeid::::withunicode - ...\")\n    check(\"\\n2nd line\", 42, \"FAILED nodeid::::withunicode - ...\")\n    check(\"\\n2nd line\", 80, \"FAILED nodeid::::withunicode - \")\n", "type": "function"}, {"name": "repr", "is_method": true, "class_name": "SafeRepr", "parameters": ["self", "x"], "calls": ["_ellipsize", "ascii", "repr", "_format_repr_exception", "super"], "code_location": {"file": "saferepr.py", "path": "/data3/pwh/swebench-repos/pytest/src/_pytest/_io", "start_line": 57, "end_line": 69}, "code_snippet": "    def repr(self, x: object) -> str:\n        try:\n            if self.use_ascii:\n                s = ascii(x)\n            else:\n                s = super().repr(x)\n        except (KeyboardInterrupt, SystemExit):\n            raise\n        except BaseException as exc:\n            s = _format_repr_exception(exc, x)\n        if self.maxsize is not None:\n            s = _ellipsize(s, self.maxsize)\n        return s\n", "type": "function"}], "retrieved_count": 10, "cost_time": 0.3574955463409424}
{"question": "Where are the functions or methods in the assertion module that indirectly invoke the _HighlightFunc protocol through conditional lexer type selection between diff and python highlighting implementations?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"name": "_get_pygments_lexer", "is_method": true, "class_name": "TerminalWriter", "parameters": ["self", "lexer"], "calls": ["PythonLexer", "DiffLexer", "assert_never"], "code_location": {"file": "terminalwriter.py", "path": "/data3/pwh/swebench-repos/pytest/src/_pytest/_io", "start_line": 204, "end_line": 210}, "code_snippet": "    def _get_pygments_lexer(self, lexer: Literal[\"python\", \"diff\"]) -> Lexer:\n        if lexer == \"python\":\n            return PythonLexer()\n        elif lexer == \"diff\":\n            return DiffLexer()\n        else:\n            assert_never(lexer)\n", "type": "function"}, {"name": "test_code_highlight", "is_method": false, "class_name": null, "parameters": ["has_markup", "code_highlight", "expected", "color_mapping"], "calls": ["pytest.mark.parametrize", "io.StringIO", "terminalwriter.TerminalWriter", "tw._write_source", "splitlines", "color_mapping.format", "pytest.raises", "tw._write_source", "pytest.param", "pytest.param", "pytest.param", "pytest.param", "f.getvalue", "re.escape"], "code_location": {"file": "test_terminalwriter.py", "path": "/data3/pwh/swebench-repos/pytest/testing/io", "start_line": 297, "end_line": 310}, "code_snippet": "def test_code_highlight(has_markup, code_highlight, expected, color_mapping):\n    f = io.StringIO()\n    tw = terminalwriter.TerminalWriter(f)\n    tw.hasmarkup = has_markup\n    tw.code_highlight = code_highlight\n    tw._write_source([\"assert 0\"])\n\n    assert f.getvalue().splitlines(keepends=True) == color_mapping.format([expected])\n\n    with pytest.raises(\n        ValueError,\n        match=re.escape(\"indents size (2) should have same size as lines (1)\"),\n    ):\n        tw._write_source([\"assert 0\"], [\" \", \" \"])\n", "type": "function"}, {"name": "test_code_highlight_simple", "is_method": true, "class_name": "TestCodeHighlight", "parameters": ["self", "pytester", "color_mapping"], "calls": ["pytester.makepyfile", "pytester.runpytest", "result.stdout.fnmatch_lines", "color_mapping.format_for_fnmatch"], "code_location": {"file": "test_terminal.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 2772, "end_line": 2788}, "code_snippet": "    def test_code_highlight_simple(self, pytester: Pytester, color_mapping) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            def test_foo():\n                assert 1 == 10\n        \"\"\"\n        )\n        result = pytester.runpytest(\"--color=yes\")\n        result.stdout.fnmatch_lines(\n            color_mapping.format_for_fnmatch(\n                [\n                    \"    {reset}{kw}def{hl-reset}{kwspace}{function}test_foo{hl-reset}():{endline}\",\n                    \">       {kw}assert{hl-reset} {number}1{hl-reset} == {number}10{hl-reset}{endline}\",\n                    \"{bold}{red}E       assert 1 == 10{reset}\",\n                ]\n            )\n        )\n", "type": "function"}, {"name": "dummy_highlighter", "is_method": false, "class_name": null, "parameters": ["source", "lexer"], "calls": [], "code_location": {"file": "util.py", "path": "/data3/pwh/swebench-repos/pytest/src/_pytest/assertion", "start_line": 46, "end_line": 51}, "code_snippet": "def dummy_highlighter(source: str, lexer: Literal[\"diff\", \"python\"] = \"python\") -> str:\n    \"\"\"Dummy highlighter that returns the text unprocessed.\n\n    Needed for _notin_text, as the diff gets post-processed to only show the \"+\" part.\n    \"\"\"\n    return source\n", "type": "function"}, {"name": "_compare_eq_any", "is_method": false, "class_name": null, "parameters": ["left", "right", "highlighter", "verbose"], "calls": ["istext", "istext", "_diff_text", "isinstance", "isinstance", "approx_side._repr_compare", "isiterable", "isiterable", "_compare_eq_iterable", "explanation.extend", "isinstance", "isinstance", "_compare_eq_cls", "type", "type", "isdatacls", "isattrs", "isnamedtuple", "issequence", "issequence", "_compare_eq_sequence", "isset", "isset", "_compare_eq_set", "isdict", "isdict", "_compare_eq_dict"], "code_location": {"file": "util.py", "path": "/data3/pwh/swebench-repos/pytest/src/_pytest/assertion", "start_line": 248, "end_line": 282}, "code_snippet": "def _compare_eq_any(\n    left: Any, right: Any, highlighter: _HighlightFunc, verbose: int = 0\n) -> list[str]:\n    explanation = []\n    if istext(left) and istext(right):\n        explanation = _diff_text(left, right, highlighter, verbose)\n    else:\n        from _pytest.python_api import ApproxBase\n\n        if isinstance(left, ApproxBase) or isinstance(right, ApproxBase):\n            # Although the common order should be obtained == expected, this ensures both ways\n            approx_side = left if isinstance(left, ApproxBase) else right\n            other_side = right if isinstance(left, ApproxBase) else left\n\n            explanation = approx_side._repr_compare(other_side)\n        elif type(left) is type(right) and (\n            isdatacls(left) or isattrs(left) or isnamedtuple(left)\n        ):\n            # Note: unlike dataclasses/attrs, namedtuples compare only the\n            # field values, not the type or field names. But this branch\n            # intentionally only handles the same-type case, which was often\n            # used in older code bases before dataclasses/attrs were available.\n            explanation = _compare_eq_cls(left, right, highlighter, verbose)\n        elif issequence(left) and issequence(right):\n            explanation = _compare_eq_sequence(left, right, highlighter, verbose)\n        elif isset(left) and isset(right):\n            explanation = _compare_eq_set(left, right, highlighter, verbose)\n        elif isdict(left) and isdict(right):\n            explanation = _compare_eq_dict(left, right, highlighter, verbose)\n\n        if isiterable(left) and isiterable(right):\n            expl = _compare_eq_iterable(left, right, highlighter, verbose)\n            explanation.extend(expl)\n\n    return explanation\n", "type": "function"}, {"name": "test_code_highlight_continuation", "is_method": true, "class_name": "TestCodeHighlight", "parameters": ["self", "pytester", "color_mapping"], "calls": ["pytester.makepyfile", "pytester.runpytest", "result.stdout.fnmatch_lines", "color_mapping.format_for_fnmatch"], "code_location": {"file": "test_terminal.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 2790, "end_line": 2811}, "code_snippet": "    def test_code_highlight_continuation(\n        self, pytester: Pytester, color_mapping\n    ) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            def test_foo():\n                print('''\n                '''); assert 0\n        \"\"\"\n        )\n        result = pytester.runpytest(\"--color=yes\")\n\n        result.stdout.fnmatch_lines(\n            color_mapping.format_for_fnmatch(\n                [\n                    \"    {reset}{kw}def{hl-reset}{kwspace}{function}test_foo{hl-reset}():{endline}\",\n                    \"        {print}print{hl-reset}({str}'''{hl-reset}{str}{hl-reset}\",\n                    \">   {str}    {hl-reset}{str}'''{hl-reset}); {kw}assert{hl-reset} {number}0{hl-reset}{endline}\",\n                    \"{bold}{red}E       assert 0{reset}\",\n                ]\n            )\n        )\n", "type": "function"}, {"name": "_compare_eq_iterable", "is_method": false, "class_name": null, "parameters": ["left", "right", "highlighter", "verbose"], "calls": ["splitlines", "splitlines", "explanation.extend", "splitlines", "running_on_ci", "pformat", "pformat", "highlighter", "PrettyPrinter", "PrettyPrinter", "join", "line.rstrip", "difflib.ndiff"], "code_location": {"file": "util.py", "path": "/data3/pwh/swebench-repos/pytest/src/_pytest/assertion", "start_line": 340, "end_line": 366}, "code_snippet": "def _compare_eq_iterable(\n    left: Iterable[Any],\n    right: Iterable[Any],\n    highlighter: _HighlightFunc,\n    verbose: int = 0,\n) -> list[str]:\n    if verbose <= 0 and not running_on_ci():\n        return [\"Use -v to get more diff\"]\n    # dynamic import to speedup pytest\n    import difflib\n\n    left_formatting = PrettyPrinter().pformat(left).splitlines()\n    right_formatting = PrettyPrinter().pformat(right).splitlines()\n\n    explanation = [\"\", \"Full diff:\"]\n    # \"right\" is the expected base against which we compare \"left\",\n    # see https://github.com/pytest-dev/pytest/issues/3333\n    explanation.extend(\n        highlighter(\n            \"\\n\".join(\n                line.rstrip()\n                for line in difflib.ndiff(right_formatting, left_formatting)\n            ),\n            lexer=\"diff\",\n        ).splitlines()\n    )\n    return explanation\n", "type": "function"}, {"name": "test_code_highlight_custom_theme", "is_method": true, "class_name": "TestCodeHighlight", "parameters": ["self", "pytester", "color_mapping", "monkeypatch"], "calls": ["pytester.makepyfile", "monkeypatch.setenv", "monkeypatch.setenv", "pytester.runpytest", "result.stdout.fnmatch_lines", "color_mapping.format_for_fnmatch"], "code_location": {"file": "test_terminal.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 2813, "end_line": 2833}, "code_snippet": "    def test_code_highlight_custom_theme(\n        self, pytester: Pytester, color_mapping, monkeypatch: MonkeyPatch\n    ) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            def test_foo():\n                assert 1 == 10\n        \"\"\"\n        )\n        monkeypatch.setenv(\"PYTEST_THEME\", \"solarized-dark\")\n        monkeypatch.setenv(\"PYTEST_THEME_MODE\", \"dark\")\n        result = pytester.runpytest(\"--color=yes\")\n        result.stdout.fnmatch_lines(\n            color_mapping.format_for_fnmatch(\n                [\n                    \"    {reset}{kw}def{hl-reset}{kwspace}{function}test_foo{hl-reset}():{endline}\",\n                    \">       {kw}assert{hl-reset} {number}1{hl-reset} == {number}10{hl-reset}{endline}\",\n                    \"{bold}{red}E       assert 1 == 10{reset}\",\n                ]\n            )\n        )\n", "type": "function"}, {"name": "_call_assertion_pass", "is_method": false, "class_name": null, "parameters": ["lineno", "orig", "expl"], "calls": ["util._assertion_pass"], "code_location": {"file": "rewrite.py", "path": "/data3/pwh/swebench-repos/pytest/src/_pytest/assertion", "start_line": 513, "end_line": 515}, "code_snippet": "def _call_assertion_pass(lineno: int, orig: str, expl: str) -> None:\n    if util._assertion_pass is not None:\n        util._assertion_pass(lineno, orig, expl)\n", "type": "function"}, {"name": "__call__", "is_method": true, "class_name": "_HighlightFunc", "parameters": ["self", "source", "lexer"], "calls": [], "code_location": {"file": "util.py", "path": "/data3/pwh/swebench-repos/pytest/src/_pytest/assertion", "start_line": 42, "end_line": 43}, "code_snippet": "    def __call__(self, source: str, lexer: Literal[\"diff\", \"python\"] = \"python\") -> str:\n        \"\"\"Apply highlighting to the given source.\"\"\"\n", "type": "function"}], "retrieved_count": 10, "cost_time": 0.3339121341705322}
{"question": "Where is the subprocess execution mechanism that `pytester.runpytest_subprocess` delegates to, and how does it handle system exception propagation during test collection?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"name": "test_pytester_subprocess", "is_method": false, "class_name": null, "parameters": ["pytester"], "calls": ["pytester.makepyfile", "pytester.runpytest_subprocess"], "code_location": {"file": "test_pytester.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 413, "end_line": 415}, "code_snippet": "def test_pytester_subprocess(pytester: Pytester) -> None:\n    testfile = pytester.makepyfile(\"def test_one(): pass\")\n    assert pytester.runpytest_subprocess(testfile).ret == 0\n", "type": "function"}, {"name": "test_respect_system_exceptions", "is_method": false, "class_name": null, "parameters": ["pytester", "exception_class", "msg"], "calls": ["pytest.mark.parametrize", "write_text", "write_text", "write_text", "pytester.runpytest_subprocess", "result.stdout.fnmatch_lines", "result.stdout.fnmatch_lines", "result.stdout.no_fnmatch_line", "ensure_file", "ensure_file", "ensure_file"], "code_location": {"file": "test_collection.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 1860, "end_line": 1880}, "code_snippet": "def test_respect_system_exceptions(\n    pytester: Pytester,\n    exception_class: type[BaseException],\n    msg: str,\n):\n    head = \"Before exception\"\n    tail = \"After exception\"\n    ensure_file(pytester.path / \"test_eggs.py\").write_text(\n        f\"print('{head}')\", encoding=\"UTF-8\"\n    )\n    ensure_file(pytester.path / \"test_ham.py\").write_text(\n        f\"raise {exception_class.__name__}()\", encoding=\"UTF-8\"\n    )\n    ensure_file(pytester.path / \"test_spam.py\").write_text(\n        f\"print('{tail}')\", encoding=\"UTF-8\"\n    )\n\n    result = pytester.runpytest_subprocess(\"-s\")\n    result.stdout.fnmatch_lines([f\"*{head}*\"])\n    result.stdout.fnmatch_lines([msg])\n    result.stdout.no_fnmatch_line(f\"*{tail}*\")\n", "type": "function"}, {"name": "test_pytester_subprocess_via_runpytest_arg", "is_method": false, "class_name": null, "parameters": ["pytester"], "calls": ["pytester.makepyfile", "pytester.runpytest_inprocess"], "code_location": {"file": "test_pytester.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 418, "end_line": 436}, "code_snippet": "def test_pytester_subprocess_via_runpytest_arg(pytester: Pytester) -> None:\n    testfile = pytester.makepyfile(\n        \"\"\"\n        def test_pytester_subprocess(pytester):\n            import os\n            testfile = pytester.makepyfile(\n                \\\"\"\"\n                import os\n                def test_one():\n                    assert {} != os.getpid()\n                \\\"\"\".format(os.getpid())\n            )\n            assert pytester.runpytest(testfile).ret == 0\n        \"\"\"\n    )\n    result = pytester.runpytest_inprocess(\n        \"-p\", \"pytester\", \"--runpytest\", \"subprocess\", testfile\n    )\n    assert result.ret == 0\n", "type": "function"}, {"name": "runpytest_subprocess", "is_method": true, "class_name": "Testdir", "parameters": ["self"], "calls": ["self._pytester.runpytest_subprocess"], "code_location": {"file": "legacypath.py", "path": "/data3/pwh/swebench-repos/pytest/src/_pytest", "start_line": 234, "end_line": 236}, "code_snippet": "    def runpytest_subprocess(self, *args, timeout=None) -> RunResult:\n        \"\"\"See :meth:`Pytester.runpytest_subprocess`.\"\"\"\n        return self._pytester.runpytest_subprocess(*args, timeout=timeout)\n", "type": "function"}, {"name": "test_systemexit_does_not_bail_out", "is_method": true, "class_name": "BaseFunctionalTests", "parameters": ["self", "pytester"], "calls": ["pytester.runitem"], "code_location": {"file": "test_runner.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 449, "end_line": 461}, "code_snippet": "    def test_systemexit_does_not_bail_out(self, pytester: Pytester) -> None:\n        try:\n            reports = pytester.runitem(\n                \"\"\"\n                def test_func():\n                    raise SystemExit(42)\n            \"\"\"\n            )\n        except SystemExit:\n            assert False, \"runner did not catch SystemExit\"\n        rep = reports[1]\n        assert rep.failed\n        assert rep.when == \"call\"\n", "type": "function"}, {"name": "runpytest_subprocess", "is_method": true, "class_name": "Pytester", "parameters": ["self"], "calls": ["make_numbered_dir", "self.run", "self._getpytestargs", "isinstance", "ValueError"], "code_location": {"file": "pytester.py", "path": "/data3/pwh/swebench-repos/pytest/src/_pytest", "start_line": 1476, "end_line": 1506}, "code_snippet": "    def runpytest_subprocess(\n        self, *args: str | os.PathLike[str], timeout: float | None = None\n    ) -> RunResult:\n        \"\"\"Run pytest as a subprocess with given arguments.\n\n        Any plugins added to the :py:attr:`plugins` list will be added using the\n        ``-p`` command line option.  Additionally ``--basetemp`` is used to put\n        any temporary files and directories in a numbered directory prefixed\n        with \"runpytest-\" to not conflict with the normal numbered pytest\n        location for temporary files and directories.\n\n        :param args:\n            The sequence of arguments to pass to the pytest subprocess.\n        :param timeout:\n            The period in seconds after which to timeout and raise\n            :py:class:`Pytester.TimeoutExpired`.\n        :returns:\n            The result.\n        \"\"\"\n        __tracebackhide__ = True\n        p = make_numbered_dir(root=self.path, prefix=\"runpytest-\", mode=0o700)\n        args = (f\"--basetemp={p}\", *args)\n        for plugin in self.plugins:\n            if not isinstance(plugin, str):\n                raise ValueError(\n                    f\"Specifying plugins as objects is not supported in pytester subprocess mode; \"\n                    f\"specify by name instead: {plugin}\"\n                )\n            args = (\"-p\", plugin, *args)\n        args = self._getpytestargs() + args\n        return self.run(*args, timeout=timeout)\n", "type": "function"}, {"name": "runpytest", "is_method": true, "class_name": "Pytester", "parameters": ["self"], "calls": ["self._ensure_basetemp", "RuntimeError", "self.runpytest_inprocess", "self.runpytest_subprocess"], "code_location": {"file": "pytester.py", "path": "/data3/pwh/swebench-repos/pytest/src/_pytest", "start_line": 1197, "end_line": 1205}, "code_snippet": "    def runpytest(self, *args: str | os.PathLike[str], **kwargs: Any) -> RunResult:\n        \"\"\"Run pytest inline or in a subprocess, depending on the command line\n        option \"--runpytest\" and return a :py:class:`~pytest.RunResult`.\"\"\"\n        new_args = self._ensure_basetemp(args)\n        if self._method == \"inprocess\":\n            return self.runpytest_inprocess(*new_args, **kwargs)\n        elif self._method == \"subprocess\":\n            return self.runpytest_subprocess(*new_args, **kwargs)\n        raise RuntimeError(f\"Unrecognized runpytest option: {self._method}\")\n", "type": "function"}, {"name": "test_python_minus_m_invocation_fail", "is_method": true, "class_name": "TestInvocationVariants", "parameters": ["self", "pytester"], "calls": ["pytester.makepyfile", "pytester.run", "str"], "code_location": {"file": "acceptance_test.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 630, "end_line": 633}, "code_snippet": "    def test_python_minus_m_invocation_fail(self, pytester: Pytester) -> None:\n        p1 = pytester.makepyfile(\"def test_fail(): 0/0\")\n        res = pytester.run(sys.executable, \"-m\", \"pytest\", str(p1))\n        assert res.ret == 1\n", "type": "function"}, {"name": "test_pytester_run_no_timeout", "is_method": false, "class_name": null, "parameters": ["pytester"], "calls": ["pytester.makepyfile", "pytester.runpytest_subprocess"], "code_location": {"file": "test_pytester.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 444, "end_line": 446}, "code_snippet": "def test_pytester_run_no_timeout(pytester: Pytester) -> None:\n    testfile = pytester.makepyfile(\"def test_no_timeout(): pass\")\n    assert pytester.runpytest_subprocess(testfile).ret == ExitCode.OK\n", "type": "function"}, {"name": "test_pytest_cmdline_main", "is_method": false, "class_name": null, "parameters": ["pytester"], "calls": ["pytester.makepyfile", "subprocess.Popen", "popen.communicate", "popen.wait", "str"], "code_location": {"file": "test_runner.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 912, "end_line": 927}, "code_snippet": "def test_pytest_cmdline_main(pytester: Pytester) -> None:\n    p = pytester.makepyfile(\n        \"\"\"\n        import pytest\n        def test_hello():\n            assert 1\n        if __name__ == '__main__':\n           pytest.cmdline.main([__file__])\n    \"\"\"\n    )\n    import subprocess\n\n    popen = subprocess.Popen([sys.executable, str(p)], stdout=subprocess.PIPE)\n    popen.communicate()\n    ret = popen.wait()\n    assert ret == 0\n", "type": "function"}], "retrieved_count": 10, "cost_time": 0.3377542495727539}
{"question": "Where in the test_attr_hasmarkup function is the hasmarkup attribute of the TerminalWriter instance being bound to control the ANSI escape code injection behavior?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"name": "test_attr_hasmarkup", "is_method": false, "class_name": null, "parameters": [], "calls": ["pytest.mark.skipif", "io.StringIO", "terminalwriter.TerminalWriter", "tw.line", "file.getvalue", "len", "len"], "code_location": {"file": "test_terminalwriter.py", "path": "/data3/pwh/swebench-repos/pytest/testing/io", "start_line": 158, "end_line": 167}, "code_snippet": "def test_attr_hasmarkup() -> None:\n    file = io.StringIO()\n    tw = terminalwriter.TerminalWriter(file)\n    assert not tw.hasmarkup\n    tw.hasmarkup = True\n    tw.line(\"hello\", bold=True)\n    s = file.getvalue()\n    assert len(s) > len(\"hello\\n\")\n    assert \"\\x1b[1m\" in s\n    assert \"\\x1b[0m\" in s\n", "type": "function"}, {"name": "test_terminalwriter_dumb_term_no_markup", "is_method": false, "class_name": null, "parameters": ["monkeypatch"], "calls": ["monkeypatch.setattr", "monkeypatch.context", "m.setattr", "sys.stdout.isatty", "terminalwriter.TerminalWriter", "MyFile"], "code_location": {"file": "test_terminalwriter.py", "path": "/data3/pwh/swebench-repos/pytest/testing/io", "start_line": 41, "end_line": 54}, "code_snippet": "def test_terminalwriter_dumb_term_no_markup(monkeypatch: MonkeyPatch) -> None:\n    monkeypatch.setattr(os, \"environ\", {\"TERM\": \"dumb\", \"PATH\": \"\"})\n\n    class MyFile:\n        closed = False\n\n        def isatty(self):\n            return True\n\n    with monkeypatch.context() as m:\n        m.setattr(sys, \"stdout\", MyFile())\n        assert sys.stdout.isatty()\n        tw = terminalwriter.TerminalWriter()\n        assert not tw.hasmarkup\n", "type": "function"}, {"name": "test_line_write_markup", "is_method": true, "class_name": "TestTerminalWriter", "parameters": ["self", "tw"], "calls": ["tw.line", "tw.write", "tw.getlines", "len", "len"], "code_location": {"file": "test_terminalwriter.py", "path": "/data3/pwh/swebench-repos/pytest/testing/io", "start_line": 140, "end_line": 147}, "code_snippet": "    def test_line_write_markup(self, tw) -> None:\n        tw.hasmarkup = True\n        tw.line(\"x\", bold=True)\n        tw.write(\"x\\n\", red=True)\n        lines = tw.getlines()\n        if sys.platform != \"win32\":\n            assert len(lines[0]) >= 2, lines\n            assert len(lines[1]) >= 2, lines\n", "type": "function"}, {"name": "assert_color", "is_method": false, "class_name": null, "parameters": ["expected", "default"], "calls": ["io.StringIO", "terminalwriter.TerminalWriter", "tw.line", "file.getvalue", "len", "len"], "code_location": {"file": "test_terminalwriter.py", "path": "/data3/pwh/swebench-repos/pytest/testing/io", "start_line": 170, "end_line": 184}, "code_snippet": "def assert_color(expected: bool, default: bool | None = None) -> None:\n    file = io.StringIO()\n    if default is None:\n        default = not expected\n    file.isatty = lambda: default  # type: ignore\n    tw = terminalwriter.TerminalWriter(file=file)\n    assert tw.hasmarkup is expected\n    tw.line(\"hello\", bold=True)\n    s = file.getvalue()\n    if expected:\n        assert len(s) > len(\"hello\\n\")\n        assert \"\\x1b[1m\" in s\n        assert \"\\x1b[0m\" in s\n    else:\n        assert s == \"hello\\n\"\n", "type": "function"}, {"name": "test_markup", "is_method": true, "class_name": "TestTerminalWriter", "parameters": ["self", "tw", "bold", "color"], "calls": ["pytest.mark.skipif", "pytest.mark.parametrize", "pytest.mark.parametrize", "tw.markup"], "code_location": {"file": "test_terminalwriter.py", "path": "/data3/pwh/swebench-repos/pytest/testing/io", "start_line": 130, "end_line": 132}, "code_snippet": "    def test_markup(self, tw, bold: bool, color: str) -> None:\n        text = tw.markup(\"hello\", **{color: True, \"bold\": bold})\n        assert \"hello\" in text\n", "type": "function"}, {"name": "test_code_highlight", "is_method": false, "class_name": null, "parameters": ["has_markup", "code_highlight", "expected", "color_mapping"], "calls": ["pytest.mark.parametrize", "io.StringIO", "terminalwriter.TerminalWriter", "tw._write_source", "splitlines", "color_mapping.format", "pytest.raises", "tw._write_source", "pytest.param", "pytest.param", "pytest.param", "pytest.param", "f.getvalue", "re.escape"], "code_location": {"file": "test_terminalwriter.py", "path": "/data3/pwh/swebench-repos/pytest/testing/io", "start_line": 297, "end_line": 310}, "code_snippet": "def test_code_highlight(has_markup, code_highlight, expected, color_mapping):\n    f = io.StringIO()\n    tw = terminalwriter.TerminalWriter(f)\n    tw.hasmarkup = has_markup\n    tw.code_highlight = code_highlight\n    tw._write_source([\"assert 0\"])\n\n    assert f.getvalue().splitlines(keepends=True) == color_mapping.format([expected])\n\n    with pytest.raises(\n        ValueError,\n        match=re.escape(\"indents size (2) should have same size as lines (1)\"),\n    ):\n        tw._write_source([\"assert 0\"], [\" \", \" \"])\n", "type": "function"}, {"name": "TestTerminalWriter", "docstring": "", "methods": ["tw", "test_line", "test_line_unicode", "test_sep_no_title", "test_sep_with_title", "test_sep_longer_than_width", "test_markup", "test_markup_bad", "test_line_write_markup", "test_attr_fullwidth"], "attributes": [], "code_location": {"file": "test_terminalwriter.py", "path": "/data3/pwh/swebench-repos/pytest/testing/io", "start_line": 69, "end_line": 154}, "type": "class"}, {"name": "test_markup_bad", "is_method": true, "class_name": "TestTerminalWriter", "parameters": ["self", "tw"], "calls": ["pytest.raises", "tw.markup", "pytest.raises", "tw.markup"], "code_location": {"file": "test_terminalwriter.py", "path": "/data3/pwh/swebench-repos/pytest/testing/io", "start_line": 134, "end_line": 138}, "code_snippet": "    def test_markup_bad(self, tw) -> None:\n        with pytest.raises(ValueError):\n            tw.markup(\"x\", wronkw=3)\n        with pytest.raises(ValueError):\n            tw.markup(\"x\", wronkw=0)\n", "type": "function"}, {"name": "test_report_teststatus_explicit_markup", "is_method": true, "class_name": "TestTerminal", "parameters": ["self", "monkeypatch", "pytester", "color_mapping", "category"], "calls": ["pytest.mark.parametrize", "monkeypatch.setenv", "pytester.makeconftest", "pytester.makepyfile", "pytester.runpytest", "result.stdout.fnmatch_lines", "color_mapping.format_for_fnmatch"], "code_location": {"file": "test_terminal.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 355, "end_line": 378}, "code_snippet": "    def test_report_teststatus_explicit_markup(\n        self, monkeypatch: MonkeyPatch, pytester: Pytester, color_mapping, category: str\n    ) -> None:\n        \"\"\"Test that TerminalReporter handles markup explicitly provided by\n        a pytest_report_teststatus hook.\"\"\"\n        monkeypatch.setenv(\"PY_COLORS\", \"1\")\n        pytester.makeconftest(\n            f\"\"\"\n            def pytest_report_teststatus(report):\n                return {category!r}, 'F', ('FOO', {{'red': True}})\n        \"\"\"\n        )\n        pytester.makepyfile(\n            \"\"\"\n            def test_foobar():\n                pass\n        \"\"\"\n        )\n\n        result = pytester.runpytest(\"-v\")\n        assert not result.stderr.lines\n        result.stdout.fnmatch_lines(\n            color_mapping.format_for_fnmatch([\"*{red}FOO{reset}*\"])\n        )\n", "type": "function"}, {"name": "test_terminalwriter_computes_width", "is_method": false, "class_name": null, "parameters": ["monkeypatch"], "calls": ["monkeypatch.setattr", "terminalwriter.TerminalWriter"], "code_location": {"file": "test_terminalwriter.py", "path": "/data3/pwh/swebench-repos/pytest/testing/io", "start_line": 35, "end_line": 38}, "code_snippet": "def test_terminalwriter_computes_width(monkeypatch: MonkeyPatch) -> None:\n    monkeypatch.setattr(terminalwriter, \"get_terminal_width\", lambda: 42)\n    tw = terminalwriter.TerminalWriter()\n    assert tw.fullwidth == 42\n", "type": "function"}], "retrieved_count": 10, "cost_time": 0.39167022705078125}
{"question": "Where is the LocalPath class definition located that implements the comparison operators being tested in test_gt_with_strings, and how does its implementation enable mixed-type comparisons between path objects and strings?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"name": "test_gt_with_strings", "is_method": true, "class_name": "TestLocalPath", "parameters": ["self", "path1"], "calls": ["path1.join", "str", "path1.join", "path1.join", "sorted"], "code_location": {"file": "test_local.py", "path": "/data3/pwh/swebench-repos/pytest/testing/_py", "start_line": 703, "end_line": 712}, "code_snippet": "    def test_gt_with_strings(self, path1):\n        path2 = path1.join(\"sampledir\")\n        path3 = str(path1.join(\"ttt\"))\n        assert path3 > path2\n        assert path2 < path3\n        assert path2 < \"ttt\"\n        assert \"ttt\" > path2\n        path4 = path1.join(\"aaa\")\n        lst = [path2, path4, path3]\n        assert sorted(lst) == [path4, path2, path3]\n", "type": "function"}, {"name": "test_cmp", "is_method": true, "class_name": "CommonFSTests", "parameters": ["self", "path1"], "calls": ["path1.join", "path1.join"], "code_location": {"file": "test_local.py", "path": "/data3/pwh/swebench-repos/pytest/testing/_py", "start_line": 233, "end_line": 237}, "code_snippet": "    def test_cmp(self, path1):\n        path1 = path1.join(\"samplefile\")\n        path2 = path1.join(\"samplefile2\")\n        assert (path1 < path2) == (\"samplefile\" < \"samplefile2\")\n        assert not (path1 < path1)\n", "type": "function"}, {"name": "test_eq_with_strings", "is_method": true, "class_name": "TestLocalPath", "parameters": ["self", "path1"], "calls": ["path1.join", "str", "path1.join"], "code_location": {"file": "test_local.py", "path": "/data3/pwh/swebench-repos/pytest/testing/_py", "start_line": 682, "end_line": 689}, "code_snippet": "    def test_eq_with_strings(self, path1):\n        path1 = path1.join(\"sampledir\")\n        path2 = str(path1)\n        assert path1 == path2\n        assert path2 == path1\n        path3 = path1.join(\"samplefile\")\n        assert path3 != path2\n        assert path2 != path3\n", "type": "function"}, {"name": "test_path_comparison_lowercase_mixed", "is_method": true, "class_name": "TestWINLocalPath", "parameters": ["self", "path1"], "calls": ["path1.join", "path1.join"], "code_location": {"file": "test_local.py", "path": "/data3/pwh/swebench-repos/pytest/testing/_py", "start_line": 1262, "end_line": 1266}, "code_snippet": "    def test_path_comparison_lowercase_mixed(self, path1):\n        t1 = path1.join(\"a_path\")\n        t2 = path1.join(\"A_path\")\n        assert t1 == t1\n        assert t1 == t2\n", "type": "function"}, {"name": "test_eq_hash_are_case_insensitive_on_windows", "is_method": true, "class_name": "TestLocalPath", "parameters": ["self"], "calls": ["pytest.mark.skipif", "local", "local", "hash", "hash", "sys.platform.startswith"], "code_location": {"file": "test_local.py", "path": "/data3/pwh/swebench-repos/pytest/testing/_py", "start_line": 674, "end_line": 680}, "code_snippet": "    def test_eq_hash_are_case_insensitive_on_windows(self):\n        a = local(\"/some/path\")\n        b = local(\"/some/PATH\")\n        assert a == b\n        assert hash(a) == hash(b)\n        assert a in {b}\n        assert a in {b: \"b\"}\n", "type": "function"}, {"name": "test_eq_nonstring", "is_method": true, "class_name": "CommonFSTests", "parameters": ["self", "path1"], "calls": ["path1.join", "path1.join"], "code_location": {"file": "test_local.py", "path": "/data3/pwh/swebench-repos/pytest/testing/_py", "start_line": 31, "end_line": 34}, "code_snippet": "    def test_eq_nonstring(self, path1):\n        p1 = path1.join(\"sampledir\")\n        p2 = path1.join(\"sampledir\")\n        assert p1 == p2\n", "type": "function"}, {"name": "test_fspath_protocol_other_class", "is_method": true, "class_name": "TestLocalPath", "parameters": ["self", "fake_fspath_obj"], "calls": ["local", "fake_fspath_obj.__fspath__", "py_path.check", "os.path.join", "py_path.join"], "code_location": {"file": "test_local.py", "path": "/data3/pwh/swebench-repos/pytest/testing/_py", "start_line": 866, "end_line": 873}, "code_snippet": "    def test_fspath_protocol_other_class(self, fake_fspath_obj):\n        # py.path is always absolute\n        py_path = local(fake_fspath_obj)\n        str_path = fake_fspath_obj.__fspath__()\n        assert py_path.check(endswith=str_path)\n        assert py_path.join(fake_fspath_obj).strpath == os.path.join(\n            py_path.strpath, str_path\n        )\n", "type": "function"}, {"name": "__gt__", "is_method": true, "class_name": "LocalPath", "parameters": ["self", "other"], "calls": ["os.fspath", "os.fspath"], "code_location": {"file": "path.py", "path": "/data3/pwh/swebench-repos/pytest/src/_pytest/_py", "start_line": 582, "end_line": 583}, "code_snippet": "    def __gt__(self, other):\n        return os.fspath(self) > os.fspath(other)\n", "type": "function"}, {"name": "test_eq_with_none", "is_method": true, "class_name": "TestLocalPath", "parameters": ["self", "path1"], "calls": [], "code_location": {"file": "test_local.py", "path": "/data3/pwh/swebench-repos/pytest/testing/_py", "start_line": 691, "end_line": 692}, "code_snippet": "    def test_eq_with_none(self, path1):\n        assert path1 != None  # noqa: E711\n", "type": "function"}, {"name": "test_constructor_equality", "is_method": true, "class_name": "CommonFSTests", "parameters": ["self", "path1"], "calls": ["path1.__class__"], "code_location": {"file": "test_local.py", "path": "/data3/pwh/swebench-repos/pytest/testing/_py", "start_line": 27, "end_line": 29}, "code_snippet": "    def test_constructor_equality(self, path1):\n        p = path1.__class__(path1)\n        assert p == path1\n", "type": "function"}], "retrieved_count": 10, "cost_time": 0.38314032554626465}
{"question": "Where does the MockTiming.patch method's delegation to monkeypatch.setattr establish the interception points for timing module functions, and what is the relationship between the three separate setattr calls in terms of their execution order and potential side effects on the timing module's state?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"name": "patch", "is_method": true, "class_name": "MockTiming", "parameters": ["self", "monkeypatch"], "calls": ["monkeypatch.setattr", "monkeypatch.setattr", "monkeypatch.setattr"], "code_location": {"file": "timing.py", "path": "/data3/pwh/swebench-repos/pytest/src/_pytest", "start_line": 86, "end_line": 91}, "code_snippet": "    def patch(self, monkeypatch: MonkeyPatch) -> None:\n        from _pytest import timing  # noqa: PLW0406\n\n        monkeypatch.setattr(timing, \"sleep\", self.sleep)\n        monkeypatch.setattr(timing, \"time\", self.time)\n        monkeypatch.setattr(timing, \"perf_counter\", self.time)\n", "type": "function"}, {"name": "MockTiming", "docstring": "Mocks _pytest.timing with a known object that can be used to control timing in tests\ndeterministically.\n\npytest itself should always use functions from `_pytest.timing` instead of `time` directly.\n\nThis then allows us more control over time during testing, if testing code also\nuses `_pytest.timing` functions.\n\nTime is static, and only advances through `sleep` calls, thus tests might sleep over large\nnumbers and obtain accurate time() calls at the end, making tests reliable and instant.", "methods": ["sleep", "time", "patch"], "attributes": [], "code_location": {"file": "timing.py", "path": "/data3/pwh/swebench-repos/pytest/src/_pytest", "start_line": 66, "end_line": 91}, "type": "class"}, {"name": "mock_timing", "is_method": false, "class_name": null, "parameters": ["monkeypatch"], "calls": ["MockTiming", "result.patch"], "code_location": {"file": "conftest.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 223, "end_line": 239}, "code_snippet": "def mock_timing(monkeypatch: MonkeyPatch):\n    \"\"\"Mocks _pytest.timing with a known object that can be used to control timing in tests\n    deterministically.\n\n    pytest itself should always use functions from `_pytest.timing` instead of `time` directly.\n\n    This then allows us more control over time during testing, if testing code also\n    uses `_pytest.timing` functions.\n\n    Time is static, and only advances through `sleep` calls, thus tests might sleep over large\n    numbers and obtain accurate time() calls at the end, making tests reliable and instant.\n    \"\"\"\n    from _pytest.timing import MockTiming\n\n    result = MockTiming()\n    result.patch(monkeypatch)\n    return result\n", "type": "function"}, {"name": "test_context", "is_method": false, "class_name": null, "parameters": [], "calls": ["MonkeyPatch", "inspect.isclass", "monkeypatch.context", "m.setattr", "inspect.isclass"], "code_location": {"file": "test_monkeypatch.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 411, "end_line": 420}, "code_snippet": "def test_context() -> None:\n    monkeypatch = MonkeyPatch()\n\n    import functools\n    import inspect\n\n    with monkeypatch.context() as m:\n        m.setattr(functools, \"partial\", 3)\n        assert not inspect.isclass(functools.partial)\n    assert inspect.isclass(functools.partial)  # type:ignore[unreachable]\n", "type": "function"}, {"name": "mp", "is_method": false, "class_name": null, "parameters": [], "calls": ["os.getcwd", "list", "os.chdir", "MonkeyPatch"], "code_location": {"file": "test_monkeypatch.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 19, "end_line": 24}, "code_snippet": "def mp() -> Generator[MonkeyPatch]:\n    cwd = os.getcwd()\n    sys_path = list(sys.path)\n    yield MonkeyPatch()\n    sys.path[:] = sys_path\n    os.chdir(cwd)\n", "type": "function"}, {"name": "monkeypatch", "is_method": true, "class_name": "Testdir", "parameters": ["self"], "calls": [], "code_location": {"file": "legacypath.py", "path": "/data3/pwh/swebench-repos/pytest/src/_pytest", "start_line": 81, "end_line": 82}, "code_snippet": "    def monkeypatch(self) -> MonkeyPatch:\n        return self._pytester._monkeypatch\n", "type": "function"}, {"name": "MonkeyPatch", "docstring": "Helper to conveniently monkeypatch attributes/items/environment\nvariables/syspath.\n\nReturned by the :fixture:`monkeypatch` fixture.\n\n.. versionchanged:: 6.2\n    Can now also be used directly as `pytest.MonkeyPatch()`, for when\n    the fixture is not available. In this case, use\n    :meth:`with MonkeyPatch.context() as mp: <context>` or remember to call\n    :meth:`undo` explicitly.", "methods": ["__init__", "context", "setattr", "setattr", "setattr", "delattr", "setitem", "delitem", "setenv", "delenv", "syspath_prepend", "chdir", "undo"], "attributes": [], "code_location": {"file": "monkeypatch.py", "path": "/data3/pwh/swebench-repos/pytest/src/_pytest", "start_line": 117, "end_line": 415}, "type": "class"}, {"name": "test_context_classmethod", "is_method": false, "class_name": null, "parameters": [], "calls": ["MonkeyPatch.context", "m.setattr"], "code_location": {"file": "test_monkeypatch.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 423, "end_line": 430}, "code_snippet": "def test_context_classmethod() -> None:\n    class A:\n        x = 1\n\n    with MonkeyPatch.context() as m:\n        m.setattr(A, \"x\", 2)\n        assert A.x == 2\n    assert A.x == 1\n", "type": "function"}, {"name": "setup_imports_tracking", "is_method": true, "class_name": "TestNamespacePackages", "parameters": ["self", "monkeypatch"], "calls": ["pytest.fixture", "monkeypatch.setattr"], "code_location": {"file": "test_pathlib.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 1380, "end_line": 1381}, "code_snippet": "    def setup_imports_tracking(self, monkeypatch: MonkeyPatch) -> None:\n        monkeypatch.setattr(sys, \"pytest_namespace_packages_test\", [], raising=False)\n", "type": "function"}, {"name": "test_string_expression", "is_method": true, "class_name": "TestSetattrWithImportPath", "parameters": ["self", "monkeypatch"], "calls": ["monkeypatch.context", "mp.setattr", "os.path.abspath"], "code_location": {"file": "test_monkeypatch.py", "path": "/data3/pwh/swebench-repos/pytest/testing", "start_line": 55, "end_line": 58}, "code_snippet": "    def test_string_expression(self, monkeypatch: MonkeyPatch) -> None:\n        with monkeypatch.context() as mp:\n            mp.setattr(\"os.path.abspath\", lambda x: \"hello2\")\n            assert os.path.abspath(\"123\") == \"hello2\"\n", "type": "function"}], "retrieved_count": 10, "cost_time": 0.49126434326171875}
