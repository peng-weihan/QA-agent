{"question": "What is Requests' adapter system?", "answer": null, "relative_code_list": null, "ground_truth": "Requests' adapter system (src/requests/adapters.py) provides a transport abstraction layer that separates HTTP client logic from the underlying transport mechanism. The system consists of: 1) BaseAdapter - an abstract base class defining the interface for transport adapters with send() and close() methods; 2) HTTPAdapter - the main implementation that wraps urllib3's PoolManager for HTTP/HTTPS connections, providing connection pooling, retry logic, and proxy support; 3) Adapter mounting - Sessions can mount different adapters for different URL schemes (http://, https://, etc.) allowing customization of transport behavior per protocol. The adapter system enables Requests to abstract away the complexity of connection management, pooling, and retries while allowing users to customize transport behavior by implementing custom adapters or configuring the built-in HTTPAdapter with different pool sizes, retry policies, and connection parameters.", "score": null, "retrieved_content": [{"start_line": 3000, "end_line": 5000, "belongs_to": {"file_name": "adapters.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "     \"host\": parsed_request_url.hostname,\n        \"port\": port,\n    }\n    return host_params, pool_kwargs\n\n\nclass BaseAdapter:\n    \"\"\"The Base Transport Adapter\"\"\"\n\n    def __init__(self):\n        super().__init__()\n\n    def send(\n        self, request, stream=False, timeout=None, verify=True, cert=None, proxies=None\n    ):\n        \"\"\"Sends PreparedRequest object. Returns Response object.\n\n        :param request: The :class:`PreparedRequest <PreparedRequest>` being sent.\n        :param stream: (optional) Whether to stream the request content.\n        :param timeout: (optional) How long to wait for the server to send\n            data before giving up, as a float, or a :ref:`(connect timeout,\n            read timeout) <timeouts>` tuple.\n        :type timeout: float or tuple\n        :param verify: (optional) Either a boolean, in which case it controls whether we verify\n            the server's TLS certificate, or a string, in which case it must be a path\n            to a CA bundle to use\n        :param cert: (optional) Any user-provided SSL certificate to be trusted.\n        :param proxies: (optional) The proxies dictionary to apply to the request.\n        \"\"\"\n        raise NotImplementedError\n\n    def close(self):\n        \"\"\"Cleans up adapter specific items.\"\"\"\n        raise NotImplementedError\n\n\nclass HTTPAdapter(BaseAdapter):\n    \"\"\"The built-in HTTP Adapter for urllib3.\n\n    Provides a general-case interface for Requests sessions to contact HTTP and\n    HTTPS urls by implementing the Transport Adapter interface. This class will\n    usually be created by the :class:`Session <Session>` class under the\n    covers.\n\n    :param pool_connections: The number of urllib3 connection pools to cache.\n    :param pool_maxsize: The maximum number of connections to save in the pool.\n    :param max_retries: The maximum number of retries each connection\n        should attempt. Note, this applies only to failed DNS lookups, socket\n        connections and connection timeouts, never to"}, {"start_line": 29000, "end_line": 30503, "belongs_to": {"file_name": "sessions.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "nnection adapter for the given URL.\n\n        :rtype: requests.adapters.BaseAdapter\n        \"\"\"\n        for prefix, adapter in self.adapters.items():\n            if url.lower().startswith(prefix.lower()):\n                return adapter\n\n        # Nothing matches :-/\n        raise InvalidSchema(f\"No connection adapters were found for {url!r}\")\n\n    def close(self):\n        \"\"\"Closes all adapters and as such the session\"\"\"\n        for v in self.adapters.values():\n            v.close()\n\n    def mount(self, prefix, adapter):\n        \"\"\"Registers a connection adapter to a prefix.\n\n        Adapters are sorted in descending order by prefix length.\n        \"\"\"\n        self.adapters[prefix] = adapter\n        keys_to_move = [k for k in self.adapters if len(k) < len(prefix)]\n\n        for key in keys_to_move:\n            self.adapters[key] = self.adapters.pop(key)\n\n    def __getstate__(self):\n        state = {attr: getattr(self, attr, None) for attr in self.__attrs__}\n        return state\n\n    def __setstate__(self, state):\n        for attr, value in state.items():\n            setattr(self, attr, value)\n\n\ndef session():\n    \"\"\"\n    Returns a :class:`Session` for context-management.\n\n    .. deprecated:: 1.0.0\n\n        This method has been deprecated since version 1.0.0 and is only kept for\n        backwards compatibility. New code should use :class:`~requests.sessions.Session`\n        to create a session. This may be removed at a future date.\n\n    :rtype: Session\n    \"\"\"\n    return Session()\n"}, {"start_line": 5000, "end_line": 7000, "belongs_to": {"file_name": "adapters.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": " requests where data has\n        made it to the server. By default, Requests does not retry failed\n        connections. If you need granular control over the conditions under\n        which we retry a request, import urllib3's ``Retry`` class and pass\n        that instead.\n    :param pool_block: Whether the connection pool should block for connections.\n\n    Usage::\n\n      >>> import requests\n      >>> s = requests.Session()\n      >>> a = requests.adapters.HTTPAdapter(max_retries=3)\n      >>> s.mount('http://', a)\n    \"\"\"\n\n    __attrs__ = [\n        \"max_retries\",\n        \"config\",\n        \"_pool_connections\",\n        \"_pool_maxsize\",\n        \"_pool_block\",\n    ]\n\n    def __init__(\n        self,\n        pool_connections=DEFAULT_POOLSIZE,\n        pool_maxsize=DEFAULT_POOLSIZE,\n        max_retries=DEFAULT_RETRIES,\n        pool_block=DEFAULT_POOLBLOCK,\n    ):\n        if max_retries == DEFAULT_RETRIES:\n            self.max_retries = Retry(0, read=False)\n        else:\n            self.max_retries = Retry.from_int(max_retries)\n        self.config = {}\n        self.proxy_manager = {}\n\n        super().__init__()\n\n        self._pool_connections = pool_connections\n        self._pool_maxsize = pool_maxsize\n        self._pool_block = pool_block\n\n        self.init_poolmanager(pool_connections, pool_maxsize, block=pool_block)\n\n    def __getstate__(self):\n        return {attr: getattr(self, attr, None) for attr in self.__attrs__}\n\n    def __setstate__(self, state):\n        # Can't handle by adding 'proxy_manager' to self.__attrs__ because\n        # self.poolmanager uses a lambda function, which isn't pickleable.\n        self.proxy_manager = {}\n        self.config = {}\n\n        for attr, value in state.items():\n            setattr(self, attr, value)\n\n        self.init_poolmanager(\n            self._pool_connections, self._pool_maxsize, block=self._pool_block\n        )\n\n    def init_poolmanager(\n        self, connections, maxsize, block=DEFAULT_POOLBLOCK, **pool_kwargs\n    ):\n        \""}, {"start_line": 28000, "end_line": 30000, "belongs_to": {"file_name": "sessions.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "vironment's proxies.\n            no_proxy = proxies.get(\"no_proxy\") if proxies is not None else None\n            env_proxies = get_environ_proxies(url, no_proxy=no_proxy)\n            for k, v in env_proxies.items():\n                proxies.setdefault(k, v)\n\n            # Look for requests environment configuration\n            # and be compatible with cURL.\n            if verify is True or verify is None:\n                verify = (\n                    os.environ.get(\"REQUESTS_CA_BUNDLE\")\n                    or os.environ.get(\"CURL_CA_BUNDLE\")\n                    or verify\n                )\n\n        # Merge all the kwargs.\n        proxies = merge_setting(proxies, self.proxies)\n        stream = merge_setting(stream, self.stream)\n        verify = merge_setting(verify, self.verify)\n        cert = merge_setting(cert, self.cert)\n\n        return {\"proxies\": proxies, \"stream\": stream, \"verify\": verify, \"cert\": cert}\n\n    def get_adapter(self, url):\n        \"\"\"\n        Returns the appropriate connection adapter for the given URL.\n\n        :rtype: requests.adapters.BaseAdapter\n        \"\"\"\n        for prefix, adapter in self.adapters.items():\n            if url.lower().startswith(prefix.lower()):\n                return adapter\n\n        # Nothing matches :-/\n        raise InvalidSchema(f\"No connection adapters were found for {url!r}\")\n\n    def close(self):\n        \"\"\"Closes all adapters and as such the session\"\"\"\n        for v in self.adapters.values():\n            v.close()\n\n    def mount(self, prefix, adapter):\n        \"\"\"Registers a connection adapter to a prefix.\n\n        Adapters are sorted in descending order by prefix length.\n        \"\"\"\n        self.adapters[prefix] = adapter\n        keys_to_move = [k for k in self.adapters if len(k) < len(prefix)]\n\n        for key in keys_to_move:\n            self.adapters[key] = self.adapters.pop(key)\n\n    def __getstate__(self):\n        state = {attr: getattr(self, attr, None) for attr in self.__attrs__}\n        return state\n\n    def "}, {"start_line": 0, "end_line": 2000, "belongs_to": {"file_name": "adapters.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "\"\"\"\nrequests.adapters\n~~~~~~~~~~~~~~~~~\n\nThis module contains the transport adapters that Requests uses to define\nand maintain connections.\n\"\"\"\n\nimport os.path\nimport socket  # noqa: F401\nimport typing\nimport warnings\n\nfrom urllib3.exceptions import ClosedPoolError, ConnectTimeoutError\nfrom urllib3.exceptions import HTTPError as _HTTPError\nfrom urllib3.exceptions import InvalidHeader as _InvalidHeader\nfrom urllib3.exceptions import (\n    LocationValueError,\n    MaxRetryError,\n    NewConnectionError,\n    ProtocolError,\n)\nfrom urllib3.exceptions import ProxyError as _ProxyError\nfrom urllib3.exceptions import ReadTimeoutError, ResponseError\nfrom urllib3.exceptions import SSLError as _SSLError\nfrom urllib3.poolmanager import PoolManager, proxy_from_url\nfrom urllib3.util import Timeout as TimeoutSauce\nfrom urllib3.util import parse_url\nfrom urllib3.util.retry import Retry\n\nfrom .auth import _basic_auth_str\nfrom .compat import basestring, urlparse\nfrom .cookies import extract_cookies_to_jar\nfrom .exceptions import (\n    ConnectionError,\n    ConnectTimeout,\n    InvalidHeader,\n    InvalidProxyURL,\n    InvalidSchema,\n    InvalidURL,\n    ProxyError,\n    ReadTimeout,\n    RetryError,\n    SSLError,\n)\nfrom .models import Response\nfrom .structures import CaseInsensitiveDict\nfrom .utils import (\n    DEFAULT_CA_BUNDLE_PATH,\n    extract_zipped_paths,\n    get_auth_from_url,\n    get_encoding_from_headers,\n    prepend_scheme_if_needed,\n    select_proxy,\n    urldefragauth,\n)\n\ntry:\n    from urllib3.contrib.socks import SOCKSProxyManager\nexcept ImportError:\n\n    def SOCKSProxyManager(*args, **kwargs):\n        raise InvalidSchema(\"Missing dependencies for SOCKS support.\")\n\n\nif typing.TYPE_CHECKING:\n    from .models import PreparedRequest\n\n\nDEFAULT_POOLBLOCK = False\nDEFAULT_POOLSIZE = 10\nDEFAULT_RETRIES = 0\nDEFAULT_POOL_TIMEOUT = None\n\n\ndef _urllib3_request_context(\n    request: \"PreparedRequest\",\n    verify: \"bool | str | None\",\n    client_cert: \"typing.Tuple[str, str] | str | None\",\n    po"}, {"start_line": 4000, "end_line": 6000, "belongs_to": {"file_name": "adapters.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "        :param cert: (optional) Any user-provided SSL certificate to be trusted.\n        :param proxies: (optional) The proxies dictionary to apply to the request.\n        \"\"\"\n        raise NotImplementedError\n\n    def close(self):\n        \"\"\"Cleans up adapter specific items.\"\"\"\n        raise NotImplementedError\n\n\nclass HTTPAdapter(BaseAdapter):\n    \"\"\"The built-in HTTP Adapter for urllib3.\n\n    Provides a general-case interface for Requests sessions to contact HTTP and\n    HTTPS urls by implementing the Transport Adapter interface. This class will\n    usually be created by the :class:`Session <Session>` class under the\n    covers.\n\n    :param pool_connections: The number of urllib3 connection pools to cache.\n    :param pool_maxsize: The maximum number of connections to save in the pool.\n    :param max_retries: The maximum number of retries each connection\n        should attempt. Note, this applies only to failed DNS lookups, socket\n        connections and connection timeouts, never to requests where data has\n        made it to the server. By default, Requests does not retry failed\n        connections. If you need granular control over the conditions under\n        which we retry a request, import urllib3's ``Retry`` class and pass\n        that instead.\n    :param pool_block: Whether the connection pool should block for connections.\n\n    Usage::\n\n      >>> import requests\n      >>> s = requests.Session()\n      >>> a = requests.adapters.HTTPAdapter(max_retries=3)\n      >>> s.mount('http://', a)\n    \"\"\"\n\n    __attrs__ = [\n        \"max_retries\",\n        \"config\",\n        \"_pool_connections\",\n        \"_pool_maxsize\",\n        \"_pool_block\",\n    ]\n\n    def __init__(\n        self,\n        pool_connections=DEFAULT_POOLSIZE,\n        pool_maxsize=DEFAULT_POOLSIZE,\n        max_retries=DEFAULT_RETRIES,\n        pool_block=DEFAULT_POOLBLOCK,\n    ):\n        if max_retries == DEFAULT_RETRIES:\n            self.max_retries = Retry(0, read=False)\n        else:\n            self.max_retr"}, {"start_line": 58000, "end_line": 60000, "belongs_to": {"file_name": "test_requests.py", "upper_path": "/data2/raymone/swebench-repos/requests/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "http://\": HTTPAdapter()}\n        s2.mount(\"https://\", HTTPAdapter())\n        assert \"http://\" in s2.adapters\n        assert \"https://\" in s2.adapters\n\n    def test_session_get_adapter_prefix_matching(self):\n        prefix = \"https://example.com\"\n        more_specific_prefix = prefix + \"/some/path\"\n\n        url_matching_only_prefix = prefix + \"/another/path\"\n        url_matching_more_specific_prefix = more_specific_prefix + \"/longer/path\"\n        url_not_matching_prefix = \"https://another.example.com/\"\n\n        s = requests.Session()\n        prefix_adapter = HTTPAdapter()\n        more_specific_prefix_adapter = HTTPAdapter()\n        s.mount(prefix, prefix_adapter)\n        s.mount(more_specific_prefix, more_specific_prefix_adapter)\n\n        assert s.get_adapter(url_matching_only_prefix) is prefix_adapter\n        assert (\n            s.get_adapter(url_matching_more_specific_prefix)\n            is more_specific_prefix_adapter\n        )\n        assert s.get_adapter(url_not_matching_prefix) not in (\n            prefix_adapter,\n            more_specific_prefix_adapter,\n        )\n\n    def test_session_get_adapter_prefix_matching_mixed_case(self):\n        mixed_case_prefix = \"hTtPs://eXamPle.CoM/MixEd_CAse_PREfix\"\n        url_matching_prefix = mixed_case_prefix + \"/full_url\"\n\n        s = requests.Session()\n        my_adapter = HTTPAdapter()\n        s.mount(mixed_case_prefix, my_adapter)\n\n        assert s.get_adapter(url_matching_prefix) is my_adapter\n\n    def test_session_get_adapter_prefix_matching_is_case_insensitive(self):\n        mixed_case_prefix = \"hTtPs://eXamPle.CoM/MixEd_CAse_PREfix\"\n        url_matching_prefix_with_different_case = (\n            \"HtTpS://exaMPLe.cOm/MiXeD_caSE_preFIX/another_url\"\n        )\n\n        s = requests.Session()\n        my_adapter = HTTPAdapter()\n        s.mount(mixed_case_prefix, my_adapter)\n\n        assert s.get_adapter(url_matching_prefix_with_different_case) is my_adapter\n\n    def test_session_get_adapter_prefix_with_trailing_slash(self"}, {"start_line": 57000, "end_line": 59000, "belongs_to": {"file_name": "test_requests.py", "upper_path": "/data2/raymone/swebench-repos/requests/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": ".mount(\"http://git\", HTTPAdapter())\n        s.mount(\"http://github\", HTTPAdapter())\n        s.mount(\"http://github.com\", HTTPAdapter())\n        s.mount(\"http://github.com/about/\", HTTPAdapter())\n        order = [\n            \"http://github.com/about/\",\n            \"http://github.com\",\n            \"http://github\",\n            \"http://git\",\n            \"https://\",\n            \"http://\",\n        ]\n        assert order == list(s.adapters)\n        s.mount(\"http://gittip\", HTTPAdapter())\n        s.mount(\"http://gittip.com\", HTTPAdapter())\n        s.mount(\"http://gittip.com/about/\", HTTPAdapter())\n        order = [\n            \"http://github.com/about/\",\n            \"http://gittip.com/about/\",\n            \"http://github.com\",\n            \"http://gittip.com\",\n            \"http://github\",\n            \"http://gittip\",\n            \"http://git\",\n            \"https://\",\n            \"http://\",\n        ]\n        assert order == list(s.adapters)\n        s2 = requests.Session()\n        s2.adapters = {\"http://\": HTTPAdapter()}\n        s2.mount(\"https://\", HTTPAdapter())\n        assert \"http://\" in s2.adapters\n        assert \"https://\" in s2.adapters\n\n    def test_session_get_adapter_prefix_matching(self):\n        prefix = \"https://example.com\"\n        more_specific_prefix = prefix + \"/some/path\"\n\n        url_matching_only_prefix = prefix + \"/another/path\"\n        url_matching_more_specific_prefix = more_specific_prefix + \"/longer/path\"\n        url_not_matching_prefix = \"https://another.example.com/\"\n\n        s = requests.Session()\n        prefix_adapter = HTTPAdapter()\n        more_specific_prefix_adapter = HTTPAdapter()\n        s.mount(prefix, prefix_adapter)\n        s.mount(more_specific_prefix, more_specific_prefix_adapter)\n\n        assert s.get_adapter(url_matching_only_prefix) is prefix_adapter\n        assert (\n            s.get_adapter(url_matching_more_specific_prefix)\n            is more_specific_prefix_adapter\n        )\n        assert s.get_adapter(url_not_matching_prefix) n"}, {"start_line": 21000, "end_line": 23000, "belongs_to": {"file_name": "adapters.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "ters.HTTPAdapter>`.\n\n        This should not be called from user code, and is only exposed for use\n        when subclassing the\n        :class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.\n\n        :param request: The :class:`PreparedRequest <PreparedRequest>` to add headers to.\n        :param kwargs: The keyword arguments from the call to send().\n        \"\"\"\n        pass\n\n    def proxy_headers(self, proxy):\n        \"\"\"Returns a dictionary of the headers to add to any request sent\n        through a proxy. This works with urllib3 magic to ensure that they are\n        correctly sent to the proxy, rather than in a tunnelled request if\n        CONNECT is being used.\n\n        This should not be called from user code, and is only exposed for use\n        when subclassing the\n        :class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.\n\n        :param proxy: The url of the proxy being used for this request.\n        :rtype: dict\n        \"\"\"\n        headers = {}\n        username, password = get_auth_from_url(proxy)\n\n        if username:\n            headers[\"Proxy-Authorization\"] = _basic_auth_str(username, password)\n\n        return headers\n\n    def send(\n        self, request, stream=False, timeout=None, verify=True, cert=None, proxies=None\n    ):\n        \"\"\"Sends PreparedRequest object. Returns Response object.\n\n        :param request: The :class:`PreparedRequest <PreparedRequest>` being sent.\n        :param stream: (optional) Whether to stream the request content.\n        :param timeout: (optional) How long to wait for the server to send\n            data before giving up, as a float, or a :ref:`(connect timeout,\n            read timeout) <timeouts>` tuple.\n        :type timeout: float or tuple or urllib3 Timeout object\n        :param verify: (optional) Either a boolean, in which case it controls whether\n            we verify the server's TLS certificate, or a string, in which case it\n            must be a path to a CA bundle to use\n        :param cert: (optional) Any user"}, {"start_line": 2000, "end_line": 4000, "belongs_to": {"file_name": "adapters.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "olmanager: \"PoolManager\",\n) -> \"(typing.Dict[str, typing.Any], typing.Dict[str, typing.Any])\":\n    host_params = {}\n    pool_kwargs = {}\n    parsed_request_url = urlparse(request.url)\n    scheme = parsed_request_url.scheme.lower()\n    port = parsed_request_url.port\n\n    cert_reqs = \"CERT_REQUIRED\"\n    if verify is False:\n        cert_reqs = \"CERT_NONE\"\n    elif isinstance(verify, str):\n        if not os.path.isdir(verify):\n            pool_kwargs[\"ca_certs\"] = verify\n        else:\n            pool_kwargs[\"ca_cert_dir\"] = verify\n    pool_kwargs[\"cert_reqs\"] = cert_reqs\n    if client_cert is not None:\n        if isinstance(client_cert, tuple) and len(client_cert) == 2:\n            pool_kwargs[\"cert_file\"] = client_cert[0]\n            pool_kwargs[\"key_file\"] = client_cert[1]\n        else:\n            # According to our docs, we allow users to specify just the client\n            # cert path\n            pool_kwargs[\"cert_file\"] = client_cert\n    host_params = {\n        \"scheme\": scheme,\n        \"host\": parsed_request_url.hostname,\n        \"port\": port,\n    }\n    return host_params, pool_kwargs\n\n\nclass BaseAdapter:\n    \"\"\"The Base Transport Adapter\"\"\"\n\n    def __init__(self):\n        super().__init__()\n\n    def send(\n        self, request, stream=False, timeout=None, verify=True, cert=None, proxies=None\n    ):\n        \"\"\"Sends PreparedRequest object. Returns Response object.\n\n        :param request: The :class:`PreparedRequest <PreparedRequest>` being sent.\n        :param stream: (optional) Whether to stream the request content.\n        :param timeout: (optional) How long to wait for the server to send\n            data before giving up, as a float, or a :ref:`(connect timeout,\n            read timeout) <timeouts>` tuple.\n        :type timeout: float or tuple\n        :param verify: (optional) Either a boolean, in which case it controls whether we verify\n            the server's TLS certificate, or a string, in which case it must be a path\n            to a CA bundle to use\n"}], "retrieved_count": 10, "cost_time": 3.52021861076355}
{"question": "What is the role of the Response class in Requests' HTTP response handling?", "answer": null, "relative_code_list": null, "ground_truth": "The Response class (src/requests/models.py) serves as the primary interface for handling HTTP responses in Requests. Its role includes: 1) Response encapsulation - wraps the raw HTTP response from the transport layer with a user-friendly interface; 2) Content access - provides multiple ways to access response content (content, text, json properties) with automatic encoding detection and decoding; 3) Header management - offers case-insensitive header access through the headers attribute; 4) Status handling - provides status_code, reason, and ok properties for response status evaluation; 5) Cookie extraction - automatically extracts and stores cookies from Set-Cookie headers in the cookies attribute; 6) Redirect support - tracks redirect history and provides is_redirect, is_permanent_redirect properties; 7) Streaming support - enables content streaming through iter_content() and raw file-like access; 8) Context management - implements context manager protocol for automatic resource cleanup; 9) Error checking - provides raise_for_status() method for automatic HTTP error detection; 10) Request reference - maintains reference to the original PreparedRequest for debugging and analysis. The Response class acts as the bridge between the low-level transport layer and the high-level user interface, providing a consistent API regardless of the underlying transport mechanism.", "score": null, "retrieved_content": [{"start_line": 21000, "end_line": 23000, "belongs_to": {"file_name": "models.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "nse>` object, which contains a\n    server's response to an HTTP request.\n    \"\"\"\n\n    __attrs__ = [\n        \"_content\",\n        \"status_code\",\n        \"headers\",\n        \"url\",\n        \"history\",\n        \"encoding\",\n        \"reason\",\n        \"cookies\",\n        \"elapsed\",\n        \"request\",\n    ]\n\n    def __init__(self):\n        self._content = False\n        self._content_consumed = False\n        self._next = None\n\n        #: Integer Code of responded HTTP Status, e.g. 404 or 200.\n        self.status_code = None\n\n        #: Case-insensitive Dictionary of Response Headers.\n        #: For example, ``headers['content-encoding']`` will return the\n        #: value of a ``'Content-Encoding'`` response header.\n        self.headers = CaseInsensitiveDict()\n\n        #: File-like object representation of response (for advanced usage).\n        #: Use of ``raw`` requires that ``stream=True`` be set on the request.\n        #: This requirement does not apply for use internally to Requests.\n        self.raw = None\n\n        #: Final URL location of Response.\n        self.url = None\n\n        #: Encoding to decode with when accessing r.text.\n        self.encoding = None\n\n        #: A list of :class:`Response <Response>` objects from\n        #: the history of the Request. Any redirect responses will end\n        #: up here. The list is sorted from the oldest to the most recent request.\n        self.history = []\n\n        #: Textual reason of responded HTTP Status, e.g. \"Not Found\" or \"OK\".\n        self.reason = None\n\n        #: A CookieJar of Cookies the server sent back.\n        self.cookies = cookiejar_from_dict({})\n\n        #: The amount of time elapsed between sending the request\n        #: and the arrival of the response (as a timedelta).\n        #: This property specifically measures the time taken between sending\n        #: the first byte of the request and finishing parsing the headers. It\n        #: is therefore unaffected by consuming the response content or the\n        #: value"}, {"start_line": 22000, "end_line": 24000, "belongs_to": {"file_name": "models.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "f.raw = None\n\n        #: Final URL location of Response.\n        self.url = None\n\n        #: Encoding to decode with when accessing r.text.\n        self.encoding = None\n\n        #: A list of :class:`Response <Response>` objects from\n        #: the history of the Request. Any redirect responses will end\n        #: up here. The list is sorted from the oldest to the most recent request.\n        self.history = []\n\n        #: Textual reason of responded HTTP Status, e.g. \"Not Found\" or \"OK\".\n        self.reason = None\n\n        #: A CookieJar of Cookies the server sent back.\n        self.cookies = cookiejar_from_dict({})\n\n        #: The amount of time elapsed between sending the request\n        #: and the arrival of the response (as a timedelta).\n        #: This property specifically measures the time taken between sending\n        #: the first byte of the request and finishing parsing the headers. It\n        #: is therefore unaffected by consuming the response content or the\n        #: value of the ``stream`` keyword argument.\n        self.elapsed = datetime.timedelta(0)\n\n        #: The :class:`PreparedRequest <PreparedRequest>` object to which this\n        #: is a response.\n        self.request = None\n\n    def __enter__(self):\n        return self\n\n    def __exit__(self, *args):\n        self.close()\n\n    def __getstate__(self):\n        # Consume everything; accessing the content attribute makes\n        # sure the content has been fully read.\n        if not self._content_consumed:\n            self.content\n\n        return {attr: getattr(self, attr, None) for attr in self.__attrs__}\n\n    def __setstate__(self, state):\n        for name, value in state.items():\n            setattr(self, name, value)\n\n        # pickled objects do not have .raw\n        setattr(self, \"_content_consumed\", True)\n        setattr(self, \"raw\", None)\n\n    def __repr__(self):\n        return f\"<Response [{self.status_code}]>\"\n\n    def __bool__(self):\n        \"\"\"Returns True if :attr:`status_code` is less"}, {"start_line": 23000, "end_line": 25000, "belongs_to": {"file_name": "models.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": " of the ``stream`` keyword argument.\n        self.elapsed = datetime.timedelta(0)\n\n        #: The :class:`PreparedRequest <PreparedRequest>` object to which this\n        #: is a response.\n        self.request = None\n\n    def __enter__(self):\n        return self\n\n    def __exit__(self, *args):\n        self.close()\n\n    def __getstate__(self):\n        # Consume everything; accessing the content attribute makes\n        # sure the content has been fully read.\n        if not self._content_consumed:\n            self.content\n\n        return {attr: getattr(self, attr, None) for attr in self.__attrs__}\n\n    def __setstate__(self, state):\n        for name, value in state.items():\n            setattr(self, name, value)\n\n        # pickled objects do not have .raw\n        setattr(self, \"_content_consumed\", True)\n        setattr(self, \"raw\", None)\n\n    def __repr__(self):\n        return f\"<Response [{self.status_code}]>\"\n\n    def __bool__(self):\n        \"\"\"Returns True if :attr:`status_code` is less than 400.\n\n        This attribute checks if the status code of the response is between\n        400 and 600 to see if there was a client error or a server error. If\n        the status code, is between 200 and 400, this will return True. This\n        is **not** a check to see if the response code is ``200 OK``.\n        \"\"\"\n        return self.ok\n\n    def __nonzero__(self):\n        \"\"\"Returns True if :attr:`status_code` is less than 400.\n\n        This attribute checks if the status code of the response is between\n        400 and 600 to see if there was a client error or a server error. If\n        the status code, is between 200 and 400, this will return True. This\n        is **not** a check to see if the response code is ``200 OK``.\n        \"\"\"\n        return self.ok\n\n    def __iter__(self):\n        \"\"\"Allows you to use a response as an iterator.\"\"\"\n        return self.iter_content(128)\n\n    @property\n    def ok(self):\n        \"\"\"Returns True if :attr:`status_code` is less than 400, Fals"}, {"start_line": 12000, "end_line": 14000, "belongs_to": {"file_name": "adapters.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "Response\n        \"\"\"\n        response = Response()\n\n        # Fallback to None if there's no status_code, for whatever reason.\n        response.status_code = getattr(resp, \"status\", None)\n\n        # Make headers case-insensitive.\n        response.headers = CaseInsensitiveDict(getattr(resp, \"headers\", {}))\n\n        # Set encoding.\n        response.encoding = get_encoding_from_headers(response.headers)\n        response.raw = resp\n        response.reason = response.raw.reason\n\n        if isinstance(req.url, bytes):\n            response.url = req.url.decode(\"utf-8\")\n        else:\n            response.url = req.url\n\n        # Add new cookies from the server.\n        extract_cookies_to_jar(response.cookies, req, resp)\n\n        # Give the Response some context.\n        response.request = req\n        response.connection = self\n\n        return response\n\n    def build_connection_pool_key_attributes(self, request, verify, cert=None):\n        \"\"\"Build the PoolKey attributes used by urllib3 to return a connection.\n\n        This looks at the PreparedRequest, the user-specified verify value,\n        and the value of the cert parameter to determine what PoolKey values\n        to use to select a connection from a given urllib3 Connection Pool.\n\n        The SSL related pool key arguments are not consistently set. As of\n        this writing, use the following to determine what keys may be in that\n        dictionary:\n\n        * If ``verify`` is ``True``, ``\"ssl_context\"`` will be set and will be the\n          default Requests SSL Context\n        * If ``verify`` is ``False``, ``\"ssl_context\"`` will not be set but\n          ``\"cert_reqs\"`` will be set\n        * If ``verify`` is a string, (i.e., it is a user-specified trust bundle)\n          ``\"ca_certs\"`` will be set if the string is not a directory recognized\n          by :py:func:`os.path.isdir`, otherwise ``\"ca_cert_dir\"`` will be\n          set.\n        * If ``\"cert\"`` is specified, ``\"cert_file\"`` will always be set. If\n          ``\""}, {"start_line": 5000, "end_line": 7000, "belongs_to": {"file_name": "sessions.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "        changed_port = old_parsed.port != new_parsed.port\n        changed_scheme = old_parsed.scheme != new_parsed.scheme\n        default_port = (DEFAULT_PORTS.get(old_parsed.scheme, None), None)\n        if (\n            not changed_scheme\n            and old_parsed.port in default_port\n            and new_parsed.port in default_port\n        ):\n            return False\n\n        # Standard case: root URI must match\n        return changed_port or changed_scheme\n\n    def resolve_redirects(\n        self,\n        resp,\n        req,\n        stream=False,\n        timeout=None,\n        verify=True,\n        cert=None,\n        proxies=None,\n        yield_requests=False,\n        **adapter_kwargs,\n    ):\n        \"\"\"Receives a Response. Returns a generator of Responses or Requests.\"\"\"\n\n        hist = []  # keep track of history\n\n        url = self.get_redirect_target(resp)\n        previous_fragment = urlparse(req.url).fragment\n        while url:\n            prepared_request = req.copy()\n\n            # Update history and keep track of redirects.\n            # resp.history must ignore the original request in this loop\n            hist.append(resp)\n            resp.history = hist[1:]\n\n            try:\n                resp.content  # Consume socket so it can be released\n            except (ChunkedEncodingError, ContentDecodingError, RuntimeError):\n                resp.raw.read(decode_content=False)\n\n            if len(resp.history) >= self.max_redirects:\n                raise TooManyRedirects(\n                    f\"Exceeded {self.max_redirects} redirects.\", response=resp\n                )\n\n            # Release the connection back into the pool.\n            resp.close()\n\n            # Handle redirection without scheme (see: RFC 1808 Section 4)\n            if url.startswith(\"//\"):\n                parsed_rurl = urlparse(resp.url)\n                url = \":\".join([to_native_string(parsed_rurl.scheme), url])\n\n            # Normalize url case and attach previous fragment if needed (RFC 723"}, {"start_line": 25000, "end_line": 27000, "belongs_to": {"file_name": "models.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "e if not.\n\n        This attribute checks if the status code of the response is between\n        400 and 600 to see if there was a client error or a server error. If\n        the status code is between 200 and 400, this will return True. This\n        is **not** a check to see if the response code is ``200 OK``.\n        \"\"\"\n        try:\n            self.raise_for_status()\n        except HTTPError:\n            return False\n        return True\n\n    @property\n    def is_redirect(self):\n        \"\"\"True if this Response is a well-formed HTTP redirect that could have\n        been processed automatically (by :meth:`Session.resolve_redirects`).\n        \"\"\"\n        return \"location\" in self.headers and self.status_code in REDIRECT_STATI\n\n    @property\n    def is_permanent_redirect(self):\n        \"\"\"True if this Response one of the permanent versions of redirect.\"\"\"\n        return \"location\" in self.headers and self.status_code in (\n            codes.moved_permanently,\n            codes.permanent_redirect,\n        )\n\n    @property\n    def next(self):\n        \"\"\"Returns a PreparedRequest for the next request in a redirect chain, if there is one.\"\"\"\n        return self._next\n\n    @property\n    def apparent_encoding(self):\n        \"\"\"The apparent encoding, provided by the charset_normalizer or chardet libraries.\"\"\"\n        if chardet is not None:\n            return chardet.detect(self.content)[\"encoding\"]\n        else:\n            # If no character detection library is available, we'll fall back\n            # to a standard Python utf-8 str.\n            return \"utf-8\"\n\n    def iter_content(self, chunk_size=1, decode_unicode=False):\n        \"\"\"Iterates over the response data.  When stream=True is set on the\n        request, this avoids reading the content at once into memory for\n        large responses.  The chunk size is the number of bytes it should\n        read into memory.  This is not necessarily the length of each item\n        returned as decoding can take place.\n\n        chunk_"}, {"start_line": 49000, "end_line": 51000, "belongs_to": {"file_name": "test_requests.py", "upper_path": "/data2/raymone/swebench-repos/requests/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "       value = \"some_value\"\n        path = \"some_path\"\n\n        jar = requests.cookies.RequestsCookieJar()\n        jar.set(key, value, path=path)\n        jar.set(key, value)\n        with pytest.raises(requests.cookies.CookieConflictError):\n            jar.get(key)\n\n    def test_cookie_policy_copy(self):\n        class MyCookiePolicy(cookielib.DefaultCookiePolicy):\n            pass\n\n        jar = requests.cookies.RequestsCookieJar()\n        jar.set_policy(MyCookiePolicy())\n        assert isinstance(jar.copy().get_policy(), MyCookiePolicy)\n\n    def test_time_elapsed_blank(self, httpbin):\n        r = requests.get(httpbin(\"get\"))\n        td = r.elapsed\n        total_seconds = (\n            td.microseconds + (td.seconds + td.days * 24 * 3600) * 10**6\n        ) / 10**6\n        assert total_seconds > 0.0\n\n    def test_empty_response_has_content_none(self):\n        r = requests.Response()\n        assert r.content is None\n\n    def test_response_is_iterable(self):\n        r = requests.Response()\n        io = StringIO.StringIO(\"abc\")\n        read_ = io.read\n\n        def read_mock(amt, decode_content=None):\n            return read_(amt)\n\n        setattr(io, \"read\", read_mock)\n        r.raw = io\n        assert next(iter(r))\n        io.close()\n\n    def test_response_decode_unicode(self):\n        \"\"\"When called with decode_unicode, Response.iter_content should always\n        return unicode.\n        \"\"\"\n        r = requests.Response()\n        r._content_consumed = True\n        r._content = b\"the content\"\n        r.encoding = \"ascii\"\n\n        chunks = r.iter_content(decode_unicode=True)\n        assert all(isinstance(chunk, str) for chunk in chunks)\n\n        # also for streaming\n        r = requests.Response()\n        r.raw = io.BytesIO(b\"the content\")\n        r.encoding = \"ascii\"\n        chunks = r.iter_content(decode_unicode=True)\n        assert all(isinstance(chunk, str) for chunk in chunks)\n\n    def test_response_reason_unicode(self):\n        # check for unicode HTTP status\n      "}, {"start_line": 13000, "end_line": 15000, "belongs_to": {"file_name": "sessions.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "POST is responded to with a 301, turn it into a GET.\n        # This bizarre behaviour is explained in Issue 1704.\n        if response.status_code == codes.moved and method == \"POST\":\n            method = \"GET\"\n\n        prepared_request.method = method\n\n\nclass Session(SessionRedirectMixin):\n    \"\"\"A Requests session.\n\n    Provides cookie persistence, connection-pooling, and configuration.\n\n    Basic Usage::\n\n      >>> import requests\n      >>> s = requests.Session()\n      >>> s.get('https://httpbin.org/get')\n      <Response [200]>\n\n    Or as a context manager::\n\n      >>> with requests.Session() as s:\n      ...     s.get('https://httpbin.org/get')\n      <Response [200]>\n    \"\"\"\n\n    __attrs__ = [\n        \"headers\",\n        \"cookies\",\n        \"auth\",\n        \"proxies\",\n        \"hooks\",\n        \"params\",\n        \"verify\",\n        \"cert\",\n        \"adapters\",\n        \"stream\",\n        \"trust_env\",\n        \"max_redirects\",\n    ]\n\n    def __init__(self):\n        #: A case-insensitive dictionary of headers to be sent on each\n        #: :class:`Request <Request>` sent from this\n        #: :class:`Session <Session>`.\n        self.headers = default_headers()\n\n        #: Default Authentication tuple or object to attach to\n        #: :class:`Request <Request>`.\n        self.auth = None\n\n        #: Dictionary mapping protocol or protocol and host to the URL of the proxy\n        #: (e.g. {'http': 'foo.bar:3128', 'http://host.name': 'foo.bar:4012'}) to\n        #: be used on each :class:`Request <Request>`.\n        self.proxies = {}\n\n        #: Event-handling hooks.\n        self.hooks = default_hooks()\n\n        #: Dictionary of querystring data to attach to each\n        #: :class:`Request <Request>`. The dictionary values may be lists for\n        #: representing multivalued query parameters.\n        self.params = {}\n\n        #: Stream response content default.\n        self.stream = False\n\n        #: SSL Verification default.\n        #: Defaults to `True`, requiring requests to verif"}, {"start_line": 24000, "end_line": 26000, "belongs_to": {"file_name": "models.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": " than 400.\n\n        This attribute checks if the status code of the response is between\n        400 and 600 to see if there was a client error or a server error. If\n        the status code, is between 200 and 400, this will return True. This\n        is **not** a check to see if the response code is ``200 OK``.\n        \"\"\"\n        return self.ok\n\n    def __nonzero__(self):\n        \"\"\"Returns True if :attr:`status_code` is less than 400.\n\n        This attribute checks if the status code of the response is between\n        400 and 600 to see if there was a client error or a server error. If\n        the status code, is between 200 and 400, this will return True. This\n        is **not** a check to see if the response code is ``200 OK``.\n        \"\"\"\n        return self.ok\n\n    def __iter__(self):\n        \"\"\"Allows you to use a response as an iterator.\"\"\"\n        return self.iter_content(128)\n\n    @property\n    def ok(self):\n        \"\"\"Returns True if :attr:`status_code` is less than 400, False if not.\n\n        This attribute checks if the status code of the response is between\n        400 and 600 to see if there was a client error or a server error. If\n        the status code is between 200 and 400, this will return True. This\n        is **not** a check to see if the response code is ``200 OK``.\n        \"\"\"\n        try:\n            self.raise_for_status()\n        except HTTPError:\n            return False\n        return True\n\n    @property\n    def is_redirect(self):\n        \"\"\"True if this Response is a well-formed HTTP redirect that could have\n        been processed automatically (by :meth:`Session.resolve_redirects`).\n        \"\"\"\n        return \"location\" in self.headers and self.status_code in REDIRECT_STATI\n\n    @property\n    def is_permanent_redirect(self):\n        \"\"\"True if this Response one of the permanent versions of redirect.\"\"\"\n        return \"location\" in self.headers and self.status_code in (\n            codes.moved_permanently,\n            codes.permanent_re"}, {"start_line": 4000, "end_line": 6000, "belongs_to": {"file_name": "sessions.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "ion in latin1.\n            location = location.encode(\"latin1\")\n            return to_native_string(location, \"utf8\")\n        return None\n\n    def should_strip_auth(self, old_url, new_url):\n        \"\"\"Decide whether Authorization header should be removed when redirecting\"\"\"\n        old_parsed = urlparse(old_url)\n        new_parsed = urlparse(new_url)\n        if old_parsed.hostname != new_parsed.hostname:\n            return True\n        # Special case: allow http -> https redirect when using the standard\n        # ports. This isn't specified by RFC 7235, but is kept to avoid\n        # breaking backwards compatibility with older versions of requests\n        # that allowed any redirects on the same host.\n        if (\n            old_parsed.scheme == \"http\"\n            and old_parsed.port in (80, None)\n            and new_parsed.scheme == \"https\"\n            and new_parsed.port in (443, None)\n        ):\n            return False\n\n        # Handle default port usage corresponding to scheme.\n        changed_port = old_parsed.port != new_parsed.port\n        changed_scheme = old_parsed.scheme != new_parsed.scheme\n        default_port = (DEFAULT_PORTS.get(old_parsed.scheme, None), None)\n        if (\n            not changed_scheme\n            and old_parsed.port in default_port\n            and new_parsed.port in default_port\n        ):\n            return False\n\n        # Standard case: root URI must match\n        return changed_port or changed_scheme\n\n    def resolve_redirects(\n        self,\n        resp,\n        req,\n        stream=False,\n        timeout=None,\n        verify=True,\n        cert=None,\n        proxies=None,\n        yield_requests=False,\n        **adapter_kwargs,\n    ):\n        \"\"\"Receives a Response. Returns a generator of Responses or Requests.\"\"\"\n\n        hist = []  # keep track of history\n\n        url = self.get_redirect_target(resp)\n        previous_fragment = urlparse(req.url).fragment\n        while url:\n            prepared_request = req.copy()\n\n          "}], "retrieved_count": 10, "cost_time": 3.5718624591827393}
{"question": "What is the relationship between Requests' authentication handlers and the session management system?", "answer": null, "relative_code_list": null, "ground_truth": "The relationship between authentication handlers and session management (src/requests/auth.py, src/requests/sessions.py) provides persistent authentication: 1) Session-level auth - Sessions can store default authentication credentials (self.auth) that are applied to all requests unless overridden; 2) Request preparation - During request preparation, Session.prepare_request() merges session auth with request-specific auth; 3) Auth handler application - Authentication handlers are applied during PreparedRequest preparation, adding appropriate headers (Authorization, Proxy-Authorization); 4) Persistent credentials - Session maintains authentication state across multiple requests, avoiding repeated credential specification; 5) Environment integration - Sessions can automatically detect and use authentication from environment variables (netrc, etc.) when trust_env is enabled; 6) Auth method flexibility - Sessions support both simple tuples (username, password) and complex auth handler objects; 7) Redirect handling - Authentication handlers can respond to 401 challenges and maintain state across redirects; 8) Cookie integration - Authentication and cookie handling work together, with auth headers and cookies both being session-persistent; 9) Thread safety - Authentication handlers like HTTPDigestAuth use thread-local storage for state management; 10) Cleanup - Sessions properly clean up authentication resources when closed. This integration enables seamless authentication across multiple requests while maintaining security and state consistency.", "score": null, "retrieved_content": [{"start_line": 67000, "end_line": 69000, "belongs_to": {"file_name": "test_requests.py", "upper_path": "/data2/raymone/swebench-repos/requests/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "    auth=(\"user\", \"pass\"),\n            verify=httpbin_ca_bundle,\n        )\n        assert r.history[0].request.headers[\"Authorization\"]\n        assert \"Authorization\" not in r.request.headers\n\n    def test_auth_is_retained_for_redirect_on_host(self, httpbin):\n        r = requests.get(httpbin(\"redirect/1\"), auth=(\"user\", \"pass\"))\n        h1 = r.history[0].request.headers[\"Authorization\"]\n        h2 = r.request.headers[\"Authorization\"]\n\n        assert h1 == h2\n\n    def test_should_strip_auth_host_change(self):\n        s = requests.Session()\n        assert s.should_strip_auth(\n            \"http://example.com/foo\", \"http://another.example.com/\"\n        )\n\n    def test_should_strip_auth_http_downgrade(self):\n        s = requests.Session()\n        assert s.should_strip_auth(\"https://example.com/foo\", \"http://example.com/bar\")\n\n    def test_should_strip_auth_https_upgrade(self):\n        s = requests.Session()\n        assert not s.should_strip_auth(\n            \"http://example.com/foo\", \"https://example.com/bar\"\n        )\n        assert not s.should_strip_auth(\n            \"http://example.com:80/foo\", \"https://example.com/bar\"\n        )\n        assert not s.should_strip_auth(\n            \"http://example.com/foo\", \"https://example.com:443/bar\"\n        )\n        # Non-standard ports should trigger stripping\n        assert s.should_strip_auth(\n            \"http://example.com:8080/foo\", \"https://example.com/bar\"\n        )\n        assert s.should_strip_auth(\n            \"http://example.com/foo\", \"https://example.com:8443/bar\"\n        )\n\n    def test_should_strip_auth_port_change(self):\n        s = requests.Session()\n        assert s.should_strip_auth(\n            \"http://example.com:1234/foo\", \"https://example.com:4321/bar\"\n        )\n\n    @pytest.mark.parametrize(\n        \"old_uri, new_uri\",\n        (\n            (\"https://example.com:443/foo\", \"https://example.com/bar\"),\n            (\"http://example.com:80/foo\", \"http://example.com/bar\"),\n            (\"https://example.com/foo\","}, {"start_line": 27000, "end_line": 29000, "belongs_to": {"file_name": "test_requests.py", "upper_path": "/data2/raymone/swebench-repos/requests/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "authtype, \"never\")\n\n            r = requests.get(url, auth=auth)\n            assert r.status_code == 200\n\n            r = requests.get(url)\n            assert r.status_code == 401\n            print(r.headers[\"WWW-Authenticate\"])\n\n            s = requests.session()\n            s.auth = HTTPDigestAuth(\"user\", \"pass\")\n            r = s.get(url)\n            assert r.status_code == 200\n\n    def test_DIGEST_AUTH_RETURNS_COOKIE(self, httpbin):\n        for authtype in self.digest_auth_algo:\n            url = httpbin(\"digest-auth\", \"auth\", \"user\", \"pass\", authtype)\n            auth = HTTPDigestAuth(\"user\", \"pass\")\n            r = requests.get(url)\n            assert r.cookies[\"fake\"] == \"fake_value\"\n\n            r = requests.get(url, auth=auth)\n            assert r.status_code == 200\n\n    def test_DIGEST_AUTH_SETS_SESSION_COOKIES(self, httpbin):\n        for authtype in self.digest_auth_algo:\n            url = httpbin(\"digest-auth\", \"auth\", \"user\", \"pass\", authtype)\n            auth = HTTPDigestAuth(\"user\", \"pass\")\n            s = requests.Session()\n            s.get(url, auth=auth)\n            assert s.cookies[\"fake\"] == \"fake_value\"\n\n    def test_DIGEST_STREAM(self, httpbin):\n        for authtype in self.digest_auth_algo:\n            auth = HTTPDigestAuth(\"user\", \"pass\")\n            url = httpbin(\"digest-auth\", \"auth\", \"user\", \"pass\", authtype)\n\n            r = requests.get(url, auth=auth, stream=True)\n            assert r.raw.read() != b\"\"\n\n            r = requests.get(url, auth=auth, stream=False)\n            assert r.raw.read() == b\"\"\n\n    def test_DIGESTAUTH_WRONG_HTTP_401_GET(self, httpbin):\n        for authtype in self.digest_auth_algo:\n            auth = HTTPDigestAuth(\"user\", \"wrongpass\")\n            url = httpbin(\"digest-auth\", \"auth\", \"user\", \"pass\", authtype)\n\n            r = requests.get(url, auth=auth)\n            assert r.status_code == 401\n\n            r = requests.get(url)\n            assert r.status_code == 401\n\n            s = requests.session()\n          "}, {"start_line": 43000, "end_line": 45000, "belongs_to": {"file_name": "test_requests.py", "upper_path": "/data2/raymone/swebench-repos/requests/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "ook})\n        prep = req.prepare()\n\n        s = requests.Session()\n        s.proxies = getproxies()\n        resp = s.send(prep)\n\n        assert hasattr(resp, \"hook_working\")\n\n    def test_prepared_from_session(self, httpbin):\n        class DummyAuth(requests.auth.AuthBase):\n            def __call__(self, r):\n                r.headers[\"Dummy-Auth-Test\"] = \"dummy-auth-test-ok\"\n                return r\n\n        req = requests.Request(\"GET\", httpbin(\"headers\"))\n        assert not req.auth\n\n        s = requests.Session()\n        s.auth = DummyAuth()\n\n        prep = s.prepare_request(req)\n        resp = s.send(prep)\n\n        assert resp.json()[\"headers\"][\"Dummy-Auth-Test\"] == \"dummy-auth-test-ok\"\n\n    def test_prepare_request_with_bytestring_url(self):\n        req = requests.Request(\"GET\", b\"https://httpbin.org/\")\n        s = requests.Session()\n        prep = s.prepare_request(req)\n        assert prep.url == \"https://httpbin.org/\"\n\n    def test_request_with_bytestring_host(self, httpbin):\n        s = requests.Session()\n        resp = s.request(\n            \"GET\",\n            httpbin(\"cookies/set?cookie=value\"),\n            allow_redirects=False,\n            headers={\"Host\": b\"httpbin.org\"},\n        )\n        assert resp.cookies.get(\"cookie\") == \"value\"\n\n    def test_links(self):\n        r = requests.Response()\n        r.headers = {\n            \"cache-control\": \"public, max-age=60, s-maxage=60\",\n            \"connection\": \"keep-alive\",\n            \"content-encoding\": \"gzip\",\n            \"content-type\": \"application/json; charset=utf-8\",\n            \"date\": \"Sat, 26 Jan 2013 16:47:56 GMT\",\n            \"etag\": '\"6ff6a73c0e446c1f61614769e3ceb778\"',\n            \"last-modified\": \"Sat, 26 Jan 2013 16:22:39 GMT\",\n            \"link\": (\n                \"<https://api.github.com/users/kennethreitz/repos?\"\n                'page=2&per_page=10>; rel=\"next\", <https://api.github.'\n                \"com/users/kennethreitz/repos?page=7&per_page=10>; \"\n                ' rel=\"last\"'\n           "}, {"start_line": 25000, "end_line": 27000, "belongs_to": {"file_name": "test_requests.py", "upper_path": "/data2/raymone/swebench-repos/requests/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "get_netrc_auth_mock(url):\n                return auth\n\n            requests.sessions.get_netrc_auth = get_netrc_auth_mock\n\n            # Should use netrc and work.\n            r = requests.get(url)\n            assert r.status_code == 200\n\n            # Given auth should override and fail.\n            r = requests.get(url, auth=wrong_auth)\n            assert r.status_code == 401\n\n            s = requests.session()\n\n            # Should use netrc and work.\n            r = s.get(url)\n            assert r.status_code == 200\n\n            # Given auth should override and fail.\n            s.auth = wrong_auth\n            r = s.get(url)\n            assert r.status_code == 401\n        finally:\n            requests.sessions.get_netrc_auth = old_auth\n\n    def test_basicauth_with_netrc_leak(self, httpbin):\n        url1 = httpbin(\"basic-auth\", \"user\", \"pass\")\n        url = url1[len(\"http://\") :]\n        domain = url.split(\":\")[0]\n        url = f\"http://example.com:@{url}\"\n\n        netrc_file = \"\"\n        with tempfile.NamedTemporaryFile(mode=\"w\", delete=False) as fp:\n            fp.write(\"machine example.com\\n\")\n            fp.write(\"login wronguser\\n\")\n            fp.write(\"password wrongpass\\n\")\n            fp.write(f\"machine {domain}\\n\")\n            fp.write(\"login user\\n\")\n            fp.write(\"password pass\\n\")\n            fp.close()\n            netrc_file = fp.name\n\n        old_netrc = os.environ.get(\"NETRC\", \"\")\n        os.environ[\"NETRC\"] = netrc_file\n\n        try:\n            # Should use netrc\n            # Make sure that we don't use the example.com credentails\n            # for the request\n            r = requests.get(url)\n            assert r.status_code == 200\n        finally:\n            os.environ[\"NETRC\"] = old_netrc\n            os.unlink(netrc_file)\n\n    def test_DIGEST_HTTP_200_OK_GET(self, httpbin):\n        for authtype in self.digest_auth_algo:\n            auth = HTTPDigestAuth(\"user\", \"pass\")\n            url = httpbin(\"digest-auth\", \"auth\", \"user\", \"pass\", "}, {"start_line": 13000, "end_line": 15000, "belongs_to": {"file_name": "sessions.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "POST is responded to with a 301, turn it into a GET.\n        # This bizarre behaviour is explained in Issue 1704.\n        if response.status_code == codes.moved and method == \"POST\":\n            method = \"GET\"\n\n        prepared_request.method = method\n\n\nclass Session(SessionRedirectMixin):\n    \"\"\"A Requests session.\n\n    Provides cookie persistence, connection-pooling, and configuration.\n\n    Basic Usage::\n\n      >>> import requests\n      >>> s = requests.Session()\n      >>> s.get('https://httpbin.org/get')\n      <Response [200]>\n\n    Or as a context manager::\n\n      >>> with requests.Session() as s:\n      ...     s.get('https://httpbin.org/get')\n      <Response [200]>\n    \"\"\"\n\n    __attrs__ = [\n        \"headers\",\n        \"cookies\",\n        \"auth\",\n        \"proxies\",\n        \"hooks\",\n        \"params\",\n        \"verify\",\n        \"cert\",\n        \"adapters\",\n        \"stream\",\n        \"trust_env\",\n        \"max_redirects\",\n    ]\n\n    def __init__(self):\n        #: A case-insensitive dictionary of headers to be sent on each\n        #: :class:`Request <Request>` sent from this\n        #: :class:`Session <Session>`.\n        self.headers = default_headers()\n\n        #: Default Authentication tuple or object to attach to\n        #: :class:`Request <Request>`.\n        self.auth = None\n\n        #: Dictionary mapping protocol or protocol and host to the URL of the proxy\n        #: (e.g. {'http': 'foo.bar:3128', 'http://host.name': 'foo.bar:4012'}) to\n        #: be used on each :class:`Request <Request>`.\n        self.proxies = {}\n\n        #: Event-handling hooks.\n        self.hooks = default_hooks()\n\n        #: Dictionary of querystring data to attach to each\n        #: :class:`Request <Request>`. The dictionary values may be lists for\n        #: representing multivalued query parameters.\n        self.params = {}\n\n        #: Stream response content default.\n        self.stream = False\n\n        #: SSL Verification default.\n        #: Defaults to `True`, requiring requests to verif"}, {"start_line": 26000, "end_line": 28000, "belongs_to": {"file_name": "test_requests.py", "upper_path": "/data2/raymone/swebench-repos/requests/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "       with tempfile.NamedTemporaryFile(mode=\"w\", delete=False) as fp:\n            fp.write(\"machine example.com\\n\")\n            fp.write(\"login wronguser\\n\")\n            fp.write(\"password wrongpass\\n\")\n            fp.write(f\"machine {domain}\\n\")\n            fp.write(\"login user\\n\")\n            fp.write(\"password pass\\n\")\n            fp.close()\n            netrc_file = fp.name\n\n        old_netrc = os.environ.get(\"NETRC\", \"\")\n        os.environ[\"NETRC\"] = netrc_file\n\n        try:\n            # Should use netrc\n            # Make sure that we don't use the example.com credentails\n            # for the request\n            r = requests.get(url)\n            assert r.status_code == 200\n        finally:\n            os.environ[\"NETRC\"] = old_netrc\n            os.unlink(netrc_file)\n\n    def test_DIGEST_HTTP_200_OK_GET(self, httpbin):\n        for authtype in self.digest_auth_algo:\n            auth = HTTPDigestAuth(\"user\", \"pass\")\n            url = httpbin(\"digest-auth\", \"auth\", \"user\", \"pass\", authtype, \"never\")\n\n            r = requests.get(url, auth=auth)\n            assert r.status_code == 200\n\n            r = requests.get(url)\n            assert r.status_code == 401\n            print(r.headers[\"WWW-Authenticate\"])\n\n            s = requests.session()\n            s.auth = HTTPDigestAuth(\"user\", \"pass\")\n            r = s.get(url)\n            assert r.status_code == 200\n\n    def test_DIGEST_AUTH_RETURNS_COOKIE(self, httpbin):\n        for authtype in self.digest_auth_algo:\n            url = httpbin(\"digest-auth\", \"auth\", \"user\", \"pass\", authtype)\n            auth = HTTPDigestAuth(\"user\", \"pass\")\n            r = requests.get(url)\n            assert r.cookies[\"fake\"] == \"fake_value\"\n\n            r = requests.get(url, auth=auth)\n            assert r.status_code == 200\n\n    def test_DIGEST_AUTH_SETS_SESSION_COOKIES(self, httpbin):\n        for authtype in self.digest_auth_algo:\n            url = httpbin(\"digest-auth\", \"auth\", \"user\", \"pass\", authtype)\n            auth = HTTPDigest"}, {"start_line": 24000, "end_line": 26000, "belongs_to": {"file_name": "test_requests.py", "upper_path": "/data2/raymone/swebench-repos/requests/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "\", {})\n\n        assert sent_headers.get(\"Proxy-Authorization\") == proxy_auth_value\n\n    @pytest.mark.parametrize(\n        \"url,has_proxy_auth\",\n        (\n            (\"http://example.com\", True),\n            (\"https://example.com\", False),\n        ),\n    )\n    def test_proxy_authorization_not_appended_to_https_request(\n        self, url, has_proxy_auth\n    ):\n        session = requests.Session()\n        proxies = {\n            \"http\": \"http://test:pass@localhost:8080\",\n            \"https\": \"http://test:pass@localhost:8090\",\n        }\n        req = requests.Request(\"GET\", url)\n        prep = req.prepare()\n        session.rebuild_proxies(prep, proxies)\n\n        assert (\"Proxy-Authorization\" in prep.headers) is has_proxy_auth\n\n    def test_basicauth_with_netrc(self, httpbin):\n        auth = (\"user\", \"pass\")\n        wrong_auth = (\"wronguser\", \"wrongpass\")\n        url = httpbin(\"basic-auth\", \"user\", \"pass\")\n\n        old_auth = requests.sessions.get_netrc_auth\n\n        try:\n\n            def get_netrc_auth_mock(url):\n                return auth\n\n            requests.sessions.get_netrc_auth = get_netrc_auth_mock\n\n            # Should use netrc and work.\n            r = requests.get(url)\n            assert r.status_code == 200\n\n            # Given auth should override and fail.\n            r = requests.get(url, auth=wrong_auth)\n            assert r.status_code == 401\n\n            s = requests.session()\n\n            # Should use netrc and work.\n            r = s.get(url)\n            assert r.status_code == 200\n\n            # Given auth should override and fail.\n            s.auth = wrong_auth\n            r = s.get(url)\n            assert r.status_code == 401\n        finally:\n            requests.sessions.get_netrc_auth = old_auth\n\n    def test_basicauth_with_netrc_leak(self, httpbin):\n        url1 = httpbin(\"basic-auth\", \"user\", \"pass\")\n        url = url1[len(\"http://\") :]\n        domain = url.split(\":\")[0]\n        url = f\"http://example.com:@{url}\"\n\n        netrc_file = \"\"\n "}, {"start_line": 0, "end_line": 2000, "belongs_to": {"file_name": "auth.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "\"\"\"\nrequests.auth\n~~~~~~~~~~~~~\n\nThis module contains the authentication handlers for Requests.\n\"\"\"\n\nimport hashlib\nimport os\nimport re\nimport threading\nimport time\nimport warnings\nfrom base64 import b64encode\n\nfrom ._internal_utils import to_native_string\nfrom .compat import basestring, str, urlparse\nfrom .cookies import extract_cookies_to_jar\nfrom .utils import parse_dict_header\n\nCONTENT_TYPE_FORM_URLENCODED = \"application/x-www-form-urlencoded\"\nCONTENT_TYPE_MULTI_PART = \"multipart/form-data\"\n\n\ndef _basic_auth_str(username, password):\n    \"\"\"Returns a Basic Auth string.\"\"\"\n\n    # \"I want us to put a big-ol' comment on top of it that\n    # says that this behaviour is dumb but we need to preserve\n    # it because people are relying on it.\"\n    #    - Lukasa\n    #\n    # These are here solely to maintain backwards compatibility\n    # for things like ints. This will be removed in 3.0.0.\n    if not isinstance(username, basestring):\n        warnings.warn(\n            \"Non-string usernames will no longer be supported in Requests \"\n            \"3.0.0. Please convert the object you've passed in ({!r}) to \"\n            \"a string or bytes object in the near future to avoid \"\n            \"problems.\".format(username),\n            category=DeprecationWarning,\n        )\n        username = str(username)\n\n    if not isinstance(password, basestring):\n        warnings.warn(\n            \"Non-string passwords will no longer be supported in Requests \"\n            \"3.0.0. Please convert the object you've passed in ({!r}) to \"\n            \"a string or bytes object in the near future to avoid \"\n            \"problems.\".format(type(password)),\n            category=DeprecationWarning,\n        )\n        password = str(password)\n    # -- End Removal --\n\n    if isinstance(username, str):\n        username = username.encode(\"latin1\")\n\n    if isinstance(password, str):\n        password = password.encode(\"latin1\")\n\n    authstr = \"Basic \" + to_native_string(\n        b64encode(b\":\".join((username, pas"}, {"start_line": 28000, "end_line": 30000, "belongs_to": {"file_name": "test_requests.py", "upper_path": "/data2/raymone/swebench-repos/requests/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "Auth(\"user\", \"pass\")\n            s = requests.Session()\n            s.get(url, auth=auth)\n            assert s.cookies[\"fake\"] == \"fake_value\"\n\n    def test_DIGEST_STREAM(self, httpbin):\n        for authtype in self.digest_auth_algo:\n            auth = HTTPDigestAuth(\"user\", \"pass\")\n            url = httpbin(\"digest-auth\", \"auth\", \"user\", \"pass\", authtype)\n\n            r = requests.get(url, auth=auth, stream=True)\n            assert r.raw.read() != b\"\"\n\n            r = requests.get(url, auth=auth, stream=False)\n            assert r.raw.read() == b\"\"\n\n    def test_DIGESTAUTH_WRONG_HTTP_401_GET(self, httpbin):\n        for authtype in self.digest_auth_algo:\n            auth = HTTPDigestAuth(\"user\", \"wrongpass\")\n            url = httpbin(\"digest-auth\", \"auth\", \"user\", \"pass\", authtype)\n\n            r = requests.get(url, auth=auth)\n            assert r.status_code == 401\n\n            r = requests.get(url)\n            assert r.status_code == 401\n\n            s = requests.session()\n            s.auth = auth\n            r = s.get(url)\n            assert r.status_code == 401\n\n    def test_DIGESTAUTH_QUOTES_QOP_VALUE(self, httpbin):\n        for authtype in self.digest_auth_algo:\n            auth = HTTPDigestAuth(\"user\", \"pass\")\n            url = httpbin(\"digest-auth\", \"auth\", \"user\", \"pass\", authtype)\n\n            r = requests.get(url, auth=auth)\n            assert '\"auth\"' in r.request.headers[\"Authorization\"]\n\n    def test_POSTBIN_GET_POST_FILES(self, httpbin):\n        url = httpbin(\"post\")\n        requests.post(url).raise_for_status()\n\n        post1 = requests.post(url, data={\"some\": \"data\"})\n        assert post1.status_code == 200\n\n        with open(\"requirements-dev.txt\") as f:\n            post2 = requests.post(url, files={\"some\": f})\n        assert post2.status_code == 200\n\n        post4 = requests.post(url, data='[{\"some\": \"json\"}]')\n        assert post4.status_code == 200\n\n        with pytest.raises(ValueError):\n            requests.post(url, files=[\"bad file data\"])\n"}, {"start_line": 12000, "end_line": 14000, "belongs_to": {"file_name": "sessions.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "          username, password = None, None\n\n        # urllib3 handles proxy authorization for us in the standard adapter.\n        # Avoid appending this to TLS tunneled requests where it may be leaked.\n        if not scheme.startswith(\"https\") and username and password:\n            headers[\"Proxy-Authorization\"] = _basic_auth_str(username, password)\n\n        return new_proxies\n\n    def rebuild_method(self, prepared_request, response):\n        \"\"\"When being redirected we may want to change the method of the request\n        based on certain specs or browser behavior.\n        \"\"\"\n        method = prepared_request.method\n\n        # https://tools.ietf.org/html/rfc7231#section-6.4.4\n        if response.status_code == codes.see_other and method != \"HEAD\":\n            method = \"GET\"\n\n        # Do what the browsers do, despite standards...\n        # First, turn 302s into GETs.\n        if response.status_code == codes.found and method != \"HEAD\":\n            method = \"GET\"\n\n        # Second, if a POST is responded to with a 301, turn it into a GET.\n        # This bizarre behaviour is explained in Issue 1704.\n        if response.status_code == codes.moved and method == \"POST\":\n            method = \"GET\"\n\n        prepared_request.method = method\n\n\nclass Session(SessionRedirectMixin):\n    \"\"\"A Requests session.\n\n    Provides cookie persistence, connection-pooling, and configuration.\n\n    Basic Usage::\n\n      >>> import requests\n      >>> s = requests.Session()\n      >>> s.get('https://httpbin.org/get')\n      <Response [200]>\n\n    Or as a context manager::\n\n      >>> with requests.Session() as s:\n      ...     s.get('https://httpbin.org/get')\n      <Response [200]>\n    \"\"\"\n\n    __attrs__ = [\n        \"headers\",\n        \"cookies\",\n        \"auth\",\n        \"proxies\",\n        \"hooks\",\n        \"params\",\n        \"verify\",\n        \"cert\",\n        \"adapters\",\n        \"stream\",\n        \"trust_env\",\n        \"max_redirects\",\n    ]\n\n    def __init__(self):\n        #: A case-insensitive dictiona"}], "retrieved_count": 10, "cost_time": 3.71234130859375}
{"question": "What dependencies exist between Requests' adapter system and the underlying transport libraries?", "answer": null, "relative_code_list": null, "ground_truth": "Requests' adapter system (src/requests/adapters.py) has specific dependencies on underlying transport libraries: 1) urllib3 dependency - HTTPAdapter depends heavily on urllib3 for connection pooling, SSL/TLS handling, and HTTP protocol implementation; 2) PoolManager integration - HTTPAdapter uses urllib3.PoolManager for connection pooling, retry logic, and connection lifecycle management; 3) Exception mapping - Adapters translate urllib3 exceptions (ConnectTimeoutError, ReadTimeoutError, SSLError, etc.) into Requests exceptions; 4) SSL/TLS handling - Adapters delegate SSL certificate verification, client certificate handling, and TLS configuration to urllib3; 5) Proxy support - HTTPAdapter uses urllib3's proxy_from_url and SOCKSProxyManager for proxy handling; 6) Retry mechanism - Adapters integrate with urllib3's Retry class for configurable retry policies and backoff strategies; 7) Connection pooling - Adapters rely on urllib3's connection pool implementation for connection reuse and management; 8) Content encoding - Adapters use urllib3's content encoding and decoding capabilities; 9) Header handling - Adapters depend on urllib3's header parsing and validation; 10) URL processing - Adapters use urllib3's URL parsing and validation utilities. The adapter system provides an abstraction layer that shields Requests from urllib3 implementation details while leveraging its robust transport capabilities.", "score": null, "retrieved_content": [{"start_line": 0, "end_line": 229, "belongs_to": {"file_name": "test_packages.py", "upper_path": "/data2/raymone/swebench-repos/requests/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "import requests\n\n\ndef test_can_access_urllib3_attribute():\n    requests.packages.urllib3\n\n\ndef test_can_access_idna_attribute():\n    requests.packages.idna\n\n\ndef test_can_access_chardet_attribute():\n    requests.packages.chardet\n"}, {"start_line": 2000, "end_line": 4000, "belongs_to": {"file_name": "adapters.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "olmanager: \"PoolManager\",\n) -> \"(typing.Dict[str, typing.Any], typing.Dict[str, typing.Any])\":\n    host_params = {}\n    pool_kwargs = {}\n    parsed_request_url = urlparse(request.url)\n    scheme = parsed_request_url.scheme.lower()\n    port = parsed_request_url.port\n\n    cert_reqs = \"CERT_REQUIRED\"\n    if verify is False:\n        cert_reqs = \"CERT_NONE\"\n    elif isinstance(verify, str):\n        if not os.path.isdir(verify):\n            pool_kwargs[\"ca_certs\"] = verify\n        else:\n            pool_kwargs[\"ca_cert_dir\"] = verify\n    pool_kwargs[\"cert_reqs\"] = cert_reqs\n    if client_cert is not None:\n        if isinstance(client_cert, tuple) and len(client_cert) == 2:\n            pool_kwargs[\"cert_file\"] = client_cert[0]\n            pool_kwargs[\"key_file\"] = client_cert[1]\n        else:\n            # According to our docs, we allow users to specify just the client\n            # cert path\n            pool_kwargs[\"cert_file\"] = client_cert\n    host_params = {\n        \"scheme\": scheme,\n        \"host\": parsed_request_url.hostname,\n        \"port\": port,\n    }\n    return host_params, pool_kwargs\n\n\nclass BaseAdapter:\n    \"\"\"The Base Transport Adapter\"\"\"\n\n    def __init__(self):\n        super().__init__()\n\n    def send(\n        self, request, stream=False, timeout=None, verify=True, cert=None, proxies=None\n    ):\n        \"\"\"Sends PreparedRequest object. Returns Response object.\n\n        :param request: The :class:`PreparedRequest <PreparedRequest>` being sent.\n        :param stream: (optional) Whether to stream the request content.\n        :param timeout: (optional) How long to wait for the server to send\n            data before giving up, as a float, or a :ref:`(connect timeout,\n            read timeout) <timeouts>` tuple.\n        :type timeout: float or tuple\n        :param verify: (optional) Either a boolean, in which case it controls whether we verify\n            the server's TLS certificate, or a string, in which case it must be a path\n            to a CA bundle to use\n"}, {"start_line": 3000, "end_line": 5000, "belongs_to": {"file_name": "adapters.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "     \"host\": parsed_request_url.hostname,\n        \"port\": port,\n    }\n    return host_params, pool_kwargs\n\n\nclass BaseAdapter:\n    \"\"\"The Base Transport Adapter\"\"\"\n\n    def __init__(self):\n        super().__init__()\n\n    def send(\n        self, request, stream=False, timeout=None, verify=True, cert=None, proxies=None\n    ):\n        \"\"\"Sends PreparedRequest object. Returns Response object.\n\n        :param request: The :class:`PreparedRequest <PreparedRequest>` being sent.\n        :param stream: (optional) Whether to stream the request content.\n        :param timeout: (optional) How long to wait for the server to send\n            data before giving up, as a float, or a :ref:`(connect timeout,\n            read timeout) <timeouts>` tuple.\n        :type timeout: float or tuple\n        :param verify: (optional) Either a boolean, in which case it controls whether we verify\n            the server's TLS certificate, or a string, in which case it must be a path\n            to a CA bundle to use\n        :param cert: (optional) Any user-provided SSL certificate to be trusted.\n        :param proxies: (optional) The proxies dictionary to apply to the request.\n        \"\"\"\n        raise NotImplementedError\n\n    def close(self):\n        \"\"\"Cleans up adapter specific items.\"\"\"\n        raise NotImplementedError\n\n\nclass HTTPAdapter(BaseAdapter):\n    \"\"\"The built-in HTTP Adapter for urllib3.\n\n    Provides a general-case interface for Requests sessions to contact HTTP and\n    HTTPS urls by implementing the Transport Adapter interface. This class will\n    usually be created by the :class:`Session <Session>` class under the\n    covers.\n\n    :param pool_connections: The number of urllib3 connection pools to cache.\n    :param pool_maxsize: The maximum number of connections to save in the pool.\n    :param max_retries: The maximum number of retries each connection\n        should attempt. Note, this applies only to failed DNS lookups, socket\n        connections and connection timeouts, never to"}, {"start_line": 2000, "end_line": 4000, "belongs_to": {"file_name": "__init__.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "t_version >= 3.0.2, < 6.0.0\n        assert (3, 0, 2) <= (major, minor, patch) < (6, 0, 0)\n    elif charset_normalizer_version:\n        major, minor, patch = charset_normalizer_version.split(\".\")[:3]\n        major, minor, patch = int(major), int(minor), int(patch)\n        # charset_normalizer >= 2.0.0 < 4.0.0\n        assert (2, 0, 0) <= (major, minor, patch) < (4, 0, 0)\n    else:\n        warnings.warn(\n            \"Unable to find acceptable character detection dependency \"\n            \"(chardet or charset_normalizer).\",\n            RequestsDependencyWarning,\n        )\n\n\ndef _check_cryptography(cryptography_version):\n    # cryptography < 1.3.4\n    try:\n        cryptography_version = list(map(int, cryptography_version.split(\".\")))\n    except ValueError:\n        return\n\n    if cryptography_version < [1, 3, 4]:\n        warning = \"Old version of cryptography ({}) may cause slowdown.\".format(\n            cryptography_version\n        )\n        warnings.warn(warning, RequestsDependencyWarning)\n\n\n# Check imported dependencies for compatibility.\ntry:\n    check_compatibility(\n        urllib3.__version__, chardet_version, charset_normalizer_version\n    )\nexcept (AssertionError, ValueError):\n    warnings.warn(\n        \"urllib3 ({}) or chardet ({})/charset_normalizer ({}) doesn't match a supported \"\n        \"version!\".format(\n            urllib3.__version__, chardet_version, charset_normalizer_version\n        ),\n        RequestsDependencyWarning,\n    )\n\n# Attempt to enable urllib3's fallback for SNI support\n# if the standard library doesn't support SNI or the\n# 'ssl' library isn't available.\ntry:\n    try:\n        import ssl\n    except ImportError:\n        ssl = None\n\n    if not getattr(ssl, \"HAS_SNI\", False):\n        from urllib3.contrib import pyopenssl\n\n        pyopenssl.inject_into_urllib3()\n\n        # Check cryptography version\n        from cryptography import __version__ as cryptography_version\n\n        _check_cryptography(cryptography_version)\nexcept ImportError:\n    pass\n\n#"}, {"start_line": 57000, "end_line": 59000, "belongs_to": {"file_name": "test_requests.py", "upper_path": "/data2/raymone/swebench-repos/requests/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": ".mount(\"http://git\", HTTPAdapter())\n        s.mount(\"http://github\", HTTPAdapter())\n        s.mount(\"http://github.com\", HTTPAdapter())\n        s.mount(\"http://github.com/about/\", HTTPAdapter())\n        order = [\n            \"http://github.com/about/\",\n            \"http://github.com\",\n            \"http://github\",\n            \"http://git\",\n            \"https://\",\n            \"http://\",\n        ]\n        assert order == list(s.adapters)\n        s.mount(\"http://gittip\", HTTPAdapter())\n        s.mount(\"http://gittip.com\", HTTPAdapter())\n        s.mount(\"http://gittip.com/about/\", HTTPAdapter())\n        order = [\n            \"http://github.com/about/\",\n            \"http://gittip.com/about/\",\n            \"http://github.com\",\n            \"http://gittip.com\",\n            \"http://github\",\n            \"http://gittip\",\n            \"http://git\",\n            \"https://\",\n            \"http://\",\n        ]\n        assert order == list(s.adapters)\n        s2 = requests.Session()\n        s2.adapters = {\"http://\": HTTPAdapter()}\n        s2.mount(\"https://\", HTTPAdapter())\n        assert \"http://\" in s2.adapters\n        assert \"https://\" in s2.adapters\n\n    def test_session_get_adapter_prefix_matching(self):\n        prefix = \"https://example.com\"\n        more_specific_prefix = prefix + \"/some/path\"\n\n        url_matching_only_prefix = prefix + \"/another/path\"\n        url_matching_more_specific_prefix = more_specific_prefix + \"/longer/path\"\n        url_not_matching_prefix = \"https://another.example.com/\"\n\n        s = requests.Session()\n        prefix_adapter = HTTPAdapter()\n        more_specific_prefix_adapter = HTTPAdapter()\n        s.mount(prefix, prefix_adapter)\n        s.mount(more_specific_prefix, more_specific_prefix_adapter)\n\n        assert s.get_adapter(url_matching_only_prefix) is prefix_adapter\n        assert (\n            s.get_adapter(url_matching_more_specific_prefix)\n            is more_specific_prefix_adapter\n        )\n        assert s.get_adapter(url_not_matching_prefix) n"}, {"start_line": 0, "end_line": 2000, "belongs_to": {"file_name": "adapters.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "\"\"\"\nrequests.adapters\n~~~~~~~~~~~~~~~~~\n\nThis module contains the transport adapters that Requests uses to define\nand maintain connections.\n\"\"\"\n\nimport os.path\nimport socket  # noqa: F401\nimport typing\nimport warnings\n\nfrom urllib3.exceptions import ClosedPoolError, ConnectTimeoutError\nfrom urllib3.exceptions import HTTPError as _HTTPError\nfrom urllib3.exceptions import InvalidHeader as _InvalidHeader\nfrom urllib3.exceptions import (\n    LocationValueError,\n    MaxRetryError,\n    NewConnectionError,\n    ProtocolError,\n)\nfrom urllib3.exceptions import ProxyError as _ProxyError\nfrom urllib3.exceptions import ReadTimeoutError, ResponseError\nfrom urllib3.exceptions import SSLError as _SSLError\nfrom urllib3.poolmanager import PoolManager, proxy_from_url\nfrom urllib3.util import Timeout as TimeoutSauce\nfrom urllib3.util import parse_url\nfrom urllib3.util.retry import Retry\n\nfrom .auth import _basic_auth_str\nfrom .compat import basestring, urlparse\nfrom .cookies import extract_cookies_to_jar\nfrom .exceptions import (\n    ConnectionError,\n    ConnectTimeout,\n    InvalidHeader,\n    InvalidProxyURL,\n    InvalidSchema,\n    InvalidURL,\n    ProxyError,\n    ReadTimeout,\n    RetryError,\n    SSLError,\n)\nfrom .models import Response\nfrom .structures import CaseInsensitiveDict\nfrom .utils import (\n    DEFAULT_CA_BUNDLE_PATH,\n    extract_zipped_paths,\n    get_auth_from_url,\n    get_encoding_from_headers,\n    prepend_scheme_if_needed,\n    select_proxy,\n    urldefragauth,\n)\n\ntry:\n    from urllib3.contrib.socks import SOCKSProxyManager\nexcept ImportError:\n\n    def SOCKSProxyManager(*args, **kwargs):\n        raise InvalidSchema(\"Missing dependencies for SOCKS support.\")\n\n\nif typing.TYPE_CHECKING:\n    from .models import PreparedRequest\n\n\nDEFAULT_POOLBLOCK = False\nDEFAULT_POOLSIZE = 10\nDEFAULT_RETRIES = 0\nDEFAULT_POOL_TIMEOUT = None\n\n\ndef _urllib3_request_context(\n    request: \"PreparedRequest\",\n    verify: \"bool | str | None\",\n    client_cert: \"typing.Tuple[str, str] | str | None\",\n    po"}, {"start_line": 1000, "end_line": 3000, "belongs_to": {"file_name": "__init__.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "ormalizer_version\nexcept ImportError:\n    charset_normalizer_version = None\n\ntry:\n    from chardet import __version__ as chardet_version\nexcept ImportError:\n    chardet_version = None\n\n\ndef check_compatibility(urllib3_version, chardet_version, charset_normalizer_version):\n    urllib3_version = urllib3_version.split(\".\")\n    assert urllib3_version != [\"dev\"]  # Verify urllib3 isn't installed from git.\n\n    # Sometimes, urllib3 only reports its version as 16.1.\n    if len(urllib3_version) == 2:\n        urllib3_version.append(\"0\")\n\n    # Check urllib3 for compatibility.\n    major, minor, patch = urllib3_version  # noqa: F811\n    major, minor, patch = int(major), int(minor), int(patch)\n    # urllib3 >= 1.21.1\n    assert major >= 1\n    if major == 1:\n        assert minor >= 21\n\n    # Check charset_normalizer for compatibility.\n    if chardet_version:\n        major, minor, patch = chardet_version.split(\".\")[:3]\n        major, minor, patch = int(major), int(minor), int(patch)\n        # chardet_version >= 3.0.2, < 6.0.0\n        assert (3, 0, 2) <= (major, minor, patch) < (6, 0, 0)\n    elif charset_normalizer_version:\n        major, minor, patch = charset_normalizer_version.split(\".\")[:3]\n        major, minor, patch = int(major), int(minor), int(patch)\n        # charset_normalizer >= 2.0.0 < 4.0.0\n        assert (2, 0, 0) <= (major, minor, patch) < (4, 0, 0)\n    else:\n        warnings.warn(\n            \"Unable to find acceptable character detection dependency \"\n            \"(chardet or charset_normalizer).\",\n            RequestsDependencyWarning,\n        )\n\n\ndef _check_cryptography(cryptography_version):\n    # cryptography < 1.3.4\n    try:\n        cryptography_version = list(map(int, cryptography_version.split(\".\")))\n    except ValueError:\n        return\n\n    if cryptography_version < [1, 3, 4]:\n        warning = \"Old version of cryptography ({}) may cause slowdown.\".format(\n            cryptography_version\n        )\n        warnings.warn(warning, RequestsDependencyWarning)\n"}, {"start_line": 58000, "end_line": 60000, "belongs_to": {"file_name": "test_requests.py", "upper_path": "/data2/raymone/swebench-repos/requests/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "http://\": HTTPAdapter()}\n        s2.mount(\"https://\", HTTPAdapter())\n        assert \"http://\" in s2.adapters\n        assert \"https://\" in s2.adapters\n\n    def test_session_get_adapter_prefix_matching(self):\n        prefix = \"https://example.com\"\n        more_specific_prefix = prefix + \"/some/path\"\n\n        url_matching_only_prefix = prefix + \"/another/path\"\n        url_matching_more_specific_prefix = more_specific_prefix + \"/longer/path\"\n        url_not_matching_prefix = \"https://another.example.com/\"\n\n        s = requests.Session()\n        prefix_adapter = HTTPAdapter()\n        more_specific_prefix_adapter = HTTPAdapter()\n        s.mount(prefix, prefix_adapter)\n        s.mount(more_specific_prefix, more_specific_prefix_adapter)\n\n        assert s.get_adapter(url_matching_only_prefix) is prefix_adapter\n        assert (\n            s.get_adapter(url_matching_more_specific_prefix)\n            is more_specific_prefix_adapter\n        )\n        assert s.get_adapter(url_not_matching_prefix) not in (\n            prefix_adapter,\n            more_specific_prefix_adapter,\n        )\n\n    def test_session_get_adapter_prefix_matching_mixed_case(self):\n        mixed_case_prefix = \"hTtPs://eXamPle.CoM/MixEd_CAse_PREfix\"\n        url_matching_prefix = mixed_case_prefix + \"/full_url\"\n\n        s = requests.Session()\n        my_adapter = HTTPAdapter()\n        s.mount(mixed_case_prefix, my_adapter)\n\n        assert s.get_adapter(url_matching_prefix) is my_adapter\n\n    def test_session_get_adapter_prefix_matching_is_case_insensitive(self):\n        mixed_case_prefix = \"hTtPs://eXamPle.CoM/MixEd_CAse_PREfix\"\n        url_matching_prefix_with_different_case = (\n            \"HtTpS://exaMPLe.cOm/MiXeD_caSE_preFIX/another_url\"\n        )\n\n        s = requests.Session()\n        my_adapter = HTTPAdapter()\n        s.mount(mixed_case_prefix, my_adapter)\n\n        assert s.get_adapter(url_matching_prefix_with_different_case) is my_adapter\n\n    def test_session_get_adapter_prefix_with_trailing_slash(self"}, {"start_line": 28000, "end_line": 30000, "belongs_to": {"file_name": "sessions.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "vironment's proxies.\n            no_proxy = proxies.get(\"no_proxy\") if proxies is not None else None\n            env_proxies = get_environ_proxies(url, no_proxy=no_proxy)\n            for k, v in env_proxies.items():\n                proxies.setdefault(k, v)\n\n            # Look for requests environment configuration\n            # and be compatible with cURL.\n            if verify is True or verify is None:\n                verify = (\n                    os.environ.get(\"REQUESTS_CA_BUNDLE\")\n                    or os.environ.get(\"CURL_CA_BUNDLE\")\n                    or verify\n                )\n\n        # Merge all the kwargs.\n        proxies = merge_setting(proxies, self.proxies)\n        stream = merge_setting(stream, self.stream)\n        verify = merge_setting(verify, self.verify)\n        cert = merge_setting(cert, self.cert)\n\n        return {\"proxies\": proxies, \"stream\": stream, \"verify\": verify, \"cert\": cert}\n\n    def get_adapter(self, url):\n        \"\"\"\n        Returns the appropriate connection adapter for the given URL.\n\n        :rtype: requests.adapters.BaseAdapter\n        \"\"\"\n        for prefix, adapter in self.adapters.items():\n            if url.lower().startswith(prefix.lower()):\n                return adapter\n\n        # Nothing matches :-/\n        raise InvalidSchema(f\"No connection adapters were found for {url!r}\")\n\n    def close(self):\n        \"\"\"Closes all adapters and as such the session\"\"\"\n        for v in self.adapters.values():\n            v.close()\n\n    def mount(self, prefix, adapter):\n        \"\"\"Registers a connection adapter to a prefix.\n\n        Adapters are sorted in descending order by prefix length.\n        \"\"\"\n        self.adapters[prefix] = adapter\n        keys_to_move = [k for k in self.adapters if len(k) < len(prefix)]\n\n        for key in keys_to_move:\n            self.adapters[key] = self.adapters.pop(key)\n\n    def __getstate__(self):\n        state = {attr: getattr(self, attr, None) for attr in self.__attrs__}\n        return state\n\n    def "}, {"start_line": 56000, "end_line": 58000, "belongs_to": {"file_name": "test_requests.py", "upper_path": "/data2/raymone/swebench-repos/requests/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "d(r.prepare())\n        assert r.status_code == 200\n\n    def test_fixes_1329(self, httpbin):\n        \"\"\"Ensure that header updates are done case-insensitively.\"\"\"\n        s = requests.Session()\n        s.headers.update({\"ACCEPT\": \"BOGUS\"})\n        s.headers.update({\"accept\": \"application/json\"})\n        r = s.get(httpbin(\"get\"))\n        headers = r.request.headers\n        assert headers[\"accept\"] == \"application/json\"\n        assert headers[\"Accept\"] == \"application/json\"\n        assert headers[\"ACCEPT\"] == \"application/json\"\n\n    def test_uppercase_scheme_redirect(self, httpbin):\n        parts = urlparse(httpbin(\"html\"))\n        url = \"HTTP://\" + parts.netloc + parts.path\n        r = requests.get(httpbin(\"redirect-to\"), params={\"url\": url})\n        assert r.status_code == 200\n        assert r.url.lower() == url.lower()\n\n    def test_transport_adapter_ordering(self):\n        s = requests.Session()\n        order = [\"https://\", \"http://\"]\n        assert order == list(s.adapters)\n        s.mount(\"http://git\", HTTPAdapter())\n        s.mount(\"http://github\", HTTPAdapter())\n        s.mount(\"http://github.com\", HTTPAdapter())\n        s.mount(\"http://github.com/about/\", HTTPAdapter())\n        order = [\n            \"http://github.com/about/\",\n            \"http://github.com\",\n            \"http://github\",\n            \"http://git\",\n            \"https://\",\n            \"http://\",\n        ]\n        assert order == list(s.adapters)\n        s.mount(\"http://gittip\", HTTPAdapter())\n        s.mount(\"http://gittip.com\", HTTPAdapter())\n        s.mount(\"http://gittip.com/about/\", HTTPAdapter())\n        order = [\n            \"http://github.com/about/\",\n            \"http://gittip.com/about/\",\n            \"http://github.com\",\n            \"http://gittip.com\",\n            \"http://github\",\n            \"http://gittip\",\n            \"http://git\",\n            \"https://\",\n            \"http://\",\n        ]\n        assert order == list(s.adapters)\n        s2 = requests.Session()\n        s2.adapters = {\""}], "retrieved_count": 10, "cost_time": 3.7565290927886963}
{"question": "What is the structure of Requests' response object?", "answer": null, "relative_code_list": null, "ground_truth": "The Response object (src/requests/models.py) has the following structure: Core attributes include status_code (HTTP status code), headers (case-insensitive dictionary of response headers), url (final URL after redirects), encoding (character encoding), reason (textual status reason), cookies (CookieJar of server cookies), elapsed (timedelta of request duration), and request (reference to the PreparedRequest). Content-related attributes include _content (raw response content), _content_consumed (flag for content consumption), raw (file-like object for streaming), and history (list of redirect responses). The object implements context manager protocol (__enter__/__exit__), iteration protocol (__iter__), and boolean evaluation (__bool__ returns True if status_code < 400). Key properties include ok (boolean status check), is_redirect (checks for redirect status), is_permanent_redirect (checks for permanent redirects), next (PreparedRequest for redirect chain), and apparent_encoding (detected character encoding). The object supports content iteration, JSON parsing, and automatic status code checking with raise_for_status().", "score": null, "retrieved_content": [{"start_line": 21000, "end_line": 23000, "belongs_to": {"file_name": "models.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "nse>` object, which contains a\n    server's response to an HTTP request.\n    \"\"\"\n\n    __attrs__ = [\n        \"_content\",\n        \"status_code\",\n        \"headers\",\n        \"url\",\n        \"history\",\n        \"encoding\",\n        \"reason\",\n        \"cookies\",\n        \"elapsed\",\n        \"request\",\n    ]\n\n    def __init__(self):\n        self._content = False\n        self._content_consumed = False\n        self._next = None\n\n        #: Integer Code of responded HTTP Status, e.g. 404 or 200.\n        self.status_code = None\n\n        #: Case-insensitive Dictionary of Response Headers.\n        #: For example, ``headers['content-encoding']`` will return the\n        #: value of a ``'Content-Encoding'`` response header.\n        self.headers = CaseInsensitiveDict()\n\n        #: File-like object representation of response (for advanced usage).\n        #: Use of ``raw`` requires that ``stream=True`` be set on the request.\n        #: This requirement does not apply for use internally to Requests.\n        self.raw = None\n\n        #: Final URL location of Response.\n        self.url = None\n\n        #: Encoding to decode with when accessing r.text.\n        self.encoding = None\n\n        #: A list of :class:`Response <Response>` objects from\n        #: the history of the Request. Any redirect responses will end\n        #: up here. The list is sorted from the oldest to the most recent request.\n        self.history = []\n\n        #: Textual reason of responded HTTP Status, e.g. \"Not Found\" or \"OK\".\n        self.reason = None\n\n        #: A CookieJar of Cookies the server sent back.\n        self.cookies = cookiejar_from_dict({})\n\n        #: The amount of time elapsed between sending the request\n        #: and the arrival of the response (as a timedelta).\n        #: This property specifically measures the time taken between sending\n        #: the first byte of the request and finishing parsing the headers. It\n        #: is therefore unaffected by consuming the response content or the\n        #: value"}, {"start_line": 22000, "end_line": 24000, "belongs_to": {"file_name": "models.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "f.raw = None\n\n        #: Final URL location of Response.\n        self.url = None\n\n        #: Encoding to decode with when accessing r.text.\n        self.encoding = None\n\n        #: A list of :class:`Response <Response>` objects from\n        #: the history of the Request. Any redirect responses will end\n        #: up here. The list is sorted from the oldest to the most recent request.\n        self.history = []\n\n        #: Textual reason of responded HTTP Status, e.g. \"Not Found\" or \"OK\".\n        self.reason = None\n\n        #: A CookieJar of Cookies the server sent back.\n        self.cookies = cookiejar_from_dict({})\n\n        #: The amount of time elapsed between sending the request\n        #: and the arrival of the response (as a timedelta).\n        #: This property specifically measures the time taken between sending\n        #: the first byte of the request and finishing parsing the headers. It\n        #: is therefore unaffected by consuming the response content or the\n        #: value of the ``stream`` keyword argument.\n        self.elapsed = datetime.timedelta(0)\n\n        #: The :class:`PreparedRequest <PreparedRequest>` object to which this\n        #: is a response.\n        self.request = None\n\n    def __enter__(self):\n        return self\n\n    def __exit__(self, *args):\n        self.close()\n\n    def __getstate__(self):\n        # Consume everything; accessing the content attribute makes\n        # sure the content has been fully read.\n        if not self._content_consumed:\n            self.content\n\n        return {attr: getattr(self, attr, None) for attr in self.__attrs__}\n\n    def __setstate__(self, state):\n        for name, value in state.items():\n            setattr(self, name, value)\n\n        # pickled objects do not have .raw\n        setattr(self, \"_content_consumed\", True)\n        setattr(self, \"raw\", None)\n\n    def __repr__(self):\n        return f\"<Response [{self.status_code}]>\"\n\n    def __bool__(self):\n        \"\"\"Returns True if :attr:`status_code` is less"}, {"start_line": 23000, "end_line": 25000, "belongs_to": {"file_name": "models.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": " of the ``stream`` keyword argument.\n        self.elapsed = datetime.timedelta(0)\n\n        #: The :class:`PreparedRequest <PreparedRequest>` object to which this\n        #: is a response.\n        self.request = None\n\n    def __enter__(self):\n        return self\n\n    def __exit__(self, *args):\n        self.close()\n\n    def __getstate__(self):\n        # Consume everything; accessing the content attribute makes\n        # sure the content has been fully read.\n        if not self._content_consumed:\n            self.content\n\n        return {attr: getattr(self, attr, None) for attr in self.__attrs__}\n\n    def __setstate__(self, state):\n        for name, value in state.items():\n            setattr(self, name, value)\n\n        # pickled objects do not have .raw\n        setattr(self, \"_content_consumed\", True)\n        setattr(self, \"raw\", None)\n\n    def __repr__(self):\n        return f\"<Response [{self.status_code}]>\"\n\n    def __bool__(self):\n        \"\"\"Returns True if :attr:`status_code` is less than 400.\n\n        This attribute checks if the status code of the response is between\n        400 and 600 to see if there was a client error or a server error. If\n        the status code, is between 200 and 400, this will return True. This\n        is **not** a check to see if the response code is ``200 OK``.\n        \"\"\"\n        return self.ok\n\n    def __nonzero__(self):\n        \"\"\"Returns True if :attr:`status_code` is less than 400.\n\n        This attribute checks if the status code of the response is between\n        400 and 600 to see if there was a client error or a server error. If\n        the status code, is between 200 and 400, this will return True. This\n        is **not** a check to see if the response code is ``200 OK``.\n        \"\"\"\n        return self.ok\n\n    def __iter__(self):\n        \"\"\"Allows you to use a response as an iterator.\"\"\"\n        return self.iter_content(128)\n\n    @property\n    def ok(self):\n        \"\"\"Returns True if :attr:`status_code` is less than 400, Fals"}, {"start_line": 74000, "end_line": 76000, "belongs_to": {"file_name": "test_requests.py", "upper_path": "/data2/raymone/swebench-repos/requests/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "name, password)\n        assert isinstance(s, builtin_str)\n        assert s == auth_str\n\n    def test_requests_history_is_saved(self, httpbin):\n        r = requests.get(httpbin(\"redirect/5\"))\n        total = r.history[-1].history\n        i = 0\n        for item in r.history:\n            assert item.history == total[0:i]\n            i += 1\n\n    def test_json_param_post_content_type_works(self, httpbin):\n        r = requests.post(httpbin(\"post\"), json={\"life\": 42})\n        assert r.status_code == 200\n        assert \"application/json\" in r.request.headers[\"Content-Type\"]\n        assert {\"life\": 42} == r.json()[\"json\"]\n\n    def test_json_param_post_should_not_override_data_param(self, httpbin):\n        r = requests.Request(\n            method=\"POST\",\n            url=httpbin(\"post\"),\n            data={\"stuff\": \"elixr\"},\n            json={\"music\": \"flute\"},\n        )\n        prep = r.prepare()\n        assert \"stuff=elixr\" == prep.body\n\n    def test_response_iter_lines(self, httpbin):\n        r = requests.get(httpbin(\"stream/4\"), stream=True)\n        assert r.status_code == 200\n\n        it = r.iter_lines()\n        next(it)\n        assert len(list(it)) == 3\n\n    def test_response_context_manager(self, httpbin):\n        with requests.get(httpbin(\"stream/4\"), stream=True) as response:\n            assert isinstance(response, requests.Response)\n\n        assert response.raw.closed\n\n    def test_unconsumed_session_response_closes_connection(self, httpbin):\n        s = requests.session()\n\n        with contextlib.closing(s.get(httpbin(\"stream/4\"), stream=True)) as response:\n            pass\n\n        assert response._content_consumed is False\n        assert response.raw.closed\n\n    @pytest.mark.xfail\n    def test_response_iter_lines_reentrant(self, httpbin):\n        \"\"\"Response.iter_lines() is not reentrant safe\"\"\"\n        r = requests.get(httpbin(\"stream/4\"), stream=True)\n        assert r.status_code == 200\n\n        next(r.iter_lines())\n        assert len(list(r.iter_lines())) == 3\n\n"}, {"start_line": 44000, "end_line": 46000, "belongs_to": {"file_name": "test_requests.py", "upper_path": "/data2/raymone/swebench-repos/requests/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "      s = requests.Session()\n        resp = s.request(\n            \"GET\",\n            httpbin(\"cookies/set?cookie=value\"),\n            allow_redirects=False,\n            headers={\"Host\": b\"httpbin.org\"},\n        )\n        assert resp.cookies.get(\"cookie\") == \"value\"\n\n    def test_links(self):\n        r = requests.Response()\n        r.headers = {\n            \"cache-control\": \"public, max-age=60, s-maxage=60\",\n            \"connection\": \"keep-alive\",\n            \"content-encoding\": \"gzip\",\n            \"content-type\": \"application/json; charset=utf-8\",\n            \"date\": \"Sat, 26 Jan 2013 16:47:56 GMT\",\n            \"etag\": '\"6ff6a73c0e446c1f61614769e3ceb778\"',\n            \"last-modified\": \"Sat, 26 Jan 2013 16:22:39 GMT\",\n            \"link\": (\n                \"<https://api.github.com/users/kennethreitz/repos?\"\n                'page=2&per_page=10>; rel=\"next\", <https://api.github.'\n                \"com/users/kennethreitz/repos?page=7&per_page=10>; \"\n                ' rel=\"last\"'\n            ),\n            \"server\": \"GitHub.com\",\n            \"status\": \"200 OK\",\n            \"vary\": \"Accept\",\n            \"x-content-type-options\": \"nosniff\",\n            \"x-github-media-type\": \"github.beta\",\n            \"x-ratelimit-limit\": \"60\",\n            \"x-ratelimit-remaining\": \"57\",\n        }\n        assert r.links[\"next\"][\"rel\"] == \"next\"\n\n    def test_cookie_parameters(self):\n        key = \"some_cookie\"\n        value = \"some_value\"\n        secure = True\n        domain = \"test.com\"\n        rest = {\"HttpOnly\": True}\n\n        jar = requests.cookies.RequestsCookieJar()\n        jar.set(key, value, secure=secure, domain=domain, rest=rest)\n\n        assert len(jar) == 1\n        assert \"some_cookie\" in jar\n\n        cookie = list(jar)[0]\n        assert cookie.secure == secure\n        assert cookie.domain == domain\n        assert cookie._rest[\"HttpOnly\"] == rest[\"HttpOnly\"]\n\n    def test_cookie_as_dict_keeps_len(self):\n        key = \"some_cookie\"\n        value = \"some_value\"\n\n        key1 = \"som"}, {"start_line": 5000, "end_line": 7000, "belongs_to": {"file_name": "sessions.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "        changed_port = old_parsed.port != new_parsed.port\n        changed_scheme = old_parsed.scheme != new_parsed.scheme\n        default_port = (DEFAULT_PORTS.get(old_parsed.scheme, None), None)\n        if (\n            not changed_scheme\n            and old_parsed.port in default_port\n            and new_parsed.port in default_port\n        ):\n            return False\n\n        # Standard case: root URI must match\n        return changed_port or changed_scheme\n\n    def resolve_redirects(\n        self,\n        resp,\n        req,\n        stream=False,\n        timeout=None,\n        verify=True,\n        cert=None,\n        proxies=None,\n        yield_requests=False,\n        **adapter_kwargs,\n    ):\n        \"\"\"Receives a Response. Returns a generator of Responses or Requests.\"\"\"\n\n        hist = []  # keep track of history\n\n        url = self.get_redirect_target(resp)\n        previous_fragment = urlparse(req.url).fragment\n        while url:\n            prepared_request = req.copy()\n\n            # Update history and keep track of redirects.\n            # resp.history must ignore the original request in this loop\n            hist.append(resp)\n            resp.history = hist[1:]\n\n            try:\n                resp.content  # Consume socket so it can be released\n            except (ChunkedEncodingError, ContentDecodingError, RuntimeError):\n                resp.raw.read(decode_content=False)\n\n            if len(resp.history) >= self.max_redirects:\n                raise TooManyRedirects(\n                    f\"Exceeded {self.max_redirects} redirects.\", response=resp\n                )\n\n            # Release the connection back into the pool.\n            resp.close()\n\n            # Handle redirection without scheme (see: RFC 1808 Section 4)\n            if url.startswith(\"//\"):\n                parsed_rurl = urlparse(resp.url)\n                url = \":\".join([to_native_string(parsed_rurl.scheme), url])\n\n            # Normalize url case and attach previous fragment if needed (RFC 723"}, {"start_line": 23000, "end_line": 25000, "belongs_to": {"file_name": "sessions.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "elf.request(\"HEAD\", url, **kwargs)\n\n    def post(self, url, data=None, json=None, **kwargs):\n        r\"\"\"Sends a POST request. Returns :class:`Response` object.\n\n        :param url: URL for the new :class:`Request` object.\n        :param data: (optional) Dictionary, list of tuples, bytes, or file-like\n            object to send in the body of the :class:`Request`.\n        :param json: (optional) json to send in the body of the :class:`Request`.\n        :param \\*\\*kwargs: Optional arguments that ``request`` takes.\n        :rtype: requests.Response\n        \"\"\"\n\n        return self.request(\"POST\", url, data=data, json=json, **kwargs)\n\n    def put(self, url, data=None, **kwargs):\n        r\"\"\"Sends a PUT request. Returns :class:`Response` object.\n\n        :param url: URL for the new :class:`Request` object.\n        :param data: (optional) Dictionary, list of tuples, bytes, or file-like\n            object to send in the body of the :class:`Request`.\n        :param \\*\\*kwargs: Optional arguments that ``request`` takes.\n        :rtype: requests.Response\n        \"\"\"\n\n        return self.request(\"PUT\", url, data=data, **kwargs)\n\n    def patch(self, url, data=None, **kwargs):\n        r\"\"\"Sends a PATCH request. Returns :class:`Response` object.\n\n        :param url: URL for the new :class:`Request` object.\n        :param data: (optional) Dictionary, list of tuples, bytes, or file-like\n            object to send in the body of the :class:`Request`.\n        :param \\*\\*kwargs: Optional arguments that ``request`` takes.\n        :rtype: requests.Response\n        \"\"\"\n\n        return self.request(\"PATCH\", url, data=data, **kwargs)\n\n    def delete(self, url, **kwargs):\n        r\"\"\"Sends a DELETE request. Returns :class:`Response` object.\n\n        :param url: URL for the new :class:`Request` object.\n        :param \\*\\*kwargs: Optional arguments that ``request`` takes.\n        :rtype: requests.Response\n        \"\"\"\n\n        return self.request(\"DELETE\", url, **kwargs)\n\n    def send(self, r"}, {"start_line": 22000, "end_line": 24000, "belongs_to": {"file_name": "sessions.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "for the new :class:`Request` object.\n        :param \\*\\*kwargs: Optional arguments that ``request`` takes.\n        :rtype: requests.Response\n        \"\"\"\n\n        kwargs.setdefault(\"allow_redirects\", True)\n        return self.request(\"GET\", url, **kwargs)\n\n    def options(self, url, **kwargs):\n        r\"\"\"Sends a OPTIONS request. Returns :class:`Response` object.\n\n        :param url: URL for the new :class:`Request` object.\n        :param \\*\\*kwargs: Optional arguments that ``request`` takes.\n        :rtype: requests.Response\n        \"\"\"\n\n        kwargs.setdefault(\"allow_redirects\", True)\n        return self.request(\"OPTIONS\", url, **kwargs)\n\n    def head(self, url, **kwargs):\n        r\"\"\"Sends a HEAD request. Returns :class:`Response` object.\n\n        :param url: URL for the new :class:`Request` object.\n        :param \\*\\*kwargs: Optional arguments that ``request`` takes.\n        :rtype: requests.Response\n        \"\"\"\n\n        kwargs.setdefault(\"allow_redirects\", False)\n        return self.request(\"HEAD\", url, **kwargs)\n\n    def post(self, url, data=None, json=None, **kwargs):\n        r\"\"\"Sends a POST request. Returns :class:`Response` object.\n\n        :param url: URL for the new :class:`Request` object.\n        :param data: (optional) Dictionary, list of tuples, bytes, or file-like\n            object to send in the body of the :class:`Request`.\n        :param json: (optional) json to send in the body of the :class:`Request`.\n        :param \\*\\*kwargs: Optional arguments that ``request`` takes.\n        :rtype: requests.Response\n        \"\"\"\n\n        return self.request(\"POST\", url, data=data, json=json, **kwargs)\n\n    def put(self, url, data=None, **kwargs):\n        r\"\"\"Sends a PUT request. Returns :class:`Response` object.\n\n        :param url: URL for the new :class:`Request` object.\n        :param data: (optional) Dictionary, list of tuples, bytes, or file-like\n            object to send in the body of the :class:`Request`.\n        :param \\*\\*kwargs: Optional argume"}, {"start_line": 49000, "end_line": 51000, "belongs_to": {"file_name": "test_requests.py", "upper_path": "/data2/raymone/swebench-repos/requests/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "       value = \"some_value\"\n        path = \"some_path\"\n\n        jar = requests.cookies.RequestsCookieJar()\n        jar.set(key, value, path=path)\n        jar.set(key, value)\n        with pytest.raises(requests.cookies.CookieConflictError):\n            jar.get(key)\n\n    def test_cookie_policy_copy(self):\n        class MyCookiePolicy(cookielib.DefaultCookiePolicy):\n            pass\n\n        jar = requests.cookies.RequestsCookieJar()\n        jar.set_policy(MyCookiePolicy())\n        assert isinstance(jar.copy().get_policy(), MyCookiePolicy)\n\n    def test_time_elapsed_blank(self, httpbin):\n        r = requests.get(httpbin(\"get\"))\n        td = r.elapsed\n        total_seconds = (\n            td.microseconds + (td.seconds + td.days * 24 * 3600) * 10**6\n        ) / 10**6\n        assert total_seconds > 0.0\n\n    def test_empty_response_has_content_none(self):\n        r = requests.Response()\n        assert r.content is None\n\n    def test_response_is_iterable(self):\n        r = requests.Response()\n        io = StringIO.StringIO(\"abc\")\n        read_ = io.read\n\n        def read_mock(amt, decode_content=None):\n            return read_(amt)\n\n        setattr(io, \"read\", read_mock)\n        r.raw = io\n        assert next(iter(r))\n        io.close()\n\n    def test_response_decode_unicode(self):\n        \"\"\"When called with decode_unicode, Response.iter_content should always\n        return unicode.\n        \"\"\"\n        r = requests.Response()\n        r._content_consumed = True\n        r._content = b\"the content\"\n        r.encoding = \"ascii\"\n\n        chunks = r.iter_content(decode_unicode=True)\n        assert all(isinstance(chunk, str) for chunk in chunks)\n\n        # also for streaming\n        r = requests.Response()\n        r.raw = io.BytesIO(b\"the content\")\n        r.encoding = \"ascii\"\n        chunks = r.iter_content(decode_unicode=True)\n        assert all(isinstance(chunk, str) for chunk in chunks)\n\n    def test_response_reason_unicode(self):\n        # check for unicode HTTP status\n      "}, {"start_line": 73000, "end_line": 75000, "belongs_to": {"file_name": "test_requests.py", "upper_path": "/data2/raymone/swebench-repos/requests/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "er.build_response\n        self._patched_response = False\n\n        def build_response(*args, **kwargs):\n            resp = org_build_response(*args, **kwargs)\n            if not self._patched_response:\n                resp.raw.headers[\"content-encoding\"] = \"gzip\"\n                self._patched_response = True\n            return resp\n\n        adapter.build_response = build_response\n\n    def test_redirect_with_wrong_gzipped_header(self, httpbin):\n        s = requests.Session()\n        url = httpbin(\"redirect/1\")\n        self._patch_adapter_gzipped_redirect(s, url)\n        s.get(url)\n\n    @pytest.mark.parametrize(\n        \"username, password, auth_str\",\n        (\n            (\"test\", \"test\", \"Basic dGVzdDp0ZXN0\"),\n            (\n                \"\".encode(),\n                \"\".encode(),\n                \"Basic 0LjQvNGPOtC/0LDRgNC+0LvRjA==\",\n            ),\n        ),\n    )\n    def test_basic_auth_str_is_always_native(self, username, password, auth_str):\n        s = _basic_auth_str(username, password)\n        assert isinstance(s, builtin_str)\n        assert s == auth_str\n\n    def test_requests_history_is_saved(self, httpbin):\n        r = requests.get(httpbin(\"redirect/5\"))\n        total = r.history[-1].history\n        i = 0\n        for item in r.history:\n            assert item.history == total[0:i]\n            i += 1\n\n    def test_json_param_post_content_type_works(self, httpbin):\n        r = requests.post(httpbin(\"post\"), json={\"life\": 42})\n        assert r.status_code == 200\n        assert \"application/json\" in r.request.headers[\"Content-Type\"]\n        assert {\"life\": 42} == r.json()[\"json\"]\n\n    def test_json_param_post_should_not_override_data_param(self, httpbin):\n        r = requests.Request(\n            method=\"POST\",\n            url=httpbin(\"post\"),\n            data={\"stuff\": \"elixr\"},\n            json={\"music\": \"flute\"},\n        )\n        prep = r.prepare()\n        assert \"stuff=elixr\" == prep.body\n\n    def test_response_iter_lines(self, httpbin):\n        r"}], "retrieved_count": 10, "cost_time": 3.8336920738220215}
{"question": "What are the core components of Requests' HTTP client?", "answer": null, "relative_code_list": null, "ground_truth": "The core components of Requests' HTTP client include: 1) Session class (src/requests/sessions.py) - manages connection pooling, cookies, and configuration; 2) Request and PreparedRequest classes (src/requests/models.py) - handle request preparation and encoding; 3) Response class (src/requests/models.py) - represents HTTP responses; 4) HTTPAdapter and BaseAdapter (src/requests/adapters.py) - provide transport abstraction and connection pooling; 5) Authentication handlers (src/requests/auth.py) - handle various authentication schemes; 6) Cookie handling (src/requests/cookies.py) - manage cookie persistence; 7) Exception classes (src/requests/exceptions.py) - handle various error conditions; 8) Utility functions (src/requests/utils.py) - provide encoding, URL parsing, and other utilities. The main API functions (get, post, etc.) are defined in src/requests/api.py and use the Session class internally.", "score": null, "retrieved_content": [{"start_line": 3000, "end_line": 5000, "belongs_to": {"file_name": "__init__.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "\n\n# Check imported dependencies for compatibility.\ntry:\n    check_compatibility(\n        urllib3.__version__, chardet_version, charset_normalizer_version\n    )\nexcept (AssertionError, ValueError):\n    warnings.warn(\n        \"urllib3 ({}) or chardet ({})/charset_normalizer ({}) doesn't match a supported \"\n        \"version!\".format(\n            urllib3.__version__, chardet_version, charset_normalizer_version\n        ),\n        RequestsDependencyWarning,\n    )\n\n# Attempt to enable urllib3's fallback for SNI support\n# if the standard library doesn't support SNI or the\n# 'ssl' library isn't available.\ntry:\n    try:\n        import ssl\n    except ImportError:\n        ssl = None\n\n    if not getattr(ssl, \"HAS_SNI\", False):\n        from urllib3.contrib import pyopenssl\n\n        pyopenssl.inject_into_urllib3()\n\n        # Check cryptography version\n        from cryptography import __version__ as cryptography_version\n\n        _check_cryptography(cryptography_version)\nexcept ImportError:\n    pass\n\n# urllib3's DependencyWarnings should be silenced.\nfrom urllib3.exceptions import DependencyWarning\n\nwarnings.simplefilter(\"ignore\", DependencyWarning)\n\n# Set default logging handler to avoid \"No handler found\" warnings.\nimport logging\nfrom logging import NullHandler\n\nfrom . import packages, utils\nfrom .__version__ import (\n    __author__,\n    __author_email__,\n    __build__,\n    __cake__,\n    __copyright__,\n    __description__,\n    __license__,\n    __title__,\n    __url__,\n    __version__,\n)\nfrom .api import delete, get, head, options, patch, post, put, request\nfrom .exceptions import (\n    ConnectionError,\n    ConnectTimeout,\n    FileModeWarning,\n    HTTPError,\n    JSONDecodeError,\n    ReadTimeout,\n    RequestException,\n    Timeout,\n    TooManyRedirects,\n    URLRequired,\n)\nfrom .models import PreparedRequest, Request, Response\nfrom .sessions import Session, session\nfrom .status_codes import codes\n\nlogging.getLogger(__name__).addHandler(NullHandler())\n\n# FileModeWarnings go off per the "}, {"start_line": 4000, "end_line": 5072, "belongs_to": {"file_name": "__init__.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": " urllib3's DependencyWarnings should be silenced.\nfrom urllib3.exceptions import DependencyWarning\n\nwarnings.simplefilter(\"ignore\", DependencyWarning)\n\n# Set default logging handler to avoid \"No handler found\" warnings.\nimport logging\nfrom logging import NullHandler\n\nfrom . import packages, utils\nfrom .__version__ import (\n    __author__,\n    __author_email__,\n    __build__,\n    __cake__,\n    __copyright__,\n    __description__,\n    __license__,\n    __title__,\n    __url__,\n    __version__,\n)\nfrom .api import delete, get, head, options, patch, post, put, request\nfrom .exceptions import (\n    ConnectionError,\n    ConnectTimeout,\n    FileModeWarning,\n    HTTPError,\n    JSONDecodeError,\n    ReadTimeout,\n    RequestException,\n    Timeout,\n    TooManyRedirects,\n    URLRequired,\n)\nfrom .models import PreparedRequest, Request, Response\nfrom .sessions import Session, session\nfrom .status_codes import codes\n\nlogging.getLogger(__name__).addHandler(NullHandler())\n\n# FileModeWarnings go off per the default.\nwarnings.simplefilter(\"default\", FileModeWarning, append=True)\n"}, {"start_line": 2000, "end_line": 4000, "belongs_to": {"file_name": "test_requests.py", "upper_path": "/data2/raymone/swebench-repos/requests/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": " requests.session\n        requests.session().get\n        requests.session().head\n        requests.get\n        requests.head\n        requests.put\n        requests.patch\n        requests.post\n        # Not really an entry point, but people rely on it.\n        from requests.packages.urllib3.poolmanager import PoolManager  # noqa:F401\n\n    @pytest.mark.parametrize(\n        \"exception, url\",\n        (\n            (MissingSchema, \"hiwpefhipowhefopw\"),\n            (InvalidSchema, \"localhost:3128\"),\n            (InvalidSchema, \"localhost.localdomain:3128/\"),\n            (InvalidSchema, \"10.122.1.1:3128/\"),\n            (InvalidURL, \"http://\"),\n            (InvalidURL, \"http://*example.com\"),\n            (InvalidURL, \"http://.example.com\"),\n        ),\n    )\n    def test_invalid_url(self, exception, url):\n        with pytest.raises(exception):\n            requests.get(url)\n\n    def test_basic_building(self):\n        req = requests.Request()\n        req.url = \"http://kennethreitz.org/\"\n        req.data = {\"life\": \"42\"}\n\n        pr = req.prepare()\n        assert pr.url == req.url\n        assert pr.body == \"life=42\"\n\n    @pytest.mark.parametrize(\"method\", (\"GET\", \"HEAD\"))\n    def test_no_content_length(self, httpbin, method):\n        req = requests.Request(method, httpbin(method.lower())).prepare()\n        assert \"Content-Length\" not in req.headers\n\n    @pytest.mark.parametrize(\"method\", (\"POST\", \"PUT\", \"PATCH\", \"OPTIONS\"))\n    def test_no_body_content_length(self, httpbin, method):\n        req = requests.Request(method, httpbin(method.lower())).prepare()\n        assert req.headers[\"Content-Length\"] == \"0\"\n\n    @pytest.mark.parametrize(\"method\", (\"POST\", \"PUT\", \"PATCH\", \"OPTIONS\"))\n    def test_empty_content_length(self, httpbin, method):\n        req = requests.Request(method, httpbin(method.lower()), data=\"\").prepare()\n        assert req.headers[\"Content-Length\"] == \"0\"\n\n    def test_override_content_length(self, httpbin):\n        headers = {\"Content-Length\": \"not zero\"}\n       "}, {"start_line": 13000, "end_line": 15000, "belongs_to": {"file_name": "sessions.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "POST is responded to with a 301, turn it into a GET.\n        # This bizarre behaviour is explained in Issue 1704.\n        if response.status_code == codes.moved and method == \"POST\":\n            method = \"GET\"\n\n        prepared_request.method = method\n\n\nclass Session(SessionRedirectMixin):\n    \"\"\"A Requests session.\n\n    Provides cookie persistence, connection-pooling, and configuration.\n\n    Basic Usage::\n\n      >>> import requests\n      >>> s = requests.Session()\n      >>> s.get('https://httpbin.org/get')\n      <Response [200]>\n\n    Or as a context manager::\n\n      >>> with requests.Session() as s:\n      ...     s.get('https://httpbin.org/get')\n      <Response [200]>\n    \"\"\"\n\n    __attrs__ = [\n        \"headers\",\n        \"cookies\",\n        \"auth\",\n        \"proxies\",\n        \"hooks\",\n        \"params\",\n        \"verify\",\n        \"cert\",\n        \"adapters\",\n        \"stream\",\n        \"trust_env\",\n        \"max_redirects\",\n    ]\n\n    def __init__(self):\n        #: A case-insensitive dictionary of headers to be sent on each\n        #: :class:`Request <Request>` sent from this\n        #: :class:`Session <Session>`.\n        self.headers = default_headers()\n\n        #: Default Authentication tuple or object to attach to\n        #: :class:`Request <Request>`.\n        self.auth = None\n\n        #: Dictionary mapping protocol or protocol and host to the URL of the proxy\n        #: (e.g. {'http': 'foo.bar:3128', 'http://host.name': 'foo.bar:4012'}) to\n        #: be used on each :class:`Request <Request>`.\n        self.proxies = {}\n\n        #: Event-handling hooks.\n        self.hooks = default_hooks()\n\n        #: Dictionary of querystring data to attach to each\n        #: :class:`Request <Request>`. The dictionary values may be lists for\n        #: representing multivalued query parameters.\n        self.params = {}\n\n        #: Stream response content default.\n        self.stream = False\n\n        #: SSL Verification default.\n        #: Defaults to `True`, requiring requests to verif"}, {"start_line": 0, "end_line": 2000, "belongs_to": {"file_name": "models.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "\"\"\"\nrequests.models\n~~~~~~~~~~~~~~~\n\nThis module contains the primary objects that power Requests.\n\"\"\"\n\nimport datetime\n\n# Import encoding now, to avoid implicit import later.\n# Implicit import within threads may cause LookupError when standard library is in a ZIP,\n# such as in Embedded Python. See https://github.com/psf/requests/issues/3578.\nimport encodings.idna  # noqa: F401\nfrom io import UnsupportedOperation\n\nfrom urllib3.exceptions import (\n    DecodeError,\n    LocationParseError,\n    ProtocolError,\n    ReadTimeoutError,\n    SSLError,\n)\nfrom urllib3.fields import RequestField\nfrom urllib3.filepost import encode_multipart_formdata\nfrom urllib3.util import parse_url\n\nfrom ._internal_utils import to_native_string, unicode_is_ascii\nfrom .auth import HTTPBasicAuth\nfrom .compat import (\n    Callable,\n    JSONDecodeError,\n    Mapping,\n    basestring,\n    builtin_str,\n    chardet,\n    cookielib,\n)\nfrom .compat import json as complexjson\nfrom .compat import urlencode, urlsplit, urlunparse\nfrom .cookies import _copy_cookie_jar, cookiejar_from_dict, get_cookie_header\nfrom .exceptions import (\n    ChunkedEncodingError,\n    ConnectionError,\n    ContentDecodingError,\n    HTTPError,\n    InvalidJSONError,\n    InvalidURL,\n)\nfrom .exceptions import JSONDecodeError as RequestsJSONDecodeError\nfrom .exceptions import MissingSchema\nfrom .exceptions import SSLError as RequestsSSLError\nfrom .exceptions import StreamConsumedError\nfrom .hooks import default_hooks\nfrom .status_codes import codes\nfrom .structures import CaseInsensitiveDict\nfrom .utils import (\n    check_header_validity,\n    get_auth_from_url,\n    guess_filename,\n    guess_json_utf,\n    iter_slices,\n    parse_header_links,\n    requote_uri,\n    stream_decode_response_unicode,\n    super_len,\n    to_key_val_list,\n)\n\n#: The set of HTTP status codes that indicate an automatically\n#: processable redirect.\nREDIRECT_STATI = (\n    codes.moved,  # 301\n    codes.found,  # 302\n    codes.other,  # 303\n    codes.temporary_redirect,  # "}, {"start_line": 0, "end_line": 2000, "belongs_to": {"file_name": "__init__.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "#   __\n#  /__)  _  _     _   _ _/   _\n# / (   (- (/ (/ (- _)  /  _)\n#          /\n\n\"\"\"\nRequests HTTP Library\n~~~~~~~~~~~~~~~~~~~~~\n\nRequests is an HTTP library, written in Python, for human beings.\nBasic GET usage:\n\n   >>> import requests\n   >>> r = requests.get('https://www.python.org')\n   >>> r.status_code\n   200\n   >>> b'Python is a programming language' in r.content\n   True\n\n... or POST:\n\n   >>> payload = dict(key1='value1', key2='value2')\n   >>> r = requests.post('https://httpbin.org/post', data=payload)\n   >>> print(r.text)\n   {\n     ...\n     \"form\": {\n       \"key1\": \"value1\",\n       \"key2\": \"value2\"\n     },\n     ...\n   }\n\nThe other HTTP methods are supported - see `requests.api`. Full documentation\nis at <https://requests.readthedocs.io>.\n\n:copyright: (c) 2017 by Kenneth Reitz.\n:license: Apache 2.0, see LICENSE for more details.\n\"\"\"\n\nimport warnings\n\nimport urllib3\n\nfrom .exceptions import RequestsDependencyWarning\n\ntry:\n    from charset_normalizer import __version__ as charset_normalizer_version\nexcept ImportError:\n    charset_normalizer_version = None\n\ntry:\n    from chardet import __version__ as chardet_version\nexcept ImportError:\n    chardet_version = None\n\n\ndef check_compatibility(urllib3_version, chardet_version, charset_normalizer_version):\n    urllib3_version = urllib3_version.split(\".\")\n    assert urllib3_version != [\"dev\"]  # Verify urllib3 isn't installed from git.\n\n    # Sometimes, urllib3 only reports its version as 16.1.\n    if len(urllib3_version) == 2:\n        urllib3_version.append(\"0\")\n\n    # Check urllib3 for compatibility.\n    major, minor, patch = urllib3_version  # noqa: F811\n    major, minor, patch = int(major), int(minor), int(patch)\n    # urllib3 >= 1.21.1\n    assert major >= 1\n    if major == 1:\n        assert minor >= 21\n\n    # Check charset_normalizer for compatibility.\n    if chardet_version:\n        major, minor, patch = chardet_version.split(\".\")[:3]\n        major, minor, patch = int(major), int(minor), int(patch)\n        # charde"}, {"start_line": 0, "end_line": 2000, "belongs_to": {"file_name": "api.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "\"\"\"\nrequests.api\n~~~~~~~~~~~~\n\nThis module implements the Requests API.\n\n:copyright: (c) 2012 by Kenneth Reitz.\n:license: Apache2, see LICENSE for more details.\n\"\"\"\n\nfrom . import sessions\n\n\ndef request(method, url, **kwargs):\n    \"\"\"Constructs and sends a :class:`Request <Request>`.\n\n    :param method: method for the new :class:`Request` object: ``GET``, ``OPTIONS``, ``HEAD``, ``POST``, ``PUT``, ``PATCH``, or ``DELETE``.\n    :param url: URL for the new :class:`Request` object.\n    :param params: (optional) Dictionary, list of tuples or bytes to send\n        in the query string for the :class:`Request`.\n    :param data: (optional) Dictionary, list of tuples, bytes, or file-like\n        object to send in the body of the :class:`Request`.\n    :param json: (optional) A JSON serializable Python object to send in the body of the :class:`Request`.\n    :param headers: (optional) Dictionary of HTTP Headers to send with the :class:`Request`.\n    :param cookies: (optional) Dict or CookieJar object to send with the :class:`Request`.\n    :param files: (optional) Dictionary of ``'name': file-like-objects`` (or ``{'name': file-tuple}``) for multipart encoding upload.\n        ``file-tuple`` can be a 2-tuple ``('filename', fileobj)``, 3-tuple ``('filename', fileobj, 'content_type')``\n        or a 4-tuple ``('filename', fileobj, 'content_type', custom_headers)``, where ``'content_type'`` is a string\n        defining the content type of the given file and ``custom_headers`` a dict-like object containing additional headers\n        to add for the file.\n    :param auth: (optional) Auth tuple to enable Basic/Digest/Custom HTTP Auth.\n    :param timeout: (optional) How many seconds to wait for the server to send data\n        before giving up, as a float, or a :ref:`(connect timeout, read\n        timeout) <timeouts>` tuple.\n    :type timeout: float or tuple\n    :param allow_redirects: (optional) Boolean. Enable/disable GET/OPTIONS/POST/PUT/PATCH/DELETE/HEAD redirection. Defaults to ``True``"}, {"start_line": 1000, "end_line": 3000, "belongs_to": {"file_name": "models.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "\nfrom .cookies import _copy_cookie_jar, cookiejar_from_dict, get_cookie_header\nfrom .exceptions import (\n    ChunkedEncodingError,\n    ConnectionError,\n    ContentDecodingError,\n    HTTPError,\n    InvalidJSONError,\n    InvalidURL,\n)\nfrom .exceptions import JSONDecodeError as RequestsJSONDecodeError\nfrom .exceptions import MissingSchema\nfrom .exceptions import SSLError as RequestsSSLError\nfrom .exceptions import StreamConsumedError\nfrom .hooks import default_hooks\nfrom .status_codes import codes\nfrom .structures import CaseInsensitiveDict\nfrom .utils import (\n    check_header_validity,\n    get_auth_from_url,\n    guess_filename,\n    guess_json_utf,\n    iter_slices,\n    parse_header_links,\n    requote_uri,\n    stream_decode_response_unicode,\n    super_len,\n    to_key_val_list,\n)\n\n#: The set of HTTP status codes that indicate an automatically\n#: processable redirect.\nREDIRECT_STATI = (\n    codes.moved,  # 301\n    codes.found,  # 302\n    codes.other,  # 303\n    codes.temporary_redirect,  # 307\n    codes.permanent_redirect,  # 308\n)\n\nDEFAULT_REDIRECT_LIMIT = 30\nCONTENT_CHUNK_SIZE = 10 * 1024\nITER_CHUNK_SIZE = 512\n\n\nclass RequestEncodingMixin:\n    @property\n    def path_url(self):\n        \"\"\"Build the path URL to use.\"\"\"\n\n        url = []\n\n        p = urlsplit(self.url)\n\n        path = p.path\n        if not path:\n            path = \"/\"\n\n        url.append(path)\n\n        query = p.query\n        if query:\n            url.append(\"?\")\n            url.append(query)\n\n        return \"\".join(url)\n\n    @staticmethod\n    def _encode_params(data):\n        \"\"\"Encode parameters in a piece of data.\n\n        Will successfully encode parameters when passed as a dict or a list of\n        2-tuples. Order is retained if data is a list of 2-tuples but arbitrary\n        if parameters are supplied as a dict.\n        \"\"\"\n\n        if isinstance(data, (str, bytes)):\n            return data\n        elif hasattr(data, \"read\"):\n            return data\n        elif hasattr(data, \"__iter__\"):\n         "}, {"start_line": 1000, "end_line": 3000, "belongs_to": {"file_name": "test_requests.py", "upper_path": "/data2/raymone/swebench-repos/requests/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "ions import Timeout, TooManyRedirects, UnrewindableBodyError\nfrom requests.hooks import default_hooks\nfrom requests.models import PreparedRequest, urlencode\nfrom requests.sessions import SessionRedirectMixin\nfrom requests.structures import CaseInsensitiveDict\n\nfrom . import SNIMissingWarning\nfrom .compat import StringIO\nfrom .testserver.server import TLSServer, consume_socket_content\nfrom .utils import override_environ\n\n# Requests to this URL should always fail with a connection timeout (nothing\n# listening on that port)\nTARPIT = \"http://10.255.255.1\"\n\n# This is to avoid waiting the timeout of using TARPIT\nINVALID_PROXY = \"http://localhost:1\"\n\ntry:\n    from ssl import SSLContext\n\n    del SSLContext\n    HAS_MODERN_SSL = True\nexcept ImportError:\n    HAS_MODERN_SSL = False\n\ntry:\n    requests.pyopenssl\n    HAS_PYOPENSSL = True\nexcept AttributeError:\n    HAS_PYOPENSSL = False\n\n\nclass TestRequests:\n    digest_auth_algo = (\"MD5\", \"SHA-256\", \"SHA-512\")\n\n    def test_entry_points(self):\n        requests.session\n        requests.session().get\n        requests.session().head\n        requests.get\n        requests.head\n        requests.put\n        requests.patch\n        requests.post\n        # Not really an entry point, but people rely on it.\n        from requests.packages.urllib3.poolmanager import PoolManager  # noqa:F401\n\n    @pytest.mark.parametrize(\n        \"exception, url\",\n        (\n            (MissingSchema, \"hiwpefhipowhefopw\"),\n            (InvalidSchema, \"localhost:3128\"),\n            (InvalidSchema, \"localhost.localdomain:3128/\"),\n            (InvalidSchema, \"10.122.1.1:3128/\"),\n            (InvalidURL, \"http://\"),\n            (InvalidURL, \"http://*example.com\"),\n            (InvalidURL, \"http://.example.com\"),\n        ),\n    )\n    def test_invalid_url(self, exception, url):\n        with pytest.raises(exception):\n            requests.get(url)\n\n    def test_basic_building(self):\n        req = requests.Request()\n        req.url = \"http://kennethreitz.org/\"\n        req"}, {"start_line": 0, "end_line": 2000, "belongs_to": {"file_name": "adapters.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "\"\"\"\nrequests.adapters\n~~~~~~~~~~~~~~~~~\n\nThis module contains the transport adapters that Requests uses to define\nand maintain connections.\n\"\"\"\n\nimport os.path\nimport socket  # noqa: F401\nimport typing\nimport warnings\n\nfrom urllib3.exceptions import ClosedPoolError, ConnectTimeoutError\nfrom urllib3.exceptions import HTTPError as _HTTPError\nfrom urllib3.exceptions import InvalidHeader as _InvalidHeader\nfrom urllib3.exceptions import (\n    LocationValueError,\n    MaxRetryError,\n    NewConnectionError,\n    ProtocolError,\n)\nfrom urllib3.exceptions import ProxyError as _ProxyError\nfrom urllib3.exceptions import ReadTimeoutError, ResponseError\nfrom urllib3.exceptions import SSLError as _SSLError\nfrom urllib3.poolmanager import PoolManager, proxy_from_url\nfrom urllib3.util import Timeout as TimeoutSauce\nfrom urllib3.util import parse_url\nfrom urllib3.util.retry import Retry\n\nfrom .auth import _basic_auth_str\nfrom .compat import basestring, urlparse\nfrom .cookies import extract_cookies_to_jar\nfrom .exceptions import (\n    ConnectionError,\n    ConnectTimeout,\n    InvalidHeader,\n    InvalidProxyURL,\n    InvalidSchema,\n    InvalidURL,\n    ProxyError,\n    ReadTimeout,\n    RetryError,\n    SSLError,\n)\nfrom .models import Response\nfrom .structures import CaseInsensitiveDict\nfrom .utils import (\n    DEFAULT_CA_BUNDLE_PATH,\n    extract_zipped_paths,\n    get_auth_from_url,\n    get_encoding_from_headers,\n    prepend_scheme_if_needed,\n    select_proxy,\n    urldefragauth,\n)\n\ntry:\n    from urllib3.contrib.socks import SOCKSProxyManager\nexcept ImportError:\n\n    def SOCKSProxyManager(*args, **kwargs):\n        raise InvalidSchema(\"Missing dependencies for SOCKS support.\")\n\n\nif typing.TYPE_CHECKING:\n    from .models import PreparedRequest\n\n\nDEFAULT_POOLBLOCK = False\nDEFAULT_POOLSIZE = 10\nDEFAULT_RETRIES = 0\nDEFAULT_POOL_TIMEOUT = None\n\n\ndef _urllib3_request_context(\n    request: \"PreparedRequest\",\n    verify: \"bool | str | None\",\n    client_cert: \"typing.Tuple[str, str] | str | None\",\n    po"}], "retrieved_count": 10, "cost_time": 3.8880510330200195}
{"question": "What are Requests' built-in authentication handlers?", "answer": null, "relative_code_list": null, "ground_truth": "Requests' built-in authentication handlers (src/requests/auth.py) include: 1) HTTPBasicAuth - handles HTTP Basic Authentication by encoding username/password in base64 and adding Authorization header; 2) HTTPDigestAuth - implements HTTP Digest Authentication with support for MD5, SHA, SHA-256, and SHA-512 algorithms, handling challenge-response flow and nonce management; 3) HTTPProxyAuth - handles proxy authentication by adding Proxy-Authorization header; 4) AuthBase - abstract base class that all authentication handlers inherit from, defining the interface for auth implementations. These handlers are callable objects that modify Request objects by adding appropriate authentication headers. The DigestAuth handler includes thread-local state management for nonce counting and challenge handling, and implements automatic retry logic for 401 responses.", "score": null, "retrieved_content": [{"start_line": 0, "end_line": 2000, "belongs_to": {"file_name": "auth.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "\"\"\"\nrequests.auth\n~~~~~~~~~~~~~\n\nThis module contains the authentication handlers for Requests.\n\"\"\"\n\nimport hashlib\nimport os\nimport re\nimport threading\nimport time\nimport warnings\nfrom base64 import b64encode\n\nfrom ._internal_utils import to_native_string\nfrom .compat import basestring, str, urlparse\nfrom .cookies import extract_cookies_to_jar\nfrom .utils import parse_dict_header\n\nCONTENT_TYPE_FORM_URLENCODED = \"application/x-www-form-urlencoded\"\nCONTENT_TYPE_MULTI_PART = \"multipart/form-data\"\n\n\ndef _basic_auth_str(username, password):\n    \"\"\"Returns a Basic Auth string.\"\"\"\n\n    # \"I want us to put a big-ol' comment on top of it that\n    # says that this behaviour is dumb but we need to preserve\n    # it because people are relying on it.\"\n    #    - Lukasa\n    #\n    # These are here solely to maintain backwards compatibility\n    # for things like ints. This will be removed in 3.0.0.\n    if not isinstance(username, basestring):\n        warnings.warn(\n            \"Non-string usernames will no longer be supported in Requests \"\n            \"3.0.0. Please convert the object you've passed in ({!r}) to \"\n            \"a string or bytes object in the near future to avoid \"\n            \"problems.\".format(username),\n            category=DeprecationWarning,\n        )\n        username = str(username)\n\n    if not isinstance(password, basestring):\n        warnings.warn(\n            \"Non-string passwords will no longer be supported in Requests \"\n            \"3.0.0. Please convert the object you've passed in ({!r}) to \"\n            \"a string or bytes object in the near future to avoid \"\n            \"problems.\".format(type(password)),\n            category=DeprecationWarning,\n        )\n        password = str(password)\n    # -- End Removal --\n\n    if isinstance(username, str):\n        username = username.encode(\"latin1\")\n\n    if isinstance(password, str):\n        password = password.encode(\"latin1\")\n\n    authstr = \"Basic \" + to_native_string(\n        b64encode(b\":\".join((username, pas"}, {"start_line": 2000, "end_line": 4000, "belongs_to": {"file_name": "auth.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "sword))).strip()\n    )\n\n    return authstr\n\n\nclass AuthBase:\n    \"\"\"Base class that all auth implementations derive from\"\"\"\n\n    def __call__(self, r):\n        raise NotImplementedError(\"Auth hooks must be callable.\")\n\n\nclass HTTPBasicAuth(AuthBase):\n    \"\"\"Attaches HTTP Basic Authentication to the given Request object.\"\"\"\n\n    def __init__(self, username, password):\n        self.username = username\n        self.password = password\n\n    def __eq__(self, other):\n        return all(\n            [\n                self.username == getattr(other, \"username\", None),\n                self.password == getattr(other, \"password\", None),\n            ]\n        )\n\n    def __ne__(self, other):\n        return not self == other\n\n    def __call__(self, r):\n        r.headers[\"Authorization\"] = _basic_auth_str(self.username, self.password)\n        return r\n\n\nclass HTTPProxyAuth(HTTPBasicAuth):\n    \"\"\"Attaches HTTP Proxy Authentication to a given Request object.\"\"\"\n\n    def __call__(self, r):\n        r.headers[\"Proxy-Authorization\"] = _basic_auth_str(self.username, self.password)\n        return r\n\n\nclass HTTPDigestAuth(AuthBase):\n    \"\"\"Attaches HTTP Digest Authentication to the given Request object.\"\"\"\n\n    def __init__(self, username, password):\n        self.username = username\n        self.password = password\n        # Keep state in per-thread local storage\n        self._thread_local = threading.local()\n\n    def init_per_thread_state(self):\n        # Ensure state is initialized just once per-thread\n        if not hasattr(self._thread_local, \"init\"):\n            self._thread_local.init = True\n            self._thread_local.last_nonce = \"\"\n            self._thread_local.nonce_count = 0\n            self._thread_local.chal = {}\n            self._thread_local.pos = None\n            self._thread_local.num_401_calls = None\n\n    def build_digest_header(self, method, url):\n        \"\"\"\n        :rtype: str\n        \"\"\"\n\n        realm = self._thread_local.chal[\"realm\"]\n        nonce = self._threa"}, {"start_line": 25000, "end_line": 27000, "belongs_to": {"file_name": "test_requests.py", "upper_path": "/data2/raymone/swebench-repos/requests/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "get_netrc_auth_mock(url):\n                return auth\n\n            requests.sessions.get_netrc_auth = get_netrc_auth_mock\n\n            # Should use netrc and work.\n            r = requests.get(url)\n            assert r.status_code == 200\n\n            # Given auth should override and fail.\n            r = requests.get(url, auth=wrong_auth)\n            assert r.status_code == 401\n\n            s = requests.session()\n\n            # Should use netrc and work.\n            r = s.get(url)\n            assert r.status_code == 200\n\n            # Given auth should override and fail.\n            s.auth = wrong_auth\n            r = s.get(url)\n            assert r.status_code == 401\n        finally:\n            requests.sessions.get_netrc_auth = old_auth\n\n    def test_basicauth_with_netrc_leak(self, httpbin):\n        url1 = httpbin(\"basic-auth\", \"user\", \"pass\")\n        url = url1[len(\"http://\") :]\n        domain = url.split(\":\")[0]\n        url = f\"http://example.com:@{url}\"\n\n        netrc_file = \"\"\n        with tempfile.NamedTemporaryFile(mode=\"w\", delete=False) as fp:\n            fp.write(\"machine example.com\\n\")\n            fp.write(\"login wronguser\\n\")\n            fp.write(\"password wrongpass\\n\")\n            fp.write(f\"machine {domain}\\n\")\n            fp.write(\"login user\\n\")\n            fp.write(\"password pass\\n\")\n            fp.close()\n            netrc_file = fp.name\n\n        old_netrc = os.environ.get(\"NETRC\", \"\")\n        os.environ[\"NETRC\"] = netrc_file\n\n        try:\n            # Should use netrc\n            # Make sure that we don't use the example.com credentails\n            # for the request\n            r = requests.get(url)\n            assert r.status_code == 200\n        finally:\n            os.environ[\"NETRC\"] = old_netrc\n            os.unlink(netrc_file)\n\n    def test_DIGEST_HTTP_200_OK_GET(self, httpbin):\n        for authtype in self.digest_auth_algo:\n            auth = HTTPDigestAuth(\"user\", \"pass\")\n            url = httpbin(\"digest-auth\", \"auth\", \"user\", \"pass\", "}, {"start_line": 27000, "end_line": 29000, "belongs_to": {"file_name": "test_requests.py", "upper_path": "/data2/raymone/swebench-repos/requests/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "authtype, \"never\")\n\n            r = requests.get(url, auth=auth)\n            assert r.status_code == 200\n\n            r = requests.get(url)\n            assert r.status_code == 401\n            print(r.headers[\"WWW-Authenticate\"])\n\n            s = requests.session()\n            s.auth = HTTPDigestAuth(\"user\", \"pass\")\n            r = s.get(url)\n            assert r.status_code == 200\n\n    def test_DIGEST_AUTH_RETURNS_COOKIE(self, httpbin):\n        for authtype in self.digest_auth_algo:\n            url = httpbin(\"digest-auth\", \"auth\", \"user\", \"pass\", authtype)\n            auth = HTTPDigestAuth(\"user\", \"pass\")\n            r = requests.get(url)\n            assert r.cookies[\"fake\"] == \"fake_value\"\n\n            r = requests.get(url, auth=auth)\n            assert r.status_code == 200\n\n    def test_DIGEST_AUTH_SETS_SESSION_COOKIES(self, httpbin):\n        for authtype in self.digest_auth_algo:\n            url = httpbin(\"digest-auth\", \"auth\", \"user\", \"pass\", authtype)\n            auth = HTTPDigestAuth(\"user\", \"pass\")\n            s = requests.Session()\n            s.get(url, auth=auth)\n            assert s.cookies[\"fake\"] == \"fake_value\"\n\n    def test_DIGEST_STREAM(self, httpbin):\n        for authtype in self.digest_auth_algo:\n            auth = HTTPDigestAuth(\"user\", \"pass\")\n            url = httpbin(\"digest-auth\", \"auth\", \"user\", \"pass\", authtype)\n\n            r = requests.get(url, auth=auth, stream=True)\n            assert r.raw.read() != b\"\"\n\n            r = requests.get(url, auth=auth, stream=False)\n            assert r.raw.read() == b\"\"\n\n    def test_DIGESTAUTH_WRONG_HTTP_401_GET(self, httpbin):\n        for authtype in self.digest_auth_algo:\n            auth = HTTPDigestAuth(\"user\", \"wrongpass\")\n            url = httpbin(\"digest-auth\", \"auth\", \"user\", \"pass\", authtype)\n\n            r = requests.get(url, auth=auth)\n            assert r.status_code == 401\n\n            r = requests.get(url)\n            assert r.status_code == 401\n\n            s = requests.session()\n          "}, {"start_line": 28000, "end_line": 30000, "belongs_to": {"file_name": "test_requests.py", "upper_path": "/data2/raymone/swebench-repos/requests/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "Auth(\"user\", \"pass\")\n            s = requests.Session()\n            s.get(url, auth=auth)\n            assert s.cookies[\"fake\"] == \"fake_value\"\n\n    def test_DIGEST_STREAM(self, httpbin):\n        for authtype in self.digest_auth_algo:\n            auth = HTTPDigestAuth(\"user\", \"pass\")\n            url = httpbin(\"digest-auth\", \"auth\", \"user\", \"pass\", authtype)\n\n            r = requests.get(url, auth=auth, stream=True)\n            assert r.raw.read() != b\"\"\n\n            r = requests.get(url, auth=auth, stream=False)\n            assert r.raw.read() == b\"\"\n\n    def test_DIGESTAUTH_WRONG_HTTP_401_GET(self, httpbin):\n        for authtype in self.digest_auth_algo:\n            auth = HTTPDigestAuth(\"user\", \"wrongpass\")\n            url = httpbin(\"digest-auth\", \"auth\", \"user\", \"pass\", authtype)\n\n            r = requests.get(url, auth=auth)\n            assert r.status_code == 401\n\n            r = requests.get(url)\n            assert r.status_code == 401\n\n            s = requests.session()\n            s.auth = auth\n            r = s.get(url)\n            assert r.status_code == 401\n\n    def test_DIGESTAUTH_QUOTES_QOP_VALUE(self, httpbin):\n        for authtype in self.digest_auth_algo:\n            auth = HTTPDigestAuth(\"user\", \"pass\")\n            url = httpbin(\"digest-auth\", \"auth\", \"user\", \"pass\", authtype)\n\n            r = requests.get(url, auth=auth)\n            assert '\"auth\"' in r.request.headers[\"Authorization\"]\n\n    def test_POSTBIN_GET_POST_FILES(self, httpbin):\n        url = httpbin(\"post\")\n        requests.post(url).raise_for_status()\n\n        post1 = requests.post(url, data={\"some\": \"data\"})\n        assert post1.status_code == 200\n\n        with open(\"requirements-dev.txt\") as f:\n            post2 = requests.post(url, files={\"some\": f})\n        assert post2.status_code == 200\n\n        post4 = requests.post(url, data='[{\"some\": \"json\"}]')\n        assert post4.status_code == 200\n\n        with pytest.raises(ValueError):\n            requests.post(url, files=[\"bad file data\"])\n"}, {"start_line": 26000, "end_line": 28000, "belongs_to": {"file_name": "test_requests.py", "upper_path": "/data2/raymone/swebench-repos/requests/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "       with tempfile.NamedTemporaryFile(mode=\"w\", delete=False) as fp:\n            fp.write(\"machine example.com\\n\")\n            fp.write(\"login wronguser\\n\")\n            fp.write(\"password wrongpass\\n\")\n            fp.write(f\"machine {domain}\\n\")\n            fp.write(\"login user\\n\")\n            fp.write(\"password pass\\n\")\n            fp.close()\n            netrc_file = fp.name\n\n        old_netrc = os.environ.get(\"NETRC\", \"\")\n        os.environ[\"NETRC\"] = netrc_file\n\n        try:\n            # Should use netrc\n            # Make sure that we don't use the example.com credentails\n            # for the request\n            r = requests.get(url)\n            assert r.status_code == 200\n        finally:\n            os.environ[\"NETRC\"] = old_netrc\n            os.unlink(netrc_file)\n\n    def test_DIGEST_HTTP_200_OK_GET(self, httpbin):\n        for authtype in self.digest_auth_algo:\n            auth = HTTPDigestAuth(\"user\", \"pass\")\n            url = httpbin(\"digest-auth\", \"auth\", \"user\", \"pass\", authtype, \"never\")\n\n            r = requests.get(url, auth=auth)\n            assert r.status_code == 200\n\n            r = requests.get(url)\n            assert r.status_code == 401\n            print(r.headers[\"WWW-Authenticate\"])\n\n            s = requests.session()\n            s.auth = HTTPDigestAuth(\"user\", \"pass\")\n            r = s.get(url)\n            assert r.status_code == 200\n\n    def test_DIGEST_AUTH_RETURNS_COOKIE(self, httpbin):\n        for authtype in self.digest_auth_algo:\n            url = httpbin(\"digest-auth\", \"auth\", \"user\", \"pass\", authtype)\n            auth = HTTPDigestAuth(\"user\", \"pass\")\n            r = requests.get(url)\n            assert r.cookies[\"fake\"] == \"fake_value\"\n\n            r = requests.get(url, auth=auth)\n            assert r.status_code == 200\n\n    def test_DIGEST_AUTH_SETS_SESSION_COOKIES(self, httpbin):\n        for authtype in self.digest_auth_algo:\n            url = httpbin(\"digest-auth\", \"auth\", \"user\", \"pass\", authtype)\n            auth = HTTPDigest"}, {"start_line": 19000, "end_line": 21000, "belongs_to": {"file_name": "test_requests.py", "upper_path": "/data2/raymone/swebench-repos/requests/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "   def test_HTTP_200_OK_HEAD(self, httpbin):\n        r = requests.head(httpbin(\"get\"))\n        assert r.status_code == 200\n\n    def test_HTTP_200_OK_PUT(self, httpbin):\n        r = requests.put(httpbin(\"put\"))\n        assert r.status_code == 200\n\n    def test_BASICAUTH_TUPLE_HTTP_200_OK_GET(self, httpbin):\n        auth = (\"user\", \"pass\")\n        url = httpbin(\"basic-auth\", \"user\", \"pass\")\n\n        r = requests.get(url, auth=auth)\n        assert r.status_code == 200\n\n        r = requests.get(url)\n        assert r.status_code == 401\n\n        s = requests.session()\n        s.auth = auth\n        r = s.get(url)\n        assert r.status_code == 200\n\n    @pytest.mark.parametrize(\n        \"username, password\",\n        (\n            (\"user\", \"pass\"),\n            (\"\".encode(), \"\".encode()),\n            (42, 42),\n            (None, None),\n        ),\n    )\n    def test_set_basicauth(self, httpbin, username, password):\n        auth = (username, password)\n        url = httpbin(\"get\")\n\n        r = requests.Request(\"GET\", url, auth=auth)\n        p = r.prepare()\n\n        assert p.headers[\"Authorization\"] == _basic_auth_str(username, password)\n\n    def test_basicauth_encodes_byte_strings(self):\n        \"\"\"Ensure b'test' formats as the byte string \"test\" rather\n        than the unicode string \"b'test'\" in Python 3.\n        \"\"\"\n        auth = (b\"\\xc5\\xafsername\", b\"test\\xc6\\xb6\")\n        r = requests.Request(\"GET\", \"http://localhost\", auth=auth)\n        p = r.prepare()\n\n        assert p.headers[\"Authorization\"] == \"Basic xa9zZXJuYW1lOnRlc3TGtg==\"\n\n    @pytest.mark.parametrize(\n        \"url, exception\",\n        (\n            # Connecting to an unknown domain should raise a ConnectionError\n            (\"http://doesnotexist.google.com\", ConnectionError),\n            # Connecting to an invalid port should raise a ConnectionError\n            (\"http://localhost:1\", ConnectionError),\n            # Inputing a URL that cannot be parsed should raise an InvalidURL error\n            (\"http"}, {"start_line": 24000, "end_line": 26000, "belongs_to": {"file_name": "test_requests.py", "upper_path": "/data2/raymone/swebench-repos/requests/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "\", {})\n\n        assert sent_headers.get(\"Proxy-Authorization\") == proxy_auth_value\n\n    @pytest.mark.parametrize(\n        \"url,has_proxy_auth\",\n        (\n            (\"http://example.com\", True),\n            (\"https://example.com\", False),\n        ),\n    )\n    def test_proxy_authorization_not_appended_to_https_request(\n        self, url, has_proxy_auth\n    ):\n        session = requests.Session()\n        proxies = {\n            \"http\": \"http://test:pass@localhost:8080\",\n            \"https\": \"http://test:pass@localhost:8090\",\n        }\n        req = requests.Request(\"GET\", url)\n        prep = req.prepare()\n        session.rebuild_proxies(prep, proxies)\n\n        assert (\"Proxy-Authorization\" in prep.headers) is has_proxy_auth\n\n    def test_basicauth_with_netrc(self, httpbin):\n        auth = (\"user\", \"pass\")\n        wrong_auth = (\"wronguser\", \"wrongpass\")\n        url = httpbin(\"basic-auth\", \"user\", \"pass\")\n\n        old_auth = requests.sessions.get_netrc_auth\n\n        try:\n\n            def get_netrc_auth_mock(url):\n                return auth\n\n            requests.sessions.get_netrc_auth = get_netrc_auth_mock\n\n            # Should use netrc and work.\n            r = requests.get(url)\n            assert r.status_code == 200\n\n            # Given auth should override and fail.\n            r = requests.get(url, auth=wrong_auth)\n            assert r.status_code == 401\n\n            s = requests.session()\n\n            # Should use netrc and work.\n            r = s.get(url)\n            assert r.status_code == 200\n\n            # Given auth should override and fail.\n            s.auth = wrong_auth\n            r = s.get(url)\n            assert r.status_code == 401\n        finally:\n            requests.sessions.get_netrc_auth = old_auth\n\n    def test_basicauth_with_netrc_leak(self, httpbin):\n        url1 = httpbin(\"basic-auth\", \"user\", \"pass\")\n        url = url1[len(\"http://\") :]\n        domain = url.split(\":\")[0]\n        url = f\"http://example.com:@{url}\"\n\n        netrc_file = \"\"\n "}, {"start_line": 8000, "end_line": 10000, "belongs_to": {"file_name": "test_lowlevel.py", "upper_path": "/data2/raymone/swebench-repos/requests/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "_socket_content(sock, timeout=0.5)\n        assert request_content == b''\n\n        return request_content\n\n    close_server = threading.Event()\n    server = Server(digest_failed_response_handler, wait_to_close_event=close_server)\n\n    with server as (host, port):\n        url = f'http://{host}:{port}/'\n        r = requests.get(url, auth=auth)\n        # Verify server didn't authenticate us.\n        assert r.status_code == 401\n        assert r.history[0].status_code == 401\n        close_server.set()\n\n\ndef test_digestauth_only_on_4xx():\n    \"\"\"Ensure we only send digestauth on 4xx challenges.\n\n    See https://github.com/psf/requests/issues/3772.\n    \"\"\"\n    text_200_chal = (b'HTTP/1.1 200 OK\\r\\n'\n                     b'Content-Length: 0\\r\\n'\n                     b'WWW-Authenticate: Digest nonce=\"6bf5d6e4da1ce66918800195d6b9130d\"'\n                     b', opaque=\"372825293d1c26955496c80ed6426e9e\", '\n                     b'realm=\"me@kennethreitz.com\", qop=auth\\r\\n\\r\\n')\n\n    auth = requests.auth.HTTPDigestAuth('user', 'pass')\n\n    def digest_response_handler(sock):\n        # Respond to GET with a 200 containing www-authenticate header.\n        request_content = consume_socket_content(sock, timeout=0.5)\n        assert request_content.startswith(b\"GET / HTTP/1.1\")\n        sock.send(text_200_chal)\n\n        # Verify the client didn't respond with auth.\n        request_content = consume_socket_content(sock, timeout=0.5)\n        assert request_content == b''\n\n        return request_content\n\n    close_server = threading.Event()\n    server = Server(digest_response_handler, wait_to_close_event=close_server)\n\n    with server as (host, port):\n        url = f'http://{host}:{port}/'\n        r = requests.get(url, auth=auth)\n        # Verify server didn't receive auth from us.\n        assert r.status_code == 200\n        assert len(r.history) == 0\n        close_server.set()\n\n\n_schemes_by_var_prefix = [\n    ('http', ['http']),\n    ('https', ['https']),\n    ('all', ['http', 'https']),\n]\n\n_p"}, {"start_line": 66000, "end_line": 68000, "belongs_to": {"file_name": "test_requests.py", "upper_path": "/data2/raymone/swebench-repos/requests/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "rt \"multipart/form-data\" in p.headers[\"Content-Type\"]\n\n    def test_autoset_header_values_are_native(self, httpbin):\n        data = \"this is a string\"\n        length = \"16\"\n        req = requests.Request(\"POST\", httpbin(\"post\"), data=data)\n        p = req.prepare()\n\n        assert p.headers[\"Content-Length\"] == length\n\n    def test_nonhttp_schemes_dont_check_URLs(self):\n        test_urls = (\n            \"data:image/gif;base64,R0lGODlhAQABAHAAACH5BAUAAAAALAAAAAABAAEAAAICRAEAOw==\",\n            \"file:///etc/passwd\",\n            \"magnet:?xt=urn:btih:be08f00302bc2d1d3cfa3af02024fa647a271431\",\n        )\n        for test_url in test_urls:\n            req = requests.Request(\"GET\", test_url)\n            preq = req.prepare()\n            assert test_url == preq.url\n\n    def test_auth_is_stripped_on_http_downgrade(\n        self, httpbin, httpbin_secure, httpbin_ca_bundle\n    ):\n        r = requests.get(\n            httpbin_secure(\"redirect-to\"),\n            params={\"url\": httpbin(\"get\")},\n            auth=(\"user\", \"pass\"),\n            verify=httpbin_ca_bundle,\n        )\n        assert r.history[0].request.headers[\"Authorization\"]\n        assert \"Authorization\" not in r.request.headers\n\n    def test_auth_is_retained_for_redirect_on_host(self, httpbin):\n        r = requests.get(httpbin(\"redirect/1\"), auth=(\"user\", \"pass\"))\n        h1 = r.history[0].request.headers[\"Authorization\"]\n        h2 = r.request.headers[\"Authorization\"]\n\n        assert h1 == h2\n\n    def test_should_strip_auth_host_change(self):\n        s = requests.Session()\n        assert s.should_strip_auth(\n            \"http://example.com/foo\", \"http://another.example.com/\"\n        )\n\n    def test_should_strip_auth_http_downgrade(self):\n        s = requests.Session()\n        assert s.should_strip_auth(\"https://example.com/foo\", \"http://example.com/bar\")\n\n    def test_should_strip_auth_https_upgrade(self):\n        s = requests.Session()\n        assert not s.should_strip_auth(\n            \"http://example.com/foo\", \"https"}], "retrieved_count": 10, "cost_time": 3.934864044189453}
{"question": "What is the relationship between Requests' Session class and the PreparedRequest class in establishing request preparation and execution?", "answer": null, "relative_code_list": null, "ground_truth": "The relationship between Session and PreparedRequest (src/requests/sessions.py, src/requests/models.py) follows a preparation-execution pattern: 1) Request preparation - Session.prepare_request() takes a Request object and creates a PreparedRequest by merging session-level settings (headers, cookies, auth, proxies) with request-specific settings; 2) Configuration merging - Session merges its persistent state (cookies, headers, auth, etc.) with the request parameters, with request settings taking precedence; 3) Cookie handling - Session merges its cookie jar with request cookies and prepares the final Cookie header; 4) Authentication - Session applies its default authentication or environment-based auth if not specified in the request; 5) Adapter selection - Session selects the appropriate adapter based on the URL scheme for the prepared request; 6) Request execution - Session.send() takes the PreparedRequest and sends it through the selected adapter; 7) Response processing - Session handles redirects, cookie extraction, and response building after adapter execution; 8) State updates - Session updates its internal state (cookies, etc.) based on the response; 9) Connection management - Session manages connection pooling and lifecycle through adapters; 10) Error handling - Session provides consistent error handling and exception translation. This relationship enables Sessions to maintain state while providing a clean interface for request execution.", "score": null, "retrieved_content": [{"start_line": 16000, "end_line": 18000, "belongs_to": {"file_name": "sessions.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "e\n\n        #: A CookieJar containing all currently outstanding cookies set on this\n        #: session. By default it is a\n        #: :class:`RequestsCookieJar <requests.cookies.RequestsCookieJar>`, but\n        #: may be any other ``cookielib.CookieJar`` compatible object.\n        self.cookies = cookiejar_from_dict({})\n\n        # Default connection adapters.\n        self.adapters = OrderedDict()\n        self.mount(\"https://\", HTTPAdapter())\n        self.mount(\"http://\", HTTPAdapter())\n\n    def __enter__(self):\n        return self\n\n    def __exit__(self, *args):\n        self.close()\n\n    def prepare_request(self, request):\n        \"\"\"Constructs a :class:`PreparedRequest <PreparedRequest>` for\n        transmission and returns it. The :class:`PreparedRequest` has settings\n        merged from the :class:`Request <Request>` instance and those of the\n        :class:`Session`.\n\n        :param request: :class:`Request` instance to prepare with this\n            session's settings.\n        :rtype: requests.PreparedRequest\n        \"\"\"\n        cookies = request.cookies or {}\n\n        # Bootstrap CookieJar.\n        if not isinstance(cookies, cookielib.CookieJar):\n            cookies = cookiejar_from_dict(cookies)\n\n        # Merge with session cookies\n        merged_cookies = merge_cookies(\n            merge_cookies(RequestsCookieJar(), self.cookies), cookies\n        )\n\n        # Set environment's basic authentication if not explicitly set.\n        auth = request.auth\n        if self.trust_env and not auth and not self.auth:\n            auth = get_netrc_auth(request.url)\n\n        p = PreparedRequest()\n        p.prepare(\n            method=request.method.upper(),\n            url=request.url,\n            files=request.files,\n            data=request.data,\n            json=request.json,\n            headers=merge_setting(\n                request.headers, self.headers, dict_class=CaseInsensitiveDict\n            ),\n            params=merge_setting(request.params, self.params),\n         "}, {"start_line": 15000, "end_line": 17000, "belongs_to": {"file_name": "sessions.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "y the TLS certificate at the\n        #: remote end.\n        #: If verify is set to `False`, requests will accept any TLS certificate\n        #: presented by the server, and will ignore hostname mismatches and/or\n        #: expired certificates, which will make your application vulnerable to\n        #: man-in-the-middle (MitM) attacks.\n        #: Only set this to `False` for testing.\n        self.verify = True\n\n        #: SSL client certificate default, if String, path to ssl client\n        #: cert file (.pem). If Tuple, ('cert', 'key') pair.\n        self.cert = None\n\n        #: Maximum number of redirects allowed. If the request exceeds this\n        #: limit, a :class:`TooManyRedirects` exception is raised.\n        #: This defaults to requests.models.DEFAULT_REDIRECT_LIMIT, which is\n        #: 30.\n        self.max_redirects = DEFAULT_REDIRECT_LIMIT\n\n        #: Trust environment settings for proxy configuration, default\n        #: authentication and similar.\n        self.trust_env = True\n\n        #: A CookieJar containing all currently outstanding cookies set on this\n        #: session. By default it is a\n        #: :class:`RequestsCookieJar <requests.cookies.RequestsCookieJar>`, but\n        #: may be any other ``cookielib.CookieJar`` compatible object.\n        self.cookies = cookiejar_from_dict({})\n\n        # Default connection adapters.\n        self.adapters = OrderedDict()\n        self.mount(\"https://\", HTTPAdapter())\n        self.mount(\"http://\", HTTPAdapter())\n\n    def __enter__(self):\n        return self\n\n    def __exit__(self, *args):\n        self.close()\n\n    def prepare_request(self, request):\n        \"\"\"Constructs a :class:`PreparedRequest <PreparedRequest>` for\n        transmission and returns it. The :class:`PreparedRequest` has settings\n        merged from the :class:`Request <Request>` instance and those of the\n        :class:`Session`.\n\n        :param request: :class:`Request` instance to prepare with this\n            session's settings.\n        :rtype"}, {"start_line": 17000, "end_line": 19000, "belongs_to": {"file_name": "sessions.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": ": requests.PreparedRequest\n        \"\"\"\n        cookies = request.cookies or {}\n\n        # Bootstrap CookieJar.\n        if not isinstance(cookies, cookielib.CookieJar):\n            cookies = cookiejar_from_dict(cookies)\n\n        # Merge with session cookies\n        merged_cookies = merge_cookies(\n            merge_cookies(RequestsCookieJar(), self.cookies), cookies\n        )\n\n        # Set environment's basic authentication if not explicitly set.\n        auth = request.auth\n        if self.trust_env and not auth and not self.auth:\n            auth = get_netrc_auth(request.url)\n\n        p = PreparedRequest()\n        p.prepare(\n            method=request.method.upper(),\n            url=request.url,\n            files=request.files,\n            data=request.data,\n            json=request.json,\n            headers=merge_setting(\n                request.headers, self.headers, dict_class=CaseInsensitiveDict\n            ),\n            params=merge_setting(request.params, self.params),\n            auth=merge_setting(auth, self.auth),\n            cookies=merged_cookies,\n            hooks=merge_hooks(request.hooks, self.hooks),\n        )\n        return p\n\n    def request(\n        self,\n        method,\n        url,\n        params=None,\n        data=None,\n        headers=None,\n        cookies=None,\n        files=None,\n        auth=None,\n        timeout=None,\n        allow_redirects=True,\n        proxies=None,\n        hooks=None,\n        stream=None,\n        verify=None,\n        cert=None,\n        json=None,\n    ):\n        \"\"\"Constructs a :class:`Request <Request>`, prepares it and sends it.\n        Returns :class:`Response <Response>` object.\n\n        :param method: method for the new :class:`Request` object.\n        :param url: URL for the new :class:`Request` object.\n        :param params: (optional) Dictionary or bytes to be sent in the query\n            string for the :class:`Request`.\n        :param data: (optional) Dictionary, list of tuples, bytes, or file-like\n           "}, {"start_line": 10000, "end_line": 12000, "belongs_to": {"file_name": "models.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "\n\n      >>> s = requests.Session()\n      >>> s.send(r)\n      <Response [200]>\n    \"\"\"\n\n    def __init__(self):\n        #: HTTP verb to send to the server.\n        self.method = None\n        #: HTTP URL to send the request to.\n        self.url = None\n        #: dictionary of HTTP headers.\n        self.headers = None\n        # The `CookieJar` used to create the Cookie header will be stored here\n        # after prepare_cookies is called\n        self._cookies = None\n        #: request body to send to the server.\n        self.body = None\n        #: dictionary of callback hooks, for internal usage.\n        self.hooks = default_hooks()\n        #: integer denoting starting position of a readable file-like body.\n        self._body_position = None\n\n    def prepare(\n        self,\n        method=None,\n        url=None,\n        headers=None,\n        files=None,\n        data=None,\n        params=None,\n        auth=None,\n        cookies=None,\n        hooks=None,\n        json=None,\n    ):\n        \"\"\"Prepares the entire request with the given parameters.\"\"\"\n\n        self.prepare_method(method)\n        self.prepare_url(url, params)\n        self.prepare_headers(headers)\n        self.prepare_cookies(cookies)\n        self.prepare_body(data, files, json)\n        self.prepare_auth(auth, url)\n\n        # Note that prepare_auth must be last to enable authentication schemes\n        # such as OAuth to work on a fully prepared request.\n\n        # This MUST go after prepare_auth. Authenticators could add a hook\n        self.prepare_hooks(hooks)\n\n    def __repr__(self):\n        return f\"<PreparedRequest [{self.method}]>\"\n\n    def copy(self):\n        p = PreparedRequest()\n        p.method = self.method\n        p.url = self.url\n        p.headers = self.headers.copy() if self.headers is not None else None\n        p._cookies = _copy_cookie_jar(self._cookies)\n        p.body = self.body\n        p.hooks = self.hooks\n        p._body_position = self._body_position\n        return p\n\n    def prepare_method("}, {"start_line": 9000, "end_line": 11000, "belongs_to": {"file_name": "models.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "class:`PreparedRequest <PreparedRequest>` for transmission and returns it.\"\"\"\n        p = PreparedRequest()\n        p.prepare(\n            method=self.method,\n            url=self.url,\n            headers=self.headers,\n            files=self.files,\n            data=self.data,\n            json=self.json,\n            params=self.params,\n            auth=self.auth,\n            cookies=self.cookies,\n            hooks=self.hooks,\n        )\n        return p\n\n\nclass PreparedRequest(RequestEncodingMixin, RequestHooksMixin):\n    \"\"\"The fully mutable :class:`PreparedRequest <PreparedRequest>` object,\n    containing the exact bytes that will be sent to the server.\n\n    Instances are generated from a :class:`Request <Request>` object, and\n    should not be instantiated manually; doing so may produce undesirable\n    effects.\n\n    Usage::\n\n      >>> import requests\n      >>> req = requests.Request('GET', 'https://httpbin.org/get')\n      >>> r = req.prepare()\n      >>> r\n      <PreparedRequest [GET]>\n\n      >>> s = requests.Session()\n      >>> s.send(r)\n      <Response [200]>\n    \"\"\"\n\n    def __init__(self):\n        #: HTTP verb to send to the server.\n        self.method = None\n        #: HTTP URL to send the request to.\n        self.url = None\n        #: dictionary of HTTP headers.\n        self.headers = None\n        # The `CookieJar` used to create the Cookie header will be stored here\n        # after prepare_cookies is called\n        self._cookies = None\n        #: request body to send to the server.\n        self.body = None\n        #: dictionary of callback hooks, for internal usage.\n        self.hooks = default_hooks()\n        #: integer denoting starting position of a readable file-like body.\n        self._body_position = None\n\n    def prepare(\n        self,\n        method=None,\n        url=None,\n        headers=None,\n        files=None,\n        data=None,\n        params=None,\n        auth=None,\n        cookies=None,\n        hooks=None,\n        json=None,\n    ):\n        \"\"\"P"}, {"start_line": 25000, "end_line": 27000, "belongs_to": {"file_name": "sessions.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "equest, **kwargs):\n        \"\"\"Send a given PreparedRequest.\n\n        :rtype: requests.Response\n        \"\"\"\n        # Set defaults that the hooks can utilize to ensure they always have\n        # the correct parameters to reproduce the previous request.\n        kwargs.setdefault(\"stream\", self.stream)\n        kwargs.setdefault(\"verify\", self.verify)\n        kwargs.setdefault(\"cert\", self.cert)\n        if \"proxies\" not in kwargs:\n            kwargs[\"proxies\"] = resolve_proxies(request, self.proxies, self.trust_env)\n\n        # It's possible that users might accidentally send a Request object.\n        # Guard against that specific failure case.\n        if isinstance(request, Request):\n            raise ValueError(\"You can only send PreparedRequests.\")\n\n        # Set up variables needed for resolve_redirects and dispatching of hooks\n        allow_redirects = kwargs.pop(\"allow_redirects\", True)\n        stream = kwargs.get(\"stream\")\n        hooks = request.hooks\n\n        # Get the appropriate adapter to use\n        adapter = self.get_adapter(url=request.url)\n\n        # Start time (approximately) of the request\n        start = preferred_clock()\n\n        # Send the request\n        r = adapter.send(request, **kwargs)\n\n        # Total elapsed time of the request (approximately)\n        elapsed = preferred_clock() - start\n        r.elapsed = timedelta(seconds=elapsed)\n\n        # Response manipulation hooks\n        r = dispatch_hook(\"response\", hooks, r, **kwargs)\n\n        # Persist cookies\n        if r.history:\n            # If the hooks create history then we want those cookies too\n            for resp in r.history:\n                extract_cookies_to_jar(self.cookies, resp.request, resp.raw)\n\n        extract_cookies_to_jar(self.cookies, request, r.raw)\n\n        # Resolve redirects if allowed.\n        if allow_redirects:\n            # Redirect resolving generator.\n            gen = self.resolve_redirects(r, request, **kwargs)\n            history = [resp for resp in gen]\n        "}, {"start_line": 43000, "end_line": 45000, "belongs_to": {"file_name": "test_requests.py", "upper_path": "/data2/raymone/swebench-repos/requests/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "ook})\n        prep = req.prepare()\n\n        s = requests.Session()\n        s.proxies = getproxies()\n        resp = s.send(prep)\n\n        assert hasattr(resp, \"hook_working\")\n\n    def test_prepared_from_session(self, httpbin):\n        class DummyAuth(requests.auth.AuthBase):\n            def __call__(self, r):\n                r.headers[\"Dummy-Auth-Test\"] = \"dummy-auth-test-ok\"\n                return r\n\n        req = requests.Request(\"GET\", httpbin(\"headers\"))\n        assert not req.auth\n\n        s = requests.Session()\n        s.auth = DummyAuth()\n\n        prep = s.prepare_request(req)\n        resp = s.send(prep)\n\n        assert resp.json()[\"headers\"][\"Dummy-Auth-Test\"] == \"dummy-auth-test-ok\"\n\n    def test_prepare_request_with_bytestring_url(self):\n        req = requests.Request(\"GET\", b\"https://httpbin.org/\")\n        s = requests.Session()\n        prep = s.prepare_request(req)\n        assert prep.url == \"https://httpbin.org/\"\n\n    def test_request_with_bytestring_host(self, httpbin):\n        s = requests.Session()\n        resp = s.request(\n            \"GET\",\n            httpbin(\"cookies/set?cookie=value\"),\n            allow_redirects=False,\n            headers={\"Host\": b\"httpbin.org\"},\n        )\n        assert resp.cookies.get(\"cookie\") == \"value\"\n\n    def test_links(self):\n        r = requests.Response()\n        r.headers = {\n            \"cache-control\": \"public, max-age=60, s-maxage=60\",\n            \"connection\": \"keep-alive\",\n            \"content-encoding\": \"gzip\",\n            \"content-type\": \"application/json; charset=utf-8\",\n            \"date\": \"Sat, 26 Jan 2013 16:47:56 GMT\",\n            \"etag\": '\"6ff6a73c0e446c1f61614769e3ceb778\"',\n            \"last-modified\": \"Sat, 26 Jan 2013 16:22:39 GMT\",\n            \"link\": (\n                \"<https://api.github.com/users/kennethreitz/repos?\"\n                'page=2&per_page=10>; rel=\"next\", <https://api.github.'\n                \"com/users/kennethreitz/repos?page=7&per_page=10>; \"\n                ' rel=\"last\"'\n           "}, {"start_line": 54000, "end_line": 56000, "belongs_to": {"file_name": "test_requests.py", "upper_path": "/data2/raymone/swebench-repos/requests/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": " s.send(r)\n        assert resp.status_code == 200\n\n    def test_prepared_request_with_file_is_pickleable(self, httpbin):\n        with open(__file__, \"rb\") as f:\n            r = requests.Request(\"POST\", httpbin(\"post\"), files={\"file\": f})\n            p = r.prepare()\n\n        # Verify PreparedRequest can be pickled and unpickled\n        r = pickle.loads(pickle.dumps(p))\n        assert r.url == p.url\n        assert r.headers == p.headers\n        assert r.body == p.body\n\n        # Verify unpickled PreparedRequest sends properly\n        s = requests.Session()\n        resp = s.send(r)\n        assert resp.status_code == 200\n\n    def test_prepared_request_with_hook_is_pickleable(self, httpbin):\n        r = requests.Request(\"GET\", httpbin(\"get\"), hooks=default_hooks())\n        p = r.prepare()\n\n        # Verify PreparedRequest can be pickled\n        r = pickle.loads(pickle.dumps(p))\n        assert r.url == p.url\n        assert r.headers == p.headers\n        assert r.body == p.body\n        assert r.hooks == p.hooks\n\n        # Verify unpickled PreparedRequest sends properly\n        s = requests.Session()\n        resp = s.send(r)\n        assert resp.status_code == 200\n\n    def test_cannot_send_unprepared_requests(self, httpbin):\n        r = requests.Request(url=httpbin())\n        with pytest.raises(ValueError):\n            requests.Session().send(r)\n\n    def test_http_error(self):\n        error = requests.exceptions.HTTPError()\n        assert not error.response\n        response = requests.Response()\n        error = requests.exceptions.HTTPError(response=response)\n        assert error.response == response\n        error = requests.exceptions.HTTPError(\"message\", response=response)\n        assert str(error) == \"message\"\n        assert error.response == response\n\n    def test_session_pickling(self, httpbin):\n        r = requests.Request(\"GET\", httpbin(\"get\"))\n        s = requests.Session()\n\n        s = pickle.loads(pickle.dumps(s))\n        s.proxies = getproxies()\n\n        r = s.sen"}, {"start_line": 8000, "end_line": 10000, "belongs_to": {"file_name": "models.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "       self,\n        method=None,\n        url=None,\n        headers=None,\n        files=None,\n        data=None,\n        params=None,\n        auth=None,\n        cookies=None,\n        hooks=None,\n        json=None,\n    ):\n        # Default empty dicts for dict params.\n        data = [] if data is None else data\n        files = [] if files is None else files\n        headers = {} if headers is None else headers\n        params = {} if params is None else params\n        hooks = {} if hooks is None else hooks\n\n        self.hooks = default_hooks()\n        for k, v in list(hooks.items()):\n            self.register_hook(event=k, hook=v)\n\n        self.method = method\n        self.url = url\n        self.headers = headers\n        self.files = files\n        self.data = data\n        self.json = json\n        self.params = params\n        self.auth = auth\n        self.cookies = cookies\n\n    def __repr__(self):\n        return f\"<Request [{self.method}]>\"\n\n    def prepare(self):\n        \"\"\"Constructs a :class:`PreparedRequest <PreparedRequest>` for transmission and returns it.\"\"\"\n        p = PreparedRequest()\n        p.prepare(\n            method=self.method,\n            url=self.url,\n            headers=self.headers,\n            files=self.files,\n            data=self.data,\n            json=self.json,\n            params=self.params,\n            auth=self.auth,\n            cookies=self.cookies,\n            hooks=self.hooks,\n        )\n        return p\n\n\nclass PreparedRequest(RequestEncodingMixin, RequestHooksMixin):\n    \"\"\"The fully mutable :class:`PreparedRequest <PreparedRequest>` object,\n    containing the exact bytes that will be sent to the server.\n\n    Instances are generated from a :class:`Request <Request>` object, and\n    should not be instantiated manually; doing so may produce undesirable\n    effects.\n\n    Usage::\n\n      >>> import requests\n      >>> req = requests.Request('GET', 'https://httpbin.org/get')\n      >>> r = req.prepare()\n      >>> r\n      <PreparedRequest [GET]>"}, {"start_line": 13000, "end_line": 15000, "belongs_to": {"file_name": "sessions.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "POST is responded to with a 301, turn it into a GET.\n        # This bizarre behaviour is explained in Issue 1704.\n        if response.status_code == codes.moved and method == \"POST\":\n            method = \"GET\"\n\n        prepared_request.method = method\n\n\nclass Session(SessionRedirectMixin):\n    \"\"\"A Requests session.\n\n    Provides cookie persistence, connection-pooling, and configuration.\n\n    Basic Usage::\n\n      >>> import requests\n      >>> s = requests.Session()\n      >>> s.get('https://httpbin.org/get')\n      <Response [200]>\n\n    Or as a context manager::\n\n      >>> with requests.Session() as s:\n      ...     s.get('https://httpbin.org/get')\n      <Response [200]>\n    \"\"\"\n\n    __attrs__ = [\n        \"headers\",\n        \"cookies\",\n        \"auth\",\n        \"proxies\",\n        \"hooks\",\n        \"params\",\n        \"verify\",\n        \"cert\",\n        \"adapters\",\n        \"stream\",\n        \"trust_env\",\n        \"max_redirects\",\n    ]\n\n    def __init__(self):\n        #: A case-insensitive dictionary of headers to be sent on each\n        #: :class:`Request <Request>` sent from this\n        #: :class:`Session <Session>`.\n        self.headers = default_headers()\n\n        #: Default Authentication tuple or object to attach to\n        #: :class:`Request <Request>`.\n        self.auth = None\n\n        #: Dictionary mapping protocol or protocol and host to the URL of the proxy\n        #: (e.g. {'http': 'foo.bar:3128', 'http://host.name': 'foo.bar:4012'}) to\n        #: be used on each :class:`Request <Request>`.\n        self.proxies = {}\n\n        #: Event-handling hooks.\n        self.hooks = default_hooks()\n\n        #: Dictionary of querystring data to attach to each\n        #: :class:`Request <Request>`. The dictionary values may be lists for\n        #: representing multivalued query parameters.\n        self.params = {}\n\n        #: Stream response content default.\n        self.stream = False\n\n        #: SSL Verification default.\n        #: Defaults to `True`, requiring requests to verif"}], "retrieved_count": 10, "cost_time": 3.9784364700317383}
{"question": "What is the precise definition of Requests' \"Session\" concept in terms of connection reuse and state management?", "answer": null, "relative_code_list": null, "ground_truth": "Requests' Session concept (src/requests/sessions.py) is defined as a stateful object that manages persistent settings and connection reuse across multiple HTTP requests. Key aspects include: 1) Connection pooling - Sessions use urllib3's connection pooling through HTTPAdapter, maintaining TCP connections to hosts for reuse, significantly improving performance by avoiding connection establishment overhead; 2) State persistence - Sessions maintain persistent state including cookies (RequestsCookieJar), authentication credentials, default headers, proxy settings, and request parameters across all requests; 3) Adapter management - Sessions mount HTTPAdapter instances for different URL schemes (http://, https://), enabling connection pooling and transport customization per protocol; 4) Configuration merging - Session-level settings (headers, auth, proxies, etc.) are merged with request-specific settings, with request settings taking precedence; 5) Cookie persistence - Cookies received in responses are automatically stored and sent in subsequent requests to the same domain; 6) Connection lifecycle - Sessions properly manage connection acquisition, usage, and return to the pool, ensuring efficient resource utilization; 7) Context management - Sessions implement context manager protocol for automatic cleanup and connection release; 8) Thread safety - Connection pools are thread-safe, allowing Sessions to be used across multiple threads. The Session provides a unified interface for making requests while maintaining state and optimizing performance through connection reuse.", "score": null, "retrieved_content": [{"start_line": 13000, "end_line": 15000, "belongs_to": {"file_name": "sessions.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "POST is responded to with a 301, turn it into a GET.\n        # This bizarre behaviour is explained in Issue 1704.\n        if response.status_code == codes.moved and method == \"POST\":\n            method = \"GET\"\n\n        prepared_request.method = method\n\n\nclass Session(SessionRedirectMixin):\n    \"\"\"A Requests session.\n\n    Provides cookie persistence, connection-pooling, and configuration.\n\n    Basic Usage::\n\n      >>> import requests\n      >>> s = requests.Session()\n      >>> s.get('https://httpbin.org/get')\n      <Response [200]>\n\n    Or as a context manager::\n\n      >>> with requests.Session() as s:\n      ...     s.get('https://httpbin.org/get')\n      <Response [200]>\n    \"\"\"\n\n    __attrs__ = [\n        \"headers\",\n        \"cookies\",\n        \"auth\",\n        \"proxies\",\n        \"hooks\",\n        \"params\",\n        \"verify\",\n        \"cert\",\n        \"adapters\",\n        \"stream\",\n        \"trust_env\",\n        \"max_redirects\",\n    ]\n\n    def __init__(self):\n        #: A case-insensitive dictionary of headers to be sent on each\n        #: :class:`Request <Request>` sent from this\n        #: :class:`Session <Session>`.\n        self.headers = default_headers()\n\n        #: Default Authentication tuple or object to attach to\n        #: :class:`Request <Request>`.\n        self.auth = None\n\n        #: Dictionary mapping protocol or protocol and host to the URL of the proxy\n        #: (e.g. {'http': 'foo.bar:3128', 'http://host.name': 'foo.bar:4012'}) to\n        #: be used on each :class:`Request <Request>`.\n        self.proxies = {}\n\n        #: Event-handling hooks.\n        self.hooks = default_hooks()\n\n        #: Dictionary of querystring data to attach to each\n        #: :class:`Request <Request>`. The dictionary values may be lists for\n        #: representing multivalued query parameters.\n        self.params = {}\n\n        #: Stream response content default.\n        self.stream = False\n\n        #: SSL Verification default.\n        #: Defaults to `True`, requiring requests to verif"}, {"start_line": 12000, "end_line": 14000, "belongs_to": {"file_name": "sessions.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "          username, password = None, None\n\n        # urllib3 handles proxy authorization for us in the standard adapter.\n        # Avoid appending this to TLS tunneled requests where it may be leaked.\n        if not scheme.startswith(\"https\") and username and password:\n            headers[\"Proxy-Authorization\"] = _basic_auth_str(username, password)\n\n        return new_proxies\n\n    def rebuild_method(self, prepared_request, response):\n        \"\"\"When being redirected we may want to change the method of the request\n        based on certain specs or browser behavior.\n        \"\"\"\n        method = prepared_request.method\n\n        # https://tools.ietf.org/html/rfc7231#section-6.4.4\n        if response.status_code == codes.see_other and method != \"HEAD\":\n            method = \"GET\"\n\n        # Do what the browsers do, despite standards...\n        # First, turn 302s into GETs.\n        if response.status_code == codes.found and method != \"HEAD\":\n            method = \"GET\"\n\n        # Second, if a POST is responded to with a 301, turn it into a GET.\n        # This bizarre behaviour is explained in Issue 1704.\n        if response.status_code == codes.moved and method == \"POST\":\n            method = \"GET\"\n\n        prepared_request.method = method\n\n\nclass Session(SessionRedirectMixin):\n    \"\"\"A Requests session.\n\n    Provides cookie persistence, connection-pooling, and configuration.\n\n    Basic Usage::\n\n      >>> import requests\n      >>> s = requests.Session()\n      >>> s.get('https://httpbin.org/get')\n      <Response [200]>\n\n    Or as a context manager::\n\n      >>> with requests.Session() as s:\n      ...     s.get('https://httpbin.org/get')\n      <Response [200]>\n    \"\"\"\n\n    __attrs__ = [\n        \"headers\",\n        \"cookies\",\n        \"auth\",\n        \"proxies\",\n        \"hooks\",\n        \"params\",\n        \"verify\",\n        \"cert\",\n        \"adapters\",\n        \"stream\",\n        \"trust_env\",\n        \"max_redirects\",\n    ]\n\n    def __init__(self):\n        #: A case-insensitive dictiona"}, {"start_line": 5000, "end_line": 7000, "belongs_to": {"file_name": "adapters.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": " requests where data has\n        made it to the server. By default, Requests does not retry failed\n        connections. If you need granular control over the conditions under\n        which we retry a request, import urllib3's ``Retry`` class and pass\n        that instead.\n    :param pool_block: Whether the connection pool should block for connections.\n\n    Usage::\n\n      >>> import requests\n      >>> s = requests.Session()\n      >>> a = requests.adapters.HTTPAdapter(max_retries=3)\n      >>> s.mount('http://', a)\n    \"\"\"\n\n    __attrs__ = [\n        \"max_retries\",\n        \"config\",\n        \"_pool_connections\",\n        \"_pool_maxsize\",\n        \"_pool_block\",\n    ]\n\n    def __init__(\n        self,\n        pool_connections=DEFAULT_POOLSIZE,\n        pool_maxsize=DEFAULT_POOLSIZE,\n        max_retries=DEFAULT_RETRIES,\n        pool_block=DEFAULT_POOLBLOCK,\n    ):\n        if max_retries == DEFAULT_RETRIES:\n            self.max_retries = Retry(0, read=False)\n        else:\n            self.max_retries = Retry.from_int(max_retries)\n        self.config = {}\n        self.proxy_manager = {}\n\n        super().__init__()\n\n        self._pool_connections = pool_connections\n        self._pool_maxsize = pool_maxsize\n        self._pool_block = pool_block\n\n        self.init_poolmanager(pool_connections, pool_maxsize, block=pool_block)\n\n    def __getstate__(self):\n        return {attr: getattr(self, attr, None) for attr in self.__attrs__}\n\n    def __setstate__(self, state):\n        # Can't handle by adding 'proxy_manager' to self.__attrs__ because\n        # self.poolmanager uses a lambda function, which isn't pickleable.\n        self.proxy_manager = {}\n        self.config = {}\n\n        for attr, value in state.items():\n            setattr(self, attr, value)\n\n        self.init_poolmanager(\n            self._pool_connections, self._pool_maxsize, block=self._pool_block\n        )\n\n    def init_poolmanager(\n        self, connections, maxsize, block=DEFAULT_POOLBLOCK, **pool_kwargs\n    ):\n        \""}, {"start_line": 0, "end_line": 2000, "belongs_to": {"file_name": "sessions.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "\"\"\"\nrequests.sessions\n~~~~~~~~~~~~~~~~~\n\nThis module provides a Session object to manage and persist settings across\nrequests (cookies, auth, proxies).\n\"\"\"\nimport os\nimport sys\nimport time\nfrom collections import OrderedDict\nfrom datetime import timedelta\n\nfrom ._internal_utils import to_native_string\nfrom .adapters import HTTPAdapter\nfrom .auth import _basic_auth_str\nfrom .compat import Mapping, cookielib, urljoin, urlparse\nfrom .cookies import (\n    RequestsCookieJar,\n    cookiejar_from_dict,\n    extract_cookies_to_jar,\n    merge_cookies,\n)\nfrom .exceptions import (\n    ChunkedEncodingError,\n    ContentDecodingError,\n    InvalidSchema,\n    TooManyRedirects,\n)\nfrom .hooks import default_hooks, dispatch_hook\n\n# formerly defined here, reexposed here for backward compatibility\nfrom .models import (  # noqa: F401\n    DEFAULT_REDIRECT_LIMIT,\n    REDIRECT_STATI,\n    PreparedRequest,\n    Request,\n)\nfrom .status_codes import codes\nfrom .structures import CaseInsensitiveDict\nfrom .utils import (  # noqa: F401\n    DEFAULT_PORTS,\n    default_headers,\n    get_auth_from_url,\n    get_environ_proxies,\n    get_netrc_auth,\n    requote_uri,\n    resolve_proxies,\n    rewind_body,\n    should_bypass_proxies,\n    to_key_val_list,\n)\n\n# Preferred clock, based on which one is more accurate on a given system.\nif sys.platform == \"win32\":\n    preferred_clock = time.perf_counter\nelse:\n    preferred_clock = time.time\n\n\ndef merge_setting(request_setting, session_setting, dict_class=OrderedDict):\n    \"\"\"Determines appropriate setting for a given request, taking into account\n    the explicit setting on that request, and the setting in the session. If a\n    setting is a dictionary, they will be merged together using `dict_class`\n    \"\"\"\n\n    if session_setting is None:\n        return request_setting\n\n    if request_setting is None:\n        return session_setting\n\n    # Bypass if not a dictionary (e.g. verify)\n    if not (\n        isinstance(session_setting, Mapping) and isinstance(request_setting, M"}, {"start_line": 15000, "end_line": 17000, "belongs_to": {"file_name": "sessions.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "y the TLS certificate at the\n        #: remote end.\n        #: If verify is set to `False`, requests will accept any TLS certificate\n        #: presented by the server, and will ignore hostname mismatches and/or\n        #: expired certificates, which will make your application vulnerable to\n        #: man-in-the-middle (MitM) attacks.\n        #: Only set this to `False` for testing.\n        self.verify = True\n\n        #: SSL client certificate default, if String, path to ssl client\n        #: cert file (.pem). If Tuple, ('cert', 'key') pair.\n        self.cert = None\n\n        #: Maximum number of redirects allowed. If the request exceeds this\n        #: limit, a :class:`TooManyRedirects` exception is raised.\n        #: This defaults to requests.models.DEFAULT_REDIRECT_LIMIT, which is\n        #: 30.\n        self.max_redirects = DEFAULT_REDIRECT_LIMIT\n\n        #: Trust environment settings for proxy configuration, default\n        #: authentication and similar.\n        self.trust_env = True\n\n        #: A CookieJar containing all currently outstanding cookies set on this\n        #: session. By default it is a\n        #: :class:`RequestsCookieJar <requests.cookies.RequestsCookieJar>`, but\n        #: may be any other ``cookielib.CookieJar`` compatible object.\n        self.cookies = cookiejar_from_dict({})\n\n        # Default connection adapters.\n        self.adapters = OrderedDict()\n        self.mount(\"https://\", HTTPAdapter())\n        self.mount(\"http://\", HTTPAdapter())\n\n    def __enter__(self):\n        return self\n\n    def __exit__(self, *args):\n        self.close()\n\n    def prepare_request(self, request):\n        \"\"\"Constructs a :class:`PreparedRequest <PreparedRequest>` for\n        transmission and returns it. The :class:`PreparedRequest` has settings\n        merged from the :class:`Request <Request>` instance and those of the\n        :class:`Session`.\n\n        :param request: :class:`Request` instance to prepare with this\n            session's settings.\n        :rtype"}, {"start_line": 2000, "end_line": 4000, "belongs_to": {"file_name": "api.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": ".\n    :type allow_redirects: bool\n    :param proxies: (optional) Dictionary mapping protocol to the URL of the proxy.\n    :param verify: (optional) Either a boolean, in which case it controls whether we verify\n            the server's TLS certificate, or a string, in which case it must be a path\n            to a CA bundle to use. Defaults to ``True``.\n    :param stream: (optional) if ``False``, the response content will be immediately downloaded.\n    :param cert: (optional) if String, path to ssl client cert file (.pem). If Tuple, ('cert', 'key') pair.\n    :return: :class:`Response <Response>` object\n    :rtype: requests.Response\n\n    Usage::\n\n      >>> import requests\n      >>> req = requests.request('GET', 'https://httpbin.org/get')\n      >>> req\n      <Response [200]>\n    \"\"\"\n\n    # By using the 'with' statement we are sure the session is closed, thus we\n    # avoid leaving sockets open which can trigger a ResourceWarning in some\n    # cases, and look like a memory leak in others.\n    with sessions.Session() as session:\n        return session.request(method=method, url=url, **kwargs)\n\n\ndef get(url, params=None, **kwargs):\n    r\"\"\"Sends a GET request.\n\n    :param url: URL for the new :class:`Request` object.\n    :param params: (optional) Dictionary, list of tuples or bytes to send\n        in the query string for the :class:`Request`.\n    :param \\*\\*kwargs: Optional arguments that ``request`` takes.\n    :return: :class:`Response <Response>` object\n    :rtype: requests.Response\n    \"\"\"\n\n    return request(\"get\", url, params=params, **kwargs)\n\n\ndef options(url, **kwargs):\n    r\"\"\"Sends an OPTIONS request.\n\n    :param url: URL for the new :class:`Request` object.\n    :param \\*\\*kwargs: Optional arguments that ``request`` takes.\n    :return: :class:`Response <Response>` object\n    :rtype: requests.Response\n    \"\"\"\n\n    return request(\"options\", url, **kwargs)\n\n\ndef head(url, **kwargs):\n    r\"\"\"Sends a HEAD request.\n\n    :param url: URL for the new :class:`Request` obje"}, {"start_line": 14000, "end_line": 16000, "belongs_to": {"file_name": "sessions.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "ry of headers to be sent on each\n        #: :class:`Request <Request>` sent from this\n        #: :class:`Session <Session>`.\n        self.headers = default_headers()\n\n        #: Default Authentication tuple or object to attach to\n        #: :class:`Request <Request>`.\n        self.auth = None\n\n        #: Dictionary mapping protocol or protocol and host to the URL of the proxy\n        #: (e.g. {'http': 'foo.bar:3128', 'http://host.name': 'foo.bar:4012'}) to\n        #: be used on each :class:`Request <Request>`.\n        self.proxies = {}\n\n        #: Event-handling hooks.\n        self.hooks = default_hooks()\n\n        #: Dictionary of querystring data to attach to each\n        #: :class:`Request <Request>`. The dictionary values may be lists for\n        #: representing multivalued query parameters.\n        self.params = {}\n\n        #: Stream response content default.\n        self.stream = False\n\n        #: SSL Verification default.\n        #: Defaults to `True`, requiring requests to verify the TLS certificate at the\n        #: remote end.\n        #: If verify is set to `False`, requests will accept any TLS certificate\n        #: presented by the server, and will ignore hostname mismatches and/or\n        #: expired certificates, which will make your application vulnerable to\n        #: man-in-the-middle (MitM) attacks.\n        #: Only set this to `False` for testing.\n        self.verify = True\n\n        #: SSL client certificate default, if String, path to ssl client\n        #: cert file (.pem). If Tuple, ('cert', 'key') pair.\n        self.cert = None\n\n        #: Maximum number of redirects allowed. If the request exceeds this\n        #: limit, a :class:`TooManyRedirects` exception is raised.\n        #: This defaults to requests.models.DEFAULT_REDIRECT_LIMIT, which is\n        #: 30.\n        self.max_redirects = DEFAULT_REDIRECT_LIMIT\n\n        #: Trust environment settings for proxy configuration, default\n        #: authentication and similar.\n        self.trust_env = Tru"}, {"start_line": 2000, "end_line": 4000, "belongs_to": {"file_name": "test_requests.py", "upper_path": "/data2/raymone/swebench-repos/requests/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": " requests.session\n        requests.session().get\n        requests.session().head\n        requests.get\n        requests.head\n        requests.put\n        requests.patch\n        requests.post\n        # Not really an entry point, but people rely on it.\n        from requests.packages.urllib3.poolmanager import PoolManager  # noqa:F401\n\n    @pytest.mark.parametrize(\n        \"exception, url\",\n        (\n            (MissingSchema, \"hiwpefhipowhefopw\"),\n            (InvalidSchema, \"localhost:3128\"),\n            (InvalidSchema, \"localhost.localdomain:3128/\"),\n            (InvalidSchema, \"10.122.1.1:3128/\"),\n            (InvalidURL, \"http://\"),\n            (InvalidURL, \"http://*example.com\"),\n            (InvalidURL, \"http://.example.com\"),\n        ),\n    )\n    def test_invalid_url(self, exception, url):\n        with pytest.raises(exception):\n            requests.get(url)\n\n    def test_basic_building(self):\n        req = requests.Request()\n        req.url = \"http://kennethreitz.org/\"\n        req.data = {\"life\": \"42\"}\n\n        pr = req.prepare()\n        assert pr.url == req.url\n        assert pr.body == \"life=42\"\n\n    @pytest.mark.parametrize(\"method\", (\"GET\", \"HEAD\"))\n    def test_no_content_length(self, httpbin, method):\n        req = requests.Request(method, httpbin(method.lower())).prepare()\n        assert \"Content-Length\" not in req.headers\n\n    @pytest.mark.parametrize(\"method\", (\"POST\", \"PUT\", \"PATCH\", \"OPTIONS\"))\n    def test_no_body_content_length(self, httpbin, method):\n        req = requests.Request(method, httpbin(method.lower())).prepare()\n        assert req.headers[\"Content-Length\"] == \"0\"\n\n    @pytest.mark.parametrize(\"method\", (\"POST\", \"PUT\", \"PATCH\", \"OPTIONS\"))\n    def test_empty_content_length(self, httpbin, method):\n        req = requests.Request(method, httpbin(method.lower()), data=\"\").prepare()\n        assert req.headers[\"Content-Length\"] == \"0\"\n\n    def test_override_content_length(self, httpbin):\n        headers = {\"Content-Length\": \"not zero\"}\n       "}, {"start_line": 3000, "end_line": 5000, "belongs_to": {"file_name": "api.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "   with sessions.Session() as session:\n        return session.request(method=method, url=url, **kwargs)\n\n\ndef get(url, params=None, **kwargs):\n    r\"\"\"Sends a GET request.\n\n    :param url: URL for the new :class:`Request` object.\n    :param params: (optional) Dictionary, list of tuples or bytes to send\n        in the query string for the :class:`Request`.\n    :param \\*\\*kwargs: Optional arguments that ``request`` takes.\n    :return: :class:`Response <Response>` object\n    :rtype: requests.Response\n    \"\"\"\n\n    return request(\"get\", url, params=params, **kwargs)\n\n\ndef options(url, **kwargs):\n    r\"\"\"Sends an OPTIONS request.\n\n    :param url: URL for the new :class:`Request` object.\n    :param \\*\\*kwargs: Optional arguments that ``request`` takes.\n    :return: :class:`Response <Response>` object\n    :rtype: requests.Response\n    \"\"\"\n\n    return request(\"options\", url, **kwargs)\n\n\ndef head(url, **kwargs):\n    r\"\"\"Sends a HEAD request.\n\n    :param url: URL for the new :class:`Request` object.\n    :param \\*\\*kwargs: Optional arguments that ``request`` takes. If\n        `allow_redirects` is not provided, it will be set to `False` (as\n        opposed to the default :meth:`request` behavior).\n    :return: :class:`Response <Response>` object\n    :rtype: requests.Response\n    \"\"\"\n\n    kwargs.setdefault(\"allow_redirects\", False)\n    return request(\"head\", url, **kwargs)\n\n\ndef post(url, data=None, json=None, **kwargs):\n    r\"\"\"Sends a POST request.\n\n    :param url: URL for the new :class:`Request` object.\n    :param data: (optional) Dictionary, list of tuples, bytes, or file-like\n        object to send in the body of the :class:`Request`.\n    :param json: (optional) A JSON serializable Python object to send in the body of the :class:`Request`.\n    :param \\*\\*kwargs: Optional arguments that ``request`` takes.\n    :return: :class:`Response <Response>` object\n    :rtype: requests.Response\n    \"\"\"\n\n    return request(\"post\", url, data=data, json=json, **kwargs)\n\n\ndef put(url, data="}, {"start_line": 0, "end_line": 2000, "belongs_to": {"file_name": "api.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "\"\"\"\nrequests.api\n~~~~~~~~~~~~\n\nThis module implements the Requests API.\n\n:copyright: (c) 2012 by Kenneth Reitz.\n:license: Apache2, see LICENSE for more details.\n\"\"\"\n\nfrom . import sessions\n\n\ndef request(method, url, **kwargs):\n    \"\"\"Constructs and sends a :class:`Request <Request>`.\n\n    :param method: method for the new :class:`Request` object: ``GET``, ``OPTIONS``, ``HEAD``, ``POST``, ``PUT``, ``PATCH``, or ``DELETE``.\n    :param url: URL for the new :class:`Request` object.\n    :param params: (optional) Dictionary, list of tuples or bytes to send\n        in the query string for the :class:`Request`.\n    :param data: (optional) Dictionary, list of tuples, bytes, or file-like\n        object to send in the body of the :class:`Request`.\n    :param json: (optional) A JSON serializable Python object to send in the body of the :class:`Request`.\n    :param headers: (optional) Dictionary of HTTP Headers to send with the :class:`Request`.\n    :param cookies: (optional) Dict or CookieJar object to send with the :class:`Request`.\n    :param files: (optional) Dictionary of ``'name': file-like-objects`` (or ``{'name': file-tuple}``) for multipart encoding upload.\n        ``file-tuple`` can be a 2-tuple ``('filename', fileobj)``, 3-tuple ``('filename', fileobj, 'content_type')``\n        or a 4-tuple ``('filename', fileobj, 'content_type', custom_headers)``, where ``'content_type'`` is a string\n        defining the content type of the given file and ``custom_headers`` a dict-like object containing additional headers\n        to add for the file.\n    :param auth: (optional) Auth tuple to enable Basic/Digest/Custom HTTP Auth.\n    :param timeout: (optional) How many seconds to wait for the server to send data\n        before giving up, as a float, or a :ref:`(connect timeout, read\n        timeout) <timeouts>` tuple.\n    :type timeout: float or tuple\n    :param allow_redirects: (optional) Boolean. Enable/disable GET/OPTIONS/POST/PUT/PATCH/DELETE/HEAD redirection. Defaults to ``True``"}], "retrieved_count": 10, "cost_time": 4.0273027420043945}
{"question": "What is the relationship between Requests' Response class and the Request class in establishing outgoing requests and incoming responses?", "answer": null, "relative_code_list": null, "ground_truth": "The relationship between Response and Request classes (src/requests/models.py) creates a request-response cycle: 1) Request reference - Response.request attribute holds a reference to the PreparedRequest that generated the response, enabling debugging and analysis; 2) Bidirectional linking - Response objects maintain links to their originating request, while Request objects can be prepared to generate responses; 3) Context preservation - Response preserves the context of the original request including method, URL, headers, and parameters; 4) History tracking - Response.history contains previous Response objects from redirect chains, each with their own request references; 5) Cookie flow - Cookies from Request are sent to server, and cookies from Response are extracted and can be used in subsequent requests; 6) Authentication flow - Authentication credentials from Request are processed, and authentication challenges in Response can trigger retry logic; 7) Header correlation - Response headers can be analyzed in context of Request headers for debugging and optimization; 8) Content relationship - Request body and Response content can be compared for debugging and validation; 9) Error context - When errors occur, both Request and Response information is available for debugging; 10) Redirect handling - During redirects, new Request objects are created based on Response headers, maintaining the chain. This relationship enables comprehensive request-response analysis and debugging capabilities.", "score": null, "retrieved_content": [{"start_line": 5000, "end_line": 7000, "belongs_to": {"file_name": "sessions.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "        changed_port = old_parsed.port != new_parsed.port\n        changed_scheme = old_parsed.scheme != new_parsed.scheme\n        default_port = (DEFAULT_PORTS.get(old_parsed.scheme, None), None)\n        if (\n            not changed_scheme\n            and old_parsed.port in default_port\n            and new_parsed.port in default_port\n        ):\n            return False\n\n        # Standard case: root URI must match\n        return changed_port or changed_scheme\n\n    def resolve_redirects(\n        self,\n        resp,\n        req,\n        stream=False,\n        timeout=None,\n        verify=True,\n        cert=None,\n        proxies=None,\n        yield_requests=False,\n        **adapter_kwargs,\n    ):\n        \"\"\"Receives a Response. Returns a generator of Responses or Requests.\"\"\"\n\n        hist = []  # keep track of history\n\n        url = self.get_redirect_target(resp)\n        previous_fragment = urlparse(req.url).fragment\n        while url:\n            prepared_request = req.copy()\n\n            # Update history and keep track of redirects.\n            # resp.history must ignore the original request in this loop\n            hist.append(resp)\n            resp.history = hist[1:]\n\n            try:\n                resp.content  # Consume socket so it can be released\n            except (ChunkedEncodingError, ContentDecodingError, RuntimeError):\n                resp.raw.read(decode_content=False)\n\n            if len(resp.history) >= self.max_redirects:\n                raise TooManyRedirects(\n                    f\"Exceeded {self.max_redirects} redirects.\", response=resp\n                )\n\n            # Release the connection back into the pool.\n            resp.close()\n\n            # Handle redirection without scheme (see: RFC 1808 Section 4)\n            if url.startswith(\"//\"):\n                parsed_rurl = urlparse(resp.url)\n                url = \":\".join([to_native_string(parsed_rurl.scheme), url])\n\n            # Normalize url case and attach previous fragment if needed (RFC 723"}, {"start_line": 21000, "end_line": 23000, "belongs_to": {"file_name": "models.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "nse>` object, which contains a\n    server's response to an HTTP request.\n    \"\"\"\n\n    __attrs__ = [\n        \"_content\",\n        \"status_code\",\n        \"headers\",\n        \"url\",\n        \"history\",\n        \"encoding\",\n        \"reason\",\n        \"cookies\",\n        \"elapsed\",\n        \"request\",\n    ]\n\n    def __init__(self):\n        self._content = False\n        self._content_consumed = False\n        self._next = None\n\n        #: Integer Code of responded HTTP Status, e.g. 404 or 200.\n        self.status_code = None\n\n        #: Case-insensitive Dictionary of Response Headers.\n        #: For example, ``headers['content-encoding']`` will return the\n        #: value of a ``'Content-Encoding'`` response header.\n        self.headers = CaseInsensitiveDict()\n\n        #: File-like object representation of response (for advanced usage).\n        #: Use of ``raw`` requires that ``stream=True`` be set on the request.\n        #: This requirement does not apply for use internally to Requests.\n        self.raw = None\n\n        #: Final URL location of Response.\n        self.url = None\n\n        #: Encoding to decode with when accessing r.text.\n        self.encoding = None\n\n        #: A list of :class:`Response <Response>` objects from\n        #: the history of the Request. Any redirect responses will end\n        #: up here. The list is sorted from the oldest to the most recent request.\n        self.history = []\n\n        #: Textual reason of responded HTTP Status, e.g. \"Not Found\" or \"OK\".\n        self.reason = None\n\n        #: A CookieJar of Cookies the server sent back.\n        self.cookies = cookiejar_from_dict({})\n\n        #: The amount of time elapsed between sending the request\n        #: and the arrival of the response (as a timedelta).\n        #: This property specifically measures the time taken between sending\n        #: the first byte of the request and finishing parsing the headers. It\n        #: is therefore unaffected by consuming the response content or the\n        #: value"}, {"start_line": 23000, "end_line": 25000, "belongs_to": {"file_name": "sessions.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "elf.request(\"HEAD\", url, **kwargs)\n\n    def post(self, url, data=None, json=None, **kwargs):\n        r\"\"\"Sends a POST request. Returns :class:`Response` object.\n\n        :param url: URL for the new :class:`Request` object.\n        :param data: (optional) Dictionary, list of tuples, bytes, or file-like\n            object to send in the body of the :class:`Request`.\n        :param json: (optional) json to send in the body of the :class:`Request`.\n        :param \\*\\*kwargs: Optional arguments that ``request`` takes.\n        :rtype: requests.Response\n        \"\"\"\n\n        return self.request(\"POST\", url, data=data, json=json, **kwargs)\n\n    def put(self, url, data=None, **kwargs):\n        r\"\"\"Sends a PUT request. Returns :class:`Response` object.\n\n        :param url: URL for the new :class:`Request` object.\n        :param data: (optional) Dictionary, list of tuples, bytes, or file-like\n            object to send in the body of the :class:`Request`.\n        :param \\*\\*kwargs: Optional arguments that ``request`` takes.\n        :rtype: requests.Response\n        \"\"\"\n\n        return self.request(\"PUT\", url, data=data, **kwargs)\n\n    def patch(self, url, data=None, **kwargs):\n        r\"\"\"Sends a PATCH request. Returns :class:`Response` object.\n\n        :param url: URL for the new :class:`Request` object.\n        :param data: (optional) Dictionary, list of tuples, bytes, or file-like\n            object to send in the body of the :class:`Request`.\n        :param \\*\\*kwargs: Optional arguments that ``request`` takes.\n        :rtype: requests.Response\n        \"\"\"\n\n        return self.request(\"PATCH\", url, data=data, **kwargs)\n\n    def delete(self, url, **kwargs):\n        r\"\"\"Sends a DELETE request. Returns :class:`Response` object.\n\n        :param url: URL for the new :class:`Request` object.\n        :param \\*\\*kwargs: Optional arguments that ``request`` takes.\n        :rtype: requests.Response\n        \"\"\"\n\n        return self.request(\"DELETE\", url, **kwargs)\n\n    def send(self, r"}, {"start_line": 18000, "end_line": 20000, "belongs_to": {"file_name": "sessions.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "   auth=merge_setting(auth, self.auth),\n            cookies=merged_cookies,\n            hooks=merge_hooks(request.hooks, self.hooks),\n        )\n        return p\n\n    def request(\n        self,\n        method,\n        url,\n        params=None,\n        data=None,\n        headers=None,\n        cookies=None,\n        files=None,\n        auth=None,\n        timeout=None,\n        allow_redirects=True,\n        proxies=None,\n        hooks=None,\n        stream=None,\n        verify=None,\n        cert=None,\n        json=None,\n    ):\n        \"\"\"Constructs a :class:`Request <Request>`, prepares it and sends it.\n        Returns :class:`Response <Response>` object.\n\n        :param method: method for the new :class:`Request` object.\n        :param url: URL for the new :class:`Request` object.\n        :param params: (optional) Dictionary or bytes to be sent in the query\n            string for the :class:`Request`.\n        :param data: (optional) Dictionary, list of tuples, bytes, or file-like\n            object to send in the body of the :class:`Request`.\n        :param json: (optional) json to send in the body of the\n            :class:`Request`.\n        :param headers: (optional) Dictionary of HTTP Headers to send with the\n            :class:`Request`.\n        :param cookies: (optional) Dict or CookieJar object to send with the\n            :class:`Request`.\n        :param files: (optional) Dictionary of ``'filename': file-like-objects``\n            for multipart encoding upload.\n        :param auth: (optional) Auth tuple or callable to enable\n            Basic/Digest/Custom HTTP Auth.\n        :param timeout: (optional) How many seconds to wait for the server to send\n            data before giving up, as a float, or a :ref:`(connect timeout,\n            read timeout) <timeouts>` tuple.\n        :type timeout: float or tuple\n        :param allow_redirects: (optional) Set to True by default.\n        :type allow_redirects: bool\n        :param proxies: (optional) Dictionary mapping protoc"}, {"start_line": 22000, "end_line": 24000, "belongs_to": {"file_name": "sessions.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "for the new :class:`Request` object.\n        :param \\*\\*kwargs: Optional arguments that ``request`` takes.\n        :rtype: requests.Response\n        \"\"\"\n\n        kwargs.setdefault(\"allow_redirects\", True)\n        return self.request(\"GET\", url, **kwargs)\n\n    def options(self, url, **kwargs):\n        r\"\"\"Sends a OPTIONS request. Returns :class:`Response` object.\n\n        :param url: URL for the new :class:`Request` object.\n        :param \\*\\*kwargs: Optional arguments that ``request`` takes.\n        :rtype: requests.Response\n        \"\"\"\n\n        kwargs.setdefault(\"allow_redirects\", True)\n        return self.request(\"OPTIONS\", url, **kwargs)\n\n    def head(self, url, **kwargs):\n        r\"\"\"Sends a HEAD request. Returns :class:`Response` object.\n\n        :param url: URL for the new :class:`Request` object.\n        :param \\*\\*kwargs: Optional arguments that ``request`` takes.\n        :rtype: requests.Response\n        \"\"\"\n\n        kwargs.setdefault(\"allow_redirects\", False)\n        return self.request(\"HEAD\", url, **kwargs)\n\n    def post(self, url, data=None, json=None, **kwargs):\n        r\"\"\"Sends a POST request. Returns :class:`Response` object.\n\n        :param url: URL for the new :class:`Request` object.\n        :param data: (optional) Dictionary, list of tuples, bytes, or file-like\n            object to send in the body of the :class:`Request`.\n        :param json: (optional) json to send in the body of the :class:`Request`.\n        :param \\*\\*kwargs: Optional arguments that ``request`` takes.\n        :rtype: requests.Response\n        \"\"\"\n\n        return self.request(\"POST\", url, data=data, json=json, **kwargs)\n\n    def put(self, url, data=None, **kwargs):\n        r\"\"\"Sends a PUT request. Returns :class:`Response` object.\n\n        :param url: URL for the new :class:`Request` object.\n        :param data: (optional) Dictionary, list of tuples, bytes, or file-like\n            object to send in the body of the :class:`Request`.\n        :param \\*\\*kwargs: Optional argume"}, {"start_line": 22000, "end_line": 24000, "belongs_to": {"file_name": "models.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "f.raw = None\n\n        #: Final URL location of Response.\n        self.url = None\n\n        #: Encoding to decode with when accessing r.text.\n        self.encoding = None\n\n        #: A list of :class:`Response <Response>` objects from\n        #: the history of the Request. Any redirect responses will end\n        #: up here. The list is sorted from the oldest to the most recent request.\n        self.history = []\n\n        #: Textual reason of responded HTTP Status, e.g. \"Not Found\" or \"OK\".\n        self.reason = None\n\n        #: A CookieJar of Cookies the server sent back.\n        self.cookies = cookiejar_from_dict({})\n\n        #: The amount of time elapsed between sending the request\n        #: and the arrival of the response (as a timedelta).\n        #: This property specifically measures the time taken between sending\n        #: the first byte of the request and finishing parsing the headers. It\n        #: is therefore unaffected by consuming the response content or the\n        #: value of the ``stream`` keyword argument.\n        self.elapsed = datetime.timedelta(0)\n\n        #: The :class:`PreparedRequest <PreparedRequest>` object to which this\n        #: is a response.\n        self.request = None\n\n    def __enter__(self):\n        return self\n\n    def __exit__(self, *args):\n        self.close()\n\n    def __getstate__(self):\n        # Consume everything; accessing the content attribute makes\n        # sure the content has been fully read.\n        if not self._content_consumed:\n            self.content\n\n        return {attr: getattr(self, attr, None) for attr in self.__attrs__}\n\n    def __setstate__(self, state):\n        for name, value in state.items():\n            setattr(self, name, value)\n\n        # pickled objects do not have .raw\n        setattr(self, \"_content_consumed\", True)\n        setattr(self, \"raw\", None)\n\n    def __repr__(self):\n        return f\"<Response [{self.status_code}]>\"\n\n    def __bool__(self):\n        \"\"\"Returns True if :attr:`status_code` is less"}, {"start_line": 12000, "end_line": 14000, "belongs_to": {"file_name": "adapters.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "Response\n        \"\"\"\n        response = Response()\n\n        # Fallback to None if there's no status_code, for whatever reason.\n        response.status_code = getattr(resp, \"status\", None)\n\n        # Make headers case-insensitive.\n        response.headers = CaseInsensitiveDict(getattr(resp, \"headers\", {}))\n\n        # Set encoding.\n        response.encoding = get_encoding_from_headers(response.headers)\n        response.raw = resp\n        response.reason = response.raw.reason\n\n        if isinstance(req.url, bytes):\n            response.url = req.url.decode(\"utf-8\")\n        else:\n            response.url = req.url\n\n        # Add new cookies from the server.\n        extract_cookies_to_jar(response.cookies, req, resp)\n\n        # Give the Response some context.\n        response.request = req\n        response.connection = self\n\n        return response\n\n    def build_connection_pool_key_attributes(self, request, verify, cert=None):\n        \"\"\"Build the PoolKey attributes used by urllib3 to return a connection.\n\n        This looks at the PreparedRequest, the user-specified verify value,\n        and the value of the cert parameter to determine what PoolKey values\n        to use to select a connection from a given urllib3 Connection Pool.\n\n        The SSL related pool key arguments are not consistently set. As of\n        this writing, use the following to determine what keys may be in that\n        dictionary:\n\n        * If ``verify`` is ``True``, ``\"ssl_context\"`` will be set and will be the\n          default Requests SSL Context\n        * If ``verify`` is ``False``, ``\"ssl_context\"`` will not be set but\n          ``\"cert_reqs\"`` will be set\n        * If ``verify`` is a string, (i.e., it is a user-specified trust bundle)\n          ``\"ca_certs\"`` will be set if the string is not a directory recognized\n          by :py:func:`os.path.isdir`, otherwise ``\"ca_cert_dir\"`` will be\n          set.\n        * If ``\"cert\"`` is specified, ``\"cert_file\"`` will always be set. If\n          ``\""}, {"start_line": 4000, "end_line": 6000, "belongs_to": {"file_name": "sessions.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "ion in latin1.\n            location = location.encode(\"latin1\")\n            return to_native_string(location, \"utf8\")\n        return None\n\n    def should_strip_auth(self, old_url, new_url):\n        \"\"\"Decide whether Authorization header should be removed when redirecting\"\"\"\n        old_parsed = urlparse(old_url)\n        new_parsed = urlparse(new_url)\n        if old_parsed.hostname != new_parsed.hostname:\n            return True\n        # Special case: allow http -> https redirect when using the standard\n        # ports. This isn't specified by RFC 7235, but is kept to avoid\n        # breaking backwards compatibility with older versions of requests\n        # that allowed any redirects on the same host.\n        if (\n            old_parsed.scheme == \"http\"\n            and old_parsed.port in (80, None)\n            and new_parsed.scheme == \"https\"\n            and new_parsed.port in (443, None)\n        ):\n            return False\n\n        # Handle default port usage corresponding to scheme.\n        changed_port = old_parsed.port != new_parsed.port\n        changed_scheme = old_parsed.scheme != new_parsed.scheme\n        default_port = (DEFAULT_PORTS.get(old_parsed.scheme, None), None)\n        if (\n            not changed_scheme\n            and old_parsed.port in default_port\n            and new_parsed.port in default_port\n        ):\n            return False\n\n        # Standard case: root URI must match\n        return changed_port or changed_scheme\n\n    def resolve_redirects(\n        self,\n        resp,\n        req,\n        stream=False,\n        timeout=None,\n        verify=True,\n        cert=None,\n        proxies=None,\n        yield_requests=False,\n        **adapter_kwargs,\n    ):\n        \"\"\"Receives a Response. Returns a generator of Responses or Requests.\"\"\"\n\n        hist = []  # keep track of history\n\n        url = self.get_redirect_target(resp)\n        previous_fragment = urlparse(req.url).fragment\n        while url:\n            prepared_request = req.copy()\n\n          "}, {"start_line": 23000, "end_line": 25000, "belongs_to": {"file_name": "models.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": " of the ``stream`` keyword argument.\n        self.elapsed = datetime.timedelta(0)\n\n        #: The :class:`PreparedRequest <PreparedRequest>` object to which this\n        #: is a response.\n        self.request = None\n\n    def __enter__(self):\n        return self\n\n    def __exit__(self, *args):\n        self.close()\n\n    def __getstate__(self):\n        # Consume everything; accessing the content attribute makes\n        # sure the content has been fully read.\n        if not self._content_consumed:\n            self.content\n\n        return {attr: getattr(self, attr, None) for attr in self.__attrs__}\n\n    def __setstate__(self, state):\n        for name, value in state.items():\n            setattr(self, name, value)\n\n        # pickled objects do not have .raw\n        setattr(self, \"_content_consumed\", True)\n        setattr(self, \"raw\", None)\n\n    def __repr__(self):\n        return f\"<Response [{self.status_code}]>\"\n\n    def __bool__(self):\n        \"\"\"Returns True if :attr:`status_code` is less than 400.\n\n        This attribute checks if the status code of the response is between\n        400 and 600 to see if there was a client error or a server error. If\n        the status code, is between 200 and 400, this will return True. This\n        is **not** a check to see if the response code is ``200 OK``.\n        \"\"\"\n        return self.ok\n\n    def __nonzero__(self):\n        \"\"\"Returns True if :attr:`status_code` is less than 400.\n\n        This attribute checks if the status code of the response is between\n        400 and 600 to see if there was a client error or a server error. If\n        the status code, is between 200 and 400, this will return True. This\n        is **not** a check to see if the response code is ``200 OK``.\n        \"\"\"\n        return self.ok\n\n    def __iter__(self):\n        \"\"\"Allows you to use a response as an iterator.\"\"\"\n        return self.iter_content(128)\n\n    @property\n    def ok(self):\n        \"\"\"Returns True if :attr:`status_code` is less than 400, Fals"}, {"start_line": 44000, "end_line": 46000, "belongs_to": {"file_name": "test_requests.py", "upper_path": "/data2/raymone/swebench-repos/requests/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "      s = requests.Session()\n        resp = s.request(\n            \"GET\",\n            httpbin(\"cookies/set?cookie=value\"),\n            allow_redirects=False,\n            headers={\"Host\": b\"httpbin.org\"},\n        )\n        assert resp.cookies.get(\"cookie\") == \"value\"\n\n    def test_links(self):\n        r = requests.Response()\n        r.headers = {\n            \"cache-control\": \"public, max-age=60, s-maxage=60\",\n            \"connection\": \"keep-alive\",\n            \"content-encoding\": \"gzip\",\n            \"content-type\": \"application/json; charset=utf-8\",\n            \"date\": \"Sat, 26 Jan 2013 16:47:56 GMT\",\n            \"etag\": '\"6ff6a73c0e446c1f61614769e3ceb778\"',\n            \"last-modified\": \"Sat, 26 Jan 2013 16:22:39 GMT\",\n            \"link\": (\n                \"<https://api.github.com/users/kennethreitz/repos?\"\n                'page=2&per_page=10>; rel=\"next\", <https://api.github.'\n                \"com/users/kennethreitz/repos?page=7&per_page=10>; \"\n                ' rel=\"last\"'\n            ),\n            \"server\": \"GitHub.com\",\n            \"status\": \"200 OK\",\n            \"vary\": \"Accept\",\n            \"x-content-type-options\": \"nosniff\",\n            \"x-github-media-type\": \"github.beta\",\n            \"x-ratelimit-limit\": \"60\",\n            \"x-ratelimit-remaining\": \"57\",\n        }\n        assert r.links[\"next\"][\"rel\"] == \"next\"\n\n    def test_cookie_parameters(self):\n        key = \"some_cookie\"\n        value = \"some_value\"\n        secure = True\n        domain = \"test.com\"\n        rest = {\"HttpOnly\": True}\n\n        jar = requests.cookies.RequestsCookieJar()\n        jar.set(key, value, secure=secure, domain=domain, rest=rest)\n\n        assert len(jar) == 1\n        assert \"some_cookie\" in jar\n\n        cookie = list(jar)[0]\n        assert cookie.secure == secure\n        assert cookie.domain == domain\n        assert cookie._rest[\"HttpOnly\"] == rest[\"HttpOnly\"]\n\n    def test_cookie_as_dict_keeps_len(self):\n        key = \"some_cookie\"\n        value = \"some_value\"\n\n        key1 = \"som"}], "retrieved_count": 10, "cost_time": 4.057285785675049}
{"question": "What is the exact meaning of Requests' \"adapter\" concept and its abstraction of underlying transport mechanisms?", "answer": null, "relative_code_list": null, "ground_truth": "Requests' adapter concept (src/requests/adapters.py) is a design pattern that provides a transport abstraction layer, separating HTTP client logic from the underlying transport implementation. The adapter system consists of: 1) BaseAdapter - an abstract interface defining the contract for transport adapters with send() and close() methods; 2) HTTPAdapter - the concrete implementation that wraps urllib3's PoolManager, providing connection pooling, retry logic, and proxy support for HTTP/HTTPS connections; 3) Transport abstraction - adapters abstract away the complexity of connection management, SSL/TLS handling, and protocol-specific details, allowing Requests to work with different underlying transport libraries; 4) Adapter mounting - Sessions can mount different adapters for different URL schemes (http://, https://, ftp://, etc.), enabling protocol-specific customization; 5) Connection pooling - HTTPAdapter manages connection pools through urllib3, handling connection reuse, limits, and lifecycle management; 6) Error handling - adapters translate transport-specific exceptions into Requests exceptions, providing a consistent error interface; 7) Configuration flexibility - adapters can be configured with different pool sizes, retry policies, and connection parameters; 8) Extensibility - custom adapters can be implemented by subclassing BaseAdapter for specialized transport needs. This abstraction enables Requests to maintain a clean, high-level API while delegating transport complexity to specialized adapter implementations.", "score": null, "retrieved_content": [{"start_line": 3000, "end_line": 5000, "belongs_to": {"file_name": "adapters.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "     \"host\": parsed_request_url.hostname,\n        \"port\": port,\n    }\n    return host_params, pool_kwargs\n\n\nclass BaseAdapter:\n    \"\"\"The Base Transport Adapter\"\"\"\n\n    def __init__(self):\n        super().__init__()\n\n    def send(\n        self, request, stream=False, timeout=None, verify=True, cert=None, proxies=None\n    ):\n        \"\"\"Sends PreparedRequest object. Returns Response object.\n\n        :param request: The :class:`PreparedRequest <PreparedRequest>` being sent.\n        :param stream: (optional) Whether to stream the request content.\n        :param timeout: (optional) How long to wait for the server to send\n            data before giving up, as a float, or a :ref:`(connect timeout,\n            read timeout) <timeouts>` tuple.\n        :type timeout: float or tuple\n        :param verify: (optional) Either a boolean, in which case it controls whether we verify\n            the server's TLS certificate, or a string, in which case it must be a path\n            to a CA bundle to use\n        :param cert: (optional) Any user-provided SSL certificate to be trusted.\n        :param proxies: (optional) The proxies dictionary to apply to the request.\n        \"\"\"\n        raise NotImplementedError\n\n    def close(self):\n        \"\"\"Cleans up adapter specific items.\"\"\"\n        raise NotImplementedError\n\n\nclass HTTPAdapter(BaseAdapter):\n    \"\"\"The built-in HTTP Adapter for urllib3.\n\n    Provides a general-case interface for Requests sessions to contact HTTP and\n    HTTPS urls by implementing the Transport Adapter interface. This class will\n    usually be created by the :class:`Session <Session>` class under the\n    covers.\n\n    :param pool_connections: The number of urllib3 connection pools to cache.\n    :param pool_maxsize: The maximum number of connections to save in the pool.\n    :param max_retries: The maximum number of retries each connection\n        should attempt. Note, this applies only to failed DNS lookups, socket\n        connections and connection timeouts, never to"}, {"start_line": 29000, "end_line": 30503, "belongs_to": {"file_name": "sessions.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "nnection adapter for the given URL.\n\n        :rtype: requests.adapters.BaseAdapter\n        \"\"\"\n        for prefix, adapter in self.adapters.items():\n            if url.lower().startswith(prefix.lower()):\n                return adapter\n\n        # Nothing matches :-/\n        raise InvalidSchema(f\"No connection adapters were found for {url!r}\")\n\n    def close(self):\n        \"\"\"Closes all adapters and as such the session\"\"\"\n        for v in self.adapters.values():\n            v.close()\n\n    def mount(self, prefix, adapter):\n        \"\"\"Registers a connection adapter to a prefix.\n\n        Adapters are sorted in descending order by prefix length.\n        \"\"\"\n        self.adapters[prefix] = adapter\n        keys_to_move = [k for k in self.adapters if len(k) < len(prefix)]\n\n        for key in keys_to_move:\n            self.adapters[key] = self.adapters.pop(key)\n\n    def __getstate__(self):\n        state = {attr: getattr(self, attr, None) for attr in self.__attrs__}\n        return state\n\n    def __setstate__(self, state):\n        for attr, value in state.items():\n            setattr(self, attr, value)\n\n\ndef session():\n    \"\"\"\n    Returns a :class:`Session` for context-management.\n\n    .. deprecated:: 1.0.0\n\n        This method has been deprecated since version 1.0.0 and is only kept for\n        backwards compatibility. New code should use :class:`~requests.sessions.Session`\n        to create a session. This may be removed at a future date.\n\n    :rtype: Session\n    \"\"\"\n    return Session()\n"}, {"start_line": 2000, "end_line": 4000, "belongs_to": {"file_name": "adapters.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "olmanager: \"PoolManager\",\n) -> \"(typing.Dict[str, typing.Any], typing.Dict[str, typing.Any])\":\n    host_params = {}\n    pool_kwargs = {}\n    parsed_request_url = urlparse(request.url)\n    scheme = parsed_request_url.scheme.lower()\n    port = parsed_request_url.port\n\n    cert_reqs = \"CERT_REQUIRED\"\n    if verify is False:\n        cert_reqs = \"CERT_NONE\"\n    elif isinstance(verify, str):\n        if not os.path.isdir(verify):\n            pool_kwargs[\"ca_certs\"] = verify\n        else:\n            pool_kwargs[\"ca_cert_dir\"] = verify\n    pool_kwargs[\"cert_reqs\"] = cert_reqs\n    if client_cert is not None:\n        if isinstance(client_cert, tuple) and len(client_cert) == 2:\n            pool_kwargs[\"cert_file\"] = client_cert[0]\n            pool_kwargs[\"key_file\"] = client_cert[1]\n        else:\n            # According to our docs, we allow users to specify just the client\n            # cert path\n            pool_kwargs[\"cert_file\"] = client_cert\n    host_params = {\n        \"scheme\": scheme,\n        \"host\": parsed_request_url.hostname,\n        \"port\": port,\n    }\n    return host_params, pool_kwargs\n\n\nclass BaseAdapter:\n    \"\"\"The Base Transport Adapter\"\"\"\n\n    def __init__(self):\n        super().__init__()\n\n    def send(\n        self, request, stream=False, timeout=None, verify=True, cert=None, proxies=None\n    ):\n        \"\"\"Sends PreparedRequest object. Returns Response object.\n\n        :param request: The :class:`PreparedRequest <PreparedRequest>` being sent.\n        :param stream: (optional) Whether to stream the request content.\n        :param timeout: (optional) How long to wait for the server to send\n            data before giving up, as a float, or a :ref:`(connect timeout,\n            read timeout) <timeouts>` tuple.\n        :type timeout: float or tuple\n        :param verify: (optional) Either a boolean, in which case it controls whether we verify\n            the server's TLS certificate, or a string, in which case it must be a path\n            to a CA bundle to use\n"}, {"start_line": 5000, "end_line": 7000, "belongs_to": {"file_name": "adapters.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": " requests where data has\n        made it to the server. By default, Requests does not retry failed\n        connections. If you need granular control over the conditions under\n        which we retry a request, import urllib3's ``Retry`` class and pass\n        that instead.\n    :param pool_block: Whether the connection pool should block for connections.\n\n    Usage::\n\n      >>> import requests\n      >>> s = requests.Session()\n      >>> a = requests.adapters.HTTPAdapter(max_retries=3)\n      >>> s.mount('http://', a)\n    \"\"\"\n\n    __attrs__ = [\n        \"max_retries\",\n        \"config\",\n        \"_pool_connections\",\n        \"_pool_maxsize\",\n        \"_pool_block\",\n    ]\n\n    def __init__(\n        self,\n        pool_connections=DEFAULT_POOLSIZE,\n        pool_maxsize=DEFAULT_POOLSIZE,\n        max_retries=DEFAULT_RETRIES,\n        pool_block=DEFAULT_POOLBLOCK,\n    ):\n        if max_retries == DEFAULT_RETRIES:\n            self.max_retries = Retry(0, read=False)\n        else:\n            self.max_retries = Retry.from_int(max_retries)\n        self.config = {}\n        self.proxy_manager = {}\n\n        super().__init__()\n\n        self._pool_connections = pool_connections\n        self._pool_maxsize = pool_maxsize\n        self._pool_block = pool_block\n\n        self.init_poolmanager(pool_connections, pool_maxsize, block=pool_block)\n\n    def __getstate__(self):\n        return {attr: getattr(self, attr, None) for attr in self.__attrs__}\n\n    def __setstate__(self, state):\n        # Can't handle by adding 'proxy_manager' to self.__attrs__ because\n        # self.poolmanager uses a lambda function, which isn't pickleable.\n        self.proxy_manager = {}\n        self.config = {}\n\n        for attr, value in state.items():\n            setattr(self, attr, value)\n\n        self.init_poolmanager(\n            self._pool_connections, self._pool_maxsize, block=self._pool_block\n        )\n\n    def init_poolmanager(\n        self, connections, maxsize, block=DEFAULT_POOLBLOCK, **pool_kwargs\n    ):\n        \""}, {"start_line": 21000, "end_line": 23000, "belongs_to": {"file_name": "adapters.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "ters.HTTPAdapter>`.\n\n        This should not be called from user code, and is only exposed for use\n        when subclassing the\n        :class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.\n\n        :param request: The :class:`PreparedRequest <PreparedRequest>` to add headers to.\n        :param kwargs: The keyword arguments from the call to send().\n        \"\"\"\n        pass\n\n    def proxy_headers(self, proxy):\n        \"\"\"Returns a dictionary of the headers to add to any request sent\n        through a proxy. This works with urllib3 magic to ensure that they are\n        correctly sent to the proxy, rather than in a tunnelled request if\n        CONNECT is being used.\n\n        This should not be called from user code, and is only exposed for use\n        when subclassing the\n        :class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.\n\n        :param proxy: The url of the proxy being used for this request.\n        :rtype: dict\n        \"\"\"\n        headers = {}\n        username, password = get_auth_from_url(proxy)\n\n        if username:\n            headers[\"Proxy-Authorization\"] = _basic_auth_str(username, password)\n\n        return headers\n\n    def send(\n        self, request, stream=False, timeout=None, verify=True, cert=None, proxies=None\n    ):\n        \"\"\"Sends PreparedRequest object. Returns Response object.\n\n        :param request: The :class:`PreparedRequest <PreparedRequest>` being sent.\n        :param stream: (optional) Whether to stream the request content.\n        :param timeout: (optional) How long to wait for the server to send\n            data before giving up, as a float, or a :ref:`(connect timeout,\n            read timeout) <timeouts>` tuple.\n        :type timeout: float or tuple or urllib3 Timeout object\n        :param verify: (optional) Either a boolean, in which case it controls whether\n            we verify the server's TLS certificate, or a string, in which case it\n            must be a path to a CA bundle to use\n        :param cert: (optional) Any user"}, {"start_line": 28000, "end_line": 30000, "belongs_to": {"file_name": "sessions.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "vironment's proxies.\n            no_proxy = proxies.get(\"no_proxy\") if proxies is not None else None\n            env_proxies = get_environ_proxies(url, no_proxy=no_proxy)\n            for k, v in env_proxies.items():\n                proxies.setdefault(k, v)\n\n            # Look for requests environment configuration\n            # and be compatible with cURL.\n            if verify is True or verify is None:\n                verify = (\n                    os.environ.get(\"REQUESTS_CA_BUNDLE\")\n                    or os.environ.get(\"CURL_CA_BUNDLE\")\n                    or verify\n                )\n\n        # Merge all the kwargs.\n        proxies = merge_setting(proxies, self.proxies)\n        stream = merge_setting(stream, self.stream)\n        verify = merge_setting(verify, self.verify)\n        cert = merge_setting(cert, self.cert)\n\n        return {\"proxies\": proxies, \"stream\": stream, \"verify\": verify, \"cert\": cert}\n\n    def get_adapter(self, url):\n        \"\"\"\n        Returns the appropriate connection adapter for the given URL.\n\n        :rtype: requests.adapters.BaseAdapter\n        \"\"\"\n        for prefix, adapter in self.adapters.items():\n            if url.lower().startswith(prefix.lower()):\n                return adapter\n\n        # Nothing matches :-/\n        raise InvalidSchema(f\"No connection adapters were found for {url!r}\")\n\n    def close(self):\n        \"\"\"Closes all adapters and as such the session\"\"\"\n        for v in self.adapters.values():\n            v.close()\n\n    def mount(self, prefix, adapter):\n        \"\"\"Registers a connection adapter to a prefix.\n\n        Adapters are sorted in descending order by prefix length.\n        \"\"\"\n        self.adapters[prefix] = adapter\n        keys_to_move = [k for k in self.adapters if len(k) < len(prefix)]\n\n        for key in keys_to_move:\n            self.adapters[key] = self.adapters.pop(key)\n\n    def __getstate__(self):\n        state = {attr: getattr(self, attr, None) for attr in self.__attrs__}\n        return state\n\n    def "}, {"start_line": 0, "end_line": 2000, "belongs_to": {"file_name": "adapters.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "\"\"\"\nrequests.adapters\n~~~~~~~~~~~~~~~~~\n\nThis module contains the transport adapters that Requests uses to define\nand maintain connections.\n\"\"\"\n\nimport os.path\nimport socket  # noqa: F401\nimport typing\nimport warnings\n\nfrom urllib3.exceptions import ClosedPoolError, ConnectTimeoutError\nfrom urllib3.exceptions import HTTPError as _HTTPError\nfrom urllib3.exceptions import InvalidHeader as _InvalidHeader\nfrom urllib3.exceptions import (\n    LocationValueError,\n    MaxRetryError,\n    NewConnectionError,\n    ProtocolError,\n)\nfrom urllib3.exceptions import ProxyError as _ProxyError\nfrom urllib3.exceptions import ReadTimeoutError, ResponseError\nfrom urllib3.exceptions import SSLError as _SSLError\nfrom urllib3.poolmanager import PoolManager, proxy_from_url\nfrom urllib3.util import Timeout as TimeoutSauce\nfrom urllib3.util import parse_url\nfrom urllib3.util.retry import Retry\n\nfrom .auth import _basic_auth_str\nfrom .compat import basestring, urlparse\nfrom .cookies import extract_cookies_to_jar\nfrom .exceptions import (\n    ConnectionError,\n    ConnectTimeout,\n    InvalidHeader,\n    InvalidProxyURL,\n    InvalidSchema,\n    InvalidURL,\n    ProxyError,\n    ReadTimeout,\n    RetryError,\n    SSLError,\n)\nfrom .models import Response\nfrom .structures import CaseInsensitiveDict\nfrom .utils import (\n    DEFAULT_CA_BUNDLE_PATH,\n    extract_zipped_paths,\n    get_auth_from_url,\n    get_encoding_from_headers,\n    prepend_scheme_if_needed,\n    select_proxy,\n    urldefragauth,\n)\n\ntry:\n    from urllib3.contrib.socks import SOCKSProxyManager\nexcept ImportError:\n\n    def SOCKSProxyManager(*args, **kwargs):\n        raise InvalidSchema(\"Missing dependencies for SOCKS support.\")\n\n\nif typing.TYPE_CHECKING:\n    from .models import PreparedRequest\n\n\nDEFAULT_POOLBLOCK = False\nDEFAULT_POOLSIZE = 10\nDEFAULT_RETRIES = 0\nDEFAULT_POOL_TIMEOUT = None\n\n\ndef _urllib3_request_context(\n    request: \"PreparedRequest\",\n    verify: \"bool | str | None\",\n    client_cert: \"typing.Tuple[str, str] | str | None\",\n    po"}, {"start_line": 4000, "end_line": 6000, "belongs_to": {"file_name": "adapters.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "        :param cert: (optional) Any user-provided SSL certificate to be trusted.\n        :param proxies: (optional) The proxies dictionary to apply to the request.\n        \"\"\"\n        raise NotImplementedError\n\n    def close(self):\n        \"\"\"Cleans up adapter specific items.\"\"\"\n        raise NotImplementedError\n\n\nclass HTTPAdapter(BaseAdapter):\n    \"\"\"The built-in HTTP Adapter for urllib3.\n\n    Provides a general-case interface for Requests sessions to contact HTTP and\n    HTTPS urls by implementing the Transport Adapter interface. This class will\n    usually be created by the :class:`Session <Session>` class under the\n    covers.\n\n    :param pool_connections: The number of urllib3 connection pools to cache.\n    :param pool_maxsize: The maximum number of connections to save in the pool.\n    :param max_retries: The maximum number of retries each connection\n        should attempt. Note, this applies only to failed DNS lookups, socket\n        connections and connection timeouts, never to requests where data has\n        made it to the server. By default, Requests does not retry failed\n        connections. If you need granular control over the conditions under\n        which we retry a request, import urllib3's ``Retry`` class and pass\n        that instead.\n    :param pool_block: Whether the connection pool should block for connections.\n\n    Usage::\n\n      >>> import requests\n      >>> s = requests.Session()\n      >>> a = requests.adapters.HTTPAdapter(max_retries=3)\n      >>> s.mount('http://', a)\n    \"\"\"\n\n    __attrs__ = [\n        \"max_retries\",\n        \"config\",\n        \"_pool_connections\",\n        \"_pool_maxsize\",\n        \"_pool_block\",\n    ]\n\n    def __init__(\n        self,\n        pool_connections=DEFAULT_POOLSIZE,\n        pool_maxsize=DEFAULT_POOLSIZE,\n        max_retries=DEFAULT_RETRIES,\n        pool_block=DEFAULT_POOLBLOCK,\n    ):\n        if max_retries == DEFAULT_RETRIES:\n            self.max_retries = Retry(0, read=False)\n        else:\n            self.max_retr"}, {"start_line": 58000, "end_line": 60000, "belongs_to": {"file_name": "test_requests.py", "upper_path": "/data2/raymone/swebench-repos/requests/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "http://\": HTTPAdapter()}\n        s2.mount(\"https://\", HTTPAdapter())\n        assert \"http://\" in s2.adapters\n        assert \"https://\" in s2.adapters\n\n    def test_session_get_adapter_prefix_matching(self):\n        prefix = \"https://example.com\"\n        more_specific_prefix = prefix + \"/some/path\"\n\n        url_matching_only_prefix = prefix + \"/another/path\"\n        url_matching_more_specific_prefix = more_specific_prefix + \"/longer/path\"\n        url_not_matching_prefix = \"https://another.example.com/\"\n\n        s = requests.Session()\n        prefix_adapter = HTTPAdapter()\n        more_specific_prefix_adapter = HTTPAdapter()\n        s.mount(prefix, prefix_adapter)\n        s.mount(more_specific_prefix, more_specific_prefix_adapter)\n\n        assert s.get_adapter(url_matching_only_prefix) is prefix_adapter\n        assert (\n            s.get_adapter(url_matching_more_specific_prefix)\n            is more_specific_prefix_adapter\n        )\n        assert s.get_adapter(url_not_matching_prefix) not in (\n            prefix_adapter,\n            more_specific_prefix_adapter,\n        )\n\n    def test_session_get_adapter_prefix_matching_mixed_case(self):\n        mixed_case_prefix = \"hTtPs://eXamPle.CoM/MixEd_CAse_PREfix\"\n        url_matching_prefix = mixed_case_prefix + \"/full_url\"\n\n        s = requests.Session()\n        my_adapter = HTTPAdapter()\n        s.mount(mixed_case_prefix, my_adapter)\n\n        assert s.get_adapter(url_matching_prefix) is my_adapter\n\n    def test_session_get_adapter_prefix_matching_is_case_insensitive(self):\n        mixed_case_prefix = \"hTtPs://eXamPle.CoM/MixEd_CAse_PREfix\"\n        url_matching_prefix_with_different_case = (\n            \"HtTpS://exaMPLe.cOm/MiXeD_caSE_preFIX/another_url\"\n        )\n\n        s = requests.Session()\n        my_adapter = HTTPAdapter()\n        s.mount(mixed_case_prefix, my_adapter)\n\n        assert s.get_adapter(url_matching_prefix_with_different_case) is my_adapter\n\n    def test_session_get_adapter_prefix_with_trailing_slash(self"}, {"start_line": 57000, "end_line": 59000, "belongs_to": {"file_name": "test_requests.py", "upper_path": "/data2/raymone/swebench-repos/requests/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": ".mount(\"http://git\", HTTPAdapter())\n        s.mount(\"http://github\", HTTPAdapter())\n        s.mount(\"http://github.com\", HTTPAdapter())\n        s.mount(\"http://github.com/about/\", HTTPAdapter())\n        order = [\n            \"http://github.com/about/\",\n            \"http://github.com\",\n            \"http://github\",\n            \"http://git\",\n            \"https://\",\n            \"http://\",\n        ]\n        assert order == list(s.adapters)\n        s.mount(\"http://gittip\", HTTPAdapter())\n        s.mount(\"http://gittip.com\", HTTPAdapter())\n        s.mount(\"http://gittip.com/about/\", HTTPAdapter())\n        order = [\n            \"http://github.com/about/\",\n            \"http://gittip.com/about/\",\n            \"http://github.com\",\n            \"http://gittip.com\",\n            \"http://github\",\n            \"http://gittip\",\n            \"http://git\",\n            \"https://\",\n            \"http://\",\n        ]\n        assert order == list(s.adapters)\n        s2 = requests.Session()\n        s2.adapters = {\"http://\": HTTPAdapter()}\n        s2.mount(\"https://\", HTTPAdapter())\n        assert \"http://\" in s2.adapters\n        assert \"https://\" in s2.adapters\n\n    def test_session_get_adapter_prefix_matching(self):\n        prefix = \"https://example.com\"\n        more_specific_prefix = prefix + \"/some/path\"\n\n        url_matching_only_prefix = prefix + \"/another/path\"\n        url_matching_more_specific_prefix = more_specific_prefix + \"/longer/path\"\n        url_not_matching_prefix = \"https://another.example.com/\"\n\n        s = requests.Session()\n        prefix_adapter = HTTPAdapter()\n        more_specific_prefix_adapter = HTTPAdapter()\n        s.mount(prefix, prefix_adapter)\n        s.mount(more_specific_prefix, more_specific_prefix_adapter)\n\n        assert s.get_adapter(url_matching_only_prefix) is prefix_adapter\n        assert (\n            s.get_adapter(url_matching_more_specific_prefix)\n            is more_specific_prefix_adapter\n        )\n        assert s.get_adapter(url_not_matching_prefix) n"}], "retrieved_count": 10, "cost_time": 4.109680414199829}
{"question": "Where in Requests is the session management system implemented?", "answer": null, "relative_code_list": null, "ground_truth": "The session management system is implemented in src/requests/sessions.py through the Session class and SessionRedirectMixin. Key components include: 1) Session class - main session implementation with connection pooling, cookie persistence, and configuration management; 2) SessionRedirectMixin - handles redirect logic and URL processing; 3) Session initialization in __init__() method sets up default headers, cookies, auth, proxies, and adapters; 4) prepare_request() method merges session settings with request-specific settings; 5) send() method coordinates request execution through adapters; 6) resolve_redirects() method handles redirect chains; 7) mount() method registers adapters for different URL schemes; 8) close() method manages resource cleanup. The session system integrates with other components: cookies from src/requests/cookies.py, authentication from src/requests/auth.py, adapters from src/requests/adapters.py, and request/response objects from src/requests/models.py. Sessions provide the primary interface for making HTTP requests with persistent state and connection pooling.", "score": null, "retrieved_content": [{"start_line": 13000, "end_line": 15000, "belongs_to": {"file_name": "sessions.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "POST is responded to with a 301, turn it into a GET.\n        # This bizarre behaviour is explained in Issue 1704.\n        if response.status_code == codes.moved and method == \"POST\":\n            method = \"GET\"\n\n        prepared_request.method = method\n\n\nclass Session(SessionRedirectMixin):\n    \"\"\"A Requests session.\n\n    Provides cookie persistence, connection-pooling, and configuration.\n\n    Basic Usage::\n\n      >>> import requests\n      >>> s = requests.Session()\n      >>> s.get('https://httpbin.org/get')\n      <Response [200]>\n\n    Or as a context manager::\n\n      >>> with requests.Session() as s:\n      ...     s.get('https://httpbin.org/get')\n      <Response [200]>\n    \"\"\"\n\n    __attrs__ = [\n        \"headers\",\n        \"cookies\",\n        \"auth\",\n        \"proxies\",\n        \"hooks\",\n        \"params\",\n        \"verify\",\n        \"cert\",\n        \"adapters\",\n        \"stream\",\n        \"trust_env\",\n        \"max_redirects\",\n    ]\n\n    def __init__(self):\n        #: A case-insensitive dictionary of headers to be sent on each\n        #: :class:`Request <Request>` sent from this\n        #: :class:`Session <Session>`.\n        self.headers = default_headers()\n\n        #: Default Authentication tuple or object to attach to\n        #: :class:`Request <Request>`.\n        self.auth = None\n\n        #: Dictionary mapping protocol or protocol and host to the URL of the proxy\n        #: (e.g. {'http': 'foo.bar:3128', 'http://host.name': 'foo.bar:4012'}) to\n        #: be used on each :class:`Request <Request>`.\n        self.proxies = {}\n\n        #: Event-handling hooks.\n        self.hooks = default_hooks()\n\n        #: Dictionary of querystring data to attach to each\n        #: :class:`Request <Request>`. The dictionary values may be lists for\n        #: representing multivalued query parameters.\n        self.params = {}\n\n        #: Stream response content default.\n        self.stream = False\n\n        #: SSL Verification default.\n        #: Defaults to `True`, requiring requests to verif"}, {"start_line": 0, "end_line": 2000, "belongs_to": {"file_name": "sessions.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "\"\"\"\nrequests.sessions\n~~~~~~~~~~~~~~~~~\n\nThis module provides a Session object to manage and persist settings across\nrequests (cookies, auth, proxies).\n\"\"\"\nimport os\nimport sys\nimport time\nfrom collections import OrderedDict\nfrom datetime import timedelta\n\nfrom ._internal_utils import to_native_string\nfrom .adapters import HTTPAdapter\nfrom .auth import _basic_auth_str\nfrom .compat import Mapping, cookielib, urljoin, urlparse\nfrom .cookies import (\n    RequestsCookieJar,\n    cookiejar_from_dict,\n    extract_cookies_to_jar,\n    merge_cookies,\n)\nfrom .exceptions import (\n    ChunkedEncodingError,\n    ContentDecodingError,\n    InvalidSchema,\n    TooManyRedirects,\n)\nfrom .hooks import default_hooks, dispatch_hook\n\n# formerly defined here, reexposed here for backward compatibility\nfrom .models import (  # noqa: F401\n    DEFAULT_REDIRECT_LIMIT,\n    REDIRECT_STATI,\n    PreparedRequest,\n    Request,\n)\nfrom .status_codes import codes\nfrom .structures import CaseInsensitiveDict\nfrom .utils import (  # noqa: F401\n    DEFAULT_PORTS,\n    default_headers,\n    get_auth_from_url,\n    get_environ_proxies,\n    get_netrc_auth,\n    requote_uri,\n    resolve_proxies,\n    rewind_body,\n    should_bypass_proxies,\n    to_key_val_list,\n)\n\n# Preferred clock, based on which one is more accurate on a given system.\nif sys.platform == \"win32\":\n    preferred_clock = time.perf_counter\nelse:\n    preferred_clock = time.time\n\n\ndef merge_setting(request_setting, session_setting, dict_class=OrderedDict):\n    \"\"\"Determines appropriate setting for a given request, taking into account\n    the explicit setting on that request, and the setting in the session. If a\n    setting is a dictionary, they will be merged together using `dict_class`\n    \"\"\"\n\n    if session_setting is None:\n        return request_setting\n\n    if request_setting is None:\n        return session_setting\n\n    # Bypass if not a dictionary (e.g. verify)\n    if not (\n        isinstance(session_setting, Mapping) and isinstance(request_setting, M"}, {"start_line": 13000, "end_line": 15000, "belongs_to": {"file_name": "test_requests.py", "upper_path": "/data2/raymone/swebench-repos/requests/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "atus_code == 200\n\n    def test_set_cookie_on_301(self, httpbin):\n        s = requests.session()\n        url = httpbin(\"cookies/set?foo=bar\")\n        s.get(url)\n        assert s.cookies[\"foo\"] == \"bar\"\n\n    def test_cookie_sent_on_redirect(self, httpbin):\n        s = requests.session()\n        s.get(httpbin(\"cookies/set?foo=bar\"))\n        r = s.get(httpbin(\"redirect/1\"))  # redirects to httpbin('get')\n        assert \"Cookie\" in r.json()[\"headers\"]\n\n    def test_cookie_removed_on_expire(self, httpbin):\n        s = requests.session()\n        s.get(httpbin(\"cookies/set?foo=bar\"))\n        assert s.cookies[\"foo\"] == \"bar\"\n        s.get(\n            httpbin(\"response-headers\"),\n            params={\"Set-Cookie\": \"foo=deleted; expires=Thu, 01-Jan-1970 00:00:01 GMT\"},\n        )\n        assert \"foo\" not in s.cookies\n\n    def test_cookie_quote_wrapped(self, httpbin):\n        s = requests.session()\n        s.get(httpbin('cookies/set?foo=\"bar:baz\"'))\n        assert s.cookies[\"foo\"] == '\"bar:baz\"'\n\n    def test_cookie_persists_via_api(self, httpbin):\n        s = requests.session()\n        r = s.get(httpbin(\"redirect/1\"), cookies={\"foo\": \"bar\"})\n        assert \"foo\" in r.request.headers[\"Cookie\"]\n        assert \"foo\" in r.history[0].request.headers[\"Cookie\"]\n\n    def test_request_cookie_overrides_session_cookie(self, httpbin):\n        s = requests.session()\n        s.cookies[\"foo\"] = \"bar\"\n        r = s.get(httpbin(\"cookies\"), cookies={\"foo\": \"baz\"})\n        assert r.json()[\"cookies\"][\"foo\"] == \"baz\"\n        # Session cookie should not be modified\n        assert s.cookies[\"foo\"] == \"bar\"\n\n    def test_request_cookies_not_persisted(self, httpbin):\n        s = requests.session()\n        s.get(httpbin(\"cookies\"), cookies={\"foo\": \"baz\"})\n        # Sending a request with cookies should not add cookies to the session\n        assert not s.cookies\n\n    def test_generic_cookiejar_works(self, httpbin):\n        cj = cookielib.CookieJar()\n        cookiejar_from_dict({\"foo\": \"bar\"}, cj)\n       "}, {"start_line": 12000, "end_line": 14000, "belongs_to": {"file_name": "sessions.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "          username, password = None, None\n\n        # urllib3 handles proxy authorization for us in the standard adapter.\n        # Avoid appending this to TLS tunneled requests where it may be leaked.\n        if not scheme.startswith(\"https\") and username and password:\n            headers[\"Proxy-Authorization\"] = _basic_auth_str(username, password)\n\n        return new_proxies\n\n    def rebuild_method(self, prepared_request, response):\n        \"\"\"When being redirected we may want to change the method of the request\n        based on certain specs or browser behavior.\n        \"\"\"\n        method = prepared_request.method\n\n        # https://tools.ietf.org/html/rfc7231#section-6.4.4\n        if response.status_code == codes.see_other and method != \"HEAD\":\n            method = \"GET\"\n\n        # Do what the browsers do, despite standards...\n        # First, turn 302s into GETs.\n        if response.status_code == codes.found and method != \"HEAD\":\n            method = \"GET\"\n\n        # Second, if a POST is responded to with a 301, turn it into a GET.\n        # This bizarre behaviour is explained in Issue 1704.\n        if response.status_code == codes.moved and method == \"POST\":\n            method = \"GET\"\n\n        prepared_request.method = method\n\n\nclass Session(SessionRedirectMixin):\n    \"\"\"A Requests session.\n\n    Provides cookie persistence, connection-pooling, and configuration.\n\n    Basic Usage::\n\n      >>> import requests\n      >>> s = requests.Session()\n      >>> s.get('https://httpbin.org/get')\n      <Response [200]>\n\n    Or as a context manager::\n\n      >>> with requests.Session() as s:\n      ...     s.get('https://httpbin.org/get')\n      <Response [200]>\n    \"\"\"\n\n    __attrs__ = [\n        \"headers\",\n        \"cookies\",\n        \"auth\",\n        \"proxies\",\n        \"hooks\",\n        \"params\",\n        \"verify\",\n        \"cert\",\n        \"adapters\",\n        \"stream\",\n        \"trust_env\",\n        \"max_redirects\",\n    ]\n\n    def __init__(self):\n        #: A case-insensitive dictiona"}, {"start_line": 44000, "end_line": 46000, "belongs_to": {"file_name": "test_requests.py", "upper_path": "/data2/raymone/swebench-repos/requests/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "      s = requests.Session()\n        resp = s.request(\n            \"GET\",\n            httpbin(\"cookies/set?cookie=value\"),\n            allow_redirects=False,\n            headers={\"Host\": b\"httpbin.org\"},\n        )\n        assert resp.cookies.get(\"cookie\") == \"value\"\n\n    def test_links(self):\n        r = requests.Response()\n        r.headers = {\n            \"cache-control\": \"public, max-age=60, s-maxage=60\",\n            \"connection\": \"keep-alive\",\n            \"content-encoding\": \"gzip\",\n            \"content-type\": \"application/json; charset=utf-8\",\n            \"date\": \"Sat, 26 Jan 2013 16:47:56 GMT\",\n            \"etag\": '\"6ff6a73c0e446c1f61614769e3ceb778\"',\n            \"last-modified\": \"Sat, 26 Jan 2013 16:22:39 GMT\",\n            \"link\": (\n                \"<https://api.github.com/users/kennethreitz/repos?\"\n                'page=2&per_page=10>; rel=\"next\", <https://api.github.'\n                \"com/users/kennethreitz/repos?page=7&per_page=10>; \"\n                ' rel=\"last\"'\n            ),\n            \"server\": \"GitHub.com\",\n            \"status\": \"200 OK\",\n            \"vary\": \"Accept\",\n            \"x-content-type-options\": \"nosniff\",\n            \"x-github-media-type\": \"github.beta\",\n            \"x-ratelimit-limit\": \"60\",\n            \"x-ratelimit-remaining\": \"57\",\n        }\n        assert r.links[\"next\"][\"rel\"] == \"next\"\n\n    def test_cookie_parameters(self):\n        key = \"some_cookie\"\n        value = \"some_value\"\n        secure = True\n        domain = \"test.com\"\n        rest = {\"HttpOnly\": True}\n\n        jar = requests.cookies.RequestsCookieJar()\n        jar.set(key, value, secure=secure, domain=domain, rest=rest)\n\n        assert len(jar) == 1\n        assert \"some_cookie\" in jar\n\n        cookie = list(jar)[0]\n        assert cookie.secure == secure\n        assert cookie.domain == domain\n        assert cookie._rest[\"HttpOnly\"] == rest[\"HttpOnly\"]\n\n    def test_cookie_as_dict_keeps_len(self):\n        key = \"some_cookie\"\n        value = \"some_value\"\n\n        key1 = \"som"}, {"start_line": 43000, "end_line": 45000, "belongs_to": {"file_name": "test_requests.py", "upper_path": "/data2/raymone/swebench-repos/requests/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "ook})\n        prep = req.prepare()\n\n        s = requests.Session()\n        s.proxies = getproxies()\n        resp = s.send(prep)\n\n        assert hasattr(resp, \"hook_working\")\n\n    def test_prepared_from_session(self, httpbin):\n        class DummyAuth(requests.auth.AuthBase):\n            def __call__(self, r):\n                r.headers[\"Dummy-Auth-Test\"] = \"dummy-auth-test-ok\"\n                return r\n\n        req = requests.Request(\"GET\", httpbin(\"headers\"))\n        assert not req.auth\n\n        s = requests.Session()\n        s.auth = DummyAuth()\n\n        prep = s.prepare_request(req)\n        resp = s.send(prep)\n\n        assert resp.json()[\"headers\"][\"Dummy-Auth-Test\"] == \"dummy-auth-test-ok\"\n\n    def test_prepare_request_with_bytestring_url(self):\n        req = requests.Request(\"GET\", b\"https://httpbin.org/\")\n        s = requests.Session()\n        prep = s.prepare_request(req)\n        assert prep.url == \"https://httpbin.org/\"\n\n    def test_request_with_bytestring_host(self, httpbin):\n        s = requests.Session()\n        resp = s.request(\n            \"GET\",\n            httpbin(\"cookies/set?cookie=value\"),\n            allow_redirects=False,\n            headers={\"Host\": b\"httpbin.org\"},\n        )\n        assert resp.cookies.get(\"cookie\") == \"value\"\n\n    def test_links(self):\n        r = requests.Response()\n        r.headers = {\n            \"cache-control\": \"public, max-age=60, s-maxage=60\",\n            \"connection\": \"keep-alive\",\n            \"content-encoding\": \"gzip\",\n            \"content-type\": \"application/json; charset=utf-8\",\n            \"date\": \"Sat, 26 Jan 2013 16:47:56 GMT\",\n            \"etag\": '\"6ff6a73c0e446c1f61614769e3ceb778\"',\n            \"last-modified\": \"Sat, 26 Jan 2013 16:22:39 GMT\",\n            \"link\": (\n                \"<https://api.github.com/users/kennethreitz/repos?\"\n                'page=2&per_page=10>; rel=\"next\", <https://api.github.'\n                \"com/users/kennethreitz/repos?page=7&per_page=10>; \"\n                ' rel=\"last\"'\n           "}, {"start_line": 0, "end_line": 2000, "belongs_to": {"file_name": "api.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "\"\"\"\nrequests.api\n~~~~~~~~~~~~\n\nThis module implements the Requests API.\n\n:copyright: (c) 2012 by Kenneth Reitz.\n:license: Apache2, see LICENSE for more details.\n\"\"\"\n\nfrom . import sessions\n\n\ndef request(method, url, **kwargs):\n    \"\"\"Constructs and sends a :class:`Request <Request>`.\n\n    :param method: method for the new :class:`Request` object: ``GET``, ``OPTIONS``, ``HEAD``, ``POST``, ``PUT``, ``PATCH``, or ``DELETE``.\n    :param url: URL for the new :class:`Request` object.\n    :param params: (optional) Dictionary, list of tuples or bytes to send\n        in the query string for the :class:`Request`.\n    :param data: (optional) Dictionary, list of tuples, bytes, or file-like\n        object to send in the body of the :class:`Request`.\n    :param json: (optional) A JSON serializable Python object to send in the body of the :class:`Request`.\n    :param headers: (optional) Dictionary of HTTP Headers to send with the :class:`Request`.\n    :param cookies: (optional) Dict or CookieJar object to send with the :class:`Request`.\n    :param files: (optional) Dictionary of ``'name': file-like-objects`` (or ``{'name': file-tuple}``) for multipart encoding upload.\n        ``file-tuple`` can be a 2-tuple ``('filename', fileobj)``, 3-tuple ``('filename', fileobj, 'content_type')``\n        or a 4-tuple ``('filename', fileobj, 'content_type', custom_headers)``, where ``'content_type'`` is a string\n        defining the content type of the given file and ``custom_headers`` a dict-like object containing additional headers\n        to add for the file.\n    :param auth: (optional) Auth tuple to enable Basic/Digest/Custom HTTP Auth.\n    :param timeout: (optional) How many seconds to wait for the server to send data\n        before giving up, as a float, or a :ref:`(connect timeout, read\n        timeout) <timeouts>` tuple.\n    :type timeout: float or tuple\n    :param allow_redirects: (optional) Boolean. Enable/disable GET/OPTIONS/POST/PUT/PATCH/DELETE/HEAD redirection. Defaults to ``True``"}, {"start_line": 2000, "end_line": 4000, "belongs_to": {"file_name": "test_requests.py", "upper_path": "/data2/raymone/swebench-repos/requests/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": " requests.session\n        requests.session().get\n        requests.session().head\n        requests.get\n        requests.head\n        requests.put\n        requests.patch\n        requests.post\n        # Not really an entry point, but people rely on it.\n        from requests.packages.urllib3.poolmanager import PoolManager  # noqa:F401\n\n    @pytest.mark.parametrize(\n        \"exception, url\",\n        (\n            (MissingSchema, \"hiwpefhipowhefopw\"),\n            (InvalidSchema, \"localhost:3128\"),\n            (InvalidSchema, \"localhost.localdomain:3128/\"),\n            (InvalidSchema, \"10.122.1.1:3128/\"),\n            (InvalidURL, \"http://\"),\n            (InvalidURL, \"http://*example.com\"),\n            (InvalidURL, \"http://.example.com\"),\n        ),\n    )\n    def test_invalid_url(self, exception, url):\n        with pytest.raises(exception):\n            requests.get(url)\n\n    def test_basic_building(self):\n        req = requests.Request()\n        req.url = \"http://kennethreitz.org/\"\n        req.data = {\"life\": \"42\"}\n\n        pr = req.prepare()\n        assert pr.url == req.url\n        assert pr.body == \"life=42\"\n\n    @pytest.mark.parametrize(\"method\", (\"GET\", \"HEAD\"))\n    def test_no_content_length(self, httpbin, method):\n        req = requests.Request(method, httpbin(method.lower())).prepare()\n        assert \"Content-Length\" not in req.headers\n\n    @pytest.mark.parametrize(\"method\", (\"POST\", \"PUT\", \"PATCH\", \"OPTIONS\"))\n    def test_no_body_content_length(self, httpbin, method):\n        req = requests.Request(method, httpbin(method.lower())).prepare()\n        assert req.headers[\"Content-Length\"] == \"0\"\n\n    @pytest.mark.parametrize(\"method\", (\"POST\", \"PUT\", \"PATCH\", \"OPTIONS\"))\n    def test_empty_content_length(self, httpbin, method):\n        req = requests.Request(method, httpbin(method.lower()), data=\"\").prepare()\n        assert req.headers[\"Content-Length\"] == \"0\"\n\n    def test_override_content_length(self, httpbin):\n        headers = {\"Content-Length\": \"not zero\"}\n       "}, {"start_line": 14000, "end_line": 16000, "belongs_to": {"file_name": "sessions.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "ry of headers to be sent on each\n        #: :class:`Request <Request>` sent from this\n        #: :class:`Session <Session>`.\n        self.headers = default_headers()\n\n        #: Default Authentication tuple or object to attach to\n        #: :class:`Request <Request>`.\n        self.auth = None\n\n        #: Dictionary mapping protocol or protocol and host to the URL of the proxy\n        #: (e.g. {'http': 'foo.bar:3128', 'http://host.name': 'foo.bar:4012'}) to\n        #: be used on each :class:`Request <Request>`.\n        self.proxies = {}\n\n        #: Event-handling hooks.\n        self.hooks = default_hooks()\n\n        #: Dictionary of querystring data to attach to each\n        #: :class:`Request <Request>`. The dictionary values may be lists for\n        #: representing multivalued query parameters.\n        self.params = {}\n\n        #: Stream response content default.\n        self.stream = False\n\n        #: SSL Verification default.\n        #: Defaults to `True`, requiring requests to verify the TLS certificate at the\n        #: remote end.\n        #: If verify is set to `False`, requests will accept any TLS certificate\n        #: presented by the server, and will ignore hostname mismatches and/or\n        #: expired certificates, which will make your application vulnerable to\n        #: man-in-the-middle (MitM) attacks.\n        #: Only set this to `False` for testing.\n        self.verify = True\n\n        #: SSL client certificate default, if String, path to ssl client\n        #: cert file (.pem). If Tuple, ('cert', 'key') pair.\n        self.cert = None\n\n        #: Maximum number of redirects allowed. If the request exceeds this\n        #: limit, a :class:`TooManyRedirects` exception is raised.\n        #: This defaults to requests.models.DEFAULT_REDIRECT_LIMIT, which is\n        #: 30.\n        self.max_redirects = DEFAULT_REDIRECT_LIMIT\n\n        #: Trust environment settings for proxy configuration, default\n        #: authentication and similar.\n        self.trust_env = Tru"}, {"start_line": 14000, "end_line": 16000, "belongs_to": {"file_name": "test_requests.py", "upper_path": "/data2/raymone/swebench-repos/requests/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "   def test_cookie_persists_via_api(self, httpbin):\n        s = requests.session()\n        r = s.get(httpbin(\"redirect/1\"), cookies={\"foo\": \"bar\"})\n        assert \"foo\" in r.request.headers[\"Cookie\"]\n        assert \"foo\" in r.history[0].request.headers[\"Cookie\"]\n\n    def test_request_cookie_overrides_session_cookie(self, httpbin):\n        s = requests.session()\n        s.cookies[\"foo\"] = \"bar\"\n        r = s.get(httpbin(\"cookies\"), cookies={\"foo\": \"baz\"})\n        assert r.json()[\"cookies\"][\"foo\"] == \"baz\"\n        # Session cookie should not be modified\n        assert s.cookies[\"foo\"] == \"bar\"\n\n    def test_request_cookies_not_persisted(self, httpbin):\n        s = requests.session()\n        s.get(httpbin(\"cookies\"), cookies={\"foo\": \"baz\"})\n        # Sending a request with cookies should not add cookies to the session\n        assert not s.cookies\n\n    def test_generic_cookiejar_works(self, httpbin):\n        cj = cookielib.CookieJar()\n        cookiejar_from_dict({\"foo\": \"bar\"}, cj)\n        s = requests.session()\n        s.cookies = cj\n        r = s.get(httpbin(\"cookies\"))\n        # Make sure the cookie was sent\n        assert r.json()[\"cookies\"][\"foo\"] == \"bar\"\n        # Make sure the session cj is still the custom one\n        assert s.cookies is cj\n\n    def test_param_cookiejar_works(self, httpbin):\n        cj = cookielib.CookieJar()\n        cookiejar_from_dict({\"foo\": \"bar\"}, cj)\n        s = requests.session()\n        r = s.get(httpbin(\"cookies\"), cookies=cj)\n        # Make sure the cookie was sent\n        assert r.json()[\"cookies\"][\"foo\"] == \"bar\"\n\n    def test_cookielib_cookiejar_on_redirect(self, httpbin):\n        \"\"\"Tests resolve_redirect doesn't fail when merging cookies\n        with non-RequestsCookieJar cookiejar.\n\n        See GH #3579\n        \"\"\"\n        cj = cookiejar_from_dict({\"foo\": \"bar\"}, cookielib.CookieJar())\n        s = requests.Session()\n        s.cookies = cookiejar_from_dict({\"cookie\": \"tasty\"})\n\n        # Prepare request without using Session\n    "}], "retrieved_count": 10, "cost_time": 4.103506088256836}
{"question": "Why does Requests implement a unified interface for different HTTP methods instead of separate classes?", "answer": null, "relative_code_list": null, "ground_truth": "Requests implements a unified interface for HTTP methods for several design and usability reasons: 1) API simplicity - Provides a consistent, easy-to-learn interface where all HTTP methods follow the same pattern (requests.get(), requests.post(), etc.); 2) Code reuse - Common functionality (authentication, cookies, headers, error handling) is shared across all HTTP methods, reducing code duplication; 3) Session compatibility - All methods work seamlessly with Session objects, maintaining consistent behavior and state management; 4) Parameter consistency - All methods accept the same parameter set (headers, cookies, auth, timeout, etc.), providing a predictable interface; 5) Flexibility - Users can easily switch between HTTP methods without learning different APIs or patterns; 6) Maintainability - Changes to common functionality (e.g., error handling, authentication) only need to be implemented once; 7) Testing - Unified interface simplifies testing and mocking across different HTTP methods; 8) Documentation - Single interface reduces documentation complexity and improves user experience; 9) Extensibility - New HTTP methods can be added easily by following the established pattern; 10) Backward compatibility - Changes to the interface affect all methods consistently, reducing compatibility issues.", "score": null, "retrieved_content": [{"start_line": 22000, "end_line": 24000, "belongs_to": {"file_name": "sessions.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "for the new :class:`Request` object.\n        :param \\*\\*kwargs: Optional arguments that ``request`` takes.\n        :rtype: requests.Response\n        \"\"\"\n\n        kwargs.setdefault(\"allow_redirects\", True)\n        return self.request(\"GET\", url, **kwargs)\n\n    def options(self, url, **kwargs):\n        r\"\"\"Sends a OPTIONS request. Returns :class:`Response` object.\n\n        :param url: URL for the new :class:`Request` object.\n        :param \\*\\*kwargs: Optional arguments that ``request`` takes.\n        :rtype: requests.Response\n        \"\"\"\n\n        kwargs.setdefault(\"allow_redirects\", True)\n        return self.request(\"OPTIONS\", url, **kwargs)\n\n    def head(self, url, **kwargs):\n        r\"\"\"Sends a HEAD request. Returns :class:`Response` object.\n\n        :param url: URL for the new :class:`Request` object.\n        :param \\*\\*kwargs: Optional arguments that ``request`` takes.\n        :rtype: requests.Response\n        \"\"\"\n\n        kwargs.setdefault(\"allow_redirects\", False)\n        return self.request(\"HEAD\", url, **kwargs)\n\n    def post(self, url, data=None, json=None, **kwargs):\n        r\"\"\"Sends a POST request. Returns :class:`Response` object.\n\n        :param url: URL for the new :class:`Request` object.\n        :param data: (optional) Dictionary, list of tuples, bytes, or file-like\n            object to send in the body of the :class:`Request`.\n        :param json: (optional) json to send in the body of the :class:`Request`.\n        :param \\*\\*kwargs: Optional arguments that ``request`` takes.\n        :rtype: requests.Response\n        \"\"\"\n\n        return self.request(\"POST\", url, data=data, json=json, **kwargs)\n\n    def put(self, url, data=None, **kwargs):\n        r\"\"\"Sends a PUT request. Returns :class:`Response` object.\n\n        :param url: URL for the new :class:`Request` object.\n        :param data: (optional) Dictionary, list of tuples, bytes, or file-like\n            object to send in the body of the :class:`Request`.\n        :param \\*\\*kwargs: Optional argume"}, {"start_line": 2000, "end_line": 4000, "belongs_to": {"file_name": "api.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": ".\n    :type allow_redirects: bool\n    :param proxies: (optional) Dictionary mapping protocol to the URL of the proxy.\n    :param verify: (optional) Either a boolean, in which case it controls whether we verify\n            the server's TLS certificate, or a string, in which case it must be a path\n            to a CA bundle to use. Defaults to ``True``.\n    :param stream: (optional) if ``False``, the response content will be immediately downloaded.\n    :param cert: (optional) if String, path to ssl client cert file (.pem). If Tuple, ('cert', 'key') pair.\n    :return: :class:`Response <Response>` object\n    :rtype: requests.Response\n\n    Usage::\n\n      >>> import requests\n      >>> req = requests.request('GET', 'https://httpbin.org/get')\n      >>> req\n      <Response [200]>\n    \"\"\"\n\n    # By using the 'with' statement we are sure the session is closed, thus we\n    # avoid leaving sockets open which can trigger a ResourceWarning in some\n    # cases, and look like a memory leak in others.\n    with sessions.Session() as session:\n        return session.request(method=method, url=url, **kwargs)\n\n\ndef get(url, params=None, **kwargs):\n    r\"\"\"Sends a GET request.\n\n    :param url: URL for the new :class:`Request` object.\n    :param params: (optional) Dictionary, list of tuples or bytes to send\n        in the query string for the :class:`Request`.\n    :param \\*\\*kwargs: Optional arguments that ``request`` takes.\n    :return: :class:`Response <Response>` object\n    :rtype: requests.Response\n    \"\"\"\n\n    return request(\"get\", url, params=params, **kwargs)\n\n\ndef options(url, **kwargs):\n    r\"\"\"Sends an OPTIONS request.\n\n    :param url: URL for the new :class:`Request` object.\n    :param \\*\\*kwargs: Optional arguments that ``request`` takes.\n    :return: :class:`Response <Response>` object\n    :rtype: requests.Response\n    \"\"\"\n\n    return request(\"options\", url, **kwargs)\n\n\ndef head(url, **kwargs):\n    r\"\"\"Sends a HEAD request.\n\n    :param url: URL for the new :class:`Request` obje"}, {"start_line": 3000, "end_line": 5000, "belongs_to": {"file_name": "api.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "   with sessions.Session() as session:\n        return session.request(method=method, url=url, **kwargs)\n\n\ndef get(url, params=None, **kwargs):\n    r\"\"\"Sends a GET request.\n\n    :param url: URL for the new :class:`Request` object.\n    :param params: (optional) Dictionary, list of tuples or bytes to send\n        in the query string for the :class:`Request`.\n    :param \\*\\*kwargs: Optional arguments that ``request`` takes.\n    :return: :class:`Response <Response>` object\n    :rtype: requests.Response\n    \"\"\"\n\n    return request(\"get\", url, params=params, **kwargs)\n\n\ndef options(url, **kwargs):\n    r\"\"\"Sends an OPTIONS request.\n\n    :param url: URL for the new :class:`Request` object.\n    :param \\*\\*kwargs: Optional arguments that ``request`` takes.\n    :return: :class:`Response <Response>` object\n    :rtype: requests.Response\n    \"\"\"\n\n    return request(\"options\", url, **kwargs)\n\n\ndef head(url, **kwargs):\n    r\"\"\"Sends a HEAD request.\n\n    :param url: URL for the new :class:`Request` object.\n    :param \\*\\*kwargs: Optional arguments that ``request`` takes. If\n        `allow_redirects` is not provided, it will be set to `False` (as\n        opposed to the default :meth:`request` behavior).\n    :return: :class:`Response <Response>` object\n    :rtype: requests.Response\n    \"\"\"\n\n    kwargs.setdefault(\"allow_redirects\", False)\n    return request(\"head\", url, **kwargs)\n\n\ndef post(url, data=None, json=None, **kwargs):\n    r\"\"\"Sends a POST request.\n\n    :param url: URL for the new :class:`Request` object.\n    :param data: (optional) Dictionary, list of tuples, bytes, or file-like\n        object to send in the body of the :class:`Request`.\n    :param json: (optional) A JSON serializable Python object to send in the body of the :class:`Request`.\n    :param \\*\\*kwargs: Optional arguments that ``request`` takes.\n    :return: :class:`Response <Response>` object\n    :rtype: requests.Response\n    \"\"\"\n\n    return request(\"post\", url, data=data, json=json, **kwargs)\n\n\ndef put(url, data="}, {"start_line": 4000, "end_line": 6000, "belongs_to": {"file_name": "api.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "ct.\n    :param \\*\\*kwargs: Optional arguments that ``request`` takes. If\n        `allow_redirects` is not provided, it will be set to `False` (as\n        opposed to the default :meth:`request` behavior).\n    :return: :class:`Response <Response>` object\n    :rtype: requests.Response\n    \"\"\"\n\n    kwargs.setdefault(\"allow_redirects\", False)\n    return request(\"head\", url, **kwargs)\n\n\ndef post(url, data=None, json=None, **kwargs):\n    r\"\"\"Sends a POST request.\n\n    :param url: URL for the new :class:`Request` object.\n    :param data: (optional) Dictionary, list of tuples, bytes, or file-like\n        object to send in the body of the :class:`Request`.\n    :param json: (optional) A JSON serializable Python object to send in the body of the :class:`Request`.\n    :param \\*\\*kwargs: Optional arguments that ``request`` takes.\n    :return: :class:`Response <Response>` object\n    :rtype: requests.Response\n    \"\"\"\n\n    return request(\"post\", url, data=data, json=json, **kwargs)\n\n\ndef put(url, data=None, **kwargs):\n    r\"\"\"Sends a PUT request.\n\n    :param url: URL for the new :class:`Request` object.\n    :param data: (optional) Dictionary, list of tuples, bytes, or file-like\n        object to send in the body of the :class:`Request`.\n    :param json: (optional) A JSON serializable Python object to send in the body of the :class:`Request`.\n    :param \\*\\*kwargs: Optional arguments that ``request`` takes.\n    :return: :class:`Response <Response>` object\n    :rtype: requests.Response\n    \"\"\"\n\n    return request(\"put\", url, data=data, **kwargs)\n\n\ndef patch(url, data=None, **kwargs):\n    r\"\"\"Sends a PATCH request.\n\n    :param url: URL for the new :class:`Request` object.\n    :param data: (optional) Dictionary, list of tuples, bytes, or file-like\n        object to send in the body of the :class:`Request`.\n    :param json: (optional) A JSON serializable Python object to send in the body of the :class:`Request`.\n    :param \\*\\*kwargs: Optional arguments that ``request`` takes.\n    :retur"}, {"start_line": 21000, "end_line": 23000, "belongs_to": {"file_name": "sessions.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "ile (.pem).\n            If Tuple, ('cert', 'key') pair.\n        :rtype: requests.Response\n        \"\"\"\n        # Create the Request.\n        req = Request(\n            method=method.upper(),\n            url=url,\n            headers=headers,\n            files=files,\n            data=data or {},\n            json=json,\n            params=params or {},\n            auth=auth,\n            cookies=cookies,\n            hooks=hooks,\n        )\n        prep = self.prepare_request(req)\n\n        proxies = proxies or {}\n\n        settings = self.merge_environment_settings(\n            prep.url, proxies, stream, verify, cert\n        )\n\n        # Send the request.\n        send_kwargs = {\n            \"timeout\": timeout,\n            \"allow_redirects\": allow_redirects,\n        }\n        send_kwargs.update(settings)\n        resp = self.send(prep, **send_kwargs)\n\n        return resp\n\n    def get(self, url, **kwargs):\n        r\"\"\"Sends a GET request. Returns :class:`Response` object.\n\n        :param url: URL for the new :class:`Request` object.\n        :param \\*\\*kwargs: Optional arguments that ``request`` takes.\n        :rtype: requests.Response\n        \"\"\"\n\n        kwargs.setdefault(\"allow_redirects\", True)\n        return self.request(\"GET\", url, **kwargs)\n\n    def options(self, url, **kwargs):\n        r\"\"\"Sends a OPTIONS request. Returns :class:`Response` object.\n\n        :param url: URL for the new :class:`Request` object.\n        :param \\*\\*kwargs: Optional arguments that ``request`` takes.\n        :rtype: requests.Response\n        \"\"\"\n\n        kwargs.setdefault(\"allow_redirects\", True)\n        return self.request(\"OPTIONS\", url, **kwargs)\n\n    def head(self, url, **kwargs):\n        r\"\"\"Sends a HEAD request. Returns :class:`Response` object.\n\n        :param url: URL for the new :class:`Request` object.\n        :param \\*\\*kwargs: Optional arguments that ``request`` takes.\n        :rtype: requests.Response\n        \"\"\"\n\n        kwargs.setdefault(\"allow_redirects\", False)\n        return s"}, {"start_line": 24000, "end_line": 26000, "belongs_to": {"file_name": "sessions.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "nts that ``request`` takes.\n        :rtype: requests.Response\n        \"\"\"\n\n        return self.request(\"PUT\", url, data=data, **kwargs)\n\n    def patch(self, url, data=None, **kwargs):\n        r\"\"\"Sends a PATCH request. Returns :class:`Response` object.\n\n        :param url: URL for the new :class:`Request` object.\n        :param data: (optional) Dictionary, list of tuples, bytes, or file-like\n            object to send in the body of the :class:`Request`.\n        :param \\*\\*kwargs: Optional arguments that ``request`` takes.\n        :rtype: requests.Response\n        \"\"\"\n\n        return self.request(\"PATCH\", url, data=data, **kwargs)\n\n    def delete(self, url, **kwargs):\n        r\"\"\"Sends a DELETE request. Returns :class:`Response` object.\n\n        :param url: URL for the new :class:`Request` object.\n        :param \\*\\*kwargs: Optional arguments that ``request`` takes.\n        :rtype: requests.Response\n        \"\"\"\n\n        return self.request(\"DELETE\", url, **kwargs)\n\n    def send(self, request, **kwargs):\n        \"\"\"Send a given PreparedRequest.\n\n        :rtype: requests.Response\n        \"\"\"\n        # Set defaults that the hooks can utilize to ensure they always have\n        # the correct parameters to reproduce the previous request.\n        kwargs.setdefault(\"stream\", self.stream)\n        kwargs.setdefault(\"verify\", self.verify)\n        kwargs.setdefault(\"cert\", self.cert)\n        if \"proxies\" not in kwargs:\n            kwargs[\"proxies\"] = resolve_proxies(request, self.proxies, self.trust_env)\n\n        # It's possible that users might accidentally send a Request object.\n        # Guard against that specific failure case.\n        if isinstance(request, Request):\n            raise ValueError(\"You can only send PreparedRequests.\")\n\n        # Set up variables needed for resolve_redirects and dispatching of hooks\n        allow_redirects = kwargs.pop(\"allow_redirects\", True)\n        stream = kwargs.get(\"stream\")\n        hooks = request.hooks\n\n        # Get the appropriate "}, {"start_line": 13000, "end_line": 15000, "belongs_to": {"file_name": "sessions.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "POST is responded to with a 301, turn it into a GET.\n        # This bizarre behaviour is explained in Issue 1704.\n        if response.status_code == codes.moved and method == \"POST\":\n            method = \"GET\"\n\n        prepared_request.method = method\n\n\nclass Session(SessionRedirectMixin):\n    \"\"\"A Requests session.\n\n    Provides cookie persistence, connection-pooling, and configuration.\n\n    Basic Usage::\n\n      >>> import requests\n      >>> s = requests.Session()\n      >>> s.get('https://httpbin.org/get')\n      <Response [200]>\n\n    Or as a context manager::\n\n      >>> with requests.Session() as s:\n      ...     s.get('https://httpbin.org/get')\n      <Response [200]>\n    \"\"\"\n\n    __attrs__ = [\n        \"headers\",\n        \"cookies\",\n        \"auth\",\n        \"proxies\",\n        \"hooks\",\n        \"params\",\n        \"verify\",\n        \"cert\",\n        \"adapters\",\n        \"stream\",\n        \"trust_env\",\n        \"max_redirects\",\n    ]\n\n    def __init__(self):\n        #: A case-insensitive dictionary of headers to be sent on each\n        #: :class:`Request <Request>` sent from this\n        #: :class:`Session <Session>`.\n        self.headers = default_headers()\n\n        #: Default Authentication tuple or object to attach to\n        #: :class:`Request <Request>`.\n        self.auth = None\n\n        #: Dictionary mapping protocol or protocol and host to the URL of the proxy\n        #: (e.g. {'http': 'foo.bar:3128', 'http://host.name': 'foo.bar:4012'}) to\n        #: be used on each :class:`Request <Request>`.\n        self.proxies = {}\n\n        #: Event-handling hooks.\n        self.hooks = default_hooks()\n\n        #: Dictionary of querystring data to attach to each\n        #: :class:`Request <Request>`. The dictionary values may be lists for\n        #: representing multivalued query parameters.\n        self.params = {}\n\n        #: Stream response content default.\n        self.stream = False\n\n        #: SSL Verification default.\n        #: Defaults to `True`, requiring requests to verif"}, {"start_line": 0, "end_line": 2000, "belongs_to": {"file_name": "api.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "\"\"\"\nrequests.api\n~~~~~~~~~~~~\n\nThis module implements the Requests API.\n\n:copyright: (c) 2012 by Kenneth Reitz.\n:license: Apache2, see LICENSE for more details.\n\"\"\"\n\nfrom . import sessions\n\n\ndef request(method, url, **kwargs):\n    \"\"\"Constructs and sends a :class:`Request <Request>`.\n\n    :param method: method for the new :class:`Request` object: ``GET``, ``OPTIONS``, ``HEAD``, ``POST``, ``PUT``, ``PATCH``, or ``DELETE``.\n    :param url: URL for the new :class:`Request` object.\n    :param params: (optional) Dictionary, list of tuples or bytes to send\n        in the query string for the :class:`Request`.\n    :param data: (optional) Dictionary, list of tuples, bytes, or file-like\n        object to send in the body of the :class:`Request`.\n    :param json: (optional) A JSON serializable Python object to send in the body of the :class:`Request`.\n    :param headers: (optional) Dictionary of HTTP Headers to send with the :class:`Request`.\n    :param cookies: (optional) Dict or CookieJar object to send with the :class:`Request`.\n    :param files: (optional) Dictionary of ``'name': file-like-objects`` (or ``{'name': file-tuple}``) for multipart encoding upload.\n        ``file-tuple`` can be a 2-tuple ``('filename', fileobj)``, 3-tuple ``('filename', fileobj, 'content_type')``\n        or a 4-tuple ``('filename', fileobj, 'content_type', custom_headers)``, where ``'content_type'`` is a string\n        defining the content type of the given file and ``custom_headers`` a dict-like object containing additional headers\n        to add for the file.\n    :param auth: (optional) Auth tuple to enable Basic/Digest/Custom HTTP Auth.\n    :param timeout: (optional) How many seconds to wait for the server to send data\n        before giving up, as a float, or a :ref:`(connect timeout, read\n        timeout) <timeouts>` tuple.\n    :type timeout: float or tuple\n    :param allow_redirects: (optional) Boolean. Enable/disable GET/OPTIONS/POST/PUT/PATCH/DELETE/HEAD redirection. Defaults to ``True``"}, {"start_line": 23000, "end_line": 25000, "belongs_to": {"file_name": "sessions.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "elf.request(\"HEAD\", url, **kwargs)\n\n    def post(self, url, data=None, json=None, **kwargs):\n        r\"\"\"Sends a POST request. Returns :class:`Response` object.\n\n        :param url: URL for the new :class:`Request` object.\n        :param data: (optional) Dictionary, list of tuples, bytes, or file-like\n            object to send in the body of the :class:`Request`.\n        :param json: (optional) json to send in the body of the :class:`Request`.\n        :param \\*\\*kwargs: Optional arguments that ``request`` takes.\n        :rtype: requests.Response\n        \"\"\"\n\n        return self.request(\"POST\", url, data=data, json=json, **kwargs)\n\n    def put(self, url, data=None, **kwargs):\n        r\"\"\"Sends a PUT request. Returns :class:`Response` object.\n\n        :param url: URL for the new :class:`Request` object.\n        :param data: (optional) Dictionary, list of tuples, bytes, or file-like\n            object to send in the body of the :class:`Request`.\n        :param \\*\\*kwargs: Optional arguments that ``request`` takes.\n        :rtype: requests.Response\n        \"\"\"\n\n        return self.request(\"PUT\", url, data=data, **kwargs)\n\n    def patch(self, url, data=None, **kwargs):\n        r\"\"\"Sends a PATCH request. Returns :class:`Response` object.\n\n        :param url: URL for the new :class:`Request` object.\n        :param data: (optional) Dictionary, list of tuples, bytes, or file-like\n            object to send in the body of the :class:`Request`.\n        :param \\*\\*kwargs: Optional arguments that ``request`` takes.\n        :rtype: requests.Response\n        \"\"\"\n\n        return self.request(\"PATCH\", url, data=data, **kwargs)\n\n    def delete(self, url, **kwargs):\n        r\"\"\"Sends a DELETE request. Returns :class:`Response` object.\n\n        :param url: URL for the new :class:`Request` object.\n        :param \\*\\*kwargs: Optional arguments that ``request`` takes.\n        :rtype: requests.Response\n        \"\"\"\n\n        return self.request(\"DELETE\", url, **kwargs)\n\n    def send(self, r"}, {"start_line": 20000, "end_line": 22000, "belongs_to": {"file_name": "sessions.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "ol or protocol and\n            hostname to the URL of the proxy.\n        :param hooks: (optional) Dictionary mapping hook name to one event or\n            list of events, event must be callable.\n        :param stream: (optional) whether to immediately download the response\n            content. Defaults to ``False``.\n        :param verify: (optional) Either a boolean, in which case it controls whether we verify\n            the server's TLS certificate, or a string, in which case it must be a path\n            to a CA bundle to use. Defaults to ``True``. When set to\n            ``False``, requests will accept any TLS certificate presented by\n            the server, and will ignore hostname mismatches and/or expired\n            certificates, which will make your application vulnerable to\n            man-in-the-middle (MitM) attacks. Setting verify to ``False``\n            may be useful during local development or testing.\n        :param cert: (optional) if String, path to ssl client cert file (.pem).\n            If Tuple, ('cert', 'key') pair.\n        :rtype: requests.Response\n        \"\"\"\n        # Create the Request.\n        req = Request(\n            method=method.upper(),\n            url=url,\n            headers=headers,\n            files=files,\n            data=data or {},\n            json=json,\n            params=params or {},\n            auth=auth,\n            cookies=cookies,\n            hooks=hooks,\n        )\n        prep = self.prepare_request(req)\n\n        proxies = proxies or {}\n\n        settings = self.merge_environment_settings(\n            prep.url, proxies, stream, verify, cert\n        )\n\n        # Send the request.\n        send_kwargs = {\n            \"timeout\": timeout,\n            \"allow_redirects\": allow_redirects,\n        }\n        send_kwargs.update(settings)\n        resp = self.send(prep, **send_kwargs)\n\n        return resp\n\n    def get(self, url, **kwargs):\n        r\"\"\"Sends a GET request. Returns :class:`Response` object.\n\n        :param url: URL "}], "retrieved_count": 10, "cost_time": 4.22409725189209}
{"question": "Why does Requests use an adapter pattern for transport abstraction instead of direct HTTP library integration?", "answer": null, "relative_code_list": null, "ground_truth": "Requests uses the adapter pattern for transport abstraction to achieve several important architectural goals: 1) Decoupling - Separates HTTP client logic from transport implementation details, making the codebase more maintainable and testable; 2) Flexibility - Allows different transport implementations (urllib3, custom libraries) to be used without changing the core Requests API; 3) Protocol support - Enables support for different protocols (HTTP, HTTPS, FTP, custom protocols) through different adapter implementations; 4) Configuration isolation - Each adapter can have its own configuration (pool sizes, retry policies, timeouts) independent of the main Requests interface; 5) Error handling consistency - Provides a unified error handling interface regardless of the underlying transport mechanism; 6) Testing - Enables easy mocking and testing of transport behavior without requiring actual network connections; 7) Extensibility - Users can implement custom adapters for specialized transport needs (e.g., custom protocols, proxy handling); 8) Performance optimization - Different adapters can be optimized for specific use cases or protocols; 9) Dependency management - Reduces tight coupling to specific transport libraries, making dependency management easier; 10) Future-proofing - Allows Requests to adapt to new transport technologies or requirements without major architectural changes.", "score": null, "retrieved_content": [{"start_line": 3000, "end_line": 5000, "belongs_to": {"file_name": "adapters.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "     \"host\": parsed_request_url.hostname,\n        \"port\": port,\n    }\n    return host_params, pool_kwargs\n\n\nclass BaseAdapter:\n    \"\"\"The Base Transport Adapter\"\"\"\n\n    def __init__(self):\n        super().__init__()\n\n    def send(\n        self, request, stream=False, timeout=None, verify=True, cert=None, proxies=None\n    ):\n        \"\"\"Sends PreparedRequest object. Returns Response object.\n\n        :param request: The :class:`PreparedRequest <PreparedRequest>` being sent.\n        :param stream: (optional) Whether to stream the request content.\n        :param timeout: (optional) How long to wait for the server to send\n            data before giving up, as a float, or a :ref:`(connect timeout,\n            read timeout) <timeouts>` tuple.\n        :type timeout: float or tuple\n        :param verify: (optional) Either a boolean, in which case it controls whether we verify\n            the server's TLS certificate, or a string, in which case it must be a path\n            to a CA bundle to use\n        :param cert: (optional) Any user-provided SSL certificate to be trusted.\n        :param proxies: (optional) The proxies dictionary to apply to the request.\n        \"\"\"\n        raise NotImplementedError\n\n    def close(self):\n        \"\"\"Cleans up adapter specific items.\"\"\"\n        raise NotImplementedError\n\n\nclass HTTPAdapter(BaseAdapter):\n    \"\"\"The built-in HTTP Adapter for urllib3.\n\n    Provides a general-case interface for Requests sessions to contact HTTP and\n    HTTPS urls by implementing the Transport Adapter interface. This class will\n    usually be created by the :class:`Session <Session>` class under the\n    covers.\n\n    :param pool_connections: The number of urllib3 connection pools to cache.\n    :param pool_maxsize: The maximum number of connections to save in the pool.\n    :param max_retries: The maximum number of retries each connection\n        should attempt. Note, this applies only to failed DNS lookups, socket\n        connections and connection timeouts, never to"}, {"start_line": 2000, "end_line": 4000, "belongs_to": {"file_name": "adapters.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "olmanager: \"PoolManager\",\n) -> \"(typing.Dict[str, typing.Any], typing.Dict[str, typing.Any])\":\n    host_params = {}\n    pool_kwargs = {}\n    parsed_request_url = urlparse(request.url)\n    scheme = parsed_request_url.scheme.lower()\n    port = parsed_request_url.port\n\n    cert_reqs = \"CERT_REQUIRED\"\n    if verify is False:\n        cert_reqs = \"CERT_NONE\"\n    elif isinstance(verify, str):\n        if not os.path.isdir(verify):\n            pool_kwargs[\"ca_certs\"] = verify\n        else:\n            pool_kwargs[\"ca_cert_dir\"] = verify\n    pool_kwargs[\"cert_reqs\"] = cert_reqs\n    if client_cert is not None:\n        if isinstance(client_cert, tuple) and len(client_cert) == 2:\n            pool_kwargs[\"cert_file\"] = client_cert[0]\n            pool_kwargs[\"key_file\"] = client_cert[1]\n        else:\n            # According to our docs, we allow users to specify just the client\n            # cert path\n            pool_kwargs[\"cert_file\"] = client_cert\n    host_params = {\n        \"scheme\": scheme,\n        \"host\": parsed_request_url.hostname,\n        \"port\": port,\n    }\n    return host_params, pool_kwargs\n\n\nclass BaseAdapter:\n    \"\"\"The Base Transport Adapter\"\"\"\n\n    def __init__(self):\n        super().__init__()\n\n    def send(\n        self, request, stream=False, timeout=None, verify=True, cert=None, proxies=None\n    ):\n        \"\"\"Sends PreparedRequest object. Returns Response object.\n\n        :param request: The :class:`PreparedRequest <PreparedRequest>` being sent.\n        :param stream: (optional) Whether to stream the request content.\n        :param timeout: (optional) How long to wait for the server to send\n            data before giving up, as a float, or a :ref:`(connect timeout,\n            read timeout) <timeouts>` tuple.\n        :type timeout: float or tuple\n        :param verify: (optional) Either a boolean, in which case it controls whether we verify\n            the server's TLS certificate, or a string, in which case it must be a path\n            to a CA bundle to use\n"}, {"start_line": 21000, "end_line": 23000, "belongs_to": {"file_name": "adapters.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "ters.HTTPAdapter>`.\n\n        This should not be called from user code, and is only exposed for use\n        when subclassing the\n        :class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.\n\n        :param request: The :class:`PreparedRequest <PreparedRequest>` to add headers to.\n        :param kwargs: The keyword arguments from the call to send().\n        \"\"\"\n        pass\n\n    def proxy_headers(self, proxy):\n        \"\"\"Returns a dictionary of the headers to add to any request sent\n        through a proxy. This works with urllib3 magic to ensure that they are\n        correctly sent to the proxy, rather than in a tunnelled request if\n        CONNECT is being used.\n\n        This should not be called from user code, and is only exposed for use\n        when subclassing the\n        :class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.\n\n        :param proxy: The url of the proxy being used for this request.\n        :rtype: dict\n        \"\"\"\n        headers = {}\n        username, password = get_auth_from_url(proxy)\n\n        if username:\n            headers[\"Proxy-Authorization\"] = _basic_auth_str(username, password)\n\n        return headers\n\n    def send(\n        self, request, stream=False, timeout=None, verify=True, cert=None, proxies=None\n    ):\n        \"\"\"Sends PreparedRequest object. Returns Response object.\n\n        :param request: The :class:`PreparedRequest <PreparedRequest>` being sent.\n        :param stream: (optional) Whether to stream the request content.\n        :param timeout: (optional) How long to wait for the server to send\n            data before giving up, as a float, or a :ref:`(connect timeout,\n            read timeout) <timeouts>` tuple.\n        :type timeout: float or tuple or urllib3 Timeout object\n        :param verify: (optional) Either a boolean, in which case it controls whether\n            we verify the server's TLS certificate, or a string, in which case it\n            must be a path to a CA bundle to use\n        :param cert: (optional) Any user"}, {"start_line": 5000, "end_line": 7000, "belongs_to": {"file_name": "adapters.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": " requests where data has\n        made it to the server. By default, Requests does not retry failed\n        connections. If you need granular control over the conditions under\n        which we retry a request, import urllib3's ``Retry`` class and pass\n        that instead.\n    :param pool_block: Whether the connection pool should block for connections.\n\n    Usage::\n\n      >>> import requests\n      >>> s = requests.Session()\n      >>> a = requests.adapters.HTTPAdapter(max_retries=3)\n      >>> s.mount('http://', a)\n    \"\"\"\n\n    __attrs__ = [\n        \"max_retries\",\n        \"config\",\n        \"_pool_connections\",\n        \"_pool_maxsize\",\n        \"_pool_block\",\n    ]\n\n    def __init__(\n        self,\n        pool_connections=DEFAULT_POOLSIZE,\n        pool_maxsize=DEFAULT_POOLSIZE,\n        max_retries=DEFAULT_RETRIES,\n        pool_block=DEFAULT_POOLBLOCK,\n    ):\n        if max_retries == DEFAULT_RETRIES:\n            self.max_retries = Retry(0, read=False)\n        else:\n            self.max_retries = Retry.from_int(max_retries)\n        self.config = {}\n        self.proxy_manager = {}\n\n        super().__init__()\n\n        self._pool_connections = pool_connections\n        self._pool_maxsize = pool_maxsize\n        self._pool_block = pool_block\n\n        self.init_poolmanager(pool_connections, pool_maxsize, block=pool_block)\n\n    def __getstate__(self):\n        return {attr: getattr(self, attr, None) for attr in self.__attrs__}\n\n    def __setstate__(self, state):\n        # Can't handle by adding 'proxy_manager' to self.__attrs__ because\n        # self.poolmanager uses a lambda function, which isn't pickleable.\n        self.proxy_manager = {}\n        self.config = {}\n\n        for attr, value in state.items():\n            setattr(self, attr, value)\n\n        self.init_poolmanager(\n            self._pool_connections, self._pool_maxsize, block=self._pool_block\n        )\n\n    def init_poolmanager(\n        self, connections, maxsize, block=DEFAULT_POOLBLOCK, **pool_kwargs\n    ):\n        \""}, {"start_line": 29000, "end_line": 30503, "belongs_to": {"file_name": "sessions.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "nnection adapter for the given URL.\n\n        :rtype: requests.adapters.BaseAdapter\n        \"\"\"\n        for prefix, adapter in self.adapters.items():\n            if url.lower().startswith(prefix.lower()):\n                return adapter\n\n        # Nothing matches :-/\n        raise InvalidSchema(f\"No connection adapters were found for {url!r}\")\n\n    def close(self):\n        \"\"\"Closes all adapters and as such the session\"\"\"\n        for v in self.adapters.values():\n            v.close()\n\n    def mount(self, prefix, adapter):\n        \"\"\"Registers a connection adapter to a prefix.\n\n        Adapters are sorted in descending order by prefix length.\n        \"\"\"\n        self.adapters[prefix] = adapter\n        keys_to_move = [k for k in self.adapters if len(k) < len(prefix)]\n\n        for key in keys_to_move:\n            self.adapters[key] = self.adapters.pop(key)\n\n    def __getstate__(self):\n        state = {attr: getattr(self, attr, None) for attr in self.__attrs__}\n        return state\n\n    def __setstate__(self, state):\n        for attr, value in state.items():\n            setattr(self, attr, value)\n\n\ndef session():\n    \"\"\"\n    Returns a :class:`Session` for context-management.\n\n    .. deprecated:: 1.0.0\n\n        This method has been deprecated since version 1.0.0 and is only kept for\n        backwards compatibility. New code should use :class:`~requests.sessions.Session`\n        to create a session. This may be removed at a future date.\n\n    :rtype: Session\n    \"\"\"\n    return Session()\n"}, {"start_line": 4000, "end_line": 6000, "belongs_to": {"file_name": "adapters.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "        :param cert: (optional) Any user-provided SSL certificate to be trusted.\n        :param proxies: (optional) The proxies dictionary to apply to the request.\n        \"\"\"\n        raise NotImplementedError\n\n    def close(self):\n        \"\"\"Cleans up adapter specific items.\"\"\"\n        raise NotImplementedError\n\n\nclass HTTPAdapter(BaseAdapter):\n    \"\"\"The built-in HTTP Adapter for urllib3.\n\n    Provides a general-case interface for Requests sessions to contact HTTP and\n    HTTPS urls by implementing the Transport Adapter interface. This class will\n    usually be created by the :class:`Session <Session>` class under the\n    covers.\n\n    :param pool_connections: The number of urllib3 connection pools to cache.\n    :param pool_maxsize: The maximum number of connections to save in the pool.\n    :param max_retries: The maximum number of retries each connection\n        should attempt. Note, this applies only to failed DNS lookups, socket\n        connections and connection timeouts, never to requests where data has\n        made it to the server. By default, Requests does not retry failed\n        connections. If you need granular control over the conditions under\n        which we retry a request, import urllib3's ``Retry`` class and pass\n        that instead.\n    :param pool_block: Whether the connection pool should block for connections.\n\n    Usage::\n\n      >>> import requests\n      >>> s = requests.Session()\n      >>> a = requests.adapters.HTTPAdapter(max_retries=3)\n      >>> s.mount('http://', a)\n    \"\"\"\n\n    __attrs__ = [\n        \"max_retries\",\n        \"config\",\n        \"_pool_connections\",\n        \"_pool_maxsize\",\n        \"_pool_block\",\n    ]\n\n    def __init__(\n        self,\n        pool_connections=DEFAULT_POOLSIZE,\n        pool_maxsize=DEFAULT_POOLSIZE,\n        max_retries=DEFAULT_RETRIES,\n        pool_block=DEFAULT_POOLBLOCK,\n    ):\n        if max_retries == DEFAULT_RETRIES:\n            self.max_retries = Retry(0, read=False)\n        else:\n            self.max_retr"}, {"start_line": 0, "end_line": 2000, "belongs_to": {"file_name": "adapters.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "\"\"\"\nrequests.adapters\n~~~~~~~~~~~~~~~~~\n\nThis module contains the transport adapters that Requests uses to define\nand maintain connections.\n\"\"\"\n\nimport os.path\nimport socket  # noqa: F401\nimport typing\nimport warnings\n\nfrom urllib3.exceptions import ClosedPoolError, ConnectTimeoutError\nfrom urllib3.exceptions import HTTPError as _HTTPError\nfrom urllib3.exceptions import InvalidHeader as _InvalidHeader\nfrom urllib3.exceptions import (\n    LocationValueError,\n    MaxRetryError,\n    NewConnectionError,\n    ProtocolError,\n)\nfrom urllib3.exceptions import ProxyError as _ProxyError\nfrom urllib3.exceptions import ReadTimeoutError, ResponseError\nfrom urllib3.exceptions import SSLError as _SSLError\nfrom urllib3.poolmanager import PoolManager, proxy_from_url\nfrom urllib3.util import Timeout as TimeoutSauce\nfrom urllib3.util import parse_url\nfrom urllib3.util.retry import Retry\n\nfrom .auth import _basic_auth_str\nfrom .compat import basestring, urlparse\nfrom .cookies import extract_cookies_to_jar\nfrom .exceptions import (\n    ConnectionError,\n    ConnectTimeout,\n    InvalidHeader,\n    InvalidProxyURL,\n    InvalidSchema,\n    InvalidURL,\n    ProxyError,\n    ReadTimeout,\n    RetryError,\n    SSLError,\n)\nfrom .models import Response\nfrom .structures import CaseInsensitiveDict\nfrom .utils import (\n    DEFAULT_CA_BUNDLE_PATH,\n    extract_zipped_paths,\n    get_auth_from_url,\n    get_encoding_from_headers,\n    prepend_scheme_if_needed,\n    select_proxy,\n    urldefragauth,\n)\n\ntry:\n    from urllib3.contrib.socks import SOCKSProxyManager\nexcept ImportError:\n\n    def SOCKSProxyManager(*args, **kwargs):\n        raise InvalidSchema(\"Missing dependencies for SOCKS support.\")\n\n\nif typing.TYPE_CHECKING:\n    from .models import PreparedRequest\n\n\nDEFAULT_POOLBLOCK = False\nDEFAULT_POOLSIZE = 10\nDEFAULT_RETRIES = 0\nDEFAULT_POOL_TIMEOUT = None\n\n\ndef _urllib3_request_context(\n    request: \"PreparedRequest\",\n    verify: \"bool | str | None\",\n    client_cert: \"typing.Tuple[str, str] | str | None\",\n    po"}, {"start_line": 28000, "end_line": 30000, "belongs_to": {"file_name": "sessions.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "vironment's proxies.\n            no_proxy = proxies.get(\"no_proxy\") if proxies is not None else None\n            env_proxies = get_environ_proxies(url, no_proxy=no_proxy)\n            for k, v in env_proxies.items():\n                proxies.setdefault(k, v)\n\n            # Look for requests environment configuration\n            # and be compatible with cURL.\n            if verify is True or verify is None:\n                verify = (\n                    os.environ.get(\"REQUESTS_CA_BUNDLE\")\n                    or os.environ.get(\"CURL_CA_BUNDLE\")\n                    or verify\n                )\n\n        # Merge all the kwargs.\n        proxies = merge_setting(proxies, self.proxies)\n        stream = merge_setting(stream, self.stream)\n        verify = merge_setting(verify, self.verify)\n        cert = merge_setting(cert, self.cert)\n\n        return {\"proxies\": proxies, \"stream\": stream, \"verify\": verify, \"cert\": cert}\n\n    def get_adapter(self, url):\n        \"\"\"\n        Returns the appropriate connection adapter for the given URL.\n\n        :rtype: requests.adapters.BaseAdapter\n        \"\"\"\n        for prefix, adapter in self.adapters.items():\n            if url.lower().startswith(prefix.lower()):\n                return adapter\n\n        # Nothing matches :-/\n        raise InvalidSchema(f\"No connection adapters were found for {url!r}\")\n\n    def close(self):\n        \"\"\"Closes all adapters and as such the session\"\"\"\n        for v in self.adapters.values():\n            v.close()\n\n    def mount(self, prefix, adapter):\n        \"\"\"Registers a connection adapter to a prefix.\n\n        Adapters are sorted in descending order by prefix length.\n        \"\"\"\n        self.adapters[prefix] = adapter\n        keys_to_move = [k for k in self.adapters if len(k) < len(prefix)]\n\n        for key in keys_to_move:\n            self.adapters[key] = self.adapters.pop(key)\n\n    def __getstate__(self):\n        state = {attr: getattr(self, attr, None) for attr in self.__attrs__}\n        return state\n\n    def "}, {"start_line": 56000, "end_line": 58000, "belongs_to": {"file_name": "test_requests.py", "upper_path": "/data2/raymone/swebench-repos/requests/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "d(r.prepare())\n        assert r.status_code == 200\n\n    def test_fixes_1329(self, httpbin):\n        \"\"\"Ensure that header updates are done case-insensitively.\"\"\"\n        s = requests.Session()\n        s.headers.update({\"ACCEPT\": \"BOGUS\"})\n        s.headers.update({\"accept\": \"application/json\"})\n        r = s.get(httpbin(\"get\"))\n        headers = r.request.headers\n        assert headers[\"accept\"] == \"application/json\"\n        assert headers[\"Accept\"] == \"application/json\"\n        assert headers[\"ACCEPT\"] == \"application/json\"\n\n    def test_uppercase_scheme_redirect(self, httpbin):\n        parts = urlparse(httpbin(\"html\"))\n        url = \"HTTP://\" + parts.netloc + parts.path\n        r = requests.get(httpbin(\"redirect-to\"), params={\"url\": url})\n        assert r.status_code == 200\n        assert r.url.lower() == url.lower()\n\n    def test_transport_adapter_ordering(self):\n        s = requests.Session()\n        order = [\"https://\", \"http://\"]\n        assert order == list(s.adapters)\n        s.mount(\"http://git\", HTTPAdapter())\n        s.mount(\"http://github\", HTTPAdapter())\n        s.mount(\"http://github.com\", HTTPAdapter())\n        s.mount(\"http://github.com/about/\", HTTPAdapter())\n        order = [\n            \"http://github.com/about/\",\n            \"http://github.com\",\n            \"http://github\",\n            \"http://git\",\n            \"https://\",\n            \"http://\",\n        ]\n        assert order == list(s.adapters)\n        s.mount(\"http://gittip\", HTTPAdapter())\n        s.mount(\"http://gittip.com\", HTTPAdapter())\n        s.mount(\"http://gittip.com/about/\", HTTPAdapter())\n        order = [\n            \"http://github.com/about/\",\n            \"http://gittip.com/about/\",\n            \"http://github.com\",\n            \"http://gittip.com\",\n            \"http://github\",\n            \"http://gittip\",\n            \"http://git\",\n            \"https://\",\n            \"http://\",\n        ]\n        assert order == list(s.adapters)\n        s2 = requests.Session()\n        s2.adapters = {\""}, {"start_line": 58000, "end_line": 60000, "belongs_to": {"file_name": "test_requests.py", "upper_path": "/data2/raymone/swebench-repos/requests/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "http://\": HTTPAdapter()}\n        s2.mount(\"https://\", HTTPAdapter())\n        assert \"http://\" in s2.adapters\n        assert \"https://\" in s2.adapters\n\n    def test_session_get_adapter_prefix_matching(self):\n        prefix = \"https://example.com\"\n        more_specific_prefix = prefix + \"/some/path\"\n\n        url_matching_only_prefix = prefix + \"/another/path\"\n        url_matching_more_specific_prefix = more_specific_prefix + \"/longer/path\"\n        url_not_matching_prefix = \"https://another.example.com/\"\n\n        s = requests.Session()\n        prefix_adapter = HTTPAdapter()\n        more_specific_prefix_adapter = HTTPAdapter()\n        s.mount(prefix, prefix_adapter)\n        s.mount(more_specific_prefix, more_specific_prefix_adapter)\n\n        assert s.get_adapter(url_matching_only_prefix) is prefix_adapter\n        assert (\n            s.get_adapter(url_matching_more_specific_prefix)\n            is more_specific_prefix_adapter\n        )\n        assert s.get_adapter(url_not_matching_prefix) not in (\n            prefix_adapter,\n            more_specific_prefix_adapter,\n        )\n\n    def test_session_get_adapter_prefix_matching_mixed_case(self):\n        mixed_case_prefix = \"hTtPs://eXamPle.CoM/MixEd_CAse_PREfix\"\n        url_matching_prefix = mixed_case_prefix + \"/full_url\"\n\n        s = requests.Session()\n        my_adapter = HTTPAdapter()\n        s.mount(mixed_case_prefix, my_adapter)\n\n        assert s.get_adapter(url_matching_prefix) is my_adapter\n\n    def test_session_get_adapter_prefix_matching_is_case_insensitive(self):\n        mixed_case_prefix = \"hTtPs://eXamPle.CoM/MixEd_CAse_PREfix\"\n        url_matching_prefix_with_different_case = (\n            \"HtTpS://exaMPLe.cOm/MiXeD_caSE_preFIX/another_url\"\n        )\n\n        s = requests.Session()\n        my_adapter = HTTPAdapter()\n        s.mount(mixed_case_prefix, my_adapter)\n\n        assert s.get_adapter(url_matching_prefix_with_different_case) is my_adapter\n\n    def test_session_get_adapter_prefix_with_trailing_slash(self"}], "retrieved_count": 10, "cost_time": 4.307748794555664}
{"question": "Why does Requests implement automatic redirect handling instead of manual redirect management?", "answer": null, "relative_code_list": null, "ground_truth": "Requests implements automatic redirect handling to provide a seamless user experience and handle complex redirect scenarios: 1) User convenience - Eliminates the need for users to manually handle redirects, which is a common and tedious requirement in HTTP clients; 2) Standards compliance - Implements redirect handling according to HTTP standards (RFC 7231) including proper method rewriting and status code handling; 3) Complex logic - Redirect handling involves multiple considerations (method changes, authentication stripping, URL resolution) that are error-prone to implement manually; 4) Security - Automatic handling includes security considerations like authentication stripping when redirecting to different hosts; 5) Performance - Proper redirect handling includes connection management and resource cleanup to prevent resource leaks; 6) History tracking - Maintains a complete history of redirects for debugging and analysis purposes; 7) Configurability - Provides allow_redirects parameter to disable automatic handling when needed; 8) Error prevention - Handles edge cases like infinite redirects, malformed Location headers, and redirect limits; 9) Fragment preservation - Correctly handles URL fragments across redirects as specified in HTTP standards; 10) Integration - Seamlessly integrates with other Requests features like cookies, authentication, and connection pooling.", "score": null, "retrieved_content": [{"start_line": 13000, "end_line": 15000, "belongs_to": {"file_name": "sessions.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "POST is responded to with a 301, turn it into a GET.\n        # This bizarre behaviour is explained in Issue 1704.\n        if response.status_code == codes.moved and method == \"POST\":\n            method = \"GET\"\n\n        prepared_request.method = method\n\n\nclass Session(SessionRedirectMixin):\n    \"\"\"A Requests session.\n\n    Provides cookie persistence, connection-pooling, and configuration.\n\n    Basic Usage::\n\n      >>> import requests\n      >>> s = requests.Session()\n      >>> s.get('https://httpbin.org/get')\n      <Response [200]>\n\n    Or as a context manager::\n\n      >>> with requests.Session() as s:\n      ...     s.get('https://httpbin.org/get')\n      <Response [200]>\n    \"\"\"\n\n    __attrs__ = [\n        \"headers\",\n        \"cookies\",\n        \"auth\",\n        \"proxies\",\n        \"hooks\",\n        \"params\",\n        \"verify\",\n        \"cert\",\n        \"adapters\",\n        \"stream\",\n        \"trust_env\",\n        \"max_redirects\",\n    ]\n\n    def __init__(self):\n        #: A case-insensitive dictionary of headers to be sent on each\n        #: :class:`Request <Request>` sent from this\n        #: :class:`Session <Session>`.\n        self.headers = default_headers()\n\n        #: Default Authentication tuple or object to attach to\n        #: :class:`Request <Request>`.\n        self.auth = None\n\n        #: Dictionary mapping protocol or protocol and host to the URL of the proxy\n        #: (e.g. {'http': 'foo.bar:3128', 'http://host.name': 'foo.bar:4012'}) to\n        #: be used on each :class:`Request <Request>`.\n        self.proxies = {}\n\n        #: Event-handling hooks.\n        self.hooks = default_hooks()\n\n        #: Dictionary of querystring data to attach to each\n        #: :class:`Request <Request>`. The dictionary values may be lists for\n        #: representing multivalued query parameters.\n        self.params = {}\n\n        #: Stream response content default.\n        self.stream = False\n\n        #: SSL Verification default.\n        #: Defaults to `True`, requiring requests to verif"}, {"start_line": 8000, "end_line": 10000, "belongs_to": {"file_name": "test_requests.py", "upper_path": "/data2/raymone/swebench-repos/requests/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "uest.url == url\n            assert e.response.url == url\n            assert len(e.response.history) == 30\n        else:\n            pytest.fail(\"Expected redirect to raise TooManyRedirects but it did not\")\n\n    def test_HTTP_302_TOO_MANY_REDIRECTS_WITH_PARAMS(self, httpbin):\n        s = requests.session()\n        s.max_redirects = 5\n        try:\n            s.get(httpbin(\"relative-redirect\", \"50\"))\n        except TooManyRedirects as e:\n            url = httpbin(\"relative-redirect\", \"45\")\n            assert e.request.url == url\n            assert e.response.url == url\n            assert len(e.response.history) == 5\n        else:\n            pytest.fail(\n                \"Expected custom max number of redirects to be respected but was not\"\n            )\n\n    def test_http_301_changes_post_to_get(self, httpbin):\n        r = requests.post(httpbin(\"status\", \"301\"))\n        assert r.status_code == 200\n        assert r.request.method == \"GET\"\n        assert r.history[0].status_code == 301\n        assert r.history[0].is_redirect\n\n    def test_http_301_doesnt_change_head_to_get(self, httpbin):\n        r = requests.head(httpbin(\"status\", \"301\"), allow_redirects=True)\n        print(r.content)\n        assert r.status_code == 200\n        assert r.request.method == \"HEAD\"\n        assert r.history[0].status_code == 301\n        assert r.history[0].is_redirect\n\n    def test_http_302_changes_post_to_get(self, httpbin):\n        r = requests.post(httpbin(\"status\", \"302\"))\n        assert r.status_code == 200\n        assert r.request.method == \"GET\"\n        assert r.history[0].status_code == 302\n        assert r.history[0].is_redirect\n\n    def test_http_302_doesnt_change_head_to_get(self, httpbin):\n        r = requests.head(httpbin(\"status\", \"302\"), allow_redirects=True)\n        assert r.status_code == 200\n        assert r.request.method == \"HEAD\"\n        assert r.history[0].status_code == 302\n        assert r.history[0].is_redirect\n\n    def test_http_303_changes_post_to_get(self, httpbin"}, {"start_line": 12000, "end_line": 14000, "belongs_to": {"file_name": "sessions.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "          username, password = None, None\n\n        # urllib3 handles proxy authorization for us in the standard adapter.\n        # Avoid appending this to TLS tunneled requests where it may be leaked.\n        if not scheme.startswith(\"https\") and username and password:\n            headers[\"Proxy-Authorization\"] = _basic_auth_str(username, password)\n\n        return new_proxies\n\n    def rebuild_method(self, prepared_request, response):\n        \"\"\"When being redirected we may want to change the method of the request\n        based on certain specs or browser behavior.\n        \"\"\"\n        method = prepared_request.method\n\n        # https://tools.ietf.org/html/rfc7231#section-6.4.4\n        if response.status_code == codes.see_other and method != \"HEAD\":\n            method = \"GET\"\n\n        # Do what the browsers do, despite standards...\n        # First, turn 302s into GETs.\n        if response.status_code == codes.found and method != \"HEAD\":\n            method = \"GET\"\n\n        # Second, if a POST is responded to with a 301, turn it into a GET.\n        # This bizarre behaviour is explained in Issue 1704.\n        if response.status_code == codes.moved and method == \"POST\":\n            method = \"GET\"\n\n        prepared_request.method = method\n\n\nclass Session(SessionRedirectMixin):\n    \"\"\"A Requests session.\n\n    Provides cookie persistence, connection-pooling, and configuration.\n\n    Basic Usage::\n\n      >>> import requests\n      >>> s = requests.Session()\n      >>> s.get('https://httpbin.org/get')\n      <Response [200]>\n\n    Or as a context manager::\n\n      >>> with requests.Session() as s:\n      ...     s.get('https://httpbin.org/get')\n      <Response [200]>\n    \"\"\"\n\n    __attrs__ = [\n        \"headers\",\n        \"cookies\",\n        \"auth\",\n        \"proxies\",\n        \"hooks\",\n        \"params\",\n        \"verify\",\n        \"cert\",\n        \"adapters\",\n        \"stream\",\n        \"trust_env\",\n        \"max_redirects\",\n    ]\n\n    def __init__(self):\n        #: A case-insensitive dictiona"}, {"start_line": 7000, "end_line": 9000, "belongs_to": {"file_name": "test_requests.py", "upper_path": "/data2/raymone/swebench-repos/requests/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "sts.post(\n            httpbin(\"redirect-to\"),\n            data=\"test\",\n            params={\"url\": \"post\", \"status_code\": 307},\n        )\n        assert r.status_code == 200\n        assert r.history[0].status_code == 307\n        assert r.history[0].is_redirect\n        assert r.json()[\"data\"] == \"test\"\n\n    def test_HTTP_307_ALLOW_REDIRECT_POST_WITH_SEEKABLE(self, httpbin):\n        byte_str = b\"test\"\n        r = requests.post(\n            httpbin(\"redirect-to\"),\n            data=io.BytesIO(byte_str),\n            params={\"url\": \"post\", \"status_code\": 307},\n        )\n        assert r.status_code == 200\n        assert r.history[0].status_code == 307\n        assert r.history[0].is_redirect\n        assert r.json()[\"data\"] == byte_str.decode(\"utf-8\")\n\n    def test_HTTP_302_TOO_MANY_REDIRECTS(self, httpbin):\n        try:\n            requests.get(httpbin(\"relative-redirect\", \"50\"))\n        except TooManyRedirects as e:\n            url = httpbin(\"relative-redirect\", \"20\")\n            assert e.request.url == url\n            assert e.response.url == url\n            assert len(e.response.history) == 30\n        else:\n            pytest.fail(\"Expected redirect to raise TooManyRedirects but it did not\")\n\n    def test_HTTP_302_TOO_MANY_REDIRECTS_WITH_PARAMS(self, httpbin):\n        s = requests.session()\n        s.max_redirects = 5\n        try:\n            s.get(httpbin(\"relative-redirect\", \"50\"))\n        except TooManyRedirects as e:\n            url = httpbin(\"relative-redirect\", \"45\")\n            assert e.request.url == url\n            assert e.response.url == url\n            assert len(e.response.history) == 5\n        else:\n            pytest.fail(\n                \"Expected custom max number of redirects to be respected but was not\"\n            )\n\n    def test_http_301_changes_post_to_get(self, httpbin):\n        r = requests.post(httpbin(\"status\", \"301\"))\n        assert r.status_code == 200\n        assert r.request.method == \"GET\"\n        assert r.history[0].status_code == 301\n    "}, {"start_line": 9000, "end_line": 11000, "belongs_to": {"file_name": "test_requests.py", "upper_path": "/data2/raymone/swebench-repos/requests/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "    assert r.history[0].is_redirect\n\n    def test_http_301_doesnt_change_head_to_get(self, httpbin):\n        r = requests.head(httpbin(\"status\", \"301\"), allow_redirects=True)\n        print(r.content)\n        assert r.status_code == 200\n        assert r.request.method == \"HEAD\"\n        assert r.history[0].status_code == 301\n        assert r.history[0].is_redirect\n\n    def test_http_302_changes_post_to_get(self, httpbin):\n        r = requests.post(httpbin(\"status\", \"302\"))\n        assert r.status_code == 200\n        assert r.request.method == \"GET\"\n        assert r.history[0].status_code == 302\n        assert r.history[0].is_redirect\n\n    def test_http_302_doesnt_change_head_to_get(self, httpbin):\n        r = requests.head(httpbin(\"status\", \"302\"), allow_redirects=True)\n        assert r.status_code == 200\n        assert r.request.method == \"HEAD\"\n        assert r.history[0].status_code == 302\n        assert r.history[0].is_redirect\n\n    def test_http_303_changes_post_to_get(self, httpbin):\n        r = requests.post(httpbin(\"status\", \"303\"))\n        assert r.status_code == 200\n        assert r.request.method == \"GET\"\n        assert r.history[0].status_code == 303\n        assert r.history[0].is_redirect\n\n    def test_http_303_doesnt_change_head_to_get(self, httpbin):\n        r = requests.head(httpbin(\"status\", \"303\"), allow_redirects=True)\n        assert r.status_code == 200\n        assert r.request.method == \"HEAD\"\n        assert r.history[0].status_code == 303\n        assert r.history[0].is_redirect\n\n    def test_header_and_body_removal_on_redirect(self, httpbin):\n        purged_headers = (\"Content-Length\", \"Content-Type\")\n        ses = requests.Session()\n        req = requests.Request(\"POST\", httpbin(\"post\"), data={\"test\": \"data\"})\n        prep = ses.prepare_request(req)\n        resp = ses.send(prep)\n\n        # Mimic a redirect response\n        resp.status_code = 302\n        resp.headers[\"location\"] = \"get\"\n\n        # Run request through resolve_redirects\n        nex"}, {"start_line": 10000, "end_line": 12000, "belongs_to": {"file_name": "test_requests.py", "upper_path": "/data2/raymone/swebench-repos/requests/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "):\n        r = requests.post(httpbin(\"status\", \"303\"))\n        assert r.status_code == 200\n        assert r.request.method == \"GET\"\n        assert r.history[0].status_code == 303\n        assert r.history[0].is_redirect\n\n    def test_http_303_doesnt_change_head_to_get(self, httpbin):\n        r = requests.head(httpbin(\"status\", \"303\"), allow_redirects=True)\n        assert r.status_code == 200\n        assert r.request.method == \"HEAD\"\n        assert r.history[0].status_code == 303\n        assert r.history[0].is_redirect\n\n    def test_header_and_body_removal_on_redirect(self, httpbin):\n        purged_headers = (\"Content-Length\", \"Content-Type\")\n        ses = requests.Session()\n        req = requests.Request(\"POST\", httpbin(\"post\"), data={\"test\": \"data\"})\n        prep = ses.prepare_request(req)\n        resp = ses.send(prep)\n\n        # Mimic a redirect response\n        resp.status_code = 302\n        resp.headers[\"location\"] = \"get\"\n\n        # Run request through resolve_redirects\n        next_resp = next(ses.resolve_redirects(resp, prep))\n        assert next_resp.request.body is None\n        for header in purged_headers:\n            assert header not in next_resp.request.headers\n\n    def test_transfer_enc_removal_on_redirect(self, httpbin):\n        purged_headers = (\"Transfer-Encoding\", \"Content-Type\")\n        ses = requests.Session()\n        req = requests.Request(\"POST\", httpbin(\"post\"), data=(b\"x\" for x in range(1)))\n        prep = ses.prepare_request(req)\n        assert \"Transfer-Encoding\" in prep.headers\n\n        # Create Response to avoid https://github.com/kevin1024/pytest-httpbin/issues/33\n        resp = requests.Response()\n        resp.raw = io.BytesIO(b\"the content\")\n        resp.request = prep\n        setattr(resp.raw, \"release_conn\", lambda *args: args)\n\n        # Mimic a redirect response\n        resp.status_code = 302\n        resp.headers[\"location\"] = httpbin(\"get\")\n\n        # Run request through resolve_redirect\n        next_resp = next(ses.resolve_redirec"}, {"start_line": 69000, "end_line": 71000, "belongs_to": {"file_name": "test_requests.py", "upper_path": "/data2/raymone/swebench-repos/requests/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": " \"https://example.com:443/bar\"),\n            (\"http://example.com/foo\", \"http://example.com:80/bar\"),\n        ),\n    )\n    def test_should_strip_auth_default_port(self, old_uri, new_uri):\n        s = requests.Session()\n        assert not s.should_strip_auth(old_uri, new_uri)\n\n    def test_manual_redirect_with_partial_body_read(self, httpbin):\n        s = requests.Session()\n        r1 = s.get(httpbin(\"redirect/2\"), allow_redirects=False, stream=True)\n        assert r1.is_redirect\n        rg = s.resolve_redirects(r1, r1.request, stream=True)\n\n        # read only the first eight bytes of the response body,\n        # then follow the redirect\n        r1.iter_content(8)\n        r2 = next(rg)\n        assert r2.is_redirect\n\n        # read all of the response via iter_content,\n        # then follow the redirect\n        for _ in r2.iter_content():\n            pass\n        r3 = next(rg)\n        assert not r3.is_redirect\n\n    def test_prepare_body_position_non_stream(self):\n        data = b\"the data\"\n        prep = requests.Request(\"GET\", \"http://example.com\", data=data).prepare()\n        assert prep._body_position is None\n\n    def test_rewind_body(self):\n        data = io.BytesIO(b\"the data\")\n        prep = requests.Request(\"GET\", \"http://example.com\", data=data).prepare()\n        assert prep._body_position == 0\n        assert prep.body.read() == b\"the data\"\n\n        # the data has all been read\n        assert prep.body.read() == b\"\"\n\n        # rewind it back\n        requests.utils.rewind_body(prep)\n        assert prep.body.read() == b\"the data\"\n\n    def test_rewind_partially_read_body(self):\n        data = io.BytesIO(b\"the data\")\n        data.read(4)  # read some data\n        prep = requests.Request(\"GET\", \"http://example.com\", data=data).prepare()\n        assert prep._body_position == 4\n        assert prep.body.read() == b\"data\"\n\n        # the data has all been read\n        assert prep.body.read() == b\"\"\n\n        # rewind it back\n        requests.utils.rewind_body(prep)\n    "}, {"start_line": 68000, "end_line": 70000, "belongs_to": {"file_name": "test_requests.py", "upper_path": "/data2/raymone/swebench-repos/requests/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "://example.com/bar\"\n        )\n        assert not s.should_strip_auth(\n            \"http://example.com:80/foo\", \"https://example.com/bar\"\n        )\n        assert not s.should_strip_auth(\n            \"http://example.com/foo\", \"https://example.com:443/bar\"\n        )\n        # Non-standard ports should trigger stripping\n        assert s.should_strip_auth(\n            \"http://example.com:8080/foo\", \"https://example.com/bar\"\n        )\n        assert s.should_strip_auth(\n            \"http://example.com/foo\", \"https://example.com:8443/bar\"\n        )\n\n    def test_should_strip_auth_port_change(self):\n        s = requests.Session()\n        assert s.should_strip_auth(\n            \"http://example.com:1234/foo\", \"https://example.com:4321/bar\"\n        )\n\n    @pytest.mark.parametrize(\n        \"old_uri, new_uri\",\n        (\n            (\"https://example.com:443/foo\", \"https://example.com/bar\"),\n            (\"http://example.com:80/foo\", \"http://example.com/bar\"),\n            (\"https://example.com/foo\", \"https://example.com:443/bar\"),\n            (\"http://example.com/foo\", \"http://example.com:80/bar\"),\n        ),\n    )\n    def test_should_strip_auth_default_port(self, old_uri, new_uri):\n        s = requests.Session()\n        assert not s.should_strip_auth(old_uri, new_uri)\n\n    def test_manual_redirect_with_partial_body_read(self, httpbin):\n        s = requests.Session()\n        r1 = s.get(httpbin(\"redirect/2\"), allow_redirects=False, stream=True)\n        assert r1.is_redirect\n        rg = s.resolve_redirects(r1, r1.request, stream=True)\n\n        # read only the first eight bytes of the response body,\n        # then follow the redirect\n        r1.iter_content(8)\n        r2 = next(rg)\n        assert r2.is_redirect\n\n        # read all of the response via iter_content,\n        # then follow the redirect\n        for _ in r2.iter_content():\n            pass\n        r3 = next(rg)\n        assert not r3.is_redirect\n\n    def test_prepare_body_position_non_stream(self):\n        data = b\"the da"}, {"start_line": 4000, "end_line": 6000, "belongs_to": {"file_name": "sessions.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "ion in latin1.\n            location = location.encode(\"latin1\")\n            return to_native_string(location, \"utf8\")\n        return None\n\n    def should_strip_auth(self, old_url, new_url):\n        \"\"\"Decide whether Authorization header should be removed when redirecting\"\"\"\n        old_parsed = urlparse(old_url)\n        new_parsed = urlparse(new_url)\n        if old_parsed.hostname != new_parsed.hostname:\n            return True\n        # Special case: allow http -> https redirect when using the standard\n        # ports. This isn't specified by RFC 7235, but is kept to avoid\n        # breaking backwards compatibility with older versions of requests\n        # that allowed any redirects on the same host.\n        if (\n            old_parsed.scheme == \"http\"\n            and old_parsed.port in (80, None)\n            and new_parsed.scheme == \"https\"\n            and new_parsed.port in (443, None)\n        ):\n            return False\n\n        # Handle default port usage corresponding to scheme.\n        changed_port = old_parsed.port != new_parsed.port\n        changed_scheme = old_parsed.scheme != new_parsed.scheme\n        default_port = (DEFAULT_PORTS.get(old_parsed.scheme, None), None)\n        if (\n            not changed_scheme\n            and old_parsed.port in default_port\n            and new_parsed.port in default_port\n        ):\n            return False\n\n        # Standard case: root URI must match\n        return changed_port or changed_scheme\n\n    def resolve_redirects(\n        self,\n        resp,\n        req,\n        stream=False,\n        timeout=None,\n        verify=True,\n        cert=None,\n        proxies=None,\n        yield_requests=False,\n        **adapter_kwargs,\n    ):\n        \"\"\"Receives a Response. Returns a generator of Responses or Requests.\"\"\"\n\n        hist = []  # keep track of history\n\n        url = self.get_redirect_target(resp)\n        previous_fragment = urlparse(req.url).fragment\n        while url:\n            prepared_request = req.copy()\n\n          "}, {"start_line": 6000, "end_line": 8000, "belongs_to": {"file_name": "test_requests.py", "upper_path": "/data2/raymone/swebench-repos/requests/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "\"\n\n    @pytest.mark.parametrize(\"scheme\", (\"http://\", \"HTTP://\", \"hTTp://\", \"HttP://\"))\n    def test_mixed_case_scheme_acceptable(self, httpbin, scheme):\n        s = requests.Session()\n        s.proxies = getproxies()\n        parts = urlparse(httpbin(\"get\"))\n        url = scheme + parts.netloc + parts.path\n        r = requests.Request(\"GET\", url)\n        r = s.send(r.prepare())\n        assert r.status_code == 200, f\"failed for scheme {scheme}\"\n\n    def test_HTTP_200_OK_GET_ALTERNATIVE(self, httpbin):\n        r = requests.Request(\"GET\", httpbin(\"get\"))\n        s = requests.Session()\n        s.proxies = getproxies()\n\n        r = s.send(r.prepare())\n\n        assert r.status_code == 200\n\n    def test_HTTP_302_ALLOW_REDIRECT_GET(self, httpbin):\n        r = requests.get(httpbin(\"redirect\", \"1\"))\n        assert r.status_code == 200\n        assert r.history[0].status_code == 302\n        assert r.history[0].is_redirect\n\n    def test_HTTP_307_ALLOW_REDIRECT_POST(self, httpbin):\n        r = requests.post(\n            httpbin(\"redirect-to\"),\n            data=\"test\",\n            params={\"url\": \"post\", \"status_code\": 307},\n        )\n        assert r.status_code == 200\n        assert r.history[0].status_code == 307\n        assert r.history[0].is_redirect\n        assert r.json()[\"data\"] == \"test\"\n\n    def test_HTTP_307_ALLOW_REDIRECT_POST_WITH_SEEKABLE(self, httpbin):\n        byte_str = b\"test\"\n        r = requests.post(\n            httpbin(\"redirect-to\"),\n            data=io.BytesIO(byte_str),\n            params={\"url\": \"post\", \"status_code\": 307},\n        )\n        assert r.status_code == 200\n        assert r.history[0].status_code == 307\n        assert r.history[0].is_redirect\n        assert r.json()[\"data\"] == byte_str.decode(\"utf-8\")\n\n    def test_HTTP_302_TOO_MANY_REDIRECTS(self, httpbin):\n        try:\n            requests.get(httpbin(\"relative-redirect\", \"50\"))\n        except TooManyRedirects as e:\n            url = httpbin(\"relative-redirect\", \"20\")\n            assert e.req"}], "retrieved_count": 10, "cost_time": 4.335310697555542}
{"question": "Why does Requests use a prepared request pattern instead of sending raw HTTP requests directly?", "answer": null, "relative_code_list": null, "ground_truth": "Requests uses a prepared request pattern for several architectural and practical reasons: 1) Separation of concerns - Separates request preparation (encoding, header generation, authentication) from request transmission, enabling better code organization and testing; 2) Immutability - PreparedRequest objects represent the final, immutable state of a request, preventing accidental modifications during transmission; 3) Reusability - Prepared requests can be reused, modified, or copied for different purposes (e.g., retries, redirects, debugging); 4) Complex preparation logic - HTTP request preparation involves multiple steps (URL encoding, cookie processing, authentication, body encoding) that benefit from being isolated and testable; 5) Session integration - Allows session-level settings to be merged with request-specific settings in a controlled manner; 6) Hook system - Enables request hooks to be applied during preparation, allowing for request modification and logging; 7) Error handling - Preparation errors can be caught and handled before network transmission begins; 8) Debugging support - Prepared requests provide a clear representation of what will be sent, aiding in debugging and logging; 9) Redirect handling - Prepared requests can be easily copied and modified for redirect chains; 10) Transport abstraction - Prepared requests provide a clean interface for different transport adapters to consume.", "score": null, "retrieved_content": [{"start_line": 10000, "end_line": 12000, "belongs_to": {"file_name": "models.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "\n\n      >>> s = requests.Session()\n      >>> s.send(r)\n      <Response [200]>\n    \"\"\"\n\n    def __init__(self):\n        #: HTTP verb to send to the server.\n        self.method = None\n        #: HTTP URL to send the request to.\n        self.url = None\n        #: dictionary of HTTP headers.\n        self.headers = None\n        # The `CookieJar` used to create the Cookie header will be stored here\n        # after prepare_cookies is called\n        self._cookies = None\n        #: request body to send to the server.\n        self.body = None\n        #: dictionary of callback hooks, for internal usage.\n        self.hooks = default_hooks()\n        #: integer denoting starting position of a readable file-like body.\n        self._body_position = None\n\n    def prepare(\n        self,\n        method=None,\n        url=None,\n        headers=None,\n        files=None,\n        data=None,\n        params=None,\n        auth=None,\n        cookies=None,\n        hooks=None,\n        json=None,\n    ):\n        \"\"\"Prepares the entire request with the given parameters.\"\"\"\n\n        self.prepare_method(method)\n        self.prepare_url(url, params)\n        self.prepare_headers(headers)\n        self.prepare_cookies(cookies)\n        self.prepare_body(data, files, json)\n        self.prepare_auth(auth, url)\n\n        # Note that prepare_auth must be last to enable authentication schemes\n        # such as OAuth to work on a fully prepared request.\n\n        # This MUST go after prepare_auth. Authenticators could add a hook\n        self.prepare_hooks(hooks)\n\n    def __repr__(self):\n        return f\"<PreparedRequest [{self.method}]>\"\n\n    def copy(self):\n        p = PreparedRequest()\n        p.method = self.method\n        p.url = self.url\n        p.headers = self.headers.copy() if self.headers is not None else None\n        p._cookies = _copy_cookie_jar(self._cookies)\n        p.body = self.body\n        p.hooks = self.hooks\n        p._body_position = self._body_position\n        return p\n\n    def prepare_method("}, {"start_line": 17000, "end_line": 19000, "belongs_to": {"file_name": "sessions.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": ": requests.PreparedRequest\n        \"\"\"\n        cookies = request.cookies or {}\n\n        # Bootstrap CookieJar.\n        if not isinstance(cookies, cookielib.CookieJar):\n            cookies = cookiejar_from_dict(cookies)\n\n        # Merge with session cookies\n        merged_cookies = merge_cookies(\n            merge_cookies(RequestsCookieJar(), self.cookies), cookies\n        )\n\n        # Set environment's basic authentication if not explicitly set.\n        auth = request.auth\n        if self.trust_env and not auth and not self.auth:\n            auth = get_netrc_auth(request.url)\n\n        p = PreparedRequest()\n        p.prepare(\n            method=request.method.upper(),\n            url=request.url,\n            files=request.files,\n            data=request.data,\n            json=request.json,\n            headers=merge_setting(\n                request.headers, self.headers, dict_class=CaseInsensitiveDict\n            ),\n            params=merge_setting(request.params, self.params),\n            auth=merge_setting(auth, self.auth),\n            cookies=merged_cookies,\n            hooks=merge_hooks(request.hooks, self.hooks),\n        )\n        return p\n\n    def request(\n        self,\n        method,\n        url,\n        params=None,\n        data=None,\n        headers=None,\n        cookies=None,\n        files=None,\n        auth=None,\n        timeout=None,\n        allow_redirects=True,\n        proxies=None,\n        hooks=None,\n        stream=None,\n        verify=None,\n        cert=None,\n        json=None,\n    ):\n        \"\"\"Constructs a :class:`Request <Request>`, prepares it and sends it.\n        Returns :class:`Response <Response>` object.\n\n        :param method: method for the new :class:`Request` object.\n        :param url: URL for the new :class:`Request` object.\n        :param params: (optional) Dictionary or bytes to be sent in the query\n            string for the :class:`Request`.\n        :param data: (optional) Dictionary, list of tuples, bytes, or file-like\n           "}, {"start_line": 18000, "end_line": 20000, "belongs_to": {"file_name": "sessions.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "   auth=merge_setting(auth, self.auth),\n            cookies=merged_cookies,\n            hooks=merge_hooks(request.hooks, self.hooks),\n        )\n        return p\n\n    def request(\n        self,\n        method,\n        url,\n        params=None,\n        data=None,\n        headers=None,\n        cookies=None,\n        files=None,\n        auth=None,\n        timeout=None,\n        allow_redirects=True,\n        proxies=None,\n        hooks=None,\n        stream=None,\n        verify=None,\n        cert=None,\n        json=None,\n    ):\n        \"\"\"Constructs a :class:`Request <Request>`, prepares it and sends it.\n        Returns :class:`Response <Response>` object.\n\n        :param method: method for the new :class:`Request` object.\n        :param url: URL for the new :class:`Request` object.\n        :param params: (optional) Dictionary or bytes to be sent in the query\n            string for the :class:`Request`.\n        :param data: (optional) Dictionary, list of tuples, bytes, or file-like\n            object to send in the body of the :class:`Request`.\n        :param json: (optional) json to send in the body of the\n            :class:`Request`.\n        :param headers: (optional) Dictionary of HTTP Headers to send with the\n            :class:`Request`.\n        :param cookies: (optional) Dict or CookieJar object to send with the\n            :class:`Request`.\n        :param files: (optional) Dictionary of ``'filename': file-like-objects``\n            for multipart encoding upload.\n        :param auth: (optional) Auth tuple or callable to enable\n            Basic/Digest/Custom HTTP Auth.\n        :param timeout: (optional) How many seconds to wait for the server to send\n            data before giving up, as a float, or a :ref:`(connect timeout,\n            read timeout) <timeouts>` tuple.\n        :type timeout: float or tuple\n        :param allow_redirects: (optional) Set to True by default.\n        :type allow_redirects: bool\n        :param proxies: (optional) Dictionary mapping protoc"}, {"start_line": 11000, "end_line": 13000, "belongs_to": {"file_name": "models.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "repares the entire request with the given parameters.\"\"\"\n\n        self.prepare_method(method)\n        self.prepare_url(url, params)\n        self.prepare_headers(headers)\n        self.prepare_cookies(cookies)\n        self.prepare_body(data, files, json)\n        self.prepare_auth(auth, url)\n\n        # Note that prepare_auth must be last to enable authentication schemes\n        # such as OAuth to work on a fully prepared request.\n\n        # This MUST go after prepare_auth. Authenticators could add a hook\n        self.prepare_hooks(hooks)\n\n    def __repr__(self):\n        return f\"<PreparedRequest [{self.method}]>\"\n\n    def copy(self):\n        p = PreparedRequest()\n        p.method = self.method\n        p.url = self.url\n        p.headers = self.headers.copy() if self.headers is not None else None\n        p._cookies = _copy_cookie_jar(self._cookies)\n        p.body = self.body\n        p.hooks = self.hooks\n        p._body_position = self._body_position\n        return p\n\n    def prepare_method(self, method):\n        \"\"\"Prepares the given HTTP method.\"\"\"\n        self.method = method\n        if self.method is not None:\n            self.method = to_native_string(self.method.upper())\n\n    @staticmethod\n    def _get_idna_encoded_host(host):\n        import idna\n\n        try:\n            host = idna.encode(host, uts46=True).decode(\"utf-8\")\n        except idna.IDNAError:\n            raise UnicodeError\n        return host\n\n    def prepare_url(self, url, params):\n        \"\"\"Prepares the given HTTP URL.\"\"\"\n        #: Accept objects that have string representations.\n        #: We're unable to blindly call unicode/str functions\n        #: as this will include the bytestring indicator (b'')\n        #: on python 3.x.\n        #: https://github.com/psf/requests/pull/2238\n        if isinstance(url, bytes):\n            url = url.decode(\"utf8\")\n        else:\n            url = str(url)\n\n        # Remove leading whitespaces from url\n        url = url.lstrip()\n\n        # Don't do any URL preparati"}, {"start_line": 9000, "end_line": 11000, "belongs_to": {"file_name": "models.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "class:`PreparedRequest <PreparedRequest>` for transmission and returns it.\"\"\"\n        p = PreparedRequest()\n        p.prepare(\n            method=self.method,\n            url=self.url,\n            headers=self.headers,\n            files=self.files,\n            data=self.data,\n            json=self.json,\n            params=self.params,\n            auth=self.auth,\n            cookies=self.cookies,\n            hooks=self.hooks,\n        )\n        return p\n\n\nclass PreparedRequest(RequestEncodingMixin, RequestHooksMixin):\n    \"\"\"The fully mutable :class:`PreparedRequest <PreparedRequest>` object,\n    containing the exact bytes that will be sent to the server.\n\n    Instances are generated from a :class:`Request <Request>` object, and\n    should not be instantiated manually; doing so may produce undesirable\n    effects.\n\n    Usage::\n\n      >>> import requests\n      >>> req = requests.Request('GET', 'https://httpbin.org/get')\n      >>> r = req.prepare()\n      >>> r\n      <PreparedRequest [GET]>\n\n      >>> s = requests.Session()\n      >>> s.send(r)\n      <Response [200]>\n    \"\"\"\n\n    def __init__(self):\n        #: HTTP verb to send to the server.\n        self.method = None\n        #: HTTP URL to send the request to.\n        self.url = None\n        #: dictionary of HTTP headers.\n        self.headers = None\n        # The `CookieJar` used to create the Cookie header will be stored here\n        # after prepare_cookies is called\n        self._cookies = None\n        #: request body to send to the server.\n        self.body = None\n        #: dictionary of callback hooks, for internal usage.\n        self.hooks = default_hooks()\n        #: integer denoting starting position of a readable file-like body.\n        self._body_position = None\n\n    def prepare(\n        self,\n        method=None,\n        url=None,\n        headers=None,\n        files=None,\n        data=None,\n        params=None,\n        auth=None,\n        cookies=None,\n        hooks=None,\n        json=None,\n    ):\n        \"\"\"P"}, {"start_line": 8000, "end_line": 10000, "belongs_to": {"file_name": "models.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "       self,\n        method=None,\n        url=None,\n        headers=None,\n        files=None,\n        data=None,\n        params=None,\n        auth=None,\n        cookies=None,\n        hooks=None,\n        json=None,\n    ):\n        # Default empty dicts for dict params.\n        data = [] if data is None else data\n        files = [] if files is None else files\n        headers = {} if headers is None else headers\n        params = {} if params is None else params\n        hooks = {} if hooks is None else hooks\n\n        self.hooks = default_hooks()\n        for k, v in list(hooks.items()):\n            self.register_hook(event=k, hook=v)\n\n        self.method = method\n        self.url = url\n        self.headers = headers\n        self.files = files\n        self.data = data\n        self.json = json\n        self.params = params\n        self.auth = auth\n        self.cookies = cookies\n\n    def __repr__(self):\n        return f\"<Request [{self.method}]>\"\n\n    def prepare(self):\n        \"\"\"Constructs a :class:`PreparedRequest <PreparedRequest>` for transmission and returns it.\"\"\"\n        p = PreparedRequest()\n        p.prepare(\n            method=self.method,\n            url=self.url,\n            headers=self.headers,\n            files=self.files,\n            data=self.data,\n            json=self.json,\n            params=self.params,\n            auth=self.auth,\n            cookies=self.cookies,\n            hooks=self.hooks,\n        )\n        return p\n\n\nclass PreparedRequest(RequestEncodingMixin, RequestHooksMixin):\n    \"\"\"The fully mutable :class:`PreparedRequest <PreparedRequest>` object,\n    containing the exact bytes that will be sent to the server.\n\n    Instances are generated from a :class:`Request <Request>` object, and\n    should not be instantiated manually; doing so may produce undesirable\n    effects.\n\n    Usage::\n\n      >>> import requests\n      >>> req = requests.Request('GET', 'https://httpbin.org/get')\n      >>> r = req.prepare()\n      >>> r\n      <PreparedRequest [GET]>"}, {"start_line": 24000, "end_line": 26000, "belongs_to": {"file_name": "sessions.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "nts that ``request`` takes.\n        :rtype: requests.Response\n        \"\"\"\n\n        return self.request(\"PUT\", url, data=data, **kwargs)\n\n    def patch(self, url, data=None, **kwargs):\n        r\"\"\"Sends a PATCH request. Returns :class:`Response` object.\n\n        :param url: URL for the new :class:`Request` object.\n        :param data: (optional) Dictionary, list of tuples, bytes, or file-like\n            object to send in the body of the :class:`Request`.\n        :param \\*\\*kwargs: Optional arguments that ``request`` takes.\n        :rtype: requests.Response\n        \"\"\"\n\n        return self.request(\"PATCH\", url, data=data, **kwargs)\n\n    def delete(self, url, **kwargs):\n        r\"\"\"Sends a DELETE request. Returns :class:`Response` object.\n\n        :param url: URL for the new :class:`Request` object.\n        :param \\*\\*kwargs: Optional arguments that ``request`` takes.\n        :rtype: requests.Response\n        \"\"\"\n\n        return self.request(\"DELETE\", url, **kwargs)\n\n    def send(self, request, **kwargs):\n        \"\"\"Send a given PreparedRequest.\n\n        :rtype: requests.Response\n        \"\"\"\n        # Set defaults that the hooks can utilize to ensure they always have\n        # the correct parameters to reproduce the previous request.\n        kwargs.setdefault(\"stream\", self.stream)\n        kwargs.setdefault(\"verify\", self.verify)\n        kwargs.setdefault(\"cert\", self.cert)\n        if \"proxies\" not in kwargs:\n            kwargs[\"proxies\"] = resolve_proxies(request, self.proxies, self.trust_env)\n\n        # It's possible that users might accidentally send a Request object.\n        # Guard against that specific failure case.\n        if isinstance(request, Request):\n            raise ValueError(\"You can only send PreparedRequests.\")\n\n        # Set up variables needed for resolve_redirects and dispatching of hooks\n        allow_redirects = kwargs.pop(\"allow_redirects\", True)\n        stream = kwargs.get(\"stream\")\n        hooks = request.hooks\n\n        # Get the appropriate "}, {"start_line": 25000, "end_line": 27000, "belongs_to": {"file_name": "sessions.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "equest, **kwargs):\n        \"\"\"Send a given PreparedRequest.\n\n        :rtype: requests.Response\n        \"\"\"\n        # Set defaults that the hooks can utilize to ensure they always have\n        # the correct parameters to reproduce the previous request.\n        kwargs.setdefault(\"stream\", self.stream)\n        kwargs.setdefault(\"verify\", self.verify)\n        kwargs.setdefault(\"cert\", self.cert)\n        if \"proxies\" not in kwargs:\n            kwargs[\"proxies\"] = resolve_proxies(request, self.proxies, self.trust_env)\n\n        # It's possible that users might accidentally send a Request object.\n        # Guard against that specific failure case.\n        if isinstance(request, Request):\n            raise ValueError(\"You can only send PreparedRequests.\")\n\n        # Set up variables needed for resolve_redirects and dispatching of hooks\n        allow_redirects = kwargs.pop(\"allow_redirects\", True)\n        stream = kwargs.get(\"stream\")\n        hooks = request.hooks\n\n        # Get the appropriate adapter to use\n        adapter = self.get_adapter(url=request.url)\n\n        # Start time (approximately) of the request\n        start = preferred_clock()\n\n        # Send the request\n        r = adapter.send(request, **kwargs)\n\n        # Total elapsed time of the request (approximately)\n        elapsed = preferred_clock() - start\n        r.elapsed = timedelta(seconds=elapsed)\n\n        # Response manipulation hooks\n        r = dispatch_hook(\"response\", hooks, r, **kwargs)\n\n        # Persist cookies\n        if r.history:\n            # If the hooks create history then we want those cookies too\n            for resp in r.history:\n                extract_cookies_to_jar(self.cookies, resp.request, resp.raw)\n\n        extract_cookies_to_jar(self.cookies, request, r.raw)\n\n        # Resolve redirects if allowed.\n        if allow_redirects:\n            # Redirect resolving generator.\n            gen = self.resolve_redirects(r, request, **kwargs)\n            history = [resp for resp in gen]\n        "}, {"start_line": 7000, "end_line": 9000, "belongs_to": {"file_name": "models.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "method to use.\n    :param url: URL to send.\n    :param headers: dictionary of headers to send.\n    :param files: dictionary of {filename: fileobject} files to multipart upload.\n    :param data: the body to attach to the request. If a dictionary or\n        list of tuples ``[(key, value)]`` is provided, form-encoding will\n        take place.\n    :param json: json for the body to attach to the request (if files or data is not specified).\n    :param params: URL parameters to append to the URL. If a dictionary or\n        list of tuples ``[(key, value)]`` is provided, form-encoding will\n        take place.\n    :param auth: Auth handler or (user, pass) tuple.\n    :param cookies: dictionary or CookieJar of cookies to attach to this request.\n    :param hooks: dictionary of callback hooks, for internal usage.\n\n    Usage::\n\n      >>> import requests\n      >>> req = requests.Request('GET', 'https://httpbin.org/get')\n      >>> req.prepare()\n      <PreparedRequest [GET]>\n    \"\"\"\n\n    def __init__(\n        self,\n        method=None,\n        url=None,\n        headers=None,\n        files=None,\n        data=None,\n        params=None,\n        auth=None,\n        cookies=None,\n        hooks=None,\n        json=None,\n    ):\n        # Default empty dicts for dict params.\n        data = [] if data is None else data\n        files = [] if files is None else files\n        headers = {} if headers is None else headers\n        params = {} if params is None else params\n        hooks = {} if hooks is None else hooks\n\n        self.hooks = default_hooks()\n        for k, v in list(hooks.items()):\n            self.register_hook(event=k, hook=v)\n\n        self.method = method\n        self.url = url\n        self.headers = headers\n        self.files = files\n        self.data = data\n        self.json = json\n        self.params = params\n        self.auth = auth\n        self.cookies = cookies\n\n    def __repr__(self):\n        return f\"<Request [{self.method}]>\"\n\n    def prepare(self):\n        \"\"\"Constructs a :"}, {"start_line": 15000, "end_line": 17000, "belongs_to": {"file_name": "sessions.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "y the TLS certificate at the\n        #: remote end.\n        #: If verify is set to `False`, requests will accept any TLS certificate\n        #: presented by the server, and will ignore hostname mismatches and/or\n        #: expired certificates, which will make your application vulnerable to\n        #: man-in-the-middle (MitM) attacks.\n        #: Only set this to `False` for testing.\n        self.verify = True\n\n        #: SSL client certificate default, if String, path to ssl client\n        #: cert file (.pem). If Tuple, ('cert', 'key') pair.\n        self.cert = None\n\n        #: Maximum number of redirects allowed. If the request exceeds this\n        #: limit, a :class:`TooManyRedirects` exception is raised.\n        #: This defaults to requests.models.DEFAULT_REDIRECT_LIMIT, which is\n        #: 30.\n        self.max_redirects = DEFAULT_REDIRECT_LIMIT\n\n        #: Trust environment settings for proxy configuration, default\n        #: authentication and similar.\n        self.trust_env = True\n\n        #: A CookieJar containing all currently outstanding cookies set on this\n        #: session. By default it is a\n        #: :class:`RequestsCookieJar <requests.cookies.RequestsCookieJar>`, but\n        #: may be any other ``cookielib.CookieJar`` compatible object.\n        self.cookies = cookiejar_from_dict({})\n\n        # Default connection adapters.\n        self.adapters = OrderedDict()\n        self.mount(\"https://\", HTTPAdapter())\n        self.mount(\"http://\", HTTPAdapter())\n\n    def __enter__(self):\n        return self\n\n    def __exit__(self, *args):\n        self.close()\n\n    def prepare_request(self, request):\n        \"\"\"Constructs a :class:`PreparedRequest <PreparedRequest>` for\n        transmission and returns it. The :class:`PreparedRequest` has settings\n        merged from the :class:`Request <Request>` instance and those of the\n        :class:`Session`.\n\n        :param request: :class:`Request` instance to prepare with this\n            session's settings.\n        :rtype"}], "retrieved_count": 10, "cost_time": 4.368843078613281}
{"question": "What is the purpose of the PreparedRequest class in Requests' request preparation system?", "answer": null, "relative_code_list": null, "ground_truth": "The PreparedRequest class (src/requests/models.py) serves as the final, fully-prepared representation of an HTTP request that is ready for transmission. Its purpose includes: 1) Request finalization - transforms user-friendly Request objects into transport-ready requests with all encoding, headers, and body preparation completed; 2) Immutable state - once prepared, the request contains the exact bytes and headers that will be sent to the server, preventing modification during transmission; 3) Encoding and formatting - handles URL encoding, parameter encoding, cookie header generation, authentication header preparation, and body encoding (form data, JSON, files); 4) Header management - prepares and validates all HTTP headers including Content-Type, Content-Length, and custom headers; 5) Cookie processing - generates Cookie headers from CookieJar objects using cookielib compatibility; 6) Authentication preparation - applies authentication handlers to add appropriate Authorization headers; 7) Body preparation - handles different body types (data, files, JSON) and encodes them appropriately; 8) URL processing - handles URL encoding, parameter appending, and IDNA hostname encoding; 9) Hook registration - sets up request hooks for pre-send processing; 10) Copy support - provides copy() method for creating duplicates, essential for redirect handling. PreparedRequest objects are created by calling Request.prepare() or Session.prepare_request() and are consumed by adapter.send() methods.", "score": null, "retrieved_content": [{"start_line": 8000, "end_line": 10000, "belongs_to": {"file_name": "models.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "       self,\n        method=None,\n        url=None,\n        headers=None,\n        files=None,\n        data=None,\n        params=None,\n        auth=None,\n        cookies=None,\n        hooks=None,\n        json=None,\n    ):\n        # Default empty dicts for dict params.\n        data = [] if data is None else data\n        files = [] if files is None else files\n        headers = {} if headers is None else headers\n        params = {} if params is None else params\n        hooks = {} if hooks is None else hooks\n\n        self.hooks = default_hooks()\n        for k, v in list(hooks.items()):\n            self.register_hook(event=k, hook=v)\n\n        self.method = method\n        self.url = url\n        self.headers = headers\n        self.files = files\n        self.data = data\n        self.json = json\n        self.params = params\n        self.auth = auth\n        self.cookies = cookies\n\n    def __repr__(self):\n        return f\"<Request [{self.method}]>\"\n\n    def prepare(self):\n        \"\"\"Constructs a :class:`PreparedRequest <PreparedRequest>` for transmission and returns it.\"\"\"\n        p = PreparedRequest()\n        p.prepare(\n            method=self.method,\n            url=self.url,\n            headers=self.headers,\n            files=self.files,\n            data=self.data,\n            json=self.json,\n            params=self.params,\n            auth=self.auth,\n            cookies=self.cookies,\n            hooks=self.hooks,\n        )\n        return p\n\n\nclass PreparedRequest(RequestEncodingMixin, RequestHooksMixin):\n    \"\"\"The fully mutable :class:`PreparedRequest <PreparedRequest>` object,\n    containing the exact bytes that will be sent to the server.\n\n    Instances are generated from a :class:`Request <Request>` object, and\n    should not be instantiated manually; doing so may produce undesirable\n    effects.\n\n    Usage::\n\n      >>> import requests\n      >>> req = requests.Request('GET', 'https://httpbin.org/get')\n      >>> r = req.prepare()\n      >>> r\n      <PreparedRequest [GET]>"}, {"start_line": 10000, "end_line": 12000, "belongs_to": {"file_name": "models.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "\n\n      >>> s = requests.Session()\n      >>> s.send(r)\n      <Response [200]>\n    \"\"\"\n\n    def __init__(self):\n        #: HTTP verb to send to the server.\n        self.method = None\n        #: HTTP URL to send the request to.\n        self.url = None\n        #: dictionary of HTTP headers.\n        self.headers = None\n        # The `CookieJar` used to create the Cookie header will be stored here\n        # after prepare_cookies is called\n        self._cookies = None\n        #: request body to send to the server.\n        self.body = None\n        #: dictionary of callback hooks, for internal usage.\n        self.hooks = default_hooks()\n        #: integer denoting starting position of a readable file-like body.\n        self._body_position = None\n\n    def prepare(\n        self,\n        method=None,\n        url=None,\n        headers=None,\n        files=None,\n        data=None,\n        params=None,\n        auth=None,\n        cookies=None,\n        hooks=None,\n        json=None,\n    ):\n        \"\"\"Prepares the entire request with the given parameters.\"\"\"\n\n        self.prepare_method(method)\n        self.prepare_url(url, params)\n        self.prepare_headers(headers)\n        self.prepare_cookies(cookies)\n        self.prepare_body(data, files, json)\n        self.prepare_auth(auth, url)\n\n        # Note that prepare_auth must be last to enable authentication schemes\n        # such as OAuth to work on a fully prepared request.\n\n        # This MUST go after prepare_auth. Authenticators could add a hook\n        self.prepare_hooks(hooks)\n\n    def __repr__(self):\n        return f\"<PreparedRequest [{self.method}]>\"\n\n    def copy(self):\n        p = PreparedRequest()\n        p.method = self.method\n        p.url = self.url\n        p.headers = self.headers.copy() if self.headers is not None else None\n        p._cookies = _copy_cookie_jar(self._cookies)\n        p.body = self.body\n        p.hooks = self.hooks\n        p._body_position = self._body_position\n        return p\n\n    def prepare_method("}, {"start_line": 9000, "end_line": 11000, "belongs_to": {"file_name": "models.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "class:`PreparedRequest <PreparedRequest>` for transmission and returns it.\"\"\"\n        p = PreparedRequest()\n        p.prepare(\n            method=self.method,\n            url=self.url,\n            headers=self.headers,\n            files=self.files,\n            data=self.data,\n            json=self.json,\n            params=self.params,\n            auth=self.auth,\n            cookies=self.cookies,\n            hooks=self.hooks,\n        )\n        return p\n\n\nclass PreparedRequest(RequestEncodingMixin, RequestHooksMixin):\n    \"\"\"The fully mutable :class:`PreparedRequest <PreparedRequest>` object,\n    containing the exact bytes that will be sent to the server.\n\n    Instances are generated from a :class:`Request <Request>` object, and\n    should not be instantiated manually; doing so may produce undesirable\n    effects.\n\n    Usage::\n\n      >>> import requests\n      >>> req = requests.Request('GET', 'https://httpbin.org/get')\n      >>> r = req.prepare()\n      >>> r\n      <PreparedRequest [GET]>\n\n      >>> s = requests.Session()\n      >>> s.send(r)\n      <Response [200]>\n    \"\"\"\n\n    def __init__(self):\n        #: HTTP verb to send to the server.\n        self.method = None\n        #: HTTP URL to send the request to.\n        self.url = None\n        #: dictionary of HTTP headers.\n        self.headers = None\n        # The `CookieJar` used to create the Cookie header will be stored here\n        # after prepare_cookies is called\n        self._cookies = None\n        #: request body to send to the server.\n        self.body = None\n        #: dictionary of callback hooks, for internal usage.\n        self.hooks = default_hooks()\n        #: integer denoting starting position of a readable file-like body.\n        self._body_position = None\n\n    def prepare(\n        self,\n        method=None,\n        url=None,\n        headers=None,\n        files=None,\n        data=None,\n        params=None,\n        auth=None,\n        cookies=None,\n        hooks=None,\n        json=None,\n    ):\n        \"\"\"P"}, {"start_line": 17000, "end_line": 19000, "belongs_to": {"file_name": "sessions.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": ": requests.PreparedRequest\n        \"\"\"\n        cookies = request.cookies or {}\n\n        # Bootstrap CookieJar.\n        if not isinstance(cookies, cookielib.CookieJar):\n            cookies = cookiejar_from_dict(cookies)\n\n        # Merge with session cookies\n        merged_cookies = merge_cookies(\n            merge_cookies(RequestsCookieJar(), self.cookies), cookies\n        )\n\n        # Set environment's basic authentication if not explicitly set.\n        auth = request.auth\n        if self.trust_env and not auth and not self.auth:\n            auth = get_netrc_auth(request.url)\n\n        p = PreparedRequest()\n        p.prepare(\n            method=request.method.upper(),\n            url=request.url,\n            files=request.files,\n            data=request.data,\n            json=request.json,\n            headers=merge_setting(\n                request.headers, self.headers, dict_class=CaseInsensitiveDict\n            ),\n            params=merge_setting(request.params, self.params),\n            auth=merge_setting(auth, self.auth),\n            cookies=merged_cookies,\n            hooks=merge_hooks(request.hooks, self.hooks),\n        )\n        return p\n\n    def request(\n        self,\n        method,\n        url,\n        params=None,\n        data=None,\n        headers=None,\n        cookies=None,\n        files=None,\n        auth=None,\n        timeout=None,\n        allow_redirects=True,\n        proxies=None,\n        hooks=None,\n        stream=None,\n        verify=None,\n        cert=None,\n        json=None,\n    ):\n        \"\"\"Constructs a :class:`Request <Request>`, prepares it and sends it.\n        Returns :class:`Response <Response>` object.\n\n        :param method: method for the new :class:`Request` object.\n        :param url: URL for the new :class:`Request` object.\n        :param params: (optional) Dictionary or bytes to be sent in the query\n            string for the :class:`Request`.\n        :param data: (optional) Dictionary, list of tuples, bytes, or file-like\n           "}, {"start_line": 16000, "end_line": 18000, "belongs_to": {"file_name": "sessions.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "e\n\n        #: A CookieJar containing all currently outstanding cookies set on this\n        #: session. By default it is a\n        #: :class:`RequestsCookieJar <requests.cookies.RequestsCookieJar>`, but\n        #: may be any other ``cookielib.CookieJar`` compatible object.\n        self.cookies = cookiejar_from_dict({})\n\n        # Default connection adapters.\n        self.adapters = OrderedDict()\n        self.mount(\"https://\", HTTPAdapter())\n        self.mount(\"http://\", HTTPAdapter())\n\n    def __enter__(self):\n        return self\n\n    def __exit__(self, *args):\n        self.close()\n\n    def prepare_request(self, request):\n        \"\"\"Constructs a :class:`PreparedRequest <PreparedRequest>` for\n        transmission and returns it. The :class:`PreparedRequest` has settings\n        merged from the :class:`Request <Request>` instance and those of the\n        :class:`Session`.\n\n        :param request: :class:`Request` instance to prepare with this\n            session's settings.\n        :rtype: requests.PreparedRequest\n        \"\"\"\n        cookies = request.cookies or {}\n\n        # Bootstrap CookieJar.\n        if not isinstance(cookies, cookielib.CookieJar):\n            cookies = cookiejar_from_dict(cookies)\n\n        # Merge with session cookies\n        merged_cookies = merge_cookies(\n            merge_cookies(RequestsCookieJar(), self.cookies), cookies\n        )\n\n        # Set environment's basic authentication if not explicitly set.\n        auth = request.auth\n        if self.trust_env and not auth and not self.auth:\n            auth = get_netrc_auth(request.url)\n\n        p = PreparedRequest()\n        p.prepare(\n            method=request.method.upper(),\n            url=request.url,\n            files=request.files,\n            data=request.data,\n            json=request.json,\n            headers=merge_setting(\n                request.headers, self.headers, dict_class=CaseInsensitiveDict\n            ),\n            params=merge_setting(request.params, self.params),\n         "}, {"start_line": 15000, "end_line": 17000, "belongs_to": {"file_name": "sessions.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "y the TLS certificate at the\n        #: remote end.\n        #: If verify is set to `False`, requests will accept any TLS certificate\n        #: presented by the server, and will ignore hostname mismatches and/or\n        #: expired certificates, which will make your application vulnerable to\n        #: man-in-the-middle (MitM) attacks.\n        #: Only set this to `False` for testing.\n        self.verify = True\n\n        #: SSL client certificate default, if String, path to ssl client\n        #: cert file (.pem). If Tuple, ('cert', 'key') pair.\n        self.cert = None\n\n        #: Maximum number of redirects allowed. If the request exceeds this\n        #: limit, a :class:`TooManyRedirects` exception is raised.\n        #: This defaults to requests.models.DEFAULT_REDIRECT_LIMIT, which is\n        #: 30.\n        self.max_redirects = DEFAULT_REDIRECT_LIMIT\n\n        #: Trust environment settings for proxy configuration, default\n        #: authentication and similar.\n        self.trust_env = True\n\n        #: A CookieJar containing all currently outstanding cookies set on this\n        #: session. By default it is a\n        #: :class:`RequestsCookieJar <requests.cookies.RequestsCookieJar>`, but\n        #: may be any other ``cookielib.CookieJar`` compatible object.\n        self.cookies = cookiejar_from_dict({})\n\n        # Default connection adapters.\n        self.adapters = OrderedDict()\n        self.mount(\"https://\", HTTPAdapter())\n        self.mount(\"http://\", HTTPAdapter())\n\n    def __enter__(self):\n        return self\n\n    def __exit__(self, *args):\n        self.close()\n\n    def prepare_request(self, request):\n        \"\"\"Constructs a :class:`PreparedRequest <PreparedRequest>` for\n        transmission and returns it. The :class:`PreparedRequest` has settings\n        merged from the :class:`Request <Request>` instance and those of the\n        :class:`Session`.\n\n        :param request: :class:`Request` instance to prepare with this\n            session's settings.\n        :rtype"}, {"start_line": 11000, "end_line": 13000, "belongs_to": {"file_name": "models.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "repares the entire request with the given parameters.\"\"\"\n\n        self.prepare_method(method)\n        self.prepare_url(url, params)\n        self.prepare_headers(headers)\n        self.prepare_cookies(cookies)\n        self.prepare_body(data, files, json)\n        self.prepare_auth(auth, url)\n\n        # Note that prepare_auth must be last to enable authentication schemes\n        # such as OAuth to work on a fully prepared request.\n\n        # This MUST go after prepare_auth. Authenticators could add a hook\n        self.prepare_hooks(hooks)\n\n    def __repr__(self):\n        return f\"<PreparedRequest [{self.method}]>\"\n\n    def copy(self):\n        p = PreparedRequest()\n        p.method = self.method\n        p.url = self.url\n        p.headers = self.headers.copy() if self.headers is not None else None\n        p._cookies = _copy_cookie_jar(self._cookies)\n        p.body = self.body\n        p.hooks = self.hooks\n        p._body_position = self._body_position\n        return p\n\n    def prepare_method(self, method):\n        \"\"\"Prepares the given HTTP method.\"\"\"\n        self.method = method\n        if self.method is not None:\n            self.method = to_native_string(self.method.upper())\n\n    @staticmethod\n    def _get_idna_encoded_host(host):\n        import idna\n\n        try:\n            host = idna.encode(host, uts46=True).decode(\"utf-8\")\n        except idna.IDNAError:\n            raise UnicodeError\n        return host\n\n    def prepare_url(self, url, params):\n        \"\"\"Prepares the given HTTP URL.\"\"\"\n        #: Accept objects that have string representations.\n        #: We're unable to blindly call unicode/str functions\n        #: as this will include the bytestring indicator (b'')\n        #: on python 3.x.\n        #: https://github.com/psf/requests/pull/2238\n        if isinstance(url, bytes):\n            url = url.decode(\"utf8\")\n        else:\n            url = str(url)\n\n        # Remove leading whitespaces from url\n        url = url.lstrip()\n\n        # Don't do any URL preparati"}, {"start_line": 25000, "end_line": 27000, "belongs_to": {"file_name": "sessions.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "equest, **kwargs):\n        \"\"\"Send a given PreparedRequest.\n\n        :rtype: requests.Response\n        \"\"\"\n        # Set defaults that the hooks can utilize to ensure they always have\n        # the correct parameters to reproduce the previous request.\n        kwargs.setdefault(\"stream\", self.stream)\n        kwargs.setdefault(\"verify\", self.verify)\n        kwargs.setdefault(\"cert\", self.cert)\n        if \"proxies\" not in kwargs:\n            kwargs[\"proxies\"] = resolve_proxies(request, self.proxies, self.trust_env)\n\n        # It's possible that users might accidentally send a Request object.\n        # Guard against that specific failure case.\n        if isinstance(request, Request):\n            raise ValueError(\"You can only send PreparedRequests.\")\n\n        # Set up variables needed for resolve_redirects and dispatching of hooks\n        allow_redirects = kwargs.pop(\"allow_redirects\", True)\n        stream = kwargs.get(\"stream\")\n        hooks = request.hooks\n\n        # Get the appropriate adapter to use\n        adapter = self.get_adapter(url=request.url)\n\n        # Start time (approximately) of the request\n        start = preferred_clock()\n\n        # Send the request\n        r = adapter.send(request, **kwargs)\n\n        # Total elapsed time of the request (approximately)\n        elapsed = preferred_clock() - start\n        r.elapsed = timedelta(seconds=elapsed)\n\n        # Response manipulation hooks\n        r = dispatch_hook(\"response\", hooks, r, **kwargs)\n\n        # Persist cookies\n        if r.history:\n            # If the hooks create history then we want those cookies too\n            for resp in r.history:\n                extract_cookies_to_jar(self.cookies, resp.request, resp.raw)\n\n        extract_cookies_to_jar(self.cookies, request, r.raw)\n\n        # Resolve redirects if allowed.\n        if allow_redirects:\n            # Redirect resolving generator.\n            gen = self.resolve_redirects(r, request, **kwargs)\n            history = [resp for resp in gen]\n        "}, {"start_line": 7000, "end_line": 9000, "belongs_to": {"file_name": "models.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "method to use.\n    :param url: URL to send.\n    :param headers: dictionary of headers to send.\n    :param files: dictionary of {filename: fileobject} files to multipart upload.\n    :param data: the body to attach to the request. If a dictionary or\n        list of tuples ``[(key, value)]`` is provided, form-encoding will\n        take place.\n    :param json: json for the body to attach to the request (if files or data is not specified).\n    :param params: URL parameters to append to the URL. If a dictionary or\n        list of tuples ``[(key, value)]`` is provided, form-encoding will\n        take place.\n    :param auth: Auth handler or (user, pass) tuple.\n    :param cookies: dictionary or CookieJar of cookies to attach to this request.\n    :param hooks: dictionary of callback hooks, for internal usage.\n\n    Usage::\n\n      >>> import requests\n      >>> req = requests.Request('GET', 'https://httpbin.org/get')\n      >>> req.prepare()\n      <PreparedRequest [GET]>\n    \"\"\"\n\n    def __init__(\n        self,\n        method=None,\n        url=None,\n        headers=None,\n        files=None,\n        data=None,\n        params=None,\n        auth=None,\n        cookies=None,\n        hooks=None,\n        json=None,\n    ):\n        # Default empty dicts for dict params.\n        data = [] if data is None else data\n        files = [] if files is None else files\n        headers = {} if headers is None else headers\n        params = {} if params is None else params\n        hooks = {} if hooks is None else hooks\n\n        self.hooks = default_hooks()\n        for k, v in list(hooks.items()):\n            self.register_hook(event=k, hook=v)\n\n        self.method = method\n        self.url = url\n        self.headers = headers\n        self.files = files\n        self.data = data\n        self.json = json\n        self.params = params\n        self.auth = auth\n        self.cookies = cookies\n\n    def __repr__(self):\n        return f\"<Request [{self.method}]>\"\n\n    def prepare(self):\n        \"\"\"Constructs a :"}, {"start_line": 19000, "end_line": 21000, "belongs_to": {"file_name": "models.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "=\"\"):\n        \"\"\"Prepares the given HTTP auth data.\"\"\"\n\n        # If no Auth is explicitly provided, extract it from the URL first.\n        if auth is None:\n            url_auth = get_auth_from_url(self.url)\n            auth = url_auth if any(url_auth) else None\n\n        if auth:\n            if isinstance(auth, tuple) and len(auth) == 2:\n                # special-case basic HTTP auth\n                auth = HTTPBasicAuth(*auth)\n\n            # Allow auth to make its changes.\n            r = auth(self)\n\n            # Update self to reflect the auth changes.\n            self.__dict__.update(r.__dict__)\n\n            # Recompute Content-Length\n            self.prepare_content_length(self.body)\n\n    def prepare_cookies(self, cookies):\n        \"\"\"Prepares the given HTTP cookie data.\n\n        This function eventually generates a ``Cookie`` header from the\n        given cookies using cookielib. Due to cookielib's design, the header\n        will not be regenerated if it already exists, meaning this function\n        can only be called once for the life of the\n        :class:`PreparedRequest <PreparedRequest>` object. Any subsequent calls\n        to ``prepare_cookies`` will have no actual effect, unless the \"Cookie\"\n        header is removed beforehand.\n        \"\"\"\n        if isinstance(cookies, cookielib.CookieJar):\n            self._cookies = cookies\n        else:\n            self._cookies = cookiejar_from_dict(cookies)\n\n        cookie_header = get_cookie_header(self._cookies, self)\n        if cookie_header is not None:\n            self.headers[\"Cookie\"] = cookie_header\n\n    def prepare_hooks(self, hooks):\n        \"\"\"Prepares the given hooks.\"\"\"\n        # hooks can be passed as None to the prepare method and to this\n        # method. To prevent iterating over None, simply use an empty list\n        # if hooks is False-y\n        hooks = hooks or []\n        for event in hooks:\n            self.register_hook(event, hooks[event])\n\n\nclass Response:\n    \"\"\"The :class:`Response <Respo"}], "retrieved_count": 10, "cost_time": 4.439103841781616}
{"question": "Where does the redirect handling flow from response analysis through location extraction to new request creation?", "answer": null, "relative_code_list": null, "ground_truth": "The redirect handling flow is implemented in src/requests/sessions.py through SessionRedirectMixin class: 1) Response analysis occurs in SessionRedirectMixin.get_redirect_target() which checks if response.is_redirect and extracts the Location header; 2) Location extraction and URL processing happens in SessionRedirectMixin.resolve_redirects() which handles relative URLs, scheme-less URLs, and fragment preservation; 3) New request creation occurs in SessionRedirectMixin.resolve_redirects() where prepared_request = req.copy() creates a copy of the original request; 4) Method rewriting is handled by SessionRedirectMixin.rebuild_method() which changes HTTP methods according to redirect status codes; 5) Authentication stripping is managed by SessionRedirectMixin.should_strip_auth() when redirecting to different hosts. The complete flow is: Response received  get_redirect_target()  resolve_redirects()  req.copy()  rebuild_method()  should_strip_auth()  new PreparedRequest  adapter.send()  recursive redirect handling.", "score": null, "retrieved_content": [{"start_line": 7000, "end_line": 9000, "belongs_to": {"file_name": "sessions.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "1 7.1.2)\n            parsed = urlparse(url)\n            if parsed.fragment == \"\" and previous_fragment:\n                parsed = parsed._replace(fragment=previous_fragment)\n            elif parsed.fragment:\n                previous_fragment = parsed.fragment\n            url = parsed.geturl()\n\n            # Facilitate relative 'location' headers, as allowed by RFC 7231.\n            # (e.g. '/path/to/resource' instead of 'http://domain.tld/path/to/resource')\n            # Compliant with RFC3986, we percent encode the url.\n            if not parsed.netloc:\n                url = urljoin(resp.url, requote_uri(url))\n            else:\n                url = requote_uri(url)\n\n            prepared_request.url = to_native_string(url)\n\n            self.rebuild_method(prepared_request, resp)\n\n            # https://github.com/psf/requests/issues/1084\n            if resp.status_code not in (\n                codes.temporary_redirect,\n                codes.permanent_redirect,\n            ):\n                # https://github.com/psf/requests/issues/3490\n                purged_headers = (\"Content-Length\", \"Content-Type\", \"Transfer-Encoding\")\n                for header in purged_headers:\n                    prepared_request.headers.pop(header, None)\n                prepared_request.body = None\n\n            headers = prepared_request.headers\n            headers.pop(\"Cookie\", None)\n\n            # Extract any cookies sent on the response to the cookiejar\n            # in the new request. Because we've mutated our copied prepared\n            # request, use the old one that we haven't yet touched.\n            extract_cookies_to_jar(prepared_request._cookies, req, resp.raw)\n            merge_cookies(prepared_request._cookies, self.cookies)\n            prepared_request.prepare_cookies(prepared_request._cookies)\n\n            # Rebuild auth and proxy information.\n            proxies = self.rebuild_proxies(prepared_request, proxies)\n            self.rebuild_auth(prepared_request, resp)\n\n         "}, {"start_line": 6000, "end_line": 8000, "belongs_to": {"file_name": "sessions.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "  # Update history and keep track of redirects.\n            # resp.history must ignore the original request in this loop\n            hist.append(resp)\n            resp.history = hist[1:]\n\n            try:\n                resp.content  # Consume socket so it can be released\n            except (ChunkedEncodingError, ContentDecodingError, RuntimeError):\n                resp.raw.read(decode_content=False)\n\n            if len(resp.history) >= self.max_redirects:\n                raise TooManyRedirects(\n                    f\"Exceeded {self.max_redirects} redirects.\", response=resp\n                )\n\n            # Release the connection back into the pool.\n            resp.close()\n\n            # Handle redirection without scheme (see: RFC 1808 Section 4)\n            if url.startswith(\"//\"):\n                parsed_rurl = urlparse(resp.url)\n                url = \":\".join([to_native_string(parsed_rurl.scheme), url])\n\n            # Normalize url case and attach previous fragment if needed (RFC 7231 7.1.2)\n            parsed = urlparse(url)\n            if parsed.fragment == \"\" and previous_fragment:\n                parsed = parsed._replace(fragment=previous_fragment)\n            elif parsed.fragment:\n                previous_fragment = parsed.fragment\n            url = parsed.geturl()\n\n            # Facilitate relative 'location' headers, as allowed by RFC 7231.\n            # (e.g. '/path/to/resource' instead of 'http://domain.tld/path/to/resource')\n            # Compliant with RFC3986, we percent encode the url.\n            if not parsed.netloc:\n                url = urljoin(resp.url, requote_uri(url))\n            else:\n                url = requote_uri(url)\n\n            prepared_request.url = to_native_string(url)\n\n            self.rebuild_method(prepared_request, resp)\n\n            # https://github.com/psf/requests/issues/1084\n            if resp.status_code not in (\n                codes.temporary_redirect,\n                codes.permanent_redirect,\n            ):\n           "}, {"start_line": 4000, "end_line": 6000, "belongs_to": {"file_name": "sessions.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "ion in latin1.\n            location = location.encode(\"latin1\")\n            return to_native_string(location, \"utf8\")\n        return None\n\n    def should_strip_auth(self, old_url, new_url):\n        \"\"\"Decide whether Authorization header should be removed when redirecting\"\"\"\n        old_parsed = urlparse(old_url)\n        new_parsed = urlparse(new_url)\n        if old_parsed.hostname != new_parsed.hostname:\n            return True\n        # Special case: allow http -> https redirect when using the standard\n        # ports. This isn't specified by RFC 7235, but is kept to avoid\n        # breaking backwards compatibility with older versions of requests\n        # that allowed any redirects on the same host.\n        if (\n            old_parsed.scheme == \"http\"\n            and old_parsed.port in (80, None)\n            and new_parsed.scheme == \"https\"\n            and new_parsed.port in (443, None)\n        ):\n            return False\n\n        # Handle default port usage corresponding to scheme.\n        changed_port = old_parsed.port != new_parsed.port\n        changed_scheme = old_parsed.scheme != new_parsed.scheme\n        default_port = (DEFAULT_PORTS.get(old_parsed.scheme, None), None)\n        if (\n            not changed_scheme\n            and old_parsed.port in default_port\n            and new_parsed.port in default_port\n        ):\n            return False\n\n        # Standard case: root URI must match\n        return changed_port or changed_scheme\n\n    def resolve_redirects(\n        self,\n        resp,\n        req,\n        stream=False,\n        timeout=None,\n        verify=True,\n        cert=None,\n        proxies=None,\n        yield_requests=False,\n        **adapter_kwargs,\n    ):\n        \"\"\"Receives a Response. Returns a generator of Responses or Requests.\"\"\"\n\n        hist = []  # keep track of history\n\n        url = self.get_redirect_target(resp)\n        previous_fragment = urlparse(req.url).fragment\n        while url:\n            prepared_request = req.copy()\n\n          "}, {"start_line": 3000, "end_line": 5000, "belongs_to": {"file_name": "sessions.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": " get_redirect_target(self, resp):\n        \"\"\"Receives a Response. Returns a redirect URI or ``None``\"\"\"\n        # Due to the nature of how requests processes redirects this method will\n        # be called at least once upon the original response and at least twice\n        # on each subsequent redirect response (if any).\n        # If a custom mixin is used to handle this logic, it may be advantageous\n        # to cache the redirect location onto the response object as a private\n        # attribute.\n        if resp.is_redirect:\n            location = resp.headers[\"location\"]\n            # Currently the underlying http module on py3 decode headers\n            # in latin1, but empirical evidence suggests that latin1 is very\n            # rarely used with non-ASCII characters in HTTP headers.\n            # It is more likely to get UTF8 header rather than latin1.\n            # This causes incorrect handling of UTF8 encoded location headers.\n            # To solve this, we re-encode the location in latin1.\n            location = location.encode(\"latin1\")\n            return to_native_string(location, \"utf8\")\n        return None\n\n    def should_strip_auth(self, old_url, new_url):\n        \"\"\"Decide whether Authorization header should be removed when redirecting\"\"\"\n        old_parsed = urlparse(old_url)\n        new_parsed = urlparse(new_url)\n        if old_parsed.hostname != new_parsed.hostname:\n            return True\n        # Special case: allow http -> https redirect when using the standard\n        # ports. This isn't specified by RFC 7235, but is kept to avoid\n        # breaking backwards compatibility with older versions of requests\n        # that allowed any redirects on the same host.\n        if (\n            old_parsed.scheme == \"http\"\n            and old_parsed.port in (80, None)\n            and new_parsed.scheme == \"https\"\n            and new_parsed.port in (443, None)\n        ):\n            return False\n\n        # Handle default port usage corresponding to scheme.\n"}, {"start_line": 10000, "end_line": 12000, "belongs_to": {"file_name": "test_requests.py", "upper_path": "/data2/raymone/swebench-repos/requests/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "):\n        r = requests.post(httpbin(\"status\", \"303\"))\n        assert r.status_code == 200\n        assert r.request.method == \"GET\"\n        assert r.history[0].status_code == 303\n        assert r.history[0].is_redirect\n\n    def test_http_303_doesnt_change_head_to_get(self, httpbin):\n        r = requests.head(httpbin(\"status\", \"303\"), allow_redirects=True)\n        assert r.status_code == 200\n        assert r.request.method == \"HEAD\"\n        assert r.history[0].status_code == 303\n        assert r.history[0].is_redirect\n\n    def test_header_and_body_removal_on_redirect(self, httpbin):\n        purged_headers = (\"Content-Length\", \"Content-Type\")\n        ses = requests.Session()\n        req = requests.Request(\"POST\", httpbin(\"post\"), data={\"test\": \"data\"})\n        prep = ses.prepare_request(req)\n        resp = ses.send(prep)\n\n        # Mimic a redirect response\n        resp.status_code = 302\n        resp.headers[\"location\"] = \"get\"\n\n        # Run request through resolve_redirects\n        next_resp = next(ses.resolve_redirects(resp, prep))\n        assert next_resp.request.body is None\n        for header in purged_headers:\n            assert header not in next_resp.request.headers\n\n    def test_transfer_enc_removal_on_redirect(self, httpbin):\n        purged_headers = (\"Transfer-Encoding\", \"Content-Type\")\n        ses = requests.Session()\n        req = requests.Request(\"POST\", httpbin(\"post\"), data=(b\"x\" for x in range(1)))\n        prep = ses.prepare_request(req)\n        assert \"Transfer-Encoding\" in prep.headers\n\n        # Create Response to avoid https://github.com/kevin1024/pytest-httpbin/issues/33\n        resp = requests.Response()\n        resp.raw = io.BytesIO(b\"the content\")\n        resp.request = prep\n        setattr(resp.raw, \"release_conn\", lambda *args: args)\n\n        # Mimic a redirect response\n        resp.status_code = 302\n        resp.headers[\"location\"] = httpbin(\"get\")\n\n        # Run request through resolve_redirect\n        next_resp = next(ses.resolve_redirec"}, {"start_line": 9000, "end_line": 11000, "belongs_to": {"file_name": "test_requests.py", "upper_path": "/data2/raymone/swebench-repos/requests/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "    assert r.history[0].is_redirect\n\n    def test_http_301_doesnt_change_head_to_get(self, httpbin):\n        r = requests.head(httpbin(\"status\", \"301\"), allow_redirects=True)\n        print(r.content)\n        assert r.status_code == 200\n        assert r.request.method == \"HEAD\"\n        assert r.history[0].status_code == 301\n        assert r.history[0].is_redirect\n\n    def test_http_302_changes_post_to_get(self, httpbin):\n        r = requests.post(httpbin(\"status\", \"302\"))\n        assert r.status_code == 200\n        assert r.request.method == \"GET\"\n        assert r.history[0].status_code == 302\n        assert r.history[0].is_redirect\n\n    def test_http_302_doesnt_change_head_to_get(self, httpbin):\n        r = requests.head(httpbin(\"status\", \"302\"), allow_redirects=True)\n        assert r.status_code == 200\n        assert r.request.method == \"HEAD\"\n        assert r.history[0].status_code == 302\n        assert r.history[0].is_redirect\n\n    def test_http_303_changes_post_to_get(self, httpbin):\n        r = requests.post(httpbin(\"status\", \"303\"))\n        assert r.status_code == 200\n        assert r.request.method == \"GET\"\n        assert r.history[0].status_code == 303\n        assert r.history[0].is_redirect\n\n    def test_http_303_doesnt_change_head_to_get(self, httpbin):\n        r = requests.head(httpbin(\"status\", \"303\"), allow_redirects=True)\n        assert r.status_code == 200\n        assert r.request.method == \"HEAD\"\n        assert r.history[0].status_code == 303\n        assert r.history[0].is_redirect\n\n    def test_header_and_body_removal_on_redirect(self, httpbin):\n        purged_headers = (\"Content-Length\", \"Content-Type\")\n        ses = requests.Session()\n        req = requests.Request(\"POST\", httpbin(\"post\"), data={\"test\": \"data\"})\n        prep = ses.prepare_request(req)\n        resp = ses.send(prep)\n\n        # Mimic a redirect response\n        resp.status_code = 302\n        resp.headers[\"location\"] = \"get\"\n\n        # Run request through resolve_redirects\n        nex"}, {"start_line": 68000, "end_line": 70000, "belongs_to": {"file_name": "test_requests.py", "upper_path": "/data2/raymone/swebench-repos/requests/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "://example.com/bar\"\n        )\n        assert not s.should_strip_auth(\n            \"http://example.com:80/foo\", \"https://example.com/bar\"\n        )\n        assert not s.should_strip_auth(\n            \"http://example.com/foo\", \"https://example.com:443/bar\"\n        )\n        # Non-standard ports should trigger stripping\n        assert s.should_strip_auth(\n            \"http://example.com:8080/foo\", \"https://example.com/bar\"\n        )\n        assert s.should_strip_auth(\n            \"http://example.com/foo\", \"https://example.com:8443/bar\"\n        )\n\n    def test_should_strip_auth_port_change(self):\n        s = requests.Session()\n        assert s.should_strip_auth(\n            \"http://example.com:1234/foo\", \"https://example.com:4321/bar\"\n        )\n\n    @pytest.mark.parametrize(\n        \"old_uri, new_uri\",\n        (\n            (\"https://example.com:443/foo\", \"https://example.com/bar\"),\n            (\"http://example.com:80/foo\", \"http://example.com/bar\"),\n            (\"https://example.com/foo\", \"https://example.com:443/bar\"),\n            (\"http://example.com/foo\", \"http://example.com:80/bar\"),\n        ),\n    )\n    def test_should_strip_auth_default_port(self, old_uri, new_uri):\n        s = requests.Session()\n        assert not s.should_strip_auth(old_uri, new_uri)\n\n    def test_manual_redirect_with_partial_body_read(self, httpbin):\n        s = requests.Session()\n        r1 = s.get(httpbin(\"redirect/2\"), allow_redirects=False, stream=True)\n        assert r1.is_redirect\n        rg = s.resolve_redirects(r1, r1.request, stream=True)\n\n        # read only the first eight bytes of the response body,\n        # then follow the redirect\n        r1.iter_content(8)\n        r2 = next(rg)\n        assert r2.is_redirect\n\n        # read all of the response via iter_content,\n        # then follow the redirect\n        for _ in r2.iter_content():\n            pass\n        r3 = next(rg)\n        assert not r3.is_redirect\n\n    def test_prepare_body_position_non_stream(self):\n        data = b\"the da"}, {"start_line": 69000, "end_line": 71000, "belongs_to": {"file_name": "test_requests.py", "upper_path": "/data2/raymone/swebench-repos/requests/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": " \"https://example.com:443/bar\"),\n            (\"http://example.com/foo\", \"http://example.com:80/bar\"),\n        ),\n    )\n    def test_should_strip_auth_default_port(self, old_uri, new_uri):\n        s = requests.Session()\n        assert not s.should_strip_auth(old_uri, new_uri)\n\n    def test_manual_redirect_with_partial_body_read(self, httpbin):\n        s = requests.Session()\n        r1 = s.get(httpbin(\"redirect/2\"), allow_redirects=False, stream=True)\n        assert r1.is_redirect\n        rg = s.resolve_redirects(r1, r1.request, stream=True)\n\n        # read only the first eight bytes of the response body,\n        # then follow the redirect\n        r1.iter_content(8)\n        r2 = next(rg)\n        assert r2.is_redirect\n\n        # read all of the response via iter_content,\n        # then follow the redirect\n        for _ in r2.iter_content():\n            pass\n        r3 = next(rg)\n        assert not r3.is_redirect\n\n    def test_prepare_body_position_non_stream(self):\n        data = b\"the data\"\n        prep = requests.Request(\"GET\", \"http://example.com\", data=data).prepare()\n        assert prep._body_position is None\n\n    def test_rewind_body(self):\n        data = io.BytesIO(b\"the data\")\n        prep = requests.Request(\"GET\", \"http://example.com\", data=data).prepare()\n        assert prep._body_position == 0\n        assert prep.body.read() == b\"the data\"\n\n        # the data has all been read\n        assert prep.body.read() == b\"\"\n\n        # rewind it back\n        requests.utils.rewind_body(prep)\n        assert prep.body.read() == b\"the data\"\n\n    def test_rewind_partially_read_body(self):\n        data = io.BytesIO(b\"the data\")\n        data.read(4)  # read some data\n        prep = requests.Request(\"GET\", \"http://example.com\", data=data).prepare()\n        assert prep._body_position == 4\n        assert prep.body.read() == b\"data\"\n\n        # the data has all been read\n        assert prep.body.read() == b\"\"\n\n        # rewind it back\n        requests.utils.rewind_body(prep)\n    "}, {"start_line": 11000, "end_line": 13000, "belongs_to": {"file_name": "test_lowlevel.py", "upper_path": "/data2/raymone/swebench-repos/requests/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "results[0]) > 0\n\n\ndef test_redirect_rfc1808_to_non_ascii_location():\n    path = ''\n    expected_path = b'%C5%A1'\n    redirect_request = []  # stores the second request to the server\n\n    def redirect_resp_handler(sock):\n        consume_socket_content(sock, timeout=0.5)\n        location = f'//{host}:{port}/{path}'\n        sock.send(\n            (\n                b'HTTP/1.1 301 Moved Permanently\\r\\n'\n                b'Content-Length: 0\\r\\n'\n                b'Location: %s\\r\\n'\n                b'\\r\\n'\n            ) % location.encode('utf8')\n        )\n        redirect_request.append(consume_socket_content(sock, timeout=0.5))\n        sock.send(b'HTTP/1.1 200 OK\\r\\n\\r\\n')\n\n    close_server = threading.Event()\n    server = Server(redirect_resp_handler, wait_to_close_event=close_server)\n\n    with server as (host, port):\n        url = f'http://{host}:{port}'\n        r = requests.get(url=url, allow_redirects=True)\n        assert r.status_code == 200\n        assert len(r.history) == 1\n        assert r.history[0].status_code == 301\n        assert redirect_request[0].startswith(b'GET /' + expected_path + b' HTTP/1.1')\n        assert r.url == '{}/{}'.format(url, expected_path.decode('ascii'))\n\n        close_server.set()\n\n\ndef test_fragment_not_sent_with_request():\n    \"\"\"Verify that the fragment portion of a URI isn't sent to the server.\"\"\"\n    close_server = threading.Event()\n    server = Server(echo_response_handler, wait_to_close_event=close_server)\n\n    with server as (host, port):\n        url = f'http://{host}:{port}/path/to/thing/#view=edit&token=hunter2'\n        r = requests.get(url)\n        raw_request = r.content\n\n        assert r.status_code == 200\n        headers, body = raw_request.split(b'\\r\\n\\r\\n', 1)\n        status_line, headers = headers.split(b'\\r\\n', 1)\n\n        assert status_line == b'GET /path/to/thing/ HTTP/1.1'\n        for frag in (b'view', b'edit', b'token', b'hunter2'):\n            assert frag not in headers\n            assert frag not in body\n\n        clo"}, {"start_line": 7000, "end_line": 9000, "belongs_to": {"file_name": "test_requests.py", "upper_path": "/data2/raymone/swebench-repos/requests/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "sts.post(\n            httpbin(\"redirect-to\"),\n            data=\"test\",\n            params={\"url\": \"post\", \"status_code\": 307},\n        )\n        assert r.status_code == 200\n        assert r.history[0].status_code == 307\n        assert r.history[0].is_redirect\n        assert r.json()[\"data\"] == \"test\"\n\n    def test_HTTP_307_ALLOW_REDIRECT_POST_WITH_SEEKABLE(self, httpbin):\n        byte_str = b\"test\"\n        r = requests.post(\n            httpbin(\"redirect-to\"),\n            data=io.BytesIO(byte_str),\n            params={\"url\": \"post\", \"status_code\": 307},\n        )\n        assert r.status_code == 200\n        assert r.history[0].status_code == 307\n        assert r.history[0].is_redirect\n        assert r.json()[\"data\"] == byte_str.decode(\"utf-8\")\n\n    def test_HTTP_302_TOO_MANY_REDIRECTS(self, httpbin):\n        try:\n            requests.get(httpbin(\"relative-redirect\", \"50\"))\n        except TooManyRedirects as e:\n            url = httpbin(\"relative-redirect\", \"20\")\n            assert e.request.url == url\n            assert e.response.url == url\n            assert len(e.response.history) == 30\n        else:\n            pytest.fail(\"Expected redirect to raise TooManyRedirects but it did not\")\n\n    def test_HTTP_302_TOO_MANY_REDIRECTS_WITH_PARAMS(self, httpbin):\n        s = requests.session()\n        s.max_redirects = 5\n        try:\n            s.get(httpbin(\"relative-redirect\", \"50\"))\n        except TooManyRedirects as e:\n            url = httpbin(\"relative-redirect\", \"45\")\n            assert e.request.url == url\n            assert e.response.url == url\n            assert len(e.response.history) == 5\n        else:\n            pytest.fail(\n                \"Expected custom max number of redirects to be respected but was not\"\n            )\n\n    def test_http_301_changes_post_to_get(self, httpbin):\n        r = requests.post(httpbin(\"status\", \"301\"))\n        assert r.status_code == 200\n        assert r.request.method == \"GET\"\n        assert r.history[0].status_code == 301\n    "}], "retrieved_count": 10, "cost_time": 4.404792547225952}
{"question": "Why does Requests implement a session-based architecture instead of stateless individual requests?", "answer": null, "relative_code_list": null, "ground_truth": "Requests implements a session-based architecture to provide essential stateful features that are crucial for real-world HTTP client usage: 1) Connection pooling - Sessions maintain persistent connections to hosts, significantly improving performance for multiple requests to the same server; 2) Cookie persistence - Sessions automatically maintain cookies across requests, essential for web applications and API authentication; 3) Authentication persistence - Sessions can store and reuse authentication credentials, avoiding repeated authentication for each request; 4) Configuration management - Sessions provide a way to set default headers, proxies, and other settings that apply to all requests; 5) Resource management - Sessions properly manage connection lifecycle, preventing resource leaks and ensuring efficient resource utilization; 6) State consistency - Sessions ensure consistent behavior across multiple requests (e.g., same headers, same authentication); 7) Performance optimization - Connection reuse and other optimizations are only possible with session-based state management; 8) Real-world compatibility - Most web applications and APIs require session-based features like cookie handling and connection reuse; 9) Thread safety - Sessions provide thread-safe state management for concurrent applications; 10) Cleanup and resource management - Sessions implement proper cleanup protocols to ensure resources are released appropriately.", "score": null, "retrieved_content": [{"start_line": 13000, "end_line": 15000, "belongs_to": {"file_name": "sessions.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "POST is responded to with a 301, turn it into a GET.\n        # This bizarre behaviour is explained in Issue 1704.\n        if response.status_code == codes.moved and method == \"POST\":\n            method = \"GET\"\n\n        prepared_request.method = method\n\n\nclass Session(SessionRedirectMixin):\n    \"\"\"A Requests session.\n\n    Provides cookie persistence, connection-pooling, and configuration.\n\n    Basic Usage::\n\n      >>> import requests\n      >>> s = requests.Session()\n      >>> s.get('https://httpbin.org/get')\n      <Response [200]>\n\n    Or as a context manager::\n\n      >>> with requests.Session() as s:\n      ...     s.get('https://httpbin.org/get')\n      <Response [200]>\n    \"\"\"\n\n    __attrs__ = [\n        \"headers\",\n        \"cookies\",\n        \"auth\",\n        \"proxies\",\n        \"hooks\",\n        \"params\",\n        \"verify\",\n        \"cert\",\n        \"adapters\",\n        \"stream\",\n        \"trust_env\",\n        \"max_redirects\",\n    ]\n\n    def __init__(self):\n        #: A case-insensitive dictionary of headers to be sent on each\n        #: :class:`Request <Request>` sent from this\n        #: :class:`Session <Session>`.\n        self.headers = default_headers()\n\n        #: Default Authentication tuple or object to attach to\n        #: :class:`Request <Request>`.\n        self.auth = None\n\n        #: Dictionary mapping protocol or protocol and host to the URL of the proxy\n        #: (e.g. {'http': 'foo.bar:3128', 'http://host.name': 'foo.bar:4012'}) to\n        #: be used on each :class:`Request <Request>`.\n        self.proxies = {}\n\n        #: Event-handling hooks.\n        self.hooks = default_hooks()\n\n        #: Dictionary of querystring data to attach to each\n        #: :class:`Request <Request>`. The dictionary values may be lists for\n        #: representing multivalued query parameters.\n        self.params = {}\n\n        #: Stream response content default.\n        self.stream = False\n\n        #: SSL Verification default.\n        #: Defaults to `True`, requiring requests to verif"}, {"start_line": 12000, "end_line": 14000, "belongs_to": {"file_name": "sessions.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "          username, password = None, None\n\n        # urllib3 handles proxy authorization for us in the standard adapter.\n        # Avoid appending this to TLS tunneled requests where it may be leaked.\n        if not scheme.startswith(\"https\") and username and password:\n            headers[\"Proxy-Authorization\"] = _basic_auth_str(username, password)\n\n        return new_proxies\n\n    def rebuild_method(self, prepared_request, response):\n        \"\"\"When being redirected we may want to change the method of the request\n        based on certain specs or browser behavior.\n        \"\"\"\n        method = prepared_request.method\n\n        # https://tools.ietf.org/html/rfc7231#section-6.4.4\n        if response.status_code == codes.see_other and method != \"HEAD\":\n            method = \"GET\"\n\n        # Do what the browsers do, despite standards...\n        # First, turn 302s into GETs.\n        if response.status_code == codes.found and method != \"HEAD\":\n            method = \"GET\"\n\n        # Second, if a POST is responded to with a 301, turn it into a GET.\n        # This bizarre behaviour is explained in Issue 1704.\n        if response.status_code == codes.moved and method == \"POST\":\n            method = \"GET\"\n\n        prepared_request.method = method\n\n\nclass Session(SessionRedirectMixin):\n    \"\"\"A Requests session.\n\n    Provides cookie persistence, connection-pooling, and configuration.\n\n    Basic Usage::\n\n      >>> import requests\n      >>> s = requests.Session()\n      >>> s.get('https://httpbin.org/get')\n      <Response [200]>\n\n    Or as a context manager::\n\n      >>> with requests.Session() as s:\n      ...     s.get('https://httpbin.org/get')\n      <Response [200]>\n    \"\"\"\n\n    __attrs__ = [\n        \"headers\",\n        \"cookies\",\n        \"auth\",\n        \"proxies\",\n        \"hooks\",\n        \"params\",\n        \"verify\",\n        \"cert\",\n        \"adapters\",\n        \"stream\",\n        \"trust_env\",\n        \"max_redirects\",\n    ]\n\n    def __init__(self):\n        #: A case-insensitive dictiona"}, {"start_line": 14000, "end_line": 16000, "belongs_to": {"file_name": "sessions.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "ry of headers to be sent on each\n        #: :class:`Request <Request>` sent from this\n        #: :class:`Session <Session>`.\n        self.headers = default_headers()\n\n        #: Default Authentication tuple or object to attach to\n        #: :class:`Request <Request>`.\n        self.auth = None\n\n        #: Dictionary mapping protocol or protocol and host to the URL of the proxy\n        #: (e.g. {'http': 'foo.bar:3128', 'http://host.name': 'foo.bar:4012'}) to\n        #: be used on each :class:`Request <Request>`.\n        self.proxies = {}\n\n        #: Event-handling hooks.\n        self.hooks = default_hooks()\n\n        #: Dictionary of querystring data to attach to each\n        #: :class:`Request <Request>`. The dictionary values may be lists for\n        #: representing multivalued query parameters.\n        self.params = {}\n\n        #: Stream response content default.\n        self.stream = False\n\n        #: SSL Verification default.\n        #: Defaults to `True`, requiring requests to verify the TLS certificate at the\n        #: remote end.\n        #: If verify is set to `False`, requests will accept any TLS certificate\n        #: presented by the server, and will ignore hostname mismatches and/or\n        #: expired certificates, which will make your application vulnerable to\n        #: man-in-the-middle (MitM) attacks.\n        #: Only set this to `False` for testing.\n        self.verify = True\n\n        #: SSL client certificate default, if String, path to ssl client\n        #: cert file (.pem). If Tuple, ('cert', 'key') pair.\n        self.cert = None\n\n        #: Maximum number of redirects allowed. If the request exceeds this\n        #: limit, a :class:`TooManyRedirects` exception is raised.\n        #: This defaults to requests.models.DEFAULT_REDIRECT_LIMIT, which is\n        #: 30.\n        self.max_redirects = DEFAULT_REDIRECT_LIMIT\n\n        #: Trust environment settings for proxy configuration, default\n        #: authentication and similar.\n        self.trust_env = Tru"}, {"start_line": 74000, "end_line": 76000, "belongs_to": {"file_name": "test_requests.py", "upper_path": "/data2/raymone/swebench-repos/requests/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "name, password)\n        assert isinstance(s, builtin_str)\n        assert s == auth_str\n\n    def test_requests_history_is_saved(self, httpbin):\n        r = requests.get(httpbin(\"redirect/5\"))\n        total = r.history[-1].history\n        i = 0\n        for item in r.history:\n            assert item.history == total[0:i]\n            i += 1\n\n    def test_json_param_post_content_type_works(self, httpbin):\n        r = requests.post(httpbin(\"post\"), json={\"life\": 42})\n        assert r.status_code == 200\n        assert \"application/json\" in r.request.headers[\"Content-Type\"]\n        assert {\"life\": 42} == r.json()[\"json\"]\n\n    def test_json_param_post_should_not_override_data_param(self, httpbin):\n        r = requests.Request(\n            method=\"POST\",\n            url=httpbin(\"post\"),\n            data={\"stuff\": \"elixr\"},\n            json={\"music\": \"flute\"},\n        )\n        prep = r.prepare()\n        assert \"stuff=elixr\" == prep.body\n\n    def test_response_iter_lines(self, httpbin):\n        r = requests.get(httpbin(\"stream/4\"), stream=True)\n        assert r.status_code == 200\n\n        it = r.iter_lines()\n        next(it)\n        assert len(list(it)) == 3\n\n    def test_response_context_manager(self, httpbin):\n        with requests.get(httpbin(\"stream/4\"), stream=True) as response:\n            assert isinstance(response, requests.Response)\n\n        assert response.raw.closed\n\n    def test_unconsumed_session_response_closes_connection(self, httpbin):\n        s = requests.session()\n\n        with contextlib.closing(s.get(httpbin(\"stream/4\"), stream=True)) as response:\n            pass\n\n        assert response._content_consumed is False\n        assert response.raw.closed\n\n    @pytest.mark.xfail\n    def test_response_iter_lines_reentrant(self, httpbin):\n        \"\"\"Response.iter_lines() is not reentrant safe\"\"\"\n        r = requests.get(httpbin(\"stream/4\"), stream=True)\n        assert r.status_code == 200\n\n        next(r.iter_lines())\n        assert len(list(r.iter_lines())) == 3\n\n"}, {"start_line": 2000, "end_line": 4000, "belongs_to": {"file_name": "test_requests.py", "upper_path": "/data2/raymone/swebench-repos/requests/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": " requests.session\n        requests.session().get\n        requests.session().head\n        requests.get\n        requests.head\n        requests.put\n        requests.patch\n        requests.post\n        # Not really an entry point, but people rely on it.\n        from requests.packages.urllib3.poolmanager import PoolManager  # noqa:F401\n\n    @pytest.mark.parametrize(\n        \"exception, url\",\n        (\n            (MissingSchema, \"hiwpefhipowhefopw\"),\n            (InvalidSchema, \"localhost:3128\"),\n            (InvalidSchema, \"localhost.localdomain:3128/\"),\n            (InvalidSchema, \"10.122.1.1:3128/\"),\n            (InvalidURL, \"http://\"),\n            (InvalidURL, \"http://*example.com\"),\n            (InvalidURL, \"http://.example.com\"),\n        ),\n    )\n    def test_invalid_url(self, exception, url):\n        with pytest.raises(exception):\n            requests.get(url)\n\n    def test_basic_building(self):\n        req = requests.Request()\n        req.url = \"http://kennethreitz.org/\"\n        req.data = {\"life\": \"42\"}\n\n        pr = req.prepare()\n        assert pr.url == req.url\n        assert pr.body == \"life=42\"\n\n    @pytest.mark.parametrize(\"method\", (\"GET\", \"HEAD\"))\n    def test_no_content_length(self, httpbin, method):\n        req = requests.Request(method, httpbin(method.lower())).prepare()\n        assert \"Content-Length\" not in req.headers\n\n    @pytest.mark.parametrize(\"method\", (\"POST\", \"PUT\", \"PATCH\", \"OPTIONS\"))\n    def test_no_body_content_length(self, httpbin, method):\n        req = requests.Request(method, httpbin(method.lower())).prepare()\n        assert req.headers[\"Content-Length\"] == \"0\"\n\n    @pytest.mark.parametrize(\"method\", (\"POST\", \"PUT\", \"PATCH\", \"OPTIONS\"))\n    def test_empty_content_length(self, httpbin, method):\n        req = requests.Request(method, httpbin(method.lower()), data=\"\").prepare()\n        assert req.headers[\"Content-Length\"] == \"0\"\n\n    def test_override_content_length(self, httpbin):\n        headers = {\"Content-Length\": \"not zero\"}\n       "}, {"start_line": 2000, "end_line": 4000, "belongs_to": {"file_name": "api.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": ".\n    :type allow_redirects: bool\n    :param proxies: (optional) Dictionary mapping protocol to the URL of the proxy.\n    :param verify: (optional) Either a boolean, in which case it controls whether we verify\n            the server's TLS certificate, or a string, in which case it must be a path\n            to a CA bundle to use. Defaults to ``True``.\n    :param stream: (optional) if ``False``, the response content will be immediately downloaded.\n    :param cert: (optional) if String, path to ssl client cert file (.pem). If Tuple, ('cert', 'key') pair.\n    :return: :class:`Response <Response>` object\n    :rtype: requests.Response\n\n    Usage::\n\n      >>> import requests\n      >>> req = requests.request('GET', 'https://httpbin.org/get')\n      >>> req\n      <Response [200]>\n    \"\"\"\n\n    # By using the 'with' statement we are sure the session is closed, thus we\n    # avoid leaving sockets open which can trigger a ResourceWarning in some\n    # cases, and look like a memory leak in others.\n    with sessions.Session() as session:\n        return session.request(method=method, url=url, **kwargs)\n\n\ndef get(url, params=None, **kwargs):\n    r\"\"\"Sends a GET request.\n\n    :param url: URL for the new :class:`Request` object.\n    :param params: (optional) Dictionary, list of tuples or bytes to send\n        in the query string for the :class:`Request`.\n    :param \\*\\*kwargs: Optional arguments that ``request`` takes.\n    :return: :class:`Response <Response>` object\n    :rtype: requests.Response\n    \"\"\"\n\n    return request(\"get\", url, params=params, **kwargs)\n\n\ndef options(url, **kwargs):\n    r\"\"\"Sends an OPTIONS request.\n\n    :param url: URL for the new :class:`Request` object.\n    :param \\*\\*kwargs: Optional arguments that ``request`` takes.\n    :return: :class:`Response <Response>` object\n    :rtype: requests.Response\n    \"\"\"\n\n    return request(\"options\", url, **kwargs)\n\n\ndef head(url, **kwargs):\n    r\"\"\"Sends a HEAD request.\n\n    :param url: URL for the new :class:`Request` obje"}, {"start_line": 15000, "end_line": 17000, "belongs_to": {"file_name": "sessions.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "y the TLS certificate at the\n        #: remote end.\n        #: If verify is set to `False`, requests will accept any TLS certificate\n        #: presented by the server, and will ignore hostname mismatches and/or\n        #: expired certificates, which will make your application vulnerable to\n        #: man-in-the-middle (MitM) attacks.\n        #: Only set this to `False` for testing.\n        self.verify = True\n\n        #: SSL client certificate default, if String, path to ssl client\n        #: cert file (.pem). If Tuple, ('cert', 'key') pair.\n        self.cert = None\n\n        #: Maximum number of redirects allowed. If the request exceeds this\n        #: limit, a :class:`TooManyRedirects` exception is raised.\n        #: This defaults to requests.models.DEFAULT_REDIRECT_LIMIT, which is\n        #: 30.\n        self.max_redirects = DEFAULT_REDIRECT_LIMIT\n\n        #: Trust environment settings for proxy configuration, default\n        #: authentication and similar.\n        self.trust_env = True\n\n        #: A CookieJar containing all currently outstanding cookies set on this\n        #: session. By default it is a\n        #: :class:`RequestsCookieJar <requests.cookies.RequestsCookieJar>`, but\n        #: may be any other ``cookielib.CookieJar`` compatible object.\n        self.cookies = cookiejar_from_dict({})\n\n        # Default connection adapters.\n        self.adapters = OrderedDict()\n        self.mount(\"https://\", HTTPAdapter())\n        self.mount(\"http://\", HTTPAdapter())\n\n    def __enter__(self):\n        return self\n\n    def __exit__(self, *args):\n        self.close()\n\n    def prepare_request(self, request):\n        \"\"\"Constructs a :class:`PreparedRequest <PreparedRequest>` for\n        transmission and returns it. The :class:`PreparedRequest` has settings\n        merged from the :class:`Request <Request>` instance and those of the\n        :class:`Session`.\n\n        :param request: :class:`Request` instance to prepare with this\n            session's settings.\n        :rtype"}, {"start_line": 43000, "end_line": 45000, "belongs_to": {"file_name": "test_requests.py", "upper_path": "/data2/raymone/swebench-repos/requests/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "ook})\n        prep = req.prepare()\n\n        s = requests.Session()\n        s.proxies = getproxies()\n        resp = s.send(prep)\n\n        assert hasattr(resp, \"hook_working\")\n\n    def test_prepared_from_session(self, httpbin):\n        class DummyAuth(requests.auth.AuthBase):\n            def __call__(self, r):\n                r.headers[\"Dummy-Auth-Test\"] = \"dummy-auth-test-ok\"\n                return r\n\n        req = requests.Request(\"GET\", httpbin(\"headers\"))\n        assert not req.auth\n\n        s = requests.Session()\n        s.auth = DummyAuth()\n\n        prep = s.prepare_request(req)\n        resp = s.send(prep)\n\n        assert resp.json()[\"headers\"][\"Dummy-Auth-Test\"] == \"dummy-auth-test-ok\"\n\n    def test_prepare_request_with_bytestring_url(self):\n        req = requests.Request(\"GET\", b\"https://httpbin.org/\")\n        s = requests.Session()\n        prep = s.prepare_request(req)\n        assert prep.url == \"https://httpbin.org/\"\n\n    def test_request_with_bytestring_host(self, httpbin):\n        s = requests.Session()\n        resp = s.request(\n            \"GET\",\n            httpbin(\"cookies/set?cookie=value\"),\n            allow_redirects=False,\n            headers={\"Host\": b\"httpbin.org\"},\n        )\n        assert resp.cookies.get(\"cookie\") == \"value\"\n\n    def test_links(self):\n        r = requests.Response()\n        r.headers = {\n            \"cache-control\": \"public, max-age=60, s-maxage=60\",\n            \"connection\": \"keep-alive\",\n            \"content-encoding\": \"gzip\",\n            \"content-type\": \"application/json; charset=utf-8\",\n            \"date\": \"Sat, 26 Jan 2013 16:47:56 GMT\",\n            \"etag\": '\"6ff6a73c0e446c1f61614769e3ceb778\"',\n            \"last-modified\": \"Sat, 26 Jan 2013 16:22:39 GMT\",\n            \"link\": (\n                \"<https://api.github.com/users/kennethreitz/repos?\"\n                'page=2&per_page=10>; rel=\"next\", <https://api.github.'\n                \"com/users/kennethreitz/repos?page=7&per_page=10>; \"\n                ' rel=\"last\"'\n           "}, {"start_line": 0, "end_line": 2000, "belongs_to": {"file_name": "sessions.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "\"\"\"\nrequests.sessions\n~~~~~~~~~~~~~~~~~\n\nThis module provides a Session object to manage and persist settings across\nrequests (cookies, auth, proxies).\n\"\"\"\nimport os\nimport sys\nimport time\nfrom collections import OrderedDict\nfrom datetime import timedelta\n\nfrom ._internal_utils import to_native_string\nfrom .adapters import HTTPAdapter\nfrom .auth import _basic_auth_str\nfrom .compat import Mapping, cookielib, urljoin, urlparse\nfrom .cookies import (\n    RequestsCookieJar,\n    cookiejar_from_dict,\n    extract_cookies_to_jar,\n    merge_cookies,\n)\nfrom .exceptions import (\n    ChunkedEncodingError,\n    ContentDecodingError,\n    InvalidSchema,\n    TooManyRedirects,\n)\nfrom .hooks import default_hooks, dispatch_hook\n\n# formerly defined here, reexposed here for backward compatibility\nfrom .models import (  # noqa: F401\n    DEFAULT_REDIRECT_LIMIT,\n    REDIRECT_STATI,\n    PreparedRequest,\n    Request,\n)\nfrom .status_codes import codes\nfrom .structures import CaseInsensitiveDict\nfrom .utils import (  # noqa: F401\n    DEFAULT_PORTS,\n    default_headers,\n    get_auth_from_url,\n    get_environ_proxies,\n    get_netrc_auth,\n    requote_uri,\n    resolve_proxies,\n    rewind_body,\n    should_bypass_proxies,\n    to_key_val_list,\n)\n\n# Preferred clock, based on which one is more accurate on a given system.\nif sys.platform == \"win32\":\n    preferred_clock = time.perf_counter\nelse:\n    preferred_clock = time.time\n\n\ndef merge_setting(request_setting, session_setting, dict_class=OrderedDict):\n    \"\"\"Determines appropriate setting for a given request, taking into account\n    the explicit setting on that request, and the setting in the session. If a\n    setting is a dictionary, they will be merged together using `dict_class`\n    \"\"\"\n\n    if session_setting is None:\n        return request_setting\n\n    if request_setting is None:\n        return session_setting\n\n    # Bypass if not a dictionary (e.g. verify)\n    if not (\n        isinstance(session_setting, Mapping) and isinstance(request_setting, M"}, {"start_line": 27000, "end_line": 29000, "belongs_to": {"file_name": "test_requests.py", "upper_path": "/data2/raymone/swebench-repos/requests/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "authtype, \"never\")\n\n            r = requests.get(url, auth=auth)\n            assert r.status_code == 200\n\n            r = requests.get(url)\n            assert r.status_code == 401\n            print(r.headers[\"WWW-Authenticate\"])\n\n            s = requests.session()\n            s.auth = HTTPDigestAuth(\"user\", \"pass\")\n            r = s.get(url)\n            assert r.status_code == 200\n\n    def test_DIGEST_AUTH_RETURNS_COOKIE(self, httpbin):\n        for authtype in self.digest_auth_algo:\n            url = httpbin(\"digest-auth\", \"auth\", \"user\", \"pass\", authtype)\n            auth = HTTPDigestAuth(\"user\", \"pass\")\n            r = requests.get(url)\n            assert r.cookies[\"fake\"] == \"fake_value\"\n\n            r = requests.get(url, auth=auth)\n            assert r.status_code == 200\n\n    def test_DIGEST_AUTH_SETS_SESSION_COOKIES(self, httpbin):\n        for authtype in self.digest_auth_algo:\n            url = httpbin(\"digest-auth\", \"auth\", \"user\", \"pass\", authtype)\n            auth = HTTPDigestAuth(\"user\", \"pass\")\n            s = requests.Session()\n            s.get(url, auth=auth)\n            assert s.cookies[\"fake\"] == \"fake_value\"\n\n    def test_DIGEST_STREAM(self, httpbin):\n        for authtype in self.digest_auth_algo:\n            auth = HTTPDigestAuth(\"user\", \"pass\")\n            url = httpbin(\"digest-auth\", \"auth\", \"user\", \"pass\", authtype)\n\n            r = requests.get(url, auth=auth, stream=True)\n            assert r.raw.read() != b\"\"\n\n            r = requests.get(url, auth=auth, stream=False)\n            assert r.raw.read() == b\"\"\n\n    def test_DIGESTAUTH_WRONG_HTTP_401_GET(self, httpbin):\n        for authtype in self.digest_auth_algo:\n            auth = HTTPDigestAuth(\"user\", \"wrongpass\")\n            url = httpbin(\"digest-auth\", \"auth\", \"user\", \"pass\", authtype)\n\n            r = requests.get(url, auth=auth)\n            assert r.status_code == 401\n\n            r = requests.get(url)\n            assert r.status_code == 401\n\n            s = requests.session()\n          "}], "retrieved_count": 10, "cost_time": 4.469133615493774}
{"question": "Why does Requests' connection pooling mechanism improve performance compared to creating new connections for each request?", "answer": null, "relative_code_list": null, "ground_truth": "Requests' connection pooling mechanism significantly improves performance through several key optimizations: 1) Connection reuse - Eliminates the overhead of TCP connection establishment (3-way handshake) for subsequent requests to the same host; 2) SSL/TLS optimization - Avoids expensive SSL/TLS handshake and certificate verification for reused connections; 3) DNS caching - Reduces DNS lookup overhead by reusing connections to the same hostname; 4) HTTP/1.1 keep-alive - Leverages HTTP/1.1 persistent connections to send multiple requests over a single TCP connection; 5) Reduced latency - Connection reuse dramatically reduces request latency, especially for multiple requests to the same server; 6) Resource efficiency - Reduces the number of open file descriptors and system resources required for concurrent requests; 7) Connection lifecycle management - Properly manages connection timeouts, cleanup, and health checks to maintain optimal performance; 8) Concurrent request handling - Connection pools enable efficient handling of concurrent requests to the same host; 9) Automatic connection management - Handles connection failures, timeouts, and retries transparently; 10) Scalability - Configurable pool sizes allow applications to scale efficiently based on their specific needs and resource constraints.", "score": null, "retrieved_content": [{"start_line": 5000, "end_line": 7000, "belongs_to": {"file_name": "adapters.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": " requests where data has\n        made it to the server. By default, Requests does not retry failed\n        connections. If you need granular control over the conditions under\n        which we retry a request, import urllib3's ``Retry`` class and pass\n        that instead.\n    :param pool_block: Whether the connection pool should block for connections.\n\n    Usage::\n\n      >>> import requests\n      >>> s = requests.Session()\n      >>> a = requests.adapters.HTTPAdapter(max_retries=3)\n      >>> s.mount('http://', a)\n    \"\"\"\n\n    __attrs__ = [\n        \"max_retries\",\n        \"config\",\n        \"_pool_connections\",\n        \"_pool_maxsize\",\n        \"_pool_block\",\n    ]\n\n    def __init__(\n        self,\n        pool_connections=DEFAULT_POOLSIZE,\n        pool_maxsize=DEFAULT_POOLSIZE,\n        max_retries=DEFAULT_RETRIES,\n        pool_block=DEFAULT_POOLBLOCK,\n    ):\n        if max_retries == DEFAULT_RETRIES:\n            self.max_retries = Retry(0, read=False)\n        else:\n            self.max_retries = Retry.from_int(max_retries)\n        self.config = {}\n        self.proxy_manager = {}\n\n        super().__init__()\n\n        self._pool_connections = pool_connections\n        self._pool_maxsize = pool_maxsize\n        self._pool_block = pool_block\n\n        self.init_poolmanager(pool_connections, pool_maxsize, block=pool_block)\n\n    def __getstate__(self):\n        return {attr: getattr(self, attr, None) for attr in self.__attrs__}\n\n    def __setstate__(self, state):\n        # Can't handle by adding 'proxy_manager' to self.__attrs__ because\n        # self.poolmanager uses a lambda function, which isn't pickleable.\n        self.proxy_manager = {}\n        self.config = {}\n\n        for attr, value in state.items():\n            setattr(self, attr, value)\n\n        self.init_poolmanager(\n            self._pool_connections, self._pool_maxsize, block=self._pool_block\n        )\n\n    def init_poolmanager(\n        self, connections, maxsize, block=DEFAULT_POOLBLOCK, **pool_kwargs\n    ):\n        \""}, {"start_line": 13000, "end_line": 15000, "belongs_to": {"file_name": "sessions.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "POST is responded to with a 301, turn it into a GET.\n        # This bizarre behaviour is explained in Issue 1704.\n        if response.status_code == codes.moved and method == \"POST\":\n            method = \"GET\"\n\n        prepared_request.method = method\n\n\nclass Session(SessionRedirectMixin):\n    \"\"\"A Requests session.\n\n    Provides cookie persistence, connection-pooling, and configuration.\n\n    Basic Usage::\n\n      >>> import requests\n      >>> s = requests.Session()\n      >>> s.get('https://httpbin.org/get')\n      <Response [200]>\n\n    Or as a context manager::\n\n      >>> with requests.Session() as s:\n      ...     s.get('https://httpbin.org/get')\n      <Response [200]>\n    \"\"\"\n\n    __attrs__ = [\n        \"headers\",\n        \"cookies\",\n        \"auth\",\n        \"proxies\",\n        \"hooks\",\n        \"params\",\n        \"verify\",\n        \"cert\",\n        \"adapters\",\n        \"stream\",\n        \"trust_env\",\n        \"max_redirects\",\n    ]\n\n    def __init__(self):\n        #: A case-insensitive dictionary of headers to be sent on each\n        #: :class:`Request <Request>` sent from this\n        #: :class:`Session <Session>`.\n        self.headers = default_headers()\n\n        #: Default Authentication tuple or object to attach to\n        #: :class:`Request <Request>`.\n        self.auth = None\n\n        #: Dictionary mapping protocol or protocol and host to the URL of the proxy\n        #: (e.g. {'http': 'foo.bar:3128', 'http://host.name': 'foo.bar:4012'}) to\n        #: be used on each :class:`Request <Request>`.\n        self.proxies = {}\n\n        #: Event-handling hooks.\n        self.hooks = default_hooks()\n\n        #: Dictionary of querystring data to attach to each\n        #: :class:`Request <Request>`. The dictionary values may be lists for\n        #: representing multivalued query parameters.\n        self.params = {}\n\n        #: Stream response content default.\n        self.stream = False\n\n        #: SSL Verification default.\n        #: Defaults to `True`, requiring requests to verif"}, {"start_line": 2000, "end_line": 4000, "belongs_to": {"file_name": "api.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": ".\n    :type allow_redirects: bool\n    :param proxies: (optional) Dictionary mapping protocol to the URL of the proxy.\n    :param verify: (optional) Either a boolean, in which case it controls whether we verify\n            the server's TLS certificate, or a string, in which case it must be a path\n            to a CA bundle to use. Defaults to ``True``.\n    :param stream: (optional) if ``False``, the response content will be immediately downloaded.\n    :param cert: (optional) if String, path to ssl client cert file (.pem). If Tuple, ('cert', 'key') pair.\n    :return: :class:`Response <Response>` object\n    :rtype: requests.Response\n\n    Usage::\n\n      >>> import requests\n      >>> req = requests.request('GET', 'https://httpbin.org/get')\n      >>> req\n      <Response [200]>\n    \"\"\"\n\n    # By using the 'with' statement we are sure the session is closed, thus we\n    # avoid leaving sockets open which can trigger a ResourceWarning in some\n    # cases, and look like a memory leak in others.\n    with sessions.Session() as session:\n        return session.request(method=method, url=url, **kwargs)\n\n\ndef get(url, params=None, **kwargs):\n    r\"\"\"Sends a GET request.\n\n    :param url: URL for the new :class:`Request` object.\n    :param params: (optional) Dictionary, list of tuples or bytes to send\n        in the query string for the :class:`Request`.\n    :param \\*\\*kwargs: Optional arguments that ``request`` takes.\n    :return: :class:`Response <Response>` object\n    :rtype: requests.Response\n    \"\"\"\n\n    return request(\"get\", url, params=params, **kwargs)\n\n\ndef options(url, **kwargs):\n    r\"\"\"Sends an OPTIONS request.\n\n    :param url: URL for the new :class:`Request` object.\n    :param \\*\\*kwargs: Optional arguments that ``request`` takes.\n    :return: :class:`Response <Response>` object\n    :rtype: requests.Response\n    \"\"\"\n\n    return request(\"options\", url, **kwargs)\n\n\ndef head(url, **kwargs):\n    r\"\"\"Sends a HEAD request.\n\n    :param url: URL for the new :class:`Request` obje"}, {"start_line": 2000, "end_line": 4000, "belongs_to": {"file_name": "test_requests.py", "upper_path": "/data2/raymone/swebench-repos/requests/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": " requests.session\n        requests.session().get\n        requests.session().head\n        requests.get\n        requests.head\n        requests.put\n        requests.patch\n        requests.post\n        # Not really an entry point, but people rely on it.\n        from requests.packages.urllib3.poolmanager import PoolManager  # noqa:F401\n\n    @pytest.mark.parametrize(\n        \"exception, url\",\n        (\n            (MissingSchema, \"hiwpefhipowhefopw\"),\n            (InvalidSchema, \"localhost:3128\"),\n            (InvalidSchema, \"localhost.localdomain:3128/\"),\n            (InvalidSchema, \"10.122.1.1:3128/\"),\n            (InvalidURL, \"http://\"),\n            (InvalidURL, \"http://*example.com\"),\n            (InvalidURL, \"http://.example.com\"),\n        ),\n    )\n    def test_invalid_url(self, exception, url):\n        with pytest.raises(exception):\n            requests.get(url)\n\n    def test_basic_building(self):\n        req = requests.Request()\n        req.url = \"http://kennethreitz.org/\"\n        req.data = {\"life\": \"42\"}\n\n        pr = req.prepare()\n        assert pr.url == req.url\n        assert pr.body == \"life=42\"\n\n    @pytest.mark.parametrize(\"method\", (\"GET\", \"HEAD\"))\n    def test_no_content_length(self, httpbin, method):\n        req = requests.Request(method, httpbin(method.lower())).prepare()\n        assert \"Content-Length\" not in req.headers\n\n    @pytest.mark.parametrize(\"method\", (\"POST\", \"PUT\", \"PATCH\", \"OPTIONS\"))\n    def test_no_body_content_length(self, httpbin, method):\n        req = requests.Request(method, httpbin(method.lower())).prepare()\n        assert req.headers[\"Content-Length\"] == \"0\"\n\n    @pytest.mark.parametrize(\"method\", (\"POST\", \"PUT\", \"PATCH\", \"OPTIONS\"))\n    def test_empty_content_length(self, httpbin, method):\n        req = requests.Request(method, httpbin(method.lower()), data=\"\").prepare()\n        assert req.headers[\"Content-Length\"] == \"0\"\n\n    def test_override_content_length(self, httpbin):\n        headers = {\"Content-Length\": \"not zero\"}\n       "}, {"start_line": 74000, "end_line": 76000, "belongs_to": {"file_name": "test_requests.py", "upper_path": "/data2/raymone/swebench-repos/requests/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "name, password)\n        assert isinstance(s, builtin_str)\n        assert s == auth_str\n\n    def test_requests_history_is_saved(self, httpbin):\n        r = requests.get(httpbin(\"redirect/5\"))\n        total = r.history[-1].history\n        i = 0\n        for item in r.history:\n            assert item.history == total[0:i]\n            i += 1\n\n    def test_json_param_post_content_type_works(self, httpbin):\n        r = requests.post(httpbin(\"post\"), json={\"life\": 42})\n        assert r.status_code == 200\n        assert \"application/json\" in r.request.headers[\"Content-Type\"]\n        assert {\"life\": 42} == r.json()[\"json\"]\n\n    def test_json_param_post_should_not_override_data_param(self, httpbin):\n        r = requests.Request(\n            method=\"POST\",\n            url=httpbin(\"post\"),\n            data={\"stuff\": \"elixr\"},\n            json={\"music\": \"flute\"},\n        )\n        prep = r.prepare()\n        assert \"stuff=elixr\" == prep.body\n\n    def test_response_iter_lines(self, httpbin):\n        r = requests.get(httpbin(\"stream/4\"), stream=True)\n        assert r.status_code == 200\n\n        it = r.iter_lines()\n        next(it)\n        assert len(list(it)) == 3\n\n    def test_response_context_manager(self, httpbin):\n        with requests.get(httpbin(\"stream/4\"), stream=True) as response:\n            assert isinstance(response, requests.Response)\n\n        assert response.raw.closed\n\n    def test_unconsumed_session_response_closes_connection(self, httpbin):\n        s = requests.session()\n\n        with contextlib.closing(s.get(httpbin(\"stream/4\"), stream=True)) as response:\n            pass\n\n        assert response._content_consumed is False\n        assert response.raw.closed\n\n    @pytest.mark.xfail\n    def test_response_iter_lines_reentrant(self, httpbin):\n        \"\"\"Response.iter_lines() is not reentrant safe\"\"\"\n        r = requests.get(httpbin(\"stream/4\"), stream=True)\n        assert r.status_code == 200\n\n        next(r.iter_lines())\n        assert len(list(r.iter_lines())) == 3\n\n"}, {"start_line": 19000, "end_line": 21000, "belongs_to": {"file_name": "adapters.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "(url)\n        else:\n            # Only scheme should be lower case\n            parsed = urlparse(url)\n            url = parsed.geturl()\n            conn = self.poolmanager.connection_from_url(url)\n\n        return conn\n\n    def close(self):\n        \"\"\"Disposes of any internal state.\n\n        Currently, this closes the PoolManager and any active ProxyManager,\n        which closes any pooled connections.\n        \"\"\"\n        self.poolmanager.clear()\n        for proxy in self.proxy_manager.values():\n            proxy.clear()\n\n    def request_url(self, request, proxies):\n        \"\"\"Obtain the url to use when making the final request.\n\n        If the message is being sent through a HTTP proxy, the full URL has to\n        be used. Otherwise, we should only use the path portion of the URL.\n\n        This should not be called from user code, and is only exposed for use\n        when subclassing the\n        :class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.\n\n        :param request: The :class:`PreparedRequest <PreparedRequest>` being sent.\n        :param proxies: A dictionary of schemes or schemes and hosts to proxy URLs.\n        :rtype: str\n        \"\"\"\n        proxy = select_proxy(request.url, proxies)\n        scheme = urlparse(request.url).scheme\n\n        is_proxied_http_request = proxy and scheme != \"https\"\n        using_socks_proxy = False\n        if proxy:\n            proxy_scheme = urlparse(proxy).scheme.lower()\n            using_socks_proxy = proxy_scheme.startswith(\"socks\")\n\n        url = request.path_url\n        if url.startswith(\"//\"):  # Don't confuse urllib3\n            url = f\"/{url.lstrip('/')}\"\n\n        if is_proxied_http_request and not using_socks_proxy:\n            url = urldefragauth(request.url)\n\n        return url\n\n    def add_headers(self, request, **kwargs):\n        \"\"\"Add any headers needed by the connection. As of v2.0 this does\n        nothing by default, but is left for overriding by users that subclass\n        the :class:`HTTPAdapter <requests.adap"}, {"start_line": 0, "end_line": 2000, "belongs_to": {"file_name": "adapters.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "\"\"\"\nrequests.adapters\n~~~~~~~~~~~~~~~~~\n\nThis module contains the transport adapters that Requests uses to define\nand maintain connections.\n\"\"\"\n\nimport os.path\nimport socket  # noqa: F401\nimport typing\nimport warnings\n\nfrom urllib3.exceptions import ClosedPoolError, ConnectTimeoutError\nfrom urllib3.exceptions import HTTPError as _HTTPError\nfrom urllib3.exceptions import InvalidHeader as _InvalidHeader\nfrom urllib3.exceptions import (\n    LocationValueError,\n    MaxRetryError,\n    NewConnectionError,\n    ProtocolError,\n)\nfrom urllib3.exceptions import ProxyError as _ProxyError\nfrom urllib3.exceptions import ReadTimeoutError, ResponseError\nfrom urllib3.exceptions import SSLError as _SSLError\nfrom urllib3.poolmanager import PoolManager, proxy_from_url\nfrom urllib3.util import Timeout as TimeoutSauce\nfrom urllib3.util import parse_url\nfrom urllib3.util.retry import Retry\n\nfrom .auth import _basic_auth_str\nfrom .compat import basestring, urlparse\nfrom .cookies import extract_cookies_to_jar\nfrom .exceptions import (\n    ConnectionError,\n    ConnectTimeout,\n    InvalidHeader,\n    InvalidProxyURL,\n    InvalidSchema,\n    InvalidURL,\n    ProxyError,\n    ReadTimeout,\n    RetryError,\n    SSLError,\n)\nfrom .models import Response\nfrom .structures import CaseInsensitiveDict\nfrom .utils import (\n    DEFAULT_CA_BUNDLE_PATH,\n    extract_zipped_paths,\n    get_auth_from_url,\n    get_encoding_from_headers,\n    prepend_scheme_if_needed,\n    select_proxy,\n    urldefragauth,\n)\n\ntry:\n    from urllib3.contrib.socks import SOCKSProxyManager\nexcept ImportError:\n\n    def SOCKSProxyManager(*args, **kwargs):\n        raise InvalidSchema(\"Missing dependencies for SOCKS support.\")\n\n\nif typing.TYPE_CHECKING:\n    from .models import PreparedRequest\n\n\nDEFAULT_POOLBLOCK = False\nDEFAULT_POOLSIZE = 10\nDEFAULT_RETRIES = 0\nDEFAULT_POOL_TIMEOUT = None\n\n\ndef _urllib3_request_context(\n    request: \"PreparedRequest\",\n    verify: \"bool | str | None\",\n    client_cert: \"typing.Tuple[str, str] | str | None\",\n    po"}, {"start_line": 3000, "end_line": 5000, "belongs_to": {"file_name": "adapters.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "     \"host\": parsed_request_url.hostname,\n        \"port\": port,\n    }\n    return host_params, pool_kwargs\n\n\nclass BaseAdapter:\n    \"\"\"The Base Transport Adapter\"\"\"\n\n    def __init__(self):\n        super().__init__()\n\n    def send(\n        self, request, stream=False, timeout=None, verify=True, cert=None, proxies=None\n    ):\n        \"\"\"Sends PreparedRequest object. Returns Response object.\n\n        :param request: The :class:`PreparedRequest <PreparedRequest>` being sent.\n        :param stream: (optional) Whether to stream the request content.\n        :param timeout: (optional) How long to wait for the server to send\n            data before giving up, as a float, or a :ref:`(connect timeout,\n            read timeout) <timeouts>` tuple.\n        :type timeout: float or tuple\n        :param verify: (optional) Either a boolean, in which case it controls whether we verify\n            the server's TLS certificate, or a string, in which case it must be a path\n            to a CA bundle to use\n        :param cert: (optional) Any user-provided SSL certificate to be trusted.\n        :param proxies: (optional) The proxies dictionary to apply to the request.\n        \"\"\"\n        raise NotImplementedError\n\n    def close(self):\n        \"\"\"Cleans up adapter specific items.\"\"\"\n        raise NotImplementedError\n\n\nclass HTTPAdapter(BaseAdapter):\n    \"\"\"The built-in HTTP Adapter for urllib3.\n\n    Provides a general-case interface for Requests sessions to contact HTTP and\n    HTTPS urls by implementing the Transport Adapter interface. This class will\n    usually be created by the :class:`Session <Session>` class under the\n    covers.\n\n    :param pool_connections: The number of urllib3 connection pools to cache.\n    :param pool_maxsize: The maximum number of connections to save in the pool.\n    :param max_retries: The maximum number of retries each connection\n        should attempt. Note, this applies only to failed DNS lookups, socket\n        connections and connection timeouts, never to"}, {"start_line": 94000, "end_line": 96000, "belongs_to": {"file_name": "test_requests.py", "upper_path": "/data2/raymone/swebench-repos/requests/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "\"_cookies\", \"body\", \"hooks\"):\n        assert getattr(p, attr) == getattr(copy, attr)\n\n\ndef test_urllib3_retries(httpbin):\n    from urllib3.util import Retry\n\n    s = requests.Session()\n    s.mount(\"http://\", HTTPAdapter(max_retries=Retry(total=2, status_forcelist=[500])))\n\n    with pytest.raises(RetryError):\n        s.get(httpbin(\"status/500\"))\n\n\ndef test_urllib3_pool_connection_closed(httpbin):\n    s = requests.Session()\n    s.mount(\"http://\", HTTPAdapter(pool_connections=0, pool_maxsize=0))\n\n    try:\n        s.get(httpbin(\"status/200\"))\n    except ConnectionError as e:\n        assert \"Pool is closed.\" in str(e)\n\n\nclass TestPreparingURLs:\n    @pytest.mark.parametrize(\n        \"url,expected\",\n        (\n            (\"http://google.com\", \"http://google.com/\"),\n            (\"http://.jp\", \"http://xn--hckqz9bzb1cyrb.jp/\"),\n            (\"http://xn--n3h.net/\", \"http://xn--n3h.net/\"),\n            (\"http://.jp\".encode(), \"http://xn--hckqz9bzb1cyrb.jp/\"),\n            (\"http://strae.de/strae\", \"http://xn--strae-oqa.de/stra%C3%9Fe\"),\n            (\n                \"http://strae.de/strae\".encode(),\n                \"http://xn--strae-oqa.de/stra%C3%9Fe\",\n            ),\n            (\n                \"http://Knigsgchen.de/strae\",\n                \"http://xn--knigsgchen-b4a3dun.de/stra%C3%9Fe\",\n            ),\n            (\n                \"http://Knigsgchen.de/strae\".encode(),\n                \"http://xn--knigsgchen-b4a3dun.de/stra%C3%9Fe\",\n            ),\n            (b\"http://xn--n3h.net/\", \"http://xn--n3h.net/\"),\n            (\n                b\"http://[1200:0000:ab00:1234:0000:2552:7777:1313]:12345/\",\n                \"http://[1200:0000:ab00:1234:0000:2552:7777:1313]:12345/\",\n            ),\n            (\n                \"http://[1200:0000:ab00:1234:0000:2552:7777:1313]:12345/\",\n                \"http://[1200:0000:ab00:1234:0000:2552:7777:1313]:12345/\",\n            ),\n        ),\n    )\n    def test_preparing_url(self, url, expected):\n        def normalize_perce"}, {"start_line": 1000, "end_line": 3000, "belongs_to": {"file_name": "test_requests.py", "upper_path": "/data2/raymone/swebench-repos/requests/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "ions import Timeout, TooManyRedirects, UnrewindableBodyError\nfrom requests.hooks import default_hooks\nfrom requests.models import PreparedRequest, urlencode\nfrom requests.sessions import SessionRedirectMixin\nfrom requests.structures import CaseInsensitiveDict\n\nfrom . import SNIMissingWarning\nfrom .compat import StringIO\nfrom .testserver.server import TLSServer, consume_socket_content\nfrom .utils import override_environ\n\n# Requests to this URL should always fail with a connection timeout (nothing\n# listening on that port)\nTARPIT = \"http://10.255.255.1\"\n\n# This is to avoid waiting the timeout of using TARPIT\nINVALID_PROXY = \"http://localhost:1\"\n\ntry:\n    from ssl import SSLContext\n\n    del SSLContext\n    HAS_MODERN_SSL = True\nexcept ImportError:\n    HAS_MODERN_SSL = False\n\ntry:\n    requests.pyopenssl\n    HAS_PYOPENSSL = True\nexcept AttributeError:\n    HAS_PYOPENSSL = False\n\n\nclass TestRequests:\n    digest_auth_algo = (\"MD5\", \"SHA-256\", \"SHA-512\")\n\n    def test_entry_points(self):\n        requests.session\n        requests.session().get\n        requests.session().head\n        requests.get\n        requests.head\n        requests.put\n        requests.patch\n        requests.post\n        # Not really an entry point, but people rely on it.\n        from requests.packages.urllib3.poolmanager import PoolManager  # noqa:F401\n\n    @pytest.mark.parametrize(\n        \"exception, url\",\n        (\n            (MissingSchema, \"hiwpefhipowhefopw\"),\n            (InvalidSchema, \"localhost:3128\"),\n            (InvalidSchema, \"localhost.localdomain:3128/\"),\n            (InvalidSchema, \"10.122.1.1:3128/\"),\n            (InvalidURL, \"http://\"),\n            (InvalidURL, \"http://*example.com\"),\n            (InvalidURL, \"http://.example.com\"),\n        ),\n    )\n    def test_invalid_url(self, exception, url):\n        with pytest.raises(exception):\n            requests.get(url)\n\n    def test_basic_building(self):\n        req = requests.Request()\n        req.url = \"http://kennethreitz.org/\"\n        req"}], "retrieved_count": 10, "cost_time": 4.480433464050293}
{"question": "Why does Requests implement a session-based connection pooling instead of creating new connections for each request?", "answer": null, "relative_code_list": null, "ground_truth": "Requests implements session-based connection pooling for several critical performance and resource management reasons: 1) Performance optimization - Reusing TCP connections eliminates the overhead of connection establishment (TCP handshake, SSL/TLS negotiation), significantly reducing latency for multiple requests to the same host; 2) Resource efficiency - Connection pooling reduces the number of open file descriptors and system resources required, preventing resource exhaustion in high-concurrency scenarios; 3) HTTP/1.1 compliance - Enables proper HTTP/1.1 keep-alive behavior, allowing multiple requests over a single connection as specified in RFC 2616; 4) Reduced server load - Fewer connection establishments reduce server-side resource consumption and improve overall system performance; 5) Network efficiency - Minimizes network overhead by avoiding repeated DNS lookups and connection setup for the same host; 6) Scalability - Connection pools can be configured with appropriate limits to handle concurrent requests efficiently; 7) Connection lifecycle management - Proper connection reuse, timeout handling, and cleanup prevents connection leaks and ensures reliable resource management; 8) Thread safety - Connection pools are thread-safe, enabling efficient concurrent access across multiple threads; 9) Automatic connection management - Handles connection failures, timeouts, and cleanup automatically without user intervention; 10) Backward compatibility - Maintains compatibility with HTTP/1.0 servers while optimizing for HTTP/1.1 capabilities.", "score": null, "retrieved_content": [{"start_line": 13000, "end_line": 15000, "belongs_to": {"file_name": "sessions.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "POST is responded to with a 301, turn it into a GET.\n        # This bizarre behaviour is explained in Issue 1704.\n        if response.status_code == codes.moved and method == \"POST\":\n            method = \"GET\"\n\n        prepared_request.method = method\n\n\nclass Session(SessionRedirectMixin):\n    \"\"\"A Requests session.\n\n    Provides cookie persistence, connection-pooling, and configuration.\n\n    Basic Usage::\n\n      >>> import requests\n      >>> s = requests.Session()\n      >>> s.get('https://httpbin.org/get')\n      <Response [200]>\n\n    Or as a context manager::\n\n      >>> with requests.Session() as s:\n      ...     s.get('https://httpbin.org/get')\n      <Response [200]>\n    \"\"\"\n\n    __attrs__ = [\n        \"headers\",\n        \"cookies\",\n        \"auth\",\n        \"proxies\",\n        \"hooks\",\n        \"params\",\n        \"verify\",\n        \"cert\",\n        \"adapters\",\n        \"stream\",\n        \"trust_env\",\n        \"max_redirects\",\n    ]\n\n    def __init__(self):\n        #: A case-insensitive dictionary of headers to be sent on each\n        #: :class:`Request <Request>` sent from this\n        #: :class:`Session <Session>`.\n        self.headers = default_headers()\n\n        #: Default Authentication tuple or object to attach to\n        #: :class:`Request <Request>`.\n        self.auth = None\n\n        #: Dictionary mapping protocol or protocol and host to the URL of the proxy\n        #: (e.g. {'http': 'foo.bar:3128', 'http://host.name': 'foo.bar:4012'}) to\n        #: be used on each :class:`Request <Request>`.\n        self.proxies = {}\n\n        #: Event-handling hooks.\n        self.hooks = default_hooks()\n\n        #: Dictionary of querystring data to attach to each\n        #: :class:`Request <Request>`. The dictionary values may be lists for\n        #: representing multivalued query parameters.\n        self.params = {}\n\n        #: Stream response content default.\n        self.stream = False\n\n        #: SSL Verification default.\n        #: Defaults to `True`, requiring requests to verif"}, {"start_line": 5000, "end_line": 7000, "belongs_to": {"file_name": "adapters.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": " requests where data has\n        made it to the server. By default, Requests does not retry failed\n        connections. If you need granular control over the conditions under\n        which we retry a request, import urllib3's ``Retry`` class and pass\n        that instead.\n    :param pool_block: Whether the connection pool should block for connections.\n\n    Usage::\n\n      >>> import requests\n      >>> s = requests.Session()\n      >>> a = requests.adapters.HTTPAdapter(max_retries=3)\n      >>> s.mount('http://', a)\n    \"\"\"\n\n    __attrs__ = [\n        \"max_retries\",\n        \"config\",\n        \"_pool_connections\",\n        \"_pool_maxsize\",\n        \"_pool_block\",\n    ]\n\n    def __init__(\n        self,\n        pool_connections=DEFAULT_POOLSIZE,\n        pool_maxsize=DEFAULT_POOLSIZE,\n        max_retries=DEFAULT_RETRIES,\n        pool_block=DEFAULT_POOLBLOCK,\n    ):\n        if max_retries == DEFAULT_RETRIES:\n            self.max_retries = Retry(0, read=False)\n        else:\n            self.max_retries = Retry.from_int(max_retries)\n        self.config = {}\n        self.proxy_manager = {}\n\n        super().__init__()\n\n        self._pool_connections = pool_connections\n        self._pool_maxsize = pool_maxsize\n        self._pool_block = pool_block\n\n        self.init_poolmanager(pool_connections, pool_maxsize, block=pool_block)\n\n    def __getstate__(self):\n        return {attr: getattr(self, attr, None) for attr in self.__attrs__}\n\n    def __setstate__(self, state):\n        # Can't handle by adding 'proxy_manager' to self.__attrs__ because\n        # self.poolmanager uses a lambda function, which isn't pickleable.\n        self.proxy_manager = {}\n        self.config = {}\n\n        for attr, value in state.items():\n            setattr(self, attr, value)\n\n        self.init_poolmanager(\n            self._pool_connections, self._pool_maxsize, block=self._pool_block\n        )\n\n    def init_poolmanager(\n        self, connections, maxsize, block=DEFAULT_POOLBLOCK, **pool_kwargs\n    ):\n        \""}, {"start_line": 12000, "end_line": 14000, "belongs_to": {"file_name": "sessions.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "          username, password = None, None\n\n        # urllib3 handles proxy authorization for us in the standard adapter.\n        # Avoid appending this to TLS tunneled requests where it may be leaked.\n        if not scheme.startswith(\"https\") and username and password:\n            headers[\"Proxy-Authorization\"] = _basic_auth_str(username, password)\n\n        return new_proxies\n\n    def rebuild_method(self, prepared_request, response):\n        \"\"\"When being redirected we may want to change the method of the request\n        based on certain specs or browser behavior.\n        \"\"\"\n        method = prepared_request.method\n\n        # https://tools.ietf.org/html/rfc7231#section-6.4.4\n        if response.status_code == codes.see_other and method != \"HEAD\":\n            method = \"GET\"\n\n        # Do what the browsers do, despite standards...\n        # First, turn 302s into GETs.\n        if response.status_code == codes.found and method != \"HEAD\":\n            method = \"GET\"\n\n        # Second, if a POST is responded to with a 301, turn it into a GET.\n        # This bizarre behaviour is explained in Issue 1704.\n        if response.status_code == codes.moved and method == \"POST\":\n            method = \"GET\"\n\n        prepared_request.method = method\n\n\nclass Session(SessionRedirectMixin):\n    \"\"\"A Requests session.\n\n    Provides cookie persistence, connection-pooling, and configuration.\n\n    Basic Usage::\n\n      >>> import requests\n      >>> s = requests.Session()\n      >>> s.get('https://httpbin.org/get')\n      <Response [200]>\n\n    Or as a context manager::\n\n      >>> with requests.Session() as s:\n      ...     s.get('https://httpbin.org/get')\n      <Response [200]>\n    \"\"\"\n\n    __attrs__ = [\n        \"headers\",\n        \"cookies\",\n        \"auth\",\n        \"proxies\",\n        \"hooks\",\n        \"params\",\n        \"verify\",\n        \"cert\",\n        \"adapters\",\n        \"stream\",\n        \"trust_env\",\n        \"max_redirects\",\n    ]\n\n    def __init__(self):\n        #: A case-insensitive dictiona"}, {"start_line": 0, "end_line": 2000, "belongs_to": {"file_name": "sessions.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "\"\"\"\nrequests.sessions\n~~~~~~~~~~~~~~~~~\n\nThis module provides a Session object to manage and persist settings across\nrequests (cookies, auth, proxies).\n\"\"\"\nimport os\nimport sys\nimport time\nfrom collections import OrderedDict\nfrom datetime import timedelta\n\nfrom ._internal_utils import to_native_string\nfrom .adapters import HTTPAdapter\nfrom .auth import _basic_auth_str\nfrom .compat import Mapping, cookielib, urljoin, urlparse\nfrom .cookies import (\n    RequestsCookieJar,\n    cookiejar_from_dict,\n    extract_cookies_to_jar,\n    merge_cookies,\n)\nfrom .exceptions import (\n    ChunkedEncodingError,\n    ContentDecodingError,\n    InvalidSchema,\n    TooManyRedirects,\n)\nfrom .hooks import default_hooks, dispatch_hook\n\n# formerly defined here, reexposed here for backward compatibility\nfrom .models import (  # noqa: F401\n    DEFAULT_REDIRECT_LIMIT,\n    REDIRECT_STATI,\n    PreparedRequest,\n    Request,\n)\nfrom .status_codes import codes\nfrom .structures import CaseInsensitiveDict\nfrom .utils import (  # noqa: F401\n    DEFAULT_PORTS,\n    default_headers,\n    get_auth_from_url,\n    get_environ_proxies,\n    get_netrc_auth,\n    requote_uri,\n    resolve_proxies,\n    rewind_body,\n    should_bypass_proxies,\n    to_key_val_list,\n)\n\n# Preferred clock, based on which one is more accurate on a given system.\nif sys.platform == \"win32\":\n    preferred_clock = time.perf_counter\nelse:\n    preferred_clock = time.time\n\n\ndef merge_setting(request_setting, session_setting, dict_class=OrderedDict):\n    \"\"\"Determines appropriate setting for a given request, taking into account\n    the explicit setting on that request, and the setting in the session. If a\n    setting is a dictionary, they will be merged together using `dict_class`\n    \"\"\"\n\n    if session_setting is None:\n        return request_setting\n\n    if request_setting is None:\n        return session_setting\n\n    # Bypass if not a dictionary (e.g. verify)\n    if not (\n        isinstance(session_setting, Mapping) and isinstance(request_setting, M"}, {"start_line": 2000, "end_line": 4000, "belongs_to": {"file_name": "api.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": ".\n    :type allow_redirects: bool\n    :param proxies: (optional) Dictionary mapping protocol to the URL of the proxy.\n    :param verify: (optional) Either a boolean, in which case it controls whether we verify\n            the server's TLS certificate, or a string, in which case it must be a path\n            to a CA bundle to use. Defaults to ``True``.\n    :param stream: (optional) if ``False``, the response content will be immediately downloaded.\n    :param cert: (optional) if String, path to ssl client cert file (.pem). If Tuple, ('cert', 'key') pair.\n    :return: :class:`Response <Response>` object\n    :rtype: requests.Response\n\n    Usage::\n\n      >>> import requests\n      >>> req = requests.request('GET', 'https://httpbin.org/get')\n      >>> req\n      <Response [200]>\n    \"\"\"\n\n    # By using the 'with' statement we are sure the session is closed, thus we\n    # avoid leaving sockets open which can trigger a ResourceWarning in some\n    # cases, and look like a memory leak in others.\n    with sessions.Session() as session:\n        return session.request(method=method, url=url, **kwargs)\n\n\ndef get(url, params=None, **kwargs):\n    r\"\"\"Sends a GET request.\n\n    :param url: URL for the new :class:`Request` object.\n    :param params: (optional) Dictionary, list of tuples or bytes to send\n        in the query string for the :class:`Request`.\n    :param \\*\\*kwargs: Optional arguments that ``request`` takes.\n    :return: :class:`Response <Response>` object\n    :rtype: requests.Response\n    \"\"\"\n\n    return request(\"get\", url, params=params, **kwargs)\n\n\ndef options(url, **kwargs):\n    r\"\"\"Sends an OPTIONS request.\n\n    :param url: URL for the new :class:`Request` object.\n    :param \\*\\*kwargs: Optional arguments that ``request`` takes.\n    :return: :class:`Response <Response>` object\n    :rtype: requests.Response\n    \"\"\"\n\n    return request(\"options\", url, **kwargs)\n\n\ndef head(url, **kwargs):\n    r\"\"\"Sends a HEAD request.\n\n    :param url: URL for the new :class:`Request` obje"}, {"start_line": 2000, "end_line": 4000, "belongs_to": {"file_name": "test_requests.py", "upper_path": "/data2/raymone/swebench-repos/requests/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": " requests.session\n        requests.session().get\n        requests.session().head\n        requests.get\n        requests.head\n        requests.put\n        requests.patch\n        requests.post\n        # Not really an entry point, but people rely on it.\n        from requests.packages.urllib3.poolmanager import PoolManager  # noqa:F401\n\n    @pytest.mark.parametrize(\n        \"exception, url\",\n        (\n            (MissingSchema, \"hiwpefhipowhefopw\"),\n            (InvalidSchema, \"localhost:3128\"),\n            (InvalidSchema, \"localhost.localdomain:3128/\"),\n            (InvalidSchema, \"10.122.1.1:3128/\"),\n            (InvalidURL, \"http://\"),\n            (InvalidURL, \"http://*example.com\"),\n            (InvalidURL, \"http://.example.com\"),\n        ),\n    )\n    def test_invalid_url(self, exception, url):\n        with pytest.raises(exception):\n            requests.get(url)\n\n    def test_basic_building(self):\n        req = requests.Request()\n        req.url = \"http://kennethreitz.org/\"\n        req.data = {\"life\": \"42\"}\n\n        pr = req.prepare()\n        assert pr.url == req.url\n        assert pr.body == \"life=42\"\n\n    @pytest.mark.parametrize(\"method\", (\"GET\", \"HEAD\"))\n    def test_no_content_length(self, httpbin, method):\n        req = requests.Request(method, httpbin(method.lower())).prepare()\n        assert \"Content-Length\" not in req.headers\n\n    @pytest.mark.parametrize(\"method\", (\"POST\", \"PUT\", \"PATCH\", \"OPTIONS\"))\n    def test_no_body_content_length(self, httpbin, method):\n        req = requests.Request(method, httpbin(method.lower())).prepare()\n        assert req.headers[\"Content-Length\"] == \"0\"\n\n    @pytest.mark.parametrize(\"method\", (\"POST\", \"PUT\", \"PATCH\", \"OPTIONS\"))\n    def test_empty_content_length(self, httpbin, method):\n        req = requests.Request(method, httpbin(method.lower()), data=\"\").prepare()\n        assert req.headers[\"Content-Length\"] == \"0\"\n\n    def test_override_content_length(self, httpbin):\n        headers = {\"Content-Length\": \"not zero\"}\n       "}, {"start_line": 15000, "end_line": 17000, "belongs_to": {"file_name": "sessions.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "y the TLS certificate at the\n        #: remote end.\n        #: If verify is set to `False`, requests will accept any TLS certificate\n        #: presented by the server, and will ignore hostname mismatches and/or\n        #: expired certificates, which will make your application vulnerable to\n        #: man-in-the-middle (MitM) attacks.\n        #: Only set this to `False` for testing.\n        self.verify = True\n\n        #: SSL client certificate default, if String, path to ssl client\n        #: cert file (.pem). If Tuple, ('cert', 'key') pair.\n        self.cert = None\n\n        #: Maximum number of redirects allowed. If the request exceeds this\n        #: limit, a :class:`TooManyRedirects` exception is raised.\n        #: This defaults to requests.models.DEFAULT_REDIRECT_LIMIT, which is\n        #: 30.\n        self.max_redirects = DEFAULT_REDIRECT_LIMIT\n\n        #: Trust environment settings for proxy configuration, default\n        #: authentication and similar.\n        self.trust_env = True\n\n        #: A CookieJar containing all currently outstanding cookies set on this\n        #: session. By default it is a\n        #: :class:`RequestsCookieJar <requests.cookies.RequestsCookieJar>`, but\n        #: may be any other ``cookielib.CookieJar`` compatible object.\n        self.cookies = cookiejar_from_dict({})\n\n        # Default connection adapters.\n        self.adapters = OrderedDict()\n        self.mount(\"https://\", HTTPAdapter())\n        self.mount(\"http://\", HTTPAdapter())\n\n    def __enter__(self):\n        return self\n\n    def __exit__(self, *args):\n        self.close()\n\n    def prepare_request(self, request):\n        \"\"\"Constructs a :class:`PreparedRequest <PreparedRequest>` for\n        transmission and returns it. The :class:`PreparedRequest` has settings\n        merged from the :class:`Request <Request>` instance and those of the\n        :class:`Session`.\n\n        :param request: :class:`Request` instance to prepare with this\n            session's settings.\n        :rtype"}, {"start_line": 14000, "end_line": 16000, "belongs_to": {"file_name": "sessions.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "ry of headers to be sent on each\n        #: :class:`Request <Request>` sent from this\n        #: :class:`Session <Session>`.\n        self.headers = default_headers()\n\n        #: Default Authentication tuple or object to attach to\n        #: :class:`Request <Request>`.\n        self.auth = None\n\n        #: Dictionary mapping protocol or protocol and host to the URL of the proxy\n        #: (e.g. {'http': 'foo.bar:3128', 'http://host.name': 'foo.bar:4012'}) to\n        #: be used on each :class:`Request <Request>`.\n        self.proxies = {}\n\n        #: Event-handling hooks.\n        self.hooks = default_hooks()\n\n        #: Dictionary of querystring data to attach to each\n        #: :class:`Request <Request>`. The dictionary values may be lists for\n        #: representing multivalued query parameters.\n        self.params = {}\n\n        #: Stream response content default.\n        self.stream = False\n\n        #: SSL Verification default.\n        #: Defaults to `True`, requiring requests to verify the TLS certificate at the\n        #: remote end.\n        #: If verify is set to `False`, requests will accept any TLS certificate\n        #: presented by the server, and will ignore hostname mismatches and/or\n        #: expired certificates, which will make your application vulnerable to\n        #: man-in-the-middle (MitM) attacks.\n        #: Only set this to `False` for testing.\n        self.verify = True\n\n        #: SSL client certificate default, if String, path to ssl client\n        #: cert file (.pem). If Tuple, ('cert', 'key') pair.\n        self.cert = None\n\n        #: Maximum number of redirects allowed. If the request exceeds this\n        #: limit, a :class:`TooManyRedirects` exception is raised.\n        #: This defaults to requests.models.DEFAULT_REDIRECT_LIMIT, which is\n        #: 30.\n        self.max_redirects = DEFAULT_REDIRECT_LIMIT\n\n        #: Trust environment settings for proxy configuration, default\n        #: authentication and similar.\n        self.trust_env = Tru"}, {"start_line": 0, "end_line": 2000, "belongs_to": {"file_name": "api.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "\"\"\"\nrequests.api\n~~~~~~~~~~~~\n\nThis module implements the Requests API.\n\n:copyright: (c) 2012 by Kenneth Reitz.\n:license: Apache2, see LICENSE for more details.\n\"\"\"\n\nfrom . import sessions\n\n\ndef request(method, url, **kwargs):\n    \"\"\"Constructs and sends a :class:`Request <Request>`.\n\n    :param method: method for the new :class:`Request` object: ``GET``, ``OPTIONS``, ``HEAD``, ``POST``, ``PUT``, ``PATCH``, or ``DELETE``.\n    :param url: URL for the new :class:`Request` object.\n    :param params: (optional) Dictionary, list of tuples or bytes to send\n        in the query string for the :class:`Request`.\n    :param data: (optional) Dictionary, list of tuples, bytes, or file-like\n        object to send in the body of the :class:`Request`.\n    :param json: (optional) A JSON serializable Python object to send in the body of the :class:`Request`.\n    :param headers: (optional) Dictionary of HTTP Headers to send with the :class:`Request`.\n    :param cookies: (optional) Dict or CookieJar object to send with the :class:`Request`.\n    :param files: (optional) Dictionary of ``'name': file-like-objects`` (or ``{'name': file-tuple}``) for multipart encoding upload.\n        ``file-tuple`` can be a 2-tuple ``('filename', fileobj)``, 3-tuple ``('filename', fileobj, 'content_type')``\n        or a 4-tuple ``('filename', fileobj, 'content_type', custom_headers)``, where ``'content_type'`` is a string\n        defining the content type of the given file and ``custom_headers`` a dict-like object containing additional headers\n        to add for the file.\n    :param auth: (optional) Auth tuple to enable Basic/Digest/Custom HTTP Auth.\n    :param timeout: (optional) How many seconds to wait for the server to send data\n        before giving up, as a float, or a :ref:`(connect timeout, read\n        timeout) <timeouts>` tuple.\n    :type timeout: float or tuple\n    :param allow_redirects: (optional) Boolean. Enable/disable GET/OPTIONS/POST/PUT/PATCH/DELETE/HEAD redirection. Defaults to ``True``"}, {"start_line": 29000, "end_line": 30503, "belongs_to": {"file_name": "sessions.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "nnection adapter for the given URL.\n\n        :rtype: requests.adapters.BaseAdapter\n        \"\"\"\n        for prefix, adapter in self.adapters.items():\n            if url.lower().startswith(prefix.lower()):\n                return adapter\n\n        # Nothing matches :-/\n        raise InvalidSchema(f\"No connection adapters were found for {url!r}\")\n\n    def close(self):\n        \"\"\"Closes all adapters and as such the session\"\"\"\n        for v in self.adapters.values():\n            v.close()\n\n    def mount(self, prefix, adapter):\n        \"\"\"Registers a connection adapter to a prefix.\n\n        Adapters are sorted in descending order by prefix length.\n        \"\"\"\n        self.adapters[prefix] = adapter\n        keys_to_move = [k for k in self.adapters if len(k) < len(prefix)]\n\n        for key in keys_to_move:\n            self.adapters[key] = self.adapters.pop(key)\n\n    def __getstate__(self):\n        state = {attr: getattr(self, attr, None) for attr in self.__attrs__}\n        return state\n\n    def __setstate__(self, state):\n        for attr, value in state.items():\n            setattr(self, attr, value)\n\n\ndef session():\n    \"\"\"\n    Returns a :class:`Session` for context-management.\n\n    .. deprecated:: 1.0.0\n\n        This method has been deprecated since version 1.0.0 and is only kept for\n        backwards compatibility. New code should use :class:`~requests.sessions.Session`\n        to create a session. This may be removed at a future date.\n\n    :rtype: Session\n    \"\"\"\n    return Session()\n"}], "retrieved_count": 10, "cost_time": 4.53222131729126}
{"question": "Why does Requests implement request/response streaming for memory efficiency in large data transfers?", "answer": null, "relative_code_list": null, "ground_truth": "Requests implements request/response streaming for memory efficiency to handle large data transfers without loading the entire response into memory at once. Key mechanisms include: 1) Stream parameter - When stream=True is set on requests, the response content is not automatically loaded into memory; 2) iter_content() method - Provides chunked iteration over response data with configurable chunk sizes, avoiding memory exhaustion for large responses; 3) Raw response access - The raw attribute provides file-like access to the response stream when streaming is enabled; 4) Lazy content loading - Response content is only loaded when explicitly accessed (via .content property), not during initial response creation; 5) Chunked processing - Data can be processed in small chunks (default 1 byte, configurable) rather than loading the entire response; 6) Memory conservation - Streaming prevents memory exhaustion when downloading large files or processing large API responses; 7) Connection reuse - Streaming works with connection pooling to maintain efficiency; 8) Error handling - Streaming includes proper error handling for chunked encoding, content decoding, and connection issues; 9) Unicode support - Streaming supports both binary and Unicode content with decode_unicode parameter; 10) Resource management - Proper cleanup of streaming resources through context managers and close() methods.", "score": null, "retrieved_content": [{"start_line": 74000, "end_line": 76000, "belongs_to": {"file_name": "test_requests.py", "upper_path": "/data2/raymone/swebench-repos/requests/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "name, password)\n        assert isinstance(s, builtin_str)\n        assert s == auth_str\n\n    def test_requests_history_is_saved(self, httpbin):\n        r = requests.get(httpbin(\"redirect/5\"))\n        total = r.history[-1].history\n        i = 0\n        for item in r.history:\n            assert item.history == total[0:i]\n            i += 1\n\n    def test_json_param_post_content_type_works(self, httpbin):\n        r = requests.post(httpbin(\"post\"), json={\"life\": 42})\n        assert r.status_code == 200\n        assert \"application/json\" in r.request.headers[\"Content-Type\"]\n        assert {\"life\": 42} == r.json()[\"json\"]\n\n    def test_json_param_post_should_not_override_data_param(self, httpbin):\n        r = requests.Request(\n            method=\"POST\",\n            url=httpbin(\"post\"),\n            data={\"stuff\": \"elixr\"},\n            json={\"music\": \"flute\"},\n        )\n        prep = r.prepare()\n        assert \"stuff=elixr\" == prep.body\n\n    def test_response_iter_lines(self, httpbin):\n        r = requests.get(httpbin(\"stream/4\"), stream=True)\n        assert r.status_code == 200\n\n        it = r.iter_lines()\n        next(it)\n        assert len(list(it)) == 3\n\n    def test_response_context_manager(self, httpbin):\n        with requests.get(httpbin(\"stream/4\"), stream=True) as response:\n            assert isinstance(response, requests.Response)\n\n        assert response.raw.closed\n\n    def test_unconsumed_session_response_closes_connection(self, httpbin):\n        s = requests.session()\n\n        with contextlib.closing(s.get(httpbin(\"stream/4\"), stream=True)) as response:\n            pass\n\n        assert response._content_consumed is False\n        assert response.raw.closed\n\n    @pytest.mark.xfail\n    def test_response_iter_lines_reentrant(self, httpbin):\n        \"\"\"Response.iter_lines() is not reentrant safe\"\"\"\n        r = requests.get(httpbin(\"stream/4\"), stream=True)\n        assert r.status_code == 200\n\n        next(r.iter_lines())\n        assert len(list(r.iter_lines())) == 3\n\n"}, {"start_line": 75000, "end_line": 77000, "belongs_to": {"file_name": "test_requests.py", "upper_path": "/data2/raymone/swebench-repos/requests/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": " = requests.get(httpbin(\"stream/4\"), stream=True)\n        assert r.status_code == 200\n\n        it = r.iter_lines()\n        next(it)\n        assert len(list(it)) == 3\n\n    def test_response_context_manager(self, httpbin):\n        with requests.get(httpbin(\"stream/4\"), stream=True) as response:\n            assert isinstance(response, requests.Response)\n\n        assert response.raw.closed\n\n    def test_unconsumed_session_response_closes_connection(self, httpbin):\n        s = requests.session()\n\n        with contextlib.closing(s.get(httpbin(\"stream/4\"), stream=True)) as response:\n            pass\n\n        assert response._content_consumed is False\n        assert response.raw.closed\n\n    @pytest.mark.xfail\n    def test_response_iter_lines_reentrant(self, httpbin):\n        \"\"\"Response.iter_lines() is not reentrant safe\"\"\"\n        r = requests.get(httpbin(\"stream/4\"), stream=True)\n        assert r.status_code == 200\n\n        next(r.iter_lines())\n        assert len(list(r.iter_lines())) == 3\n\n    def test_session_close_proxy_clear(self):\n        proxies = {\n            \"one\": mock.Mock(),\n            \"two\": mock.Mock(),\n        }\n        session = requests.Session()\n        with mock.patch.dict(session.adapters[\"http://\"].proxy_manager, proxies):\n            session.close()\n            proxies[\"one\"].clear.assert_called_once_with()\n            proxies[\"two\"].clear.assert_called_once_with()\n\n    def test_proxy_auth(self):\n        adapter = HTTPAdapter()\n        headers = adapter.proxy_headers(\"http://user:pass@httpbin.org\")\n        assert headers == {\"Proxy-Authorization\": \"Basic dXNlcjpwYXNz\"}\n\n    def test_proxy_auth_empty_pass(self):\n        adapter = HTTPAdapter()\n        headers = adapter.proxy_headers(\"http://user:@httpbin.org\")\n        assert headers == {\"Proxy-Authorization\": \"Basic dXNlcjo=\"}\n\n    def test_response_json_when_content_is_None(self, httpbin):\n        r = requests.get(httpbin(\"/status/204\"))\n        # Make sure r.content is None\n        r.status_code = "}, {"start_line": 77000, "end_line": 79000, "belongs_to": {"file_name": "test_requests.py", "upper_path": "/data2/raymone/swebench-repos/requests/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "0\n        r._content = False\n        r._content_consumed = False\n\n        assert r.content is None\n        with pytest.raises(ValueError):\n            r.json()\n\n    def test_response_without_release_conn(self):\n        \"\"\"Test `close` call for non-urllib3-like raw objects.\n        Should work when `release_conn` attr doesn't exist on `response.raw`.\n        \"\"\"\n        resp = requests.Response()\n        resp.raw = StringIO.StringIO(\"test\")\n        assert not resp.raw.closed\n        resp.close()\n        assert resp.raw.closed\n\n    def test_empty_stream_with_auth_does_not_set_content_length_header(self, httpbin):\n        \"\"\"Ensure that a byte stream with size 0 will not set both a Content-Length\n        and Transfer-Encoding header.\n        \"\"\"\n        auth = (\"user\", \"pass\")\n        url = httpbin(\"post\")\n        file_obj = io.BytesIO(b\"\")\n        r = requests.Request(\"POST\", url, auth=auth, data=file_obj)\n        prepared_request = r.prepare()\n        assert \"Transfer-Encoding\" in prepared_request.headers\n        assert \"Content-Length\" not in prepared_request.headers\n\n    def test_stream_with_auth_does_not_set_transfer_encoding_header(self, httpbin):\n        \"\"\"Ensure that a byte stream with size > 0 will not set both a Content-Length\n        and Transfer-Encoding header.\n        \"\"\"\n        auth = (\"user\", \"pass\")\n        url = httpbin(\"post\")\n        file_obj = io.BytesIO(b\"test data\")\n        r = requests.Request(\"POST\", url, auth=auth, data=file_obj)\n        prepared_request = r.prepare()\n        assert \"Transfer-Encoding\" not in prepared_request.headers\n        assert \"Content-Length\" in prepared_request.headers\n\n    def test_chunked_upload_does_not_set_content_length_header(self, httpbin):\n        \"\"\"Ensure that requests with a generator body stream using\n        Transfer-Encoding: chunked, not a Content-Length header.\n        \"\"\"\n        data = (i for i in [b\"a\", b\"b\", b\"c\"])\n        url = httpbin(\"post\")\n        r = requests.Request(\"POST\", url, data=data)\n "}, {"start_line": 78000, "end_line": 80000, "belongs_to": {"file_name": "test_requests.py", "upper_path": "/data2/raymone/swebench-repos/requests/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "red_request.headers\n        assert \"Content-Length\" not in prepared_request.headers\n\n    def test_stream_with_auth_does_not_set_transfer_encoding_header(self, httpbin):\n        \"\"\"Ensure that a byte stream with size > 0 will not set both a Content-Length\n        and Transfer-Encoding header.\n        \"\"\"\n        auth = (\"user\", \"pass\")\n        url = httpbin(\"post\")\n        file_obj = io.BytesIO(b\"test data\")\n        r = requests.Request(\"POST\", url, auth=auth, data=file_obj)\n        prepared_request = r.prepare()\n        assert \"Transfer-Encoding\" not in prepared_request.headers\n        assert \"Content-Length\" in prepared_request.headers\n\n    def test_chunked_upload_does_not_set_content_length_header(self, httpbin):\n        \"\"\"Ensure that requests with a generator body stream using\n        Transfer-Encoding: chunked, not a Content-Length header.\n        \"\"\"\n        data = (i for i in [b\"a\", b\"b\", b\"c\"])\n        url = httpbin(\"post\")\n        r = requests.Request(\"POST\", url, data=data)\n        prepared_request = r.prepare()\n        assert \"Transfer-Encoding\" in prepared_request.headers\n        assert \"Content-Length\" not in prepared_request.headers\n\n    def test_custom_redirect_mixin(self, httpbin):\n        \"\"\"Tests a custom mixin to overwrite ``get_redirect_target``.\n\n        Ensures a subclassed ``requests.Session`` can handle a certain type of\n        malformed redirect responses.\n\n        1. original request receives a proper response: 302 redirect\n        2. following the redirect, a malformed response is given:\n            status code = HTTP 200\n            location = alternate url\n        3. the custom session catches the edge case and follows the redirect\n        \"\"\"\n        url_final = httpbin(\"html\")\n        querystring_malformed = urlencode({\"location\": url_final})\n        url_redirect_malformed = httpbin(\"response-headers?%s\" % querystring_malformed)\n        querystring_redirect = urlencode({\"url\": url_redirect_malformed})\n        url_redirect = httpbin(\"r"}, {"start_line": 8000, "end_line": 10000, "belongs_to": {"file_name": "sessions.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "     # https://github.com/psf/requests/issues/3490\n                purged_headers = (\"Content-Length\", \"Content-Type\", \"Transfer-Encoding\")\n                for header in purged_headers:\n                    prepared_request.headers.pop(header, None)\n                prepared_request.body = None\n\n            headers = prepared_request.headers\n            headers.pop(\"Cookie\", None)\n\n            # Extract any cookies sent on the response to the cookiejar\n            # in the new request. Because we've mutated our copied prepared\n            # request, use the old one that we haven't yet touched.\n            extract_cookies_to_jar(prepared_request._cookies, req, resp.raw)\n            merge_cookies(prepared_request._cookies, self.cookies)\n            prepared_request.prepare_cookies(prepared_request._cookies)\n\n            # Rebuild auth and proxy information.\n            proxies = self.rebuild_proxies(prepared_request, proxies)\n            self.rebuild_auth(prepared_request, resp)\n\n            # A failed tell() sets `_body_position` to `object()`. This non-None\n            # value ensures `rewindable` will be True, allowing us to raise an\n            # UnrewindableBodyError, instead of hanging the connection.\n            rewindable = prepared_request._body_position is not None and (\n                \"Content-Length\" in headers or \"Transfer-Encoding\" in headers\n            )\n\n            # Attempt to rewind consumed file-like object.\n            if rewindable:\n                rewind_body(prepared_request)\n\n            # Override the original request.\n            req = prepared_request\n\n            if yield_requests:\n                yield req\n            else:\n                resp = self.send(\n                    req,\n                    stream=stream,\n                    timeout=timeout,\n                    verify=verify,\n                    cert=cert,\n                    proxies=proxies,\n                    allow_redirects=False,\n                    **adapter_kwargs,\n     "}, {"start_line": 2000, "end_line": 4000, "belongs_to": {"file_name": "api.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": ".\n    :type allow_redirects: bool\n    :param proxies: (optional) Dictionary mapping protocol to the URL of the proxy.\n    :param verify: (optional) Either a boolean, in which case it controls whether we verify\n            the server's TLS certificate, or a string, in which case it must be a path\n            to a CA bundle to use. Defaults to ``True``.\n    :param stream: (optional) if ``False``, the response content will be immediately downloaded.\n    :param cert: (optional) if String, path to ssl client cert file (.pem). If Tuple, ('cert', 'key') pair.\n    :return: :class:`Response <Response>` object\n    :rtype: requests.Response\n\n    Usage::\n\n      >>> import requests\n      >>> req = requests.request('GET', 'https://httpbin.org/get')\n      >>> req\n      <Response [200]>\n    \"\"\"\n\n    # By using the 'with' statement we are sure the session is closed, thus we\n    # avoid leaving sockets open which can trigger a ResourceWarning in some\n    # cases, and look like a memory leak in others.\n    with sessions.Session() as session:\n        return session.request(method=method, url=url, **kwargs)\n\n\ndef get(url, params=None, **kwargs):\n    r\"\"\"Sends a GET request.\n\n    :param url: URL for the new :class:`Request` object.\n    :param params: (optional) Dictionary, list of tuples or bytes to send\n        in the query string for the :class:`Request`.\n    :param \\*\\*kwargs: Optional arguments that ``request`` takes.\n    :return: :class:`Response <Response>` object\n    :rtype: requests.Response\n    \"\"\"\n\n    return request(\"get\", url, params=params, **kwargs)\n\n\ndef options(url, **kwargs):\n    r\"\"\"Sends an OPTIONS request.\n\n    :param url: URL for the new :class:`Request` object.\n    :param \\*\\*kwargs: Optional arguments that ``request`` takes.\n    :return: :class:`Response <Response>` object\n    :rtype: requests.Response\n    \"\"\"\n\n    return request(\"options\", url, **kwargs)\n\n\ndef head(url, **kwargs):\n    r\"\"\"Sends a HEAD request.\n\n    :param url: URL for the new :class:`Request` obje"}, {"start_line": 31000, "end_line": 33000, "belongs_to": {"file_name": "test_requests.py", "upper_path": "/data2/raymone/swebench-repos/requests/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "eek(self, offset, where=0):\n                if where == 0:\n                    self.index = offset\n                elif where == 1:\n                    self.index += offset\n                elif where == 2:\n                    self.index = self.length + offset\n\n        test = TestStream(\"test\")\n        post1 = requests.post(httpbin(\"post\"), data=test)\n        assert post1.status_code == 200\n        assert post1.json()[\"data\"] == \"test\"\n\n        test = TestStream(\"test\")\n        test.seek(2)\n        post2 = requests.post(httpbin(\"post\"), data=test)\n        assert post2.status_code == 200\n        assert post2.json()[\"data\"] == \"st\"\n\n    def test_POSTBIN_GET_POST_FILES_WITH_DATA(self, httpbin):\n        url = httpbin(\"post\")\n        requests.post(url).raise_for_status()\n\n        post1 = requests.post(url, data={\"some\": \"data\"})\n        assert post1.status_code == 200\n\n        with open(\"requirements-dev.txt\") as f:\n            post2 = requests.post(url, data={\"some\": \"data\"}, files={\"some\": f})\n        assert post2.status_code == 200\n\n        post4 = requests.post(url, data='[{\"some\": \"json\"}]')\n        assert post4.status_code == 200\n\n        with pytest.raises(ValueError):\n            requests.post(url, files=[\"bad file data\"])\n\n    def test_post_with_custom_mapping(self, httpbin):\n        class CustomMapping(MutableMapping):\n            def __init__(self, *args, **kwargs):\n                self.data = dict(*args, **kwargs)\n\n            def __delitem__(self, key):\n                del self.data[key]\n\n            def __getitem__(self, key):\n                return self.data[key]\n\n            def __setitem__(self, key, value):\n                self.data[key] = value\n\n            def __iter__(self):\n                return iter(self.data)\n\n            def __len__(self):\n                return len(self.data)\n\n        data = CustomMapping({\"some\": \"data\"})\n        url = httpbin(\"post\")\n        found_json = requests.post(url, data=data).json().get(\"form\")\n        assert found_jso"}, {"start_line": 23000, "end_line": 25000, "belongs_to": {"file_name": "models.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": " of the ``stream`` keyword argument.\n        self.elapsed = datetime.timedelta(0)\n\n        #: The :class:`PreparedRequest <PreparedRequest>` object to which this\n        #: is a response.\n        self.request = None\n\n    def __enter__(self):\n        return self\n\n    def __exit__(self, *args):\n        self.close()\n\n    def __getstate__(self):\n        # Consume everything; accessing the content attribute makes\n        # sure the content has been fully read.\n        if not self._content_consumed:\n            self.content\n\n        return {attr: getattr(self, attr, None) for attr in self.__attrs__}\n\n    def __setstate__(self, state):\n        for name, value in state.items():\n            setattr(self, name, value)\n\n        # pickled objects do not have .raw\n        setattr(self, \"_content_consumed\", True)\n        setattr(self, \"raw\", None)\n\n    def __repr__(self):\n        return f\"<Response [{self.status_code}]>\"\n\n    def __bool__(self):\n        \"\"\"Returns True if :attr:`status_code` is less than 400.\n\n        This attribute checks if the status code of the response is between\n        400 and 600 to see if there was a client error or a server error. If\n        the status code, is between 200 and 400, this will return True. This\n        is **not** a check to see if the response code is ``200 OK``.\n        \"\"\"\n        return self.ok\n\n    def __nonzero__(self):\n        \"\"\"Returns True if :attr:`status_code` is less than 400.\n\n        This attribute checks if the status code of the response is between\n        400 and 600 to see if there was a client error or a server error. If\n        the status code, is between 200 and 400, this will return True. This\n        is **not** a check to see if the response code is ``200 OK``.\n        \"\"\"\n        return self.ok\n\n    def __iter__(self):\n        \"\"\"Allows you to use a response as an iterator.\"\"\"\n        return self.iter_content(128)\n\n    @property\n    def ok(self):\n        \"\"\"Returns True if :attr:`status_code` is less than 400, Fals"}, {"start_line": 0, "end_line": 2000, "belongs_to": {"file_name": "test_lowlevel.py", "upper_path": "/data2/raymone/swebench-repos/requests/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "import threading\n\nimport pytest\nfrom tests.testserver.server import Server, consume_socket_content\n\nimport requests\nfrom requests.compat import JSONDecodeError\n\nfrom .utils import override_environ\n\n\ndef echo_response_handler(sock):\n    \"\"\"Simple handler that will take request and echo it back to requester.\"\"\"\n    request_content = consume_socket_content(sock, timeout=0.5)\n\n    text_200 = (\n        b\"HTTP/1.1 200 OK\\r\\n\"\n        b\"Content-Length: %d\\r\\n\\r\\n\"\n        b\"%s\"\n    ) % (len(request_content), request_content)\n    sock.send(text_200)\n\n\ndef test_chunked_upload():\n    \"\"\"can safely send generators\"\"\"\n    close_server = threading.Event()\n    server = Server.basic_response_server(wait_to_close_event=close_server)\n    data = iter([b\"a\", b\"b\", b\"c\"])\n\n    with server as (host, port):\n        url = f\"http://{host}:{port}/\"\n        r = requests.post(url, data=data, stream=True)\n        close_server.set()  # release server block\n\n    assert r.status_code == 200\n    assert r.request.headers[\"Transfer-Encoding\"] == \"chunked\"\n\n\ndef test_chunked_encoding_error():\n    \"\"\"get a ChunkedEncodingError if the server returns a bad response\"\"\"\n\n    def incomplete_chunked_response_handler(sock):\n        request_content = consume_socket_content(sock, timeout=0.5)\n\n        # The server never ends the request and doesn't provide any valid chunks\n        sock.send(\n            b\"HTTP/1.1 200 OK\\r\\n\"\n            b\"Transfer-Encoding: chunked\\r\\n\"\n        )\n\n        return request_content\n\n    close_server = threading.Event()\n    server = Server(incomplete_chunked_response_handler)\n\n    with server as (host, port):\n        url = f\"http://{host}:{port}/\"\n        with pytest.raises(requests.exceptions.ChunkedEncodingError):\n            requests.get(url)\n        close_server.set()  # release server block\n\n\ndef test_chunked_upload_uses_only_specified_host_header():\n    \"\"\"Ensure we use only the specified Host header for chunked requests.\"\"\"\n    close_server = threading.Event()\n    server = "}, {"start_line": 1000, "end_line": 3000, "belongs_to": {"file_name": "api.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "ct to send with the :class:`Request`.\n    :param files: (optional) Dictionary of ``'name': file-like-objects`` (or ``{'name': file-tuple}``) for multipart encoding upload.\n        ``file-tuple`` can be a 2-tuple ``('filename', fileobj)``, 3-tuple ``('filename', fileobj, 'content_type')``\n        or a 4-tuple ``('filename', fileobj, 'content_type', custom_headers)``, where ``'content_type'`` is a string\n        defining the content type of the given file and ``custom_headers`` a dict-like object containing additional headers\n        to add for the file.\n    :param auth: (optional) Auth tuple to enable Basic/Digest/Custom HTTP Auth.\n    :param timeout: (optional) How many seconds to wait for the server to send data\n        before giving up, as a float, or a :ref:`(connect timeout, read\n        timeout) <timeouts>` tuple.\n    :type timeout: float or tuple\n    :param allow_redirects: (optional) Boolean. Enable/disable GET/OPTIONS/POST/PUT/PATCH/DELETE/HEAD redirection. Defaults to ``True``.\n    :type allow_redirects: bool\n    :param proxies: (optional) Dictionary mapping protocol to the URL of the proxy.\n    :param verify: (optional) Either a boolean, in which case it controls whether we verify\n            the server's TLS certificate, or a string, in which case it must be a path\n            to a CA bundle to use. Defaults to ``True``.\n    :param stream: (optional) if ``False``, the response content will be immediately downloaded.\n    :param cert: (optional) if String, path to ssl client cert file (.pem). If Tuple, ('cert', 'key') pair.\n    :return: :class:`Response <Response>` object\n    :rtype: requests.Response\n\n    Usage::\n\n      >>> import requests\n      >>> req = requests.request('GET', 'https://httpbin.org/get')\n      >>> req\n      <Response [200]>\n    \"\"\"\n\n    # By using the 'with' statement we are sure the session is closed, thus we\n    # avoid leaving sockets open which can trigger a ResourceWarning in some\n    # cases, and look like a memory leak in others.\n "}], "retrieved_count": 10, "cost_time": 4.536683082580566}
{"question": "Why does Requests provide built-in authentication handlers for common authentication schemes?", "answer": null, "relative_code_list": null, "ground_truth": "Requests provides built-in authentication handlers to address common real-world authentication requirements: 1) Usability - Eliminates the need for users to implement common authentication schemes from scratch, reducing development time and errors; 2) Security - Provides secure, well-tested implementations of authentication protocols that follow security best practices; 3) Standards compliance - Implements authentication schemes according to HTTP standards (RFC 2617 for Basic/Digest, RFC 7235 for authentication framework); 4) Common use cases - Covers the most widely used authentication methods (Basic, Digest, Proxy) that users encounter in practice; 5) Integration - Authentication handlers integrate seamlessly with Sessions and the request preparation system; 6) Extensibility - Provides a base class (AuthBase) that users can extend for custom authentication schemes; 7) Error handling - Built-in handlers include proper error handling and retry logic for authentication challenges; 8) Thread safety - Handlers like HTTPDigestAuth implement thread-safe state management for concurrent usage; 9) Performance - Optimized implementations avoid unnecessary overhead and provide efficient authentication processing; 10) Documentation and examples - Built-in handlers serve as examples and documentation for implementing custom authentication.", "score": null, "retrieved_content": [{"start_line": 0, "end_line": 2000, "belongs_to": {"file_name": "auth.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "\"\"\"\nrequests.auth\n~~~~~~~~~~~~~\n\nThis module contains the authentication handlers for Requests.\n\"\"\"\n\nimport hashlib\nimport os\nimport re\nimport threading\nimport time\nimport warnings\nfrom base64 import b64encode\n\nfrom ._internal_utils import to_native_string\nfrom .compat import basestring, str, urlparse\nfrom .cookies import extract_cookies_to_jar\nfrom .utils import parse_dict_header\n\nCONTENT_TYPE_FORM_URLENCODED = \"application/x-www-form-urlencoded\"\nCONTENT_TYPE_MULTI_PART = \"multipart/form-data\"\n\n\ndef _basic_auth_str(username, password):\n    \"\"\"Returns a Basic Auth string.\"\"\"\n\n    # \"I want us to put a big-ol' comment on top of it that\n    # says that this behaviour is dumb but we need to preserve\n    # it because people are relying on it.\"\n    #    - Lukasa\n    #\n    # These are here solely to maintain backwards compatibility\n    # for things like ints. This will be removed in 3.0.0.\n    if not isinstance(username, basestring):\n        warnings.warn(\n            \"Non-string usernames will no longer be supported in Requests \"\n            \"3.0.0. Please convert the object you've passed in ({!r}) to \"\n            \"a string or bytes object in the near future to avoid \"\n            \"problems.\".format(username),\n            category=DeprecationWarning,\n        )\n        username = str(username)\n\n    if not isinstance(password, basestring):\n        warnings.warn(\n            \"Non-string passwords will no longer be supported in Requests \"\n            \"3.0.0. Please convert the object you've passed in ({!r}) to \"\n            \"a string or bytes object in the near future to avoid \"\n            \"problems.\".format(type(password)),\n            category=DeprecationWarning,\n        )\n        password = str(password)\n    # -- End Removal --\n\n    if isinstance(username, str):\n        username = username.encode(\"latin1\")\n\n    if isinstance(password, str):\n        password = password.encode(\"latin1\")\n\n    authstr = \"Basic \" + to_native_string(\n        b64encode(b\":\".join((username, pas"}, {"start_line": 2000, "end_line": 4000, "belongs_to": {"file_name": "auth.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "sword))).strip()\n    )\n\n    return authstr\n\n\nclass AuthBase:\n    \"\"\"Base class that all auth implementations derive from\"\"\"\n\n    def __call__(self, r):\n        raise NotImplementedError(\"Auth hooks must be callable.\")\n\n\nclass HTTPBasicAuth(AuthBase):\n    \"\"\"Attaches HTTP Basic Authentication to the given Request object.\"\"\"\n\n    def __init__(self, username, password):\n        self.username = username\n        self.password = password\n\n    def __eq__(self, other):\n        return all(\n            [\n                self.username == getattr(other, \"username\", None),\n                self.password == getattr(other, \"password\", None),\n            ]\n        )\n\n    def __ne__(self, other):\n        return not self == other\n\n    def __call__(self, r):\n        r.headers[\"Authorization\"] = _basic_auth_str(self.username, self.password)\n        return r\n\n\nclass HTTPProxyAuth(HTTPBasicAuth):\n    \"\"\"Attaches HTTP Proxy Authentication to a given Request object.\"\"\"\n\n    def __call__(self, r):\n        r.headers[\"Proxy-Authorization\"] = _basic_auth_str(self.username, self.password)\n        return r\n\n\nclass HTTPDigestAuth(AuthBase):\n    \"\"\"Attaches HTTP Digest Authentication to the given Request object.\"\"\"\n\n    def __init__(self, username, password):\n        self.username = username\n        self.password = password\n        # Keep state in per-thread local storage\n        self._thread_local = threading.local()\n\n    def init_per_thread_state(self):\n        # Ensure state is initialized just once per-thread\n        if not hasattr(self._thread_local, \"init\"):\n            self._thread_local.init = True\n            self._thread_local.last_nonce = \"\"\n            self._thread_local.nonce_count = 0\n            self._thread_local.chal = {}\n            self._thread_local.pos = None\n            self._thread_local.num_401_calls = None\n\n    def build_digest_header(self, method, url):\n        \"\"\"\n        :rtype: str\n        \"\"\"\n\n        realm = self._thread_local.chal[\"realm\"]\n        nonce = self._threa"}, {"start_line": 25000, "end_line": 27000, "belongs_to": {"file_name": "test_requests.py", "upper_path": "/data2/raymone/swebench-repos/requests/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "get_netrc_auth_mock(url):\n                return auth\n\n            requests.sessions.get_netrc_auth = get_netrc_auth_mock\n\n            # Should use netrc and work.\n            r = requests.get(url)\n            assert r.status_code == 200\n\n            # Given auth should override and fail.\n            r = requests.get(url, auth=wrong_auth)\n            assert r.status_code == 401\n\n            s = requests.session()\n\n            # Should use netrc and work.\n            r = s.get(url)\n            assert r.status_code == 200\n\n            # Given auth should override and fail.\n            s.auth = wrong_auth\n            r = s.get(url)\n            assert r.status_code == 401\n        finally:\n            requests.sessions.get_netrc_auth = old_auth\n\n    def test_basicauth_with_netrc_leak(self, httpbin):\n        url1 = httpbin(\"basic-auth\", \"user\", \"pass\")\n        url = url1[len(\"http://\") :]\n        domain = url.split(\":\")[0]\n        url = f\"http://example.com:@{url}\"\n\n        netrc_file = \"\"\n        with tempfile.NamedTemporaryFile(mode=\"w\", delete=False) as fp:\n            fp.write(\"machine example.com\\n\")\n            fp.write(\"login wronguser\\n\")\n            fp.write(\"password wrongpass\\n\")\n            fp.write(f\"machine {domain}\\n\")\n            fp.write(\"login user\\n\")\n            fp.write(\"password pass\\n\")\n            fp.close()\n            netrc_file = fp.name\n\n        old_netrc = os.environ.get(\"NETRC\", \"\")\n        os.environ[\"NETRC\"] = netrc_file\n\n        try:\n            # Should use netrc\n            # Make sure that we don't use the example.com credentails\n            # for the request\n            r = requests.get(url)\n            assert r.status_code == 200\n        finally:\n            os.environ[\"NETRC\"] = old_netrc\n            os.unlink(netrc_file)\n\n    def test_DIGEST_HTTP_200_OK_GET(self, httpbin):\n        for authtype in self.digest_auth_algo:\n            auth = HTTPDigestAuth(\"user\", \"pass\")\n            url = httpbin(\"digest-auth\", \"auth\", \"user\", \"pass\", "}, {"start_line": 27000, "end_line": 29000, "belongs_to": {"file_name": "test_requests.py", "upper_path": "/data2/raymone/swebench-repos/requests/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "authtype, \"never\")\n\n            r = requests.get(url, auth=auth)\n            assert r.status_code == 200\n\n            r = requests.get(url)\n            assert r.status_code == 401\n            print(r.headers[\"WWW-Authenticate\"])\n\n            s = requests.session()\n            s.auth = HTTPDigestAuth(\"user\", \"pass\")\n            r = s.get(url)\n            assert r.status_code == 200\n\n    def test_DIGEST_AUTH_RETURNS_COOKIE(self, httpbin):\n        for authtype in self.digest_auth_algo:\n            url = httpbin(\"digest-auth\", \"auth\", \"user\", \"pass\", authtype)\n            auth = HTTPDigestAuth(\"user\", \"pass\")\n            r = requests.get(url)\n            assert r.cookies[\"fake\"] == \"fake_value\"\n\n            r = requests.get(url, auth=auth)\n            assert r.status_code == 200\n\n    def test_DIGEST_AUTH_SETS_SESSION_COOKIES(self, httpbin):\n        for authtype in self.digest_auth_algo:\n            url = httpbin(\"digest-auth\", \"auth\", \"user\", \"pass\", authtype)\n            auth = HTTPDigestAuth(\"user\", \"pass\")\n            s = requests.Session()\n            s.get(url, auth=auth)\n            assert s.cookies[\"fake\"] == \"fake_value\"\n\n    def test_DIGEST_STREAM(self, httpbin):\n        for authtype in self.digest_auth_algo:\n            auth = HTTPDigestAuth(\"user\", \"pass\")\n            url = httpbin(\"digest-auth\", \"auth\", \"user\", \"pass\", authtype)\n\n            r = requests.get(url, auth=auth, stream=True)\n            assert r.raw.read() != b\"\"\n\n            r = requests.get(url, auth=auth, stream=False)\n            assert r.raw.read() == b\"\"\n\n    def test_DIGESTAUTH_WRONG_HTTP_401_GET(self, httpbin):\n        for authtype in self.digest_auth_algo:\n            auth = HTTPDigestAuth(\"user\", \"wrongpass\")\n            url = httpbin(\"digest-auth\", \"auth\", \"user\", \"pass\", authtype)\n\n            r = requests.get(url, auth=auth)\n            assert r.status_code == 401\n\n            r = requests.get(url)\n            assert r.status_code == 401\n\n            s = requests.session()\n          "}, {"start_line": 26000, "end_line": 28000, "belongs_to": {"file_name": "test_requests.py", "upper_path": "/data2/raymone/swebench-repos/requests/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "       with tempfile.NamedTemporaryFile(mode=\"w\", delete=False) as fp:\n            fp.write(\"machine example.com\\n\")\n            fp.write(\"login wronguser\\n\")\n            fp.write(\"password wrongpass\\n\")\n            fp.write(f\"machine {domain}\\n\")\n            fp.write(\"login user\\n\")\n            fp.write(\"password pass\\n\")\n            fp.close()\n            netrc_file = fp.name\n\n        old_netrc = os.environ.get(\"NETRC\", \"\")\n        os.environ[\"NETRC\"] = netrc_file\n\n        try:\n            # Should use netrc\n            # Make sure that we don't use the example.com credentails\n            # for the request\n            r = requests.get(url)\n            assert r.status_code == 200\n        finally:\n            os.environ[\"NETRC\"] = old_netrc\n            os.unlink(netrc_file)\n\n    def test_DIGEST_HTTP_200_OK_GET(self, httpbin):\n        for authtype in self.digest_auth_algo:\n            auth = HTTPDigestAuth(\"user\", \"pass\")\n            url = httpbin(\"digest-auth\", \"auth\", \"user\", \"pass\", authtype, \"never\")\n\n            r = requests.get(url, auth=auth)\n            assert r.status_code == 200\n\n            r = requests.get(url)\n            assert r.status_code == 401\n            print(r.headers[\"WWW-Authenticate\"])\n\n            s = requests.session()\n            s.auth = HTTPDigestAuth(\"user\", \"pass\")\n            r = s.get(url)\n            assert r.status_code == 200\n\n    def test_DIGEST_AUTH_RETURNS_COOKIE(self, httpbin):\n        for authtype in self.digest_auth_algo:\n            url = httpbin(\"digest-auth\", \"auth\", \"user\", \"pass\", authtype)\n            auth = HTTPDigestAuth(\"user\", \"pass\")\n            r = requests.get(url)\n            assert r.cookies[\"fake\"] == \"fake_value\"\n\n            r = requests.get(url, auth=auth)\n            assert r.status_code == 200\n\n    def test_DIGEST_AUTH_SETS_SESSION_COOKIES(self, httpbin):\n        for authtype in self.digest_auth_algo:\n            url = httpbin(\"digest-auth\", \"auth\", \"user\", \"pass\", authtype)\n            auth = HTTPDigest"}, {"start_line": 28000, "end_line": 30000, "belongs_to": {"file_name": "test_requests.py", "upper_path": "/data2/raymone/swebench-repos/requests/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "Auth(\"user\", \"pass\")\n            s = requests.Session()\n            s.get(url, auth=auth)\n            assert s.cookies[\"fake\"] == \"fake_value\"\n\n    def test_DIGEST_STREAM(self, httpbin):\n        for authtype in self.digest_auth_algo:\n            auth = HTTPDigestAuth(\"user\", \"pass\")\n            url = httpbin(\"digest-auth\", \"auth\", \"user\", \"pass\", authtype)\n\n            r = requests.get(url, auth=auth, stream=True)\n            assert r.raw.read() != b\"\"\n\n            r = requests.get(url, auth=auth, stream=False)\n            assert r.raw.read() == b\"\"\n\n    def test_DIGESTAUTH_WRONG_HTTP_401_GET(self, httpbin):\n        for authtype in self.digest_auth_algo:\n            auth = HTTPDigestAuth(\"user\", \"wrongpass\")\n            url = httpbin(\"digest-auth\", \"auth\", \"user\", \"pass\", authtype)\n\n            r = requests.get(url, auth=auth)\n            assert r.status_code == 401\n\n            r = requests.get(url)\n            assert r.status_code == 401\n\n            s = requests.session()\n            s.auth = auth\n            r = s.get(url)\n            assert r.status_code == 401\n\n    def test_DIGESTAUTH_QUOTES_QOP_VALUE(self, httpbin):\n        for authtype in self.digest_auth_algo:\n            auth = HTTPDigestAuth(\"user\", \"pass\")\n            url = httpbin(\"digest-auth\", \"auth\", \"user\", \"pass\", authtype)\n\n            r = requests.get(url, auth=auth)\n            assert '\"auth\"' in r.request.headers[\"Authorization\"]\n\n    def test_POSTBIN_GET_POST_FILES(self, httpbin):\n        url = httpbin(\"post\")\n        requests.post(url).raise_for_status()\n\n        post1 = requests.post(url, data={\"some\": \"data\"})\n        assert post1.status_code == 200\n\n        with open(\"requirements-dev.txt\") as f:\n            post2 = requests.post(url, files={\"some\": f})\n        assert post2.status_code == 200\n\n        post4 = requests.post(url, data='[{\"some\": \"json\"}]')\n        assert post4.status_code == 200\n\n        with pytest.raises(ValueError):\n            requests.post(url, files=[\"bad file data\"])\n"}, {"start_line": 24000, "end_line": 26000, "belongs_to": {"file_name": "test_requests.py", "upper_path": "/data2/raymone/swebench-repos/requests/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "\", {})\n\n        assert sent_headers.get(\"Proxy-Authorization\") == proxy_auth_value\n\n    @pytest.mark.parametrize(\n        \"url,has_proxy_auth\",\n        (\n            (\"http://example.com\", True),\n            (\"https://example.com\", False),\n        ),\n    )\n    def test_proxy_authorization_not_appended_to_https_request(\n        self, url, has_proxy_auth\n    ):\n        session = requests.Session()\n        proxies = {\n            \"http\": \"http://test:pass@localhost:8080\",\n            \"https\": \"http://test:pass@localhost:8090\",\n        }\n        req = requests.Request(\"GET\", url)\n        prep = req.prepare()\n        session.rebuild_proxies(prep, proxies)\n\n        assert (\"Proxy-Authorization\" in prep.headers) is has_proxy_auth\n\n    def test_basicauth_with_netrc(self, httpbin):\n        auth = (\"user\", \"pass\")\n        wrong_auth = (\"wronguser\", \"wrongpass\")\n        url = httpbin(\"basic-auth\", \"user\", \"pass\")\n\n        old_auth = requests.sessions.get_netrc_auth\n\n        try:\n\n            def get_netrc_auth_mock(url):\n                return auth\n\n            requests.sessions.get_netrc_auth = get_netrc_auth_mock\n\n            # Should use netrc and work.\n            r = requests.get(url)\n            assert r.status_code == 200\n\n            # Given auth should override and fail.\n            r = requests.get(url, auth=wrong_auth)\n            assert r.status_code == 401\n\n            s = requests.session()\n\n            # Should use netrc and work.\n            r = s.get(url)\n            assert r.status_code == 200\n\n            # Given auth should override and fail.\n            s.auth = wrong_auth\n            r = s.get(url)\n            assert r.status_code == 401\n        finally:\n            requests.sessions.get_netrc_auth = old_auth\n\n    def test_basicauth_with_netrc_leak(self, httpbin):\n        url1 = httpbin(\"basic-auth\", \"user\", \"pass\")\n        url = url1[len(\"http://\") :]\n        domain = url.split(\":\")[0]\n        url = f\"http://example.com:@{url}\"\n\n        netrc_file = \"\"\n "}, {"start_line": 8000, "end_line": 10000, "belongs_to": {"file_name": "test_lowlevel.py", "upper_path": "/data2/raymone/swebench-repos/requests/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "_socket_content(sock, timeout=0.5)\n        assert request_content == b''\n\n        return request_content\n\n    close_server = threading.Event()\n    server = Server(digest_failed_response_handler, wait_to_close_event=close_server)\n\n    with server as (host, port):\n        url = f'http://{host}:{port}/'\n        r = requests.get(url, auth=auth)\n        # Verify server didn't authenticate us.\n        assert r.status_code == 401\n        assert r.history[0].status_code == 401\n        close_server.set()\n\n\ndef test_digestauth_only_on_4xx():\n    \"\"\"Ensure we only send digestauth on 4xx challenges.\n\n    See https://github.com/psf/requests/issues/3772.\n    \"\"\"\n    text_200_chal = (b'HTTP/1.1 200 OK\\r\\n'\n                     b'Content-Length: 0\\r\\n'\n                     b'WWW-Authenticate: Digest nonce=\"6bf5d6e4da1ce66918800195d6b9130d\"'\n                     b', opaque=\"372825293d1c26955496c80ed6426e9e\", '\n                     b'realm=\"me@kennethreitz.com\", qop=auth\\r\\n\\r\\n')\n\n    auth = requests.auth.HTTPDigestAuth('user', 'pass')\n\n    def digest_response_handler(sock):\n        # Respond to GET with a 200 containing www-authenticate header.\n        request_content = consume_socket_content(sock, timeout=0.5)\n        assert request_content.startswith(b\"GET / HTTP/1.1\")\n        sock.send(text_200_chal)\n\n        # Verify the client didn't respond with auth.\n        request_content = consume_socket_content(sock, timeout=0.5)\n        assert request_content == b''\n\n        return request_content\n\n    close_server = threading.Event()\n    server = Server(digest_response_handler, wait_to_close_event=close_server)\n\n    with server as (host, port):\n        url = f'http://{host}:{port}/'\n        r = requests.get(url, auth=auth)\n        # Verify server didn't receive auth from us.\n        assert r.status_code == 200\n        assert len(r.history) == 0\n        close_server.set()\n\n\n_schemes_by_var_prefix = [\n    ('http', ['http']),\n    ('https', ['https']),\n    ('all', ['http', 'https']),\n]\n\n_p"}, {"start_line": 1000, "end_line": 3000, "belongs_to": {"file_name": "auth.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "ill no longer be supported in Requests \"\n            \"3.0.0. Please convert the object you've passed in ({!r}) to \"\n            \"a string or bytes object in the near future to avoid \"\n            \"problems.\".format(username),\n            category=DeprecationWarning,\n        )\n        username = str(username)\n\n    if not isinstance(password, basestring):\n        warnings.warn(\n            \"Non-string passwords will no longer be supported in Requests \"\n            \"3.0.0. Please convert the object you've passed in ({!r}) to \"\n            \"a string or bytes object in the near future to avoid \"\n            \"problems.\".format(type(password)),\n            category=DeprecationWarning,\n        )\n        password = str(password)\n    # -- End Removal --\n\n    if isinstance(username, str):\n        username = username.encode(\"latin1\")\n\n    if isinstance(password, str):\n        password = password.encode(\"latin1\")\n\n    authstr = \"Basic \" + to_native_string(\n        b64encode(b\":\".join((username, password))).strip()\n    )\n\n    return authstr\n\n\nclass AuthBase:\n    \"\"\"Base class that all auth implementations derive from\"\"\"\n\n    def __call__(self, r):\n        raise NotImplementedError(\"Auth hooks must be callable.\")\n\n\nclass HTTPBasicAuth(AuthBase):\n    \"\"\"Attaches HTTP Basic Authentication to the given Request object.\"\"\"\n\n    def __init__(self, username, password):\n        self.username = username\n        self.password = password\n\n    def __eq__(self, other):\n        return all(\n            [\n                self.username == getattr(other, \"username\", None),\n                self.password == getattr(other, \"password\", None),\n            ]\n        )\n\n    def __ne__(self, other):\n        return not self == other\n\n    def __call__(self, r):\n        r.headers[\"Authorization\"] = _basic_auth_str(self.username, self.password)\n        return r\n\n\nclass HTTPProxyAuth(HTTPBasicAuth):\n    \"\"\"Attaches HTTP Proxy Authentication to a given Request object.\"\"\"\n\n    def __call__(self, r):\n        r.hea"}, {"start_line": 66000, "end_line": 68000, "belongs_to": {"file_name": "test_requests.py", "upper_path": "/data2/raymone/swebench-repos/requests/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "rt \"multipart/form-data\" in p.headers[\"Content-Type\"]\n\n    def test_autoset_header_values_are_native(self, httpbin):\n        data = \"this is a string\"\n        length = \"16\"\n        req = requests.Request(\"POST\", httpbin(\"post\"), data=data)\n        p = req.prepare()\n\n        assert p.headers[\"Content-Length\"] == length\n\n    def test_nonhttp_schemes_dont_check_URLs(self):\n        test_urls = (\n            \"data:image/gif;base64,R0lGODlhAQABAHAAACH5BAUAAAAALAAAAAABAAEAAAICRAEAOw==\",\n            \"file:///etc/passwd\",\n            \"magnet:?xt=urn:btih:be08f00302bc2d1d3cfa3af02024fa647a271431\",\n        )\n        for test_url in test_urls:\n            req = requests.Request(\"GET\", test_url)\n            preq = req.prepare()\n            assert test_url == preq.url\n\n    def test_auth_is_stripped_on_http_downgrade(\n        self, httpbin, httpbin_secure, httpbin_ca_bundle\n    ):\n        r = requests.get(\n            httpbin_secure(\"redirect-to\"),\n            params={\"url\": httpbin(\"get\")},\n            auth=(\"user\", \"pass\"),\n            verify=httpbin_ca_bundle,\n        )\n        assert r.history[0].request.headers[\"Authorization\"]\n        assert \"Authorization\" not in r.request.headers\n\n    def test_auth_is_retained_for_redirect_on_host(self, httpbin):\n        r = requests.get(httpbin(\"redirect/1\"), auth=(\"user\", \"pass\"))\n        h1 = r.history[0].request.headers[\"Authorization\"]\n        h2 = r.request.headers[\"Authorization\"]\n\n        assert h1 == h2\n\n    def test_should_strip_auth_host_change(self):\n        s = requests.Session()\n        assert s.should_strip_auth(\n            \"http://example.com/foo\", \"http://another.example.com/\"\n        )\n\n    def test_should_strip_auth_http_downgrade(self):\n        s = requests.Session()\n        assert s.should_strip_auth(\"https://example.com/foo\", \"http://example.com/bar\")\n\n    def test_should_strip_auth_https_upgrade(self):\n        s = requests.Session()\n        assert not s.should_strip_auth(\n            \"http://example.com/foo\", \"https"}], "retrieved_count": 10, "cost_time": 4.582193613052368}
{"question": "Where in the Requests codebase does the response flow from the transport layer through the response object back to the user application?", "answer": null, "relative_code_list": null, "ground_truth": "The response flow from transport layer to user application occurs in src/requests/adapters.py through HTTPAdapter.build_response() method, which creates a Response object from the urllib3 response. The flow then returns through Session.send() in src/requests/sessions.py, which processes the response through redirect handling (Session.resolve_redirects()) and cookie extraction (extract_cookies_to_jar()). The Response object is then returned to the user application. The complete response flow is: urllib3.HTTPResponse  HTTPAdapter.build_response()  Response object creation  Session.send()  redirect processing  cookie extraction  Response object returned to user. The Response class itself is defined in src/requests/models.py and provides the user interface for accessing response data, headers, status codes, and content.", "score": null, "retrieved_content": [{"start_line": 12000, "end_line": 14000, "belongs_to": {"file_name": "adapters.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "Response\n        \"\"\"\n        response = Response()\n\n        # Fallback to None if there's no status_code, for whatever reason.\n        response.status_code = getattr(resp, \"status\", None)\n\n        # Make headers case-insensitive.\n        response.headers = CaseInsensitiveDict(getattr(resp, \"headers\", {}))\n\n        # Set encoding.\n        response.encoding = get_encoding_from_headers(response.headers)\n        response.raw = resp\n        response.reason = response.raw.reason\n\n        if isinstance(req.url, bytes):\n            response.url = req.url.decode(\"utf-8\")\n        else:\n            response.url = req.url\n\n        # Add new cookies from the server.\n        extract_cookies_to_jar(response.cookies, req, resp)\n\n        # Give the Response some context.\n        response.request = req\n        response.connection = self\n\n        return response\n\n    def build_connection_pool_key_attributes(self, request, verify, cert=None):\n        \"\"\"Build the PoolKey attributes used by urllib3 to return a connection.\n\n        This looks at the PreparedRequest, the user-specified verify value,\n        and the value of the cert parameter to determine what PoolKey values\n        to use to select a connection from a given urllib3 Connection Pool.\n\n        The SSL related pool key arguments are not consistently set. As of\n        this writing, use the following to determine what keys may be in that\n        dictionary:\n\n        * If ``verify`` is ``True``, ``\"ssl_context\"`` will be set and will be the\n          default Requests SSL Context\n        * If ``verify`` is ``False``, ``\"ssl_context\"`` will not be set but\n          ``\"cert_reqs\"`` will be set\n        * If ``verify`` is a string, (i.e., it is a user-specified trust bundle)\n          ``\"ca_certs\"`` will be set if the string is not a directory recognized\n          by :py:func:`os.path.isdir`, otherwise ``\"ca_cert_dir\"`` will be\n          set.\n        * If ``\"cert\"`` is specified, ``\"cert_file\"`` will always be set. If\n          ``\""}, {"start_line": 21000, "end_line": 23000, "belongs_to": {"file_name": "models.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "nse>` object, which contains a\n    server's response to an HTTP request.\n    \"\"\"\n\n    __attrs__ = [\n        \"_content\",\n        \"status_code\",\n        \"headers\",\n        \"url\",\n        \"history\",\n        \"encoding\",\n        \"reason\",\n        \"cookies\",\n        \"elapsed\",\n        \"request\",\n    ]\n\n    def __init__(self):\n        self._content = False\n        self._content_consumed = False\n        self._next = None\n\n        #: Integer Code of responded HTTP Status, e.g. 404 or 200.\n        self.status_code = None\n\n        #: Case-insensitive Dictionary of Response Headers.\n        #: For example, ``headers['content-encoding']`` will return the\n        #: value of a ``'Content-Encoding'`` response header.\n        self.headers = CaseInsensitiveDict()\n\n        #: File-like object representation of response (for advanced usage).\n        #: Use of ``raw`` requires that ``stream=True`` be set on the request.\n        #: This requirement does not apply for use internally to Requests.\n        self.raw = None\n\n        #: Final URL location of Response.\n        self.url = None\n\n        #: Encoding to decode with when accessing r.text.\n        self.encoding = None\n\n        #: A list of :class:`Response <Response>` objects from\n        #: the history of the Request. Any redirect responses will end\n        #: up here. The list is sorted from the oldest to the most recent request.\n        self.history = []\n\n        #: Textual reason of responded HTTP Status, e.g. \"Not Found\" or \"OK\".\n        self.reason = None\n\n        #: A CookieJar of Cookies the server sent back.\n        self.cookies = cookiejar_from_dict({})\n\n        #: The amount of time elapsed between sending the request\n        #: and the arrival of the response (as a timedelta).\n        #: This property specifically measures the time taken between sending\n        #: the first byte of the request and finishing parsing the headers. It\n        #: is therefore unaffected by consuming the response content or the\n        #: value"}, {"start_line": 5000, "end_line": 7000, "belongs_to": {"file_name": "sessions.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "        changed_port = old_parsed.port != new_parsed.port\n        changed_scheme = old_parsed.scheme != new_parsed.scheme\n        default_port = (DEFAULT_PORTS.get(old_parsed.scheme, None), None)\n        if (\n            not changed_scheme\n            and old_parsed.port in default_port\n            and new_parsed.port in default_port\n        ):\n            return False\n\n        # Standard case: root URI must match\n        return changed_port or changed_scheme\n\n    def resolve_redirects(\n        self,\n        resp,\n        req,\n        stream=False,\n        timeout=None,\n        verify=True,\n        cert=None,\n        proxies=None,\n        yield_requests=False,\n        **adapter_kwargs,\n    ):\n        \"\"\"Receives a Response. Returns a generator of Responses or Requests.\"\"\"\n\n        hist = []  # keep track of history\n\n        url = self.get_redirect_target(resp)\n        previous_fragment = urlparse(req.url).fragment\n        while url:\n            prepared_request = req.copy()\n\n            # Update history and keep track of redirects.\n            # resp.history must ignore the original request in this loop\n            hist.append(resp)\n            resp.history = hist[1:]\n\n            try:\n                resp.content  # Consume socket so it can be released\n            except (ChunkedEncodingError, ContentDecodingError, RuntimeError):\n                resp.raw.read(decode_content=False)\n\n            if len(resp.history) >= self.max_redirects:\n                raise TooManyRedirects(\n                    f\"Exceeded {self.max_redirects} redirects.\", response=resp\n                )\n\n            # Release the connection back into the pool.\n            resp.close()\n\n            # Handle redirection without scheme (see: RFC 1808 Section 4)\n            if url.startswith(\"//\"):\n                parsed_rurl = urlparse(resp.url)\n                url = \":\".join([to_native_string(parsed_rurl.scheme), url])\n\n            # Normalize url case and attach previous fragment if needed (RFC 723"}, {"start_line": 4000, "end_line": 6000, "belongs_to": {"file_name": "sessions.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "ion in latin1.\n            location = location.encode(\"latin1\")\n            return to_native_string(location, \"utf8\")\n        return None\n\n    def should_strip_auth(self, old_url, new_url):\n        \"\"\"Decide whether Authorization header should be removed when redirecting\"\"\"\n        old_parsed = urlparse(old_url)\n        new_parsed = urlparse(new_url)\n        if old_parsed.hostname != new_parsed.hostname:\n            return True\n        # Special case: allow http -> https redirect when using the standard\n        # ports. This isn't specified by RFC 7235, but is kept to avoid\n        # breaking backwards compatibility with older versions of requests\n        # that allowed any redirects on the same host.\n        if (\n            old_parsed.scheme == \"http\"\n            and old_parsed.port in (80, None)\n            and new_parsed.scheme == \"https\"\n            and new_parsed.port in (443, None)\n        ):\n            return False\n\n        # Handle default port usage corresponding to scheme.\n        changed_port = old_parsed.port != new_parsed.port\n        changed_scheme = old_parsed.scheme != new_parsed.scheme\n        default_port = (DEFAULT_PORTS.get(old_parsed.scheme, None), None)\n        if (\n            not changed_scheme\n            and old_parsed.port in default_port\n            and new_parsed.port in default_port\n        ):\n            return False\n\n        # Standard case: root URI must match\n        return changed_port or changed_scheme\n\n    def resolve_redirects(\n        self,\n        resp,\n        req,\n        stream=False,\n        timeout=None,\n        verify=True,\n        cert=None,\n        proxies=None,\n        yield_requests=False,\n        **adapter_kwargs,\n    ):\n        \"\"\"Receives a Response. Returns a generator of Responses or Requests.\"\"\"\n\n        hist = []  # keep track of history\n\n        url = self.get_redirect_target(resp)\n        previous_fragment = urlparse(req.url).fragment\n        while url:\n            prepared_request = req.copy()\n\n          "}, {"start_line": 74000, "end_line": 76000, "belongs_to": {"file_name": "test_requests.py", "upper_path": "/data2/raymone/swebench-repos/requests/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "name, password)\n        assert isinstance(s, builtin_str)\n        assert s == auth_str\n\n    def test_requests_history_is_saved(self, httpbin):\n        r = requests.get(httpbin(\"redirect/5\"))\n        total = r.history[-1].history\n        i = 0\n        for item in r.history:\n            assert item.history == total[0:i]\n            i += 1\n\n    def test_json_param_post_content_type_works(self, httpbin):\n        r = requests.post(httpbin(\"post\"), json={\"life\": 42})\n        assert r.status_code == 200\n        assert \"application/json\" in r.request.headers[\"Content-Type\"]\n        assert {\"life\": 42} == r.json()[\"json\"]\n\n    def test_json_param_post_should_not_override_data_param(self, httpbin):\n        r = requests.Request(\n            method=\"POST\",\n            url=httpbin(\"post\"),\n            data={\"stuff\": \"elixr\"},\n            json={\"music\": \"flute\"},\n        )\n        prep = r.prepare()\n        assert \"stuff=elixr\" == prep.body\n\n    def test_response_iter_lines(self, httpbin):\n        r = requests.get(httpbin(\"stream/4\"), stream=True)\n        assert r.status_code == 200\n\n        it = r.iter_lines()\n        next(it)\n        assert len(list(it)) == 3\n\n    def test_response_context_manager(self, httpbin):\n        with requests.get(httpbin(\"stream/4\"), stream=True) as response:\n            assert isinstance(response, requests.Response)\n\n        assert response.raw.closed\n\n    def test_unconsumed_session_response_closes_connection(self, httpbin):\n        s = requests.session()\n\n        with contextlib.closing(s.get(httpbin(\"stream/4\"), stream=True)) as response:\n            pass\n\n        assert response._content_consumed is False\n        assert response.raw.closed\n\n    @pytest.mark.xfail\n    def test_response_iter_lines_reentrant(self, httpbin):\n        \"\"\"Response.iter_lines() is not reentrant safe\"\"\"\n        r = requests.get(httpbin(\"stream/4\"), stream=True)\n        assert r.status_code == 200\n\n        next(r.iter_lines())\n        assert len(list(r.iter_lines())) == 3\n\n"}, {"start_line": 22000, "end_line": 24000, "belongs_to": {"file_name": "models.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "f.raw = None\n\n        #: Final URL location of Response.\n        self.url = None\n\n        #: Encoding to decode with when accessing r.text.\n        self.encoding = None\n\n        #: A list of :class:`Response <Response>` objects from\n        #: the history of the Request. Any redirect responses will end\n        #: up here. The list is sorted from the oldest to the most recent request.\n        self.history = []\n\n        #: Textual reason of responded HTTP Status, e.g. \"Not Found\" or \"OK\".\n        self.reason = None\n\n        #: A CookieJar of Cookies the server sent back.\n        self.cookies = cookiejar_from_dict({})\n\n        #: The amount of time elapsed between sending the request\n        #: and the arrival of the response (as a timedelta).\n        #: This property specifically measures the time taken between sending\n        #: the first byte of the request and finishing parsing the headers. It\n        #: is therefore unaffected by consuming the response content or the\n        #: value of the ``stream`` keyword argument.\n        self.elapsed = datetime.timedelta(0)\n\n        #: The :class:`PreparedRequest <PreparedRequest>` object to which this\n        #: is a response.\n        self.request = None\n\n    def __enter__(self):\n        return self\n\n    def __exit__(self, *args):\n        self.close()\n\n    def __getstate__(self):\n        # Consume everything; accessing the content attribute makes\n        # sure the content has been fully read.\n        if not self._content_consumed:\n            self.content\n\n        return {attr: getattr(self, attr, None) for attr in self.__attrs__}\n\n    def __setstate__(self, state):\n        for name, value in state.items():\n            setattr(self, name, value)\n\n        # pickled objects do not have .raw\n        setattr(self, \"_content_consumed\", True)\n        setattr(self, \"raw\", None)\n\n    def __repr__(self):\n        return f\"<Response [{self.status_code}]>\"\n\n    def __bool__(self):\n        \"\"\"Returns True if :attr:`status_code` is less"}, {"start_line": 3000, "end_line": 5000, "belongs_to": {"file_name": "adapters.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "     \"host\": parsed_request_url.hostname,\n        \"port\": port,\n    }\n    return host_params, pool_kwargs\n\n\nclass BaseAdapter:\n    \"\"\"The Base Transport Adapter\"\"\"\n\n    def __init__(self):\n        super().__init__()\n\n    def send(\n        self, request, stream=False, timeout=None, verify=True, cert=None, proxies=None\n    ):\n        \"\"\"Sends PreparedRequest object. Returns Response object.\n\n        :param request: The :class:`PreparedRequest <PreparedRequest>` being sent.\n        :param stream: (optional) Whether to stream the request content.\n        :param timeout: (optional) How long to wait for the server to send\n            data before giving up, as a float, or a :ref:`(connect timeout,\n            read timeout) <timeouts>` tuple.\n        :type timeout: float or tuple\n        :param verify: (optional) Either a boolean, in which case it controls whether we verify\n            the server's TLS certificate, or a string, in which case it must be a path\n            to a CA bundle to use\n        :param cert: (optional) Any user-provided SSL certificate to be trusted.\n        :param proxies: (optional) The proxies dictionary to apply to the request.\n        \"\"\"\n        raise NotImplementedError\n\n    def close(self):\n        \"\"\"Cleans up adapter specific items.\"\"\"\n        raise NotImplementedError\n\n\nclass HTTPAdapter(BaseAdapter):\n    \"\"\"The built-in HTTP Adapter for urllib3.\n\n    Provides a general-case interface for Requests sessions to contact HTTP and\n    HTTPS urls by implementing the Transport Adapter interface. This class will\n    usually be created by the :class:`Session <Session>` class under the\n    covers.\n\n    :param pool_connections: The number of urllib3 connection pools to cache.\n    :param pool_maxsize: The maximum number of connections to save in the pool.\n    :param max_retries: The maximum number of retries each connection\n        should attempt. Note, this applies only to failed DNS lookups, socket\n        connections and connection timeouts, never to"}, {"start_line": 23000, "end_line": 25000, "belongs_to": {"file_name": "models.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": " of the ``stream`` keyword argument.\n        self.elapsed = datetime.timedelta(0)\n\n        #: The :class:`PreparedRequest <PreparedRequest>` object to which this\n        #: is a response.\n        self.request = None\n\n    def __enter__(self):\n        return self\n\n    def __exit__(self, *args):\n        self.close()\n\n    def __getstate__(self):\n        # Consume everything; accessing the content attribute makes\n        # sure the content has been fully read.\n        if not self._content_consumed:\n            self.content\n\n        return {attr: getattr(self, attr, None) for attr in self.__attrs__}\n\n    def __setstate__(self, state):\n        for name, value in state.items():\n            setattr(self, name, value)\n\n        # pickled objects do not have .raw\n        setattr(self, \"_content_consumed\", True)\n        setattr(self, \"raw\", None)\n\n    def __repr__(self):\n        return f\"<Response [{self.status_code}]>\"\n\n    def __bool__(self):\n        \"\"\"Returns True if :attr:`status_code` is less than 400.\n\n        This attribute checks if the status code of the response is between\n        400 and 600 to see if there was a client error or a server error. If\n        the status code, is between 200 and 400, this will return True. This\n        is **not** a check to see if the response code is ``200 OK``.\n        \"\"\"\n        return self.ok\n\n    def __nonzero__(self):\n        \"\"\"Returns True if :attr:`status_code` is less than 400.\n\n        This attribute checks if the status code of the response is between\n        400 and 600 to see if there was a client error or a server error. If\n        the status code, is between 200 and 400, this will return True. This\n        is **not** a check to see if the response code is ``200 OK``.\n        \"\"\"\n        return self.ok\n\n    def __iter__(self):\n        \"\"\"Allows you to use a response as an iterator.\"\"\"\n        return self.iter_content(128)\n\n    @property\n    def ok(self):\n        \"\"\"Returns True if :attr:`status_code` is less than 400, Fals"}, {"start_line": 75000, "end_line": 77000, "belongs_to": {"file_name": "test_requests.py", "upper_path": "/data2/raymone/swebench-repos/requests/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": " = requests.get(httpbin(\"stream/4\"), stream=True)\n        assert r.status_code == 200\n\n        it = r.iter_lines()\n        next(it)\n        assert len(list(it)) == 3\n\n    def test_response_context_manager(self, httpbin):\n        with requests.get(httpbin(\"stream/4\"), stream=True) as response:\n            assert isinstance(response, requests.Response)\n\n        assert response.raw.closed\n\n    def test_unconsumed_session_response_closes_connection(self, httpbin):\n        s = requests.session()\n\n        with contextlib.closing(s.get(httpbin(\"stream/4\"), stream=True)) as response:\n            pass\n\n        assert response._content_consumed is False\n        assert response.raw.closed\n\n    @pytest.mark.xfail\n    def test_response_iter_lines_reentrant(self, httpbin):\n        \"\"\"Response.iter_lines() is not reentrant safe\"\"\"\n        r = requests.get(httpbin(\"stream/4\"), stream=True)\n        assert r.status_code == 200\n\n        next(r.iter_lines())\n        assert len(list(r.iter_lines())) == 3\n\n    def test_session_close_proxy_clear(self):\n        proxies = {\n            \"one\": mock.Mock(),\n            \"two\": mock.Mock(),\n        }\n        session = requests.Session()\n        with mock.patch.dict(session.adapters[\"http://\"].proxy_manager, proxies):\n            session.close()\n            proxies[\"one\"].clear.assert_called_once_with()\n            proxies[\"two\"].clear.assert_called_once_with()\n\n    def test_proxy_auth(self):\n        adapter = HTTPAdapter()\n        headers = adapter.proxy_headers(\"http://user:pass@httpbin.org\")\n        assert headers == {\"Proxy-Authorization\": \"Basic dXNlcjpwYXNz\"}\n\n    def test_proxy_auth_empty_pass(self):\n        adapter = HTTPAdapter()\n        headers = adapter.proxy_headers(\"http://user:@httpbin.org\")\n        assert headers == {\"Proxy-Authorization\": \"Basic dXNlcjo=\"}\n\n    def test_response_json_when_content_is_None(self, httpbin):\n        r = requests.get(httpbin(\"/status/204\"))\n        # Make sure r.content is None\n        r.status_code = "}, {"start_line": 52000, "end_line": 54000, "belongs_to": {"file_name": "test_requests.py", "upper_path": "/data2/raymone/swebench-repos/requests/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": " = requests.Response()\n        r.raw = io.BytesIO(b\"the content\")\n        chunks = r.iter_content(None)\n        assert list(chunks) == [b\"the content\"]\n\n        r = requests.Response()\n        r.raw = io.BytesIO(b\"the content\")\n        with pytest.raises(TypeError):\n            chunks = r.iter_content(\"1024\")\n\n    @pytest.mark.parametrize(\n        \"exception, args, expected\",\n        (\n            (urllib3.exceptions.ProtocolError, tuple(), ChunkedEncodingError),\n            (urllib3.exceptions.DecodeError, tuple(), ContentDecodingError),\n            (urllib3.exceptions.ReadTimeoutError, (None, \"\", \"\"), ConnectionError),\n            (urllib3.exceptions.SSLError, tuple(), RequestsSSLError),\n        ),\n    )\n    def test_iter_content_wraps_exceptions(self, httpbin, exception, args, expected):\n        r = requests.Response()\n        r.raw = mock.Mock()\n        # ReadTimeoutError can't be initialized by mock\n        # so we'll manually create the instance with args\n        r.raw.stream.side_effect = exception(*args)\n\n        with pytest.raises(expected):\n            next(r.iter_content(1024))\n\n    def test_request_and_response_are_pickleable(self, httpbin):\n        r = requests.get(httpbin(\"get\"))\n\n        # verify we can pickle the original request\n        assert pickle.loads(pickle.dumps(r.request))\n\n        # verify we can pickle the response and that we have access to\n        # the original request.\n        pr = pickle.loads(pickle.dumps(r))\n        assert r.request.url == pr.request.url\n        assert r.request.headers == pr.request.headers\n\n    def test_prepared_request_is_pickleable(self, httpbin):\n        p = requests.Request(\"GET\", httpbin(\"get\")).prepare()\n\n        # Verify PreparedRequest can be pickled and unpickled\n        r = pickle.loads(pickle.dumps(p))\n        assert r.url == p.url\n        assert r.headers == p.headers\n        assert r.body == p.body\n\n        # Verify unpickled PreparedRequest sends properly\n        s = requests.Session()\n        resp ="}], "retrieved_count": 10, "cost_time": 4.5916221141815186}
{"question": "Where does Requests store its authentication handlers?", "answer": null, "relative_code_list": null, "ground_truth": "Requests stores its authentication handlers in src/requests/auth.py. This file contains: 1) HTTPBasicAuth class for Basic Authentication; 2) HTTPDigestAuth class for Digest Authentication with support for MD5, SHA, SHA-256, and SHA-512 algorithms; 3) HTTPProxyAuth class for proxy authentication; 4) AuthBase abstract base class that defines the interface for all authentication handlers; 5) Helper functions like _basic_auth_str() for encoding authentication credentials. The authentication handlers are callable objects that implement the __call__() method to modify Request objects by adding appropriate Authorization or Proxy-Authorization headers. These handlers are applied during request preparation in PreparedRequest.prepare_auth() method in src/requests/models.py, and they integrate with the session management system in src/requests/sessions.py for persistent authentication across multiple requests.", "score": null, "retrieved_content": [{"start_line": 0, "end_line": 2000, "belongs_to": {"file_name": "auth.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "\"\"\"\nrequests.auth\n~~~~~~~~~~~~~\n\nThis module contains the authentication handlers for Requests.\n\"\"\"\n\nimport hashlib\nimport os\nimport re\nimport threading\nimport time\nimport warnings\nfrom base64 import b64encode\n\nfrom ._internal_utils import to_native_string\nfrom .compat import basestring, str, urlparse\nfrom .cookies import extract_cookies_to_jar\nfrom .utils import parse_dict_header\n\nCONTENT_TYPE_FORM_URLENCODED = \"application/x-www-form-urlencoded\"\nCONTENT_TYPE_MULTI_PART = \"multipart/form-data\"\n\n\ndef _basic_auth_str(username, password):\n    \"\"\"Returns a Basic Auth string.\"\"\"\n\n    # \"I want us to put a big-ol' comment on top of it that\n    # says that this behaviour is dumb but we need to preserve\n    # it because people are relying on it.\"\n    #    - Lukasa\n    #\n    # These are here solely to maintain backwards compatibility\n    # for things like ints. This will be removed in 3.0.0.\n    if not isinstance(username, basestring):\n        warnings.warn(\n            \"Non-string usernames will no longer be supported in Requests \"\n            \"3.0.0. Please convert the object you've passed in ({!r}) to \"\n            \"a string or bytes object in the near future to avoid \"\n            \"problems.\".format(username),\n            category=DeprecationWarning,\n        )\n        username = str(username)\n\n    if not isinstance(password, basestring):\n        warnings.warn(\n            \"Non-string passwords will no longer be supported in Requests \"\n            \"3.0.0. Please convert the object you've passed in ({!r}) to \"\n            \"a string or bytes object in the near future to avoid \"\n            \"problems.\".format(type(password)),\n            category=DeprecationWarning,\n        )\n        password = str(password)\n    # -- End Removal --\n\n    if isinstance(username, str):\n        username = username.encode(\"latin1\")\n\n    if isinstance(password, str):\n        password = password.encode(\"latin1\")\n\n    authstr = \"Basic \" + to_native_string(\n        b64encode(b\":\".join((username, pas"}, {"start_line": 2000, "end_line": 4000, "belongs_to": {"file_name": "auth.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "sword))).strip()\n    )\n\n    return authstr\n\n\nclass AuthBase:\n    \"\"\"Base class that all auth implementations derive from\"\"\"\n\n    def __call__(self, r):\n        raise NotImplementedError(\"Auth hooks must be callable.\")\n\n\nclass HTTPBasicAuth(AuthBase):\n    \"\"\"Attaches HTTP Basic Authentication to the given Request object.\"\"\"\n\n    def __init__(self, username, password):\n        self.username = username\n        self.password = password\n\n    def __eq__(self, other):\n        return all(\n            [\n                self.username == getattr(other, \"username\", None),\n                self.password == getattr(other, \"password\", None),\n            ]\n        )\n\n    def __ne__(self, other):\n        return not self == other\n\n    def __call__(self, r):\n        r.headers[\"Authorization\"] = _basic_auth_str(self.username, self.password)\n        return r\n\n\nclass HTTPProxyAuth(HTTPBasicAuth):\n    \"\"\"Attaches HTTP Proxy Authentication to a given Request object.\"\"\"\n\n    def __call__(self, r):\n        r.headers[\"Proxy-Authorization\"] = _basic_auth_str(self.username, self.password)\n        return r\n\n\nclass HTTPDigestAuth(AuthBase):\n    \"\"\"Attaches HTTP Digest Authentication to the given Request object.\"\"\"\n\n    def __init__(self, username, password):\n        self.username = username\n        self.password = password\n        # Keep state in per-thread local storage\n        self._thread_local = threading.local()\n\n    def init_per_thread_state(self):\n        # Ensure state is initialized just once per-thread\n        if not hasattr(self._thread_local, \"init\"):\n            self._thread_local.init = True\n            self._thread_local.last_nonce = \"\"\n            self._thread_local.nonce_count = 0\n            self._thread_local.chal = {}\n            self._thread_local.pos = None\n            self._thread_local.num_401_calls = None\n\n    def build_digest_header(self, method, url):\n        \"\"\"\n        :rtype: str\n        \"\"\"\n\n        realm = self._thread_local.chal[\"realm\"]\n        nonce = self._threa"}, {"start_line": 25000, "end_line": 27000, "belongs_to": {"file_name": "test_requests.py", "upper_path": "/data2/raymone/swebench-repos/requests/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "get_netrc_auth_mock(url):\n                return auth\n\n            requests.sessions.get_netrc_auth = get_netrc_auth_mock\n\n            # Should use netrc and work.\n            r = requests.get(url)\n            assert r.status_code == 200\n\n            # Given auth should override and fail.\n            r = requests.get(url, auth=wrong_auth)\n            assert r.status_code == 401\n\n            s = requests.session()\n\n            # Should use netrc and work.\n            r = s.get(url)\n            assert r.status_code == 200\n\n            # Given auth should override and fail.\n            s.auth = wrong_auth\n            r = s.get(url)\n            assert r.status_code == 401\n        finally:\n            requests.sessions.get_netrc_auth = old_auth\n\n    def test_basicauth_with_netrc_leak(self, httpbin):\n        url1 = httpbin(\"basic-auth\", \"user\", \"pass\")\n        url = url1[len(\"http://\") :]\n        domain = url.split(\":\")[0]\n        url = f\"http://example.com:@{url}\"\n\n        netrc_file = \"\"\n        with tempfile.NamedTemporaryFile(mode=\"w\", delete=False) as fp:\n            fp.write(\"machine example.com\\n\")\n            fp.write(\"login wronguser\\n\")\n            fp.write(\"password wrongpass\\n\")\n            fp.write(f\"machine {domain}\\n\")\n            fp.write(\"login user\\n\")\n            fp.write(\"password pass\\n\")\n            fp.close()\n            netrc_file = fp.name\n\n        old_netrc = os.environ.get(\"NETRC\", \"\")\n        os.environ[\"NETRC\"] = netrc_file\n\n        try:\n            # Should use netrc\n            # Make sure that we don't use the example.com credentails\n            # for the request\n            r = requests.get(url)\n            assert r.status_code == 200\n        finally:\n            os.environ[\"NETRC\"] = old_netrc\n            os.unlink(netrc_file)\n\n    def test_DIGEST_HTTP_200_OK_GET(self, httpbin):\n        for authtype in self.digest_auth_algo:\n            auth = HTTPDigestAuth(\"user\", \"pass\")\n            url = httpbin(\"digest-auth\", \"auth\", \"user\", \"pass\", "}, {"start_line": 67000, "end_line": 69000, "belongs_to": {"file_name": "test_requests.py", "upper_path": "/data2/raymone/swebench-repos/requests/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "    auth=(\"user\", \"pass\"),\n            verify=httpbin_ca_bundle,\n        )\n        assert r.history[0].request.headers[\"Authorization\"]\n        assert \"Authorization\" not in r.request.headers\n\n    def test_auth_is_retained_for_redirect_on_host(self, httpbin):\n        r = requests.get(httpbin(\"redirect/1\"), auth=(\"user\", \"pass\"))\n        h1 = r.history[0].request.headers[\"Authorization\"]\n        h2 = r.request.headers[\"Authorization\"]\n\n        assert h1 == h2\n\n    def test_should_strip_auth_host_change(self):\n        s = requests.Session()\n        assert s.should_strip_auth(\n            \"http://example.com/foo\", \"http://another.example.com/\"\n        )\n\n    def test_should_strip_auth_http_downgrade(self):\n        s = requests.Session()\n        assert s.should_strip_auth(\"https://example.com/foo\", \"http://example.com/bar\")\n\n    def test_should_strip_auth_https_upgrade(self):\n        s = requests.Session()\n        assert not s.should_strip_auth(\n            \"http://example.com/foo\", \"https://example.com/bar\"\n        )\n        assert not s.should_strip_auth(\n            \"http://example.com:80/foo\", \"https://example.com/bar\"\n        )\n        assert not s.should_strip_auth(\n            \"http://example.com/foo\", \"https://example.com:443/bar\"\n        )\n        # Non-standard ports should trigger stripping\n        assert s.should_strip_auth(\n            \"http://example.com:8080/foo\", \"https://example.com/bar\"\n        )\n        assert s.should_strip_auth(\n            \"http://example.com/foo\", \"https://example.com:8443/bar\"\n        )\n\n    def test_should_strip_auth_port_change(self):\n        s = requests.Session()\n        assert s.should_strip_auth(\n            \"http://example.com:1234/foo\", \"https://example.com:4321/bar\"\n        )\n\n    @pytest.mark.parametrize(\n        \"old_uri, new_uri\",\n        (\n            (\"https://example.com:443/foo\", \"https://example.com/bar\"),\n            (\"http://example.com:80/foo\", \"http://example.com/bar\"),\n            (\"https://example.com/foo\","}, {"start_line": 26000, "end_line": 28000, "belongs_to": {"file_name": "test_requests.py", "upper_path": "/data2/raymone/swebench-repos/requests/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "       with tempfile.NamedTemporaryFile(mode=\"w\", delete=False) as fp:\n            fp.write(\"machine example.com\\n\")\n            fp.write(\"login wronguser\\n\")\n            fp.write(\"password wrongpass\\n\")\n            fp.write(f\"machine {domain}\\n\")\n            fp.write(\"login user\\n\")\n            fp.write(\"password pass\\n\")\n            fp.close()\n            netrc_file = fp.name\n\n        old_netrc = os.environ.get(\"NETRC\", \"\")\n        os.environ[\"NETRC\"] = netrc_file\n\n        try:\n            # Should use netrc\n            # Make sure that we don't use the example.com credentails\n            # for the request\n            r = requests.get(url)\n            assert r.status_code == 200\n        finally:\n            os.environ[\"NETRC\"] = old_netrc\n            os.unlink(netrc_file)\n\n    def test_DIGEST_HTTP_200_OK_GET(self, httpbin):\n        for authtype in self.digest_auth_algo:\n            auth = HTTPDigestAuth(\"user\", \"pass\")\n            url = httpbin(\"digest-auth\", \"auth\", \"user\", \"pass\", authtype, \"never\")\n\n            r = requests.get(url, auth=auth)\n            assert r.status_code == 200\n\n            r = requests.get(url)\n            assert r.status_code == 401\n            print(r.headers[\"WWW-Authenticate\"])\n\n            s = requests.session()\n            s.auth = HTTPDigestAuth(\"user\", \"pass\")\n            r = s.get(url)\n            assert r.status_code == 200\n\n    def test_DIGEST_AUTH_RETURNS_COOKIE(self, httpbin):\n        for authtype in self.digest_auth_algo:\n            url = httpbin(\"digest-auth\", \"auth\", \"user\", \"pass\", authtype)\n            auth = HTTPDigestAuth(\"user\", \"pass\")\n            r = requests.get(url)\n            assert r.cookies[\"fake\"] == \"fake_value\"\n\n            r = requests.get(url, auth=auth)\n            assert r.status_code == 200\n\n    def test_DIGEST_AUTH_SETS_SESSION_COOKIES(self, httpbin):\n        for authtype in self.digest_auth_algo:\n            url = httpbin(\"digest-auth\", \"auth\", \"user\", \"pass\", authtype)\n            auth = HTTPDigest"}, {"start_line": 27000, "end_line": 29000, "belongs_to": {"file_name": "test_requests.py", "upper_path": "/data2/raymone/swebench-repos/requests/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "authtype, \"never\")\n\n            r = requests.get(url, auth=auth)\n            assert r.status_code == 200\n\n            r = requests.get(url)\n            assert r.status_code == 401\n            print(r.headers[\"WWW-Authenticate\"])\n\n            s = requests.session()\n            s.auth = HTTPDigestAuth(\"user\", \"pass\")\n            r = s.get(url)\n            assert r.status_code == 200\n\n    def test_DIGEST_AUTH_RETURNS_COOKIE(self, httpbin):\n        for authtype in self.digest_auth_algo:\n            url = httpbin(\"digest-auth\", \"auth\", \"user\", \"pass\", authtype)\n            auth = HTTPDigestAuth(\"user\", \"pass\")\n            r = requests.get(url)\n            assert r.cookies[\"fake\"] == \"fake_value\"\n\n            r = requests.get(url, auth=auth)\n            assert r.status_code == 200\n\n    def test_DIGEST_AUTH_SETS_SESSION_COOKIES(self, httpbin):\n        for authtype in self.digest_auth_algo:\n            url = httpbin(\"digest-auth\", \"auth\", \"user\", \"pass\", authtype)\n            auth = HTTPDigestAuth(\"user\", \"pass\")\n            s = requests.Session()\n            s.get(url, auth=auth)\n            assert s.cookies[\"fake\"] == \"fake_value\"\n\n    def test_DIGEST_STREAM(self, httpbin):\n        for authtype in self.digest_auth_algo:\n            auth = HTTPDigestAuth(\"user\", \"pass\")\n            url = httpbin(\"digest-auth\", \"auth\", \"user\", \"pass\", authtype)\n\n            r = requests.get(url, auth=auth, stream=True)\n            assert r.raw.read() != b\"\"\n\n            r = requests.get(url, auth=auth, stream=False)\n            assert r.raw.read() == b\"\"\n\n    def test_DIGESTAUTH_WRONG_HTTP_401_GET(self, httpbin):\n        for authtype in self.digest_auth_algo:\n            auth = HTTPDigestAuth(\"user\", \"wrongpass\")\n            url = httpbin(\"digest-auth\", \"auth\", \"user\", \"pass\", authtype)\n\n            r = requests.get(url, auth=auth)\n            assert r.status_code == 401\n\n            r = requests.get(url)\n            assert r.status_code == 401\n\n            s = requests.session()\n          "}, {"start_line": 8000, "end_line": 10000, "belongs_to": {"file_name": "test_lowlevel.py", "upper_path": "/data2/raymone/swebench-repos/requests/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "_socket_content(sock, timeout=0.5)\n        assert request_content == b''\n\n        return request_content\n\n    close_server = threading.Event()\n    server = Server(digest_failed_response_handler, wait_to_close_event=close_server)\n\n    with server as (host, port):\n        url = f'http://{host}:{port}/'\n        r = requests.get(url, auth=auth)\n        # Verify server didn't authenticate us.\n        assert r.status_code == 401\n        assert r.history[0].status_code == 401\n        close_server.set()\n\n\ndef test_digestauth_only_on_4xx():\n    \"\"\"Ensure we only send digestauth on 4xx challenges.\n\n    See https://github.com/psf/requests/issues/3772.\n    \"\"\"\n    text_200_chal = (b'HTTP/1.1 200 OK\\r\\n'\n                     b'Content-Length: 0\\r\\n'\n                     b'WWW-Authenticate: Digest nonce=\"6bf5d6e4da1ce66918800195d6b9130d\"'\n                     b', opaque=\"372825293d1c26955496c80ed6426e9e\", '\n                     b'realm=\"me@kennethreitz.com\", qop=auth\\r\\n\\r\\n')\n\n    auth = requests.auth.HTTPDigestAuth('user', 'pass')\n\n    def digest_response_handler(sock):\n        # Respond to GET with a 200 containing www-authenticate header.\n        request_content = consume_socket_content(sock, timeout=0.5)\n        assert request_content.startswith(b\"GET / HTTP/1.1\")\n        sock.send(text_200_chal)\n\n        # Verify the client didn't respond with auth.\n        request_content = consume_socket_content(sock, timeout=0.5)\n        assert request_content == b''\n\n        return request_content\n\n    close_server = threading.Event()\n    server = Server(digest_response_handler, wait_to_close_event=close_server)\n\n    with server as (host, port):\n        url = f'http://{host}:{port}/'\n        r = requests.get(url, auth=auth)\n        # Verify server didn't receive auth from us.\n        assert r.status_code == 200\n        assert len(r.history) == 0\n        close_server.set()\n\n\n_schemes_by_var_prefix = [\n    ('http', ['http']),\n    ('https', ['https']),\n    ('all', ['http', 'https']),\n]\n\n_p"}, {"start_line": 8000, "end_line": 10000, "belongs_to": {"file_name": "auth.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": " it was to resend the request.\n            r.request.body.seek(self._thread_local.pos)\n        s_auth = r.headers.get(\"www-authenticate\", \"\")\n\n        if \"digest\" in s_auth.lower() and self._thread_local.num_401_calls < 2:\n            self._thread_local.num_401_calls += 1\n            pat = re.compile(r\"digest \", flags=re.IGNORECASE)\n            self._thread_local.chal = parse_dict_header(pat.sub(\"\", s_auth, count=1))\n\n            # Consume content and release the original connection\n            # to allow our new request to reuse the same one.\n            r.content\n            r.close()\n            prep = r.request.copy()\n            extract_cookies_to_jar(prep._cookies, r.request, r.raw)\n            prep.prepare_cookies(prep._cookies)\n\n            prep.headers[\"Authorization\"] = self.build_digest_header(\n                prep.method, prep.url\n            )\n            _r = r.connection.send(prep, **kwargs)\n            _r.history.append(r)\n            _r.request = prep\n\n            return _r\n\n        self._thread_local.num_401_calls = 1\n        return r\n\n    def __call__(self, r):\n        # Initialize per-thread state, if needed\n        self.init_per_thread_state()\n        # If we have a saved nonce, skip the 401\n        if self._thread_local.last_nonce:\n            r.headers[\"Authorization\"] = self.build_digest_header(r.method, r.url)\n        try:\n            self._thread_local.pos = r.body.tell()\n        except AttributeError:\n            # In the case of HTTPDigestAuth being reused and the body of\n            # the previous request was a file-like object, pos has the\n            # file position of the previous body. Ensure it's set to\n            # None.\n            self._thread_local.pos = None\n        r.register_hook(\"response\", self.handle_401)\n        r.register_hook(\"response\", self.handle_redirect)\n        self._thread_local.num_401_calls = 1\n\n        return r\n\n    def __eq__(self, other):\n        return all(\n            [\n                self.username == ge"}, {"start_line": 66000, "end_line": 68000, "belongs_to": {"file_name": "test_requests.py", "upper_path": "/data2/raymone/swebench-repos/requests/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "rt \"multipart/form-data\" in p.headers[\"Content-Type\"]\n\n    def test_autoset_header_values_are_native(self, httpbin):\n        data = \"this is a string\"\n        length = \"16\"\n        req = requests.Request(\"POST\", httpbin(\"post\"), data=data)\n        p = req.prepare()\n\n        assert p.headers[\"Content-Length\"] == length\n\n    def test_nonhttp_schemes_dont_check_URLs(self):\n        test_urls = (\n            \"data:image/gif;base64,R0lGODlhAQABAHAAACH5BAUAAAAALAAAAAABAAEAAAICRAEAOw==\",\n            \"file:///etc/passwd\",\n            \"magnet:?xt=urn:btih:be08f00302bc2d1d3cfa3af02024fa647a271431\",\n        )\n        for test_url in test_urls:\n            req = requests.Request(\"GET\", test_url)\n            preq = req.prepare()\n            assert test_url == preq.url\n\n    def test_auth_is_stripped_on_http_downgrade(\n        self, httpbin, httpbin_secure, httpbin_ca_bundle\n    ):\n        r = requests.get(\n            httpbin_secure(\"redirect-to\"),\n            params={\"url\": httpbin(\"get\")},\n            auth=(\"user\", \"pass\"),\n            verify=httpbin_ca_bundle,\n        )\n        assert r.history[0].request.headers[\"Authorization\"]\n        assert \"Authorization\" not in r.request.headers\n\n    def test_auth_is_retained_for_redirect_on_host(self, httpbin):\n        r = requests.get(httpbin(\"redirect/1\"), auth=(\"user\", \"pass\"))\n        h1 = r.history[0].request.headers[\"Authorization\"]\n        h2 = r.request.headers[\"Authorization\"]\n\n        assert h1 == h2\n\n    def test_should_strip_auth_host_change(self):\n        s = requests.Session()\n        assert s.should_strip_auth(\n            \"http://example.com/foo\", \"http://another.example.com/\"\n        )\n\n    def test_should_strip_auth_http_downgrade(self):\n        s = requests.Session()\n        assert s.should_strip_auth(\"https://example.com/foo\", \"http://example.com/bar\")\n\n    def test_should_strip_auth_https_upgrade(self):\n        s = requests.Session()\n        assert not s.should_strip_auth(\n            \"http://example.com/foo\", \"https"}, {"start_line": 28000, "end_line": 30000, "belongs_to": {"file_name": "test_requests.py", "upper_path": "/data2/raymone/swebench-repos/requests/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "Auth(\"user\", \"pass\")\n            s = requests.Session()\n            s.get(url, auth=auth)\n            assert s.cookies[\"fake\"] == \"fake_value\"\n\n    def test_DIGEST_STREAM(self, httpbin):\n        for authtype in self.digest_auth_algo:\n            auth = HTTPDigestAuth(\"user\", \"pass\")\n            url = httpbin(\"digest-auth\", \"auth\", \"user\", \"pass\", authtype)\n\n            r = requests.get(url, auth=auth, stream=True)\n            assert r.raw.read() != b\"\"\n\n            r = requests.get(url, auth=auth, stream=False)\n            assert r.raw.read() == b\"\"\n\n    def test_DIGESTAUTH_WRONG_HTTP_401_GET(self, httpbin):\n        for authtype in self.digest_auth_algo:\n            auth = HTTPDigestAuth(\"user\", \"wrongpass\")\n            url = httpbin(\"digest-auth\", \"auth\", \"user\", \"pass\", authtype)\n\n            r = requests.get(url, auth=auth)\n            assert r.status_code == 401\n\n            r = requests.get(url)\n            assert r.status_code == 401\n\n            s = requests.session()\n            s.auth = auth\n            r = s.get(url)\n            assert r.status_code == 401\n\n    def test_DIGESTAUTH_QUOTES_QOP_VALUE(self, httpbin):\n        for authtype in self.digest_auth_algo:\n            auth = HTTPDigestAuth(\"user\", \"pass\")\n            url = httpbin(\"digest-auth\", \"auth\", \"user\", \"pass\", authtype)\n\n            r = requests.get(url, auth=auth)\n            assert '\"auth\"' in r.request.headers[\"Authorization\"]\n\n    def test_POSTBIN_GET_POST_FILES(self, httpbin):\n        url = httpbin(\"post\")\n        requests.post(url).raise_for_status()\n\n        post1 = requests.post(url, data={\"some\": \"data\"})\n        assert post1.status_code == 200\n\n        with open(\"requirements-dev.txt\") as f:\n            post2 = requests.post(url, files={\"some\": f})\n        assert post2.status_code == 200\n\n        post4 = requests.post(url, data='[{\"some\": \"json\"}]')\n        assert post4.status_code == 200\n\n        with pytest.raises(ValueError):\n            requests.post(url, files=[\"bad file data\"])\n"}], "retrieved_count": 10, "cost_time": 4.601603746414185}
{"question": "Where does the authentication flow from handler selection through credential application to request execution?", "answer": null, "relative_code_list": null, "ground_truth": "The authentication flow occurs in multiple locations: 1) Authentication handler selection happens in src/requests/sessions.py during Session.prepare_request() where session auth and request auth are merged; 2) Credential application occurs in src/requests/models.py in PreparedRequest.prepare_auth() method, which calls the authentication handler to add Authorization headers; 3) Authentication handlers are defined in src/requests/auth.py (HTTPBasicAuth, HTTPDigestAuth, etc.) and implement the __call__() method to modify request headers; 4) Request execution with authentication occurs in src/requests/adapters.py through HTTPAdapter.send() which sends the prepared request with authentication headers; 5) Authentication challenge handling (for 401 responses) is implemented in HTTPDigestAuth.handle_401() method in src/requests/auth.py. The complete flow is: Session.prepare_request()  PreparedRequest.prepare_auth()  AuthHandler.__call__()  HTTPAdapter.send()  Response processing  AuthHandler.handle_401() (if needed).", "score": null, "retrieved_content": [{"start_line": 9000, "end_line": 11000, "belongs_to": {"file_name": "sessions.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "   # A failed tell() sets `_body_position` to `object()`. This non-None\n            # value ensures `rewindable` will be True, allowing us to raise an\n            # UnrewindableBodyError, instead of hanging the connection.\n            rewindable = prepared_request._body_position is not None and (\n                \"Content-Length\" in headers or \"Transfer-Encoding\" in headers\n            )\n\n            # Attempt to rewind consumed file-like object.\n            if rewindable:\n                rewind_body(prepared_request)\n\n            # Override the original request.\n            req = prepared_request\n\n            if yield_requests:\n                yield req\n            else:\n                resp = self.send(\n                    req,\n                    stream=stream,\n                    timeout=timeout,\n                    verify=verify,\n                    cert=cert,\n                    proxies=proxies,\n                    allow_redirects=False,\n                    **adapter_kwargs,\n                )\n\n                extract_cookies_to_jar(self.cookies, prepared_request, resp.raw)\n\n                # extract redirect url, if any, for the next loop\n                url = self.get_redirect_target(resp)\n                yield resp\n\n    def rebuild_auth(self, prepared_request, response):\n        \"\"\"When being redirected we may want to strip authentication from the\n        request to avoid leaking credentials. This method intelligently removes\n        and reapplies authentication where possible to avoid credential loss.\n        \"\"\"\n        headers = prepared_request.headers\n        url = prepared_request.url\n\n        if \"Authorization\" in headers and self.should_strip_auth(\n            response.request.url, url\n        ):\n            # If we get redirected to a new host, we should strip out any\n            # authentication headers.\n            del headers[\"Authorization\"]\n\n        # .netrc might have more auth for us on our new host.\n        new_auth = get_netrc_auth(url) if s"}, {"start_line": 10000, "end_line": 12000, "belongs_to": {"file_name": "sessions.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "           )\n\n                extract_cookies_to_jar(self.cookies, prepared_request, resp.raw)\n\n                # extract redirect url, if any, for the next loop\n                url = self.get_redirect_target(resp)\n                yield resp\n\n    def rebuild_auth(self, prepared_request, response):\n        \"\"\"When being redirected we may want to strip authentication from the\n        request to avoid leaking credentials. This method intelligently removes\n        and reapplies authentication where possible to avoid credential loss.\n        \"\"\"\n        headers = prepared_request.headers\n        url = prepared_request.url\n\n        if \"Authorization\" in headers and self.should_strip_auth(\n            response.request.url, url\n        ):\n            # If we get redirected to a new host, we should strip out any\n            # authentication headers.\n            del headers[\"Authorization\"]\n\n        # .netrc might have more auth for us on our new host.\n        new_auth = get_netrc_auth(url) if self.trust_env else None\n        if new_auth is not None:\n            prepared_request.prepare_auth(new_auth)\n\n    def rebuild_proxies(self, prepared_request, proxies):\n        \"\"\"This method re-evaluates the proxy configuration by considering the\n        environment variables. If we are redirected to a URL covered by\n        NO_PROXY, we strip the proxy configuration. Otherwise, we set missing\n        proxy keys for this URL (in case they were stripped by a previous\n        redirect).\n\n        This method also replaces the Proxy-Authorization header where\n        necessary.\n\n        :rtype: dict\n        \"\"\"\n        headers = prepared_request.headers\n        scheme = urlparse(prepared_request.url).scheme\n        new_proxies = resolve_proxies(prepared_request, proxies, self.trust_env)\n\n        if \"Proxy-Authorization\" in headers:\n            del headers[\"Proxy-Authorization\"]\n\n        try:\n            username, password = get_auth_from_url(new_proxies[scheme])\n        except KeyError:\n  "}, {"start_line": 2000, "end_line": 4000, "belongs_to": {"file_name": "auth.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "sword))).strip()\n    )\n\n    return authstr\n\n\nclass AuthBase:\n    \"\"\"Base class that all auth implementations derive from\"\"\"\n\n    def __call__(self, r):\n        raise NotImplementedError(\"Auth hooks must be callable.\")\n\n\nclass HTTPBasicAuth(AuthBase):\n    \"\"\"Attaches HTTP Basic Authentication to the given Request object.\"\"\"\n\n    def __init__(self, username, password):\n        self.username = username\n        self.password = password\n\n    def __eq__(self, other):\n        return all(\n            [\n                self.username == getattr(other, \"username\", None),\n                self.password == getattr(other, \"password\", None),\n            ]\n        )\n\n    def __ne__(self, other):\n        return not self == other\n\n    def __call__(self, r):\n        r.headers[\"Authorization\"] = _basic_auth_str(self.username, self.password)\n        return r\n\n\nclass HTTPProxyAuth(HTTPBasicAuth):\n    \"\"\"Attaches HTTP Proxy Authentication to a given Request object.\"\"\"\n\n    def __call__(self, r):\n        r.headers[\"Proxy-Authorization\"] = _basic_auth_str(self.username, self.password)\n        return r\n\n\nclass HTTPDigestAuth(AuthBase):\n    \"\"\"Attaches HTTP Digest Authentication to the given Request object.\"\"\"\n\n    def __init__(self, username, password):\n        self.username = username\n        self.password = password\n        # Keep state in per-thread local storage\n        self._thread_local = threading.local()\n\n    def init_per_thread_state(self):\n        # Ensure state is initialized just once per-thread\n        if not hasattr(self._thread_local, \"init\"):\n            self._thread_local.init = True\n            self._thread_local.last_nonce = \"\"\n            self._thread_local.nonce_count = 0\n            self._thread_local.chal = {}\n            self._thread_local.pos = None\n            self._thread_local.num_401_calls = None\n\n    def build_digest_header(self, method, url):\n        \"\"\"\n        :rtype: str\n        \"\"\"\n\n        realm = self._thread_local.chal[\"realm\"]\n        nonce = self._threa"}, {"start_line": 9000, "end_line": 10186, "belongs_to": {"file_name": "auth.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "rn _r\n\n        self._thread_local.num_401_calls = 1\n        return r\n\n    def __call__(self, r):\n        # Initialize per-thread state, if needed\n        self.init_per_thread_state()\n        # If we have a saved nonce, skip the 401\n        if self._thread_local.last_nonce:\n            r.headers[\"Authorization\"] = self.build_digest_header(r.method, r.url)\n        try:\n            self._thread_local.pos = r.body.tell()\n        except AttributeError:\n            # In the case of HTTPDigestAuth being reused and the body of\n            # the previous request was a file-like object, pos has the\n            # file position of the previous body. Ensure it's set to\n            # None.\n            self._thread_local.pos = None\n        r.register_hook(\"response\", self.handle_401)\n        r.register_hook(\"response\", self.handle_redirect)\n        self._thread_local.num_401_calls = 1\n\n        return r\n\n    def __eq__(self, other):\n        return all(\n            [\n                self.username == getattr(other, \"username\", None),\n                self.password == getattr(other, \"password\", None),\n            ]\n        )\n\n    def __ne__(self, other):\n        return not self == other\n"}, {"start_line": 25000, "end_line": 27000, "belongs_to": {"file_name": "test_requests.py", "upper_path": "/data2/raymone/swebench-repos/requests/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "get_netrc_auth_mock(url):\n                return auth\n\n            requests.sessions.get_netrc_auth = get_netrc_auth_mock\n\n            # Should use netrc and work.\n            r = requests.get(url)\n            assert r.status_code == 200\n\n            # Given auth should override and fail.\n            r = requests.get(url, auth=wrong_auth)\n            assert r.status_code == 401\n\n            s = requests.session()\n\n            # Should use netrc and work.\n            r = s.get(url)\n            assert r.status_code == 200\n\n            # Given auth should override and fail.\n            s.auth = wrong_auth\n            r = s.get(url)\n            assert r.status_code == 401\n        finally:\n            requests.sessions.get_netrc_auth = old_auth\n\n    def test_basicauth_with_netrc_leak(self, httpbin):\n        url1 = httpbin(\"basic-auth\", \"user\", \"pass\")\n        url = url1[len(\"http://\") :]\n        domain = url.split(\":\")[0]\n        url = f\"http://example.com:@{url}\"\n\n        netrc_file = \"\"\n        with tempfile.NamedTemporaryFile(mode=\"w\", delete=False) as fp:\n            fp.write(\"machine example.com\\n\")\n            fp.write(\"login wronguser\\n\")\n            fp.write(\"password wrongpass\\n\")\n            fp.write(f\"machine {domain}\\n\")\n            fp.write(\"login user\\n\")\n            fp.write(\"password pass\\n\")\n            fp.close()\n            netrc_file = fp.name\n\n        old_netrc = os.environ.get(\"NETRC\", \"\")\n        os.environ[\"NETRC\"] = netrc_file\n\n        try:\n            # Should use netrc\n            # Make sure that we don't use the example.com credentails\n            # for the request\n            r = requests.get(url)\n            assert r.status_code == 200\n        finally:\n            os.environ[\"NETRC\"] = old_netrc\n            os.unlink(netrc_file)\n\n    def test_DIGEST_HTTP_200_OK_GET(self, httpbin):\n        for authtype in self.digest_auth_algo:\n            auth = HTTPDigestAuth(\"user\", \"pass\")\n            url = httpbin(\"digest-auth\", \"auth\", \"user\", \"pass\", "}, {"start_line": 8000, "end_line": 10000, "belongs_to": {"file_name": "auth.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": " it was to resend the request.\n            r.request.body.seek(self._thread_local.pos)\n        s_auth = r.headers.get(\"www-authenticate\", \"\")\n\n        if \"digest\" in s_auth.lower() and self._thread_local.num_401_calls < 2:\n            self._thread_local.num_401_calls += 1\n            pat = re.compile(r\"digest \", flags=re.IGNORECASE)\n            self._thread_local.chal = parse_dict_header(pat.sub(\"\", s_auth, count=1))\n\n            # Consume content and release the original connection\n            # to allow our new request to reuse the same one.\n            r.content\n            r.close()\n            prep = r.request.copy()\n            extract_cookies_to_jar(prep._cookies, r.request, r.raw)\n            prep.prepare_cookies(prep._cookies)\n\n            prep.headers[\"Authorization\"] = self.build_digest_header(\n                prep.method, prep.url\n            )\n            _r = r.connection.send(prep, **kwargs)\n            _r.history.append(r)\n            _r.request = prep\n\n            return _r\n\n        self._thread_local.num_401_calls = 1\n        return r\n\n    def __call__(self, r):\n        # Initialize per-thread state, if needed\n        self.init_per_thread_state()\n        # If we have a saved nonce, skip the 401\n        if self._thread_local.last_nonce:\n            r.headers[\"Authorization\"] = self.build_digest_header(r.method, r.url)\n        try:\n            self._thread_local.pos = r.body.tell()\n        except AttributeError:\n            # In the case of HTTPDigestAuth being reused and the body of\n            # the previous request was a file-like object, pos has the\n            # file position of the previous body. Ensure it's set to\n            # None.\n            self._thread_local.pos = None\n        r.register_hook(\"response\", self.handle_401)\n        r.register_hook(\"response\", self.handle_redirect)\n        self._thread_local.num_401_calls = 1\n\n        return r\n\n    def __eq__(self, other):\n        return all(\n            [\n                self.username == ge"}, {"start_line": 6000, "end_line": 8000, "belongs_to": {"file_name": "auth.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "= 1\n        else:\n            self._thread_local.nonce_count = 1\n        ncvalue = f\"{self._thread_local.nonce_count:08x}\"\n        s = str(self._thread_local.nonce_count).encode(\"utf-8\")\n        s += nonce.encode(\"utf-8\")\n        s += time.ctime().encode(\"utf-8\")\n        s += os.urandom(8)\n\n        cnonce = hashlib.sha1(s).hexdigest()[:16]\n        if _algorithm == \"MD5-SESS\":\n            HA1 = hash_utf8(f\"{HA1}:{nonce}:{cnonce}\")\n\n        if not qop:\n            respdig = KD(HA1, f\"{nonce}:{HA2}\")\n        elif qop == \"auth\" or \"auth\" in qop.split(\",\"):\n            noncebit = f\"{nonce}:{ncvalue}:{cnonce}:auth:{HA2}\"\n            respdig = KD(HA1, noncebit)\n        else:\n            # XXX handle auth-int.\n            return None\n\n        self._thread_local.last_nonce = nonce\n\n        # XXX should the partial digests be encoded too?\n        base = (\n            f'username=\"{self.username}\", realm=\"{realm}\", nonce=\"{nonce}\", '\n            f'uri=\"{path}\", response=\"{respdig}\"'\n        )\n        if opaque:\n            base += f', opaque=\"{opaque}\"'\n        if algorithm:\n            base += f', algorithm=\"{algorithm}\"'\n        if entdig:\n            base += f', digest=\"{entdig}\"'\n        if qop:\n            base += f', qop=\"auth\", nc={ncvalue}, cnonce=\"{cnonce}\"'\n\n        return f\"Digest {base}\"\n\n    def handle_redirect(self, r, **kwargs):\n        \"\"\"Reset num_401_calls counter on redirects.\"\"\"\n        if r.is_redirect:\n            self._thread_local.num_401_calls = 1\n\n    def handle_401(self, r, **kwargs):\n        \"\"\"\n        Takes the given response and tries digest-auth, if needed.\n\n        :rtype: requests.Response\n        \"\"\"\n\n        # If response is not 4xx, do not auth\n        # See https://github.com/psf/requests/issues/3772\n        if not 400 <= r.status_code < 500:\n            self._thread_local.num_401_calls = 1\n            return r\n\n        if self._thread_local.pos is not None:\n            # Rewind the file position indicator of the body to where\n            #"}, {"start_line": 67000, "end_line": 69000, "belongs_to": {"file_name": "test_requests.py", "upper_path": "/data2/raymone/swebench-repos/requests/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "    auth=(\"user\", \"pass\"),\n            verify=httpbin_ca_bundle,\n        )\n        assert r.history[0].request.headers[\"Authorization\"]\n        assert \"Authorization\" not in r.request.headers\n\n    def test_auth_is_retained_for_redirect_on_host(self, httpbin):\n        r = requests.get(httpbin(\"redirect/1\"), auth=(\"user\", \"pass\"))\n        h1 = r.history[0].request.headers[\"Authorization\"]\n        h2 = r.request.headers[\"Authorization\"]\n\n        assert h1 == h2\n\n    def test_should_strip_auth_host_change(self):\n        s = requests.Session()\n        assert s.should_strip_auth(\n            \"http://example.com/foo\", \"http://another.example.com/\"\n        )\n\n    def test_should_strip_auth_http_downgrade(self):\n        s = requests.Session()\n        assert s.should_strip_auth(\"https://example.com/foo\", \"http://example.com/bar\")\n\n    def test_should_strip_auth_https_upgrade(self):\n        s = requests.Session()\n        assert not s.should_strip_auth(\n            \"http://example.com/foo\", \"https://example.com/bar\"\n        )\n        assert not s.should_strip_auth(\n            \"http://example.com:80/foo\", \"https://example.com/bar\"\n        )\n        assert not s.should_strip_auth(\n            \"http://example.com/foo\", \"https://example.com:443/bar\"\n        )\n        # Non-standard ports should trigger stripping\n        assert s.should_strip_auth(\n            \"http://example.com:8080/foo\", \"https://example.com/bar\"\n        )\n        assert s.should_strip_auth(\n            \"http://example.com/foo\", \"https://example.com:8443/bar\"\n        )\n\n    def test_should_strip_auth_port_change(self):\n        s = requests.Session()\n        assert s.should_strip_auth(\n            \"http://example.com:1234/foo\", \"https://example.com:4321/bar\"\n        )\n\n    @pytest.mark.parametrize(\n        \"old_uri, new_uri\",\n        (\n            (\"https://example.com:443/foo\", \"https://example.com/bar\"),\n            (\"http://example.com:80/foo\", \"http://example.com/bar\"),\n            (\"https://example.com/foo\","}, {"start_line": 26000, "end_line": 28000, "belongs_to": {"file_name": "test_requests.py", "upper_path": "/data2/raymone/swebench-repos/requests/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "       with tempfile.NamedTemporaryFile(mode=\"w\", delete=False) as fp:\n            fp.write(\"machine example.com\\n\")\n            fp.write(\"login wronguser\\n\")\n            fp.write(\"password wrongpass\\n\")\n            fp.write(f\"machine {domain}\\n\")\n            fp.write(\"login user\\n\")\n            fp.write(\"password pass\\n\")\n            fp.close()\n            netrc_file = fp.name\n\n        old_netrc = os.environ.get(\"NETRC\", \"\")\n        os.environ[\"NETRC\"] = netrc_file\n\n        try:\n            # Should use netrc\n            # Make sure that we don't use the example.com credentails\n            # for the request\n            r = requests.get(url)\n            assert r.status_code == 200\n        finally:\n            os.environ[\"NETRC\"] = old_netrc\n            os.unlink(netrc_file)\n\n    def test_DIGEST_HTTP_200_OK_GET(self, httpbin):\n        for authtype in self.digest_auth_algo:\n            auth = HTTPDigestAuth(\"user\", \"pass\")\n            url = httpbin(\"digest-auth\", \"auth\", \"user\", \"pass\", authtype, \"never\")\n\n            r = requests.get(url, auth=auth)\n            assert r.status_code == 200\n\n            r = requests.get(url)\n            assert r.status_code == 401\n            print(r.headers[\"WWW-Authenticate\"])\n\n            s = requests.session()\n            s.auth = HTTPDigestAuth(\"user\", \"pass\")\n            r = s.get(url)\n            assert r.status_code == 200\n\n    def test_DIGEST_AUTH_RETURNS_COOKIE(self, httpbin):\n        for authtype in self.digest_auth_algo:\n            url = httpbin(\"digest-auth\", \"auth\", \"user\", \"pass\", authtype)\n            auth = HTTPDigestAuth(\"user\", \"pass\")\n            r = requests.get(url)\n            assert r.cookies[\"fake\"] == \"fake_value\"\n\n            r = requests.get(url, auth=auth)\n            assert r.status_code == 200\n\n    def test_DIGEST_AUTH_SETS_SESSION_COOKIES(self, httpbin):\n        for authtype in self.digest_auth_algo:\n            url = httpbin(\"digest-auth\", \"auth\", \"user\", \"pass\", authtype)\n            auth = HTTPDigest"}, {"start_line": 0, "end_line": 2000, "belongs_to": {"file_name": "auth.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "\"\"\"\nrequests.auth\n~~~~~~~~~~~~~\n\nThis module contains the authentication handlers for Requests.\n\"\"\"\n\nimport hashlib\nimport os\nimport re\nimport threading\nimport time\nimport warnings\nfrom base64 import b64encode\n\nfrom ._internal_utils import to_native_string\nfrom .compat import basestring, str, urlparse\nfrom .cookies import extract_cookies_to_jar\nfrom .utils import parse_dict_header\n\nCONTENT_TYPE_FORM_URLENCODED = \"application/x-www-form-urlencoded\"\nCONTENT_TYPE_MULTI_PART = \"multipart/form-data\"\n\n\ndef _basic_auth_str(username, password):\n    \"\"\"Returns a Basic Auth string.\"\"\"\n\n    # \"I want us to put a big-ol' comment on top of it that\n    # says that this behaviour is dumb but we need to preserve\n    # it because people are relying on it.\"\n    #    - Lukasa\n    #\n    # These are here solely to maintain backwards compatibility\n    # for things like ints. This will be removed in 3.0.0.\n    if not isinstance(username, basestring):\n        warnings.warn(\n            \"Non-string usernames will no longer be supported in Requests \"\n            \"3.0.0. Please convert the object you've passed in ({!r}) to \"\n            \"a string or bytes object in the near future to avoid \"\n            \"problems.\".format(username),\n            category=DeprecationWarning,\n        )\n        username = str(username)\n\n    if not isinstance(password, basestring):\n        warnings.warn(\n            \"Non-string passwords will no longer be supported in Requests \"\n            \"3.0.0. Please convert the object you've passed in ({!r}) to \"\n            \"a string or bytes object in the near future to avoid \"\n            \"problems.\".format(type(password)),\n            category=DeprecationWarning,\n        )\n        password = str(password)\n    # -- End Removal --\n\n    if isinstance(username, str):\n        username = username.encode(\"latin1\")\n\n    if isinstance(password, str):\n        password = password.encode(\"latin1\")\n\n    authstr = \"Basic \" + to_native_string(\n        b64encode(b\":\".join((username, pas"}], "retrieved_count": 10, "cost_time": 4.637355089187622}
{"question": "Why does Requests use connection pooling for concurrent request handling?", "answer": null, "relative_code_list": null, "ground_truth": "Requests uses connection pooling for concurrent request handling to efficiently manage multiple simultaneous connections: 1) Concurrent access - Connection pools enable multiple threads or processes to safely share connections to the same hosts; 2) Resource management - Pools limit the number of concurrent connections to prevent resource exhaustion and server overload; 3) Thread safety - Pool implementations are thread-safe, eliminating the need for external synchronization; 4) Connection lifecycle - Pools manage connection creation, reuse, and cleanup automatically; 5) Load balancing - Pools distribute requests across available connections, improving overall throughput; 6) Failure handling - Pools can handle connection failures and automatically create new connections as needed; 7) Performance optimization - Reusing connections within the pool eliminates connection establishment overhead; 8) Configurable limits - Pool sizes can be tuned based on application needs and server capabilities; 9) Health monitoring - Pools can monitor connection health and remove stale connections; 10) Scalability - Connection pooling enables applications to scale efficiently without proportional increases in resource usage.", "score": null, "retrieved_content": [{"start_line": 5000, "end_line": 7000, "belongs_to": {"file_name": "adapters.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": " requests where data has\n        made it to the server. By default, Requests does not retry failed\n        connections. If you need granular control over the conditions under\n        which we retry a request, import urllib3's ``Retry`` class and pass\n        that instead.\n    :param pool_block: Whether the connection pool should block for connections.\n\n    Usage::\n\n      >>> import requests\n      >>> s = requests.Session()\n      >>> a = requests.adapters.HTTPAdapter(max_retries=3)\n      >>> s.mount('http://', a)\n    \"\"\"\n\n    __attrs__ = [\n        \"max_retries\",\n        \"config\",\n        \"_pool_connections\",\n        \"_pool_maxsize\",\n        \"_pool_block\",\n    ]\n\n    def __init__(\n        self,\n        pool_connections=DEFAULT_POOLSIZE,\n        pool_maxsize=DEFAULT_POOLSIZE,\n        max_retries=DEFAULT_RETRIES,\n        pool_block=DEFAULT_POOLBLOCK,\n    ):\n        if max_retries == DEFAULT_RETRIES:\n            self.max_retries = Retry(0, read=False)\n        else:\n            self.max_retries = Retry.from_int(max_retries)\n        self.config = {}\n        self.proxy_manager = {}\n\n        super().__init__()\n\n        self._pool_connections = pool_connections\n        self._pool_maxsize = pool_maxsize\n        self._pool_block = pool_block\n\n        self.init_poolmanager(pool_connections, pool_maxsize, block=pool_block)\n\n    def __getstate__(self):\n        return {attr: getattr(self, attr, None) for attr in self.__attrs__}\n\n    def __setstate__(self, state):\n        # Can't handle by adding 'proxy_manager' to self.__attrs__ because\n        # self.poolmanager uses a lambda function, which isn't pickleable.\n        self.proxy_manager = {}\n        self.config = {}\n\n        for attr, value in state.items():\n            setattr(self, attr, value)\n\n        self.init_poolmanager(\n            self._pool_connections, self._pool_maxsize, block=self._pool_block\n        )\n\n    def init_poolmanager(\n        self, connections, maxsize, block=DEFAULT_POOLBLOCK, **pool_kwargs\n    ):\n        \""}, {"start_line": 13000, "end_line": 15000, "belongs_to": {"file_name": "sessions.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "POST is responded to with a 301, turn it into a GET.\n        # This bizarre behaviour is explained in Issue 1704.\n        if response.status_code == codes.moved and method == \"POST\":\n            method = \"GET\"\n\n        prepared_request.method = method\n\n\nclass Session(SessionRedirectMixin):\n    \"\"\"A Requests session.\n\n    Provides cookie persistence, connection-pooling, and configuration.\n\n    Basic Usage::\n\n      >>> import requests\n      >>> s = requests.Session()\n      >>> s.get('https://httpbin.org/get')\n      <Response [200]>\n\n    Or as a context manager::\n\n      >>> with requests.Session() as s:\n      ...     s.get('https://httpbin.org/get')\n      <Response [200]>\n    \"\"\"\n\n    __attrs__ = [\n        \"headers\",\n        \"cookies\",\n        \"auth\",\n        \"proxies\",\n        \"hooks\",\n        \"params\",\n        \"verify\",\n        \"cert\",\n        \"adapters\",\n        \"stream\",\n        \"trust_env\",\n        \"max_redirects\",\n    ]\n\n    def __init__(self):\n        #: A case-insensitive dictionary of headers to be sent on each\n        #: :class:`Request <Request>` sent from this\n        #: :class:`Session <Session>`.\n        self.headers = default_headers()\n\n        #: Default Authentication tuple or object to attach to\n        #: :class:`Request <Request>`.\n        self.auth = None\n\n        #: Dictionary mapping protocol or protocol and host to the URL of the proxy\n        #: (e.g. {'http': 'foo.bar:3128', 'http://host.name': 'foo.bar:4012'}) to\n        #: be used on each :class:`Request <Request>`.\n        self.proxies = {}\n\n        #: Event-handling hooks.\n        self.hooks = default_hooks()\n\n        #: Dictionary of querystring data to attach to each\n        #: :class:`Request <Request>`. The dictionary values may be lists for\n        #: representing multivalued query parameters.\n        self.params = {}\n\n        #: Stream response content default.\n        self.stream = False\n\n        #: SSL Verification default.\n        #: Defaults to `True`, requiring requests to verif"}, {"start_line": 0, "end_line": 2000, "belongs_to": {"file_name": "adapters.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "\"\"\"\nrequests.adapters\n~~~~~~~~~~~~~~~~~\n\nThis module contains the transport adapters that Requests uses to define\nand maintain connections.\n\"\"\"\n\nimport os.path\nimport socket  # noqa: F401\nimport typing\nimport warnings\n\nfrom urllib3.exceptions import ClosedPoolError, ConnectTimeoutError\nfrom urllib3.exceptions import HTTPError as _HTTPError\nfrom urllib3.exceptions import InvalidHeader as _InvalidHeader\nfrom urllib3.exceptions import (\n    LocationValueError,\n    MaxRetryError,\n    NewConnectionError,\n    ProtocolError,\n)\nfrom urllib3.exceptions import ProxyError as _ProxyError\nfrom urllib3.exceptions import ReadTimeoutError, ResponseError\nfrom urllib3.exceptions import SSLError as _SSLError\nfrom urllib3.poolmanager import PoolManager, proxy_from_url\nfrom urllib3.util import Timeout as TimeoutSauce\nfrom urllib3.util import parse_url\nfrom urllib3.util.retry import Retry\n\nfrom .auth import _basic_auth_str\nfrom .compat import basestring, urlparse\nfrom .cookies import extract_cookies_to_jar\nfrom .exceptions import (\n    ConnectionError,\n    ConnectTimeout,\n    InvalidHeader,\n    InvalidProxyURL,\n    InvalidSchema,\n    InvalidURL,\n    ProxyError,\n    ReadTimeout,\n    RetryError,\n    SSLError,\n)\nfrom .models import Response\nfrom .structures import CaseInsensitiveDict\nfrom .utils import (\n    DEFAULT_CA_BUNDLE_PATH,\n    extract_zipped_paths,\n    get_auth_from_url,\n    get_encoding_from_headers,\n    prepend_scheme_if_needed,\n    select_proxy,\n    urldefragauth,\n)\n\ntry:\n    from urllib3.contrib.socks import SOCKSProxyManager\nexcept ImportError:\n\n    def SOCKSProxyManager(*args, **kwargs):\n        raise InvalidSchema(\"Missing dependencies for SOCKS support.\")\n\n\nif typing.TYPE_CHECKING:\n    from .models import PreparedRequest\n\n\nDEFAULT_POOLBLOCK = False\nDEFAULT_POOLSIZE = 10\nDEFAULT_RETRIES = 0\nDEFAULT_POOL_TIMEOUT = None\n\n\ndef _urllib3_request_context(\n    request: \"PreparedRequest\",\n    verify: \"bool | str | None\",\n    client_cert: \"typing.Tuple[str, str] | str | None\",\n    po"}, {"start_line": 74000, "end_line": 76000, "belongs_to": {"file_name": "test_requests.py", "upper_path": "/data2/raymone/swebench-repos/requests/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "name, password)\n        assert isinstance(s, builtin_str)\n        assert s == auth_str\n\n    def test_requests_history_is_saved(self, httpbin):\n        r = requests.get(httpbin(\"redirect/5\"))\n        total = r.history[-1].history\n        i = 0\n        for item in r.history:\n            assert item.history == total[0:i]\n            i += 1\n\n    def test_json_param_post_content_type_works(self, httpbin):\n        r = requests.post(httpbin(\"post\"), json={\"life\": 42})\n        assert r.status_code == 200\n        assert \"application/json\" in r.request.headers[\"Content-Type\"]\n        assert {\"life\": 42} == r.json()[\"json\"]\n\n    def test_json_param_post_should_not_override_data_param(self, httpbin):\n        r = requests.Request(\n            method=\"POST\",\n            url=httpbin(\"post\"),\n            data={\"stuff\": \"elixr\"},\n            json={\"music\": \"flute\"},\n        )\n        prep = r.prepare()\n        assert \"stuff=elixr\" == prep.body\n\n    def test_response_iter_lines(self, httpbin):\n        r = requests.get(httpbin(\"stream/4\"), stream=True)\n        assert r.status_code == 200\n\n        it = r.iter_lines()\n        next(it)\n        assert len(list(it)) == 3\n\n    def test_response_context_manager(self, httpbin):\n        with requests.get(httpbin(\"stream/4\"), stream=True) as response:\n            assert isinstance(response, requests.Response)\n\n        assert response.raw.closed\n\n    def test_unconsumed_session_response_closes_connection(self, httpbin):\n        s = requests.session()\n\n        with contextlib.closing(s.get(httpbin(\"stream/4\"), stream=True)) as response:\n            pass\n\n        assert response._content_consumed is False\n        assert response.raw.closed\n\n    @pytest.mark.xfail\n    def test_response_iter_lines_reentrant(self, httpbin):\n        \"\"\"Response.iter_lines() is not reentrant safe\"\"\"\n        r = requests.get(httpbin(\"stream/4\"), stream=True)\n        assert r.status_code == 200\n\n        next(r.iter_lines())\n        assert len(list(r.iter_lines())) == 3\n\n"}, {"start_line": 101000, "end_line": 103000, "belongs_to": {"file_name": "test_requests.py", "upper_path": "/data2/raymone/swebench-repos/requests/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "       s = requests.Session()\n        close_server = threading.Event()\n        server = TLSServer(\n            handler=response_handler,\n            wait_to_close_event=close_server,\n            requests_to_handle=3,\n            cert_chain=\"tests/certs/expired/server/server.pem\",\n            keyfile=\"tests/certs/expired/server/server.key\",\n        )\n\n        with server as (host, port):\n            url = f\"https://{host}:{port}\"\n            r1 = s.get(url, verify=False)\n            assert r1.status_code == 200\n\n            # Cannot verify self-signed certificate\n            with pytest.raises(requests.exceptions.SSLError):\n                s.get(url)\n\n            close_server.set()\n        assert 2 == len(s.adapters[\"https://\"].poolmanager.pools)\n\n    def test_different_connection_pool_for_tls_settings_verify_bundle_expired_cert(\n        self,\n    ):\n        def response_handler(sock):\n            consume_socket_content(sock, timeout=0.5)\n            sock.send(\n                b\"HTTP/1.1 200 OK\\r\\n\"\n                b\"Content-Length: 18\\r\\n\\r\\n\"\n                b'\\xff\\xfe{\\x00\"\\x00K0\"\\x00=\\x00\"\\x00\\xab0\"\\x00\\r\\n'\n            )\n\n        s = requests.Session()\n        close_server = threading.Event()\n        server = TLSServer(\n            handler=response_handler,\n            wait_to_close_event=close_server,\n            requests_to_handle=3,\n            cert_chain=\"tests/certs/expired/server/server.pem\",\n            keyfile=\"tests/certs/expired/server/server.key\",\n        )\n\n        with server as (host, port):\n            url = f\"https://{host}:{port}\"\n            r1 = s.get(url, verify=False)\n            assert r1.status_code == 200\n\n            # Has right trust bundle, but certificate expired\n            with pytest.raises(requests.exceptions.SSLError):\n                s.get(url, verify=\"tests/certs/expired/ca/ca.crt\")\n\n            close_server.set()\n        assert 2 == len(s.adapters[\"https://\"].poolmanager.pools)\n\n    def test_different_connection_pool_for_tls_s"}, {"start_line": 75000, "end_line": 77000, "belongs_to": {"file_name": "test_requests.py", "upper_path": "/data2/raymone/swebench-repos/requests/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": " = requests.get(httpbin(\"stream/4\"), stream=True)\n        assert r.status_code == 200\n\n        it = r.iter_lines()\n        next(it)\n        assert len(list(it)) == 3\n\n    def test_response_context_manager(self, httpbin):\n        with requests.get(httpbin(\"stream/4\"), stream=True) as response:\n            assert isinstance(response, requests.Response)\n\n        assert response.raw.closed\n\n    def test_unconsumed_session_response_closes_connection(self, httpbin):\n        s = requests.session()\n\n        with contextlib.closing(s.get(httpbin(\"stream/4\"), stream=True)) as response:\n            pass\n\n        assert response._content_consumed is False\n        assert response.raw.closed\n\n    @pytest.mark.xfail\n    def test_response_iter_lines_reentrant(self, httpbin):\n        \"\"\"Response.iter_lines() is not reentrant safe\"\"\"\n        r = requests.get(httpbin(\"stream/4\"), stream=True)\n        assert r.status_code == 200\n\n        next(r.iter_lines())\n        assert len(list(r.iter_lines())) == 3\n\n    def test_session_close_proxy_clear(self):\n        proxies = {\n            \"one\": mock.Mock(),\n            \"two\": mock.Mock(),\n        }\n        session = requests.Session()\n        with mock.patch.dict(session.adapters[\"http://\"].proxy_manager, proxies):\n            session.close()\n            proxies[\"one\"].clear.assert_called_once_with()\n            proxies[\"two\"].clear.assert_called_once_with()\n\n    def test_proxy_auth(self):\n        adapter = HTTPAdapter()\n        headers = adapter.proxy_headers(\"http://user:pass@httpbin.org\")\n        assert headers == {\"Proxy-Authorization\": \"Basic dXNlcjpwYXNz\"}\n\n    def test_proxy_auth_empty_pass(self):\n        adapter = HTTPAdapter()\n        headers = adapter.proxy_headers(\"http://user:@httpbin.org\")\n        assert headers == {\"Proxy-Authorization\": \"Basic dXNlcjo=\"}\n\n    def test_response_json_when_content_is_None(self, httpbin):\n        r = requests.get(httpbin(\"/status/204\"))\n        # Make sure r.content is None\n        r.status_code = "}, {"start_line": 102000, "end_line": 104000, "belongs_to": {"file_name": "test_requests.py", "upper_path": "/data2/raymone/swebench-repos/requests/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "1 200 OK\\r\\n\"\n                b\"Content-Length: 18\\r\\n\\r\\n\"\n                b'\\xff\\xfe{\\x00\"\\x00K0\"\\x00=\\x00\"\\x00\\xab0\"\\x00\\r\\n'\n            )\n\n        s = requests.Session()\n        close_server = threading.Event()\n        server = TLSServer(\n            handler=response_handler,\n            wait_to_close_event=close_server,\n            requests_to_handle=3,\n            cert_chain=\"tests/certs/expired/server/server.pem\",\n            keyfile=\"tests/certs/expired/server/server.key\",\n        )\n\n        with server as (host, port):\n            url = f\"https://{host}:{port}\"\n            r1 = s.get(url, verify=False)\n            assert r1.status_code == 200\n\n            # Has right trust bundle, but certificate expired\n            with pytest.raises(requests.exceptions.SSLError):\n                s.get(url, verify=\"tests/certs/expired/ca/ca.crt\")\n\n            close_server.set()\n        assert 2 == len(s.adapters[\"https://\"].poolmanager.pools)\n\n    def test_different_connection_pool_for_tls_settings_verify_bundle_unexpired_cert(\n        self,\n    ):\n        def response_handler(sock):\n            consume_socket_content(sock, timeout=0.5)\n            sock.send(\n                b\"HTTP/1.1 200 OK\\r\\n\"\n                b\"Content-Length: 18\\r\\n\\r\\n\"\n                b'\\xff\\xfe{\\x00\"\\x00K0\"\\x00=\\x00\"\\x00\\xab0\"\\x00\\r\\n'\n            )\n\n        s = requests.Session()\n        close_server = threading.Event()\n        server = TLSServer(\n            handler=response_handler,\n            wait_to_close_event=close_server,\n            requests_to_handle=3,\n            cert_chain=\"tests/certs/valid/server/server.pem\",\n            keyfile=\"tests/certs/valid/server/server.key\",\n        )\n\n        with server as (host, port):\n            url = f\"https://{host}:{port}\"\n            r1 = s.get(url, verify=False)\n            assert r1.status_code == 200\n\n            r2 = s.get(url, verify=\"tests/certs/valid/ca/ca.crt\")\n            assert r2.status_code == 200\n\n            close_server.set()\n      "}, {"start_line": 0, "end_line": 2000, "belongs_to": {"file_name": "sessions.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "\"\"\"\nrequests.sessions\n~~~~~~~~~~~~~~~~~\n\nThis module provides a Session object to manage and persist settings across\nrequests (cookies, auth, proxies).\n\"\"\"\nimport os\nimport sys\nimport time\nfrom collections import OrderedDict\nfrom datetime import timedelta\n\nfrom ._internal_utils import to_native_string\nfrom .adapters import HTTPAdapter\nfrom .auth import _basic_auth_str\nfrom .compat import Mapping, cookielib, urljoin, urlparse\nfrom .cookies import (\n    RequestsCookieJar,\n    cookiejar_from_dict,\n    extract_cookies_to_jar,\n    merge_cookies,\n)\nfrom .exceptions import (\n    ChunkedEncodingError,\n    ContentDecodingError,\n    InvalidSchema,\n    TooManyRedirects,\n)\nfrom .hooks import default_hooks, dispatch_hook\n\n# formerly defined here, reexposed here for backward compatibility\nfrom .models import (  # noqa: F401\n    DEFAULT_REDIRECT_LIMIT,\n    REDIRECT_STATI,\n    PreparedRequest,\n    Request,\n)\nfrom .status_codes import codes\nfrom .structures import CaseInsensitiveDict\nfrom .utils import (  # noqa: F401\n    DEFAULT_PORTS,\n    default_headers,\n    get_auth_from_url,\n    get_environ_proxies,\n    get_netrc_auth,\n    requote_uri,\n    resolve_proxies,\n    rewind_body,\n    should_bypass_proxies,\n    to_key_val_list,\n)\n\n# Preferred clock, based on which one is more accurate on a given system.\nif sys.platform == \"win32\":\n    preferred_clock = time.perf_counter\nelse:\n    preferred_clock = time.time\n\n\ndef merge_setting(request_setting, session_setting, dict_class=OrderedDict):\n    \"\"\"Determines appropriate setting for a given request, taking into account\n    the explicit setting on that request, and the setting in the session. If a\n    setting is a dictionary, they will be merged together using `dict_class`\n    \"\"\"\n\n    if session_setting is None:\n        return request_setting\n\n    if request_setting is None:\n        return session_setting\n\n    # Bypass if not a dictionary (e.g. verify)\n    if not (\n        isinstance(session_setting, Mapping) and isinstance(request_setting, M"}, {"start_line": 19000, "end_line": 21000, "belongs_to": {"file_name": "adapters.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "(url)\n        else:\n            # Only scheme should be lower case\n            parsed = urlparse(url)\n            url = parsed.geturl()\n            conn = self.poolmanager.connection_from_url(url)\n\n        return conn\n\n    def close(self):\n        \"\"\"Disposes of any internal state.\n\n        Currently, this closes the PoolManager and any active ProxyManager,\n        which closes any pooled connections.\n        \"\"\"\n        self.poolmanager.clear()\n        for proxy in self.proxy_manager.values():\n            proxy.clear()\n\n    def request_url(self, request, proxies):\n        \"\"\"Obtain the url to use when making the final request.\n\n        If the message is being sent through a HTTP proxy, the full URL has to\n        be used. Otherwise, we should only use the path portion of the URL.\n\n        This should not be called from user code, and is only exposed for use\n        when subclassing the\n        :class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.\n\n        :param request: The :class:`PreparedRequest <PreparedRequest>` being sent.\n        :param proxies: A dictionary of schemes or schemes and hosts to proxy URLs.\n        :rtype: str\n        \"\"\"\n        proxy = select_proxy(request.url, proxies)\n        scheme = urlparse(request.url).scheme\n\n        is_proxied_http_request = proxy and scheme != \"https\"\n        using_socks_proxy = False\n        if proxy:\n            proxy_scheme = urlparse(proxy).scheme.lower()\n            using_socks_proxy = proxy_scheme.startswith(\"socks\")\n\n        url = request.path_url\n        if url.startswith(\"//\"):  # Don't confuse urllib3\n            url = f\"/{url.lstrip('/')}\"\n\n        if is_proxied_http_request and not using_socks_proxy:\n            url = urldefragauth(request.url)\n\n        return url\n\n    def add_headers(self, request, **kwargs):\n        \"\"\"Add any headers needed by the connection. As of v2.0 this does\n        nothing by default, but is left for overriding by users that subclass\n        the :class:`HTTPAdapter <requests.adap"}, {"start_line": 6000, "end_line": 8000, "belongs_to": {"file_name": "adapters.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "ies = Retry.from_int(max_retries)\n        self.config = {}\n        self.proxy_manager = {}\n\n        super().__init__()\n\n        self._pool_connections = pool_connections\n        self._pool_maxsize = pool_maxsize\n        self._pool_block = pool_block\n\n        self.init_poolmanager(pool_connections, pool_maxsize, block=pool_block)\n\n    def __getstate__(self):\n        return {attr: getattr(self, attr, None) for attr in self.__attrs__}\n\n    def __setstate__(self, state):\n        # Can't handle by adding 'proxy_manager' to self.__attrs__ because\n        # self.poolmanager uses a lambda function, which isn't pickleable.\n        self.proxy_manager = {}\n        self.config = {}\n\n        for attr, value in state.items():\n            setattr(self, attr, value)\n\n        self.init_poolmanager(\n            self._pool_connections, self._pool_maxsize, block=self._pool_block\n        )\n\n    def init_poolmanager(\n        self, connections, maxsize, block=DEFAULT_POOLBLOCK, **pool_kwargs\n    ):\n        \"\"\"Initializes a urllib3 PoolManager.\n\n        This method should not be called from user code, and is only\n        exposed for use when subclassing the\n        :class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.\n\n        :param connections: The number of urllib3 connection pools to cache.\n        :param maxsize: The maximum number of connections to save in the pool.\n        :param block: Block when no free connections are available.\n        :param pool_kwargs: Extra keyword arguments used to initialize the Pool Manager.\n        \"\"\"\n        # save these values for pickling\n        self._pool_connections = connections\n        self._pool_maxsize = maxsize\n        self._pool_block = block\n\n        self.poolmanager = PoolManager(\n            num_pools=connections,\n            maxsize=maxsize,\n            block=block,\n            **pool_kwargs,\n        )\n\n    def proxy_manager_for(self, proxy, **proxy_kwargs):\n        \"\"\"Return urllib3 ProxyManager for the given proxy.\n\n        This method"}], "retrieved_count": 10, "cost_time": 4.669817209243774}
{"question": "Why does Requests implement connection reuse for performance optimization?", "answer": null, "relative_code_list": null, "ground_truth": "Requests implements connection reuse for performance optimization to address fundamental network efficiency challenges: 1) Connection establishment overhead - TCP connection setup involves multiple round trips (SYN, SYN-ACK, ACK) that add significant latency; 2) SSL/TLS handshake cost - SSL/TLS negotiation involves expensive cryptographic operations that are avoided through connection reuse; 3) DNS resolution - DNS lookups are eliminated for subsequent requests to the same host; 4) HTTP/1.1 compliance - Leverages HTTP/1.1 keep-alive feature to send multiple requests over a single connection; 5) Reduced server load - Fewer connection establishments reduce server-side resource consumption; 6) Network efficiency - Minimizes network overhead and reduces bandwidth usage from connection setup; 7) Improved throughput - Connection reuse enables higher request throughput, especially for applications making many requests to the same servers; 8) Resource conservation - Reduces the number of open file descriptors and system resources required; 9) Latency reduction - Eliminates connection setup time for subsequent requests, dramatically improving response times; 10) Scalability - Enables applications to handle higher request volumes without proportional increases in resource usage.", "score": null, "retrieved_content": [{"start_line": 5000, "end_line": 7000, "belongs_to": {"file_name": "adapters.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": " requests where data has\n        made it to the server. By default, Requests does not retry failed\n        connections. If you need granular control over the conditions under\n        which we retry a request, import urllib3's ``Retry`` class and pass\n        that instead.\n    :param pool_block: Whether the connection pool should block for connections.\n\n    Usage::\n\n      >>> import requests\n      >>> s = requests.Session()\n      >>> a = requests.adapters.HTTPAdapter(max_retries=3)\n      >>> s.mount('http://', a)\n    \"\"\"\n\n    __attrs__ = [\n        \"max_retries\",\n        \"config\",\n        \"_pool_connections\",\n        \"_pool_maxsize\",\n        \"_pool_block\",\n    ]\n\n    def __init__(\n        self,\n        pool_connections=DEFAULT_POOLSIZE,\n        pool_maxsize=DEFAULT_POOLSIZE,\n        max_retries=DEFAULT_RETRIES,\n        pool_block=DEFAULT_POOLBLOCK,\n    ):\n        if max_retries == DEFAULT_RETRIES:\n            self.max_retries = Retry(0, read=False)\n        else:\n            self.max_retries = Retry.from_int(max_retries)\n        self.config = {}\n        self.proxy_manager = {}\n\n        super().__init__()\n\n        self._pool_connections = pool_connections\n        self._pool_maxsize = pool_maxsize\n        self._pool_block = pool_block\n\n        self.init_poolmanager(pool_connections, pool_maxsize, block=pool_block)\n\n    def __getstate__(self):\n        return {attr: getattr(self, attr, None) for attr in self.__attrs__}\n\n    def __setstate__(self, state):\n        # Can't handle by adding 'proxy_manager' to self.__attrs__ because\n        # self.poolmanager uses a lambda function, which isn't pickleable.\n        self.proxy_manager = {}\n        self.config = {}\n\n        for attr, value in state.items():\n            setattr(self, attr, value)\n\n        self.init_poolmanager(\n            self._pool_connections, self._pool_maxsize, block=self._pool_block\n        )\n\n    def init_poolmanager(\n        self, connections, maxsize, block=DEFAULT_POOLBLOCK, **pool_kwargs\n    ):\n        \""}, {"start_line": 19000, "end_line": 21000, "belongs_to": {"file_name": "adapters.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "(url)\n        else:\n            # Only scheme should be lower case\n            parsed = urlparse(url)\n            url = parsed.geturl()\n            conn = self.poolmanager.connection_from_url(url)\n\n        return conn\n\n    def close(self):\n        \"\"\"Disposes of any internal state.\n\n        Currently, this closes the PoolManager and any active ProxyManager,\n        which closes any pooled connections.\n        \"\"\"\n        self.poolmanager.clear()\n        for proxy in self.proxy_manager.values():\n            proxy.clear()\n\n    def request_url(self, request, proxies):\n        \"\"\"Obtain the url to use when making the final request.\n\n        If the message is being sent through a HTTP proxy, the full URL has to\n        be used. Otherwise, we should only use the path portion of the URL.\n\n        This should not be called from user code, and is only exposed for use\n        when subclassing the\n        :class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.\n\n        :param request: The :class:`PreparedRequest <PreparedRequest>` being sent.\n        :param proxies: A dictionary of schemes or schemes and hosts to proxy URLs.\n        :rtype: str\n        \"\"\"\n        proxy = select_proxy(request.url, proxies)\n        scheme = urlparse(request.url).scheme\n\n        is_proxied_http_request = proxy and scheme != \"https\"\n        using_socks_proxy = False\n        if proxy:\n            proxy_scheme = urlparse(proxy).scheme.lower()\n            using_socks_proxy = proxy_scheme.startswith(\"socks\")\n\n        url = request.path_url\n        if url.startswith(\"//\"):  # Don't confuse urllib3\n            url = f\"/{url.lstrip('/')}\"\n\n        if is_proxied_http_request and not using_socks_proxy:\n            url = urldefragauth(request.url)\n\n        return url\n\n    def add_headers(self, request, **kwargs):\n        \"\"\"Add any headers needed by the connection. As of v2.0 this does\n        nothing by default, but is left for overriding by users that subclass\n        the :class:`HTTPAdapter <requests.adap"}, {"start_line": 13000, "end_line": 15000, "belongs_to": {"file_name": "sessions.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "POST is responded to with a 301, turn it into a GET.\n        # This bizarre behaviour is explained in Issue 1704.\n        if response.status_code == codes.moved and method == \"POST\":\n            method = \"GET\"\n\n        prepared_request.method = method\n\n\nclass Session(SessionRedirectMixin):\n    \"\"\"A Requests session.\n\n    Provides cookie persistence, connection-pooling, and configuration.\n\n    Basic Usage::\n\n      >>> import requests\n      >>> s = requests.Session()\n      >>> s.get('https://httpbin.org/get')\n      <Response [200]>\n\n    Or as a context manager::\n\n      >>> with requests.Session() as s:\n      ...     s.get('https://httpbin.org/get')\n      <Response [200]>\n    \"\"\"\n\n    __attrs__ = [\n        \"headers\",\n        \"cookies\",\n        \"auth\",\n        \"proxies\",\n        \"hooks\",\n        \"params\",\n        \"verify\",\n        \"cert\",\n        \"adapters\",\n        \"stream\",\n        \"trust_env\",\n        \"max_redirects\",\n    ]\n\n    def __init__(self):\n        #: A case-insensitive dictionary of headers to be sent on each\n        #: :class:`Request <Request>` sent from this\n        #: :class:`Session <Session>`.\n        self.headers = default_headers()\n\n        #: Default Authentication tuple or object to attach to\n        #: :class:`Request <Request>`.\n        self.auth = None\n\n        #: Dictionary mapping protocol or protocol and host to the URL of the proxy\n        #: (e.g. {'http': 'foo.bar:3128', 'http://host.name': 'foo.bar:4012'}) to\n        #: be used on each :class:`Request <Request>`.\n        self.proxies = {}\n\n        #: Event-handling hooks.\n        self.hooks = default_hooks()\n\n        #: Dictionary of querystring data to attach to each\n        #: :class:`Request <Request>`. The dictionary values may be lists for\n        #: representing multivalued query parameters.\n        self.params = {}\n\n        #: Stream response content default.\n        self.stream = False\n\n        #: SSL Verification default.\n        #: Defaults to `True`, requiring requests to verif"}, {"start_line": 8000, "end_line": 10000, "belongs_to": {"file_name": "sessions.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "     # https://github.com/psf/requests/issues/3490\n                purged_headers = (\"Content-Length\", \"Content-Type\", \"Transfer-Encoding\")\n                for header in purged_headers:\n                    prepared_request.headers.pop(header, None)\n                prepared_request.body = None\n\n            headers = prepared_request.headers\n            headers.pop(\"Cookie\", None)\n\n            # Extract any cookies sent on the response to the cookiejar\n            # in the new request. Because we've mutated our copied prepared\n            # request, use the old one that we haven't yet touched.\n            extract_cookies_to_jar(prepared_request._cookies, req, resp.raw)\n            merge_cookies(prepared_request._cookies, self.cookies)\n            prepared_request.prepare_cookies(prepared_request._cookies)\n\n            # Rebuild auth and proxy information.\n            proxies = self.rebuild_proxies(prepared_request, proxies)\n            self.rebuild_auth(prepared_request, resp)\n\n            # A failed tell() sets `_body_position` to `object()`. This non-None\n            # value ensures `rewindable` will be True, allowing us to raise an\n            # UnrewindableBodyError, instead of hanging the connection.\n            rewindable = prepared_request._body_position is not None and (\n                \"Content-Length\" in headers or \"Transfer-Encoding\" in headers\n            )\n\n            # Attempt to rewind consumed file-like object.\n            if rewindable:\n                rewind_body(prepared_request)\n\n            # Override the original request.\n            req = prepared_request\n\n            if yield_requests:\n                yield req\n            else:\n                resp = self.send(\n                    req,\n                    stream=stream,\n                    timeout=timeout,\n                    verify=verify,\n                    cert=cert,\n                    proxies=proxies,\n                    allow_redirects=False,\n                    **adapter_kwargs,\n     "}, {"start_line": 75000, "end_line": 77000, "belongs_to": {"file_name": "test_requests.py", "upper_path": "/data2/raymone/swebench-repos/requests/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": " = requests.get(httpbin(\"stream/4\"), stream=True)\n        assert r.status_code == 200\n\n        it = r.iter_lines()\n        next(it)\n        assert len(list(it)) == 3\n\n    def test_response_context_manager(self, httpbin):\n        with requests.get(httpbin(\"stream/4\"), stream=True) as response:\n            assert isinstance(response, requests.Response)\n\n        assert response.raw.closed\n\n    def test_unconsumed_session_response_closes_connection(self, httpbin):\n        s = requests.session()\n\n        with contextlib.closing(s.get(httpbin(\"stream/4\"), stream=True)) as response:\n            pass\n\n        assert response._content_consumed is False\n        assert response.raw.closed\n\n    @pytest.mark.xfail\n    def test_response_iter_lines_reentrant(self, httpbin):\n        \"\"\"Response.iter_lines() is not reentrant safe\"\"\"\n        r = requests.get(httpbin(\"stream/4\"), stream=True)\n        assert r.status_code == 200\n\n        next(r.iter_lines())\n        assert len(list(r.iter_lines())) == 3\n\n    def test_session_close_proxy_clear(self):\n        proxies = {\n            \"one\": mock.Mock(),\n            \"two\": mock.Mock(),\n        }\n        session = requests.Session()\n        with mock.patch.dict(session.adapters[\"http://\"].proxy_manager, proxies):\n            session.close()\n            proxies[\"one\"].clear.assert_called_once_with()\n            proxies[\"two\"].clear.assert_called_once_with()\n\n    def test_proxy_auth(self):\n        adapter = HTTPAdapter()\n        headers = adapter.proxy_headers(\"http://user:pass@httpbin.org\")\n        assert headers == {\"Proxy-Authorization\": \"Basic dXNlcjpwYXNz\"}\n\n    def test_proxy_auth_empty_pass(self):\n        adapter = HTTPAdapter()\n        headers = adapter.proxy_headers(\"http://user:@httpbin.org\")\n        assert headers == {\"Proxy-Authorization\": \"Basic dXNlcjo=\"}\n\n    def test_response_json_when_content_is_None(self, httpbin):\n        r = requests.get(httpbin(\"/status/204\"))\n        # Make sure r.content is None\n        r.status_code = "}, {"start_line": 94000, "end_line": 96000, "belongs_to": {"file_name": "test_requests.py", "upper_path": "/data2/raymone/swebench-repos/requests/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "\"_cookies\", \"body\", \"hooks\"):\n        assert getattr(p, attr) == getattr(copy, attr)\n\n\ndef test_urllib3_retries(httpbin):\n    from urllib3.util import Retry\n\n    s = requests.Session()\n    s.mount(\"http://\", HTTPAdapter(max_retries=Retry(total=2, status_forcelist=[500])))\n\n    with pytest.raises(RetryError):\n        s.get(httpbin(\"status/500\"))\n\n\ndef test_urllib3_pool_connection_closed(httpbin):\n    s = requests.Session()\n    s.mount(\"http://\", HTTPAdapter(pool_connections=0, pool_maxsize=0))\n\n    try:\n        s.get(httpbin(\"status/200\"))\n    except ConnectionError as e:\n        assert \"Pool is closed.\" in str(e)\n\n\nclass TestPreparingURLs:\n    @pytest.mark.parametrize(\n        \"url,expected\",\n        (\n            (\"http://google.com\", \"http://google.com/\"),\n            (\"http://.jp\", \"http://xn--hckqz9bzb1cyrb.jp/\"),\n            (\"http://xn--n3h.net/\", \"http://xn--n3h.net/\"),\n            (\"http://.jp\".encode(), \"http://xn--hckqz9bzb1cyrb.jp/\"),\n            (\"http://strae.de/strae\", \"http://xn--strae-oqa.de/stra%C3%9Fe\"),\n            (\n                \"http://strae.de/strae\".encode(),\n                \"http://xn--strae-oqa.de/stra%C3%9Fe\",\n            ),\n            (\n                \"http://Knigsgchen.de/strae\",\n                \"http://xn--knigsgchen-b4a3dun.de/stra%C3%9Fe\",\n            ),\n            (\n                \"http://Knigsgchen.de/strae\".encode(),\n                \"http://xn--knigsgchen-b4a3dun.de/stra%C3%9Fe\",\n            ),\n            (b\"http://xn--n3h.net/\", \"http://xn--n3h.net/\"),\n            (\n                b\"http://[1200:0000:ab00:1234:0000:2552:7777:1313]:12345/\",\n                \"http://[1200:0000:ab00:1234:0000:2552:7777:1313]:12345/\",\n            ),\n            (\n                \"http://[1200:0000:ab00:1234:0000:2552:7777:1313]:12345/\",\n                \"http://[1200:0000:ab00:1234:0000:2552:7777:1313]:12345/\",\n            ),\n        ),\n    )\n    def test_preparing_url(self, url, expected):\n        def normalize_perce"}, {"start_line": 4000, "end_line": 6000, "belongs_to": {"file_name": "adapters.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "        :param cert: (optional) Any user-provided SSL certificate to be trusted.\n        :param proxies: (optional) The proxies dictionary to apply to the request.\n        \"\"\"\n        raise NotImplementedError\n\n    def close(self):\n        \"\"\"Cleans up adapter specific items.\"\"\"\n        raise NotImplementedError\n\n\nclass HTTPAdapter(BaseAdapter):\n    \"\"\"The built-in HTTP Adapter for urllib3.\n\n    Provides a general-case interface for Requests sessions to contact HTTP and\n    HTTPS urls by implementing the Transport Adapter interface. This class will\n    usually be created by the :class:`Session <Session>` class under the\n    covers.\n\n    :param pool_connections: The number of urllib3 connection pools to cache.\n    :param pool_maxsize: The maximum number of connections to save in the pool.\n    :param max_retries: The maximum number of retries each connection\n        should attempt. Note, this applies only to failed DNS lookups, socket\n        connections and connection timeouts, never to requests where data has\n        made it to the server. By default, Requests does not retry failed\n        connections. If you need granular control over the conditions under\n        which we retry a request, import urllib3's ``Retry`` class and pass\n        that instead.\n    :param pool_block: Whether the connection pool should block for connections.\n\n    Usage::\n\n      >>> import requests\n      >>> s = requests.Session()\n      >>> a = requests.adapters.HTTPAdapter(max_retries=3)\n      >>> s.mount('http://', a)\n    \"\"\"\n\n    __attrs__ = [\n        \"max_retries\",\n        \"config\",\n        \"_pool_connections\",\n        \"_pool_maxsize\",\n        \"_pool_block\",\n    ]\n\n    def __init__(\n        self,\n        pool_connections=DEFAULT_POOLSIZE,\n        pool_maxsize=DEFAULT_POOLSIZE,\n        max_retries=DEFAULT_RETRIES,\n        pool_block=DEFAULT_POOLBLOCK,\n    ):\n        if max_retries == DEFAULT_RETRIES:\n            self.max_retries = Retry(0, read=False)\n        else:\n            self.max_retr"}, {"start_line": 74000, "end_line": 76000, "belongs_to": {"file_name": "test_requests.py", "upper_path": "/data2/raymone/swebench-repos/requests/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "name, password)\n        assert isinstance(s, builtin_str)\n        assert s == auth_str\n\n    def test_requests_history_is_saved(self, httpbin):\n        r = requests.get(httpbin(\"redirect/5\"))\n        total = r.history[-1].history\n        i = 0\n        for item in r.history:\n            assert item.history == total[0:i]\n            i += 1\n\n    def test_json_param_post_content_type_works(self, httpbin):\n        r = requests.post(httpbin(\"post\"), json={\"life\": 42})\n        assert r.status_code == 200\n        assert \"application/json\" in r.request.headers[\"Content-Type\"]\n        assert {\"life\": 42} == r.json()[\"json\"]\n\n    def test_json_param_post_should_not_override_data_param(self, httpbin):\n        r = requests.Request(\n            method=\"POST\",\n            url=httpbin(\"post\"),\n            data={\"stuff\": \"elixr\"},\n            json={\"music\": \"flute\"},\n        )\n        prep = r.prepare()\n        assert \"stuff=elixr\" == prep.body\n\n    def test_response_iter_lines(self, httpbin):\n        r = requests.get(httpbin(\"stream/4\"), stream=True)\n        assert r.status_code == 200\n\n        it = r.iter_lines()\n        next(it)\n        assert len(list(it)) == 3\n\n    def test_response_context_manager(self, httpbin):\n        with requests.get(httpbin(\"stream/4\"), stream=True) as response:\n            assert isinstance(response, requests.Response)\n\n        assert response.raw.closed\n\n    def test_unconsumed_session_response_closes_connection(self, httpbin):\n        s = requests.session()\n\n        with contextlib.closing(s.get(httpbin(\"stream/4\"), stream=True)) as response:\n            pass\n\n        assert response._content_consumed is False\n        assert response.raw.closed\n\n    @pytest.mark.xfail\n    def test_response_iter_lines_reentrant(self, httpbin):\n        \"\"\"Response.iter_lines() is not reentrant safe\"\"\"\n        r = requests.get(httpbin(\"stream/4\"), stream=True)\n        assert r.status_code == 200\n\n        next(r.iter_lines())\n        assert len(list(r.iter_lines())) == 3\n\n"}, {"start_line": 0, "end_line": 2000, "belongs_to": {"file_name": "adapters.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "\"\"\"\nrequests.adapters\n~~~~~~~~~~~~~~~~~\n\nThis module contains the transport adapters that Requests uses to define\nand maintain connections.\n\"\"\"\n\nimport os.path\nimport socket  # noqa: F401\nimport typing\nimport warnings\n\nfrom urllib3.exceptions import ClosedPoolError, ConnectTimeoutError\nfrom urllib3.exceptions import HTTPError as _HTTPError\nfrom urllib3.exceptions import InvalidHeader as _InvalidHeader\nfrom urllib3.exceptions import (\n    LocationValueError,\n    MaxRetryError,\n    NewConnectionError,\n    ProtocolError,\n)\nfrom urllib3.exceptions import ProxyError as _ProxyError\nfrom urllib3.exceptions import ReadTimeoutError, ResponseError\nfrom urllib3.exceptions import SSLError as _SSLError\nfrom urllib3.poolmanager import PoolManager, proxy_from_url\nfrom urllib3.util import Timeout as TimeoutSauce\nfrom urllib3.util import parse_url\nfrom urllib3.util.retry import Retry\n\nfrom .auth import _basic_auth_str\nfrom .compat import basestring, urlparse\nfrom .cookies import extract_cookies_to_jar\nfrom .exceptions import (\n    ConnectionError,\n    ConnectTimeout,\n    InvalidHeader,\n    InvalidProxyURL,\n    InvalidSchema,\n    InvalidURL,\n    ProxyError,\n    ReadTimeout,\n    RetryError,\n    SSLError,\n)\nfrom .models import Response\nfrom .structures import CaseInsensitiveDict\nfrom .utils import (\n    DEFAULT_CA_BUNDLE_PATH,\n    extract_zipped_paths,\n    get_auth_from_url,\n    get_encoding_from_headers,\n    prepend_scheme_if_needed,\n    select_proxy,\n    urldefragauth,\n)\n\ntry:\n    from urllib3.contrib.socks import SOCKSProxyManager\nexcept ImportError:\n\n    def SOCKSProxyManager(*args, **kwargs):\n        raise InvalidSchema(\"Missing dependencies for SOCKS support.\")\n\n\nif typing.TYPE_CHECKING:\n    from .models import PreparedRequest\n\n\nDEFAULT_POOLBLOCK = False\nDEFAULT_POOLSIZE = 10\nDEFAULT_RETRIES = 0\nDEFAULT_POOL_TIMEOUT = None\n\n\ndef _urllib3_request_context(\n    request: \"PreparedRequest\",\n    verify: \"bool | str | None\",\n    client_cert: \"typing.Tuple[str, str] | str | None\",\n    po"}, {"start_line": 2000, "end_line": 4000, "belongs_to": {"file_name": "api.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": ".\n    :type allow_redirects: bool\n    :param proxies: (optional) Dictionary mapping protocol to the URL of the proxy.\n    :param verify: (optional) Either a boolean, in which case it controls whether we verify\n            the server's TLS certificate, or a string, in which case it must be a path\n            to a CA bundle to use. Defaults to ``True``.\n    :param stream: (optional) if ``False``, the response content will be immediately downloaded.\n    :param cert: (optional) if String, path to ssl client cert file (.pem). If Tuple, ('cert', 'key') pair.\n    :return: :class:`Response <Response>` object\n    :rtype: requests.Response\n\n    Usage::\n\n      >>> import requests\n      >>> req = requests.request('GET', 'https://httpbin.org/get')\n      >>> req\n      <Response [200]>\n    \"\"\"\n\n    # By using the 'with' statement we are sure the session is closed, thus we\n    # avoid leaving sockets open which can trigger a ResourceWarning in some\n    # cases, and look like a memory leak in others.\n    with sessions.Session() as session:\n        return session.request(method=method, url=url, **kwargs)\n\n\ndef get(url, params=None, **kwargs):\n    r\"\"\"Sends a GET request.\n\n    :param url: URL for the new :class:`Request` object.\n    :param params: (optional) Dictionary, list of tuples or bytes to send\n        in the query string for the :class:`Request`.\n    :param \\*\\*kwargs: Optional arguments that ``request`` takes.\n    :return: :class:`Response <Response>` object\n    :rtype: requests.Response\n    \"\"\"\n\n    return request(\"get\", url, params=params, **kwargs)\n\n\ndef options(url, **kwargs):\n    r\"\"\"Sends an OPTIONS request.\n\n    :param url: URL for the new :class:`Request` object.\n    :param \\*\\*kwargs: Optional arguments that ``request`` takes.\n    :return: :class:`Response <Response>` object\n    :rtype: requests.Response\n    \"\"\"\n\n    return request(\"options\", url, **kwargs)\n\n\ndef head(url, **kwargs):\n    r\"\"\"Sends a HEAD request.\n\n    :param url: URL for the new :class:`Request` obje"}], "retrieved_count": 10, "cost_time": 4.709742307662964}
{"question": "Where in the Requests codebase is the core HTTP client implemented?", "answer": null, "relative_code_list": null, "ground_truth": "The core HTTP client is implemented across multiple files in the src/requests/ directory: 1) Main API functions (get, post, etc.) are defined in src/requests/api.py and use Session objects internally; 2) Session management and request coordination is implemented in src/requests/sessions.py through the Session class; 3) Request and Response objects are defined in src/requests/models.py; 4) Transport abstraction and connection pooling is handled in src/requests/adapters.py through HTTPAdapter; 5) Authentication is implemented in src/requests/auth.py; 6) Cookie handling is in src/requests/cookies.py; 7) Exception classes are defined in src/requests/exceptions.py; 8) Utility functions are in src/requests/utils.py. The main entry point is src/requests/__init__.py which imports and exposes the public API. The core client architecture follows a layered approach: API layer (api.py)  Session layer (sessions.py)  Request/Response layer (models.py)  Adapter layer (adapters.py)  Transport layer (urllib3).", "score": null, "retrieved_content": [{"start_line": 0, "end_line": 2000, "belongs_to": {"file_name": "api.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "\"\"\"\nrequests.api\n~~~~~~~~~~~~\n\nThis module implements the Requests API.\n\n:copyright: (c) 2012 by Kenneth Reitz.\n:license: Apache2, see LICENSE for more details.\n\"\"\"\n\nfrom . import sessions\n\n\ndef request(method, url, **kwargs):\n    \"\"\"Constructs and sends a :class:`Request <Request>`.\n\n    :param method: method for the new :class:`Request` object: ``GET``, ``OPTIONS``, ``HEAD``, ``POST``, ``PUT``, ``PATCH``, or ``DELETE``.\n    :param url: URL for the new :class:`Request` object.\n    :param params: (optional) Dictionary, list of tuples or bytes to send\n        in the query string for the :class:`Request`.\n    :param data: (optional) Dictionary, list of tuples, bytes, or file-like\n        object to send in the body of the :class:`Request`.\n    :param json: (optional) A JSON serializable Python object to send in the body of the :class:`Request`.\n    :param headers: (optional) Dictionary of HTTP Headers to send with the :class:`Request`.\n    :param cookies: (optional) Dict or CookieJar object to send with the :class:`Request`.\n    :param files: (optional) Dictionary of ``'name': file-like-objects`` (or ``{'name': file-tuple}``) for multipart encoding upload.\n        ``file-tuple`` can be a 2-tuple ``('filename', fileobj)``, 3-tuple ``('filename', fileobj, 'content_type')``\n        or a 4-tuple ``('filename', fileobj, 'content_type', custom_headers)``, where ``'content_type'`` is a string\n        defining the content type of the given file and ``custom_headers`` a dict-like object containing additional headers\n        to add for the file.\n    :param auth: (optional) Auth tuple to enable Basic/Digest/Custom HTTP Auth.\n    :param timeout: (optional) How many seconds to wait for the server to send data\n        before giving up, as a float, or a :ref:`(connect timeout, read\n        timeout) <timeouts>` tuple.\n    :type timeout: float or tuple\n    :param allow_redirects: (optional) Boolean. Enable/disable GET/OPTIONS/POST/PUT/PATCH/DELETE/HEAD redirection. Defaults to ``True``"}, {"start_line": 0, "end_line": 2000, "belongs_to": {"file_name": "models.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "\"\"\"\nrequests.models\n~~~~~~~~~~~~~~~\n\nThis module contains the primary objects that power Requests.\n\"\"\"\n\nimport datetime\n\n# Import encoding now, to avoid implicit import later.\n# Implicit import within threads may cause LookupError when standard library is in a ZIP,\n# such as in Embedded Python. See https://github.com/psf/requests/issues/3578.\nimport encodings.idna  # noqa: F401\nfrom io import UnsupportedOperation\n\nfrom urllib3.exceptions import (\n    DecodeError,\n    LocationParseError,\n    ProtocolError,\n    ReadTimeoutError,\n    SSLError,\n)\nfrom urllib3.fields import RequestField\nfrom urllib3.filepost import encode_multipart_formdata\nfrom urllib3.util import parse_url\n\nfrom ._internal_utils import to_native_string, unicode_is_ascii\nfrom .auth import HTTPBasicAuth\nfrom .compat import (\n    Callable,\n    JSONDecodeError,\n    Mapping,\n    basestring,\n    builtin_str,\n    chardet,\n    cookielib,\n)\nfrom .compat import json as complexjson\nfrom .compat import urlencode, urlsplit, urlunparse\nfrom .cookies import _copy_cookie_jar, cookiejar_from_dict, get_cookie_header\nfrom .exceptions import (\n    ChunkedEncodingError,\n    ConnectionError,\n    ContentDecodingError,\n    HTTPError,\n    InvalidJSONError,\n    InvalidURL,\n)\nfrom .exceptions import JSONDecodeError as RequestsJSONDecodeError\nfrom .exceptions import MissingSchema\nfrom .exceptions import SSLError as RequestsSSLError\nfrom .exceptions import StreamConsumedError\nfrom .hooks import default_hooks\nfrom .status_codes import codes\nfrom .structures import CaseInsensitiveDict\nfrom .utils import (\n    check_header_validity,\n    get_auth_from_url,\n    guess_filename,\n    guess_json_utf,\n    iter_slices,\n    parse_header_links,\n    requote_uri,\n    stream_decode_response_unicode,\n    super_len,\n    to_key_val_list,\n)\n\n#: The set of HTTP status codes that indicate an automatically\n#: processable redirect.\nREDIRECT_STATI = (\n    codes.moved,  # 301\n    codes.found,  # 302\n    codes.other,  # 303\n    codes.temporary_redirect,  # "}, {"start_line": 1000, "end_line": 3000, "belongs_to": {"file_name": "models.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "\nfrom .cookies import _copy_cookie_jar, cookiejar_from_dict, get_cookie_header\nfrom .exceptions import (\n    ChunkedEncodingError,\n    ConnectionError,\n    ContentDecodingError,\n    HTTPError,\n    InvalidJSONError,\n    InvalidURL,\n)\nfrom .exceptions import JSONDecodeError as RequestsJSONDecodeError\nfrom .exceptions import MissingSchema\nfrom .exceptions import SSLError as RequestsSSLError\nfrom .exceptions import StreamConsumedError\nfrom .hooks import default_hooks\nfrom .status_codes import codes\nfrom .structures import CaseInsensitiveDict\nfrom .utils import (\n    check_header_validity,\n    get_auth_from_url,\n    guess_filename,\n    guess_json_utf,\n    iter_slices,\n    parse_header_links,\n    requote_uri,\n    stream_decode_response_unicode,\n    super_len,\n    to_key_val_list,\n)\n\n#: The set of HTTP status codes that indicate an automatically\n#: processable redirect.\nREDIRECT_STATI = (\n    codes.moved,  # 301\n    codes.found,  # 302\n    codes.other,  # 303\n    codes.temporary_redirect,  # 307\n    codes.permanent_redirect,  # 308\n)\n\nDEFAULT_REDIRECT_LIMIT = 30\nCONTENT_CHUNK_SIZE = 10 * 1024\nITER_CHUNK_SIZE = 512\n\n\nclass RequestEncodingMixin:\n    @property\n    def path_url(self):\n        \"\"\"Build the path URL to use.\"\"\"\n\n        url = []\n\n        p = urlsplit(self.url)\n\n        path = p.path\n        if not path:\n            path = \"/\"\n\n        url.append(path)\n\n        query = p.query\n        if query:\n            url.append(\"?\")\n            url.append(query)\n\n        return \"\".join(url)\n\n    @staticmethod\n    def _encode_params(data):\n        \"\"\"Encode parameters in a piece of data.\n\n        Will successfully encode parameters when passed as a dict or a list of\n        2-tuples. Order is retained if data is a list of 2-tuples but arbitrary\n        if parameters are supplied as a dict.\n        \"\"\"\n\n        if isinstance(data, (str, bytes)):\n            return data\n        elif hasattr(data, \"read\"):\n            return data\n        elif hasattr(data, \"__iter__\"):\n         "}, {"start_line": 4000, "end_line": 5072, "belongs_to": {"file_name": "__init__.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": " urllib3's DependencyWarnings should be silenced.\nfrom urllib3.exceptions import DependencyWarning\n\nwarnings.simplefilter(\"ignore\", DependencyWarning)\n\n# Set default logging handler to avoid \"No handler found\" warnings.\nimport logging\nfrom logging import NullHandler\n\nfrom . import packages, utils\nfrom .__version__ import (\n    __author__,\n    __author_email__,\n    __build__,\n    __cake__,\n    __copyright__,\n    __description__,\n    __license__,\n    __title__,\n    __url__,\n    __version__,\n)\nfrom .api import delete, get, head, options, patch, post, put, request\nfrom .exceptions import (\n    ConnectionError,\n    ConnectTimeout,\n    FileModeWarning,\n    HTTPError,\n    JSONDecodeError,\n    ReadTimeout,\n    RequestException,\n    Timeout,\n    TooManyRedirects,\n    URLRequired,\n)\nfrom .models import PreparedRequest, Request, Response\nfrom .sessions import Session, session\nfrom .status_codes import codes\n\nlogging.getLogger(__name__).addHandler(NullHandler())\n\n# FileModeWarnings go off per the default.\nwarnings.simplefilter(\"default\", FileModeWarning, append=True)\n"}, {"start_line": 2000, "end_line": 4000, "belongs_to": {"file_name": "test_requests.py", "upper_path": "/data2/raymone/swebench-repos/requests/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": " requests.session\n        requests.session().get\n        requests.session().head\n        requests.get\n        requests.head\n        requests.put\n        requests.patch\n        requests.post\n        # Not really an entry point, but people rely on it.\n        from requests.packages.urllib3.poolmanager import PoolManager  # noqa:F401\n\n    @pytest.mark.parametrize(\n        \"exception, url\",\n        (\n            (MissingSchema, \"hiwpefhipowhefopw\"),\n            (InvalidSchema, \"localhost:3128\"),\n            (InvalidSchema, \"localhost.localdomain:3128/\"),\n            (InvalidSchema, \"10.122.1.1:3128/\"),\n            (InvalidURL, \"http://\"),\n            (InvalidURL, \"http://*example.com\"),\n            (InvalidURL, \"http://.example.com\"),\n        ),\n    )\n    def test_invalid_url(self, exception, url):\n        with pytest.raises(exception):\n            requests.get(url)\n\n    def test_basic_building(self):\n        req = requests.Request()\n        req.url = \"http://kennethreitz.org/\"\n        req.data = {\"life\": \"42\"}\n\n        pr = req.prepare()\n        assert pr.url == req.url\n        assert pr.body == \"life=42\"\n\n    @pytest.mark.parametrize(\"method\", (\"GET\", \"HEAD\"))\n    def test_no_content_length(self, httpbin, method):\n        req = requests.Request(method, httpbin(method.lower())).prepare()\n        assert \"Content-Length\" not in req.headers\n\n    @pytest.mark.parametrize(\"method\", (\"POST\", \"PUT\", \"PATCH\", \"OPTIONS\"))\n    def test_no_body_content_length(self, httpbin, method):\n        req = requests.Request(method, httpbin(method.lower())).prepare()\n        assert req.headers[\"Content-Length\"] == \"0\"\n\n    @pytest.mark.parametrize(\"method\", (\"POST\", \"PUT\", \"PATCH\", \"OPTIONS\"))\n    def test_empty_content_length(self, httpbin, method):\n        req = requests.Request(method, httpbin(method.lower()), data=\"\").prepare()\n        assert req.headers[\"Content-Length\"] == \"0\"\n\n    def test_override_content_length(self, httpbin):\n        headers = {\"Content-Length\": \"not zero\"}\n       "}, {"start_line": 0, "end_line": 2000, "belongs_to": {"file_name": "adapters.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "\"\"\"\nrequests.adapters\n~~~~~~~~~~~~~~~~~\n\nThis module contains the transport adapters that Requests uses to define\nand maintain connections.\n\"\"\"\n\nimport os.path\nimport socket  # noqa: F401\nimport typing\nimport warnings\n\nfrom urllib3.exceptions import ClosedPoolError, ConnectTimeoutError\nfrom urllib3.exceptions import HTTPError as _HTTPError\nfrom urllib3.exceptions import InvalidHeader as _InvalidHeader\nfrom urllib3.exceptions import (\n    LocationValueError,\n    MaxRetryError,\n    NewConnectionError,\n    ProtocolError,\n)\nfrom urllib3.exceptions import ProxyError as _ProxyError\nfrom urllib3.exceptions import ReadTimeoutError, ResponseError\nfrom urllib3.exceptions import SSLError as _SSLError\nfrom urllib3.poolmanager import PoolManager, proxy_from_url\nfrom urllib3.util import Timeout as TimeoutSauce\nfrom urllib3.util import parse_url\nfrom urllib3.util.retry import Retry\n\nfrom .auth import _basic_auth_str\nfrom .compat import basestring, urlparse\nfrom .cookies import extract_cookies_to_jar\nfrom .exceptions import (\n    ConnectionError,\n    ConnectTimeout,\n    InvalidHeader,\n    InvalidProxyURL,\n    InvalidSchema,\n    InvalidURL,\n    ProxyError,\n    ReadTimeout,\n    RetryError,\n    SSLError,\n)\nfrom .models import Response\nfrom .structures import CaseInsensitiveDict\nfrom .utils import (\n    DEFAULT_CA_BUNDLE_PATH,\n    extract_zipped_paths,\n    get_auth_from_url,\n    get_encoding_from_headers,\n    prepend_scheme_if_needed,\n    select_proxy,\n    urldefragauth,\n)\n\ntry:\n    from urllib3.contrib.socks import SOCKSProxyManager\nexcept ImportError:\n\n    def SOCKSProxyManager(*args, **kwargs):\n        raise InvalidSchema(\"Missing dependencies for SOCKS support.\")\n\n\nif typing.TYPE_CHECKING:\n    from .models import PreparedRequest\n\n\nDEFAULT_POOLBLOCK = False\nDEFAULT_POOLSIZE = 10\nDEFAULT_RETRIES = 0\nDEFAULT_POOL_TIMEOUT = None\n\n\ndef _urllib3_request_context(\n    request: \"PreparedRequest\",\n    verify: \"bool | str | None\",\n    client_cert: \"typing.Tuple[str, str] | str | None\",\n    po"}, {"start_line": 3000, "end_line": 5000, "belongs_to": {"file_name": "__init__.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "\n\n# Check imported dependencies for compatibility.\ntry:\n    check_compatibility(\n        urllib3.__version__, chardet_version, charset_normalizer_version\n    )\nexcept (AssertionError, ValueError):\n    warnings.warn(\n        \"urllib3 ({}) or chardet ({})/charset_normalizer ({}) doesn't match a supported \"\n        \"version!\".format(\n            urllib3.__version__, chardet_version, charset_normalizer_version\n        ),\n        RequestsDependencyWarning,\n    )\n\n# Attempt to enable urllib3's fallback for SNI support\n# if the standard library doesn't support SNI or the\n# 'ssl' library isn't available.\ntry:\n    try:\n        import ssl\n    except ImportError:\n        ssl = None\n\n    if not getattr(ssl, \"HAS_SNI\", False):\n        from urllib3.contrib import pyopenssl\n\n        pyopenssl.inject_into_urllib3()\n\n        # Check cryptography version\n        from cryptography import __version__ as cryptography_version\n\n        _check_cryptography(cryptography_version)\nexcept ImportError:\n    pass\n\n# urllib3's DependencyWarnings should be silenced.\nfrom urllib3.exceptions import DependencyWarning\n\nwarnings.simplefilter(\"ignore\", DependencyWarning)\n\n# Set default logging handler to avoid \"No handler found\" warnings.\nimport logging\nfrom logging import NullHandler\n\nfrom . import packages, utils\nfrom .__version__ import (\n    __author__,\n    __author_email__,\n    __build__,\n    __cake__,\n    __copyright__,\n    __description__,\n    __license__,\n    __title__,\n    __url__,\n    __version__,\n)\nfrom .api import delete, get, head, options, patch, post, put, request\nfrom .exceptions import (\n    ConnectionError,\n    ConnectTimeout,\n    FileModeWarning,\n    HTTPError,\n    JSONDecodeError,\n    ReadTimeout,\n    RequestException,\n    Timeout,\n    TooManyRedirects,\n    URLRequired,\n)\nfrom .models import PreparedRequest, Request, Response\nfrom .sessions import Session, session\nfrom .status_codes import codes\n\nlogging.getLogger(__name__).addHandler(NullHandler())\n\n# FileModeWarnings go off per the "}, {"start_line": 0, "end_line": 2000, "belongs_to": {"file_name": "__init__.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "#   __\n#  /__)  _  _     _   _ _/   _\n# / (   (- (/ (/ (- _)  /  _)\n#          /\n\n\"\"\"\nRequests HTTP Library\n~~~~~~~~~~~~~~~~~~~~~\n\nRequests is an HTTP library, written in Python, for human beings.\nBasic GET usage:\n\n   >>> import requests\n   >>> r = requests.get('https://www.python.org')\n   >>> r.status_code\n   200\n   >>> b'Python is a programming language' in r.content\n   True\n\n... or POST:\n\n   >>> payload = dict(key1='value1', key2='value2')\n   >>> r = requests.post('https://httpbin.org/post', data=payload)\n   >>> print(r.text)\n   {\n     ...\n     \"form\": {\n       \"key1\": \"value1\",\n       \"key2\": \"value2\"\n     },\n     ...\n   }\n\nThe other HTTP methods are supported - see `requests.api`. Full documentation\nis at <https://requests.readthedocs.io>.\n\n:copyright: (c) 2017 by Kenneth Reitz.\n:license: Apache 2.0, see LICENSE for more details.\n\"\"\"\n\nimport warnings\n\nimport urllib3\n\nfrom .exceptions import RequestsDependencyWarning\n\ntry:\n    from charset_normalizer import __version__ as charset_normalizer_version\nexcept ImportError:\n    charset_normalizer_version = None\n\ntry:\n    from chardet import __version__ as chardet_version\nexcept ImportError:\n    chardet_version = None\n\n\ndef check_compatibility(urllib3_version, chardet_version, charset_normalizer_version):\n    urllib3_version = urllib3_version.split(\".\")\n    assert urllib3_version != [\"dev\"]  # Verify urllib3 isn't installed from git.\n\n    # Sometimes, urllib3 only reports its version as 16.1.\n    if len(urllib3_version) == 2:\n        urllib3_version.append(\"0\")\n\n    # Check urllib3 for compatibility.\n    major, minor, patch = urllib3_version  # noqa: F811\n    major, minor, patch = int(major), int(minor), int(patch)\n    # urllib3 >= 1.21.1\n    assert major >= 1\n    if major == 1:\n        assert minor >= 21\n\n    # Check charset_normalizer for compatibility.\n    if chardet_version:\n        major, minor, patch = chardet_version.split(\".\")[:3]\n        major, minor, patch = int(major), int(minor), int(patch)\n        # charde"}, {"start_line": 13000, "end_line": 15000, "belongs_to": {"file_name": "sessions.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "POST is responded to with a 301, turn it into a GET.\n        # This bizarre behaviour is explained in Issue 1704.\n        if response.status_code == codes.moved and method == \"POST\":\n            method = \"GET\"\n\n        prepared_request.method = method\n\n\nclass Session(SessionRedirectMixin):\n    \"\"\"A Requests session.\n\n    Provides cookie persistence, connection-pooling, and configuration.\n\n    Basic Usage::\n\n      >>> import requests\n      >>> s = requests.Session()\n      >>> s.get('https://httpbin.org/get')\n      <Response [200]>\n\n    Or as a context manager::\n\n      >>> with requests.Session() as s:\n      ...     s.get('https://httpbin.org/get')\n      <Response [200]>\n    \"\"\"\n\n    __attrs__ = [\n        \"headers\",\n        \"cookies\",\n        \"auth\",\n        \"proxies\",\n        \"hooks\",\n        \"params\",\n        \"verify\",\n        \"cert\",\n        \"adapters\",\n        \"stream\",\n        \"trust_env\",\n        \"max_redirects\",\n    ]\n\n    def __init__(self):\n        #: A case-insensitive dictionary of headers to be sent on each\n        #: :class:`Request <Request>` sent from this\n        #: :class:`Session <Session>`.\n        self.headers = default_headers()\n\n        #: Default Authentication tuple or object to attach to\n        #: :class:`Request <Request>`.\n        self.auth = None\n\n        #: Dictionary mapping protocol or protocol and host to the URL of the proxy\n        #: (e.g. {'http': 'foo.bar:3128', 'http://host.name': 'foo.bar:4012'}) to\n        #: be used on each :class:`Request <Request>`.\n        self.proxies = {}\n\n        #: Event-handling hooks.\n        self.hooks = default_hooks()\n\n        #: Dictionary of querystring data to attach to each\n        #: :class:`Request <Request>`. The dictionary values may be lists for\n        #: representing multivalued query parameters.\n        self.params = {}\n\n        #: Stream response content default.\n        self.stream = False\n\n        #: SSL Verification default.\n        #: Defaults to `True`, requiring requests to verif"}, {"start_line": 1000, "end_line": 3000, "belongs_to": {"file_name": "test_requests.py", "upper_path": "/data2/raymone/swebench-repos/requests/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "ions import Timeout, TooManyRedirects, UnrewindableBodyError\nfrom requests.hooks import default_hooks\nfrom requests.models import PreparedRequest, urlencode\nfrom requests.sessions import SessionRedirectMixin\nfrom requests.structures import CaseInsensitiveDict\n\nfrom . import SNIMissingWarning\nfrom .compat import StringIO\nfrom .testserver.server import TLSServer, consume_socket_content\nfrom .utils import override_environ\n\n# Requests to this URL should always fail with a connection timeout (nothing\n# listening on that port)\nTARPIT = \"http://10.255.255.1\"\n\n# This is to avoid waiting the timeout of using TARPIT\nINVALID_PROXY = \"http://localhost:1\"\n\ntry:\n    from ssl import SSLContext\n\n    del SSLContext\n    HAS_MODERN_SSL = True\nexcept ImportError:\n    HAS_MODERN_SSL = False\n\ntry:\n    requests.pyopenssl\n    HAS_PYOPENSSL = True\nexcept AttributeError:\n    HAS_PYOPENSSL = False\n\n\nclass TestRequests:\n    digest_auth_algo = (\"MD5\", \"SHA-256\", \"SHA-512\")\n\n    def test_entry_points(self):\n        requests.session\n        requests.session().get\n        requests.session().head\n        requests.get\n        requests.head\n        requests.put\n        requests.patch\n        requests.post\n        # Not really an entry point, but people rely on it.\n        from requests.packages.urllib3.poolmanager import PoolManager  # noqa:F401\n\n    @pytest.mark.parametrize(\n        \"exception, url\",\n        (\n            (MissingSchema, \"hiwpefhipowhefopw\"),\n            (InvalidSchema, \"localhost:3128\"),\n            (InvalidSchema, \"localhost.localdomain:3128/\"),\n            (InvalidSchema, \"10.122.1.1:3128/\"),\n            (InvalidURL, \"http://\"),\n            (InvalidURL, \"http://*example.com\"),\n            (InvalidURL, \"http://.example.com\"),\n        ),\n    )\n    def test_invalid_url(self, exception, url):\n        with pytest.raises(exception):\n            requests.get(url)\n\n    def test_basic_building(self):\n        req = requests.Request()\n        req.url = \"http://kennethreitz.org/\"\n        req"}], "retrieved_count": 10, "cost_time": 4.710411787033081}
{"question": "Where are Requests' built-in adapters defined?", "answer": null, "relative_code_list": null, "ground_truth": "Requests' built-in adapters are defined in src/requests/adapters.py. The main adapter implementations include: 1) BaseAdapter - abstract base class defining the adapter interface with send() and close() methods; 2) HTTPAdapter - the primary implementation that wraps urllib3's PoolManager for HTTP/HTTPS connections, providing connection pooling, retry logic, proxy support, and SSL/TLS handling; 3) Adapter mounting system - Sessions mount adapters for different URL schemes (http://, https://) in Session.__init__() method in src/requests/sessions.py; 4) HTTPAdapter configuration includes pool_connections, pool_maxsize, max_retries, and pool_block parameters; 5) HTTPAdapter methods include send(), build_response(), cert_verify(), and connection pool management methods. The adapters provide the transport abstraction layer between Requests' high-level API and urllib3's low-level transport implementation. Custom adapters can be implemented by subclassing BaseAdapter and mounted to Sessions for specialized transport needs.", "score": null, "retrieved_content": [{"start_line": 28000, "end_line": 30000, "belongs_to": {"file_name": "sessions.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "vironment's proxies.\n            no_proxy = proxies.get(\"no_proxy\") if proxies is not None else None\n            env_proxies = get_environ_proxies(url, no_proxy=no_proxy)\n            for k, v in env_proxies.items():\n                proxies.setdefault(k, v)\n\n            # Look for requests environment configuration\n            # and be compatible with cURL.\n            if verify is True or verify is None:\n                verify = (\n                    os.environ.get(\"REQUESTS_CA_BUNDLE\")\n                    or os.environ.get(\"CURL_CA_BUNDLE\")\n                    or verify\n                )\n\n        # Merge all the kwargs.\n        proxies = merge_setting(proxies, self.proxies)\n        stream = merge_setting(stream, self.stream)\n        verify = merge_setting(verify, self.verify)\n        cert = merge_setting(cert, self.cert)\n\n        return {\"proxies\": proxies, \"stream\": stream, \"verify\": verify, \"cert\": cert}\n\n    def get_adapter(self, url):\n        \"\"\"\n        Returns the appropriate connection adapter for the given URL.\n\n        :rtype: requests.adapters.BaseAdapter\n        \"\"\"\n        for prefix, adapter in self.adapters.items():\n            if url.lower().startswith(prefix.lower()):\n                return adapter\n\n        # Nothing matches :-/\n        raise InvalidSchema(f\"No connection adapters were found for {url!r}\")\n\n    def close(self):\n        \"\"\"Closes all adapters and as such the session\"\"\"\n        for v in self.adapters.values():\n            v.close()\n\n    def mount(self, prefix, adapter):\n        \"\"\"Registers a connection adapter to a prefix.\n\n        Adapters are sorted in descending order by prefix length.\n        \"\"\"\n        self.adapters[prefix] = adapter\n        keys_to_move = [k for k in self.adapters if len(k) < len(prefix)]\n\n        for key in keys_to_move:\n            self.adapters[key] = self.adapters.pop(key)\n\n    def __getstate__(self):\n        state = {attr: getattr(self, attr, None) for attr in self.__attrs__}\n        return state\n\n    def "}, {"start_line": 29000, "end_line": 30503, "belongs_to": {"file_name": "sessions.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "nnection adapter for the given URL.\n\n        :rtype: requests.adapters.BaseAdapter\n        \"\"\"\n        for prefix, adapter in self.adapters.items():\n            if url.lower().startswith(prefix.lower()):\n                return adapter\n\n        # Nothing matches :-/\n        raise InvalidSchema(f\"No connection adapters were found for {url!r}\")\n\n    def close(self):\n        \"\"\"Closes all adapters and as such the session\"\"\"\n        for v in self.adapters.values():\n            v.close()\n\n    def mount(self, prefix, adapter):\n        \"\"\"Registers a connection adapter to a prefix.\n\n        Adapters are sorted in descending order by prefix length.\n        \"\"\"\n        self.adapters[prefix] = adapter\n        keys_to_move = [k for k in self.adapters if len(k) < len(prefix)]\n\n        for key in keys_to_move:\n            self.adapters[key] = self.adapters.pop(key)\n\n    def __getstate__(self):\n        state = {attr: getattr(self, attr, None) for attr in self.__attrs__}\n        return state\n\n    def __setstate__(self, state):\n        for attr, value in state.items():\n            setattr(self, attr, value)\n\n\ndef session():\n    \"\"\"\n    Returns a :class:`Session` for context-management.\n\n    .. deprecated:: 1.0.0\n\n        This method has been deprecated since version 1.0.0 and is only kept for\n        backwards compatibility. New code should use :class:`~requests.sessions.Session`\n        to create a session. This may be removed at a future date.\n\n    :rtype: Session\n    \"\"\"\n    return Session()\n"}, {"start_line": 0, "end_line": 2000, "belongs_to": {"file_name": "adapters.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "\"\"\"\nrequests.adapters\n~~~~~~~~~~~~~~~~~\n\nThis module contains the transport adapters that Requests uses to define\nand maintain connections.\n\"\"\"\n\nimport os.path\nimport socket  # noqa: F401\nimport typing\nimport warnings\n\nfrom urllib3.exceptions import ClosedPoolError, ConnectTimeoutError\nfrom urllib3.exceptions import HTTPError as _HTTPError\nfrom urllib3.exceptions import InvalidHeader as _InvalidHeader\nfrom urllib3.exceptions import (\n    LocationValueError,\n    MaxRetryError,\n    NewConnectionError,\n    ProtocolError,\n)\nfrom urllib3.exceptions import ProxyError as _ProxyError\nfrom urllib3.exceptions import ReadTimeoutError, ResponseError\nfrom urllib3.exceptions import SSLError as _SSLError\nfrom urllib3.poolmanager import PoolManager, proxy_from_url\nfrom urllib3.util import Timeout as TimeoutSauce\nfrom urllib3.util import parse_url\nfrom urllib3.util.retry import Retry\n\nfrom .auth import _basic_auth_str\nfrom .compat import basestring, urlparse\nfrom .cookies import extract_cookies_to_jar\nfrom .exceptions import (\n    ConnectionError,\n    ConnectTimeout,\n    InvalidHeader,\n    InvalidProxyURL,\n    InvalidSchema,\n    InvalidURL,\n    ProxyError,\n    ReadTimeout,\n    RetryError,\n    SSLError,\n)\nfrom .models import Response\nfrom .structures import CaseInsensitiveDict\nfrom .utils import (\n    DEFAULT_CA_BUNDLE_PATH,\n    extract_zipped_paths,\n    get_auth_from_url,\n    get_encoding_from_headers,\n    prepend_scheme_if_needed,\n    select_proxy,\n    urldefragauth,\n)\n\ntry:\n    from urllib3.contrib.socks import SOCKSProxyManager\nexcept ImportError:\n\n    def SOCKSProxyManager(*args, **kwargs):\n        raise InvalidSchema(\"Missing dependencies for SOCKS support.\")\n\n\nif typing.TYPE_CHECKING:\n    from .models import PreparedRequest\n\n\nDEFAULT_POOLBLOCK = False\nDEFAULT_POOLSIZE = 10\nDEFAULT_RETRIES = 0\nDEFAULT_POOL_TIMEOUT = None\n\n\ndef _urllib3_request_context(\n    request: \"PreparedRequest\",\n    verify: \"bool | str | None\",\n    client_cert: \"typing.Tuple[str, str] | str | None\",\n    po"}, {"start_line": 57000, "end_line": 59000, "belongs_to": {"file_name": "test_requests.py", "upper_path": "/data2/raymone/swebench-repos/requests/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": ".mount(\"http://git\", HTTPAdapter())\n        s.mount(\"http://github\", HTTPAdapter())\n        s.mount(\"http://github.com\", HTTPAdapter())\n        s.mount(\"http://github.com/about/\", HTTPAdapter())\n        order = [\n            \"http://github.com/about/\",\n            \"http://github.com\",\n            \"http://github\",\n            \"http://git\",\n            \"https://\",\n            \"http://\",\n        ]\n        assert order == list(s.adapters)\n        s.mount(\"http://gittip\", HTTPAdapter())\n        s.mount(\"http://gittip.com\", HTTPAdapter())\n        s.mount(\"http://gittip.com/about/\", HTTPAdapter())\n        order = [\n            \"http://github.com/about/\",\n            \"http://gittip.com/about/\",\n            \"http://github.com\",\n            \"http://gittip.com\",\n            \"http://github\",\n            \"http://gittip\",\n            \"http://git\",\n            \"https://\",\n            \"http://\",\n        ]\n        assert order == list(s.adapters)\n        s2 = requests.Session()\n        s2.adapters = {\"http://\": HTTPAdapter()}\n        s2.mount(\"https://\", HTTPAdapter())\n        assert \"http://\" in s2.adapters\n        assert \"https://\" in s2.adapters\n\n    def test_session_get_adapter_prefix_matching(self):\n        prefix = \"https://example.com\"\n        more_specific_prefix = prefix + \"/some/path\"\n\n        url_matching_only_prefix = prefix + \"/another/path\"\n        url_matching_more_specific_prefix = more_specific_prefix + \"/longer/path\"\n        url_not_matching_prefix = \"https://another.example.com/\"\n\n        s = requests.Session()\n        prefix_adapter = HTTPAdapter()\n        more_specific_prefix_adapter = HTTPAdapter()\n        s.mount(prefix, prefix_adapter)\n        s.mount(more_specific_prefix, more_specific_prefix_adapter)\n\n        assert s.get_adapter(url_matching_only_prefix) is prefix_adapter\n        assert (\n            s.get_adapter(url_matching_more_specific_prefix)\n            is more_specific_prefix_adapter\n        )\n        assert s.get_adapter(url_not_matching_prefix) n"}, {"start_line": 3000, "end_line": 5000, "belongs_to": {"file_name": "adapters.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "     \"host\": parsed_request_url.hostname,\n        \"port\": port,\n    }\n    return host_params, pool_kwargs\n\n\nclass BaseAdapter:\n    \"\"\"The Base Transport Adapter\"\"\"\n\n    def __init__(self):\n        super().__init__()\n\n    def send(\n        self, request, stream=False, timeout=None, verify=True, cert=None, proxies=None\n    ):\n        \"\"\"Sends PreparedRequest object. Returns Response object.\n\n        :param request: The :class:`PreparedRequest <PreparedRequest>` being sent.\n        :param stream: (optional) Whether to stream the request content.\n        :param timeout: (optional) How long to wait for the server to send\n            data before giving up, as a float, or a :ref:`(connect timeout,\n            read timeout) <timeouts>` tuple.\n        :type timeout: float or tuple\n        :param verify: (optional) Either a boolean, in which case it controls whether we verify\n            the server's TLS certificate, or a string, in which case it must be a path\n            to a CA bundle to use\n        :param cert: (optional) Any user-provided SSL certificate to be trusted.\n        :param proxies: (optional) The proxies dictionary to apply to the request.\n        \"\"\"\n        raise NotImplementedError\n\n    def close(self):\n        \"\"\"Cleans up adapter specific items.\"\"\"\n        raise NotImplementedError\n\n\nclass HTTPAdapter(BaseAdapter):\n    \"\"\"The built-in HTTP Adapter for urllib3.\n\n    Provides a general-case interface for Requests sessions to contact HTTP and\n    HTTPS urls by implementing the Transport Adapter interface. This class will\n    usually be created by the :class:`Session <Session>` class under the\n    covers.\n\n    :param pool_connections: The number of urllib3 connection pools to cache.\n    :param pool_maxsize: The maximum number of connections to save in the pool.\n    :param max_retries: The maximum number of retries each connection\n        should attempt. Note, this applies only to failed DNS lookups, socket\n        connections and connection timeouts, never to"}, {"start_line": 2000, "end_line": 4000, "belongs_to": {"file_name": "adapters.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "olmanager: \"PoolManager\",\n) -> \"(typing.Dict[str, typing.Any], typing.Dict[str, typing.Any])\":\n    host_params = {}\n    pool_kwargs = {}\n    parsed_request_url = urlparse(request.url)\n    scheme = parsed_request_url.scheme.lower()\n    port = parsed_request_url.port\n\n    cert_reqs = \"CERT_REQUIRED\"\n    if verify is False:\n        cert_reqs = \"CERT_NONE\"\n    elif isinstance(verify, str):\n        if not os.path.isdir(verify):\n            pool_kwargs[\"ca_certs\"] = verify\n        else:\n            pool_kwargs[\"ca_cert_dir\"] = verify\n    pool_kwargs[\"cert_reqs\"] = cert_reqs\n    if client_cert is not None:\n        if isinstance(client_cert, tuple) and len(client_cert) == 2:\n            pool_kwargs[\"cert_file\"] = client_cert[0]\n            pool_kwargs[\"key_file\"] = client_cert[1]\n        else:\n            # According to our docs, we allow users to specify just the client\n            # cert path\n            pool_kwargs[\"cert_file\"] = client_cert\n    host_params = {\n        \"scheme\": scheme,\n        \"host\": parsed_request_url.hostname,\n        \"port\": port,\n    }\n    return host_params, pool_kwargs\n\n\nclass BaseAdapter:\n    \"\"\"The Base Transport Adapter\"\"\"\n\n    def __init__(self):\n        super().__init__()\n\n    def send(\n        self, request, stream=False, timeout=None, verify=True, cert=None, proxies=None\n    ):\n        \"\"\"Sends PreparedRequest object. Returns Response object.\n\n        :param request: The :class:`PreparedRequest <PreparedRequest>` being sent.\n        :param stream: (optional) Whether to stream the request content.\n        :param timeout: (optional) How long to wait for the server to send\n            data before giving up, as a float, or a :ref:`(connect timeout,\n            read timeout) <timeouts>` tuple.\n        :type timeout: float or tuple\n        :param verify: (optional) Either a boolean, in which case it controls whether we verify\n            the server's TLS certificate, or a string, in which case it must be a path\n            to a CA bundle to use\n"}, {"start_line": 58000, "end_line": 60000, "belongs_to": {"file_name": "test_requests.py", "upper_path": "/data2/raymone/swebench-repos/requests/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "http://\": HTTPAdapter()}\n        s2.mount(\"https://\", HTTPAdapter())\n        assert \"http://\" in s2.adapters\n        assert \"https://\" in s2.adapters\n\n    def test_session_get_adapter_prefix_matching(self):\n        prefix = \"https://example.com\"\n        more_specific_prefix = prefix + \"/some/path\"\n\n        url_matching_only_prefix = prefix + \"/another/path\"\n        url_matching_more_specific_prefix = more_specific_prefix + \"/longer/path\"\n        url_not_matching_prefix = \"https://another.example.com/\"\n\n        s = requests.Session()\n        prefix_adapter = HTTPAdapter()\n        more_specific_prefix_adapter = HTTPAdapter()\n        s.mount(prefix, prefix_adapter)\n        s.mount(more_specific_prefix, more_specific_prefix_adapter)\n\n        assert s.get_adapter(url_matching_only_prefix) is prefix_adapter\n        assert (\n            s.get_adapter(url_matching_more_specific_prefix)\n            is more_specific_prefix_adapter\n        )\n        assert s.get_adapter(url_not_matching_prefix) not in (\n            prefix_adapter,\n            more_specific_prefix_adapter,\n        )\n\n    def test_session_get_adapter_prefix_matching_mixed_case(self):\n        mixed_case_prefix = \"hTtPs://eXamPle.CoM/MixEd_CAse_PREfix\"\n        url_matching_prefix = mixed_case_prefix + \"/full_url\"\n\n        s = requests.Session()\n        my_adapter = HTTPAdapter()\n        s.mount(mixed_case_prefix, my_adapter)\n\n        assert s.get_adapter(url_matching_prefix) is my_adapter\n\n    def test_session_get_adapter_prefix_matching_is_case_insensitive(self):\n        mixed_case_prefix = \"hTtPs://eXamPle.CoM/MixEd_CAse_PREfix\"\n        url_matching_prefix_with_different_case = (\n            \"HtTpS://exaMPLe.cOm/MiXeD_caSE_preFIX/another_url\"\n        )\n\n        s = requests.Session()\n        my_adapter = HTTPAdapter()\n        s.mount(mixed_case_prefix, my_adapter)\n\n        assert s.get_adapter(url_matching_prefix_with_different_case) is my_adapter\n\n    def test_session_get_adapter_prefix_with_trailing_slash(self"}, {"start_line": 4000, "end_line": 6000, "belongs_to": {"file_name": "adapters.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "        :param cert: (optional) Any user-provided SSL certificate to be trusted.\n        :param proxies: (optional) The proxies dictionary to apply to the request.\n        \"\"\"\n        raise NotImplementedError\n\n    def close(self):\n        \"\"\"Cleans up adapter specific items.\"\"\"\n        raise NotImplementedError\n\n\nclass HTTPAdapter(BaseAdapter):\n    \"\"\"The built-in HTTP Adapter for urllib3.\n\n    Provides a general-case interface for Requests sessions to contact HTTP and\n    HTTPS urls by implementing the Transport Adapter interface. This class will\n    usually be created by the :class:`Session <Session>` class under the\n    covers.\n\n    :param pool_connections: The number of urllib3 connection pools to cache.\n    :param pool_maxsize: The maximum number of connections to save in the pool.\n    :param max_retries: The maximum number of retries each connection\n        should attempt. Note, this applies only to failed DNS lookups, socket\n        connections and connection timeouts, never to requests where data has\n        made it to the server. By default, Requests does not retry failed\n        connections. If you need granular control over the conditions under\n        which we retry a request, import urllib3's ``Retry`` class and pass\n        that instead.\n    :param pool_block: Whether the connection pool should block for connections.\n\n    Usage::\n\n      >>> import requests\n      >>> s = requests.Session()\n      >>> a = requests.adapters.HTTPAdapter(max_retries=3)\n      >>> s.mount('http://', a)\n    \"\"\"\n\n    __attrs__ = [\n        \"max_retries\",\n        \"config\",\n        \"_pool_connections\",\n        \"_pool_maxsize\",\n        \"_pool_block\",\n    ]\n\n    def __init__(\n        self,\n        pool_connections=DEFAULT_POOLSIZE,\n        pool_maxsize=DEFAULT_POOLSIZE,\n        max_retries=DEFAULT_RETRIES,\n        pool_block=DEFAULT_POOLBLOCK,\n    ):\n        if max_retries == DEFAULT_RETRIES:\n            self.max_retries = Retry(0, read=False)\n        else:\n            self.max_retr"}, {"start_line": 5000, "end_line": 7000, "belongs_to": {"file_name": "adapters.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": " requests where data has\n        made it to the server. By default, Requests does not retry failed\n        connections. If you need granular control over the conditions under\n        which we retry a request, import urllib3's ``Retry`` class and pass\n        that instead.\n    :param pool_block: Whether the connection pool should block for connections.\n\n    Usage::\n\n      >>> import requests\n      >>> s = requests.Session()\n      >>> a = requests.adapters.HTTPAdapter(max_retries=3)\n      >>> s.mount('http://', a)\n    \"\"\"\n\n    __attrs__ = [\n        \"max_retries\",\n        \"config\",\n        \"_pool_connections\",\n        \"_pool_maxsize\",\n        \"_pool_block\",\n    ]\n\n    def __init__(\n        self,\n        pool_connections=DEFAULT_POOLSIZE,\n        pool_maxsize=DEFAULT_POOLSIZE,\n        max_retries=DEFAULT_RETRIES,\n        pool_block=DEFAULT_POOLBLOCK,\n    ):\n        if max_retries == DEFAULT_RETRIES:\n            self.max_retries = Retry(0, read=False)\n        else:\n            self.max_retries = Retry.from_int(max_retries)\n        self.config = {}\n        self.proxy_manager = {}\n\n        super().__init__()\n\n        self._pool_connections = pool_connections\n        self._pool_maxsize = pool_maxsize\n        self._pool_block = pool_block\n\n        self.init_poolmanager(pool_connections, pool_maxsize, block=pool_block)\n\n    def __getstate__(self):\n        return {attr: getattr(self, attr, None) for attr in self.__attrs__}\n\n    def __setstate__(self, state):\n        # Can't handle by adding 'proxy_manager' to self.__attrs__ because\n        # self.poolmanager uses a lambda function, which isn't pickleable.\n        self.proxy_manager = {}\n        self.config = {}\n\n        for attr, value in state.items():\n            setattr(self, attr, value)\n\n        self.init_poolmanager(\n            self._pool_connections, self._pool_maxsize, block=self._pool_block\n        )\n\n    def init_poolmanager(\n        self, connections, maxsize, block=DEFAULT_POOLBLOCK, **pool_kwargs\n    ):\n        \""}, {"start_line": 21000, "end_line": 23000, "belongs_to": {"file_name": "adapters.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "ters.HTTPAdapter>`.\n\n        This should not be called from user code, and is only exposed for use\n        when subclassing the\n        :class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.\n\n        :param request: The :class:`PreparedRequest <PreparedRequest>` to add headers to.\n        :param kwargs: The keyword arguments from the call to send().\n        \"\"\"\n        pass\n\n    def proxy_headers(self, proxy):\n        \"\"\"Returns a dictionary of the headers to add to any request sent\n        through a proxy. This works with urllib3 magic to ensure that they are\n        correctly sent to the proxy, rather than in a tunnelled request if\n        CONNECT is being used.\n\n        This should not be called from user code, and is only exposed for use\n        when subclassing the\n        :class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.\n\n        :param proxy: The url of the proxy being used for this request.\n        :rtype: dict\n        \"\"\"\n        headers = {}\n        username, password = get_auth_from_url(proxy)\n\n        if username:\n            headers[\"Proxy-Authorization\"] = _basic_auth_str(username, password)\n\n        return headers\n\n    def send(\n        self, request, stream=False, timeout=None, verify=True, cert=None, proxies=None\n    ):\n        \"\"\"Sends PreparedRequest object. Returns Response object.\n\n        :param request: The :class:`PreparedRequest <PreparedRequest>` being sent.\n        :param stream: (optional) Whether to stream the request content.\n        :param timeout: (optional) How long to wait for the server to send\n            data before giving up, as a float, or a :ref:`(connect timeout,\n            read timeout) <timeouts>` tuple.\n        :type timeout: float or tuple or urllib3 Timeout object\n        :param verify: (optional) Either a boolean, in which case it controls whether\n            we verify the server's TLS certificate, or a string, in which case it\n            must be a path to a CA bundle to use\n        :param cert: (optional) Any user"}], "retrieved_count": 10, "cost_time": 4.719018220901489}
{"question": "Why does Requests' session management system optimize memory usage and performance in high-concurrency scenarios?", "answer": null, "relative_code_list": null, "ground_truth": "Requests' session management system optimizes memory usage and performance in high-concurrency scenarios through several key mechanisms: 1) Connection pooling - Reuses connections across multiple requests, reducing memory overhead from connection establishment and maintenance; 2) Shared state - Sessions share common resources (cookies, headers, authentication) across requests, avoiding duplication; 3) Resource lifecycle management - Proper connection cleanup and resource release prevents memory leaks in long-running applications; 4) Thread-safe pools - Connection pools are thread-safe, enabling efficient concurrent access without additional synchronization overhead; 5) Configurable limits - Pool sizes and connection limits can be tuned to match application requirements and resource constraints; 6) Lazy initialization - Resources are created on-demand rather than pre-allocated, reducing initial memory footprint; 7) Efficient data structures - Uses optimized data structures for headers, cookies, and other session state; 8) Connection health management - Automatically removes stale or failed connections from pools, maintaining optimal performance; 9) Memory-efficient streaming - Supports streaming responses to avoid loading large responses into memory; 10) Context management - Proper cleanup through context managers ensures resources are released even in error scenarios.", "score": null, "retrieved_content": [{"start_line": 13000, "end_line": 15000, "belongs_to": {"file_name": "sessions.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "POST is responded to with a 301, turn it into a GET.\n        # This bizarre behaviour is explained in Issue 1704.\n        if response.status_code == codes.moved and method == \"POST\":\n            method = \"GET\"\n\n        prepared_request.method = method\n\n\nclass Session(SessionRedirectMixin):\n    \"\"\"A Requests session.\n\n    Provides cookie persistence, connection-pooling, and configuration.\n\n    Basic Usage::\n\n      >>> import requests\n      >>> s = requests.Session()\n      >>> s.get('https://httpbin.org/get')\n      <Response [200]>\n\n    Or as a context manager::\n\n      >>> with requests.Session() as s:\n      ...     s.get('https://httpbin.org/get')\n      <Response [200]>\n    \"\"\"\n\n    __attrs__ = [\n        \"headers\",\n        \"cookies\",\n        \"auth\",\n        \"proxies\",\n        \"hooks\",\n        \"params\",\n        \"verify\",\n        \"cert\",\n        \"adapters\",\n        \"stream\",\n        \"trust_env\",\n        \"max_redirects\",\n    ]\n\n    def __init__(self):\n        #: A case-insensitive dictionary of headers to be sent on each\n        #: :class:`Request <Request>` sent from this\n        #: :class:`Session <Session>`.\n        self.headers = default_headers()\n\n        #: Default Authentication tuple or object to attach to\n        #: :class:`Request <Request>`.\n        self.auth = None\n\n        #: Dictionary mapping protocol or protocol and host to the URL of the proxy\n        #: (e.g. {'http': 'foo.bar:3128', 'http://host.name': 'foo.bar:4012'}) to\n        #: be used on each :class:`Request <Request>`.\n        self.proxies = {}\n\n        #: Event-handling hooks.\n        self.hooks = default_hooks()\n\n        #: Dictionary of querystring data to attach to each\n        #: :class:`Request <Request>`. The dictionary values may be lists for\n        #: representing multivalued query parameters.\n        self.params = {}\n\n        #: Stream response content default.\n        self.stream = False\n\n        #: SSL Verification default.\n        #: Defaults to `True`, requiring requests to verif"}, {"start_line": 0, "end_line": 2000, "belongs_to": {"file_name": "sessions.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "\"\"\"\nrequests.sessions\n~~~~~~~~~~~~~~~~~\n\nThis module provides a Session object to manage and persist settings across\nrequests (cookies, auth, proxies).\n\"\"\"\nimport os\nimport sys\nimport time\nfrom collections import OrderedDict\nfrom datetime import timedelta\n\nfrom ._internal_utils import to_native_string\nfrom .adapters import HTTPAdapter\nfrom .auth import _basic_auth_str\nfrom .compat import Mapping, cookielib, urljoin, urlparse\nfrom .cookies import (\n    RequestsCookieJar,\n    cookiejar_from_dict,\n    extract_cookies_to_jar,\n    merge_cookies,\n)\nfrom .exceptions import (\n    ChunkedEncodingError,\n    ContentDecodingError,\n    InvalidSchema,\n    TooManyRedirects,\n)\nfrom .hooks import default_hooks, dispatch_hook\n\n# formerly defined here, reexposed here for backward compatibility\nfrom .models import (  # noqa: F401\n    DEFAULT_REDIRECT_LIMIT,\n    REDIRECT_STATI,\n    PreparedRequest,\n    Request,\n)\nfrom .status_codes import codes\nfrom .structures import CaseInsensitiveDict\nfrom .utils import (  # noqa: F401\n    DEFAULT_PORTS,\n    default_headers,\n    get_auth_from_url,\n    get_environ_proxies,\n    get_netrc_auth,\n    requote_uri,\n    resolve_proxies,\n    rewind_body,\n    should_bypass_proxies,\n    to_key_val_list,\n)\n\n# Preferred clock, based on which one is more accurate on a given system.\nif sys.platform == \"win32\":\n    preferred_clock = time.perf_counter\nelse:\n    preferred_clock = time.time\n\n\ndef merge_setting(request_setting, session_setting, dict_class=OrderedDict):\n    \"\"\"Determines appropriate setting for a given request, taking into account\n    the explicit setting on that request, and the setting in the session. If a\n    setting is a dictionary, they will be merged together using `dict_class`\n    \"\"\"\n\n    if session_setting is None:\n        return request_setting\n\n    if request_setting is None:\n        return session_setting\n\n    # Bypass if not a dictionary (e.g. verify)\n    if not (\n        isinstance(session_setting, Mapping) and isinstance(request_setting, M"}, {"start_line": 15000, "end_line": 17000, "belongs_to": {"file_name": "sessions.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "y the TLS certificate at the\n        #: remote end.\n        #: If verify is set to `False`, requests will accept any TLS certificate\n        #: presented by the server, and will ignore hostname mismatches and/or\n        #: expired certificates, which will make your application vulnerable to\n        #: man-in-the-middle (MitM) attacks.\n        #: Only set this to `False` for testing.\n        self.verify = True\n\n        #: SSL client certificate default, if String, path to ssl client\n        #: cert file (.pem). If Tuple, ('cert', 'key') pair.\n        self.cert = None\n\n        #: Maximum number of redirects allowed. If the request exceeds this\n        #: limit, a :class:`TooManyRedirects` exception is raised.\n        #: This defaults to requests.models.DEFAULT_REDIRECT_LIMIT, which is\n        #: 30.\n        self.max_redirects = DEFAULT_REDIRECT_LIMIT\n\n        #: Trust environment settings for proxy configuration, default\n        #: authentication and similar.\n        self.trust_env = True\n\n        #: A CookieJar containing all currently outstanding cookies set on this\n        #: session. By default it is a\n        #: :class:`RequestsCookieJar <requests.cookies.RequestsCookieJar>`, but\n        #: may be any other ``cookielib.CookieJar`` compatible object.\n        self.cookies = cookiejar_from_dict({})\n\n        # Default connection adapters.\n        self.adapters = OrderedDict()\n        self.mount(\"https://\", HTTPAdapter())\n        self.mount(\"http://\", HTTPAdapter())\n\n    def __enter__(self):\n        return self\n\n    def __exit__(self, *args):\n        self.close()\n\n    def prepare_request(self, request):\n        \"\"\"Constructs a :class:`PreparedRequest <PreparedRequest>` for\n        transmission and returns it. The :class:`PreparedRequest` has settings\n        merged from the :class:`Request <Request>` instance and those of the\n        :class:`Session`.\n\n        :param request: :class:`Request` instance to prepare with this\n            session's settings.\n        :rtype"}, {"start_line": 12000, "end_line": 14000, "belongs_to": {"file_name": "sessions.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "          username, password = None, None\n\n        # urllib3 handles proxy authorization for us in the standard adapter.\n        # Avoid appending this to TLS tunneled requests where it may be leaked.\n        if not scheme.startswith(\"https\") and username and password:\n            headers[\"Proxy-Authorization\"] = _basic_auth_str(username, password)\n\n        return new_proxies\n\n    def rebuild_method(self, prepared_request, response):\n        \"\"\"When being redirected we may want to change the method of the request\n        based on certain specs or browser behavior.\n        \"\"\"\n        method = prepared_request.method\n\n        # https://tools.ietf.org/html/rfc7231#section-6.4.4\n        if response.status_code == codes.see_other and method != \"HEAD\":\n            method = \"GET\"\n\n        # Do what the browsers do, despite standards...\n        # First, turn 302s into GETs.\n        if response.status_code == codes.found and method != \"HEAD\":\n            method = \"GET\"\n\n        # Second, if a POST is responded to with a 301, turn it into a GET.\n        # This bizarre behaviour is explained in Issue 1704.\n        if response.status_code == codes.moved and method == \"POST\":\n            method = \"GET\"\n\n        prepared_request.method = method\n\n\nclass Session(SessionRedirectMixin):\n    \"\"\"A Requests session.\n\n    Provides cookie persistence, connection-pooling, and configuration.\n\n    Basic Usage::\n\n      >>> import requests\n      >>> s = requests.Session()\n      >>> s.get('https://httpbin.org/get')\n      <Response [200]>\n\n    Or as a context manager::\n\n      >>> with requests.Session() as s:\n      ...     s.get('https://httpbin.org/get')\n      <Response [200]>\n    \"\"\"\n\n    __attrs__ = [\n        \"headers\",\n        \"cookies\",\n        \"auth\",\n        \"proxies\",\n        \"hooks\",\n        \"params\",\n        \"verify\",\n        \"cert\",\n        \"adapters\",\n        \"stream\",\n        \"trust_env\",\n        \"max_redirects\",\n    ]\n\n    def __init__(self):\n        #: A case-insensitive dictiona"}, {"start_line": 14000, "end_line": 16000, "belongs_to": {"file_name": "sessions.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "ry of headers to be sent on each\n        #: :class:`Request <Request>` sent from this\n        #: :class:`Session <Session>`.\n        self.headers = default_headers()\n\n        #: Default Authentication tuple or object to attach to\n        #: :class:`Request <Request>`.\n        self.auth = None\n\n        #: Dictionary mapping protocol or protocol and host to the URL of the proxy\n        #: (e.g. {'http': 'foo.bar:3128', 'http://host.name': 'foo.bar:4012'}) to\n        #: be used on each :class:`Request <Request>`.\n        self.proxies = {}\n\n        #: Event-handling hooks.\n        self.hooks = default_hooks()\n\n        #: Dictionary of querystring data to attach to each\n        #: :class:`Request <Request>`. The dictionary values may be lists for\n        #: representing multivalued query parameters.\n        self.params = {}\n\n        #: Stream response content default.\n        self.stream = False\n\n        #: SSL Verification default.\n        #: Defaults to `True`, requiring requests to verify the TLS certificate at the\n        #: remote end.\n        #: If verify is set to `False`, requests will accept any TLS certificate\n        #: presented by the server, and will ignore hostname mismatches and/or\n        #: expired certificates, which will make your application vulnerable to\n        #: man-in-the-middle (MitM) attacks.\n        #: Only set this to `False` for testing.\n        self.verify = True\n\n        #: SSL client certificate default, if String, path to ssl client\n        #: cert file (.pem). If Tuple, ('cert', 'key') pair.\n        self.cert = None\n\n        #: Maximum number of redirects allowed. If the request exceeds this\n        #: limit, a :class:`TooManyRedirects` exception is raised.\n        #: This defaults to requests.models.DEFAULT_REDIRECT_LIMIT, which is\n        #: 30.\n        self.max_redirects = DEFAULT_REDIRECT_LIMIT\n\n        #: Trust environment settings for proxy configuration, default\n        #: authentication and similar.\n        self.trust_env = Tru"}, {"start_line": 5000, "end_line": 7000, "belongs_to": {"file_name": "adapters.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": " requests where data has\n        made it to the server. By default, Requests does not retry failed\n        connections. If you need granular control over the conditions under\n        which we retry a request, import urllib3's ``Retry`` class and pass\n        that instead.\n    :param pool_block: Whether the connection pool should block for connections.\n\n    Usage::\n\n      >>> import requests\n      >>> s = requests.Session()\n      >>> a = requests.adapters.HTTPAdapter(max_retries=3)\n      >>> s.mount('http://', a)\n    \"\"\"\n\n    __attrs__ = [\n        \"max_retries\",\n        \"config\",\n        \"_pool_connections\",\n        \"_pool_maxsize\",\n        \"_pool_block\",\n    ]\n\n    def __init__(\n        self,\n        pool_connections=DEFAULT_POOLSIZE,\n        pool_maxsize=DEFAULT_POOLSIZE,\n        max_retries=DEFAULT_RETRIES,\n        pool_block=DEFAULT_POOLBLOCK,\n    ):\n        if max_retries == DEFAULT_RETRIES:\n            self.max_retries = Retry(0, read=False)\n        else:\n            self.max_retries = Retry.from_int(max_retries)\n        self.config = {}\n        self.proxy_manager = {}\n\n        super().__init__()\n\n        self._pool_connections = pool_connections\n        self._pool_maxsize = pool_maxsize\n        self._pool_block = pool_block\n\n        self.init_poolmanager(pool_connections, pool_maxsize, block=pool_block)\n\n    def __getstate__(self):\n        return {attr: getattr(self, attr, None) for attr in self.__attrs__}\n\n    def __setstate__(self, state):\n        # Can't handle by adding 'proxy_manager' to self.__attrs__ because\n        # self.poolmanager uses a lambda function, which isn't pickleable.\n        self.proxy_manager = {}\n        self.config = {}\n\n        for attr, value in state.items():\n            setattr(self, attr, value)\n\n        self.init_poolmanager(\n            self._pool_connections, self._pool_maxsize, block=self._pool_block\n        )\n\n    def init_poolmanager(\n        self, connections, maxsize, block=DEFAULT_POOLBLOCK, **pool_kwargs\n    ):\n        \""}, {"start_line": 74000, "end_line": 76000, "belongs_to": {"file_name": "test_requests.py", "upper_path": "/data2/raymone/swebench-repos/requests/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "name, password)\n        assert isinstance(s, builtin_str)\n        assert s == auth_str\n\n    def test_requests_history_is_saved(self, httpbin):\n        r = requests.get(httpbin(\"redirect/5\"))\n        total = r.history[-1].history\n        i = 0\n        for item in r.history:\n            assert item.history == total[0:i]\n            i += 1\n\n    def test_json_param_post_content_type_works(self, httpbin):\n        r = requests.post(httpbin(\"post\"), json={\"life\": 42})\n        assert r.status_code == 200\n        assert \"application/json\" in r.request.headers[\"Content-Type\"]\n        assert {\"life\": 42} == r.json()[\"json\"]\n\n    def test_json_param_post_should_not_override_data_param(self, httpbin):\n        r = requests.Request(\n            method=\"POST\",\n            url=httpbin(\"post\"),\n            data={\"stuff\": \"elixr\"},\n            json={\"music\": \"flute\"},\n        )\n        prep = r.prepare()\n        assert \"stuff=elixr\" == prep.body\n\n    def test_response_iter_lines(self, httpbin):\n        r = requests.get(httpbin(\"stream/4\"), stream=True)\n        assert r.status_code == 200\n\n        it = r.iter_lines()\n        next(it)\n        assert len(list(it)) == 3\n\n    def test_response_context_manager(self, httpbin):\n        with requests.get(httpbin(\"stream/4\"), stream=True) as response:\n            assert isinstance(response, requests.Response)\n\n        assert response.raw.closed\n\n    def test_unconsumed_session_response_closes_connection(self, httpbin):\n        s = requests.session()\n\n        with contextlib.closing(s.get(httpbin(\"stream/4\"), stream=True)) as response:\n            pass\n\n        assert response._content_consumed is False\n        assert response.raw.closed\n\n    @pytest.mark.xfail\n    def test_response_iter_lines_reentrant(self, httpbin):\n        \"\"\"Response.iter_lines() is not reentrant safe\"\"\"\n        r = requests.get(httpbin(\"stream/4\"), stream=True)\n        assert r.status_code == 200\n\n        next(r.iter_lines())\n        assert len(list(r.iter_lines())) == 3\n\n"}, {"start_line": 43000, "end_line": 45000, "belongs_to": {"file_name": "test_requests.py", "upper_path": "/data2/raymone/swebench-repos/requests/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "ook})\n        prep = req.prepare()\n\n        s = requests.Session()\n        s.proxies = getproxies()\n        resp = s.send(prep)\n\n        assert hasattr(resp, \"hook_working\")\n\n    def test_prepared_from_session(self, httpbin):\n        class DummyAuth(requests.auth.AuthBase):\n            def __call__(self, r):\n                r.headers[\"Dummy-Auth-Test\"] = \"dummy-auth-test-ok\"\n                return r\n\n        req = requests.Request(\"GET\", httpbin(\"headers\"))\n        assert not req.auth\n\n        s = requests.Session()\n        s.auth = DummyAuth()\n\n        prep = s.prepare_request(req)\n        resp = s.send(prep)\n\n        assert resp.json()[\"headers\"][\"Dummy-Auth-Test\"] == \"dummy-auth-test-ok\"\n\n    def test_prepare_request_with_bytestring_url(self):\n        req = requests.Request(\"GET\", b\"https://httpbin.org/\")\n        s = requests.Session()\n        prep = s.prepare_request(req)\n        assert prep.url == \"https://httpbin.org/\"\n\n    def test_request_with_bytestring_host(self, httpbin):\n        s = requests.Session()\n        resp = s.request(\n            \"GET\",\n            httpbin(\"cookies/set?cookie=value\"),\n            allow_redirects=False,\n            headers={\"Host\": b\"httpbin.org\"},\n        )\n        assert resp.cookies.get(\"cookie\") == \"value\"\n\n    def test_links(self):\n        r = requests.Response()\n        r.headers = {\n            \"cache-control\": \"public, max-age=60, s-maxage=60\",\n            \"connection\": \"keep-alive\",\n            \"content-encoding\": \"gzip\",\n            \"content-type\": \"application/json; charset=utf-8\",\n            \"date\": \"Sat, 26 Jan 2013 16:47:56 GMT\",\n            \"etag\": '\"6ff6a73c0e446c1f61614769e3ceb778\"',\n            \"last-modified\": \"Sat, 26 Jan 2013 16:22:39 GMT\",\n            \"link\": (\n                \"<https://api.github.com/users/kennethreitz/repos?\"\n                'page=2&per_page=10>; rel=\"next\", <https://api.github.'\n                \"com/users/kennethreitz/repos?page=7&per_page=10>; \"\n                ' rel=\"last\"'\n           "}, {"start_line": 2000, "end_line": 4000, "belongs_to": {"file_name": "api.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": ".\n    :type allow_redirects: bool\n    :param proxies: (optional) Dictionary mapping protocol to the URL of the proxy.\n    :param verify: (optional) Either a boolean, in which case it controls whether we verify\n            the server's TLS certificate, or a string, in which case it must be a path\n            to a CA bundle to use. Defaults to ``True``.\n    :param stream: (optional) if ``False``, the response content will be immediately downloaded.\n    :param cert: (optional) if String, path to ssl client cert file (.pem). If Tuple, ('cert', 'key') pair.\n    :return: :class:`Response <Response>` object\n    :rtype: requests.Response\n\n    Usage::\n\n      >>> import requests\n      >>> req = requests.request('GET', 'https://httpbin.org/get')\n      >>> req\n      <Response [200]>\n    \"\"\"\n\n    # By using the 'with' statement we are sure the session is closed, thus we\n    # avoid leaving sockets open which can trigger a ResourceWarning in some\n    # cases, and look like a memory leak in others.\n    with sessions.Session() as session:\n        return session.request(method=method, url=url, **kwargs)\n\n\ndef get(url, params=None, **kwargs):\n    r\"\"\"Sends a GET request.\n\n    :param url: URL for the new :class:`Request` object.\n    :param params: (optional) Dictionary, list of tuples or bytes to send\n        in the query string for the :class:`Request`.\n    :param \\*\\*kwargs: Optional arguments that ``request`` takes.\n    :return: :class:`Response <Response>` object\n    :rtype: requests.Response\n    \"\"\"\n\n    return request(\"get\", url, params=params, **kwargs)\n\n\ndef options(url, **kwargs):\n    r\"\"\"Sends an OPTIONS request.\n\n    :param url: URL for the new :class:`Request` object.\n    :param \\*\\*kwargs: Optional arguments that ``request`` takes.\n    :return: :class:`Response <Response>` object\n    :rtype: requests.Response\n    \"\"\"\n\n    return request(\"options\", url, **kwargs)\n\n\ndef head(url, **kwargs):\n    r\"\"\"Sends a HEAD request.\n\n    :param url: URL for the new :class:`Request` obje"}, {"start_line": 8000, "end_line": 10000, "belongs_to": {"file_name": "sessions.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "     # https://github.com/psf/requests/issues/3490\n                purged_headers = (\"Content-Length\", \"Content-Type\", \"Transfer-Encoding\")\n                for header in purged_headers:\n                    prepared_request.headers.pop(header, None)\n                prepared_request.body = None\n\n            headers = prepared_request.headers\n            headers.pop(\"Cookie\", None)\n\n            # Extract any cookies sent on the response to the cookiejar\n            # in the new request. Because we've mutated our copied prepared\n            # request, use the old one that we haven't yet touched.\n            extract_cookies_to_jar(prepared_request._cookies, req, resp.raw)\n            merge_cookies(prepared_request._cookies, self.cookies)\n            prepared_request.prepare_cookies(prepared_request._cookies)\n\n            # Rebuild auth and proxy information.\n            proxies = self.rebuild_proxies(prepared_request, proxies)\n            self.rebuild_auth(prepared_request, resp)\n\n            # A failed tell() sets `_body_position` to `object()`. This non-None\n            # value ensures `rewindable` will be True, allowing us to raise an\n            # UnrewindableBodyError, instead of hanging the connection.\n            rewindable = prepared_request._body_position is not None and (\n                \"Content-Length\" in headers or \"Transfer-Encoding\" in headers\n            )\n\n            # Attempt to rewind consumed file-like object.\n            if rewindable:\n                rewind_body(prepared_request)\n\n            # Override the original request.\n            req = prepared_request\n\n            if yield_requests:\n                yield req\n            else:\n                resp = self.send(\n                    req,\n                    stream=stream,\n                    timeout=timeout,\n                    verify=verify,\n                    cert=cert,\n                    proxies=proxies,\n                    allow_redirects=False,\n                    **adapter_kwargs,\n     "}], "retrieved_count": 10, "cost_time": 4.783571481704712}
{"question": "Where in the Requests codebase does the HTTP request flow begin from the Session object through the adapter layer to the underlying transport?", "answer": null, "relative_code_list": null, "ground_truth": "The HTTP request flow begins in src/requests/sessions.py with Session.request() method, which creates a Request object and calls Session.prepare_request() to create a PreparedRequest. The flow then moves to Session.send() which selects the appropriate adapter based on URL scheme and calls adapter.send(). The adapter layer is implemented in src/requests/adapters.py where HTTPAdapter.send() handles the actual transport through urllib3's PoolManager. The flow proceeds through adapter.build_response() to create a Response object, and then back through Session.resolve_redirects() for redirect handling. The complete flow is: Session.request()  Session.prepare_request()  Session.send()  HTTPAdapter.send()  urllib3.PoolManager.urlopen()  adapter.build_response()  Session.resolve_redirects()  Response object returned to user.", "score": null, "retrieved_content": [{"start_line": 13000, "end_line": 15000, "belongs_to": {"file_name": "sessions.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "POST is responded to with a 301, turn it into a GET.\n        # This bizarre behaviour is explained in Issue 1704.\n        if response.status_code == codes.moved and method == \"POST\":\n            method = \"GET\"\n\n        prepared_request.method = method\n\n\nclass Session(SessionRedirectMixin):\n    \"\"\"A Requests session.\n\n    Provides cookie persistence, connection-pooling, and configuration.\n\n    Basic Usage::\n\n      >>> import requests\n      >>> s = requests.Session()\n      >>> s.get('https://httpbin.org/get')\n      <Response [200]>\n\n    Or as a context manager::\n\n      >>> with requests.Session() as s:\n      ...     s.get('https://httpbin.org/get')\n      <Response [200]>\n    \"\"\"\n\n    __attrs__ = [\n        \"headers\",\n        \"cookies\",\n        \"auth\",\n        \"proxies\",\n        \"hooks\",\n        \"params\",\n        \"verify\",\n        \"cert\",\n        \"adapters\",\n        \"stream\",\n        \"trust_env\",\n        \"max_redirects\",\n    ]\n\n    def __init__(self):\n        #: A case-insensitive dictionary of headers to be sent on each\n        #: :class:`Request <Request>` sent from this\n        #: :class:`Session <Session>`.\n        self.headers = default_headers()\n\n        #: Default Authentication tuple or object to attach to\n        #: :class:`Request <Request>`.\n        self.auth = None\n\n        #: Dictionary mapping protocol or protocol and host to the URL of the proxy\n        #: (e.g. {'http': 'foo.bar:3128', 'http://host.name': 'foo.bar:4012'}) to\n        #: be used on each :class:`Request <Request>`.\n        self.proxies = {}\n\n        #: Event-handling hooks.\n        self.hooks = default_hooks()\n\n        #: Dictionary of querystring data to attach to each\n        #: :class:`Request <Request>`. The dictionary values may be lists for\n        #: representing multivalued query parameters.\n        self.params = {}\n\n        #: Stream response content default.\n        self.stream = False\n\n        #: SSL Verification default.\n        #: Defaults to `True`, requiring requests to verif"}, {"start_line": 3000, "end_line": 5000, "belongs_to": {"file_name": "adapters.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "     \"host\": parsed_request_url.hostname,\n        \"port\": port,\n    }\n    return host_params, pool_kwargs\n\n\nclass BaseAdapter:\n    \"\"\"The Base Transport Adapter\"\"\"\n\n    def __init__(self):\n        super().__init__()\n\n    def send(\n        self, request, stream=False, timeout=None, verify=True, cert=None, proxies=None\n    ):\n        \"\"\"Sends PreparedRequest object. Returns Response object.\n\n        :param request: The :class:`PreparedRequest <PreparedRequest>` being sent.\n        :param stream: (optional) Whether to stream the request content.\n        :param timeout: (optional) How long to wait for the server to send\n            data before giving up, as a float, or a :ref:`(connect timeout,\n            read timeout) <timeouts>` tuple.\n        :type timeout: float or tuple\n        :param verify: (optional) Either a boolean, in which case it controls whether we verify\n            the server's TLS certificate, or a string, in which case it must be a path\n            to a CA bundle to use\n        :param cert: (optional) Any user-provided SSL certificate to be trusted.\n        :param proxies: (optional) The proxies dictionary to apply to the request.\n        \"\"\"\n        raise NotImplementedError\n\n    def close(self):\n        \"\"\"Cleans up adapter specific items.\"\"\"\n        raise NotImplementedError\n\n\nclass HTTPAdapter(BaseAdapter):\n    \"\"\"The built-in HTTP Adapter for urllib3.\n\n    Provides a general-case interface for Requests sessions to contact HTTP and\n    HTTPS urls by implementing the Transport Adapter interface. This class will\n    usually be created by the :class:`Session <Session>` class under the\n    covers.\n\n    :param pool_connections: The number of urllib3 connection pools to cache.\n    :param pool_maxsize: The maximum number of connections to save in the pool.\n    :param max_retries: The maximum number of retries each connection\n        should attempt. Note, this applies only to failed DNS lookups, socket\n        connections and connection timeouts, never to"}, {"start_line": 21000, "end_line": 23000, "belongs_to": {"file_name": "adapters.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "ters.HTTPAdapter>`.\n\n        This should not be called from user code, and is only exposed for use\n        when subclassing the\n        :class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.\n\n        :param request: The :class:`PreparedRequest <PreparedRequest>` to add headers to.\n        :param kwargs: The keyword arguments from the call to send().\n        \"\"\"\n        pass\n\n    def proxy_headers(self, proxy):\n        \"\"\"Returns a dictionary of the headers to add to any request sent\n        through a proxy. This works with urllib3 magic to ensure that they are\n        correctly sent to the proxy, rather than in a tunnelled request if\n        CONNECT is being used.\n\n        This should not be called from user code, and is only exposed for use\n        when subclassing the\n        :class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.\n\n        :param proxy: The url of the proxy being used for this request.\n        :rtype: dict\n        \"\"\"\n        headers = {}\n        username, password = get_auth_from_url(proxy)\n\n        if username:\n            headers[\"Proxy-Authorization\"] = _basic_auth_str(username, password)\n\n        return headers\n\n    def send(\n        self, request, stream=False, timeout=None, verify=True, cert=None, proxies=None\n    ):\n        \"\"\"Sends PreparedRequest object. Returns Response object.\n\n        :param request: The :class:`PreparedRequest <PreparedRequest>` being sent.\n        :param stream: (optional) Whether to stream the request content.\n        :param timeout: (optional) How long to wait for the server to send\n            data before giving up, as a float, or a :ref:`(connect timeout,\n            read timeout) <timeouts>` tuple.\n        :type timeout: float or tuple or urllib3 Timeout object\n        :param verify: (optional) Either a boolean, in which case it controls whether\n            we verify the server's TLS certificate, or a string, in which case it\n            must be a path to a CA bundle to use\n        :param cert: (optional) Any user"}, {"start_line": 29000, "end_line": 30503, "belongs_to": {"file_name": "sessions.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "nnection adapter for the given URL.\n\n        :rtype: requests.adapters.BaseAdapter\n        \"\"\"\n        for prefix, adapter in self.adapters.items():\n            if url.lower().startswith(prefix.lower()):\n                return adapter\n\n        # Nothing matches :-/\n        raise InvalidSchema(f\"No connection adapters were found for {url!r}\")\n\n    def close(self):\n        \"\"\"Closes all adapters and as such the session\"\"\"\n        for v in self.adapters.values():\n            v.close()\n\n    def mount(self, prefix, adapter):\n        \"\"\"Registers a connection adapter to a prefix.\n\n        Adapters are sorted in descending order by prefix length.\n        \"\"\"\n        self.adapters[prefix] = adapter\n        keys_to_move = [k for k in self.adapters if len(k) < len(prefix)]\n\n        for key in keys_to_move:\n            self.adapters[key] = self.adapters.pop(key)\n\n    def __getstate__(self):\n        state = {attr: getattr(self, attr, None) for attr in self.__attrs__}\n        return state\n\n    def __setstate__(self, state):\n        for attr, value in state.items():\n            setattr(self, attr, value)\n\n\ndef session():\n    \"\"\"\n    Returns a :class:`Session` for context-management.\n\n    .. deprecated:: 1.0.0\n\n        This method has been deprecated since version 1.0.0 and is only kept for\n        backwards compatibility. New code should use :class:`~requests.sessions.Session`\n        to create a session. This may be removed at a future date.\n\n    :rtype: Session\n    \"\"\"\n    return Session()\n"}, {"start_line": 58000, "end_line": 60000, "belongs_to": {"file_name": "test_requests.py", "upper_path": "/data2/raymone/swebench-repos/requests/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "http://\": HTTPAdapter()}\n        s2.mount(\"https://\", HTTPAdapter())\n        assert \"http://\" in s2.adapters\n        assert \"https://\" in s2.adapters\n\n    def test_session_get_adapter_prefix_matching(self):\n        prefix = \"https://example.com\"\n        more_specific_prefix = prefix + \"/some/path\"\n\n        url_matching_only_prefix = prefix + \"/another/path\"\n        url_matching_more_specific_prefix = more_specific_prefix + \"/longer/path\"\n        url_not_matching_prefix = \"https://another.example.com/\"\n\n        s = requests.Session()\n        prefix_adapter = HTTPAdapter()\n        more_specific_prefix_adapter = HTTPAdapter()\n        s.mount(prefix, prefix_adapter)\n        s.mount(more_specific_prefix, more_specific_prefix_adapter)\n\n        assert s.get_adapter(url_matching_only_prefix) is prefix_adapter\n        assert (\n            s.get_adapter(url_matching_more_specific_prefix)\n            is more_specific_prefix_adapter\n        )\n        assert s.get_adapter(url_not_matching_prefix) not in (\n            prefix_adapter,\n            more_specific_prefix_adapter,\n        )\n\n    def test_session_get_adapter_prefix_matching_mixed_case(self):\n        mixed_case_prefix = \"hTtPs://eXamPle.CoM/MixEd_CAse_PREfix\"\n        url_matching_prefix = mixed_case_prefix + \"/full_url\"\n\n        s = requests.Session()\n        my_adapter = HTTPAdapter()\n        s.mount(mixed_case_prefix, my_adapter)\n\n        assert s.get_adapter(url_matching_prefix) is my_adapter\n\n    def test_session_get_adapter_prefix_matching_is_case_insensitive(self):\n        mixed_case_prefix = \"hTtPs://eXamPle.CoM/MixEd_CAse_PREfix\"\n        url_matching_prefix_with_different_case = (\n            \"HtTpS://exaMPLe.cOm/MiXeD_caSE_preFIX/another_url\"\n        )\n\n        s = requests.Session()\n        my_adapter = HTTPAdapter()\n        s.mount(mixed_case_prefix, my_adapter)\n\n        assert s.get_adapter(url_matching_prefix_with_different_case) is my_adapter\n\n    def test_session_get_adapter_prefix_with_trailing_slash(self"}, {"start_line": 57000, "end_line": 59000, "belongs_to": {"file_name": "test_requests.py", "upper_path": "/data2/raymone/swebench-repos/requests/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": ".mount(\"http://git\", HTTPAdapter())\n        s.mount(\"http://github\", HTTPAdapter())\n        s.mount(\"http://github.com\", HTTPAdapter())\n        s.mount(\"http://github.com/about/\", HTTPAdapter())\n        order = [\n            \"http://github.com/about/\",\n            \"http://github.com\",\n            \"http://github\",\n            \"http://git\",\n            \"https://\",\n            \"http://\",\n        ]\n        assert order == list(s.adapters)\n        s.mount(\"http://gittip\", HTTPAdapter())\n        s.mount(\"http://gittip.com\", HTTPAdapter())\n        s.mount(\"http://gittip.com/about/\", HTTPAdapter())\n        order = [\n            \"http://github.com/about/\",\n            \"http://gittip.com/about/\",\n            \"http://github.com\",\n            \"http://gittip.com\",\n            \"http://github\",\n            \"http://gittip\",\n            \"http://git\",\n            \"https://\",\n            \"http://\",\n        ]\n        assert order == list(s.adapters)\n        s2 = requests.Session()\n        s2.adapters = {\"http://\": HTTPAdapter()}\n        s2.mount(\"https://\", HTTPAdapter())\n        assert \"http://\" in s2.adapters\n        assert \"https://\" in s2.adapters\n\n    def test_session_get_adapter_prefix_matching(self):\n        prefix = \"https://example.com\"\n        more_specific_prefix = prefix + \"/some/path\"\n\n        url_matching_only_prefix = prefix + \"/another/path\"\n        url_matching_more_specific_prefix = more_specific_prefix + \"/longer/path\"\n        url_not_matching_prefix = \"https://another.example.com/\"\n\n        s = requests.Session()\n        prefix_adapter = HTTPAdapter()\n        more_specific_prefix_adapter = HTTPAdapter()\n        s.mount(prefix, prefix_adapter)\n        s.mount(more_specific_prefix, more_specific_prefix_adapter)\n\n        assert s.get_adapter(url_matching_only_prefix) is prefix_adapter\n        assert (\n            s.get_adapter(url_matching_more_specific_prefix)\n            is more_specific_prefix_adapter\n        )\n        assert s.get_adapter(url_not_matching_prefix) n"}, {"start_line": 59000, "end_line": 61000, "belongs_to": {"file_name": "test_requests.py", "upper_path": "/data2/raymone/swebench-repos/requests/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "ot in (\n            prefix_adapter,\n            more_specific_prefix_adapter,\n        )\n\n    def test_session_get_adapter_prefix_matching_mixed_case(self):\n        mixed_case_prefix = \"hTtPs://eXamPle.CoM/MixEd_CAse_PREfix\"\n        url_matching_prefix = mixed_case_prefix + \"/full_url\"\n\n        s = requests.Session()\n        my_adapter = HTTPAdapter()\n        s.mount(mixed_case_prefix, my_adapter)\n\n        assert s.get_adapter(url_matching_prefix) is my_adapter\n\n    def test_session_get_adapter_prefix_matching_is_case_insensitive(self):\n        mixed_case_prefix = \"hTtPs://eXamPle.CoM/MixEd_CAse_PREfix\"\n        url_matching_prefix_with_different_case = (\n            \"HtTpS://exaMPLe.cOm/MiXeD_caSE_preFIX/another_url\"\n        )\n\n        s = requests.Session()\n        my_adapter = HTTPAdapter()\n        s.mount(mixed_case_prefix, my_adapter)\n\n        assert s.get_adapter(url_matching_prefix_with_different_case) is my_adapter\n\n    def test_session_get_adapter_prefix_with_trailing_slash(self):\n        # from issue #6935\n        prefix = \"https://example.com/\"  # trailing slash\n        url_matching_prefix = \"https://example.com/some/path\"\n        url_not_matching_prefix = \"https://example.com.other.com/some/path\"\n\n        s = requests.Session()\n        adapter = HTTPAdapter()\n        s.mount(prefix, adapter)\n\n        assert s.get_adapter(url_matching_prefix) is adapter\n        assert s.get_adapter(url_not_matching_prefix) is not adapter\n\n    def test_session_get_adapter_prefix_without_trailing_slash(self):\n        # from issue #6935\n        prefix = \"https://example.com\"  # no trailing slash\n        url_matching_prefix = \"https://example.com/some/path\"\n        url_extended_hostname = \"https://example.com.other.com/some/path\"\n\n        s = requests.Session()\n        adapter = HTTPAdapter()\n        s.mount(prefix, adapter)\n\n        assert s.get_adapter(url_matching_prefix) is adapter\n        assert s.get_adapter(url_extended_hostname) is adapter\n\n    def test_header_remove_is"}, {"start_line": 26000, "end_line": 28000, "belongs_to": {"file_name": "sessions.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "adapter to use\n        adapter = self.get_adapter(url=request.url)\n\n        # Start time (approximately) of the request\n        start = preferred_clock()\n\n        # Send the request\n        r = adapter.send(request, **kwargs)\n\n        # Total elapsed time of the request (approximately)\n        elapsed = preferred_clock() - start\n        r.elapsed = timedelta(seconds=elapsed)\n\n        # Response manipulation hooks\n        r = dispatch_hook(\"response\", hooks, r, **kwargs)\n\n        # Persist cookies\n        if r.history:\n            # If the hooks create history then we want those cookies too\n            for resp in r.history:\n                extract_cookies_to_jar(self.cookies, resp.request, resp.raw)\n\n        extract_cookies_to_jar(self.cookies, request, r.raw)\n\n        # Resolve redirects if allowed.\n        if allow_redirects:\n            # Redirect resolving generator.\n            gen = self.resolve_redirects(r, request, **kwargs)\n            history = [resp for resp in gen]\n        else:\n            history = []\n\n        # Shuffle things around if there's history.\n        if history:\n            # Insert the first (original) request at the start\n            history.insert(0, r)\n            # Get the last request made\n            r = history.pop()\n            r.history = history\n\n        # If redirects aren't being followed, store the response on the Request for Response.next().\n        if not allow_redirects:\n            try:\n                r._next = next(\n                    self.resolve_redirects(r, request, yield_requests=True, **kwargs)\n                )\n            except StopIteration:\n                pass\n\n        if not stream:\n            r.content\n\n        return r\n\n    def merge_environment_settings(self, url, proxies, stream, verify, cert):\n        \"\"\"\n        Check the environment and merge it with some settings.\n\n        :rtype: dict\n        \"\"\"\n        # Gather clues from the surrounding environment.\n        if self.trust_env:\n            # Set en"}, {"start_line": 0, "end_line": 2000, "belongs_to": {"file_name": "sessions.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "\"\"\"\nrequests.sessions\n~~~~~~~~~~~~~~~~~\n\nThis module provides a Session object to manage and persist settings across\nrequests (cookies, auth, proxies).\n\"\"\"\nimport os\nimport sys\nimport time\nfrom collections import OrderedDict\nfrom datetime import timedelta\n\nfrom ._internal_utils import to_native_string\nfrom .adapters import HTTPAdapter\nfrom .auth import _basic_auth_str\nfrom .compat import Mapping, cookielib, urljoin, urlparse\nfrom .cookies import (\n    RequestsCookieJar,\n    cookiejar_from_dict,\n    extract_cookies_to_jar,\n    merge_cookies,\n)\nfrom .exceptions import (\n    ChunkedEncodingError,\n    ContentDecodingError,\n    InvalidSchema,\n    TooManyRedirects,\n)\nfrom .hooks import default_hooks, dispatch_hook\n\n# formerly defined here, reexposed here for backward compatibility\nfrom .models import (  # noqa: F401\n    DEFAULT_REDIRECT_LIMIT,\n    REDIRECT_STATI,\n    PreparedRequest,\n    Request,\n)\nfrom .status_codes import codes\nfrom .structures import CaseInsensitiveDict\nfrom .utils import (  # noqa: F401\n    DEFAULT_PORTS,\n    default_headers,\n    get_auth_from_url,\n    get_environ_proxies,\n    get_netrc_auth,\n    requote_uri,\n    resolve_proxies,\n    rewind_body,\n    should_bypass_proxies,\n    to_key_val_list,\n)\n\n# Preferred clock, based on which one is more accurate on a given system.\nif sys.platform == \"win32\":\n    preferred_clock = time.perf_counter\nelse:\n    preferred_clock = time.time\n\n\ndef merge_setting(request_setting, session_setting, dict_class=OrderedDict):\n    \"\"\"Determines appropriate setting for a given request, taking into account\n    the explicit setting on that request, and the setting in the session. If a\n    setting is a dictionary, they will be merged together using `dict_class`\n    \"\"\"\n\n    if session_setting is None:\n        return request_setting\n\n    if request_setting is None:\n        return session_setting\n\n    # Bypass if not a dictionary (e.g. verify)\n    if not (\n        isinstance(session_setting, Mapping) and isinstance(request_setting, M"}, {"start_line": 60000, "end_line": 62000, "belongs_to": {"file_name": "test_requests.py", "upper_path": "/data2/raymone/swebench-repos/requests/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "):\n        # from issue #6935\n        prefix = \"https://example.com/\"  # trailing slash\n        url_matching_prefix = \"https://example.com/some/path\"\n        url_not_matching_prefix = \"https://example.com.other.com/some/path\"\n\n        s = requests.Session()\n        adapter = HTTPAdapter()\n        s.mount(prefix, adapter)\n\n        assert s.get_adapter(url_matching_prefix) is adapter\n        assert s.get_adapter(url_not_matching_prefix) is not adapter\n\n    def test_session_get_adapter_prefix_without_trailing_slash(self):\n        # from issue #6935\n        prefix = \"https://example.com\"  # no trailing slash\n        url_matching_prefix = \"https://example.com/some/path\"\n        url_extended_hostname = \"https://example.com.other.com/some/path\"\n\n        s = requests.Session()\n        adapter = HTTPAdapter()\n        s.mount(prefix, adapter)\n\n        assert s.get_adapter(url_matching_prefix) is adapter\n        assert s.get_adapter(url_extended_hostname) is adapter\n\n    def test_header_remove_is_case_insensitive(self, httpbin):\n        # From issue #1321\n        s = requests.Session()\n        s.headers[\"foo\"] = \"bar\"\n        r = s.get(httpbin(\"get\"), headers={\"FOO\": None})\n        assert \"foo\" not in r.request.headers\n\n    def test_params_are_merged_case_sensitive(self, httpbin):\n        s = requests.Session()\n        s.params[\"foo\"] = \"bar\"\n        r = s.get(httpbin(\"get\"), params={\"FOO\": \"bar\"})\n        assert r.json()[\"args\"] == {\"foo\": \"bar\", \"FOO\": \"bar\"}\n\n    def test_long_authinfo_in_url(self):\n        url = \"http://{}:{}@{}:9000/path?query#frag\".format(\n            \"E8A3BE87-9E3F-4620-8858-95478E385B5B\",\n            \"EA770032-DA4D-4D84-8CE9-29C6D910BF1E\",\n            \"exactly-------------sixty-----------three------------characters\",\n        )\n        r = requests.Request(\"GET\", url).prepare()\n        assert r.url == url\n\n    def test_header_keys_are_native(self, httpbin):\n        headers = {\"unicode\": \"blah\", b\"byte\": \"blah\"}\n        r = requests.Request(\"GET\", httpbi"}], "retrieved_count": 10, "cost_time": 4.817185401916504}
{"question": "Where in Requests' codebase is the \"get\" method defined?", "answer": null, "relative_code_list": null, "ground_truth": "The \"get\" method is defined in multiple locations depending on the context: 1) Module-level get() function is defined in src/requests/api.py as a convenience function that calls requests.request('GET', url, **kwargs); 2) Session.get() method is defined in src/requests/sessions.py in the Session class, which calls self.request('GET', url, **kwargs) with allow_redirects=True by default; 3) The actual request processing is handled by Session.request() method which creates Request objects and processes them through the adapter layer. The module-level get() function creates a temporary Session object and delegates to Session.get(), while Session.get() provides persistent session features like connection pooling, cookie persistence, and configuration management. Both implementations ultimately use the same underlying request processing pipeline through Session.request()  Session.prepare_request()  Session.send()  HTTPAdapter.send().", "score": null, "retrieved_content": [{"start_line": 3000, "end_line": 5000, "belongs_to": {"file_name": "api.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "   with sessions.Session() as session:\n        return session.request(method=method, url=url, **kwargs)\n\n\ndef get(url, params=None, **kwargs):\n    r\"\"\"Sends a GET request.\n\n    :param url: URL for the new :class:`Request` object.\n    :param params: (optional) Dictionary, list of tuples or bytes to send\n        in the query string for the :class:`Request`.\n    :param \\*\\*kwargs: Optional arguments that ``request`` takes.\n    :return: :class:`Response <Response>` object\n    :rtype: requests.Response\n    \"\"\"\n\n    return request(\"get\", url, params=params, **kwargs)\n\n\ndef options(url, **kwargs):\n    r\"\"\"Sends an OPTIONS request.\n\n    :param url: URL for the new :class:`Request` object.\n    :param \\*\\*kwargs: Optional arguments that ``request`` takes.\n    :return: :class:`Response <Response>` object\n    :rtype: requests.Response\n    \"\"\"\n\n    return request(\"options\", url, **kwargs)\n\n\ndef head(url, **kwargs):\n    r\"\"\"Sends a HEAD request.\n\n    :param url: URL for the new :class:`Request` object.\n    :param \\*\\*kwargs: Optional arguments that ``request`` takes. If\n        `allow_redirects` is not provided, it will be set to `False` (as\n        opposed to the default :meth:`request` behavior).\n    :return: :class:`Response <Response>` object\n    :rtype: requests.Response\n    \"\"\"\n\n    kwargs.setdefault(\"allow_redirects\", False)\n    return request(\"head\", url, **kwargs)\n\n\ndef post(url, data=None, json=None, **kwargs):\n    r\"\"\"Sends a POST request.\n\n    :param url: URL for the new :class:`Request` object.\n    :param data: (optional) Dictionary, list of tuples, bytes, or file-like\n        object to send in the body of the :class:`Request`.\n    :param json: (optional) A JSON serializable Python object to send in the body of the :class:`Request`.\n    :param \\*\\*kwargs: Optional arguments that ``request`` takes.\n    :return: :class:`Response <Response>` object\n    :rtype: requests.Response\n    \"\"\"\n\n    return request(\"post\", url, data=data, json=json, **kwargs)\n\n\ndef put(url, data="}, {"start_line": 2000, "end_line": 4000, "belongs_to": {"file_name": "api.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": ".\n    :type allow_redirects: bool\n    :param proxies: (optional) Dictionary mapping protocol to the URL of the proxy.\n    :param verify: (optional) Either a boolean, in which case it controls whether we verify\n            the server's TLS certificate, or a string, in which case it must be a path\n            to a CA bundle to use. Defaults to ``True``.\n    :param stream: (optional) if ``False``, the response content will be immediately downloaded.\n    :param cert: (optional) if String, path to ssl client cert file (.pem). If Tuple, ('cert', 'key') pair.\n    :return: :class:`Response <Response>` object\n    :rtype: requests.Response\n\n    Usage::\n\n      >>> import requests\n      >>> req = requests.request('GET', 'https://httpbin.org/get')\n      >>> req\n      <Response [200]>\n    \"\"\"\n\n    # By using the 'with' statement we are sure the session is closed, thus we\n    # avoid leaving sockets open which can trigger a ResourceWarning in some\n    # cases, and look like a memory leak in others.\n    with sessions.Session() as session:\n        return session.request(method=method, url=url, **kwargs)\n\n\ndef get(url, params=None, **kwargs):\n    r\"\"\"Sends a GET request.\n\n    :param url: URL for the new :class:`Request` object.\n    :param params: (optional) Dictionary, list of tuples or bytes to send\n        in the query string for the :class:`Request`.\n    :param \\*\\*kwargs: Optional arguments that ``request`` takes.\n    :return: :class:`Response <Response>` object\n    :rtype: requests.Response\n    \"\"\"\n\n    return request(\"get\", url, params=params, **kwargs)\n\n\ndef options(url, **kwargs):\n    r\"\"\"Sends an OPTIONS request.\n\n    :param url: URL for the new :class:`Request` object.\n    :param \\*\\*kwargs: Optional arguments that ``request`` takes.\n    :return: :class:`Response <Response>` object\n    :rtype: requests.Response\n    \"\"\"\n\n    return request(\"options\", url, **kwargs)\n\n\ndef head(url, **kwargs):\n    r\"\"\"Sends a HEAD request.\n\n    :param url: URL for the new :class:`Request` obje"}, {"start_line": 21000, "end_line": 23000, "belongs_to": {"file_name": "sessions.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "ile (.pem).\n            If Tuple, ('cert', 'key') pair.\n        :rtype: requests.Response\n        \"\"\"\n        # Create the Request.\n        req = Request(\n            method=method.upper(),\n            url=url,\n            headers=headers,\n            files=files,\n            data=data or {},\n            json=json,\n            params=params or {},\n            auth=auth,\n            cookies=cookies,\n            hooks=hooks,\n        )\n        prep = self.prepare_request(req)\n\n        proxies = proxies or {}\n\n        settings = self.merge_environment_settings(\n            prep.url, proxies, stream, verify, cert\n        )\n\n        # Send the request.\n        send_kwargs = {\n            \"timeout\": timeout,\n            \"allow_redirects\": allow_redirects,\n        }\n        send_kwargs.update(settings)\n        resp = self.send(prep, **send_kwargs)\n\n        return resp\n\n    def get(self, url, **kwargs):\n        r\"\"\"Sends a GET request. Returns :class:`Response` object.\n\n        :param url: URL for the new :class:`Request` object.\n        :param \\*\\*kwargs: Optional arguments that ``request`` takes.\n        :rtype: requests.Response\n        \"\"\"\n\n        kwargs.setdefault(\"allow_redirects\", True)\n        return self.request(\"GET\", url, **kwargs)\n\n    def options(self, url, **kwargs):\n        r\"\"\"Sends a OPTIONS request. Returns :class:`Response` object.\n\n        :param url: URL for the new :class:`Request` object.\n        :param \\*\\*kwargs: Optional arguments that ``request`` takes.\n        :rtype: requests.Response\n        \"\"\"\n\n        kwargs.setdefault(\"allow_redirects\", True)\n        return self.request(\"OPTIONS\", url, **kwargs)\n\n    def head(self, url, **kwargs):\n        r\"\"\"Sends a HEAD request. Returns :class:`Response` object.\n\n        :param url: URL for the new :class:`Request` object.\n        :param \\*\\*kwargs: Optional arguments that ``request`` takes.\n        :rtype: requests.Response\n        \"\"\"\n\n        kwargs.setdefault(\"allow_redirects\", False)\n        return s"}, {"start_line": 22000, "end_line": 24000, "belongs_to": {"file_name": "sessions.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "for the new :class:`Request` object.\n        :param \\*\\*kwargs: Optional arguments that ``request`` takes.\n        :rtype: requests.Response\n        \"\"\"\n\n        kwargs.setdefault(\"allow_redirects\", True)\n        return self.request(\"GET\", url, **kwargs)\n\n    def options(self, url, **kwargs):\n        r\"\"\"Sends a OPTIONS request. Returns :class:`Response` object.\n\n        :param url: URL for the new :class:`Request` object.\n        :param \\*\\*kwargs: Optional arguments that ``request`` takes.\n        :rtype: requests.Response\n        \"\"\"\n\n        kwargs.setdefault(\"allow_redirects\", True)\n        return self.request(\"OPTIONS\", url, **kwargs)\n\n    def head(self, url, **kwargs):\n        r\"\"\"Sends a HEAD request. Returns :class:`Response` object.\n\n        :param url: URL for the new :class:`Request` object.\n        :param \\*\\*kwargs: Optional arguments that ``request`` takes.\n        :rtype: requests.Response\n        \"\"\"\n\n        kwargs.setdefault(\"allow_redirects\", False)\n        return self.request(\"HEAD\", url, **kwargs)\n\n    def post(self, url, data=None, json=None, **kwargs):\n        r\"\"\"Sends a POST request. Returns :class:`Response` object.\n\n        :param url: URL for the new :class:`Request` object.\n        :param data: (optional) Dictionary, list of tuples, bytes, or file-like\n            object to send in the body of the :class:`Request`.\n        :param json: (optional) json to send in the body of the :class:`Request`.\n        :param \\*\\*kwargs: Optional arguments that ``request`` takes.\n        :rtype: requests.Response\n        \"\"\"\n\n        return self.request(\"POST\", url, data=data, json=json, **kwargs)\n\n    def put(self, url, data=None, **kwargs):\n        r\"\"\"Sends a PUT request. Returns :class:`Response` object.\n\n        :param url: URL for the new :class:`Request` object.\n        :param data: (optional) Dictionary, list of tuples, bytes, or file-like\n            object to send in the body of the :class:`Request`.\n        :param \\*\\*kwargs: Optional argume"}, {"start_line": 0, "end_line": 2000, "belongs_to": {"file_name": "api.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "\"\"\"\nrequests.api\n~~~~~~~~~~~~\n\nThis module implements the Requests API.\n\n:copyright: (c) 2012 by Kenneth Reitz.\n:license: Apache2, see LICENSE for more details.\n\"\"\"\n\nfrom . import sessions\n\n\ndef request(method, url, **kwargs):\n    \"\"\"Constructs and sends a :class:`Request <Request>`.\n\n    :param method: method for the new :class:`Request` object: ``GET``, ``OPTIONS``, ``HEAD``, ``POST``, ``PUT``, ``PATCH``, or ``DELETE``.\n    :param url: URL for the new :class:`Request` object.\n    :param params: (optional) Dictionary, list of tuples or bytes to send\n        in the query string for the :class:`Request`.\n    :param data: (optional) Dictionary, list of tuples, bytes, or file-like\n        object to send in the body of the :class:`Request`.\n    :param json: (optional) A JSON serializable Python object to send in the body of the :class:`Request`.\n    :param headers: (optional) Dictionary of HTTP Headers to send with the :class:`Request`.\n    :param cookies: (optional) Dict or CookieJar object to send with the :class:`Request`.\n    :param files: (optional) Dictionary of ``'name': file-like-objects`` (or ``{'name': file-tuple}``) for multipart encoding upload.\n        ``file-tuple`` can be a 2-tuple ``('filename', fileobj)``, 3-tuple ``('filename', fileobj, 'content_type')``\n        or a 4-tuple ``('filename', fileobj, 'content_type', custom_headers)``, where ``'content_type'`` is a string\n        defining the content type of the given file and ``custom_headers`` a dict-like object containing additional headers\n        to add for the file.\n    :param auth: (optional) Auth tuple to enable Basic/Digest/Custom HTTP Auth.\n    :param timeout: (optional) How many seconds to wait for the server to send data\n        before giving up, as a float, or a :ref:`(connect timeout, read\n        timeout) <timeouts>` tuple.\n    :type timeout: float or tuple\n    :param allow_redirects: (optional) Boolean. Enable/disable GET/OPTIONS/POST/PUT/PATCH/DELETE/HEAD redirection. Defaults to ``True``"}, {"start_line": 20000, "end_line": 22000, "belongs_to": {"file_name": "sessions.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "ol or protocol and\n            hostname to the URL of the proxy.\n        :param hooks: (optional) Dictionary mapping hook name to one event or\n            list of events, event must be callable.\n        :param stream: (optional) whether to immediately download the response\n            content. Defaults to ``False``.\n        :param verify: (optional) Either a boolean, in which case it controls whether we verify\n            the server's TLS certificate, or a string, in which case it must be a path\n            to a CA bundle to use. Defaults to ``True``. When set to\n            ``False``, requests will accept any TLS certificate presented by\n            the server, and will ignore hostname mismatches and/or expired\n            certificates, which will make your application vulnerable to\n            man-in-the-middle (MitM) attacks. Setting verify to ``False``\n            may be useful during local development or testing.\n        :param cert: (optional) if String, path to ssl client cert file (.pem).\n            If Tuple, ('cert', 'key') pair.\n        :rtype: requests.Response\n        \"\"\"\n        # Create the Request.\n        req = Request(\n            method=method.upper(),\n            url=url,\n            headers=headers,\n            files=files,\n            data=data or {},\n            json=json,\n            params=params or {},\n            auth=auth,\n            cookies=cookies,\n            hooks=hooks,\n        )\n        prep = self.prepare_request(req)\n\n        proxies = proxies or {}\n\n        settings = self.merge_environment_settings(\n            prep.url, proxies, stream, verify, cert\n        )\n\n        # Send the request.\n        send_kwargs = {\n            \"timeout\": timeout,\n            \"allow_redirects\": allow_redirects,\n        }\n        send_kwargs.update(settings)\n        resp = self.send(prep, **send_kwargs)\n\n        return resp\n\n    def get(self, url, **kwargs):\n        r\"\"\"Sends a GET request. Returns :class:`Response` object.\n\n        :param url: URL "}, {"start_line": 0, "end_line": 2000, "belongs_to": {"file_name": "__init__.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "#   __\n#  /__)  _  _     _   _ _/   _\n# / (   (- (/ (/ (- _)  /  _)\n#          /\n\n\"\"\"\nRequests HTTP Library\n~~~~~~~~~~~~~~~~~~~~~\n\nRequests is an HTTP library, written in Python, for human beings.\nBasic GET usage:\n\n   >>> import requests\n   >>> r = requests.get('https://www.python.org')\n   >>> r.status_code\n   200\n   >>> b'Python is a programming language' in r.content\n   True\n\n... or POST:\n\n   >>> payload = dict(key1='value1', key2='value2')\n   >>> r = requests.post('https://httpbin.org/post', data=payload)\n   >>> print(r.text)\n   {\n     ...\n     \"form\": {\n       \"key1\": \"value1\",\n       \"key2\": \"value2\"\n     },\n     ...\n   }\n\nThe other HTTP methods are supported - see `requests.api`. Full documentation\nis at <https://requests.readthedocs.io>.\n\n:copyright: (c) 2017 by Kenneth Reitz.\n:license: Apache 2.0, see LICENSE for more details.\n\"\"\"\n\nimport warnings\n\nimport urllib3\n\nfrom .exceptions import RequestsDependencyWarning\n\ntry:\n    from charset_normalizer import __version__ as charset_normalizer_version\nexcept ImportError:\n    charset_normalizer_version = None\n\ntry:\n    from chardet import __version__ as chardet_version\nexcept ImportError:\n    chardet_version = None\n\n\ndef check_compatibility(urllib3_version, chardet_version, charset_normalizer_version):\n    urllib3_version = urllib3_version.split(\".\")\n    assert urllib3_version != [\"dev\"]  # Verify urllib3 isn't installed from git.\n\n    # Sometimes, urllib3 only reports its version as 16.1.\n    if len(urllib3_version) == 2:\n        urllib3_version.append(\"0\")\n\n    # Check urllib3 for compatibility.\n    major, minor, patch = urllib3_version  # noqa: F811\n    major, minor, patch = int(major), int(minor), int(patch)\n    # urllib3 >= 1.21.1\n    assert major >= 1\n    if major == 1:\n        assert minor >= 21\n\n    # Check charset_normalizer for compatibility.\n    if chardet_version:\n        major, minor, patch = chardet_version.split(\".\")[:3]\n        major, minor, patch = int(major), int(minor), int(patch)\n        # charde"}, {"start_line": 2000, "end_line": 4000, "belongs_to": {"file_name": "test_requests.py", "upper_path": "/data2/raymone/swebench-repos/requests/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": " requests.session\n        requests.session().get\n        requests.session().head\n        requests.get\n        requests.head\n        requests.put\n        requests.patch\n        requests.post\n        # Not really an entry point, but people rely on it.\n        from requests.packages.urllib3.poolmanager import PoolManager  # noqa:F401\n\n    @pytest.mark.parametrize(\n        \"exception, url\",\n        (\n            (MissingSchema, \"hiwpefhipowhefopw\"),\n            (InvalidSchema, \"localhost:3128\"),\n            (InvalidSchema, \"localhost.localdomain:3128/\"),\n            (InvalidSchema, \"10.122.1.1:3128/\"),\n            (InvalidURL, \"http://\"),\n            (InvalidURL, \"http://*example.com\"),\n            (InvalidURL, \"http://.example.com\"),\n        ),\n    )\n    def test_invalid_url(self, exception, url):\n        with pytest.raises(exception):\n            requests.get(url)\n\n    def test_basic_building(self):\n        req = requests.Request()\n        req.url = \"http://kennethreitz.org/\"\n        req.data = {\"life\": \"42\"}\n\n        pr = req.prepare()\n        assert pr.url == req.url\n        assert pr.body == \"life=42\"\n\n    @pytest.mark.parametrize(\"method\", (\"GET\", \"HEAD\"))\n    def test_no_content_length(self, httpbin, method):\n        req = requests.Request(method, httpbin(method.lower())).prepare()\n        assert \"Content-Length\" not in req.headers\n\n    @pytest.mark.parametrize(\"method\", (\"POST\", \"PUT\", \"PATCH\", \"OPTIONS\"))\n    def test_no_body_content_length(self, httpbin, method):\n        req = requests.Request(method, httpbin(method.lower())).prepare()\n        assert req.headers[\"Content-Length\"] == \"0\"\n\n    @pytest.mark.parametrize(\"method\", (\"POST\", \"PUT\", \"PATCH\", \"OPTIONS\"))\n    def test_empty_content_length(self, httpbin, method):\n        req = requests.Request(method, httpbin(method.lower()), data=\"\").prepare()\n        assert req.headers[\"Content-Length\"] == \"0\"\n\n    def test_override_content_length(self, httpbin):\n        headers = {\"Content-Length\": \"not zero\"}\n       "}, {"start_line": 4000, "end_line": 6000, "belongs_to": {"file_name": "api.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "ct.\n    :param \\*\\*kwargs: Optional arguments that ``request`` takes. If\n        `allow_redirects` is not provided, it will be set to `False` (as\n        opposed to the default :meth:`request` behavior).\n    :return: :class:`Response <Response>` object\n    :rtype: requests.Response\n    \"\"\"\n\n    kwargs.setdefault(\"allow_redirects\", False)\n    return request(\"head\", url, **kwargs)\n\n\ndef post(url, data=None, json=None, **kwargs):\n    r\"\"\"Sends a POST request.\n\n    :param url: URL for the new :class:`Request` object.\n    :param data: (optional) Dictionary, list of tuples, bytes, or file-like\n        object to send in the body of the :class:`Request`.\n    :param json: (optional) A JSON serializable Python object to send in the body of the :class:`Request`.\n    :param \\*\\*kwargs: Optional arguments that ``request`` takes.\n    :return: :class:`Response <Response>` object\n    :rtype: requests.Response\n    \"\"\"\n\n    return request(\"post\", url, data=data, json=json, **kwargs)\n\n\ndef put(url, data=None, **kwargs):\n    r\"\"\"Sends a PUT request.\n\n    :param url: URL for the new :class:`Request` object.\n    :param data: (optional) Dictionary, list of tuples, bytes, or file-like\n        object to send in the body of the :class:`Request`.\n    :param json: (optional) A JSON serializable Python object to send in the body of the :class:`Request`.\n    :param \\*\\*kwargs: Optional arguments that ``request`` takes.\n    :return: :class:`Response <Response>` object\n    :rtype: requests.Response\n    \"\"\"\n\n    return request(\"put\", url, data=data, **kwargs)\n\n\ndef patch(url, data=None, **kwargs):\n    r\"\"\"Sends a PATCH request.\n\n    :param url: URL for the new :class:`Request` object.\n    :param data: (optional) Dictionary, list of tuples, bytes, or file-like\n        object to send in the body of the :class:`Request`.\n    :param json: (optional) A JSON serializable Python object to send in the body of the :class:`Request`.\n    :param \\*\\*kwargs: Optional arguments that ``request`` takes.\n    :retur"}, {"start_line": 7000, "end_line": 9000, "belongs_to": {"file_name": "models.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "method to use.\n    :param url: URL to send.\n    :param headers: dictionary of headers to send.\n    :param files: dictionary of {filename: fileobject} files to multipart upload.\n    :param data: the body to attach to the request. If a dictionary or\n        list of tuples ``[(key, value)]`` is provided, form-encoding will\n        take place.\n    :param json: json for the body to attach to the request (if files or data is not specified).\n    :param params: URL parameters to append to the URL. If a dictionary or\n        list of tuples ``[(key, value)]`` is provided, form-encoding will\n        take place.\n    :param auth: Auth handler or (user, pass) tuple.\n    :param cookies: dictionary or CookieJar of cookies to attach to this request.\n    :param hooks: dictionary of callback hooks, for internal usage.\n\n    Usage::\n\n      >>> import requests\n      >>> req = requests.Request('GET', 'https://httpbin.org/get')\n      >>> req.prepare()\n      <PreparedRequest [GET]>\n    \"\"\"\n\n    def __init__(\n        self,\n        method=None,\n        url=None,\n        headers=None,\n        files=None,\n        data=None,\n        params=None,\n        auth=None,\n        cookies=None,\n        hooks=None,\n        json=None,\n    ):\n        # Default empty dicts for dict params.\n        data = [] if data is None else data\n        files = [] if files is None else files\n        headers = {} if headers is None else headers\n        params = {} if params is None else params\n        hooks = {} if hooks is None else hooks\n\n        self.hooks = default_hooks()\n        for k, v in list(hooks.items()):\n            self.register_hook(event=k, hook=v)\n\n        self.method = method\n        self.url = url\n        self.headers = headers\n        self.files = files\n        self.data = data\n        self.json = json\n        self.params = params\n        self.auth = auth\n        self.cookies = cookies\n\n    def __repr__(self):\n        return f\"<Request [{self.method}]>\"\n\n    def prepare(self):\n        \"\"\"Constructs a :"}], "retrieved_count": 10, "cost_time": 1.3822362422943115}
{"question": "Where is the \"send\" method defined in the adapter hierarchy?", "answer": null, "relative_code_list": null, "ground_truth": "The \"send\" method is defined in the adapter hierarchy in src/requests/adapters.py: 1) BaseAdapter.send() - abstract method defined in the BaseAdapter class that serves as the interface contract for all adapters; 2) HTTPAdapter.send() - concrete implementation in the HTTPAdapter class that handles HTTP/HTTPS requests through urllib3's PoolManager. The send() method signature is: send(self, request, stream=False, timeout=None, verify=True, cert=None, proxies=None) where request is a PreparedRequest object. The HTTPAdapter.send() method handles connection pooling, retry logic, proxy support, SSL/TLS configuration, and response building. It delegates the actual transport to urllib3's PoolManager.urlopen() method and then builds a Response object through HTTPAdapter.build_response(). The send() method is called by Session.send() in src/requests/sessions.py after selecting the appropriate adapter based on the URL scheme.", "score": null, "retrieved_content": [{"start_line": 3000, "end_line": 5000, "belongs_to": {"file_name": "adapters.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "     \"host\": parsed_request_url.hostname,\n        \"port\": port,\n    }\n    return host_params, pool_kwargs\n\n\nclass BaseAdapter:\n    \"\"\"The Base Transport Adapter\"\"\"\n\n    def __init__(self):\n        super().__init__()\n\n    def send(\n        self, request, stream=False, timeout=None, verify=True, cert=None, proxies=None\n    ):\n        \"\"\"Sends PreparedRequest object. Returns Response object.\n\n        :param request: The :class:`PreparedRequest <PreparedRequest>` being sent.\n        :param stream: (optional) Whether to stream the request content.\n        :param timeout: (optional) How long to wait for the server to send\n            data before giving up, as a float, or a :ref:`(connect timeout,\n            read timeout) <timeouts>` tuple.\n        :type timeout: float or tuple\n        :param verify: (optional) Either a boolean, in which case it controls whether we verify\n            the server's TLS certificate, or a string, in which case it must be a path\n            to a CA bundle to use\n        :param cert: (optional) Any user-provided SSL certificate to be trusted.\n        :param proxies: (optional) The proxies dictionary to apply to the request.\n        \"\"\"\n        raise NotImplementedError\n\n    def close(self):\n        \"\"\"Cleans up adapter specific items.\"\"\"\n        raise NotImplementedError\n\n\nclass HTTPAdapter(BaseAdapter):\n    \"\"\"The built-in HTTP Adapter for urllib3.\n\n    Provides a general-case interface for Requests sessions to contact HTTP and\n    HTTPS urls by implementing the Transport Adapter interface. This class will\n    usually be created by the :class:`Session <Session>` class under the\n    covers.\n\n    :param pool_connections: The number of urllib3 connection pools to cache.\n    :param pool_maxsize: The maximum number of connections to save in the pool.\n    :param max_retries: The maximum number of retries each connection\n        should attempt. Note, this applies only to failed DNS lookups, socket\n        connections and connection timeouts, never to"}, {"start_line": 21000, "end_line": 23000, "belongs_to": {"file_name": "adapters.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "ters.HTTPAdapter>`.\n\n        This should not be called from user code, and is only exposed for use\n        when subclassing the\n        :class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.\n\n        :param request: The :class:`PreparedRequest <PreparedRequest>` to add headers to.\n        :param kwargs: The keyword arguments from the call to send().\n        \"\"\"\n        pass\n\n    def proxy_headers(self, proxy):\n        \"\"\"Returns a dictionary of the headers to add to any request sent\n        through a proxy. This works with urllib3 magic to ensure that they are\n        correctly sent to the proxy, rather than in a tunnelled request if\n        CONNECT is being used.\n\n        This should not be called from user code, and is only exposed for use\n        when subclassing the\n        :class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.\n\n        :param proxy: The url of the proxy being used for this request.\n        :rtype: dict\n        \"\"\"\n        headers = {}\n        username, password = get_auth_from_url(proxy)\n\n        if username:\n            headers[\"Proxy-Authorization\"] = _basic_auth_str(username, password)\n\n        return headers\n\n    def send(\n        self, request, stream=False, timeout=None, verify=True, cert=None, proxies=None\n    ):\n        \"\"\"Sends PreparedRequest object. Returns Response object.\n\n        :param request: The :class:`PreparedRequest <PreparedRequest>` being sent.\n        :param stream: (optional) Whether to stream the request content.\n        :param timeout: (optional) How long to wait for the server to send\n            data before giving up, as a float, or a :ref:`(connect timeout,\n            read timeout) <timeouts>` tuple.\n        :type timeout: float or tuple or urllib3 Timeout object\n        :param verify: (optional) Either a boolean, in which case it controls whether\n            we verify the server's TLS certificate, or a string, in which case it\n            must be a path to a CA bundle to use\n        :param cert: (optional) Any user"}, {"start_line": 2000, "end_line": 4000, "belongs_to": {"file_name": "adapters.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "olmanager: \"PoolManager\",\n) -> \"(typing.Dict[str, typing.Any], typing.Dict[str, typing.Any])\":\n    host_params = {}\n    pool_kwargs = {}\n    parsed_request_url = urlparse(request.url)\n    scheme = parsed_request_url.scheme.lower()\n    port = parsed_request_url.port\n\n    cert_reqs = \"CERT_REQUIRED\"\n    if verify is False:\n        cert_reqs = \"CERT_NONE\"\n    elif isinstance(verify, str):\n        if not os.path.isdir(verify):\n            pool_kwargs[\"ca_certs\"] = verify\n        else:\n            pool_kwargs[\"ca_cert_dir\"] = verify\n    pool_kwargs[\"cert_reqs\"] = cert_reqs\n    if client_cert is not None:\n        if isinstance(client_cert, tuple) and len(client_cert) == 2:\n            pool_kwargs[\"cert_file\"] = client_cert[0]\n            pool_kwargs[\"key_file\"] = client_cert[1]\n        else:\n            # According to our docs, we allow users to specify just the client\n            # cert path\n            pool_kwargs[\"cert_file\"] = client_cert\n    host_params = {\n        \"scheme\": scheme,\n        \"host\": parsed_request_url.hostname,\n        \"port\": port,\n    }\n    return host_params, pool_kwargs\n\n\nclass BaseAdapter:\n    \"\"\"The Base Transport Adapter\"\"\"\n\n    def __init__(self):\n        super().__init__()\n\n    def send(\n        self, request, stream=False, timeout=None, verify=True, cert=None, proxies=None\n    ):\n        \"\"\"Sends PreparedRequest object. Returns Response object.\n\n        :param request: The :class:`PreparedRequest <PreparedRequest>` being sent.\n        :param stream: (optional) Whether to stream the request content.\n        :param timeout: (optional) How long to wait for the server to send\n            data before giving up, as a float, or a :ref:`(connect timeout,\n            read timeout) <timeouts>` tuple.\n        :type timeout: float or tuple\n        :param verify: (optional) Either a boolean, in which case it controls whether we verify\n            the server's TLS certificate, or a string, in which case it must be a path\n            to a CA bundle to use\n"}, {"start_line": 26000, "end_line": 28000, "belongs_to": {"file_name": "sessions.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "adapter to use\n        adapter = self.get_adapter(url=request.url)\n\n        # Start time (approximately) of the request\n        start = preferred_clock()\n\n        # Send the request\n        r = adapter.send(request, **kwargs)\n\n        # Total elapsed time of the request (approximately)\n        elapsed = preferred_clock() - start\n        r.elapsed = timedelta(seconds=elapsed)\n\n        # Response manipulation hooks\n        r = dispatch_hook(\"response\", hooks, r, **kwargs)\n\n        # Persist cookies\n        if r.history:\n            # If the hooks create history then we want those cookies too\n            for resp in r.history:\n                extract_cookies_to_jar(self.cookies, resp.request, resp.raw)\n\n        extract_cookies_to_jar(self.cookies, request, r.raw)\n\n        # Resolve redirects if allowed.\n        if allow_redirects:\n            # Redirect resolving generator.\n            gen = self.resolve_redirects(r, request, **kwargs)\n            history = [resp for resp in gen]\n        else:\n            history = []\n\n        # Shuffle things around if there's history.\n        if history:\n            # Insert the first (original) request at the start\n            history.insert(0, r)\n            # Get the last request made\n            r = history.pop()\n            r.history = history\n\n        # If redirects aren't being followed, store the response on the Request for Response.next().\n        if not allow_redirects:\n            try:\n                r._next = next(\n                    self.resolve_redirects(r, request, yield_requests=True, **kwargs)\n                )\n            except StopIteration:\n                pass\n\n        if not stream:\n            r.content\n\n        return r\n\n    def merge_environment_settings(self, url, proxies, stream, verify, cert):\n        \"\"\"\n        Check the environment and merge it with some settings.\n\n        :rtype: dict\n        \"\"\"\n        # Gather clues from the surrounding environment.\n        if self.trust_env:\n            # Set en"}, {"start_line": 24000, "end_line": 26000, "belongs_to": {"file_name": "sessions.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "nts that ``request`` takes.\n        :rtype: requests.Response\n        \"\"\"\n\n        return self.request(\"PUT\", url, data=data, **kwargs)\n\n    def patch(self, url, data=None, **kwargs):\n        r\"\"\"Sends a PATCH request. Returns :class:`Response` object.\n\n        :param url: URL for the new :class:`Request` object.\n        :param data: (optional) Dictionary, list of tuples, bytes, or file-like\n            object to send in the body of the :class:`Request`.\n        :param \\*\\*kwargs: Optional arguments that ``request`` takes.\n        :rtype: requests.Response\n        \"\"\"\n\n        return self.request(\"PATCH\", url, data=data, **kwargs)\n\n    def delete(self, url, **kwargs):\n        r\"\"\"Sends a DELETE request. Returns :class:`Response` object.\n\n        :param url: URL for the new :class:`Request` object.\n        :param \\*\\*kwargs: Optional arguments that ``request`` takes.\n        :rtype: requests.Response\n        \"\"\"\n\n        return self.request(\"DELETE\", url, **kwargs)\n\n    def send(self, request, **kwargs):\n        \"\"\"Send a given PreparedRequest.\n\n        :rtype: requests.Response\n        \"\"\"\n        # Set defaults that the hooks can utilize to ensure they always have\n        # the correct parameters to reproduce the previous request.\n        kwargs.setdefault(\"stream\", self.stream)\n        kwargs.setdefault(\"verify\", self.verify)\n        kwargs.setdefault(\"cert\", self.cert)\n        if \"proxies\" not in kwargs:\n            kwargs[\"proxies\"] = resolve_proxies(request, self.proxies, self.trust_env)\n\n        # It's possible that users might accidentally send a Request object.\n        # Guard against that specific failure case.\n        if isinstance(request, Request):\n            raise ValueError(\"You can only send PreparedRequests.\")\n\n        # Set up variables needed for resolve_redirects and dispatching of hooks\n        allow_redirects = kwargs.pop(\"allow_redirects\", True)\n        stream = kwargs.get(\"stream\")\n        hooks = request.hooks\n\n        # Get the appropriate "}, {"start_line": 22000, "end_line": 24000, "belongs_to": {"file_name": "adapters.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "t_auth_from_url(proxy)\n\n        if username:\n            headers[\"Proxy-Authorization\"] = _basic_auth_str(username, password)\n\n        return headers\n\n    def send(\n        self, request, stream=False, timeout=None, verify=True, cert=None, proxies=None\n    ):\n        \"\"\"Sends PreparedRequest object. Returns Response object.\n\n        :param request: The :class:`PreparedRequest <PreparedRequest>` being sent.\n        :param stream: (optional) Whether to stream the request content.\n        :param timeout: (optional) How long to wait for the server to send\n            data before giving up, as a float, or a :ref:`(connect timeout,\n            read timeout) <timeouts>` tuple.\n        :type timeout: float or tuple or urllib3 Timeout object\n        :param verify: (optional) Either a boolean, in which case it controls whether\n            we verify the server's TLS certificate, or a string, in which case it\n            must be a path to a CA bundle to use\n        :param cert: (optional) Any user-provided SSL certificate to be trusted.\n        :param proxies: (optional) The proxies dictionary to apply to the request.\n        :rtype: requests.Response\n        \"\"\"\n\n        try:\n            conn = self.get_connection_with_tls_context(\n                request, verify, proxies=proxies, cert=cert\n            )\n        except LocationValueError as e:\n            raise InvalidURL(e, request=request)\n\n        self.cert_verify(conn, request.url, verify, cert)\n        url = self.request_url(request, proxies)\n        self.add_headers(\n            request,\n            stream=stream,\n            timeout=timeout,\n            verify=verify,\n            cert=cert,\n            proxies=proxies,\n        )\n\n        chunked = not (request.body is None or \"Content-Length\" in request.headers)\n\n        if isinstance(timeout, tuple):\n            try:\n                connect, read = timeout\n                timeout = TimeoutSauce(connect=connect, read=read)\n            except ValueError:\n                "}, {"start_line": 29000, "end_line": 30503, "belongs_to": {"file_name": "sessions.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "nnection adapter for the given URL.\n\n        :rtype: requests.adapters.BaseAdapter\n        \"\"\"\n        for prefix, adapter in self.adapters.items():\n            if url.lower().startswith(prefix.lower()):\n                return adapter\n\n        # Nothing matches :-/\n        raise InvalidSchema(f\"No connection adapters were found for {url!r}\")\n\n    def close(self):\n        \"\"\"Closes all adapters and as such the session\"\"\"\n        for v in self.adapters.values():\n            v.close()\n\n    def mount(self, prefix, adapter):\n        \"\"\"Registers a connection adapter to a prefix.\n\n        Adapters are sorted in descending order by prefix length.\n        \"\"\"\n        self.adapters[prefix] = adapter\n        keys_to_move = [k for k in self.adapters if len(k) < len(prefix)]\n\n        for key in keys_to_move:\n            self.adapters[key] = self.adapters.pop(key)\n\n    def __getstate__(self):\n        state = {attr: getattr(self, attr, None) for attr in self.__attrs__}\n        return state\n\n    def __setstate__(self, state):\n        for attr, value in state.items():\n            setattr(self, attr, value)\n\n\ndef session():\n    \"\"\"\n    Returns a :class:`Session` for context-management.\n\n    .. deprecated:: 1.0.0\n\n        This method has been deprecated since version 1.0.0 and is only kept for\n        backwards compatibility. New code should use :class:`~requests.sessions.Session`\n        to create a session. This may be removed at a future date.\n\n    :rtype: Session\n    \"\"\"\n    return Session()\n"}, {"start_line": 28000, "end_line": 30000, "belongs_to": {"file_name": "sessions.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "vironment's proxies.\n            no_proxy = proxies.get(\"no_proxy\") if proxies is not None else None\n            env_proxies = get_environ_proxies(url, no_proxy=no_proxy)\n            for k, v in env_proxies.items():\n                proxies.setdefault(k, v)\n\n            # Look for requests environment configuration\n            # and be compatible with cURL.\n            if verify is True or verify is None:\n                verify = (\n                    os.environ.get(\"REQUESTS_CA_BUNDLE\")\n                    or os.environ.get(\"CURL_CA_BUNDLE\")\n                    or verify\n                )\n\n        # Merge all the kwargs.\n        proxies = merge_setting(proxies, self.proxies)\n        stream = merge_setting(stream, self.stream)\n        verify = merge_setting(verify, self.verify)\n        cert = merge_setting(cert, self.cert)\n\n        return {\"proxies\": proxies, \"stream\": stream, \"verify\": verify, \"cert\": cert}\n\n    def get_adapter(self, url):\n        \"\"\"\n        Returns the appropriate connection adapter for the given URL.\n\n        :rtype: requests.adapters.BaseAdapter\n        \"\"\"\n        for prefix, adapter in self.adapters.items():\n            if url.lower().startswith(prefix.lower()):\n                return adapter\n\n        # Nothing matches :-/\n        raise InvalidSchema(f\"No connection adapters were found for {url!r}\")\n\n    def close(self):\n        \"\"\"Closes all adapters and as such the session\"\"\"\n        for v in self.adapters.values():\n            v.close()\n\n    def mount(self, prefix, adapter):\n        \"\"\"Registers a connection adapter to a prefix.\n\n        Adapters are sorted in descending order by prefix length.\n        \"\"\"\n        self.adapters[prefix] = adapter\n        keys_to_move = [k for k in self.adapters if len(k) < len(prefix)]\n\n        for key in keys_to_move:\n            self.adapters[key] = self.adapters.pop(key)\n\n    def __getstate__(self):\n        state = {attr: getattr(self, attr, None) for attr in self.__attrs__}\n        return state\n\n    def "}, {"start_line": 57000, "end_line": 59000, "belongs_to": {"file_name": "test_requests.py", "upper_path": "/data2/raymone/swebench-repos/requests/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": ".mount(\"http://git\", HTTPAdapter())\n        s.mount(\"http://github\", HTTPAdapter())\n        s.mount(\"http://github.com\", HTTPAdapter())\n        s.mount(\"http://github.com/about/\", HTTPAdapter())\n        order = [\n            \"http://github.com/about/\",\n            \"http://github.com\",\n            \"http://github\",\n            \"http://git\",\n            \"https://\",\n            \"http://\",\n        ]\n        assert order == list(s.adapters)\n        s.mount(\"http://gittip\", HTTPAdapter())\n        s.mount(\"http://gittip.com\", HTTPAdapter())\n        s.mount(\"http://gittip.com/about/\", HTTPAdapter())\n        order = [\n            \"http://github.com/about/\",\n            \"http://gittip.com/about/\",\n            \"http://github.com\",\n            \"http://gittip.com\",\n            \"http://github\",\n            \"http://gittip\",\n            \"http://git\",\n            \"https://\",\n            \"http://\",\n        ]\n        assert order == list(s.adapters)\n        s2 = requests.Session()\n        s2.adapters = {\"http://\": HTTPAdapter()}\n        s2.mount(\"https://\", HTTPAdapter())\n        assert \"http://\" in s2.adapters\n        assert \"https://\" in s2.adapters\n\n    def test_session_get_adapter_prefix_matching(self):\n        prefix = \"https://example.com\"\n        more_specific_prefix = prefix + \"/some/path\"\n\n        url_matching_only_prefix = prefix + \"/another/path\"\n        url_matching_more_specific_prefix = more_specific_prefix + \"/longer/path\"\n        url_not_matching_prefix = \"https://another.example.com/\"\n\n        s = requests.Session()\n        prefix_adapter = HTTPAdapter()\n        more_specific_prefix_adapter = HTTPAdapter()\n        s.mount(prefix, prefix_adapter)\n        s.mount(more_specific_prefix, more_specific_prefix_adapter)\n\n        assert s.get_adapter(url_matching_only_prefix) is prefix_adapter\n        assert (\n            s.get_adapter(url_matching_more_specific_prefix)\n            is more_specific_prefix_adapter\n        )\n        assert s.get_adapter(url_not_matching_prefix) n"}, {"start_line": 8000, "end_line": 10000, "belongs_to": {"file_name": "sessions.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "     # https://github.com/psf/requests/issues/3490\n                purged_headers = (\"Content-Length\", \"Content-Type\", \"Transfer-Encoding\")\n                for header in purged_headers:\n                    prepared_request.headers.pop(header, None)\n                prepared_request.body = None\n\n            headers = prepared_request.headers\n            headers.pop(\"Cookie\", None)\n\n            # Extract any cookies sent on the response to the cookiejar\n            # in the new request. Because we've mutated our copied prepared\n            # request, use the old one that we haven't yet touched.\n            extract_cookies_to_jar(prepared_request._cookies, req, resp.raw)\n            merge_cookies(prepared_request._cookies, self.cookies)\n            prepared_request.prepare_cookies(prepared_request._cookies)\n\n            # Rebuild auth and proxy information.\n            proxies = self.rebuild_proxies(prepared_request, proxies)\n            self.rebuild_auth(prepared_request, resp)\n\n            # A failed tell() sets `_body_position` to `object()`. This non-None\n            # value ensures `rewindable` will be True, allowing us to raise an\n            # UnrewindableBodyError, instead of hanging the connection.\n            rewindable = prepared_request._body_position is not None and (\n                \"Content-Length\" in headers or \"Transfer-Encoding\" in headers\n            )\n\n            # Attempt to rewind consumed file-like object.\n            if rewindable:\n                rewind_body(prepared_request)\n\n            # Override the original request.\n            req = prepared_request\n\n            if yield_requests:\n                yield req\n            else:\n                resp = self.send(\n                    req,\n                    stream=stream,\n                    timeout=timeout,\n                    verify=verify,\n                    cert=cert,\n                    proxies=proxies,\n                    allow_redirects=False,\n                    **adapter_kwargs,\n     "}], "retrieved_count": 10, "cost_time": 1.3492779731750488}
{"question": "Where in Requests' codebase is the \"Session\" class defined?", "answer": null, "relative_code_list": null, "ground_truth": "The \"Session\" class is defined in src/requests/sessions.py. The Session class inherits from SessionRedirectMixin and provides the main session management functionality. Key aspects of the Session class definition include: 1) Class definition: class Session(SessionRedirectMixin): with comprehensive docstring and usage examples; 2) __attrs__ list defining the attributes that are preserved during serialization/deserialization; 3) __init__() method that initializes session state including headers, cookies, auth, proxies, hooks, params, verify, cert, adapters, stream, trust_env, and max_redirects; 4) Context manager methods __enter__() and __exit__() for automatic resource cleanup; 5) Core methods like request(), prepare_request(), send(), get(), post(), etc. for making HTTP requests; 6) Configuration methods like mount() for adapter registration and merge_environment_settings() for environment integration; 7) Resource management methods like close() for cleanup. The Session class serves as the primary interface for making HTTP requests with persistent state, connection pooling, and configuration management.", "score": null, "retrieved_content": [{"start_line": 13000, "end_line": 15000, "belongs_to": {"file_name": "sessions.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "POST is responded to with a 301, turn it into a GET.\n        # This bizarre behaviour is explained in Issue 1704.\n        if response.status_code == codes.moved and method == \"POST\":\n            method = \"GET\"\n\n        prepared_request.method = method\n\n\nclass Session(SessionRedirectMixin):\n    \"\"\"A Requests session.\n\n    Provides cookie persistence, connection-pooling, and configuration.\n\n    Basic Usage::\n\n      >>> import requests\n      >>> s = requests.Session()\n      >>> s.get('https://httpbin.org/get')\n      <Response [200]>\n\n    Or as a context manager::\n\n      >>> with requests.Session() as s:\n      ...     s.get('https://httpbin.org/get')\n      <Response [200]>\n    \"\"\"\n\n    __attrs__ = [\n        \"headers\",\n        \"cookies\",\n        \"auth\",\n        \"proxies\",\n        \"hooks\",\n        \"params\",\n        \"verify\",\n        \"cert\",\n        \"adapters\",\n        \"stream\",\n        \"trust_env\",\n        \"max_redirects\",\n    ]\n\n    def __init__(self):\n        #: A case-insensitive dictionary of headers to be sent on each\n        #: :class:`Request <Request>` sent from this\n        #: :class:`Session <Session>`.\n        self.headers = default_headers()\n\n        #: Default Authentication tuple or object to attach to\n        #: :class:`Request <Request>`.\n        self.auth = None\n\n        #: Dictionary mapping protocol or protocol and host to the URL of the proxy\n        #: (e.g. {'http': 'foo.bar:3128', 'http://host.name': 'foo.bar:4012'}) to\n        #: be used on each :class:`Request <Request>`.\n        self.proxies = {}\n\n        #: Event-handling hooks.\n        self.hooks = default_hooks()\n\n        #: Dictionary of querystring data to attach to each\n        #: :class:`Request <Request>`. The dictionary values may be lists for\n        #: representing multivalued query parameters.\n        self.params = {}\n\n        #: Stream response content default.\n        self.stream = False\n\n        #: SSL Verification default.\n        #: Defaults to `True`, requiring requests to verif"}, {"start_line": 0, "end_line": 2000, "belongs_to": {"file_name": "sessions.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "\"\"\"\nrequests.sessions\n~~~~~~~~~~~~~~~~~\n\nThis module provides a Session object to manage and persist settings across\nrequests (cookies, auth, proxies).\n\"\"\"\nimport os\nimport sys\nimport time\nfrom collections import OrderedDict\nfrom datetime import timedelta\n\nfrom ._internal_utils import to_native_string\nfrom .adapters import HTTPAdapter\nfrom .auth import _basic_auth_str\nfrom .compat import Mapping, cookielib, urljoin, urlparse\nfrom .cookies import (\n    RequestsCookieJar,\n    cookiejar_from_dict,\n    extract_cookies_to_jar,\n    merge_cookies,\n)\nfrom .exceptions import (\n    ChunkedEncodingError,\n    ContentDecodingError,\n    InvalidSchema,\n    TooManyRedirects,\n)\nfrom .hooks import default_hooks, dispatch_hook\n\n# formerly defined here, reexposed here for backward compatibility\nfrom .models import (  # noqa: F401\n    DEFAULT_REDIRECT_LIMIT,\n    REDIRECT_STATI,\n    PreparedRequest,\n    Request,\n)\nfrom .status_codes import codes\nfrom .structures import CaseInsensitiveDict\nfrom .utils import (  # noqa: F401\n    DEFAULT_PORTS,\n    default_headers,\n    get_auth_from_url,\n    get_environ_proxies,\n    get_netrc_auth,\n    requote_uri,\n    resolve_proxies,\n    rewind_body,\n    should_bypass_proxies,\n    to_key_val_list,\n)\n\n# Preferred clock, based on which one is more accurate on a given system.\nif sys.platform == \"win32\":\n    preferred_clock = time.perf_counter\nelse:\n    preferred_clock = time.time\n\n\ndef merge_setting(request_setting, session_setting, dict_class=OrderedDict):\n    \"\"\"Determines appropriate setting for a given request, taking into account\n    the explicit setting on that request, and the setting in the session. If a\n    setting is a dictionary, they will be merged together using `dict_class`\n    \"\"\"\n\n    if session_setting is None:\n        return request_setting\n\n    if request_setting is None:\n        return session_setting\n\n    # Bypass if not a dictionary (e.g. verify)\n    if not (\n        isinstance(session_setting, Mapping) and isinstance(request_setting, M"}, {"start_line": 0, "end_line": 2000, "belongs_to": {"file_name": "api.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "\"\"\"\nrequests.api\n~~~~~~~~~~~~\n\nThis module implements the Requests API.\n\n:copyright: (c) 2012 by Kenneth Reitz.\n:license: Apache2, see LICENSE for more details.\n\"\"\"\n\nfrom . import sessions\n\n\ndef request(method, url, **kwargs):\n    \"\"\"Constructs and sends a :class:`Request <Request>`.\n\n    :param method: method for the new :class:`Request` object: ``GET``, ``OPTIONS``, ``HEAD``, ``POST``, ``PUT``, ``PATCH``, or ``DELETE``.\n    :param url: URL for the new :class:`Request` object.\n    :param params: (optional) Dictionary, list of tuples or bytes to send\n        in the query string for the :class:`Request`.\n    :param data: (optional) Dictionary, list of tuples, bytes, or file-like\n        object to send in the body of the :class:`Request`.\n    :param json: (optional) A JSON serializable Python object to send in the body of the :class:`Request`.\n    :param headers: (optional) Dictionary of HTTP Headers to send with the :class:`Request`.\n    :param cookies: (optional) Dict or CookieJar object to send with the :class:`Request`.\n    :param files: (optional) Dictionary of ``'name': file-like-objects`` (or ``{'name': file-tuple}``) for multipart encoding upload.\n        ``file-tuple`` can be a 2-tuple ``('filename', fileobj)``, 3-tuple ``('filename', fileobj, 'content_type')``\n        or a 4-tuple ``('filename', fileobj, 'content_type', custom_headers)``, where ``'content_type'`` is a string\n        defining the content type of the given file and ``custom_headers`` a dict-like object containing additional headers\n        to add for the file.\n    :param auth: (optional) Auth tuple to enable Basic/Digest/Custom HTTP Auth.\n    :param timeout: (optional) How many seconds to wait for the server to send data\n        before giving up, as a float, or a :ref:`(connect timeout, read\n        timeout) <timeouts>` tuple.\n    :type timeout: float or tuple\n    :param allow_redirects: (optional) Boolean. Enable/disable GET/OPTIONS/POST/PUT/PATCH/DELETE/HEAD redirection. Defaults to ``True``"}, {"start_line": 14000, "end_line": 16000, "belongs_to": {"file_name": "sessions.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "ry of headers to be sent on each\n        #: :class:`Request <Request>` sent from this\n        #: :class:`Session <Session>`.\n        self.headers = default_headers()\n\n        #: Default Authentication tuple or object to attach to\n        #: :class:`Request <Request>`.\n        self.auth = None\n\n        #: Dictionary mapping protocol or protocol and host to the URL of the proxy\n        #: (e.g. {'http': 'foo.bar:3128', 'http://host.name': 'foo.bar:4012'}) to\n        #: be used on each :class:`Request <Request>`.\n        self.proxies = {}\n\n        #: Event-handling hooks.\n        self.hooks = default_hooks()\n\n        #: Dictionary of querystring data to attach to each\n        #: :class:`Request <Request>`. The dictionary values may be lists for\n        #: representing multivalued query parameters.\n        self.params = {}\n\n        #: Stream response content default.\n        self.stream = False\n\n        #: SSL Verification default.\n        #: Defaults to `True`, requiring requests to verify the TLS certificate at the\n        #: remote end.\n        #: If verify is set to `False`, requests will accept any TLS certificate\n        #: presented by the server, and will ignore hostname mismatches and/or\n        #: expired certificates, which will make your application vulnerable to\n        #: man-in-the-middle (MitM) attacks.\n        #: Only set this to `False` for testing.\n        self.verify = True\n\n        #: SSL client certificate default, if String, path to ssl client\n        #: cert file (.pem). If Tuple, ('cert', 'key') pair.\n        self.cert = None\n\n        #: Maximum number of redirects allowed. If the request exceeds this\n        #: limit, a :class:`TooManyRedirects` exception is raised.\n        #: This defaults to requests.models.DEFAULT_REDIRECT_LIMIT, which is\n        #: 30.\n        self.max_redirects = DEFAULT_REDIRECT_LIMIT\n\n        #: Trust environment settings for proxy configuration, default\n        #: authentication and similar.\n        self.trust_env = Tru"}, {"start_line": 12000, "end_line": 14000, "belongs_to": {"file_name": "sessions.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "          username, password = None, None\n\n        # urllib3 handles proxy authorization for us in the standard adapter.\n        # Avoid appending this to TLS tunneled requests where it may be leaked.\n        if not scheme.startswith(\"https\") and username and password:\n            headers[\"Proxy-Authorization\"] = _basic_auth_str(username, password)\n\n        return new_proxies\n\n    def rebuild_method(self, prepared_request, response):\n        \"\"\"When being redirected we may want to change the method of the request\n        based on certain specs or browser behavior.\n        \"\"\"\n        method = prepared_request.method\n\n        # https://tools.ietf.org/html/rfc7231#section-6.4.4\n        if response.status_code == codes.see_other and method != \"HEAD\":\n            method = \"GET\"\n\n        # Do what the browsers do, despite standards...\n        # First, turn 302s into GETs.\n        if response.status_code == codes.found and method != \"HEAD\":\n            method = \"GET\"\n\n        # Second, if a POST is responded to with a 301, turn it into a GET.\n        # This bizarre behaviour is explained in Issue 1704.\n        if response.status_code == codes.moved and method == \"POST\":\n            method = \"GET\"\n\n        prepared_request.method = method\n\n\nclass Session(SessionRedirectMixin):\n    \"\"\"A Requests session.\n\n    Provides cookie persistence, connection-pooling, and configuration.\n\n    Basic Usage::\n\n      >>> import requests\n      >>> s = requests.Session()\n      >>> s.get('https://httpbin.org/get')\n      <Response [200]>\n\n    Or as a context manager::\n\n      >>> with requests.Session() as s:\n      ...     s.get('https://httpbin.org/get')\n      <Response [200]>\n    \"\"\"\n\n    __attrs__ = [\n        \"headers\",\n        \"cookies\",\n        \"auth\",\n        \"proxies\",\n        \"hooks\",\n        \"params\",\n        \"verify\",\n        \"cert\",\n        \"adapters\",\n        \"stream\",\n        \"trust_env\",\n        \"max_redirects\",\n    ]\n\n    def __init__(self):\n        #: A case-insensitive dictiona"}, {"start_line": 3000, "end_line": 5000, "belongs_to": {"file_name": "__init__.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "\n\n# Check imported dependencies for compatibility.\ntry:\n    check_compatibility(\n        urllib3.__version__, chardet_version, charset_normalizer_version\n    )\nexcept (AssertionError, ValueError):\n    warnings.warn(\n        \"urllib3 ({}) or chardet ({})/charset_normalizer ({}) doesn't match a supported \"\n        \"version!\".format(\n            urllib3.__version__, chardet_version, charset_normalizer_version\n        ),\n        RequestsDependencyWarning,\n    )\n\n# Attempt to enable urllib3's fallback for SNI support\n# if the standard library doesn't support SNI or the\n# 'ssl' library isn't available.\ntry:\n    try:\n        import ssl\n    except ImportError:\n        ssl = None\n\n    if not getattr(ssl, \"HAS_SNI\", False):\n        from urllib3.contrib import pyopenssl\n\n        pyopenssl.inject_into_urllib3()\n\n        # Check cryptography version\n        from cryptography import __version__ as cryptography_version\n\n        _check_cryptography(cryptography_version)\nexcept ImportError:\n    pass\n\n# urllib3's DependencyWarnings should be silenced.\nfrom urllib3.exceptions import DependencyWarning\n\nwarnings.simplefilter(\"ignore\", DependencyWarning)\n\n# Set default logging handler to avoid \"No handler found\" warnings.\nimport logging\nfrom logging import NullHandler\n\nfrom . import packages, utils\nfrom .__version__ import (\n    __author__,\n    __author_email__,\n    __build__,\n    __cake__,\n    __copyright__,\n    __description__,\n    __license__,\n    __title__,\n    __url__,\n    __version__,\n)\nfrom .api import delete, get, head, options, patch, post, put, request\nfrom .exceptions import (\n    ConnectionError,\n    ConnectTimeout,\n    FileModeWarning,\n    HTTPError,\n    JSONDecodeError,\n    ReadTimeout,\n    RequestException,\n    Timeout,\n    TooManyRedirects,\n    URLRequired,\n)\nfrom .models import PreparedRequest, Request, Response\nfrom .sessions import Session, session\nfrom .status_codes import codes\n\nlogging.getLogger(__name__).addHandler(NullHandler())\n\n# FileModeWarnings go off per the "}, {"start_line": 2000, "end_line": 4000, "belongs_to": {"file_name": "test_requests.py", "upper_path": "/data2/raymone/swebench-repos/requests/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": " requests.session\n        requests.session().get\n        requests.session().head\n        requests.get\n        requests.head\n        requests.put\n        requests.patch\n        requests.post\n        # Not really an entry point, but people rely on it.\n        from requests.packages.urllib3.poolmanager import PoolManager  # noqa:F401\n\n    @pytest.mark.parametrize(\n        \"exception, url\",\n        (\n            (MissingSchema, \"hiwpefhipowhefopw\"),\n            (InvalidSchema, \"localhost:3128\"),\n            (InvalidSchema, \"localhost.localdomain:3128/\"),\n            (InvalidSchema, \"10.122.1.1:3128/\"),\n            (InvalidURL, \"http://\"),\n            (InvalidURL, \"http://*example.com\"),\n            (InvalidURL, \"http://.example.com\"),\n        ),\n    )\n    def test_invalid_url(self, exception, url):\n        with pytest.raises(exception):\n            requests.get(url)\n\n    def test_basic_building(self):\n        req = requests.Request()\n        req.url = \"http://kennethreitz.org/\"\n        req.data = {\"life\": \"42\"}\n\n        pr = req.prepare()\n        assert pr.url == req.url\n        assert pr.body == \"life=42\"\n\n    @pytest.mark.parametrize(\"method\", (\"GET\", \"HEAD\"))\n    def test_no_content_length(self, httpbin, method):\n        req = requests.Request(method, httpbin(method.lower())).prepare()\n        assert \"Content-Length\" not in req.headers\n\n    @pytest.mark.parametrize(\"method\", (\"POST\", \"PUT\", \"PATCH\", \"OPTIONS\"))\n    def test_no_body_content_length(self, httpbin, method):\n        req = requests.Request(method, httpbin(method.lower())).prepare()\n        assert req.headers[\"Content-Length\"] == \"0\"\n\n    @pytest.mark.parametrize(\"method\", (\"POST\", \"PUT\", \"PATCH\", \"OPTIONS\"))\n    def test_empty_content_length(self, httpbin, method):\n        req = requests.Request(method, httpbin(method.lower()), data=\"\").prepare()\n        assert req.headers[\"Content-Length\"] == \"0\"\n\n    def test_override_content_length(self, httpbin):\n        headers = {\"Content-Length\": \"not zero\"}\n       "}, {"start_line": 4000, "end_line": 5072, "belongs_to": {"file_name": "__init__.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": " urllib3's DependencyWarnings should be silenced.\nfrom urllib3.exceptions import DependencyWarning\n\nwarnings.simplefilter(\"ignore\", DependencyWarning)\n\n# Set default logging handler to avoid \"No handler found\" warnings.\nimport logging\nfrom logging import NullHandler\n\nfrom . import packages, utils\nfrom .__version__ import (\n    __author__,\n    __author_email__,\n    __build__,\n    __cake__,\n    __copyright__,\n    __description__,\n    __license__,\n    __title__,\n    __url__,\n    __version__,\n)\nfrom .api import delete, get, head, options, patch, post, put, request\nfrom .exceptions import (\n    ConnectionError,\n    ConnectTimeout,\n    FileModeWarning,\n    HTTPError,\n    JSONDecodeError,\n    ReadTimeout,\n    RequestException,\n    Timeout,\n    TooManyRedirects,\n    URLRequired,\n)\nfrom .models import PreparedRequest, Request, Response\nfrom .sessions import Session, session\nfrom .status_codes import codes\n\nlogging.getLogger(__name__).addHandler(NullHandler())\n\n# FileModeWarnings go off per the default.\nwarnings.simplefilter(\"default\", FileModeWarning, append=True)\n"}, {"start_line": 15000, "end_line": 17000, "belongs_to": {"file_name": "sessions.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "y the TLS certificate at the\n        #: remote end.\n        #: If verify is set to `False`, requests will accept any TLS certificate\n        #: presented by the server, and will ignore hostname mismatches and/or\n        #: expired certificates, which will make your application vulnerable to\n        #: man-in-the-middle (MitM) attacks.\n        #: Only set this to `False` for testing.\n        self.verify = True\n\n        #: SSL client certificate default, if String, path to ssl client\n        #: cert file (.pem). If Tuple, ('cert', 'key') pair.\n        self.cert = None\n\n        #: Maximum number of redirects allowed. If the request exceeds this\n        #: limit, a :class:`TooManyRedirects` exception is raised.\n        #: This defaults to requests.models.DEFAULT_REDIRECT_LIMIT, which is\n        #: 30.\n        self.max_redirects = DEFAULT_REDIRECT_LIMIT\n\n        #: Trust environment settings for proxy configuration, default\n        #: authentication and similar.\n        self.trust_env = True\n\n        #: A CookieJar containing all currently outstanding cookies set on this\n        #: session. By default it is a\n        #: :class:`RequestsCookieJar <requests.cookies.RequestsCookieJar>`, but\n        #: may be any other ``cookielib.CookieJar`` compatible object.\n        self.cookies = cookiejar_from_dict({})\n\n        # Default connection adapters.\n        self.adapters = OrderedDict()\n        self.mount(\"https://\", HTTPAdapter())\n        self.mount(\"http://\", HTTPAdapter())\n\n    def __enter__(self):\n        return self\n\n    def __exit__(self, *args):\n        self.close()\n\n    def prepare_request(self, request):\n        \"\"\"Constructs a :class:`PreparedRequest <PreparedRequest>` for\n        transmission and returns it. The :class:`PreparedRequest` has settings\n        merged from the :class:`Request <Request>` instance and those of the\n        :class:`Session`.\n\n        :param request: :class:`Request` instance to prepare with this\n            session's settings.\n        :rtype"}, {"start_line": 44000, "end_line": 46000, "belongs_to": {"file_name": "test_requests.py", "upper_path": "/data2/raymone/swebench-repos/requests/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "      s = requests.Session()\n        resp = s.request(\n            \"GET\",\n            httpbin(\"cookies/set?cookie=value\"),\n            allow_redirects=False,\n            headers={\"Host\": b\"httpbin.org\"},\n        )\n        assert resp.cookies.get(\"cookie\") == \"value\"\n\n    def test_links(self):\n        r = requests.Response()\n        r.headers = {\n            \"cache-control\": \"public, max-age=60, s-maxage=60\",\n            \"connection\": \"keep-alive\",\n            \"content-encoding\": \"gzip\",\n            \"content-type\": \"application/json; charset=utf-8\",\n            \"date\": \"Sat, 26 Jan 2013 16:47:56 GMT\",\n            \"etag\": '\"6ff6a73c0e446c1f61614769e3ceb778\"',\n            \"last-modified\": \"Sat, 26 Jan 2013 16:22:39 GMT\",\n            \"link\": (\n                \"<https://api.github.com/users/kennethreitz/repos?\"\n                'page=2&per_page=10>; rel=\"next\", <https://api.github.'\n                \"com/users/kennethreitz/repos?page=7&per_page=10>; \"\n                ' rel=\"last\"'\n            ),\n            \"server\": \"GitHub.com\",\n            \"status\": \"200 OK\",\n            \"vary\": \"Accept\",\n            \"x-content-type-options\": \"nosniff\",\n            \"x-github-media-type\": \"github.beta\",\n            \"x-ratelimit-limit\": \"60\",\n            \"x-ratelimit-remaining\": \"57\",\n        }\n        assert r.links[\"next\"][\"rel\"] == \"next\"\n\n    def test_cookie_parameters(self):\n        key = \"some_cookie\"\n        value = \"some_value\"\n        secure = True\n        domain = \"test.com\"\n        rest = {\"HttpOnly\": True}\n\n        jar = requests.cookies.RequestsCookieJar()\n        jar.set(key, value, secure=secure, domain=domain, rest=rest)\n\n        assert len(jar) == 1\n        assert \"some_cookie\" in jar\n\n        cookie = list(jar)[0]\n        assert cookie.secure == secure\n        assert cookie.domain == domain\n        assert cookie._rest[\"HttpOnly\"] == rest[\"HttpOnly\"]\n\n    def test_cookie_as_dict_keeps_len(self):\n        key = \"some_cookie\"\n        value = \"some_value\"\n\n        key1 = \"som"}], "retrieved_count": 10, "cost_time": 1.2028248310089111}
{"question": "Where are Requests' built-in adapter implementations located?", "answer": null, "relative_code_list": null, "ground_truth": "Requests' built-in adapter implementations are located in src/requests/adapters.py. The main adapter implementations include: 1) BaseAdapter class - abstract base class defining the adapter interface with send() and close() methods; 2) HTTPAdapter class - the primary concrete implementation that wraps urllib3's PoolManager for HTTP/HTTPS connections; 3) HTTPAdapter methods include __init__(), send(), build_response(), cert_verify(), init_poolmanager(), proxy_manager_for(), and connection pool management methods; 4) Helper functions like _urllib3_request_context() for preparing request context for urllib3; 5) Default configuration constants like DEFAULT_POOLSIZE, DEFAULT_RETRIES, DEFAULT_POOLBLOCK; 6) Exception handling and mapping from urllib3 exceptions to Requests exceptions. The adapters are mounted to Session objects in src/requests/sessions.py during Session.__init__() where HTTPAdapter instances are created and mounted for 'http://' and 'https://' URL schemes. Custom adapters can also be implemented by subclassing BaseAdapter and mounted to Sessions for specialized transport needs.", "score": null, "retrieved_content": [{"start_line": 28000, "end_line": 30000, "belongs_to": {"file_name": "sessions.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "vironment's proxies.\n            no_proxy = proxies.get(\"no_proxy\") if proxies is not None else None\n            env_proxies = get_environ_proxies(url, no_proxy=no_proxy)\n            for k, v in env_proxies.items():\n                proxies.setdefault(k, v)\n\n            # Look for requests environment configuration\n            # and be compatible with cURL.\n            if verify is True or verify is None:\n                verify = (\n                    os.environ.get(\"REQUESTS_CA_BUNDLE\")\n                    or os.environ.get(\"CURL_CA_BUNDLE\")\n                    or verify\n                )\n\n        # Merge all the kwargs.\n        proxies = merge_setting(proxies, self.proxies)\n        stream = merge_setting(stream, self.stream)\n        verify = merge_setting(verify, self.verify)\n        cert = merge_setting(cert, self.cert)\n\n        return {\"proxies\": proxies, \"stream\": stream, \"verify\": verify, \"cert\": cert}\n\n    def get_adapter(self, url):\n        \"\"\"\n        Returns the appropriate connection adapter for the given URL.\n\n        :rtype: requests.adapters.BaseAdapter\n        \"\"\"\n        for prefix, adapter in self.adapters.items():\n            if url.lower().startswith(prefix.lower()):\n                return adapter\n\n        # Nothing matches :-/\n        raise InvalidSchema(f\"No connection adapters were found for {url!r}\")\n\n    def close(self):\n        \"\"\"Closes all adapters and as such the session\"\"\"\n        for v in self.adapters.values():\n            v.close()\n\n    def mount(self, prefix, adapter):\n        \"\"\"Registers a connection adapter to a prefix.\n\n        Adapters are sorted in descending order by prefix length.\n        \"\"\"\n        self.adapters[prefix] = adapter\n        keys_to_move = [k for k in self.adapters if len(k) < len(prefix)]\n\n        for key in keys_to_move:\n            self.adapters[key] = self.adapters.pop(key)\n\n    def __getstate__(self):\n        state = {attr: getattr(self, attr, None) for attr in self.__attrs__}\n        return state\n\n    def "}, {"start_line": 29000, "end_line": 30503, "belongs_to": {"file_name": "sessions.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "nnection adapter for the given URL.\n\n        :rtype: requests.adapters.BaseAdapter\n        \"\"\"\n        for prefix, adapter in self.adapters.items():\n            if url.lower().startswith(prefix.lower()):\n                return adapter\n\n        # Nothing matches :-/\n        raise InvalidSchema(f\"No connection adapters were found for {url!r}\")\n\n    def close(self):\n        \"\"\"Closes all adapters and as such the session\"\"\"\n        for v in self.adapters.values():\n            v.close()\n\n    def mount(self, prefix, adapter):\n        \"\"\"Registers a connection adapter to a prefix.\n\n        Adapters are sorted in descending order by prefix length.\n        \"\"\"\n        self.adapters[prefix] = adapter\n        keys_to_move = [k for k in self.adapters if len(k) < len(prefix)]\n\n        for key in keys_to_move:\n            self.adapters[key] = self.adapters.pop(key)\n\n    def __getstate__(self):\n        state = {attr: getattr(self, attr, None) for attr in self.__attrs__}\n        return state\n\n    def __setstate__(self, state):\n        for attr, value in state.items():\n            setattr(self, attr, value)\n\n\ndef session():\n    \"\"\"\n    Returns a :class:`Session` for context-management.\n\n    .. deprecated:: 1.0.0\n\n        This method has been deprecated since version 1.0.0 and is only kept for\n        backwards compatibility. New code should use :class:`~requests.sessions.Session`\n        to create a session. This may be removed at a future date.\n\n    :rtype: Session\n    \"\"\"\n    return Session()\n"}, {"start_line": 2000, "end_line": 4000, "belongs_to": {"file_name": "adapters.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "olmanager: \"PoolManager\",\n) -> \"(typing.Dict[str, typing.Any], typing.Dict[str, typing.Any])\":\n    host_params = {}\n    pool_kwargs = {}\n    parsed_request_url = urlparse(request.url)\n    scheme = parsed_request_url.scheme.lower()\n    port = parsed_request_url.port\n\n    cert_reqs = \"CERT_REQUIRED\"\n    if verify is False:\n        cert_reqs = \"CERT_NONE\"\n    elif isinstance(verify, str):\n        if not os.path.isdir(verify):\n            pool_kwargs[\"ca_certs\"] = verify\n        else:\n            pool_kwargs[\"ca_cert_dir\"] = verify\n    pool_kwargs[\"cert_reqs\"] = cert_reqs\n    if client_cert is not None:\n        if isinstance(client_cert, tuple) and len(client_cert) == 2:\n            pool_kwargs[\"cert_file\"] = client_cert[0]\n            pool_kwargs[\"key_file\"] = client_cert[1]\n        else:\n            # According to our docs, we allow users to specify just the client\n            # cert path\n            pool_kwargs[\"cert_file\"] = client_cert\n    host_params = {\n        \"scheme\": scheme,\n        \"host\": parsed_request_url.hostname,\n        \"port\": port,\n    }\n    return host_params, pool_kwargs\n\n\nclass BaseAdapter:\n    \"\"\"The Base Transport Adapter\"\"\"\n\n    def __init__(self):\n        super().__init__()\n\n    def send(\n        self, request, stream=False, timeout=None, verify=True, cert=None, proxies=None\n    ):\n        \"\"\"Sends PreparedRequest object. Returns Response object.\n\n        :param request: The :class:`PreparedRequest <PreparedRequest>` being sent.\n        :param stream: (optional) Whether to stream the request content.\n        :param timeout: (optional) How long to wait for the server to send\n            data before giving up, as a float, or a :ref:`(connect timeout,\n            read timeout) <timeouts>` tuple.\n        :type timeout: float or tuple\n        :param verify: (optional) Either a boolean, in which case it controls whether we verify\n            the server's TLS certificate, or a string, in which case it must be a path\n            to a CA bundle to use\n"}, {"start_line": 0, "end_line": 2000, "belongs_to": {"file_name": "adapters.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "\"\"\"\nrequests.adapters\n~~~~~~~~~~~~~~~~~\n\nThis module contains the transport adapters that Requests uses to define\nand maintain connections.\n\"\"\"\n\nimport os.path\nimport socket  # noqa: F401\nimport typing\nimport warnings\n\nfrom urllib3.exceptions import ClosedPoolError, ConnectTimeoutError\nfrom urllib3.exceptions import HTTPError as _HTTPError\nfrom urllib3.exceptions import InvalidHeader as _InvalidHeader\nfrom urllib3.exceptions import (\n    LocationValueError,\n    MaxRetryError,\n    NewConnectionError,\n    ProtocolError,\n)\nfrom urllib3.exceptions import ProxyError as _ProxyError\nfrom urllib3.exceptions import ReadTimeoutError, ResponseError\nfrom urllib3.exceptions import SSLError as _SSLError\nfrom urllib3.poolmanager import PoolManager, proxy_from_url\nfrom urllib3.util import Timeout as TimeoutSauce\nfrom urllib3.util import parse_url\nfrom urllib3.util.retry import Retry\n\nfrom .auth import _basic_auth_str\nfrom .compat import basestring, urlparse\nfrom .cookies import extract_cookies_to_jar\nfrom .exceptions import (\n    ConnectionError,\n    ConnectTimeout,\n    InvalidHeader,\n    InvalidProxyURL,\n    InvalidSchema,\n    InvalidURL,\n    ProxyError,\n    ReadTimeout,\n    RetryError,\n    SSLError,\n)\nfrom .models import Response\nfrom .structures import CaseInsensitiveDict\nfrom .utils import (\n    DEFAULT_CA_BUNDLE_PATH,\n    extract_zipped_paths,\n    get_auth_from_url,\n    get_encoding_from_headers,\n    prepend_scheme_if_needed,\n    select_proxy,\n    urldefragauth,\n)\n\ntry:\n    from urllib3.contrib.socks import SOCKSProxyManager\nexcept ImportError:\n\n    def SOCKSProxyManager(*args, **kwargs):\n        raise InvalidSchema(\"Missing dependencies for SOCKS support.\")\n\n\nif typing.TYPE_CHECKING:\n    from .models import PreparedRequest\n\n\nDEFAULT_POOLBLOCK = False\nDEFAULT_POOLSIZE = 10\nDEFAULT_RETRIES = 0\nDEFAULT_POOL_TIMEOUT = None\n\n\ndef _urllib3_request_context(\n    request: \"PreparedRequest\",\n    verify: \"bool | str | None\",\n    client_cert: \"typing.Tuple[str, str] | str | None\",\n    po"}, {"start_line": 57000, "end_line": 59000, "belongs_to": {"file_name": "test_requests.py", "upper_path": "/data2/raymone/swebench-repos/requests/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": ".mount(\"http://git\", HTTPAdapter())\n        s.mount(\"http://github\", HTTPAdapter())\n        s.mount(\"http://github.com\", HTTPAdapter())\n        s.mount(\"http://github.com/about/\", HTTPAdapter())\n        order = [\n            \"http://github.com/about/\",\n            \"http://github.com\",\n            \"http://github\",\n            \"http://git\",\n            \"https://\",\n            \"http://\",\n        ]\n        assert order == list(s.adapters)\n        s.mount(\"http://gittip\", HTTPAdapter())\n        s.mount(\"http://gittip.com\", HTTPAdapter())\n        s.mount(\"http://gittip.com/about/\", HTTPAdapter())\n        order = [\n            \"http://github.com/about/\",\n            \"http://gittip.com/about/\",\n            \"http://github.com\",\n            \"http://gittip.com\",\n            \"http://github\",\n            \"http://gittip\",\n            \"http://git\",\n            \"https://\",\n            \"http://\",\n        ]\n        assert order == list(s.adapters)\n        s2 = requests.Session()\n        s2.adapters = {\"http://\": HTTPAdapter()}\n        s2.mount(\"https://\", HTTPAdapter())\n        assert \"http://\" in s2.adapters\n        assert \"https://\" in s2.adapters\n\n    def test_session_get_adapter_prefix_matching(self):\n        prefix = \"https://example.com\"\n        more_specific_prefix = prefix + \"/some/path\"\n\n        url_matching_only_prefix = prefix + \"/another/path\"\n        url_matching_more_specific_prefix = more_specific_prefix + \"/longer/path\"\n        url_not_matching_prefix = \"https://another.example.com/\"\n\n        s = requests.Session()\n        prefix_adapter = HTTPAdapter()\n        more_specific_prefix_adapter = HTTPAdapter()\n        s.mount(prefix, prefix_adapter)\n        s.mount(more_specific_prefix, more_specific_prefix_adapter)\n\n        assert s.get_adapter(url_matching_only_prefix) is prefix_adapter\n        assert (\n            s.get_adapter(url_matching_more_specific_prefix)\n            is more_specific_prefix_adapter\n        )\n        assert s.get_adapter(url_not_matching_prefix) n"}, {"start_line": 3000, "end_line": 5000, "belongs_to": {"file_name": "adapters.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "     \"host\": parsed_request_url.hostname,\n        \"port\": port,\n    }\n    return host_params, pool_kwargs\n\n\nclass BaseAdapter:\n    \"\"\"The Base Transport Adapter\"\"\"\n\n    def __init__(self):\n        super().__init__()\n\n    def send(\n        self, request, stream=False, timeout=None, verify=True, cert=None, proxies=None\n    ):\n        \"\"\"Sends PreparedRequest object. Returns Response object.\n\n        :param request: The :class:`PreparedRequest <PreparedRequest>` being sent.\n        :param stream: (optional) Whether to stream the request content.\n        :param timeout: (optional) How long to wait for the server to send\n            data before giving up, as a float, or a :ref:`(connect timeout,\n            read timeout) <timeouts>` tuple.\n        :type timeout: float or tuple\n        :param verify: (optional) Either a boolean, in which case it controls whether we verify\n            the server's TLS certificate, or a string, in which case it must be a path\n            to a CA bundle to use\n        :param cert: (optional) Any user-provided SSL certificate to be trusted.\n        :param proxies: (optional) The proxies dictionary to apply to the request.\n        \"\"\"\n        raise NotImplementedError\n\n    def close(self):\n        \"\"\"Cleans up adapter specific items.\"\"\"\n        raise NotImplementedError\n\n\nclass HTTPAdapter(BaseAdapter):\n    \"\"\"The built-in HTTP Adapter for urllib3.\n\n    Provides a general-case interface for Requests sessions to contact HTTP and\n    HTTPS urls by implementing the Transport Adapter interface. This class will\n    usually be created by the :class:`Session <Session>` class under the\n    covers.\n\n    :param pool_connections: The number of urllib3 connection pools to cache.\n    :param pool_maxsize: The maximum number of connections to save in the pool.\n    :param max_retries: The maximum number of retries each connection\n        should attempt. Note, this applies only to failed DNS lookups, socket\n        connections and connection timeouts, never to"}, {"start_line": 58000, "end_line": 60000, "belongs_to": {"file_name": "test_requests.py", "upper_path": "/data2/raymone/swebench-repos/requests/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "http://\": HTTPAdapter()}\n        s2.mount(\"https://\", HTTPAdapter())\n        assert \"http://\" in s2.adapters\n        assert \"https://\" in s2.adapters\n\n    def test_session_get_adapter_prefix_matching(self):\n        prefix = \"https://example.com\"\n        more_specific_prefix = prefix + \"/some/path\"\n\n        url_matching_only_prefix = prefix + \"/another/path\"\n        url_matching_more_specific_prefix = more_specific_prefix + \"/longer/path\"\n        url_not_matching_prefix = \"https://another.example.com/\"\n\n        s = requests.Session()\n        prefix_adapter = HTTPAdapter()\n        more_specific_prefix_adapter = HTTPAdapter()\n        s.mount(prefix, prefix_adapter)\n        s.mount(more_specific_prefix, more_specific_prefix_adapter)\n\n        assert s.get_adapter(url_matching_only_prefix) is prefix_adapter\n        assert (\n            s.get_adapter(url_matching_more_specific_prefix)\n            is more_specific_prefix_adapter\n        )\n        assert s.get_adapter(url_not_matching_prefix) not in (\n            prefix_adapter,\n            more_specific_prefix_adapter,\n        )\n\n    def test_session_get_adapter_prefix_matching_mixed_case(self):\n        mixed_case_prefix = \"hTtPs://eXamPle.CoM/MixEd_CAse_PREfix\"\n        url_matching_prefix = mixed_case_prefix + \"/full_url\"\n\n        s = requests.Session()\n        my_adapter = HTTPAdapter()\n        s.mount(mixed_case_prefix, my_adapter)\n\n        assert s.get_adapter(url_matching_prefix) is my_adapter\n\n    def test_session_get_adapter_prefix_matching_is_case_insensitive(self):\n        mixed_case_prefix = \"hTtPs://eXamPle.CoM/MixEd_CAse_PREfix\"\n        url_matching_prefix_with_different_case = (\n            \"HtTpS://exaMPLe.cOm/MiXeD_caSE_preFIX/another_url\"\n        )\n\n        s = requests.Session()\n        my_adapter = HTTPAdapter()\n        s.mount(mixed_case_prefix, my_adapter)\n\n        assert s.get_adapter(url_matching_prefix_with_different_case) is my_adapter\n\n    def test_session_get_adapter_prefix_with_trailing_slash(self"}, {"start_line": 4000, "end_line": 6000, "belongs_to": {"file_name": "adapters.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "        :param cert: (optional) Any user-provided SSL certificate to be trusted.\n        :param proxies: (optional) The proxies dictionary to apply to the request.\n        \"\"\"\n        raise NotImplementedError\n\n    def close(self):\n        \"\"\"Cleans up adapter specific items.\"\"\"\n        raise NotImplementedError\n\n\nclass HTTPAdapter(BaseAdapter):\n    \"\"\"The built-in HTTP Adapter for urllib3.\n\n    Provides a general-case interface for Requests sessions to contact HTTP and\n    HTTPS urls by implementing the Transport Adapter interface. This class will\n    usually be created by the :class:`Session <Session>` class under the\n    covers.\n\n    :param pool_connections: The number of urllib3 connection pools to cache.\n    :param pool_maxsize: The maximum number of connections to save in the pool.\n    :param max_retries: The maximum number of retries each connection\n        should attempt. Note, this applies only to failed DNS lookups, socket\n        connections and connection timeouts, never to requests where data has\n        made it to the server. By default, Requests does not retry failed\n        connections. If you need granular control over the conditions under\n        which we retry a request, import urllib3's ``Retry`` class and pass\n        that instead.\n    :param pool_block: Whether the connection pool should block for connections.\n\n    Usage::\n\n      >>> import requests\n      >>> s = requests.Session()\n      >>> a = requests.adapters.HTTPAdapter(max_retries=3)\n      >>> s.mount('http://', a)\n    \"\"\"\n\n    __attrs__ = [\n        \"max_retries\",\n        \"config\",\n        \"_pool_connections\",\n        \"_pool_maxsize\",\n        \"_pool_block\",\n    ]\n\n    def __init__(\n        self,\n        pool_connections=DEFAULT_POOLSIZE,\n        pool_maxsize=DEFAULT_POOLSIZE,\n        max_retries=DEFAULT_RETRIES,\n        pool_block=DEFAULT_POOLBLOCK,\n    ):\n        if max_retries == DEFAULT_RETRIES:\n            self.max_retries = Retry(0, read=False)\n        else:\n            self.max_retr"}, {"start_line": 5000, "end_line": 7000, "belongs_to": {"file_name": "adapters.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": " requests where data has\n        made it to the server. By default, Requests does not retry failed\n        connections. If you need granular control over the conditions under\n        which we retry a request, import urllib3's ``Retry`` class and pass\n        that instead.\n    :param pool_block: Whether the connection pool should block for connections.\n\n    Usage::\n\n      >>> import requests\n      >>> s = requests.Session()\n      >>> a = requests.adapters.HTTPAdapter(max_retries=3)\n      >>> s.mount('http://', a)\n    \"\"\"\n\n    __attrs__ = [\n        \"max_retries\",\n        \"config\",\n        \"_pool_connections\",\n        \"_pool_maxsize\",\n        \"_pool_block\",\n    ]\n\n    def __init__(\n        self,\n        pool_connections=DEFAULT_POOLSIZE,\n        pool_maxsize=DEFAULT_POOLSIZE,\n        max_retries=DEFAULT_RETRIES,\n        pool_block=DEFAULT_POOLBLOCK,\n    ):\n        if max_retries == DEFAULT_RETRIES:\n            self.max_retries = Retry(0, read=False)\n        else:\n            self.max_retries = Retry.from_int(max_retries)\n        self.config = {}\n        self.proxy_manager = {}\n\n        super().__init__()\n\n        self._pool_connections = pool_connections\n        self._pool_maxsize = pool_maxsize\n        self._pool_block = pool_block\n\n        self.init_poolmanager(pool_connections, pool_maxsize, block=pool_block)\n\n    def __getstate__(self):\n        return {attr: getattr(self, attr, None) for attr in self.__attrs__}\n\n    def __setstate__(self, state):\n        # Can't handle by adding 'proxy_manager' to self.__attrs__ because\n        # self.poolmanager uses a lambda function, which isn't pickleable.\n        self.proxy_manager = {}\n        self.config = {}\n\n        for attr, value in state.items():\n            setattr(self, attr, value)\n\n        self.init_poolmanager(\n            self._pool_connections, self._pool_maxsize, block=self._pool_block\n        )\n\n    def init_poolmanager(\n        self, connections, maxsize, block=DEFAULT_POOLBLOCK, **pool_kwargs\n    ):\n        \""}, {"start_line": 59000, "end_line": 61000, "belongs_to": {"file_name": "test_requests.py", "upper_path": "/data2/raymone/swebench-repos/requests/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "ot in (\n            prefix_adapter,\n            more_specific_prefix_adapter,\n        )\n\n    def test_session_get_adapter_prefix_matching_mixed_case(self):\n        mixed_case_prefix = \"hTtPs://eXamPle.CoM/MixEd_CAse_PREfix\"\n        url_matching_prefix = mixed_case_prefix + \"/full_url\"\n\n        s = requests.Session()\n        my_adapter = HTTPAdapter()\n        s.mount(mixed_case_prefix, my_adapter)\n\n        assert s.get_adapter(url_matching_prefix) is my_adapter\n\n    def test_session_get_adapter_prefix_matching_is_case_insensitive(self):\n        mixed_case_prefix = \"hTtPs://eXamPle.CoM/MixEd_CAse_PREfix\"\n        url_matching_prefix_with_different_case = (\n            \"HtTpS://exaMPLe.cOm/MiXeD_caSE_preFIX/another_url\"\n        )\n\n        s = requests.Session()\n        my_adapter = HTTPAdapter()\n        s.mount(mixed_case_prefix, my_adapter)\n\n        assert s.get_adapter(url_matching_prefix_with_different_case) is my_adapter\n\n    def test_session_get_adapter_prefix_with_trailing_slash(self):\n        # from issue #6935\n        prefix = \"https://example.com/\"  # trailing slash\n        url_matching_prefix = \"https://example.com/some/path\"\n        url_not_matching_prefix = \"https://example.com.other.com/some/path\"\n\n        s = requests.Session()\n        adapter = HTTPAdapter()\n        s.mount(prefix, adapter)\n\n        assert s.get_adapter(url_matching_prefix) is adapter\n        assert s.get_adapter(url_not_matching_prefix) is not adapter\n\n    def test_session_get_adapter_prefix_without_trailing_slash(self):\n        # from issue #6935\n        prefix = \"https://example.com\"  # no trailing slash\n        url_matching_prefix = \"https://example.com/some/path\"\n        url_extended_hostname = \"https://example.com.other.com/some/path\"\n\n        s = requests.Session()\n        adapter = HTTPAdapter()\n        s.mount(prefix, adapter)\n\n        assert s.get_adapter(url_matching_prefix) is adapter\n        assert s.get_adapter(url_extended_hostname) is adapter\n\n    def test_header_remove_is"}], "retrieved_count": 10, "cost_time": 1.1845250129699707}
{"question": "How does Requests implement its session management system for connection pooling?", "answer": null, "relative_code_list": null, "ground_truth": "Requests implements session management for connection pooling through several key mechanisms in src/requests/sessions.py and src/requests/adapters.py: 1) Session initialization - Session.__init__() creates HTTPAdapter instances and mounts them for 'http://' and 'https://' schemes using self.mount(); 2) Adapter delegation - Session.send() selects the appropriate adapter based on URL scheme and delegates to adapter.send(); 3) Connection pooling - HTTPAdapter uses urllib3's PoolManager for connection pooling with configurable pool sizes (pool_connections, pool_maxsize); 4) Connection lifecycle - HTTPAdapter.init_poolmanager() creates connection pools and manages their lifecycle; 5) Connection reuse - HTTPAdapter.send() uses urllib3's urlopen() which automatically reuses connections from the pool; 6) Thread safety - urllib3's connection pools are thread-safe, enabling concurrent access; 7) Connection limits - Pool sizes can be configured to prevent resource exhaustion; 8) Connection health - Pools automatically handle connection failures and create new connections as needed; 9) Resource cleanup - Session.close() and HTTPAdapter.close() properly clean up connection pools; 10) Configuration flexibility - Connection pooling parameters can be customized per adapter and per session.", "score": null, "retrieved_content": [{"start_line": 13000, "end_line": 15000, "belongs_to": {"file_name": "sessions.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "POST is responded to with a 301, turn it into a GET.\n        # This bizarre behaviour is explained in Issue 1704.\n        if response.status_code == codes.moved and method == \"POST\":\n            method = \"GET\"\n\n        prepared_request.method = method\n\n\nclass Session(SessionRedirectMixin):\n    \"\"\"A Requests session.\n\n    Provides cookie persistence, connection-pooling, and configuration.\n\n    Basic Usage::\n\n      >>> import requests\n      >>> s = requests.Session()\n      >>> s.get('https://httpbin.org/get')\n      <Response [200]>\n\n    Or as a context manager::\n\n      >>> with requests.Session() as s:\n      ...     s.get('https://httpbin.org/get')\n      <Response [200]>\n    \"\"\"\n\n    __attrs__ = [\n        \"headers\",\n        \"cookies\",\n        \"auth\",\n        \"proxies\",\n        \"hooks\",\n        \"params\",\n        \"verify\",\n        \"cert\",\n        \"adapters\",\n        \"stream\",\n        \"trust_env\",\n        \"max_redirects\",\n    ]\n\n    def __init__(self):\n        #: A case-insensitive dictionary of headers to be sent on each\n        #: :class:`Request <Request>` sent from this\n        #: :class:`Session <Session>`.\n        self.headers = default_headers()\n\n        #: Default Authentication tuple or object to attach to\n        #: :class:`Request <Request>`.\n        self.auth = None\n\n        #: Dictionary mapping protocol or protocol and host to the URL of the proxy\n        #: (e.g. {'http': 'foo.bar:3128', 'http://host.name': 'foo.bar:4012'}) to\n        #: be used on each :class:`Request <Request>`.\n        self.proxies = {}\n\n        #: Event-handling hooks.\n        self.hooks = default_hooks()\n\n        #: Dictionary of querystring data to attach to each\n        #: :class:`Request <Request>`. The dictionary values may be lists for\n        #: representing multivalued query parameters.\n        self.params = {}\n\n        #: Stream response content default.\n        self.stream = False\n\n        #: SSL Verification default.\n        #: Defaults to `True`, requiring requests to verif"}, {"start_line": 5000, "end_line": 7000, "belongs_to": {"file_name": "adapters.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": " requests where data has\n        made it to the server. By default, Requests does not retry failed\n        connections. If you need granular control over the conditions under\n        which we retry a request, import urllib3's ``Retry`` class and pass\n        that instead.\n    :param pool_block: Whether the connection pool should block for connections.\n\n    Usage::\n\n      >>> import requests\n      >>> s = requests.Session()\n      >>> a = requests.adapters.HTTPAdapter(max_retries=3)\n      >>> s.mount('http://', a)\n    \"\"\"\n\n    __attrs__ = [\n        \"max_retries\",\n        \"config\",\n        \"_pool_connections\",\n        \"_pool_maxsize\",\n        \"_pool_block\",\n    ]\n\n    def __init__(\n        self,\n        pool_connections=DEFAULT_POOLSIZE,\n        pool_maxsize=DEFAULT_POOLSIZE,\n        max_retries=DEFAULT_RETRIES,\n        pool_block=DEFAULT_POOLBLOCK,\n    ):\n        if max_retries == DEFAULT_RETRIES:\n            self.max_retries = Retry(0, read=False)\n        else:\n            self.max_retries = Retry.from_int(max_retries)\n        self.config = {}\n        self.proxy_manager = {}\n\n        super().__init__()\n\n        self._pool_connections = pool_connections\n        self._pool_maxsize = pool_maxsize\n        self._pool_block = pool_block\n\n        self.init_poolmanager(pool_connections, pool_maxsize, block=pool_block)\n\n    def __getstate__(self):\n        return {attr: getattr(self, attr, None) for attr in self.__attrs__}\n\n    def __setstate__(self, state):\n        # Can't handle by adding 'proxy_manager' to self.__attrs__ because\n        # self.poolmanager uses a lambda function, which isn't pickleable.\n        self.proxy_manager = {}\n        self.config = {}\n\n        for attr, value in state.items():\n            setattr(self, attr, value)\n\n        self.init_poolmanager(\n            self._pool_connections, self._pool_maxsize, block=self._pool_block\n        )\n\n    def init_poolmanager(\n        self, connections, maxsize, block=DEFAULT_POOLBLOCK, **pool_kwargs\n    ):\n        \""}, {"start_line": 0, "end_line": 2000, "belongs_to": {"file_name": "sessions.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "\"\"\"\nrequests.sessions\n~~~~~~~~~~~~~~~~~\n\nThis module provides a Session object to manage and persist settings across\nrequests (cookies, auth, proxies).\n\"\"\"\nimport os\nimport sys\nimport time\nfrom collections import OrderedDict\nfrom datetime import timedelta\n\nfrom ._internal_utils import to_native_string\nfrom .adapters import HTTPAdapter\nfrom .auth import _basic_auth_str\nfrom .compat import Mapping, cookielib, urljoin, urlparse\nfrom .cookies import (\n    RequestsCookieJar,\n    cookiejar_from_dict,\n    extract_cookies_to_jar,\n    merge_cookies,\n)\nfrom .exceptions import (\n    ChunkedEncodingError,\n    ContentDecodingError,\n    InvalidSchema,\n    TooManyRedirects,\n)\nfrom .hooks import default_hooks, dispatch_hook\n\n# formerly defined here, reexposed here for backward compatibility\nfrom .models import (  # noqa: F401\n    DEFAULT_REDIRECT_LIMIT,\n    REDIRECT_STATI,\n    PreparedRequest,\n    Request,\n)\nfrom .status_codes import codes\nfrom .structures import CaseInsensitiveDict\nfrom .utils import (  # noqa: F401\n    DEFAULT_PORTS,\n    default_headers,\n    get_auth_from_url,\n    get_environ_proxies,\n    get_netrc_auth,\n    requote_uri,\n    resolve_proxies,\n    rewind_body,\n    should_bypass_proxies,\n    to_key_val_list,\n)\n\n# Preferred clock, based on which one is more accurate on a given system.\nif sys.platform == \"win32\":\n    preferred_clock = time.perf_counter\nelse:\n    preferred_clock = time.time\n\n\ndef merge_setting(request_setting, session_setting, dict_class=OrderedDict):\n    \"\"\"Determines appropriate setting for a given request, taking into account\n    the explicit setting on that request, and the setting in the session. If a\n    setting is a dictionary, they will be merged together using `dict_class`\n    \"\"\"\n\n    if session_setting is None:\n        return request_setting\n\n    if request_setting is None:\n        return session_setting\n\n    # Bypass if not a dictionary (e.g. verify)\n    if not (\n        isinstance(session_setting, Mapping) and isinstance(request_setting, M"}, {"start_line": 15000, "end_line": 17000, "belongs_to": {"file_name": "sessions.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "y the TLS certificate at the\n        #: remote end.\n        #: If verify is set to `False`, requests will accept any TLS certificate\n        #: presented by the server, and will ignore hostname mismatches and/or\n        #: expired certificates, which will make your application vulnerable to\n        #: man-in-the-middle (MitM) attacks.\n        #: Only set this to `False` for testing.\n        self.verify = True\n\n        #: SSL client certificate default, if String, path to ssl client\n        #: cert file (.pem). If Tuple, ('cert', 'key') pair.\n        self.cert = None\n\n        #: Maximum number of redirects allowed. If the request exceeds this\n        #: limit, a :class:`TooManyRedirects` exception is raised.\n        #: This defaults to requests.models.DEFAULT_REDIRECT_LIMIT, which is\n        #: 30.\n        self.max_redirects = DEFAULT_REDIRECT_LIMIT\n\n        #: Trust environment settings for proxy configuration, default\n        #: authentication and similar.\n        self.trust_env = True\n\n        #: A CookieJar containing all currently outstanding cookies set on this\n        #: session. By default it is a\n        #: :class:`RequestsCookieJar <requests.cookies.RequestsCookieJar>`, but\n        #: may be any other ``cookielib.CookieJar`` compatible object.\n        self.cookies = cookiejar_from_dict({})\n\n        # Default connection adapters.\n        self.adapters = OrderedDict()\n        self.mount(\"https://\", HTTPAdapter())\n        self.mount(\"http://\", HTTPAdapter())\n\n    def __enter__(self):\n        return self\n\n    def __exit__(self, *args):\n        self.close()\n\n    def prepare_request(self, request):\n        \"\"\"Constructs a :class:`PreparedRequest <PreparedRequest>` for\n        transmission and returns it. The :class:`PreparedRequest` has settings\n        merged from the :class:`Request <Request>` instance and those of the\n        :class:`Session`.\n\n        :param request: :class:`Request` instance to prepare with this\n            session's settings.\n        :rtype"}, {"start_line": 12000, "end_line": 14000, "belongs_to": {"file_name": "sessions.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "          username, password = None, None\n\n        # urllib3 handles proxy authorization for us in the standard adapter.\n        # Avoid appending this to TLS tunneled requests where it may be leaked.\n        if not scheme.startswith(\"https\") and username and password:\n            headers[\"Proxy-Authorization\"] = _basic_auth_str(username, password)\n\n        return new_proxies\n\n    def rebuild_method(self, prepared_request, response):\n        \"\"\"When being redirected we may want to change the method of the request\n        based on certain specs or browser behavior.\n        \"\"\"\n        method = prepared_request.method\n\n        # https://tools.ietf.org/html/rfc7231#section-6.4.4\n        if response.status_code == codes.see_other and method != \"HEAD\":\n            method = \"GET\"\n\n        # Do what the browsers do, despite standards...\n        # First, turn 302s into GETs.\n        if response.status_code == codes.found and method != \"HEAD\":\n            method = \"GET\"\n\n        # Second, if a POST is responded to with a 301, turn it into a GET.\n        # This bizarre behaviour is explained in Issue 1704.\n        if response.status_code == codes.moved and method == \"POST\":\n            method = \"GET\"\n\n        prepared_request.method = method\n\n\nclass Session(SessionRedirectMixin):\n    \"\"\"A Requests session.\n\n    Provides cookie persistence, connection-pooling, and configuration.\n\n    Basic Usage::\n\n      >>> import requests\n      >>> s = requests.Session()\n      >>> s.get('https://httpbin.org/get')\n      <Response [200]>\n\n    Or as a context manager::\n\n      >>> with requests.Session() as s:\n      ...     s.get('https://httpbin.org/get')\n      <Response [200]>\n    \"\"\"\n\n    __attrs__ = [\n        \"headers\",\n        \"cookies\",\n        \"auth\",\n        \"proxies\",\n        \"hooks\",\n        \"params\",\n        \"verify\",\n        \"cert\",\n        \"adapters\",\n        \"stream\",\n        \"trust_env\",\n        \"max_redirects\",\n    ]\n\n    def __init__(self):\n        #: A case-insensitive dictiona"}, {"start_line": 29000, "end_line": 30503, "belongs_to": {"file_name": "sessions.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "nnection adapter for the given URL.\n\n        :rtype: requests.adapters.BaseAdapter\n        \"\"\"\n        for prefix, adapter in self.adapters.items():\n            if url.lower().startswith(prefix.lower()):\n                return adapter\n\n        # Nothing matches :-/\n        raise InvalidSchema(f\"No connection adapters were found for {url!r}\")\n\n    def close(self):\n        \"\"\"Closes all adapters and as such the session\"\"\"\n        for v in self.adapters.values():\n            v.close()\n\n    def mount(self, prefix, adapter):\n        \"\"\"Registers a connection adapter to a prefix.\n\n        Adapters are sorted in descending order by prefix length.\n        \"\"\"\n        self.adapters[prefix] = adapter\n        keys_to_move = [k for k in self.adapters if len(k) < len(prefix)]\n\n        for key in keys_to_move:\n            self.adapters[key] = self.adapters.pop(key)\n\n    def __getstate__(self):\n        state = {attr: getattr(self, attr, None) for attr in self.__attrs__}\n        return state\n\n    def __setstate__(self, state):\n        for attr, value in state.items():\n            setattr(self, attr, value)\n\n\ndef session():\n    \"\"\"\n    Returns a :class:`Session` for context-management.\n\n    .. deprecated:: 1.0.0\n\n        This method has been deprecated since version 1.0.0 and is only kept for\n        backwards compatibility. New code should use :class:`~requests.sessions.Session`\n        to create a session. This may be removed at a future date.\n\n    :rtype: Session\n    \"\"\"\n    return Session()\n"}, {"start_line": 14000, "end_line": 16000, "belongs_to": {"file_name": "sessions.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "ry of headers to be sent on each\n        #: :class:`Request <Request>` sent from this\n        #: :class:`Session <Session>`.\n        self.headers = default_headers()\n\n        #: Default Authentication tuple or object to attach to\n        #: :class:`Request <Request>`.\n        self.auth = None\n\n        #: Dictionary mapping protocol or protocol and host to the URL of the proxy\n        #: (e.g. {'http': 'foo.bar:3128', 'http://host.name': 'foo.bar:4012'}) to\n        #: be used on each :class:`Request <Request>`.\n        self.proxies = {}\n\n        #: Event-handling hooks.\n        self.hooks = default_hooks()\n\n        #: Dictionary of querystring data to attach to each\n        #: :class:`Request <Request>`. The dictionary values may be lists for\n        #: representing multivalued query parameters.\n        self.params = {}\n\n        #: Stream response content default.\n        self.stream = False\n\n        #: SSL Verification default.\n        #: Defaults to `True`, requiring requests to verify the TLS certificate at the\n        #: remote end.\n        #: If verify is set to `False`, requests will accept any TLS certificate\n        #: presented by the server, and will ignore hostname mismatches and/or\n        #: expired certificates, which will make your application vulnerable to\n        #: man-in-the-middle (MitM) attacks.\n        #: Only set this to `False` for testing.\n        self.verify = True\n\n        #: SSL client certificate default, if String, path to ssl client\n        #: cert file (.pem). If Tuple, ('cert', 'key') pair.\n        self.cert = None\n\n        #: Maximum number of redirects allowed. If the request exceeds this\n        #: limit, a :class:`TooManyRedirects` exception is raised.\n        #: This defaults to requests.models.DEFAULT_REDIRECT_LIMIT, which is\n        #: 30.\n        self.max_redirects = DEFAULT_REDIRECT_LIMIT\n\n        #: Trust environment settings for proxy configuration, default\n        #: authentication and similar.\n        self.trust_env = Tru"}, {"start_line": 28000, "end_line": 30000, "belongs_to": {"file_name": "sessions.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "vironment's proxies.\n            no_proxy = proxies.get(\"no_proxy\") if proxies is not None else None\n            env_proxies = get_environ_proxies(url, no_proxy=no_proxy)\n            for k, v in env_proxies.items():\n                proxies.setdefault(k, v)\n\n            # Look for requests environment configuration\n            # and be compatible with cURL.\n            if verify is True or verify is None:\n                verify = (\n                    os.environ.get(\"REQUESTS_CA_BUNDLE\")\n                    or os.environ.get(\"CURL_CA_BUNDLE\")\n                    or verify\n                )\n\n        # Merge all the kwargs.\n        proxies = merge_setting(proxies, self.proxies)\n        stream = merge_setting(stream, self.stream)\n        verify = merge_setting(verify, self.verify)\n        cert = merge_setting(cert, self.cert)\n\n        return {\"proxies\": proxies, \"stream\": stream, \"verify\": verify, \"cert\": cert}\n\n    def get_adapter(self, url):\n        \"\"\"\n        Returns the appropriate connection adapter for the given URL.\n\n        :rtype: requests.adapters.BaseAdapter\n        \"\"\"\n        for prefix, adapter in self.adapters.items():\n            if url.lower().startswith(prefix.lower()):\n                return adapter\n\n        # Nothing matches :-/\n        raise InvalidSchema(f\"No connection adapters were found for {url!r}\")\n\n    def close(self):\n        \"\"\"Closes all adapters and as such the session\"\"\"\n        for v in self.adapters.values():\n            v.close()\n\n    def mount(self, prefix, adapter):\n        \"\"\"Registers a connection adapter to a prefix.\n\n        Adapters are sorted in descending order by prefix length.\n        \"\"\"\n        self.adapters[prefix] = adapter\n        keys_to_move = [k for k in self.adapters if len(k) < len(prefix)]\n\n        for key in keys_to_move:\n            self.adapters[key] = self.adapters.pop(key)\n\n    def __getstate__(self):\n        state = {attr: getattr(self, attr, None) for attr in self.__attrs__}\n        return state\n\n    def "}, {"start_line": 0, "end_line": 2000, "belongs_to": {"file_name": "adapters.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "\"\"\"\nrequests.adapters\n~~~~~~~~~~~~~~~~~\n\nThis module contains the transport adapters that Requests uses to define\nand maintain connections.\n\"\"\"\n\nimport os.path\nimport socket  # noqa: F401\nimport typing\nimport warnings\n\nfrom urllib3.exceptions import ClosedPoolError, ConnectTimeoutError\nfrom urllib3.exceptions import HTTPError as _HTTPError\nfrom urllib3.exceptions import InvalidHeader as _InvalidHeader\nfrom urllib3.exceptions import (\n    LocationValueError,\n    MaxRetryError,\n    NewConnectionError,\n    ProtocolError,\n)\nfrom urllib3.exceptions import ProxyError as _ProxyError\nfrom urllib3.exceptions import ReadTimeoutError, ResponseError\nfrom urllib3.exceptions import SSLError as _SSLError\nfrom urllib3.poolmanager import PoolManager, proxy_from_url\nfrom urllib3.util import Timeout as TimeoutSauce\nfrom urllib3.util import parse_url\nfrom urllib3.util.retry import Retry\n\nfrom .auth import _basic_auth_str\nfrom .compat import basestring, urlparse\nfrom .cookies import extract_cookies_to_jar\nfrom .exceptions import (\n    ConnectionError,\n    ConnectTimeout,\n    InvalidHeader,\n    InvalidProxyURL,\n    InvalidSchema,\n    InvalidURL,\n    ProxyError,\n    ReadTimeout,\n    RetryError,\n    SSLError,\n)\nfrom .models import Response\nfrom .structures import CaseInsensitiveDict\nfrom .utils import (\n    DEFAULT_CA_BUNDLE_PATH,\n    extract_zipped_paths,\n    get_auth_from_url,\n    get_encoding_from_headers,\n    prepend_scheme_if_needed,\n    select_proxy,\n    urldefragauth,\n)\n\ntry:\n    from urllib3.contrib.socks import SOCKSProxyManager\nexcept ImportError:\n\n    def SOCKSProxyManager(*args, **kwargs):\n        raise InvalidSchema(\"Missing dependencies for SOCKS support.\")\n\n\nif typing.TYPE_CHECKING:\n    from .models import PreparedRequest\n\n\nDEFAULT_POOLBLOCK = False\nDEFAULT_POOLSIZE = 10\nDEFAULT_RETRIES = 0\nDEFAULT_POOL_TIMEOUT = None\n\n\ndef _urllib3_request_context(\n    request: \"PreparedRequest\",\n    verify: \"bool | str | None\",\n    client_cert: \"typing.Tuple[str, str] | str | None\",\n    po"}, {"start_line": 0, "end_line": 2000, "belongs_to": {"file_name": "api.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "\"\"\"\nrequests.api\n~~~~~~~~~~~~\n\nThis module implements the Requests API.\n\n:copyright: (c) 2012 by Kenneth Reitz.\n:license: Apache2, see LICENSE for more details.\n\"\"\"\n\nfrom . import sessions\n\n\ndef request(method, url, **kwargs):\n    \"\"\"Constructs and sends a :class:`Request <Request>`.\n\n    :param method: method for the new :class:`Request` object: ``GET``, ``OPTIONS``, ``HEAD``, ``POST``, ``PUT``, ``PATCH``, or ``DELETE``.\n    :param url: URL for the new :class:`Request` object.\n    :param params: (optional) Dictionary, list of tuples or bytes to send\n        in the query string for the :class:`Request`.\n    :param data: (optional) Dictionary, list of tuples, bytes, or file-like\n        object to send in the body of the :class:`Request`.\n    :param json: (optional) A JSON serializable Python object to send in the body of the :class:`Request`.\n    :param headers: (optional) Dictionary of HTTP Headers to send with the :class:`Request`.\n    :param cookies: (optional) Dict or CookieJar object to send with the :class:`Request`.\n    :param files: (optional) Dictionary of ``'name': file-like-objects`` (or ``{'name': file-tuple}``) for multipart encoding upload.\n        ``file-tuple`` can be a 2-tuple ``('filename', fileobj)``, 3-tuple ``('filename', fileobj, 'content_type')``\n        or a 4-tuple ``('filename', fileobj, 'content_type', custom_headers)``, where ``'content_type'`` is a string\n        defining the content type of the given file and ``custom_headers`` a dict-like object containing additional headers\n        to add for the file.\n    :param auth: (optional) Auth tuple to enable Basic/Digest/Custom HTTP Auth.\n    :param timeout: (optional) How many seconds to wait for the server to send data\n        before giving up, as a float, or a :ref:`(connect timeout, read\n        timeout) <timeouts>` tuple.\n    :type timeout: float or tuple\n    :param allow_redirects: (optional) Boolean. Enable/disable GET/OPTIONS/POST/PUT/PATCH/DELETE/HEAD redirection. Defaults to ``True``"}], "retrieved_count": 10, "cost_time": 1.1497297286987305}
{"question": "How does Requests ensure backward compatibility when introducing new features?", "answer": null, "relative_code_list": null, "ground_truth": "Requests ensures backward compatibility through several strategies: 1) Deprecation warnings - Uses Python's warnings module to notify users of deprecated features before removal; 2) Gradual deprecation - Features are marked as deprecated in one version and removed in a later major version; 3) Parameter defaults - New parameters are added with sensible defaults that maintain existing behavior; 4) Method signatures - Existing method signatures are preserved, with new functionality added through optional parameters; 5) Import compatibility - Public APIs remain stable, with internal refactoring hidden from users; 6) Documentation - Clear migration guides and deprecation notices in documentation; 7) Testing - Comprehensive test suite ensures existing functionality continues to work; 8) Version management - Semantic versioning (semver) clearly indicates breaking vs. non-breaking changes; 9) Legacy support - Critical deprecated features may be maintained longer for enterprise users; 10) Community feedback - Deprecation decisions are discussed with the community before implementation.", "score": null, "retrieved_content": [{"start_line": 0, "end_line": 2000, "belongs_to": {"file_name": "cookies.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "\"\"\"\nrequests.cookies\n~~~~~~~~~~~~~~~~\n\nCompatibility code to be able to use `http.cookiejar.CookieJar` with requests.\n\nrequests.utils imports from here, so be careful with imports.\n\"\"\"\n\nimport calendar\nimport copy\nimport time\n\nfrom ._internal_utils import to_native_string\nfrom .compat import Morsel, MutableMapping, cookielib, urlparse, urlunparse\n\ntry:\n    import threading\nexcept ImportError:\n    import dummy_threading as threading\n\n\nclass MockRequest:\n    \"\"\"Wraps a `requests.Request` to mimic a `urllib2.Request`.\n\n    The code in `http.cookiejar.CookieJar` expects this interface in order to correctly\n    manage cookie policies, i.e., determine whether a cookie can be set, given the\n    domains of the request and the cookie.\n\n    The original request object is read-only. The client is responsible for collecting\n    the new headers via `get_new_headers()` and interpreting them appropriately. You\n    probably want `get_cookie_header`, defined below.\n    \"\"\"\n\n    def __init__(self, request):\n        self._r = request\n        self._new_headers = {}\n        self.type = urlparse(self._r.url).scheme\n\n    def get_type(self):\n        return self.type\n\n    def get_host(self):\n        return urlparse(self._r.url).netloc\n\n    def get_origin_req_host(self):\n        return self.get_host()\n\n    def get_full_url(self):\n        # Only return the response's URL if the user hadn't set the Host\n        # header\n        if not self._r.headers.get(\"Host\"):\n            return self._r.url\n        # If they did set it, retrieve it and reconstruct the expected domain\n        host = to_native_string(self._r.headers[\"Host\"], encoding=\"utf-8\")\n        parsed = urlparse(self._r.url)\n        # Reconstruct the URL as we expect it\n        return urlunparse(\n            [\n                parsed.scheme,\n                host,\n                parsed.path,\n                parsed.params,\n                parsed.query,\n                parsed.fragment,\n            ]\n        )\n\n    def is_unverifiable(self)"}, {"start_line": 0, "end_line": 2000, "belongs_to": {"file_name": "__init__.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "#   __\n#  /__)  _  _     _   _ _/   _\n# / (   (- (/ (/ (- _)  /  _)\n#          /\n\n\"\"\"\nRequests HTTP Library\n~~~~~~~~~~~~~~~~~~~~~\n\nRequests is an HTTP library, written in Python, for human beings.\nBasic GET usage:\n\n   >>> import requests\n   >>> r = requests.get('https://www.python.org')\n   >>> r.status_code\n   200\n   >>> b'Python is a programming language' in r.content\n   True\n\n... or POST:\n\n   >>> payload = dict(key1='value1', key2='value2')\n   >>> r = requests.post('https://httpbin.org/post', data=payload)\n   >>> print(r.text)\n   {\n     ...\n     \"form\": {\n       \"key1\": \"value1\",\n       \"key2\": \"value2\"\n     },\n     ...\n   }\n\nThe other HTTP methods are supported - see `requests.api`. Full documentation\nis at <https://requests.readthedocs.io>.\n\n:copyright: (c) 2017 by Kenneth Reitz.\n:license: Apache 2.0, see LICENSE for more details.\n\"\"\"\n\nimport warnings\n\nimport urllib3\n\nfrom .exceptions import RequestsDependencyWarning\n\ntry:\n    from charset_normalizer import __version__ as charset_normalizer_version\nexcept ImportError:\n    charset_normalizer_version = None\n\ntry:\n    from chardet import __version__ as chardet_version\nexcept ImportError:\n    chardet_version = None\n\n\ndef check_compatibility(urllib3_version, chardet_version, charset_normalizer_version):\n    urllib3_version = urllib3_version.split(\".\")\n    assert urllib3_version != [\"dev\"]  # Verify urllib3 isn't installed from git.\n\n    # Sometimes, urllib3 only reports its version as 16.1.\n    if len(urllib3_version) == 2:\n        urllib3_version.append(\"0\")\n\n    # Check urllib3 for compatibility.\n    major, minor, patch = urllib3_version  # noqa: F811\n    major, minor, patch = int(major), int(minor), int(patch)\n    # urllib3 >= 1.21.1\n    assert major >= 1\n    if major == 1:\n        assert minor >= 21\n\n    # Check charset_normalizer for compatibility.\n    if chardet_version:\n        major, minor, patch = chardet_version.split(\".\")[:3]\n        major, minor, patch = int(major), int(minor), int(patch)\n        # charde"}, {"start_line": 3000, "end_line": 5000, "belongs_to": {"file_name": "__init__.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "\n\n# Check imported dependencies for compatibility.\ntry:\n    check_compatibility(\n        urllib3.__version__, chardet_version, charset_normalizer_version\n    )\nexcept (AssertionError, ValueError):\n    warnings.warn(\n        \"urllib3 ({}) or chardet ({})/charset_normalizer ({}) doesn't match a supported \"\n        \"version!\".format(\n            urllib3.__version__, chardet_version, charset_normalizer_version\n        ),\n        RequestsDependencyWarning,\n    )\n\n# Attempt to enable urllib3's fallback for SNI support\n# if the standard library doesn't support SNI or the\n# 'ssl' library isn't available.\ntry:\n    try:\n        import ssl\n    except ImportError:\n        ssl = None\n\n    if not getattr(ssl, \"HAS_SNI\", False):\n        from urllib3.contrib import pyopenssl\n\n        pyopenssl.inject_into_urllib3()\n\n        # Check cryptography version\n        from cryptography import __version__ as cryptography_version\n\n        _check_cryptography(cryptography_version)\nexcept ImportError:\n    pass\n\n# urllib3's DependencyWarnings should be silenced.\nfrom urllib3.exceptions import DependencyWarning\n\nwarnings.simplefilter(\"ignore\", DependencyWarning)\n\n# Set default logging handler to avoid \"No handler found\" warnings.\nimport logging\nfrom logging import NullHandler\n\nfrom . import packages, utils\nfrom .__version__ import (\n    __author__,\n    __author_email__,\n    __build__,\n    __cake__,\n    __copyright__,\n    __description__,\n    __license__,\n    __title__,\n    __url__,\n    __version__,\n)\nfrom .api import delete, get, head, options, patch, post, put, request\nfrom .exceptions import (\n    ConnectionError,\n    ConnectTimeout,\n    FileModeWarning,\n    HTTPError,\n    JSONDecodeError,\n    ReadTimeout,\n    RequestException,\n    Timeout,\n    TooManyRedirects,\n    URLRequired,\n)\nfrom .models import PreparedRequest, Request, Response\nfrom .sessions import Session, session\nfrom .status_codes import codes\n\nlogging.getLogger(__name__).addHandler(NullHandler())\n\n# FileModeWarnings go off per the "}, {"start_line": 0, "end_line": 2000, "belongs_to": {"file_name": "sessions.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "\"\"\"\nrequests.sessions\n~~~~~~~~~~~~~~~~~\n\nThis module provides a Session object to manage and persist settings across\nrequests (cookies, auth, proxies).\n\"\"\"\nimport os\nimport sys\nimport time\nfrom collections import OrderedDict\nfrom datetime import timedelta\n\nfrom ._internal_utils import to_native_string\nfrom .adapters import HTTPAdapter\nfrom .auth import _basic_auth_str\nfrom .compat import Mapping, cookielib, urljoin, urlparse\nfrom .cookies import (\n    RequestsCookieJar,\n    cookiejar_from_dict,\n    extract_cookies_to_jar,\n    merge_cookies,\n)\nfrom .exceptions import (\n    ChunkedEncodingError,\n    ContentDecodingError,\n    InvalidSchema,\n    TooManyRedirects,\n)\nfrom .hooks import default_hooks, dispatch_hook\n\n# formerly defined here, reexposed here for backward compatibility\nfrom .models import (  # noqa: F401\n    DEFAULT_REDIRECT_LIMIT,\n    REDIRECT_STATI,\n    PreparedRequest,\n    Request,\n)\nfrom .status_codes import codes\nfrom .structures import CaseInsensitiveDict\nfrom .utils import (  # noqa: F401\n    DEFAULT_PORTS,\n    default_headers,\n    get_auth_from_url,\n    get_environ_proxies,\n    get_netrc_auth,\n    requote_uri,\n    resolve_proxies,\n    rewind_body,\n    should_bypass_proxies,\n    to_key_val_list,\n)\n\n# Preferred clock, based on which one is more accurate on a given system.\nif sys.platform == \"win32\":\n    preferred_clock = time.perf_counter\nelse:\n    preferred_clock = time.time\n\n\ndef merge_setting(request_setting, session_setting, dict_class=OrderedDict):\n    \"\"\"Determines appropriate setting for a given request, taking into account\n    the explicit setting on that request, and the setting in the session. If a\n    setting is a dictionary, they will be merged together using `dict_class`\n    \"\"\"\n\n    if session_setting is None:\n        return request_setting\n\n    if request_setting is None:\n        return session_setting\n\n    # Bypass if not a dictionary (e.g. verify)\n    if not (\n        isinstance(session_setting, Mapping) and isinstance(request_setting, M"}, {"start_line": 4000, "end_line": 5072, "belongs_to": {"file_name": "__init__.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": " urllib3's DependencyWarnings should be silenced.\nfrom urllib3.exceptions import DependencyWarning\n\nwarnings.simplefilter(\"ignore\", DependencyWarning)\n\n# Set default logging handler to avoid \"No handler found\" warnings.\nimport logging\nfrom logging import NullHandler\n\nfrom . import packages, utils\nfrom .__version__ import (\n    __author__,\n    __author_email__,\n    __build__,\n    __cake__,\n    __copyright__,\n    __description__,\n    __license__,\n    __title__,\n    __url__,\n    __version__,\n)\nfrom .api import delete, get, head, options, patch, post, put, request\nfrom .exceptions import (\n    ConnectionError,\n    ConnectTimeout,\n    FileModeWarning,\n    HTTPError,\n    JSONDecodeError,\n    ReadTimeout,\n    RequestException,\n    Timeout,\n    TooManyRedirects,\n    URLRequired,\n)\nfrom .models import PreparedRequest, Request, Response\nfrom .sessions import Session, session\nfrom .status_codes import codes\n\nlogging.getLogger(__name__).addHandler(NullHandler())\n\n# FileModeWarnings go off per the default.\nwarnings.simplefilter(\"default\", FileModeWarning, append=True)\n"}, {"start_line": 0, "end_line": 2000, "belongs_to": {"file_name": "structures.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "\"\"\"\nrequests.structures\n~~~~~~~~~~~~~~~~~~~\n\nData structures that power Requests.\n\"\"\"\n\nfrom collections import OrderedDict\n\nfrom .compat import Mapping, MutableMapping\n\n\nclass CaseInsensitiveDict(MutableMapping):\n    \"\"\"A case-insensitive ``dict``-like object.\n\n    Implements all methods and operations of\n    ``MutableMapping`` as well as dict's ``copy``. Also\n    provides ``lower_items``.\n\n    All keys are expected to be strings. The structure remembers the\n    case of the last key to be set, and ``iter(instance)``,\n    ``keys()``, ``items()``, ``iterkeys()``, and ``iteritems()``\n    will contain case-sensitive keys. However, querying and contains\n    testing is case insensitive::\n\n        cid = CaseInsensitiveDict()\n        cid['Accept'] = 'application/json'\n        cid['aCCEPT'] == 'application/json'  # True\n        list(cid) == ['Accept']  # True\n\n    For example, ``headers['content-encoding']`` will return the\n    value of a ``'Content-Encoding'`` response header, regardless\n    of how the header name was originally stored.\n\n    If the constructor, ``.update``, or equality comparison\n    operations are given keys that have equal ``.lower()``s, the\n    behavior is undefined.\n    \"\"\"\n\n    def __init__(self, data=None, **kwargs):\n        self._store = OrderedDict()\n        if data is None:\n            data = {}\n        self.update(data, **kwargs)\n\n    def __setitem__(self, key, value):\n        # Use the lowercased key for lookups, but store the actual\n        # key alongside the value.\n        self._store[key.lower()] = (key, value)\n\n    def __getitem__(self, key):\n        return self._store[key.lower()][1]\n\n    def __delitem__(self, key):\n        del self._store[key.lower()]\n\n    def __iter__(self):\n        return (casedkey for casedkey, mappedvalue in self._store.values())\n\n    def __len__(self):\n        return len(self._store)\n\n    def lower_items(self):\n        \"\"\"Like iteritems(), but with all lowercase keys.\"\"\"\n        return ((lowerkey, keyval[1]) for (lowe"}, {"start_line": 13000, "end_line": 15000, "belongs_to": {"file_name": "sessions.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "POST is responded to with a 301, turn it into a GET.\n        # This bizarre behaviour is explained in Issue 1704.\n        if response.status_code == codes.moved and method == \"POST\":\n            method = \"GET\"\n\n        prepared_request.method = method\n\n\nclass Session(SessionRedirectMixin):\n    \"\"\"A Requests session.\n\n    Provides cookie persistence, connection-pooling, and configuration.\n\n    Basic Usage::\n\n      >>> import requests\n      >>> s = requests.Session()\n      >>> s.get('https://httpbin.org/get')\n      <Response [200]>\n\n    Or as a context manager::\n\n      >>> with requests.Session() as s:\n      ...     s.get('https://httpbin.org/get')\n      <Response [200]>\n    \"\"\"\n\n    __attrs__ = [\n        \"headers\",\n        \"cookies\",\n        \"auth\",\n        \"proxies\",\n        \"hooks\",\n        \"params\",\n        \"verify\",\n        \"cert\",\n        \"adapters\",\n        \"stream\",\n        \"trust_env\",\n        \"max_redirects\",\n    ]\n\n    def __init__(self):\n        #: A case-insensitive dictionary of headers to be sent on each\n        #: :class:`Request <Request>` sent from this\n        #: :class:`Session <Session>`.\n        self.headers = default_headers()\n\n        #: Default Authentication tuple or object to attach to\n        #: :class:`Request <Request>`.\n        self.auth = None\n\n        #: Dictionary mapping protocol or protocol and host to the URL of the proxy\n        #: (e.g. {'http': 'foo.bar:3128', 'http://host.name': 'foo.bar:4012'}) to\n        #: be used on each :class:`Request <Request>`.\n        self.proxies = {}\n\n        #: Event-handling hooks.\n        self.hooks = default_hooks()\n\n        #: Dictionary of querystring data to attach to each\n        #: :class:`Request <Request>`. The dictionary values may be lists for\n        #: representing multivalued query parameters.\n        self.params = {}\n\n        #: Stream response content default.\n        self.stream = False\n\n        #: SSL Verification default.\n        #: Defaults to `True`, requiring requests to verif"}, {"start_line": 0, "end_line": 904, "belongs_to": {"file_name": "packages.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "import sys\n\nfrom .compat import chardet\n\n# This code exists for backwards compatibility reasons.\n# I don't like it either. Just look the other way. :)\n\nfor package in (\"urllib3\", \"idna\"):\n    locals()[package] = __import__(package)\n    # This traversal is apparently necessary such that the identities are\n    # preserved (requests.packages.urllib3.* is urllib3.*)\n    for mod in list(sys.modules):\n        if mod == package or mod.startswith(f\"{package}.\"):\n            sys.modules[f\"requests.packages.{mod}\"] = sys.modules[mod]\n\nif chardet is not None:\n    target = chardet.__name__\n    for mod in list(sys.modules):\n        if mod == target or mod.startswith(f\"{target}.\"):\n            imported_mod = sys.modules[mod]\n            sys.modules[f\"requests.packages.{mod}\"] = imported_mod\n            mod = mod.replace(target, \"chardet\")\n            sys.modules[f\"requests.packages.{mod}\"] = imported_mod\n"}, {"start_line": 0, "end_line": 2000, "belongs_to": {"file_name": "test_requests.py", "upper_path": "/data2/raymone/swebench-repos/requests/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "\"\"\"Tests for Requests.\"\"\"\n\nimport collections\nimport contextlib\nimport io\nimport json\nimport os\nimport pickle\nimport re\nimport tempfile\nimport threading\nimport warnings\nfrom unittest import mock\n\nimport pytest\nimport urllib3\nfrom urllib3.util import Timeout as Urllib3Timeout\n\nimport requests\nfrom requests.adapters import HTTPAdapter\nfrom requests.auth import HTTPDigestAuth, _basic_auth_str\nfrom requests.compat import (\n    JSONDecodeError,\n    Morsel,\n    MutableMapping,\n    builtin_str,\n    cookielib,\n    getproxies,\n    is_urllib3_1,\n    urlparse,\n)\nfrom requests.cookies import cookiejar_from_dict, morsel_to_cookie\nfrom requests.exceptions import (\n    ChunkedEncodingError,\n    ConnectionError,\n    ConnectTimeout,\n    ContentDecodingError,\n    InvalidHeader,\n    InvalidProxyURL,\n    InvalidSchema,\n    InvalidURL,\n    MissingSchema,\n    ProxyError,\n    ReadTimeout,\n    RequestException,\n    RetryError,\n)\nfrom requests.exceptions import SSLError as RequestsSSLError\nfrom requests.exceptions import Timeout, TooManyRedirects, UnrewindableBodyError\nfrom requests.hooks import default_hooks\nfrom requests.models import PreparedRequest, urlencode\nfrom requests.sessions import SessionRedirectMixin\nfrom requests.structures import CaseInsensitiveDict\n\nfrom . import SNIMissingWarning\nfrom .compat import StringIO\nfrom .testserver.server import TLSServer, consume_socket_content\nfrom .utils import override_environ\n\n# Requests to this URL should always fail with a connection timeout (nothing\n# listening on that port)\nTARPIT = \"http://10.255.255.1\"\n\n# This is to avoid waiting the timeout of using TARPIT\nINVALID_PROXY = \"http://localhost:1\"\n\ntry:\n    from ssl import SSLContext\n\n    del SSLContext\n    HAS_MODERN_SSL = True\nexcept ImportError:\n    HAS_MODERN_SSL = False\n\ntry:\n    requests.pyopenssl\n    HAS_PYOPENSSL = True\nexcept AttributeError:\n    HAS_PYOPENSSL = False\n\n\nclass TestRequests:\n    digest_auth_algo = (\"MD5\", \"SHA-256\", \"SHA-512\")\n\n    def test_entry_points(self):\n       "}, {"start_line": 0, "end_line": 2000, "belongs_to": {"file_name": "compat.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "\"\"\"\nrequests.compat\n~~~~~~~~~~~~~~~\n\nThis module previously handled import compatibility issues\nbetween Python 2 and Python 3. It remains for backwards\ncompatibility until the next major version.\n\"\"\"\n\nimport importlib\nimport sys\n\n# -------\n# urllib3\n# -------\nfrom urllib3 import __version__ as urllib3_version\n\n# Detect which major version of urllib3 is being used.\ntry:\n    is_urllib3_1 = int(urllib3_version.split(\".\")[0]) == 1\nexcept (TypeError, AttributeError):\n    # If we can't discern a version, prefer old functionality.\n    is_urllib3_1 = True\n\n# -------------------\n# Character Detection\n# -------------------\n\n\ndef _resolve_char_detection():\n    \"\"\"Find supported character detection libraries.\"\"\"\n    chardet = None\n    for lib in (\"chardet\", \"charset_normalizer\"):\n        if chardet is None:\n            try:\n                chardet = importlib.import_module(lib)\n            except ImportError:\n                pass\n    return chardet\n\n\nchardet = _resolve_char_detection()\n\n# -------\n# Pythons\n# -------\n\n# Syntax sugar.\n_ver = sys.version_info\n\n#: Python 2.x?\nis_py2 = _ver[0] == 2\n\n#: Python 3.x?\nis_py3 = _ver[0] == 3\n\n# json/simplejson module import resolution\nhas_simplejson = False\ntry:\n    import simplejson as json\n\n    has_simplejson = True\nexcept ImportError:\n    import json\n\nif has_simplejson:\n    from simplejson import JSONDecodeError\nelse:\n    from json import JSONDecodeError\n\n# Keep OrderedDict for backwards compatibility.\nfrom collections import OrderedDict\nfrom collections.abc import Callable, Mapping, MutableMapping\nfrom http import cookiejar as cookielib\nfrom http.cookies import Morsel\nfrom io import StringIO\n\n# --------------\n# Legacy Imports\n# --------------\nfrom urllib.parse import (\n    quote,\n    quote_plus,\n    unquote,\n    unquote_plus,\n    urldefrag,\n    urlencode,\n    urljoin,\n    urlparse,\n    urlsplit,\n    urlunparse,\n)\nfrom urllib.request import (\n    getproxies,\n    getproxies_environment,\n    parse_http_list,\n    proxy_bypass,\n    proxy_b"}], "retrieved_count": 10, "cost_time": 1.112192153930664}
{"question": "How does Requests' design facilitate integration with other HTTP libraries?", "answer": null, "relative_code_list": null, "ground_truth": "Requests' design facilitates integration with other HTTP libraries through several architectural features: 1) Adapter pattern - The adapter system allows custom transport implementations to be plugged in without changing the core API; 2) BaseAdapter interface - Custom adapters can be implemented by subclassing BaseAdapter and implementing send() and close() methods; 3) Session mounting - Custom adapters can be mounted to Sessions for specific URL schemes or protocols; 4) Request/Response objects - Standardized Request and Response objects provide a consistent interface regardless of underlying transport; 5) Hook system - Request and response hooks allow integration with external libraries for logging, monitoring, or modification; 6) Exception mapping - Custom adapters can map their exceptions to Requests exceptions for consistent error handling; 7) Configuration flexibility - Adapters can have their own configuration parameters while maintaining the Requests interface; 8) Protocol support - Different adapters can support different protocols (HTTP, HTTPS, FTP, custom protocols); 9) Testing support - The adapter pattern enables easy mocking and testing of transport behavior; 10) Extensibility - The design allows for gradual migration from other libraries by implementing adapters that wrap existing functionality.", "score": null, "retrieved_content": [{"start_line": 0, "end_line": 2000, "belongs_to": {"file_name": "__init__.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "#   __\n#  /__)  _  _     _   _ _/   _\n# / (   (- (/ (/ (- _)  /  _)\n#          /\n\n\"\"\"\nRequests HTTP Library\n~~~~~~~~~~~~~~~~~~~~~\n\nRequests is an HTTP library, written in Python, for human beings.\nBasic GET usage:\n\n   >>> import requests\n   >>> r = requests.get('https://www.python.org')\n   >>> r.status_code\n   200\n   >>> b'Python is a programming language' in r.content\n   True\n\n... or POST:\n\n   >>> payload = dict(key1='value1', key2='value2')\n   >>> r = requests.post('https://httpbin.org/post', data=payload)\n   >>> print(r.text)\n   {\n     ...\n     \"form\": {\n       \"key1\": \"value1\",\n       \"key2\": \"value2\"\n     },\n     ...\n   }\n\nThe other HTTP methods are supported - see `requests.api`. Full documentation\nis at <https://requests.readthedocs.io>.\n\n:copyright: (c) 2017 by Kenneth Reitz.\n:license: Apache 2.0, see LICENSE for more details.\n\"\"\"\n\nimport warnings\n\nimport urllib3\n\nfrom .exceptions import RequestsDependencyWarning\n\ntry:\n    from charset_normalizer import __version__ as charset_normalizer_version\nexcept ImportError:\n    charset_normalizer_version = None\n\ntry:\n    from chardet import __version__ as chardet_version\nexcept ImportError:\n    chardet_version = None\n\n\ndef check_compatibility(urllib3_version, chardet_version, charset_normalizer_version):\n    urllib3_version = urllib3_version.split(\".\")\n    assert urllib3_version != [\"dev\"]  # Verify urllib3 isn't installed from git.\n\n    # Sometimes, urllib3 only reports its version as 16.1.\n    if len(urllib3_version) == 2:\n        urllib3_version.append(\"0\")\n\n    # Check urllib3 for compatibility.\n    major, minor, patch = urllib3_version  # noqa: F811\n    major, minor, patch = int(major), int(minor), int(patch)\n    # urllib3 >= 1.21.1\n    assert major >= 1\n    if major == 1:\n        assert minor >= 21\n\n    # Check charset_normalizer for compatibility.\n    if chardet_version:\n        major, minor, patch = chardet_version.split(\".\")[:3]\n        major, minor, patch = int(major), int(minor), int(patch)\n        # charde"}, {"start_line": 13000, "end_line": 15000, "belongs_to": {"file_name": "sessions.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "POST is responded to with a 301, turn it into a GET.\n        # This bizarre behaviour is explained in Issue 1704.\n        if response.status_code == codes.moved and method == \"POST\":\n            method = \"GET\"\n\n        prepared_request.method = method\n\n\nclass Session(SessionRedirectMixin):\n    \"\"\"A Requests session.\n\n    Provides cookie persistence, connection-pooling, and configuration.\n\n    Basic Usage::\n\n      >>> import requests\n      >>> s = requests.Session()\n      >>> s.get('https://httpbin.org/get')\n      <Response [200]>\n\n    Or as a context manager::\n\n      >>> with requests.Session() as s:\n      ...     s.get('https://httpbin.org/get')\n      <Response [200]>\n    \"\"\"\n\n    __attrs__ = [\n        \"headers\",\n        \"cookies\",\n        \"auth\",\n        \"proxies\",\n        \"hooks\",\n        \"params\",\n        \"verify\",\n        \"cert\",\n        \"adapters\",\n        \"stream\",\n        \"trust_env\",\n        \"max_redirects\",\n    ]\n\n    def __init__(self):\n        #: A case-insensitive dictionary of headers to be sent on each\n        #: :class:`Request <Request>` sent from this\n        #: :class:`Session <Session>`.\n        self.headers = default_headers()\n\n        #: Default Authentication tuple or object to attach to\n        #: :class:`Request <Request>`.\n        self.auth = None\n\n        #: Dictionary mapping protocol or protocol and host to the URL of the proxy\n        #: (e.g. {'http': 'foo.bar:3128', 'http://host.name': 'foo.bar:4012'}) to\n        #: be used on each :class:`Request <Request>`.\n        self.proxies = {}\n\n        #: Event-handling hooks.\n        self.hooks = default_hooks()\n\n        #: Dictionary of querystring data to attach to each\n        #: :class:`Request <Request>`. The dictionary values may be lists for\n        #: representing multivalued query parameters.\n        self.params = {}\n\n        #: Stream response content default.\n        self.stream = False\n\n        #: SSL Verification default.\n        #: Defaults to `True`, requiring requests to verif"}, {"start_line": 0, "end_line": 2000, "belongs_to": {"file_name": "api.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "\"\"\"\nrequests.api\n~~~~~~~~~~~~\n\nThis module implements the Requests API.\n\n:copyright: (c) 2012 by Kenneth Reitz.\n:license: Apache2, see LICENSE for more details.\n\"\"\"\n\nfrom . import sessions\n\n\ndef request(method, url, **kwargs):\n    \"\"\"Constructs and sends a :class:`Request <Request>`.\n\n    :param method: method for the new :class:`Request` object: ``GET``, ``OPTIONS``, ``HEAD``, ``POST``, ``PUT``, ``PATCH``, or ``DELETE``.\n    :param url: URL for the new :class:`Request` object.\n    :param params: (optional) Dictionary, list of tuples or bytes to send\n        in the query string for the :class:`Request`.\n    :param data: (optional) Dictionary, list of tuples, bytes, or file-like\n        object to send in the body of the :class:`Request`.\n    :param json: (optional) A JSON serializable Python object to send in the body of the :class:`Request`.\n    :param headers: (optional) Dictionary of HTTP Headers to send with the :class:`Request`.\n    :param cookies: (optional) Dict or CookieJar object to send with the :class:`Request`.\n    :param files: (optional) Dictionary of ``'name': file-like-objects`` (or ``{'name': file-tuple}``) for multipart encoding upload.\n        ``file-tuple`` can be a 2-tuple ``('filename', fileobj)``, 3-tuple ``('filename', fileobj, 'content_type')``\n        or a 4-tuple ``('filename', fileobj, 'content_type', custom_headers)``, where ``'content_type'`` is a string\n        defining the content type of the given file and ``custom_headers`` a dict-like object containing additional headers\n        to add for the file.\n    :param auth: (optional) Auth tuple to enable Basic/Digest/Custom HTTP Auth.\n    :param timeout: (optional) How many seconds to wait for the server to send data\n        before giving up, as a float, or a :ref:`(connect timeout, read\n        timeout) <timeouts>` tuple.\n    :type timeout: float or tuple\n    :param allow_redirects: (optional) Boolean. Enable/disable GET/OPTIONS/POST/PUT/PATCH/DELETE/HEAD redirection. Defaults to ``True``"}, {"start_line": 21000, "end_line": 23000, "belongs_to": {"file_name": "adapters.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "ters.HTTPAdapter>`.\n\n        This should not be called from user code, and is only exposed for use\n        when subclassing the\n        :class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.\n\n        :param request: The :class:`PreparedRequest <PreparedRequest>` to add headers to.\n        :param kwargs: The keyword arguments from the call to send().\n        \"\"\"\n        pass\n\n    def proxy_headers(self, proxy):\n        \"\"\"Returns a dictionary of the headers to add to any request sent\n        through a proxy. This works with urllib3 magic to ensure that they are\n        correctly sent to the proxy, rather than in a tunnelled request if\n        CONNECT is being used.\n\n        This should not be called from user code, and is only exposed for use\n        when subclassing the\n        :class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.\n\n        :param proxy: The url of the proxy being used for this request.\n        :rtype: dict\n        \"\"\"\n        headers = {}\n        username, password = get_auth_from_url(proxy)\n\n        if username:\n            headers[\"Proxy-Authorization\"] = _basic_auth_str(username, password)\n\n        return headers\n\n    def send(\n        self, request, stream=False, timeout=None, verify=True, cert=None, proxies=None\n    ):\n        \"\"\"Sends PreparedRequest object. Returns Response object.\n\n        :param request: The :class:`PreparedRequest <PreparedRequest>` being sent.\n        :param stream: (optional) Whether to stream the request content.\n        :param timeout: (optional) How long to wait for the server to send\n            data before giving up, as a float, or a :ref:`(connect timeout,\n            read timeout) <timeouts>` tuple.\n        :type timeout: float or tuple or urllib3 Timeout object\n        :param verify: (optional) Either a boolean, in which case it controls whether\n            we verify the server's TLS certificate, or a string, in which case it\n            must be a path to a CA bundle to use\n        :param cert: (optional) Any user"}, {"start_line": 0, "end_line": 229, "belongs_to": {"file_name": "test_packages.py", "upper_path": "/data2/raymone/swebench-repos/requests/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "import requests\n\n\ndef test_can_access_urllib3_attribute():\n    requests.packages.urllib3\n\n\ndef test_can_access_idna_attribute():\n    requests.packages.idna\n\n\ndef test_can_access_chardet_attribute():\n    requests.packages.chardet\n"}, {"start_line": 4000, "end_line": 5072, "belongs_to": {"file_name": "__init__.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": " urllib3's DependencyWarnings should be silenced.\nfrom urllib3.exceptions import DependencyWarning\n\nwarnings.simplefilter(\"ignore\", DependencyWarning)\n\n# Set default logging handler to avoid \"No handler found\" warnings.\nimport logging\nfrom logging import NullHandler\n\nfrom . import packages, utils\nfrom .__version__ import (\n    __author__,\n    __author_email__,\n    __build__,\n    __cake__,\n    __copyright__,\n    __description__,\n    __license__,\n    __title__,\n    __url__,\n    __version__,\n)\nfrom .api import delete, get, head, options, patch, post, put, request\nfrom .exceptions import (\n    ConnectionError,\n    ConnectTimeout,\n    FileModeWarning,\n    HTTPError,\n    JSONDecodeError,\n    ReadTimeout,\n    RequestException,\n    Timeout,\n    TooManyRedirects,\n    URLRequired,\n)\nfrom .models import PreparedRequest, Request, Response\nfrom .sessions import Session, session\nfrom .status_codes import codes\n\nlogging.getLogger(__name__).addHandler(NullHandler())\n\n# FileModeWarnings go off per the default.\nwarnings.simplefilter(\"default\", FileModeWarning, append=True)\n"}, {"start_line": 3000, "end_line": 5000, "belongs_to": {"file_name": "__init__.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "\n\n# Check imported dependencies for compatibility.\ntry:\n    check_compatibility(\n        urllib3.__version__, chardet_version, charset_normalizer_version\n    )\nexcept (AssertionError, ValueError):\n    warnings.warn(\n        \"urllib3 ({}) or chardet ({})/charset_normalizer ({}) doesn't match a supported \"\n        \"version!\".format(\n            urllib3.__version__, chardet_version, charset_normalizer_version\n        ),\n        RequestsDependencyWarning,\n    )\n\n# Attempt to enable urllib3's fallback for SNI support\n# if the standard library doesn't support SNI or the\n# 'ssl' library isn't available.\ntry:\n    try:\n        import ssl\n    except ImportError:\n        ssl = None\n\n    if not getattr(ssl, \"HAS_SNI\", False):\n        from urllib3.contrib import pyopenssl\n\n        pyopenssl.inject_into_urllib3()\n\n        # Check cryptography version\n        from cryptography import __version__ as cryptography_version\n\n        _check_cryptography(cryptography_version)\nexcept ImportError:\n    pass\n\n# urllib3's DependencyWarnings should be silenced.\nfrom urllib3.exceptions import DependencyWarning\n\nwarnings.simplefilter(\"ignore\", DependencyWarning)\n\n# Set default logging handler to avoid \"No handler found\" warnings.\nimport logging\nfrom logging import NullHandler\n\nfrom . import packages, utils\nfrom .__version__ import (\n    __author__,\n    __author_email__,\n    __build__,\n    __cake__,\n    __copyright__,\n    __description__,\n    __license__,\n    __title__,\n    __url__,\n    __version__,\n)\nfrom .api import delete, get, head, options, patch, post, put, request\nfrom .exceptions import (\n    ConnectionError,\n    ConnectTimeout,\n    FileModeWarning,\n    HTTPError,\n    JSONDecodeError,\n    ReadTimeout,\n    RequestException,\n    Timeout,\n    TooManyRedirects,\n    URLRequired,\n)\nfrom .models import PreparedRequest, Request, Response\nfrom .sessions import Session, session\nfrom .status_codes import codes\n\nlogging.getLogger(__name__).addHandler(NullHandler())\n\n# FileModeWarnings go off per the "}, {"start_line": 4000, "end_line": 6000, "belongs_to": {"file_name": "adapters.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "        :param cert: (optional) Any user-provided SSL certificate to be trusted.\n        :param proxies: (optional) The proxies dictionary to apply to the request.\n        \"\"\"\n        raise NotImplementedError\n\n    def close(self):\n        \"\"\"Cleans up adapter specific items.\"\"\"\n        raise NotImplementedError\n\n\nclass HTTPAdapter(BaseAdapter):\n    \"\"\"The built-in HTTP Adapter for urllib3.\n\n    Provides a general-case interface for Requests sessions to contact HTTP and\n    HTTPS urls by implementing the Transport Adapter interface. This class will\n    usually be created by the :class:`Session <Session>` class under the\n    covers.\n\n    :param pool_connections: The number of urllib3 connection pools to cache.\n    :param pool_maxsize: The maximum number of connections to save in the pool.\n    :param max_retries: The maximum number of retries each connection\n        should attempt. Note, this applies only to failed DNS lookups, socket\n        connections and connection timeouts, never to requests where data has\n        made it to the server. By default, Requests does not retry failed\n        connections. If you need granular control over the conditions under\n        which we retry a request, import urllib3's ``Retry`` class and pass\n        that instead.\n    :param pool_block: Whether the connection pool should block for connections.\n\n    Usage::\n\n      >>> import requests\n      >>> s = requests.Session()\n      >>> a = requests.adapters.HTTPAdapter(max_retries=3)\n      >>> s.mount('http://', a)\n    \"\"\"\n\n    __attrs__ = [\n        \"max_retries\",\n        \"config\",\n        \"_pool_connections\",\n        \"_pool_maxsize\",\n        \"_pool_block\",\n    ]\n\n    def __init__(\n        self,\n        pool_connections=DEFAULT_POOLSIZE,\n        pool_maxsize=DEFAULT_POOLSIZE,\n        max_retries=DEFAULT_RETRIES,\n        pool_block=DEFAULT_POOLBLOCK,\n    ):\n        if max_retries == DEFAULT_RETRIES:\n            self.max_retries = Retry(0, read=False)\n        else:\n            self.max_retr"}, {"start_line": 0, "end_line": 2000, "belongs_to": {"file_name": "structures.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "\"\"\"\nrequests.structures\n~~~~~~~~~~~~~~~~~~~\n\nData structures that power Requests.\n\"\"\"\n\nfrom collections import OrderedDict\n\nfrom .compat import Mapping, MutableMapping\n\n\nclass CaseInsensitiveDict(MutableMapping):\n    \"\"\"A case-insensitive ``dict``-like object.\n\n    Implements all methods and operations of\n    ``MutableMapping`` as well as dict's ``copy``. Also\n    provides ``lower_items``.\n\n    All keys are expected to be strings. The structure remembers the\n    case of the last key to be set, and ``iter(instance)``,\n    ``keys()``, ``items()``, ``iterkeys()``, and ``iteritems()``\n    will contain case-sensitive keys. However, querying and contains\n    testing is case insensitive::\n\n        cid = CaseInsensitiveDict()\n        cid['Accept'] = 'application/json'\n        cid['aCCEPT'] == 'application/json'  # True\n        list(cid) == ['Accept']  # True\n\n    For example, ``headers['content-encoding']`` will return the\n    value of a ``'Content-Encoding'`` response header, regardless\n    of how the header name was originally stored.\n\n    If the constructor, ``.update``, or equality comparison\n    operations are given keys that have equal ``.lower()``s, the\n    behavior is undefined.\n    \"\"\"\n\n    def __init__(self, data=None, **kwargs):\n        self._store = OrderedDict()\n        if data is None:\n            data = {}\n        self.update(data, **kwargs)\n\n    def __setitem__(self, key, value):\n        # Use the lowercased key for lookups, but store the actual\n        # key alongside the value.\n        self._store[key.lower()] = (key, value)\n\n    def __getitem__(self, key):\n        return self._store[key.lower()][1]\n\n    def __delitem__(self, key):\n        del self._store[key.lower()]\n\n    def __iter__(self):\n        return (casedkey for casedkey, mappedvalue in self._store.values())\n\n    def __len__(self):\n        return len(self._store)\n\n    def lower_items(self):\n        \"\"\"Like iteritems(), but with all lowercase keys.\"\"\"\n        return ((lowerkey, keyval[1]) for (lowe"}, {"start_line": 0, "end_line": 2000, "belongs_to": {"file_name": "cookies.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "\"\"\"\nrequests.cookies\n~~~~~~~~~~~~~~~~\n\nCompatibility code to be able to use `http.cookiejar.CookieJar` with requests.\n\nrequests.utils imports from here, so be careful with imports.\n\"\"\"\n\nimport calendar\nimport copy\nimport time\n\nfrom ._internal_utils import to_native_string\nfrom .compat import Morsel, MutableMapping, cookielib, urlparse, urlunparse\n\ntry:\n    import threading\nexcept ImportError:\n    import dummy_threading as threading\n\n\nclass MockRequest:\n    \"\"\"Wraps a `requests.Request` to mimic a `urllib2.Request`.\n\n    The code in `http.cookiejar.CookieJar` expects this interface in order to correctly\n    manage cookie policies, i.e., determine whether a cookie can be set, given the\n    domains of the request and the cookie.\n\n    The original request object is read-only. The client is responsible for collecting\n    the new headers via `get_new_headers()` and interpreting them appropriately. You\n    probably want `get_cookie_header`, defined below.\n    \"\"\"\n\n    def __init__(self, request):\n        self._r = request\n        self._new_headers = {}\n        self.type = urlparse(self._r.url).scheme\n\n    def get_type(self):\n        return self.type\n\n    def get_host(self):\n        return urlparse(self._r.url).netloc\n\n    def get_origin_req_host(self):\n        return self.get_host()\n\n    def get_full_url(self):\n        # Only return the response's URL if the user hadn't set the Host\n        # header\n        if not self._r.headers.get(\"Host\"):\n            return self._r.url\n        # If they did set it, retrieve it and reconstruct the expected domain\n        host = to_native_string(self._r.headers[\"Host\"], encoding=\"utf-8\")\n        parsed = urlparse(self._r.url)\n        # Reconstruct the URL as we expect it\n        return urlunparse(\n            [\n                parsed.scheme,\n                host,\n                parsed.path,\n                parsed.params,\n                parsed.query,\n                parsed.fragment,\n            ]\n        )\n\n    def is_unverifiable(self)"}], "retrieved_count": 10, "cost_time": 1.0873267650604248}
{"question": "How does Requests implement its configuration management system?", "answer": null, "relative_code_list": null, "ground_truth": "Requests implements configuration management through a hierarchical system in src/requests/sessions.py: 1) Session-level defaults - Session.__init__() sets default values for headers, cookies, auth, proxies, verify, cert, etc.; 2) Configuration merging - merge_setting() function combines session-level and request-level settings with request settings taking precedence; 3) Environment integration - merge_environment_settings() integrates environment variables (proxies, certificates) when trust_env is enabled; 4) Adapter configuration - HTTPAdapter can be configured with pool sizes, retry policies, and connection parameters; 5) Per-request overrides - Individual requests can override session defaults through method parameters; 6) Persistent state - Session objects maintain configuration across multiple requests; 7) Context management - Sessions can be used as context managers for automatic cleanup; 8) Serialization support - Session configuration can be serialized/deserialized through __getstate__() and __setstate__(); 9) Hook configuration - Request and response hooks can be configured at session or request level; 10) Validation - Configuration parameters are validated and sanitized before use.", "score": null, "retrieved_content": [{"start_line": 13000, "end_line": 15000, "belongs_to": {"file_name": "sessions.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "POST is responded to with a 301, turn it into a GET.\n        # This bizarre behaviour is explained in Issue 1704.\n        if response.status_code == codes.moved and method == \"POST\":\n            method = \"GET\"\n\n        prepared_request.method = method\n\n\nclass Session(SessionRedirectMixin):\n    \"\"\"A Requests session.\n\n    Provides cookie persistence, connection-pooling, and configuration.\n\n    Basic Usage::\n\n      >>> import requests\n      >>> s = requests.Session()\n      >>> s.get('https://httpbin.org/get')\n      <Response [200]>\n\n    Or as a context manager::\n\n      >>> with requests.Session() as s:\n      ...     s.get('https://httpbin.org/get')\n      <Response [200]>\n    \"\"\"\n\n    __attrs__ = [\n        \"headers\",\n        \"cookies\",\n        \"auth\",\n        \"proxies\",\n        \"hooks\",\n        \"params\",\n        \"verify\",\n        \"cert\",\n        \"adapters\",\n        \"stream\",\n        \"trust_env\",\n        \"max_redirects\",\n    ]\n\n    def __init__(self):\n        #: A case-insensitive dictionary of headers to be sent on each\n        #: :class:`Request <Request>` sent from this\n        #: :class:`Session <Session>`.\n        self.headers = default_headers()\n\n        #: Default Authentication tuple or object to attach to\n        #: :class:`Request <Request>`.\n        self.auth = None\n\n        #: Dictionary mapping protocol or protocol and host to the URL of the proxy\n        #: (e.g. {'http': 'foo.bar:3128', 'http://host.name': 'foo.bar:4012'}) to\n        #: be used on each :class:`Request <Request>`.\n        self.proxies = {}\n\n        #: Event-handling hooks.\n        self.hooks = default_hooks()\n\n        #: Dictionary of querystring data to attach to each\n        #: :class:`Request <Request>`. The dictionary values may be lists for\n        #: representing multivalued query parameters.\n        self.params = {}\n\n        #: Stream response content default.\n        self.stream = False\n\n        #: SSL Verification default.\n        #: Defaults to `True`, requiring requests to verif"}, {"start_line": 14000, "end_line": 16000, "belongs_to": {"file_name": "sessions.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "ry of headers to be sent on each\n        #: :class:`Request <Request>` sent from this\n        #: :class:`Session <Session>`.\n        self.headers = default_headers()\n\n        #: Default Authentication tuple or object to attach to\n        #: :class:`Request <Request>`.\n        self.auth = None\n\n        #: Dictionary mapping protocol or protocol and host to the URL of the proxy\n        #: (e.g. {'http': 'foo.bar:3128', 'http://host.name': 'foo.bar:4012'}) to\n        #: be used on each :class:`Request <Request>`.\n        self.proxies = {}\n\n        #: Event-handling hooks.\n        self.hooks = default_hooks()\n\n        #: Dictionary of querystring data to attach to each\n        #: :class:`Request <Request>`. The dictionary values may be lists for\n        #: representing multivalued query parameters.\n        self.params = {}\n\n        #: Stream response content default.\n        self.stream = False\n\n        #: SSL Verification default.\n        #: Defaults to `True`, requiring requests to verify the TLS certificate at the\n        #: remote end.\n        #: If verify is set to `False`, requests will accept any TLS certificate\n        #: presented by the server, and will ignore hostname mismatches and/or\n        #: expired certificates, which will make your application vulnerable to\n        #: man-in-the-middle (MitM) attacks.\n        #: Only set this to `False` for testing.\n        self.verify = True\n\n        #: SSL client certificate default, if String, path to ssl client\n        #: cert file (.pem). If Tuple, ('cert', 'key') pair.\n        self.cert = None\n\n        #: Maximum number of redirects allowed. If the request exceeds this\n        #: limit, a :class:`TooManyRedirects` exception is raised.\n        #: This defaults to requests.models.DEFAULT_REDIRECT_LIMIT, which is\n        #: 30.\n        self.max_redirects = DEFAULT_REDIRECT_LIMIT\n\n        #: Trust environment settings for proxy configuration, default\n        #: authentication and similar.\n        self.trust_env = Tru"}, {"start_line": 0, "end_line": 2000, "belongs_to": {"file_name": "conf.py", "upper_path": "/data2/raymone/swebench-repos/requests/docs", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "# -*- coding: utf-8 -*-\n#\n# Requests documentation build configuration file, created by\n# sphinx-quickstart on Fri Feb 19 00:05:47 2016.\n#\n# This file is execfile()d with the current directory set to its\n# containing dir.\n#\n# Note that not all possible configuration values are present in this\n# autogenerated file.\n#\n# All configuration values have a default; values that are commented out\n# serve to show the default.\n\nimport sys\nimport os\n\n# If extensions (or modules to document with autodoc) are in another directory,\n# add these directories to sys.path here. If the directory is relative to the\n# documentation root, use os.path.abspath to make it absolute, like shown here.\n# sys.path.insert(0, os.path.abspath('.'))\n\n# Insert Requests' path into the system.\nsys.path.insert(0, os.path.abspath(\"..\"))\nsys.path.insert(0, os.path.abspath(\"_themes\"))\n\nimport requests\n\n\n# -- General configuration ------------------------------------------------\n\n# If your documentation needs a minimal Sphinx version, state it here.\n# needs_sphinx = '1.0'\n\n# Add any Sphinx extension module names here, as strings. They can be\n# extensions coming with Sphinx (named 'sphinx.ext.*') or your custom\n# ones.\nextensions = [\n    \"sphinx.ext.autodoc\",\n    \"sphinx.ext.intersphinx\",\n    \"sphinx.ext.todo\",\n    \"sphinx.ext.viewcode\",\n]\n\n# Add any paths that contain templates here, relative to this directory.\ntemplates_path = [\"_templates\"]\n\n# The suffix(es) of source filenames.\n# You can specify multiple suffix as a list of string:\n# source_suffix = ['.rst', '.md']\nsource_suffix = \".rst\"\n\n# The encoding of source files.\n# source_encoding = 'utf-8-sig'\n\n# The master toctree document.\nmaster_doc = \"index\"\n\n# General information about the project.\nproject = u\"Requests\"\ncopyright = u'MMXVIX. A Kenneth Reitz Project'\nauthor = u\"Kenneth Reitz\"\n\n# The version info for the project you're documenting, acts as replacement for\n# |version| and |release|, also used in various other places throughout the\n# built documen"}, {"start_line": 15000, "end_line": 17000, "belongs_to": {"file_name": "sessions.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "y the TLS certificate at the\n        #: remote end.\n        #: If verify is set to `False`, requests will accept any TLS certificate\n        #: presented by the server, and will ignore hostname mismatches and/or\n        #: expired certificates, which will make your application vulnerable to\n        #: man-in-the-middle (MitM) attacks.\n        #: Only set this to `False` for testing.\n        self.verify = True\n\n        #: SSL client certificate default, if String, path to ssl client\n        #: cert file (.pem). If Tuple, ('cert', 'key') pair.\n        self.cert = None\n\n        #: Maximum number of redirects allowed. If the request exceeds this\n        #: limit, a :class:`TooManyRedirects` exception is raised.\n        #: This defaults to requests.models.DEFAULT_REDIRECT_LIMIT, which is\n        #: 30.\n        self.max_redirects = DEFAULT_REDIRECT_LIMIT\n\n        #: Trust environment settings for proxy configuration, default\n        #: authentication and similar.\n        self.trust_env = True\n\n        #: A CookieJar containing all currently outstanding cookies set on this\n        #: session. By default it is a\n        #: :class:`RequestsCookieJar <requests.cookies.RequestsCookieJar>`, but\n        #: may be any other ``cookielib.CookieJar`` compatible object.\n        self.cookies = cookiejar_from_dict({})\n\n        # Default connection adapters.\n        self.adapters = OrderedDict()\n        self.mount(\"https://\", HTTPAdapter())\n        self.mount(\"http://\", HTTPAdapter())\n\n    def __enter__(self):\n        return self\n\n    def __exit__(self, *args):\n        self.close()\n\n    def prepare_request(self, request):\n        \"\"\"Constructs a :class:`PreparedRequest <PreparedRequest>` for\n        transmission and returns it. The :class:`PreparedRequest` has settings\n        merged from the :class:`Request <Request>` instance and those of the\n        :class:`Session`.\n\n        :param request: :class:`Request` instance to prepare with this\n            session's settings.\n        :rtype"}, {"start_line": 0, "end_line": 2000, "belongs_to": {"file_name": "api.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "\"\"\"\nrequests.api\n~~~~~~~~~~~~\n\nThis module implements the Requests API.\n\n:copyright: (c) 2012 by Kenneth Reitz.\n:license: Apache2, see LICENSE for more details.\n\"\"\"\n\nfrom . import sessions\n\n\ndef request(method, url, **kwargs):\n    \"\"\"Constructs and sends a :class:`Request <Request>`.\n\n    :param method: method for the new :class:`Request` object: ``GET``, ``OPTIONS``, ``HEAD``, ``POST``, ``PUT``, ``PATCH``, or ``DELETE``.\n    :param url: URL for the new :class:`Request` object.\n    :param params: (optional) Dictionary, list of tuples or bytes to send\n        in the query string for the :class:`Request`.\n    :param data: (optional) Dictionary, list of tuples, bytes, or file-like\n        object to send in the body of the :class:`Request`.\n    :param json: (optional) A JSON serializable Python object to send in the body of the :class:`Request`.\n    :param headers: (optional) Dictionary of HTTP Headers to send with the :class:`Request`.\n    :param cookies: (optional) Dict or CookieJar object to send with the :class:`Request`.\n    :param files: (optional) Dictionary of ``'name': file-like-objects`` (or ``{'name': file-tuple}``) for multipart encoding upload.\n        ``file-tuple`` can be a 2-tuple ``('filename', fileobj)``, 3-tuple ``('filename', fileobj, 'content_type')``\n        or a 4-tuple ``('filename', fileobj, 'content_type', custom_headers)``, where ``'content_type'`` is a string\n        defining the content type of the given file and ``custom_headers`` a dict-like object containing additional headers\n        to add for the file.\n    :param auth: (optional) Auth tuple to enable Basic/Digest/Custom HTTP Auth.\n    :param timeout: (optional) How many seconds to wait for the server to send data\n        before giving up, as a float, or a :ref:`(connect timeout, read\n        timeout) <timeouts>` tuple.\n    :type timeout: float or tuple\n    :param allow_redirects: (optional) Boolean. Enable/disable GET/OPTIONS/POST/PUT/PATCH/DELETE/HEAD redirection. Defaults to ``True``"}, {"start_line": 0, "end_line": 2000, "belongs_to": {"file_name": "sessions.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "\"\"\"\nrequests.sessions\n~~~~~~~~~~~~~~~~~\n\nThis module provides a Session object to manage and persist settings across\nrequests (cookies, auth, proxies).\n\"\"\"\nimport os\nimport sys\nimport time\nfrom collections import OrderedDict\nfrom datetime import timedelta\n\nfrom ._internal_utils import to_native_string\nfrom .adapters import HTTPAdapter\nfrom .auth import _basic_auth_str\nfrom .compat import Mapping, cookielib, urljoin, urlparse\nfrom .cookies import (\n    RequestsCookieJar,\n    cookiejar_from_dict,\n    extract_cookies_to_jar,\n    merge_cookies,\n)\nfrom .exceptions import (\n    ChunkedEncodingError,\n    ContentDecodingError,\n    InvalidSchema,\n    TooManyRedirects,\n)\nfrom .hooks import default_hooks, dispatch_hook\n\n# formerly defined here, reexposed here for backward compatibility\nfrom .models import (  # noqa: F401\n    DEFAULT_REDIRECT_LIMIT,\n    REDIRECT_STATI,\n    PreparedRequest,\n    Request,\n)\nfrom .status_codes import codes\nfrom .structures import CaseInsensitiveDict\nfrom .utils import (  # noqa: F401\n    DEFAULT_PORTS,\n    default_headers,\n    get_auth_from_url,\n    get_environ_proxies,\n    get_netrc_auth,\n    requote_uri,\n    resolve_proxies,\n    rewind_body,\n    should_bypass_proxies,\n    to_key_val_list,\n)\n\n# Preferred clock, based on which one is more accurate on a given system.\nif sys.platform == \"win32\":\n    preferred_clock = time.perf_counter\nelse:\n    preferred_clock = time.time\n\n\ndef merge_setting(request_setting, session_setting, dict_class=OrderedDict):\n    \"\"\"Determines appropriate setting for a given request, taking into account\n    the explicit setting on that request, and the setting in the session. If a\n    setting is a dictionary, they will be merged together using `dict_class`\n    \"\"\"\n\n    if session_setting is None:\n        return request_setting\n\n    if request_setting is None:\n        return session_setting\n\n    # Bypass if not a dictionary (e.g. verify)\n    if not (\n        isinstance(session_setting, Mapping) and isinstance(request_setting, M"}, {"start_line": 28000, "end_line": 30000, "belongs_to": {"file_name": "sessions.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "vironment's proxies.\n            no_proxy = proxies.get(\"no_proxy\") if proxies is not None else None\n            env_proxies = get_environ_proxies(url, no_proxy=no_proxy)\n            for k, v in env_proxies.items():\n                proxies.setdefault(k, v)\n\n            # Look for requests environment configuration\n            # and be compatible with cURL.\n            if verify is True or verify is None:\n                verify = (\n                    os.environ.get(\"REQUESTS_CA_BUNDLE\")\n                    or os.environ.get(\"CURL_CA_BUNDLE\")\n                    or verify\n                )\n\n        # Merge all the kwargs.\n        proxies = merge_setting(proxies, self.proxies)\n        stream = merge_setting(stream, self.stream)\n        verify = merge_setting(verify, self.verify)\n        cert = merge_setting(cert, self.cert)\n\n        return {\"proxies\": proxies, \"stream\": stream, \"verify\": verify, \"cert\": cert}\n\n    def get_adapter(self, url):\n        \"\"\"\n        Returns the appropriate connection adapter for the given URL.\n\n        :rtype: requests.adapters.BaseAdapter\n        \"\"\"\n        for prefix, adapter in self.adapters.items():\n            if url.lower().startswith(prefix.lower()):\n                return adapter\n\n        # Nothing matches :-/\n        raise InvalidSchema(f\"No connection adapters were found for {url!r}\")\n\n    def close(self):\n        \"\"\"Closes all adapters and as such the session\"\"\"\n        for v in self.adapters.values():\n            v.close()\n\n    def mount(self, prefix, adapter):\n        \"\"\"Registers a connection adapter to a prefix.\n\n        Adapters are sorted in descending order by prefix length.\n        \"\"\"\n        self.adapters[prefix] = adapter\n        keys_to_move = [k for k in self.adapters if len(k) < len(prefix)]\n\n        for key in keys_to_move:\n            self.adapters[key] = self.adapters.pop(key)\n\n    def __getstate__(self):\n        state = {attr: getattr(self, attr, None) for attr in self.__attrs__}\n        return state\n\n    def "}, {"start_line": 1000, "end_line": 3000, "belongs_to": {"file_name": "sessions.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": " (  # noqa: F401\n    DEFAULT_PORTS,\n    default_headers,\n    get_auth_from_url,\n    get_environ_proxies,\n    get_netrc_auth,\n    requote_uri,\n    resolve_proxies,\n    rewind_body,\n    should_bypass_proxies,\n    to_key_val_list,\n)\n\n# Preferred clock, based on which one is more accurate on a given system.\nif sys.platform == \"win32\":\n    preferred_clock = time.perf_counter\nelse:\n    preferred_clock = time.time\n\n\ndef merge_setting(request_setting, session_setting, dict_class=OrderedDict):\n    \"\"\"Determines appropriate setting for a given request, taking into account\n    the explicit setting on that request, and the setting in the session. If a\n    setting is a dictionary, they will be merged together using `dict_class`\n    \"\"\"\n\n    if session_setting is None:\n        return request_setting\n\n    if request_setting is None:\n        return session_setting\n\n    # Bypass if not a dictionary (e.g. verify)\n    if not (\n        isinstance(session_setting, Mapping) and isinstance(request_setting, Mapping)\n    ):\n        return request_setting\n\n    merged_setting = dict_class(to_key_val_list(session_setting))\n    merged_setting.update(to_key_val_list(request_setting))\n\n    # Remove keys that are set to None. Extract keys first to avoid altering\n    # the dictionary during iteration.\n    none_keys = [k for (k, v) in merged_setting.items() if v is None]\n    for key in none_keys:\n        del merged_setting[key]\n\n    return merged_setting\n\n\ndef merge_hooks(request_hooks, session_hooks, dict_class=OrderedDict):\n    \"\"\"Properly merges both requests and session hooks.\n\n    This is necessary because when request_hooks == {'response': []}, the\n    merge breaks Session hooks entirely.\n    \"\"\"\n    if session_hooks is None or session_hooks.get(\"response\") == []:\n        return request_hooks\n\n    if request_hooks is None or request_hooks.get(\"response\") == []:\n        return session_hooks\n\n    return merge_setting(request_hooks, session_hooks, dict_class)\n\n\nclass SessionRedirectMixin:\n    def"}, {"start_line": 26000, "end_line": 28000, "belongs_to": {"file_name": "sessions.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "adapter to use\n        adapter = self.get_adapter(url=request.url)\n\n        # Start time (approximately) of the request\n        start = preferred_clock()\n\n        # Send the request\n        r = adapter.send(request, **kwargs)\n\n        # Total elapsed time of the request (approximately)\n        elapsed = preferred_clock() - start\n        r.elapsed = timedelta(seconds=elapsed)\n\n        # Response manipulation hooks\n        r = dispatch_hook(\"response\", hooks, r, **kwargs)\n\n        # Persist cookies\n        if r.history:\n            # If the hooks create history then we want those cookies too\n            for resp in r.history:\n                extract_cookies_to_jar(self.cookies, resp.request, resp.raw)\n\n        extract_cookies_to_jar(self.cookies, request, r.raw)\n\n        # Resolve redirects if allowed.\n        if allow_redirects:\n            # Redirect resolving generator.\n            gen = self.resolve_redirects(r, request, **kwargs)\n            history = [resp for resp in gen]\n        else:\n            history = []\n\n        # Shuffle things around if there's history.\n        if history:\n            # Insert the first (original) request at the start\n            history.insert(0, r)\n            # Get the last request made\n            r = history.pop()\n            r.history = history\n\n        # If redirects aren't being followed, store the response on the Request for Response.next().\n        if not allow_redirects:\n            try:\n                r._next = next(\n                    self.resolve_redirects(r, request, yield_requests=True, **kwargs)\n                )\n            except StopIteration:\n                pass\n\n        if not stream:\n            r.content\n\n        return r\n\n    def merge_environment_settings(self, url, proxies, stream, verify, cert):\n        \"\"\"\n        Check the environment and merge it with some settings.\n\n        :rtype: dict\n        \"\"\"\n        # Gather clues from the surrounding environment.\n        if self.trust_env:\n            # Set en"}, {"start_line": 17000, "end_line": 19000, "belongs_to": {"file_name": "sessions.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": ": requests.PreparedRequest\n        \"\"\"\n        cookies = request.cookies or {}\n\n        # Bootstrap CookieJar.\n        if not isinstance(cookies, cookielib.CookieJar):\n            cookies = cookiejar_from_dict(cookies)\n\n        # Merge with session cookies\n        merged_cookies = merge_cookies(\n            merge_cookies(RequestsCookieJar(), self.cookies), cookies\n        )\n\n        # Set environment's basic authentication if not explicitly set.\n        auth = request.auth\n        if self.trust_env and not auth and not self.auth:\n            auth = get_netrc_auth(request.url)\n\n        p = PreparedRequest()\n        p.prepare(\n            method=request.method.upper(),\n            url=request.url,\n            files=request.files,\n            data=request.data,\n            json=request.json,\n            headers=merge_setting(\n                request.headers, self.headers, dict_class=CaseInsensitiveDict\n            ),\n            params=merge_setting(request.params, self.params),\n            auth=merge_setting(auth, self.auth),\n            cookies=merged_cookies,\n            hooks=merge_hooks(request.hooks, self.hooks),\n        )\n        return p\n\n    def request(\n        self,\n        method,\n        url,\n        params=None,\n        data=None,\n        headers=None,\n        cookies=None,\n        files=None,\n        auth=None,\n        timeout=None,\n        allow_redirects=True,\n        proxies=None,\n        hooks=None,\n        stream=None,\n        verify=None,\n        cert=None,\n        json=None,\n    ):\n        \"\"\"Constructs a :class:`Request <Request>`, prepares it and sends it.\n        Returns :class:`Response <Response>` object.\n\n        :param method: method for the new :class:`Request` object.\n        :param url: URL for the new :class:`Request` object.\n        :param params: (optional) Dictionary or bytes to be sent in the query\n            string for the :class:`Request`.\n        :param data: (optional) Dictionary, list of tuples, bytes, or file-like\n           "}], "retrieved_count": 10, "cost_time": 1.0587153434753418}
{"question": "How does Requests implement its session management system?", "answer": null, "relative_code_list": null, "ground_truth": "Requests implements session management through the Session class in src/requests/sessions.py: 1) State persistence - Sessions maintain persistent state including cookies, headers, auth, proxies, and configuration across requests; 2) Connection pooling - Sessions use HTTPAdapter instances for connection pooling and reuse; 3) Configuration merging - Session.prepare_request() merges session settings with request-specific settings; 4) Cookie management - Sessions maintain RequestsCookieJar for automatic cookie persistence; 5) Authentication persistence - Sessions store default authentication credentials applied to all requests; 6) Adapter mounting - Sessions mount different adapters for different URL schemes; 7) Resource management - Sessions implement context manager protocol for automatic cleanup; 8) Thread safety - Connection pools and session state are thread-safe for concurrent usage; 9) Request coordination - Sessions coordinate the complete request lifecycle from preparation to response processing; 10) Error handling - Sessions provide consistent error handling and exception translation across all requests.", "score": null, "retrieved_content": [{"start_line": 13000, "end_line": 15000, "belongs_to": {"file_name": "sessions.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "POST is responded to with a 301, turn it into a GET.\n        # This bizarre behaviour is explained in Issue 1704.\n        if response.status_code == codes.moved and method == \"POST\":\n            method = \"GET\"\n\n        prepared_request.method = method\n\n\nclass Session(SessionRedirectMixin):\n    \"\"\"A Requests session.\n\n    Provides cookie persistence, connection-pooling, and configuration.\n\n    Basic Usage::\n\n      >>> import requests\n      >>> s = requests.Session()\n      >>> s.get('https://httpbin.org/get')\n      <Response [200]>\n\n    Or as a context manager::\n\n      >>> with requests.Session() as s:\n      ...     s.get('https://httpbin.org/get')\n      <Response [200]>\n    \"\"\"\n\n    __attrs__ = [\n        \"headers\",\n        \"cookies\",\n        \"auth\",\n        \"proxies\",\n        \"hooks\",\n        \"params\",\n        \"verify\",\n        \"cert\",\n        \"adapters\",\n        \"stream\",\n        \"trust_env\",\n        \"max_redirects\",\n    ]\n\n    def __init__(self):\n        #: A case-insensitive dictionary of headers to be sent on each\n        #: :class:`Request <Request>` sent from this\n        #: :class:`Session <Session>`.\n        self.headers = default_headers()\n\n        #: Default Authentication tuple or object to attach to\n        #: :class:`Request <Request>`.\n        self.auth = None\n\n        #: Dictionary mapping protocol or protocol and host to the URL of the proxy\n        #: (e.g. {'http': 'foo.bar:3128', 'http://host.name': 'foo.bar:4012'}) to\n        #: be used on each :class:`Request <Request>`.\n        self.proxies = {}\n\n        #: Event-handling hooks.\n        self.hooks = default_hooks()\n\n        #: Dictionary of querystring data to attach to each\n        #: :class:`Request <Request>`. The dictionary values may be lists for\n        #: representing multivalued query parameters.\n        self.params = {}\n\n        #: Stream response content default.\n        self.stream = False\n\n        #: SSL Verification default.\n        #: Defaults to `True`, requiring requests to verif"}, {"start_line": 12000, "end_line": 14000, "belongs_to": {"file_name": "sessions.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "          username, password = None, None\n\n        # urllib3 handles proxy authorization for us in the standard adapter.\n        # Avoid appending this to TLS tunneled requests where it may be leaked.\n        if not scheme.startswith(\"https\") and username and password:\n            headers[\"Proxy-Authorization\"] = _basic_auth_str(username, password)\n\n        return new_proxies\n\n    def rebuild_method(self, prepared_request, response):\n        \"\"\"When being redirected we may want to change the method of the request\n        based on certain specs or browser behavior.\n        \"\"\"\n        method = prepared_request.method\n\n        # https://tools.ietf.org/html/rfc7231#section-6.4.4\n        if response.status_code == codes.see_other and method != \"HEAD\":\n            method = \"GET\"\n\n        # Do what the browsers do, despite standards...\n        # First, turn 302s into GETs.\n        if response.status_code == codes.found and method != \"HEAD\":\n            method = \"GET\"\n\n        # Second, if a POST is responded to with a 301, turn it into a GET.\n        # This bizarre behaviour is explained in Issue 1704.\n        if response.status_code == codes.moved and method == \"POST\":\n            method = \"GET\"\n\n        prepared_request.method = method\n\n\nclass Session(SessionRedirectMixin):\n    \"\"\"A Requests session.\n\n    Provides cookie persistence, connection-pooling, and configuration.\n\n    Basic Usage::\n\n      >>> import requests\n      >>> s = requests.Session()\n      >>> s.get('https://httpbin.org/get')\n      <Response [200]>\n\n    Or as a context manager::\n\n      >>> with requests.Session() as s:\n      ...     s.get('https://httpbin.org/get')\n      <Response [200]>\n    \"\"\"\n\n    __attrs__ = [\n        \"headers\",\n        \"cookies\",\n        \"auth\",\n        \"proxies\",\n        \"hooks\",\n        \"params\",\n        \"verify\",\n        \"cert\",\n        \"adapters\",\n        \"stream\",\n        \"trust_env\",\n        \"max_redirects\",\n    ]\n\n    def __init__(self):\n        #: A case-insensitive dictiona"}, {"start_line": 0, "end_line": 2000, "belongs_to": {"file_name": "sessions.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "\"\"\"\nrequests.sessions\n~~~~~~~~~~~~~~~~~\n\nThis module provides a Session object to manage and persist settings across\nrequests (cookies, auth, proxies).\n\"\"\"\nimport os\nimport sys\nimport time\nfrom collections import OrderedDict\nfrom datetime import timedelta\n\nfrom ._internal_utils import to_native_string\nfrom .adapters import HTTPAdapter\nfrom .auth import _basic_auth_str\nfrom .compat import Mapping, cookielib, urljoin, urlparse\nfrom .cookies import (\n    RequestsCookieJar,\n    cookiejar_from_dict,\n    extract_cookies_to_jar,\n    merge_cookies,\n)\nfrom .exceptions import (\n    ChunkedEncodingError,\n    ContentDecodingError,\n    InvalidSchema,\n    TooManyRedirects,\n)\nfrom .hooks import default_hooks, dispatch_hook\n\n# formerly defined here, reexposed here for backward compatibility\nfrom .models import (  # noqa: F401\n    DEFAULT_REDIRECT_LIMIT,\n    REDIRECT_STATI,\n    PreparedRequest,\n    Request,\n)\nfrom .status_codes import codes\nfrom .structures import CaseInsensitiveDict\nfrom .utils import (  # noqa: F401\n    DEFAULT_PORTS,\n    default_headers,\n    get_auth_from_url,\n    get_environ_proxies,\n    get_netrc_auth,\n    requote_uri,\n    resolve_proxies,\n    rewind_body,\n    should_bypass_proxies,\n    to_key_val_list,\n)\n\n# Preferred clock, based on which one is more accurate on a given system.\nif sys.platform == \"win32\":\n    preferred_clock = time.perf_counter\nelse:\n    preferred_clock = time.time\n\n\ndef merge_setting(request_setting, session_setting, dict_class=OrderedDict):\n    \"\"\"Determines appropriate setting for a given request, taking into account\n    the explicit setting on that request, and the setting in the session. If a\n    setting is a dictionary, they will be merged together using `dict_class`\n    \"\"\"\n\n    if session_setting is None:\n        return request_setting\n\n    if request_setting is None:\n        return session_setting\n\n    # Bypass if not a dictionary (e.g. verify)\n    if not (\n        isinstance(session_setting, Mapping) and isinstance(request_setting, M"}, {"start_line": 14000, "end_line": 16000, "belongs_to": {"file_name": "sessions.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "ry of headers to be sent on each\n        #: :class:`Request <Request>` sent from this\n        #: :class:`Session <Session>`.\n        self.headers = default_headers()\n\n        #: Default Authentication tuple or object to attach to\n        #: :class:`Request <Request>`.\n        self.auth = None\n\n        #: Dictionary mapping protocol or protocol and host to the URL of the proxy\n        #: (e.g. {'http': 'foo.bar:3128', 'http://host.name': 'foo.bar:4012'}) to\n        #: be used on each :class:`Request <Request>`.\n        self.proxies = {}\n\n        #: Event-handling hooks.\n        self.hooks = default_hooks()\n\n        #: Dictionary of querystring data to attach to each\n        #: :class:`Request <Request>`. The dictionary values may be lists for\n        #: representing multivalued query parameters.\n        self.params = {}\n\n        #: Stream response content default.\n        self.stream = False\n\n        #: SSL Verification default.\n        #: Defaults to `True`, requiring requests to verify the TLS certificate at the\n        #: remote end.\n        #: If verify is set to `False`, requests will accept any TLS certificate\n        #: presented by the server, and will ignore hostname mismatches and/or\n        #: expired certificates, which will make your application vulnerable to\n        #: man-in-the-middle (MitM) attacks.\n        #: Only set this to `False` for testing.\n        self.verify = True\n\n        #: SSL client certificate default, if String, path to ssl client\n        #: cert file (.pem). If Tuple, ('cert', 'key') pair.\n        self.cert = None\n\n        #: Maximum number of redirects allowed. If the request exceeds this\n        #: limit, a :class:`TooManyRedirects` exception is raised.\n        #: This defaults to requests.models.DEFAULT_REDIRECT_LIMIT, which is\n        #: 30.\n        self.max_redirects = DEFAULT_REDIRECT_LIMIT\n\n        #: Trust environment settings for proxy configuration, default\n        #: authentication and similar.\n        self.trust_env = Tru"}, {"start_line": 15000, "end_line": 17000, "belongs_to": {"file_name": "sessions.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "y the TLS certificate at the\n        #: remote end.\n        #: If verify is set to `False`, requests will accept any TLS certificate\n        #: presented by the server, and will ignore hostname mismatches and/or\n        #: expired certificates, which will make your application vulnerable to\n        #: man-in-the-middle (MitM) attacks.\n        #: Only set this to `False` for testing.\n        self.verify = True\n\n        #: SSL client certificate default, if String, path to ssl client\n        #: cert file (.pem). If Tuple, ('cert', 'key') pair.\n        self.cert = None\n\n        #: Maximum number of redirects allowed. If the request exceeds this\n        #: limit, a :class:`TooManyRedirects` exception is raised.\n        #: This defaults to requests.models.DEFAULT_REDIRECT_LIMIT, which is\n        #: 30.\n        self.max_redirects = DEFAULT_REDIRECT_LIMIT\n\n        #: Trust environment settings for proxy configuration, default\n        #: authentication and similar.\n        self.trust_env = True\n\n        #: A CookieJar containing all currently outstanding cookies set on this\n        #: session. By default it is a\n        #: :class:`RequestsCookieJar <requests.cookies.RequestsCookieJar>`, but\n        #: may be any other ``cookielib.CookieJar`` compatible object.\n        self.cookies = cookiejar_from_dict({})\n\n        # Default connection adapters.\n        self.adapters = OrderedDict()\n        self.mount(\"https://\", HTTPAdapter())\n        self.mount(\"http://\", HTTPAdapter())\n\n    def __enter__(self):\n        return self\n\n    def __exit__(self, *args):\n        self.close()\n\n    def prepare_request(self, request):\n        \"\"\"Constructs a :class:`PreparedRequest <PreparedRequest>` for\n        transmission and returns it. The :class:`PreparedRequest` has settings\n        merged from the :class:`Request <Request>` instance and those of the\n        :class:`Session`.\n\n        :param request: :class:`Request` instance to prepare with this\n            session's settings.\n        :rtype"}, {"start_line": 43000, "end_line": 45000, "belongs_to": {"file_name": "test_requests.py", "upper_path": "/data2/raymone/swebench-repos/requests/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "ook})\n        prep = req.prepare()\n\n        s = requests.Session()\n        s.proxies = getproxies()\n        resp = s.send(prep)\n\n        assert hasattr(resp, \"hook_working\")\n\n    def test_prepared_from_session(self, httpbin):\n        class DummyAuth(requests.auth.AuthBase):\n            def __call__(self, r):\n                r.headers[\"Dummy-Auth-Test\"] = \"dummy-auth-test-ok\"\n                return r\n\n        req = requests.Request(\"GET\", httpbin(\"headers\"))\n        assert not req.auth\n\n        s = requests.Session()\n        s.auth = DummyAuth()\n\n        prep = s.prepare_request(req)\n        resp = s.send(prep)\n\n        assert resp.json()[\"headers\"][\"Dummy-Auth-Test\"] == \"dummy-auth-test-ok\"\n\n    def test_prepare_request_with_bytestring_url(self):\n        req = requests.Request(\"GET\", b\"https://httpbin.org/\")\n        s = requests.Session()\n        prep = s.prepare_request(req)\n        assert prep.url == \"https://httpbin.org/\"\n\n    def test_request_with_bytestring_host(self, httpbin):\n        s = requests.Session()\n        resp = s.request(\n            \"GET\",\n            httpbin(\"cookies/set?cookie=value\"),\n            allow_redirects=False,\n            headers={\"Host\": b\"httpbin.org\"},\n        )\n        assert resp.cookies.get(\"cookie\") == \"value\"\n\n    def test_links(self):\n        r = requests.Response()\n        r.headers = {\n            \"cache-control\": \"public, max-age=60, s-maxage=60\",\n            \"connection\": \"keep-alive\",\n            \"content-encoding\": \"gzip\",\n            \"content-type\": \"application/json; charset=utf-8\",\n            \"date\": \"Sat, 26 Jan 2013 16:47:56 GMT\",\n            \"etag\": '\"6ff6a73c0e446c1f61614769e3ceb778\"',\n            \"last-modified\": \"Sat, 26 Jan 2013 16:22:39 GMT\",\n            \"link\": (\n                \"<https://api.github.com/users/kennethreitz/repos?\"\n                'page=2&per_page=10>; rel=\"next\", <https://api.github.'\n                \"com/users/kennethreitz/repos?page=7&per_page=10>; \"\n                ' rel=\"last\"'\n           "}, {"start_line": 13000, "end_line": 15000, "belongs_to": {"file_name": "test_requests.py", "upper_path": "/data2/raymone/swebench-repos/requests/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "atus_code == 200\n\n    def test_set_cookie_on_301(self, httpbin):\n        s = requests.session()\n        url = httpbin(\"cookies/set?foo=bar\")\n        s.get(url)\n        assert s.cookies[\"foo\"] == \"bar\"\n\n    def test_cookie_sent_on_redirect(self, httpbin):\n        s = requests.session()\n        s.get(httpbin(\"cookies/set?foo=bar\"))\n        r = s.get(httpbin(\"redirect/1\"))  # redirects to httpbin('get')\n        assert \"Cookie\" in r.json()[\"headers\"]\n\n    def test_cookie_removed_on_expire(self, httpbin):\n        s = requests.session()\n        s.get(httpbin(\"cookies/set?foo=bar\"))\n        assert s.cookies[\"foo\"] == \"bar\"\n        s.get(\n            httpbin(\"response-headers\"),\n            params={\"Set-Cookie\": \"foo=deleted; expires=Thu, 01-Jan-1970 00:00:01 GMT\"},\n        )\n        assert \"foo\" not in s.cookies\n\n    def test_cookie_quote_wrapped(self, httpbin):\n        s = requests.session()\n        s.get(httpbin('cookies/set?foo=\"bar:baz\"'))\n        assert s.cookies[\"foo\"] == '\"bar:baz\"'\n\n    def test_cookie_persists_via_api(self, httpbin):\n        s = requests.session()\n        r = s.get(httpbin(\"redirect/1\"), cookies={\"foo\": \"bar\"})\n        assert \"foo\" in r.request.headers[\"Cookie\"]\n        assert \"foo\" in r.history[0].request.headers[\"Cookie\"]\n\n    def test_request_cookie_overrides_session_cookie(self, httpbin):\n        s = requests.session()\n        s.cookies[\"foo\"] = \"bar\"\n        r = s.get(httpbin(\"cookies\"), cookies={\"foo\": \"baz\"})\n        assert r.json()[\"cookies\"][\"foo\"] == \"baz\"\n        # Session cookie should not be modified\n        assert s.cookies[\"foo\"] == \"bar\"\n\n    def test_request_cookies_not_persisted(self, httpbin):\n        s = requests.session()\n        s.get(httpbin(\"cookies\"), cookies={\"foo\": \"baz\"})\n        # Sending a request with cookies should not add cookies to the session\n        assert not s.cookies\n\n    def test_generic_cookiejar_works(self, httpbin):\n        cj = cookielib.CookieJar()\n        cookiejar_from_dict({\"foo\": \"bar\"}, cj)\n       "}, {"start_line": 0, "end_line": 2000, "belongs_to": {"file_name": "api.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "\"\"\"\nrequests.api\n~~~~~~~~~~~~\n\nThis module implements the Requests API.\n\n:copyright: (c) 2012 by Kenneth Reitz.\n:license: Apache2, see LICENSE for more details.\n\"\"\"\n\nfrom . import sessions\n\n\ndef request(method, url, **kwargs):\n    \"\"\"Constructs and sends a :class:`Request <Request>`.\n\n    :param method: method for the new :class:`Request` object: ``GET``, ``OPTIONS``, ``HEAD``, ``POST``, ``PUT``, ``PATCH``, or ``DELETE``.\n    :param url: URL for the new :class:`Request` object.\n    :param params: (optional) Dictionary, list of tuples or bytes to send\n        in the query string for the :class:`Request`.\n    :param data: (optional) Dictionary, list of tuples, bytes, or file-like\n        object to send in the body of the :class:`Request`.\n    :param json: (optional) A JSON serializable Python object to send in the body of the :class:`Request`.\n    :param headers: (optional) Dictionary of HTTP Headers to send with the :class:`Request`.\n    :param cookies: (optional) Dict or CookieJar object to send with the :class:`Request`.\n    :param files: (optional) Dictionary of ``'name': file-like-objects`` (or ``{'name': file-tuple}``) for multipart encoding upload.\n        ``file-tuple`` can be a 2-tuple ``('filename', fileobj)``, 3-tuple ``('filename', fileobj, 'content_type')``\n        or a 4-tuple ``('filename', fileobj, 'content_type', custom_headers)``, where ``'content_type'`` is a string\n        defining the content type of the given file and ``custom_headers`` a dict-like object containing additional headers\n        to add for the file.\n    :param auth: (optional) Auth tuple to enable Basic/Digest/Custom HTTP Auth.\n    :param timeout: (optional) How many seconds to wait for the server to send data\n        before giving up, as a float, or a :ref:`(connect timeout, read\n        timeout) <timeouts>` tuple.\n    :type timeout: float or tuple\n    :param allow_redirects: (optional) Boolean. Enable/disable GET/OPTIONS/POST/PUT/PATCH/DELETE/HEAD redirection. Defaults to ``True``"}, {"start_line": 44000, "end_line": 46000, "belongs_to": {"file_name": "test_requests.py", "upper_path": "/data2/raymone/swebench-repos/requests/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "      s = requests.Session()\n        resp = s.request(\n            \"GET\",\n            httpbin(\"cookies/set?cookie=value\"),\n            allow_redirects=False,\n            headers={\"Host\": b\"httpbin.org\"},\n        )\n        assert resp.cookies.get(\"cookie\") == \"value\"\n\n    def test_links(self):\n        r = requests.Response()\n        r.headers = {\n            \"cache-control\": \"public, max-age=60, s-maxage=60\",\n            \"connection\": \"keep-alive\",\n            \"content-encoding\": \"gzip\",\n            \"content-type\": \"application/json; charset=utf-8\",\n            \"date\": \"Sat, 26 Jan 2013 16:47:56 GMT\",\n            \"etag\": '\"6ff6a73c0e446c1f61614769e3ceb778\"',\n            \"last-modified\": \"Sat, 26 Jan 2013 16:22:39 GMT\",\n            \"link\": (\n                \"<https://api.github.com/users/kennethreitz/repos?\"\n                'page=2&per_page=10>; rel=\"next\", <https://api.github.'\n                \"com/users/kennethreitz/repos?page=7&per_page=10>; \"\n                ' rel=\"last\"'\n            ),\n            \"server\": \"GitHub.com\",\n            \"status\": \"200 OK\",\n            \"vary\": \"Accept\",\n            \"x-content-type-options\": \"nosniff\",\n            \"x-github-media-type\": \"github.beta\",\n            \"x-ratelimit-limit\": \"60\",\n            \"x-ratelimit-remaining\": \"57\",\n        }\n        assert r.links[\"next\"][\"rel\"] == \"next\"\n\n    def test_cookie_parameters(self):\n        key = \"some_cookie\"\n        value = \"some_value\"\n        secure = True\n        domain = \"test.com\"\n        rest = {\"HttpOnly\": True}\n\n        jar = requests.cookies.RequestsCookieJar()\n        jar.set(key, value, secure=secure, domain=domain, rest=rest)\n\n        assert len(jar) == 1\n        assert \"some_cookie\" in jar\n\n        cookie = list(jar)[0]\n        assert cookie.secure == secure\n        assert cookie.domain == domain\n        assert cookie._rest[\"HttpOnly\"] == rest[\"HttpOnly\"]\n\n    def test_cookie_as_dict_keeps_len(self):\n        key = \"some_cookie\"\n        value = \"some_value\"\n\n        key1 = \"som"}, {"start_line": 16000, "end_line": 18000, "belongs_to": {"file_name": "test_requests.py", "upper_path": "/data2/raymone/swebench-repos/requests/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "    req = requests.Request(\"GET\", httpbin(\"headers\"), cookies=cj)\n        prep_req = req.prepare()\n\n        # Send request and simulate redirect\n        resp = s.send(prep_req)\n        resp.status_code = 302\n        resp.headers[\"location\"] = httpbin(\"get\")\n        redirects = s.resolve_redirects(resp, prep_req)\n        resp = next(redirects)\n\n        # Verify CookieJar isn't being converted to RequestsCookieJar\n        assert isinstance(prep_req._cookies, cookielib.CookieJar)\n        assert isinstance(resp.request._cookies, cookielib.CookieJar)\n        assert not isinstance(resp.request._cookies, requests.cookies.RequestsCookieJar)\n\n        cookies = {}\n        for c in resp.request._cookies:\n            cookies[c.name] = c.value\n        assert cookies[\"foo\"] == \"bar\"\n        assert cookies[\"cookie\"] == \"tasty\"\n\n    def test_requests_in_history_are_not_overridden(self, httpbin):\n        resp = requests.get(httpbin(\"redirect/3\"))\n        urls = [r.url for r in resp.history]\n        req_urls = [r.request.url for r in resp.history]\n        assert urls == req_urls\n\n    def test_history_is_always_a_list(self, httpbin):\n        \"\"\"Show that even with redirects, Response.history is always a list.\"\"\"\n        resp = requests.get(httpbin(\"get\"))\n        assert isinstance(resp.history, list)\n        resp = requests.get(httpbin(\"redirect/1\"))\n        assert isinstance(resp.history, list)\n        assert not isinstance(resp.history, tuple)\n\n    def test_headers_on_session_with_None_are_not_sent(self, httpbin):\n        \"\"\"Do not send headers in Session.headers with None values.\"\"\"\n        ses = requests.Session()\n        ses.headers[\"Accept-Encoding\"] = None\n        req = requests.Request(\"GET\", httpbin(\"get\"))\n        prep = ses.prepare_request(req)\n        assert \"Accept-Encoding\" not in prep.headers\n\n    def test_headers_preserve_order(self, httpbin):\n        \"\"\"Preserve order when headers provided as OrderedDict.\"\"\"\n        ses = requests.Session()\n        ses.headers = colle"}], "retrieved_count": 10, "cost_time": 1.0354254245758057}
{"question": "How does Requests handle connection pooling and reuse?", "answer": null, "relative_code_list": null, "ground_truth": "Requests handles connection pooling and reuse through HTTPAdapter in src/requests/adapters.py: 1) Pool creation - HTTPAdapter.init_poolmanager() creates urllib3 PoolManager instances for connection pooling; 2) Connection limits - Pools are configured with pool_connections (number of pools) and pool_maxsize (connections per pool); 3) Connection reuse - HTTPAdapter.send() uses urllib3's urlopen() which automatically reuses connections from the pool; 4) Host-based pooling - Connections are pooled per host, allowing reuse across multiple requests to the same server; 5) Connection lifecycle - Pools manage connection creation, reuse, and cleanup automatically; 6) Thread safety - urllib3 pools are thread-safe, enabling concurrent access; 7) Connection health - Pools automatically handle failed connections and create new ones as needed; 8) Timeout management - Connection timeouts are handled at the pool level; 9) Resource cleanup - HTTPAdapter.close() properly closes and cleans up connection pools; 10) Configuration flexibility - Pool parameters can be customized per adapter for different use cases.", "score": null, "retrieved_content": [{"start_line": 5000, "end_line": 7000, "belongs_to": {"file_name": "adapters.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": " requests where data has\n        made it to the server. By default, Requests does not retry failed\n        connections. If you need granular control over the conditions under\n        which we retry a request, import urllib3's ``Retry`` class and pass\n        that instead.\n    :param pool_block: Whether the connection pool should block for connections.\n\n    Usage::\n\n      >>> import requests\n      >>> s = requests.Session()\n      >>> a = requests.adapters.HTTPAdapter(max_retries=3)\n      >>> s.mount('http://', a)\n    \"\"\"\n\n    __attrs__ = [\n        \"max_retries\",\n        \"config\",\n        \"_pool_connections\",\n        \"_pool_maxsize\",\n        \"_pool_block\",\n    ]\n\n    def __init__(\n        self,\n        pool_connections=DEFAULT_POOLSIZE,\n        pool_maxsize=DEFAULT_POOLSIZE,\n        max_retries=DEFAULT_RETRIES,\n        pool_block=DEFAULT_POOLBLOCK,\n    ):\n        if max_retries == DEFAULT_RETRIES:\n            self.max_retries = Retry(0, read=False)\n        else:\n            self.max_retries = Retry.from_int(max_retries)\n        self.config = {}\n        self.proxy_manager = {}\n\n        super().__init__()\n\n        self._pool_connections = pool_connections\n        self._pool_maxsize = pool_maxsize\n        self._pool_block = pool_block\n\n        self.init_poolmanager(pool_connections, pool_maxsize, block=pool_block)\n\n    def __getstate__(self):\n        return {attr: getattr(self, attr, None) for attr in self.__attrs__}\n\n    def __setstate__(self, state):\n        # Can't handle by adding 'proxy_manager' to self.__attrs__ because\n        # self.poolmanager uses a lambda function, which isn't pickleable.\n        self.proxy_manager = {}\n        self.config = {}\n\n        for attr, value in state.items():\n            setattr(self, attr, value)\n\n        self.init_poolmanager(\n            self._pool_connections, self._pool_maxsize, block=self._pool_block\n        )\n\n    def init_poolmanager(\n        self, connections, maxsize, block=DEFAULT_POOLBLOCK, **pool_kwargs\n    ):\n        \""}, {"start_line": 13000, "end_line": 15000, "belongs_to": {"file_name": "sessions.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "POST is responded to with a 301, turn it into a GET.\n        # This bizarre behaviour is explained in Issue 1704.\n        if response.status_code == codes.moved and method == \"POST\":\n            method = \"GET\"\n\n        prepared_request.method = method\n\n\nclass Session(SessionRedirectMixin):\n    \"\"\"A Requests session.\n\n    Provides cookie persistence, connection-pooling, and configuration.\n\n    Basic Usage::\n\n      >>> import requests\n      >>> s = requests.Session()\n      >>> s.get('https://httpbin.org/get')\n      <Response [200]>\n\n    Or as a context manager::\n\n      >>> with requests.Session() as s:\n      ...     s.get('https://httpbin.org/get')\n      <Response [200]>\n    \"\"\"\n\n    __attrs__ = [\n        \"headers\",\n        \"cookies\",\n        \"auth\",\n        \"proxies\",\n        \"hooks\",\n        \"params\",\n        \"verify\",\n        \"cert\",\n        \"adapters\",\n        \"stream\",\n        \"trust_env\",\n        \"max_redirects\",\n    ]\n\n    def __init__(self):\n        #: A case-insensitive dictionary of headers to be sent on each\n        #: :class:`Request <Request>` sent from this\n        #: :class:`Session <Session>`.\n        self.headers = default_headers()\n\n        #: Default Authentication tuple or object to attach to\n        #: :class:`Request <Request>`.\n        self.auth = None\n\n        #: Dictionary mapping protocol or protocol and host to the URL of the proxy\n        #: (e.g. {'http': 'foo.bar:3128', 'http://host.name': 'foo.bar:4012'}) to\n        #: be used on each :class:`Request <Request>`.\n        self.proxies = {}\n\n        #: Event-handling hooks.\n        self.hooks = default_hooks()\n\n        #: Dictionary of querystring data to attach to each\n        #: :class:`Request <Request>`. The dictionary values may be lists for\n        #: representing multivalued query parameters.\n        self.params = {}\n\n        #: Stream response content default.\n        self.stream = False\n\n        #: SSL Verification default.\n        #: Defaults to `True`, requiring requests to verif"}, {"start_line": 19000, "end_line": 21000, "belongs_to": {"file_name": "adapters.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "(url)\n        else:\n            # Only scheme should be lower case\n            parsed = urlparse(url)\n            url = parsed.geturl()\n            conn = self.poolmanager.connection_from_url(url)\n\n        return conn\n\n    def close(self):\n        \"\"\"Disposes of any internal state.\n\n        Currently, this closes the PoolManager and any active ProxyManager,\n        which closes any pooled connections.\n        \"\"\"\n        self.poolmanager.clear()\n        for proxy in self.proxy_manager.values():\n            proxy.clear()\n\n    def request_url(self, request, proxies):\n        \"\"\"Obtain the url to use when making the final request.\n\n        If the message is being sent through a HTTP proxy, the full URL has to\n        be used. Otherwise, we should only use the path portion of the URL.\n\n        This should not be called from user code, and is only exposed for use\n        when subclassing the\n        :class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.\n\n        :param request: The :class:`PreparedRequest <PreparedRequest>` being sent.\n        :param proxies: A dictionary of schemes or schemes and hosts to proxy URLs.\n        :rtype: str\n        \"\"\"\n        proxy = select_proxy(request.url, proxies)\n        scheme = urlparse(request.url).scheme\n\n        is_proxied_http_request = proxy and scheme != \"https\"\n        using_socks_proxy = False\n        if proxy:\n            proxy_scheme = urlparse(proxy).scheme.lower()\n            using_socks_proxy = proxy_scheme.startswith(\"socks\")\n\n        url = request.path_url\n        if url.startswith(\"//\"):  # Don't confuse urllib3\n            url = f\"/{url.lstrip('/')}\"\n\n        if is_proxied_http_request and not using_socks_proxy:\n            url = urldefragauth(request.url)\n\n        return url\n\n    def add_headers(self, request, **kwargs):\n        \"\"\"Add any headers needed by the connection. As of v2.0 this does\n        nothing by default, but is left for overriding by users that subclass\n        the :class:`HTTPAdapter <requests.adap"}, {"start_line": 0, "end_line": 2000, "belongs_to": {"file_name": "adapters.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "\"\"\"\nrequests.adapters\n~~~~~~~~~~~~~~~~~\n\nThis module contains the transport adapters that Requests uses to define\nand maintain connections.\n\"\"\"\n\nimport os.path\nimport socket  # noqa: F401\nimport typing\nimport warnings\n\nfrom urllib3.exceptions import ClosedPoolError, ConnectTimeoutError\nfrom urllib3.exceptions import HTTPError as _HTTPError\nfrom urllib3.exceptions import InvalidHeader as _InvalidHeader\nfrom urllib3.exceptions import (\n    LocationValueError,\n    MaxRetryError,\n    NewConnectionError,\n    ProtocolError,\n)\nfrom urllib3.exceptions import ProxyError as _ProxyError\nfrom urllib3.exceptions import ReadTimeoutError, ResponseError\nfrom urllib3.exceptions import SSLError as _SSLError\nfrom urllib3.poolmanager import PoolManager, proxy_from_url\nfrom urllib3.util import Timeout as TimeoutSauce\nfrom urllib3.util import parse_url\nfrom urllib3.util.retry import Retry\n\nfrom .auth import _basic_auth_str\nfrom .compat import basestring, urlparse\nfrom .cookies import extract_cookies_to_jar\nfrom .exceptions import (\n    ConnectionError,\n    ConnectTimeout,\n    InvalidHeader,\n    InvalidProxyURL,\n    InvalidSchema,\n    InvalidURL,\n    ProxyError,\n    ReadTimeout,\n    RetryError,\n    SSLError,\n)\nfrom .models import Response\nfrom .structures import CaseInsensitiveDict\nfrom .utils import (\n    DEFAULT_CA_BUNDLE_PATH,\n    extract_zipped_paths,\n    get_auth_from_url,\n    get_encoding_from_headers,\n    prepend_scheme_if_needed,\n    select_proxy,\n    urldefragauth,\n)\n\ntry:\n    from urllib3.contrib.socks import SOCKSProxyManager\nexcept ImportError:\n\n    def SOCKSProxyManager(*args, **kwargs):\n        raise InvalidSchema(\"Missing dependencies for SOCKS support.\")\n\n\nif typing.TYPE_CHECKING:\n    from .models import PreparedRequest\n\n\nDEFAULT_POOLBLOCK = False\nDEFAULT_POOLSIZE = 10\nDEFAULT_RETRIES = 0\nDEFAULT_POOL_TIMEOUT = None\n\n\ndef _urllib3_request_context(\n    request: \"PreparedRequest\",\n    verify: \"bool | str | None\",\n    client_cert: \"typing.Tuple[str, str] | str | None\",\n    po"}, {"start_line": 94000, "end_line": 96000, "belongs_to": {"file_name": "test_requests.py", "upper_path": "/data2/raymone/swebench-repos/requests/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "\"_cookies\", \"body\", \"hooks\"):\n        assert getattr(p, attr) == getattr(copy, attr)\n\n\ndef test_urllib3_retries(httpbin):\n    from urllib3.util import Retry\n\n    s = requests.Session()\n    s.mount(\"http://\", HTTPAdapter(max_retries=Retry(total=2, status_forcelist=[500])))\n\n    with pytest.raises(RetryError):\n        s.get(httpbin(\"status/500\"))\n\n\ndef test_urllib3_pool_connection_closed(httpbin):\n    s = requests.Session()\n    s.mount(\"http://\", HTTPAdapter(pool_connections=0, pool_maxsize=0))\n\n    try:\n        s.get(httpbin(\"status/200\"))\n    except ConnectionError as e:\n        assert \"Pool is closed.\" in str(e)\n\n\nclass TestPreparingURLs:\n    @pytest.mark.parametrize(\n        \"url,expected\",\n        (\n            (\"http://google.com\", \"http://google.com/\"),\n            (\"http://.jp\", \"http://xn--hckqz9bzb1cyrb.jp/\"),\n            (\"http://xn--n3h.net/\", \"http://xn--n3h.net/\"),\n            (\"http://.jp\".encode(), \"http://xn--hckqz9bzb1cyrb.jp/\"),\n            (\"http://strae.de/strae\", \"http://xn--strae-oqa.de/stra%C3%9Fe\"),\n            (\n                \"http://strae.de/strae\".encode(),\n                \"http://xn--strae-oqa.de/stra%C3%9Fe\",\n            ),\n            (\n                \"http://Knigsgchen.de/strae\",\n                \"http://xn--knigsgchen-b4a3dun.de/stra%C3%9Fe\",\n            ),\n            (\n                \"http://Knigsgchen.de/strae\".encode(),\n                \"http://xn--knigsgchen-b4a3dun.de/stra%C3%9Fe\",\n            ),\n            (b\"http://xn--n3h.net/\", \"http://xn--n3h.net/\"),\n            (\n                b\"http://[1200:0000:ab00:1234:0000:2552:7777:1313]:12345/\",\n                \"http://[1200:0000:ab00:1234:0000:2552:7777:1313]:12345/\",\n            ),\n            (\n                \"http://[1200:0000:ab00:1234:0000:2552:7777:1313]:12345/\",\n                \"http://[1200:0000:ab00:1234:0000:2552:7777:1313]:12345/\",\n            ),\n        ),\n    )\n    def test_preparing_url(self, url, expected):\n        def normalize_perce"}, {"start_line": 4000, "end_line": 6000, "belongs_to": {"file_name": "adapters.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "        :param cert: (optional) Any user-provided SSL certificate to be trusted.\n        :param proxies: (optional) The proxies dictionary to apply to the request.\n        \"\"\"\n        raise NotImplementedError\n\n    def close(self):\n        \"\"\"Cleans up adapter specific items.\"\"\"\n        raise NotImplementedError\n\n\nclass HTTPAdapter(BaseAdapter):\n    \"\"\"The built-in HTTP Adapter for urllib3.\n\n    Provides a general-case interface for Requests sessions to contact HTTP and\n    HTTPS urls by implementing the Transport Adapter interface. This class will\n    usually be created by the :class:`Session <Session>` class under the\n    covers.\n\n    :param pool_connections: The number of urllib3 connection pools to cache.\n    :param pool_maxsize: The maximum number of connections to save in the pool.\n    :param max_retries: The maximum number of retries each connection\n        should attempt. Note, this applies only to failed DNS lookups, socket\n        connections and connection timeouts, never to requests where data has\n        made it to the server. By default, Requests does not retry failed\n        connections. If you need granular control over the conditions under\n        which we retry a request, import urllib3's ``Retry`` class and pass\n        that instead.\n    :param pool_block: Whether the connection pool should block for connections.\n\n    Usage::\n\n      >>> import requests\n      >>> s = requests.Session()\n      >>> a = requests.adapters.HTTPAdapter(max_retries=3)\n      >>> s.mount('http://', a)\n    \"\"\"\n\n    __attrs__ = [\n        \"max_retries\",\n        \"config\",\n        \"_pool_connections\",\n        \"_pool_maxsize\",\n        \"_pool_block\",\n    ]\n\n    def __init__(\n        self,\n        pool_connections=DEFAULT_POOLSIZE,\n        pool_maxsize=DEFAULT_POOLSIZE,\n        max_retries=DEFAULT_RETRIES,\n        pool_block=DEFAULT_POOLBLOCK,\n    ):\n        if max_retries == DEFAULT_RETRIES:\n            self.max_retries = Retry(0, read=False)\n        else:\n            self.max_retr"}, {"start_line": 3000, "end_line": 5000, "belongs_to": {"file_name": "adapters.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "     \"host\": parsed_request_url.hostname,\n        \"port\": port,\n    }\n    return host_params, pool_kwargs\n\n\nclass BaseAdapter:\n    \"\"\"The Base Transport Adapter\"\"\"\n\n    def __init__(self):\n        super().__init__()\n\n    def send(\n        self, request, stream=False, timeout=None, verify=True, cert=None, proxies=None\n    ):\n        \"\"\"Sends PreparedRequest object. Returns Response object.\n\n        :param request: The :class:`PreparedRequest <PreparedRequest>` being sent.\n        :param stream: (optional) Whether to stream the request content.\n        :param timeout: (optional) How long to wait for the server to send\n            data before giving up, as a float, or a :ref:`(connect timeout,\n            read timeout) <timeouts>` tuple.\n        :type timeout: float or tuple\n        :param verify: (optional) Either a boolean, in which case it controls whether we verify\n            the server's TLS certificate, or a string, in which case it must be a path\n            to a CA bundle to use\n        :param cert: (optional) Any user-provided SSL certificate to be trusted.\n        :param proxies: (optional) The proxies dictionary to apply to the request.\n        \"\"\"\n        raise NotImplementedError\n\n    def close(self):\n        \"\"\"Cleans up adapter specific items.\"\"\"\n        raise NotImplementedError\n\n\nclass HTTPAdapter(BaseAdapter):\n    \"\"\"The built-in HTTP Adapter for urllib3.\n\n    Provides a general-case interface for Requests sessions to contact HTTP and\n    HTTPS urls by implementing the Transport Adapter interface. This class will\n    usually be created by the :class:`Session <Session>` class under the\n    covers.\n\n    :param pool_connections: The number of urllib3 connection pools to cache.\n    :param pool_maxsize: The maximum number of connections to save in the pool.\n    :param max_retries: The maximum number of retries each connection\n        should attempt. Note, this applies only to failed DNS lookups, socket\n        connections and connection timeouts, never to"}, {"start_line": 74000, "end_line": 76000, "belongs_to": {"file_name": "test_requests.py", "upper_path": "/data2/raymone/swebench-repos/requests/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "name, password)\n        assert isinstance(s, builtin_str)\n        assert s == auth_str\n\n    def test_requests_history_is_saved(self, httpbin):\n        r = requests.get(httpbin(\"redirect/5\"))\n        total = r.history[-1].history\n        i = 0\n        for item in r.history:\n            assert item.history == total[0:i]\n            i += 1\n\n    def test_json_param_post_content_type_works(self, httpbin):\n        r = requests.post(httpbin(\"post\"), json={\"life\": 42})\n        assert r.status_code == 200\n        assert \"application/json\" in r.request.headers[\"Content-Type\"]\n        assert {\"life\": 42} == r.json()[\"json\"]\n\n    def test_json_param_post_should_not_override_data_param(self, httpbin):\n        r = requests.Request(\n            method=\"POST\",\n            url=httpbin(\"post\"),\n            data={\"stuff\": \"elixr\"},\n            json={\"music\": \"flute\"},\n        )\n        prep = r.prepare()\n        assert \"stuff=elixr\" == prep.body\n\n    def test_response_iter_lines(self, httpbin):\n        r = requests.get(httpbin(\"stream/4\"), stream=True)\n        assert r.status_code == 200\n\n        it = r.iter_lines()\n        next(it)\n        assert len(list(it)) == 3\n\n    def test_response_context_manager(self, httpbin):\n        with requests.get(httpbin(\"stream/4\"), stream=True) as response:\n            assert isinstance(response, requests.Response)\n\n        assert response.raw.closed\n\n    def test_unconsumed_session_response_closes_connection(self, httpbin):\n        s = requests.session()\n\n        with contextlib.closing(s.get(httpbin(\"stream/4\"), stream=True)) as response:\n            pass\n\n        assert response._content_consumed is False\n        assert response.raw.closed\n\n    @pytest.mark.xfail\n    def test_response_iter_lines_reentrant(self, httpbin):\n        \"\"\"Response.iter_lines() is not reentrant safe\"\"\"\n        r = requests.get(httpbin(\"stream/4\"), stream=True)\n        assert r.status_code == 200\n\n        next(r.iter_lines())\n        assert len(list(r.iter_lines())) == 3\n\n"}, {"start_line": 8000, "end_line": 10000, "belongs_to": {"file_name": "sessions.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "     # https://github.com/psf/requests/issues/3490\n                purged_headers = (\"Content-Length\", \"Content-Type\", \"Transfer-Encoding\")\n                for header in purged_headers:\n                    prepared_request.headers.pop(header, None)\n                prepared_request.body = None\n\n            headers = prepared_request.headers\n            headers.pop(\"Cookie\", None)\n\n            # Extract any cookies sent on the response to the cookiejar\n            # in the new request. Because we've mutated our copied prepared\n            # request, use the old one that we haven't yet touched.\n            extract_cookies_to_jar(prepared_request._cookies, req, resp.raw)\n            merge_cookies(prepared_request._cookies, self.cookies)\n            prepared_request.prepare_cookies(prepared_request._cookies)\n\n            # Rebuild auth and proxy information.\n            proxies = self.rebuild_proxies(prepared_request, proxies)\n            self.rebuild_auth(prepared_request, resp)\n\n            # A failed tell() sets `_body_position` to `object()`. This non-None\n            # value ensures `rewindable` will be True, allowing us to raise an\n            # UnrewindableBodyError, instead of hanging the connection.\n            rewindable = prepared_request._body_position is not None and (\n                \"Content-Length\" in headers or \"Transfer-Encoding\" in headers\n            )\n\n            # Attempt to rewind consumed file-like object.\n            if rewindable:\n                rewind_body(prepared_request)\n\n            # Override the original request.\n            req = prepared_request\n\n            if yield_requests:\n                yield req\n            else:\n                resp = self.send(\n                    req,\n                    stream=stream,\n                    timeout=timeout,\n                    verify=verify,\n                    cert=cert,\n                    proxies=proxies,\n                    allow_redirects=False,\n                    **adapter_kwargs,\n     "}, {"start_line": 0, "end_line": 2000, "belongs_to": {"file_name": "sessions.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "\"\"\"\nrequests.sessions\n~~~~~~~~~~~~~~~~~\n\nThis module provides a Session object to manage and persist settings across\nrequests (cookies, auth, proxies).\n\"\"\"\nimport os\nimport sys\nimport time\nfrom collections import OrderedDict\nfrom datetime import timedelta\n\nfrom ._internal_utils import to_native_string\nfrom .adapters import HTTPAdapter\nfrom .auth import _basic_auth_str\nfrom .compat import Mapping, cookielib, urljoin, urlparse\nfrom .cookies import (\n    RequestsCookieJar,\n    cookiejar_from_dict,\n    extract_cookies_to_jar,\n    merge_cookies,\n)\nfrom .exceptions import (\n    ChunkedEncodingError,\n    ContentDecodingError,\n    InvalidSchema,\n    TooManyRedirects,\n)\nfrom .hooks import default_hooks, dispatch_hook\n\n# formerly defined here, reexposed here for backward compatibility\nfrom .models import (  # noqa: F401\n    DEFAULT_REDIRECT_LIMIT,\n    REDIRECT_STATI,\n    PreparedRequest,\n    Request,\n)\nfrom .status_codes import codes\nfrom .structures import CaseInsensitiveDict\nfrom .utils import (  # noqa: F401\n    DEFAULT_PORTS,\n    default_headers,\n    get_auth_from_url,\n    get_environ_proxies,\n    get_netrc_auth,\n    requote_uri,\n    resolve_proxies,\n    rewind_body,\n    should_bypass_proxies,\n    to_key_val_list,\n)\n\n# Preferred clock, based on which one is more accurate on a given system.\nif sys.platform == \"win32\":\n    preferred_clock = time.perf_counter\nelse:\n    preferred_clock = time.time\n\n\ndef merge_setting(request_setting, session_setting, dict_class=OrderedDict):\n    \"\"\"Determines appropriate setting for a given request, taking into account\n    the explicit setting on that request, and the setting in the session. If a\n    setting is a dictionary, they will be merged together using `dict_class`\n    \"\"\"\n\n    if session_setting is None:\n        return request_setting\n\n    if request_setting is None:\n        return session_setting\n\n    # Bypass if not a dictionary (e.g. verify)\n    if not (\n        isinstance(session_setting, Mapping) and isinstance(request_setting, M"}], "retrieved_count": 10, "cost_time": 1.011732578277588}
{"question": "How does Requests handle HTTP authentication?", "answer": null, "relative_code_list": null, "ground_truth": "Requests handles HTTP authentication through multiple components: 1) Authentication handlers - Defined in src/requests/auth.py (HTTPBasicAuth, HTTPDigestAuth, HTTPProxyAuth) that implement the __call__() method; 2) Request preparation - PreparedRequest.prepare_auth() in src/requests/models.py applies authentication handlers to add Authorization headers; 3) Session integration - Sessions can store default authentication credentials applied to all requests; 4) Challenge handling - HTTPDigestAuth.handle_401() implements automatic retry logic for 401 challenges; 5) Header generation - Authentication handlers generate appropriate Authorization or Proxy-Authorization headers; 6) Credential encoding - _basic_auth_str() function encodes username/password in base64 for Basic Auth; 7) Digest calculation - HTTPDigestAuth implements MD5, SHA, SHA-256, SHA-512 digest algorithms; 8) Thread safety - HTTPDigestAuth uses thread-local storage for nonce management; 9) Redirect handling - Authentication handlers can respond to authentication challenges during redirects; 10) Environment integration - Sessions can automatically detect authentication from environment variables when trust_env is enabled.", "score": null, "retrieved_content": [{"start_line": 25000, "end_line": 27000, "belongs_to": {"file_name": "test_requests.py", "upper_path": "/data2/raymone/swebench-repos/requests/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "get_netrc_auth_mock(url):\n                return auth\n\n            requests.sessions.get_netrc_auth = get_netrc_auth_mock\n\n            # Should use netrc and work.\n            r = requests.get(url)\n            assert r.status_code == 200\n\n            # Given auth should override and fail.\n            r = requests.get(url, auth=wrong_auth)\n            assert r.status_code == 401\n\n            s = requests.session()\n\n            # Should use netrc and work.\n            r = s.get(url)\n            assert r.status_code == 200\n\n            # Given auth should override and fail.\n            s.auth = wrong_auth\n            r = s.get(url)\n            assert r.status_code == 401\n        finally:\n            requests.sessions.get_netrc_auth = old_auth\n\n    def test_basicauth_with_netrc_leak(self, httpbin):\n        url1 = httpbin(\"basic-auth\", \"user\", \"pass\")\n        url = url1[len(\"http://\") :]\n        domain = url.split(\":\")[0]\n        url = f\"http://example.com:@{url}\"\n\n        netrc_file = \"\"\n        with tempfile.NamedTemporaryFile(mode=\"w\", delete=False) as fp:\n            fp.write(\"machine example.com\\n\")\n            fp.write(\"login wronguser\\n\")\n            fp.write(\"password wrongpass\\n\")\n            fp.write(f\"machine {domain}\\n\")\n            fp.write(\"login user\\n\")\n            fp.write(\"password pass\\n\")\n            fp.close()\n            netrc_file = fp.name\n\n        old_netrc = os.environ.get(\"NETRC\", \"\")\n        os.environ[\"NETRC\"] = netrc_file\n\n        try:\n            # Should use netrc\n            # Make sure that we don't use the example.com credentails\n            # for the request\n            r = requests.get(url)\n            assert r.status_code == 200\n        finally:\n            os.environ[\"NETRC\"] = old_netrc\n            os.unlink(netrc_file)\n\n    def test_DIGEST_HTTP_200_OK_GET(self, httpbin):\n        for authtype in self.digest_auth_algo:\n            auth = HTTPDigestAuth(\"user\", \"pass\")\n            url = httpbin(\"digest-auth\", \"auth\", \"user\", \"pass\", "}, {"start_line": 27000, "end_line": 29000, "belongs_to": {"file_name": "test_requests.py", "upper_path": "/data2/raymone/swebench-repos/requests/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "authtype, \"never\")\n\n            r = requests.get(url, auth=auth)\n            assert r.status_code == 200\n\n            r = requests.get(url)\n            assert r.status_code == 401\n            print(r.headers[\"WWW-Authenticate\"])\n\n            s = requests.session()\n            s.auth = HTTPDigestAuth(\"user\", \"pass\")\n            r = s.get(url)\n            assert r.status_code == 200\n\n    def test_DIGEST_AUTH_RETURNS_COOKIE(self, httpbin):\n        for authtype in self.digest_auth_algo:\n            url = httpbin(\"digest-auth\", \"auth\", \"user\", \"pass\", authtype)\n            auth = HTTPDigestAuth(\"user\", \"pass\")\n            r = requests.get(url)\n            assert r.cookies[\"fake\"] == \"fake_value\"\n\n            r = requests.get(url, auth=auth)\n            assert r.status_code == 200\n\n    def test_DIGEST_AUTH_SETS_SESSION_COOKIES(self, httpbin):\n        for authtype in self.digest_auth_algo:\n            url = httpbin(\"digest-auth\", \"auth\", \"user\", \"pass\", authtype)\n            auth = HTTPDigestAuth(\"user\", \"pass\")\n            s = requests.Session()\n            s.get(url, auth=auth)\n            assert s.cookies[\"fake\"] == \"fake_value\"\n\n    def test_DIGEST_STREAM(self, httpbin):\n        for authtype in self.digest_auth_algo:\n            auth = HTTPDigestAuth(\"user\", \"pass\")\n            url = httpbin(\"digest-auth\", \"auth\", \"user\", \"pass\", authtype)\n\n            r = requests.get(url, auth=auth, stream=True)\n            assert r.raw.read() != b\"\"\n\n            r = requests.get(url, auth=auth, stream=False)\n            assert r.raw.read() == b\"\"\n\n    def test_DIGESTAUTH_WRONG_HTTP_401_GET(self, httpbin):\n        for authtype in self.digest_auth_algo:\n            auth = HTTPDigestAuth(\"user\", \"wrongpass\")\n            url = httpbin(\"digest-auth\", \"auth\", \"user\", \"pass\", authtype)\n\n            r = requests.get(url, auth=auth)\n            assert r.status_code == 401\n\n            r = requests.get(url)\n            assert r.status_code == 401\n\n            s = requests.session()\n          "}, {"start_line": 28000, "end_line": 30000, "belongs_to": {"file_name": "test_requests.py", "upper_path": "/data2/raymone/swebench-repos/requests/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "Auth(\"user\", \"pass\")\n            s = requests.Session()\n            s.get(url, auth=auth)\n            assert s.cookies[\"fake\"] == \"fake_value\"\n\n    def test_DIGEST_STREAM(self, httpbin):\n        for authtype in self.digest_auth_algo:\n            auth = HTTPDigestAuth(\"user\", \"pass\")\n            url = httpbin(\"digest-auth\", \"auth\", \"user\", \"pass\", authtype)\n\n            r = requests.get(url, auth=auth, stream=True)\n            assert r.raw.read() != b\"\"\n\n            r = requests.get(url, auth=auth, stream=False)\n            assert r.raw.read() == b\"\"\n\n    def test_DIGESTAUTH_WRONG_HTTP_401_GET(self, httpbin):\n        for authtype in self.digest_auth_algo:\n            auth = HTTPDigestAuth(\"user\", \"wrongpass\")\n            url = httpbin(\"digest-auth\", \"auth\", \"user\", \"pass\", authtype)\n\n            r = requests.get(url, auth=auth)\n            assert r.status_code == 401\n\n            r = requests.get(url)\n            assert r.status_code == 401\n\n            s = requests.session()\n            s.auth = auth\n            r = s.get(url)\n            assert r.status_code == 401\n\n    def test_DIGESTAUTH_QUOTES_QOP_VALUE(self, httpbin):\n        for authtype in self.digest_auth_algo:\n            auth = HTTPDigestAuth(\"user\", \"pass\")\n            url = httpbin(\"digest-auth\", \"auth\", \"user\", \"pass\", authtype)\n\n            r = requests.get(url, auth=auth)\n            assert '\"auth\"' in r.request.headers[\"Authorization\"]\n\n    def test_POSTBIN_GET_POST_FILES(self, httpbin):\n        url = httpbin(\"post\")\n        requests.post(url).raise_for_status()\n\n        post1 = requests.post(url, data={\"some\": \"data\"})\n        assert post1.status_code == 200\n\n        with open(\"requirements-dev.txt\") as f:\n            post2 = requests.post(url, files={\"some\": f})\n        assert post2.status_code == 200\n\n        post4 = requests.post(url, data='[{\"some\": \"json\"}]')\n        assert post4.status_code == 200\n\n        with pytest.raises(ValueError):\n            requests.post(url, files=[\"bad file data\"])\n"}, {"start_line": 19000, "end_line": 21000, "belongs_to": {"file_name": "test_requests.py", "upper_path": "/data2/raymone/swebench-repos/requests/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "   def test_HTTP_200_OK_HEAD(self, httpbin):\n        r = requests.head(httpbin(\"get\"))\n        assert r.status_code == 200\n\n    def test_HTTP_200_OK_PUT(self, httpbin):\n        r = requests.put(httpbin(\"put\"))\n        assert r.status_code == 200\n\n    def test_BASICAUTH_TUPLE_HTTP_200_OK_GET(self, httpbin):\n        auth = (\"user\", \"pass\")\n        url = httpbin(\"basic-auth\", \"user\", \"pass\")\n\n        r = requests.get(url, auth=auth)\n        assert r.status_code == 200\n\n        r = requests.get(url)\n        assert r.status_code == 401\n\n        s = requests.session()\n        s.auth = auth\n        r = s.get(url)\n        assert r.status_code == 200\n\n    @pytest.mark.parametrize(\n        \"username, password\",\n        (\n            (\"user\", \"pass\"),\n            (\"\".encode(), \"\".encode()),\n            (42, 42),\n            (None, None),\n        ),\n    )\n    def test_set_basicauth(self, httpbin, username, password):\n        auth = (username, password)\n        url = httpbin(\"get\")\n\n        r = requests.Request(\"GET\", url, auth=auth)\n        p = r.prepare()\n\n        assert p.headers[\"Authorization\"] == _basic_auth_str(username, password)\n\n    def test_basicauth_encodes_byte_strings(self):\n        \"\"\"Ensure b'test' formats as the byte string \"test\" rather\n        than the unicode string \"b'test'\" in Python 3.\n        \"\"\"\n        auth = (b\"\\xc5\\xafsername\", b\"test\\xc6\\xb6\")\n        r = requests.Request(\"GET\", \"http://localhost\", auth=auth)\n        p = r.prepare()\n\n        assert p.headers[\"Authorization\"] == \"Basic xa9zZXJuYW1lOnRlc3TGtg==\"\n\n    @pytest.mark.parametrize(\n        \"url, exception\",\n        (\n            # Connecting to an unknown domain should raise a ConnectionError\n            (\"http://doesnotexist.google.com\", ConnectionError),\n            # Connecting to an invalid port should raise a ConnectionError\n            (\"http://localhost:1\", ConnectionError),\n            # Inputing a URL that cannot be parsed should raise an InvalidURL error\n            (\"http"}, {"start_line": 26000, "end_line": 28000, "belongs_to": {"file_name": "test_requests.py", "upper_path": "/data2/raymone/swebench-repos/requests/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "       with tempfile.NamedTemporaryFile(mode=\"w\", delete=False) as fp:\n            fp.write(\"machine example.com\\n\")\n            fp.write(\"login wronguser\\n\")\n            fp.write(\"password wrongpass\\n\")\n            fp.write(f\"machine {domain}\\n\")\n            fp.write(\"login user\\n\")\n            fp.write(\"password pass\\n\")\n            fp.close()\n            netrc_file = fp.name\n\n        old_netrc = os.environ.get(\"NETRC\", \"\")\n        os.environ[\"NETRC\"] = netrc_file\n\n        try:\n            # Should use netrc\n            # Make sure that we don't use the example.com credentails\n            # for the request\n            r = requests.get(url)\n            assert r.status_code == 200\n        finally:\n            os.environ[\"NETRC\"] = old_netrc\n            os.unlink(netrc_file)\n\n    def test_DIGEST_HTTP_200_OK_GET(self, httpbin):\n        for authtype in self.digest_auth_algo:\n            auth = HTTPDigestAuth(\"user\", \"pass\")\n            url = httpbin(\"digest-auth\", \"auth\", \"user\", \"pass\", authtype, \"never\")\n\n            r = requests.get(url, auth=auth)\n            assert r.status_code == 200\n\n            r = requests.get(url)\n            assert r.status_code == 401\n            print(r.headers[\"WWW-Authenticate\"])\n\n            s = requests.session()\n            s.auth = HTTPDigestAuth(\"user\", \"pass\")\n            r = s.get(url)\n            assert r.status_code == 200\n\n    def test_DIGEST_AUTH_RETURNS_COOKIE(self, httpbin):\n        for authtype in self.digest_auth_algo:\n            url = httpbin(\"digest-auth\", \"auth\", \"user\", \"pass\", authtype)\n            auth = HTTPDigestAuth(\"user\", \"pass\")\n            r = requests.get(url)\n            assert r.cookies[\"fake\"] == \"fake_value\"\n\n            r = requests.get(url, auth=auth)\n            assert r.status_code == 200\n\n    def test_DIGEST_AUTH_SETS_SESSION_COOKIES(self, httpbin):\n        for authtype in self.digest_auth_algo:\n            url = httpbin(\"digest-auth\", \"auth\", \"user\", \"pass\", authtype)\n            auth = HTTPDigest"}, {"start_line": 0, "end_line": 2000, "belongs_to": {"file_name": "auth.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "\"\"\"\nrequests.auth\n~~~~~~~~~~~~~\n\nThis module contains the authentication handlers for Requests.\n\"\"\"\n\nimport hashlib\nimport os\nimport re\nimport threading\nimport time\nimport warnings\nfrom base64 import b64encode\n\nfrom ._internal_utils import to_native_string\nfrom .compat import basestring, str, urlparse\nfrom .cookies import extract_cookies_to_jar\nfrom .utils import parse_dict_header\n\nCONTENT_TYPE_FORM_URLENCODED = \"application/x-www-form-urlencoded\"\nCONTENT_TYPE_MULTI_PART = \"multipart/form-data\"\n\n\ndef _basic_auth_str(username, password):\n    \"\"\"Returns a Basic Auth string.\"\"\"\n\n    # \"I want us to put a big-ol' comment on top of it that\n    # says that this behaviour is dumb but we need to preserve\n    # it because people are relying on it.\"\n    #    - Lukasa\n    #\n    # These are here solely to maintain backwards compatibility\n    # for things like ints. This will be removed in 3.0.0.\n    if not isinstance(username, basestring):\n        warnings.warn(\n            \"Non-string usernames will no longer be supported in Requests \"\n            \"3.0.0. Please convert the object you've passed in ({!r}) to \"\n            \"a string or bytes object in the near future to avoid \"\n            \"problems.\".format(username),\n            category=DeprecationWarning,\n        )\n        username = str(username)\n\n    if not isinstance(password, basestring):\n        warnings.warn(\n            \"Non-string passwords will no longer be supported in Requests \"\n            \"3.0.0. Please convert the object you've passed in ({!r}) to \"\n            \"a string or bytes object in the near future to avoid \"\n            \"problems.\".format(type(password)),\n            category=DeprecationWarning,\n        )\n        password = str(password)\n    # -- End Removal --\n\n    if isinstance(username, str):\n        username = username.encode(\"latin1\")\n\n    if isinstance(password, str):\n        password = password.encode(\"latin1\")\n\n    authstr = \"Basic \" + to_native_string(\n        b64encode(b\":\".join((username, pas"}, {"start_line": 67000, "end_line": 69000, "belongs_to": {"file_name": "test_requests.py", "upper_path": "/data2/raymone/swebench-repos/requests/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "    auth=(\"user\", \"pass\"),\n            verify=httpbin_ca_bundle,\n        )\n        assert r.history[0].request.headers[\"Authorization\"]\n        assert \"Authorization\" not in r.request.headers\n\n    def test_auth_is_retained_for_redirect_on_host(self, httpbin):\n        r = requests.get(httpbin(\"redirect/1\"), auth=(\"user\", \"pass\"))\n        h1 = r.history[0].request.headers[\"Authorization\"]\n        h2 = r.request.headers[\"Authorization\"]\n\n        assert h1 == h2\n\n    def test_should_strip_auth_host_change(self):\n        s = requests.Session()\n        assert s.should_strip_auth(\n            \"http://example.com/foo\", \"http://another.example.com/\"\n        )\n\n    def test_should_strip_auth_http_downgrade(self):\n        s = requests.Session()\n        assert s.should_strip_auth(\"https://example.com/foo\", \"http://example.com/bar\")\n\n    def test_should_strip_auth_https_upgrade(self):\n        s = requests.Session()\n        assert not s.should_strip_auth(\n            \"http://example.com/foo\", \"https://example.com/bar\"\n        )\n        assert not s.should_strip_auth(\n            \"http://example.com:80/foo\", \"https://example.com/bar\"\n        )\n        assert not s.should_strip_auth(\n            \"http://example.com/foo\", \"https://example.com:443/bar\"\n        )\n        # Non-standard ports should trigger stripping\n        assert s.should_strip_auth(\n            \"http://example.com:8080/foo\", \"https://example.com/bar\"\n        )\n        assert s.should_strip_auth(\n            \"http://example.com/foo\", \"https://example.com:8443/bar\"\n        )\n\n    def test_should_strip_auth_port_change(self):\n        s = requests.Session()\n        assert s.should_strip_auth(\n            \"http://example.com:1234/foo\", \"https://example.com:4321/bar\"\n        )\n\n    @pytest.mark.parametrize(\n        \"old_uri, new_uri\",\n        (\n            (\"https://example.com:443/foo\", \"https://example.com/bar\"),\n            (\"http://example.com:80/foo\", \"http://example.com/bar\"),\n            (\"https://example.com/foo\","}, {"start_line": 2000, "end_line": 4000, "belongs_to": {"file_name": "auth.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "sword))).strip()\n    )\n\n    return authstr\n\n\nclass AuthBase:\n    \"\"\"Base class that all auth implementations derive from\"\"\"\n\n    def __call__(self, r):\n        raise NotImplementedError(\"Auth hooks must be callable.\")\n\n\nclass HTTPBasicAuth(AuthBase):\n    \"\"\"Attaches HTTP Basic Authentication to the given Request object.\"\"\"\n\n    def __init__(self, username, password):\n        self.username = username\n        self.password = password\n\n    def __eq__(self, other):\n        return all(\n            [\n                self.username == getattr(other, \"username\", None),\n                self.password == getattr(other, \"password\", None),\n            ]\n        )\n\n    def __ne__(self, other):\n        return not self == other\n\n    def __call__(self, r):\n        r.headers[\"Authorization\"] = _basic_auth_str(self.username, self.password)\n        return r\n\n\nclass HTTPProxyAuth(HTTPBasicAuth):\n    \"\"\"Attaches HTTP Proxy Authentication to a given Request object.\"\"\"\n\n    def __call__(self, r):\n        r.headers[\"Proxy-Authorization\"] = _basic_auth_str(self.username, self.password)\n        return r\n\n\nclass HTTPDigestAuth(AuthBase):\n    \"\"\"Attaches HTTP Digest Authentication to the given Request object.\"\"\"\n\n    def __init__(self, username, password):\n        self.username = username\n        self.password = password\n        # Keep state in per-thread local storage\n        self._thread_local = threading.local()\n\n    def init_per_thread_state(self):\n        # Ensure state is initialized just once per-thread\n        if not hasattr(self._thread_local, \"init\"):\n            self._thread_local.init = True\n            self._thread_local.last_nonce = \"\"\n            self._thread_local.nonce_count = 0\n            self._thread_local.chal = {}\n            self._thread_local.pos = None\n            self._thread_local.num_401_calls = None\n\n    def build_digest_header(self, method, url):\n        \"\"\"\n        :rtype: str\n        \"\"\"\n\n        realm = self._thread_local.chal[\"realm\"]\n        nonce = self._threa"}, {"start_line": 24000, "end_line": 26000, "belongs_to": {"file_name": "test_requests.py", "upper_path": "/data2/raymone/swebench-repos/requests/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "\", {})\n\n        assert sent_headers.get(\"Proxy-Authorization\") == proxy_auth_value\n\n    @pytest.mark.parametrize(\n        \"url,has_proxy_auth\",\n        (\n            (\"http://example.com\", True),\n            (\"https://example.com\", False),\n        ),\n    )\n    def test_proxy_authorization_not_appended_to_https_request(\n        self, url, has_proxy_auth\n    ):\n        session = requests.Session()\n        proxies = {\n            \"http\": \"http://test:pass@localhost:8080\",\n            \"https\": \"http://test:pass@localhost:8090\",\n        }\n        req = requests.Request(\"GET\", url)\n        prep = req.prepare()\n        session.rebuild_proxies(prep, proxies)\n\n        assert (\"Proxy-Authorization\" in prep.headers) is has_proxy_auth\n\n    def test_basicauth_with_netrc(self, httpbin):\n        auth = (\"user\", \"pass\")\n        wrong_auth = (\"wronguser\", \"wrongpass\")\n        url = httpbin(\"basic-auth\", \"user\", \"pass\")\n\n        old_auth = requests.sessions.get_netrc_auth\n\n        try:\n\n            def get_netrc_auth_mock(url):\n                return auth\n\n            requests.sessions.get_netrc_auth = get_netrc_auth_mock\n\n            # Should use netrc and work.\n            r = requests.get(url)\n            assert r.status_code == 200\n\n            # Given auth should override and fail.\n            r = requests.get(url, auth=wrong_auth)\n            assert r.status_code == 401\n\n            s = requests.session()\n\n            # Should use netrc and work.\n            r = s.get(url)\n            assert r.status_code == 200\n\n            # Given auth should override and fail.\n            s.auth = wrong_auth\n            r = s.get(url)\n            assert r.status_code == 401\n        finally:\n            requests.sessions.get_netrc_auth = old_auth\n\n    def test_basicauth_with_netrc_leak(self, httpbin):\n        url1 = httpbin(\"basic-auth\", \"user\", \"pass\")\n        url = url1[len(\"http://\") :]\n        domain = url.split(\":\")[0]\n        url = f\"http://example.com:@{url}\"\n\n        netrc_file = \"\"\n "}, {"start_line": 66000, "end_line": 68000, "belongs_to": {"file_name": "test_requests.py", "upper_path": "/data2/raymone/swebench-repos/requests/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "rt \"multipart/form-data\" in p.headers[\"Content-Type\"]\n\n    def test_autoset_header_values_are_native(self, httpbin):\n        data = \"this is a string\"\n        length = \"16\"\n        req = requests.Request(\"POST\", httpbin(\"post\"), data=data)\n        p = req.prepare()\n\n        assert p.headers[\"Content-Length\"] == length\n\n    def test_nonhttp_schemes_dont_check_URLs(self):\n        test_urls = (\n            \"data:image/gif;base64,R0lGODlhAQABAHAAACH5BAUAAAAALAAAAAABAAEAAAICRAEAOw==\",\n            \"file:///etc/passwd\",\n            \"magnet:?xt=urn:btih:be08f00302bc2d1d3cfa3af02024fa647a271431\",\n        )\n        for test_url in test_urls:\n            req = requests.Request(\"GET\", test_url)\n            preq = req.prepare()\n            assert test_url == preq.url\n\n    def test_auth_is_stripped_on_http_downgrade(\n        self, httpbin, httpbin_secure, httpbin_ca_bundle\n    ):\n        r = requests.get(\n            httpbin_secure(\"redirect-to\"),\n            params={\"url\": httpbin(\"get\")},\n            auth=(\"user\", \"pass\"),\n            verify=httpbin_ca_bundle,\n        )\n        assert r.history[0].request.headers[\"Authorization\"]\n        assert \"Authorization\" not in r.request.headers\n\n    def test_auth_is_retained_for_redirect_on_host(self, httpbin):\n        r = requests.get(httpbin(\"redirect/1\"), auth=(\"user\", \"pass\"))\n        h1 = r.history[0].request.headers[\"Authorization\"]\n        h2 = r.request.headers[\"Authorization\"]\n\n        assert h1 == h2\n\n    def test_should_strip_auth_host_change(self):\n        s = requests.Session()\n        assert s.should_strip_auth(\n            \"http://example.com/foo\", \"http://another.example.com/\"\n        )\n\n    def test_should_strip_auth_http_downgrade(self):\n        s = requests.Session()\n        assert s.should_strip_auth(\"https://example.com/foo\", \"http://example.com/bar\")\n\n    def test_should_strip_auth_https_upgrade(self):\n        s = requests.Session()\n        assert not s.should_strip_auth(\n            \"http://example.com/foo\", \"https"}], "retrieved_count": 10, "cost_time": 0.9841969013214111}
{"question": "How does Requests implement its retry mechanism?", "answer": null, "relative_code_list": null, "ground_truth": "Requests implements retry mechanism through HTTPAdapter in src/requests/adapters.py: 1) Retry configuration - HTTPAdapter.__init__() configures max_retries parameter which creates a urllib3.Retry object; 2) urllib3 integration - HTTPAdapter.send() uses urllib3's urlopen() with the configured retry policy; 3) Retry conditions - urllib3.Retry handles retries for connection errors, timeouts, and specific HTTP status codes; 4) Backoff strategies - Retry policies can include exponential backoff and jitter for retry delays; 5) Status code filtering - status_forcelist parameter allows retrying specific HTTP status codes (e.g., 502, 503, 504); 6) Method filtering - allowed_methods parameter controls which HTTP methods can be retried; 7) Exception handling - HTTPAdapter.send() catches MaxRetryError and other transport exceptions; 8) Custom retry policies - Users can pass urllib3.Retry objects for advanced retry configuration; 9) Retry limits - total parameter controls maximum number of retry attempts; 10) Retry logging - Retry attempts can be logged and monitored for debugging purposes.", "score": null, "retrieved_content": [{"start_line": 5000, "end_line": 7000, "belongs_to": {"file_name": "adapters.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": " requests where data has\n        made it to the server. By default, Requests does not retry failed\n        connections. If you need granular control over the conditions under\n        which we retry a request, import urllib3's ``Retry`` class and pass\n        that instead.\n    :param pool_block: Whether the connection pool should block for connections.\n\n    Usage::\n\n      >>> import requests\n      >>> s = requests.Session()\n      >>> a = requests.adapters.HTTPAdapter(max_retries=3)\n      >>> s.mount('http://', a)\n    \"\"\"\n\n    __attrs__ = [\n        \"max_retries\",\n        \"config\",\n        \"_pool_connections\",\n        \"_pool_maxsize\",\n        \"_pool_block\",\n    ]\n\n    def __init__(\n        self,\n        pool_connections=DEFAULT_POOLSIZE,\n        pool_maxsize=DEFAULT_POOLSIZE,\n        max_retries=DEFAULT_RETRIES,\n        pool_block=DEFAULT_POOLBLOCK,\n    ):\n        if max_retries == DEFAULT_RETRIES:\n            self.max_retries = Retry(0, read=False)\n        else:\n            self.max_retries = Retry.from_int(max_retries)\n        self.config = {}\n        self.proxy_manager = {}\n\n        super().__init__()\n\n        self._pool_connections = pool_connections\n        self._pool_maxsize = pool_maxsize\n        self._pool_block = pool_block\n\n        self.init_poolmanager(pool_connections, pool_maxsize, block=pool_block)\n\n    def __getstate__(self):\n        return {attr: getattr(self, attr, None) for attr in self.__attrs__}\n\n    def __setstate__(self, state):\n        # Can't handle by adding 'proxy_manager' to self.__attrs__ because\n        # self.poolmanager uses a lambda function, which isn't pickleable.\n        self.proxy_manager = {}\n        self.config = {}\n\n        for attr, value in state.items():\n            setattr(self, attr, value)\n\n        self.init_poolmanager(\n            self._pool_connections, self._pool_maxsize, block=self._pool_block\n        )\n\n    def init_poolmanager(\n        self, connections, maxsize, block=DEFAULT_POOLBLOCK, **pool_kwargs\n    ):\n        \""}, {"start_line": 94000, "end_line": 96000, "belongs_to": {"file_name": "test_requests.py", "upper_path": "/data2/raymone/swebench-repos/requests/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "\"_cookies\", \"body\", \"hooks\"):\n        assert getattr(p, attr) == getattr(copy, attr)\n\n\ndef test_urllib3_retries(httpbin):\n    from urllib3.util import Retry\n\n    s = requests.Session()\n    s.mount(\"http://\", HTTPAdapter(max_retries=Retry(total=2, status_forcelist=[500])))\n\n    with pytest.raises(RetryError):\n        s.get(httpbin(\"status/500\"))\n\n\ndef test_urllib3_pool_connection_closed(httpbin):\n    s = requests.Session()\n    s.mount(\"http://\", HTTPAdapter(pool_connections=0, pool_maxsize=0))\n\n    try:\n        s.get(httpbin(\"status/200\"))\n    except ConnectionError as e:\n        assert \"Pool is closed.\" in str(e)\n\n\nclass TestPreparingURLs:\n    @pytest.mark.parametrize(\n        \"url,expected\",\n        (\n            (\"http://google.com\", \"http://google.com/\"),\n            (\"http://.jp\", \"http://xn--hckqz9bzb1cyrb.jp/\"),\n            (\"http://xn--n3h.net/\", \"http://xn--n3h.net/\"),\n            (\"http://.jp\".encode(), \"http://xn--hckqz9bzb1cyrb.jp/\"),\n            (\"http://strae.de/strae\", \"http://xn--strae-oqa.de/stra%C3%9Fe\"),\n            (\n                \"http://strae.de/strae\".encode(),\n                \"http://xn--strae-oqa.de/stra%C3%9Fe\",\n            ),\n            (\n                \"http://Knigsgchen.de/strae\",\n                \"http://xn--knigsgchen-b4a3dun.de/stra%C3%9Fe\",\n            ),\n            (\n                \"http://Knigsgchen.de/strae\".encode(),\n                \"http://xn--knigsgchen-b4a3dun.de/stra%C3%9Fe\",\n            ),\n            (b\"http://xn--n3h.net/\", \"http://xn--n3h.net/\"),\n            (\n                b\"http://[1200:0000:ab00:1234:0000:2552:7777:1313]:12345/\",\n                \"http://[1200:0000:ab00:1234:0000:2552:7777:1313]:12345/\",\n            ),\n            (\n                \"http://[1200:0000:ab00:1234:0000:2552:7777:1313]:12345/\",\n                \"http://[1200:0000:ab00:1234:0000:2552:7777:1313]:12345/\",\n            ),\n        ),\n    )\n    def test_preparing_url(self, url, expected):\n        def normalize_perce"}, {"start_line": 8000, "end_line": 10000, "belongs_to": {"file_name": "sessions.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "     # https://github.com/psf/requests/issues/3490\n                purged_headers = (\"Content-Length\", \"Content-Type\", \"Transfer-Encoding\")\n                for header in purged_headers:\n                    prepared_request.headers.pop(header, None)\n                prepared_request.body = None\n\n            headers = prepared_request.headers\n            headers.pop(\"Cookie\", None)\n\n            # Extract any cookies sent on the response to the cookiejar\n            # in the new request. Because we've mutated our copied prepared\n            # request, use the old one that we haven't yet touched.\n            extract_cookies_to_jar(prepared_request._cookies, req, resp.raw)\n            merge_cookies(prepared_request._cookies, self.cookies)\n            prepared_request.prepare_cookies(prepared_request._cookies)\n\n            # Rebuild auth and proxy information.\n            proxies = self.rebuild_proxies(prepared_request, proxies)\n            self.rebuild_auth(prepared_request, resp)\n\n            # A failed tell() sets `_body_position` to `object()`. This non-None\n            # value ensures `rewindable` will be True, allowing us to raise an\n            # UnrewindableBodyError, instead of hanging the connection.\n            rewindable = prepared_request._body_position is not None and (\n                \"Content-Length\" in headers or \"Transfer-Encoding\" in headers\n            )\n\n            # Attempt to rewind consumed file-like object.\n            if rewindable:\n                rewind_body(prepared_request)\n\n            # Override the original request.\n            req = prepared_request\n\n            if yield_requests:\n                yield req\n            else:\n                resp = self.send(\n                    req,\n                    stream=stream,\n                    timeout=timeout,\n                    verify=verify,\n                    cert=cert,\n                    proxies=proxies,\n                    allow_redirects=False,\n                    **adapter_kwargs,\n     "}, {"start_line": 2000, "end_line": 4000, "belongs_to": {"file_name": "exceptions.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "ror occurred.\"\"\"\n\n\nclass ProxyError(ConnectionError):\n    \"\"\"A proxy error occurred.\"\"\"\n\n\nclass SSLError(ConnectionError):\n    \"\"\"An SSL error occurred.\"\"\"\n\n\nclass Timeout(RequestException):\n    \"\"\"The request timed out.\n\n    Catching this error will catch both\n    :exc:`~requests.exceptions.ConnectTimeout` and\n    :exc:`~requests.exceptions.ReadTimeout` errors.\n    \"\"\"\n\n\nclass ConnectTimeout(ConnectionError, Timeout):\n    \"\"\"The request timed out while trying to connect to the remote server.\n\n    Requests that produced this error are safe to retry.\n    \"\"\"\n\n\nclass ReadTimeout(Timeout):\n    \"\"\"The server did not send any data in the allotted amount of time.\"\"\"\n\n\nclass URLRequired(RequestException):\n    \"\"\"A valid URL is required to make a request.\"\"\"\n\n\nclass TooManyRedirects(RequestException):\n    \"\"\"Too many redirects.\"\"\"\n\n\nclass MissingSchema(RequestException, ValueError):\n    \"\"\"The URL scheme (e.g. http or https) is missing.\"\"\"\n\n\nclass InvalidSchema(RequestException, ValueError):\n    \"\"\"The URL scheme provided is either invalid or unsupported.\"\"\"\n\n\nclass InvalidURL(RequestException, ValueError):\n    \"\"\"The URL provided was somehow invalid.\"\"\"\n\n\nclass InvalidHeader(RequestException, ValueError):\n    \"\"\"The header value provided was somehow invalid.\"\"\"\n\n\nclass InvalidProxyURL(InvalidURL):\n    \"\"\"The proxy URL provided is invalid.\"\"\"\n\n\nclass ChunkedEncodingError(RequestException):\n    \"\"\"The server declared chunked encoding but sent an invalid chunk.\"\"\"\n\n\nclass ContentDecodingError(RequestException, BaseHTTPError):\n    \"\"\"Failed to decode response content.\"\"\"\n\n\nclass StreamConsumedError(RequestException, TypeError):\n    \"\"\"The content for this response was already consumed.\"\"\"\n\n\nclass RetryError(RequestException):\n    \"\"\"Custom retries logic failed\"\"\"\n\n\nclass UnrewindableBodyError(RequestException):\n    \"\"\"Requests encountered an error when trying to rewind a body.\"\"\"\n\n\n# Warnings\n\n\nclass RequestsWarning(Warning):\n    \"\"\"Base warning for Requests.\"\"\"\n\n\nclass FileMo"}, {"start_line": 13000, "end_line": 15000, "belongs_to": {"file_name": "sessions.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "POST is responded to with a 301, turn it into a GET.\n        # This bizarre behaviour is explained in Issue 1704.\n        if response.status_code == codes.moved and method == \"POST\":\n            method = \"GET\"\n\n        prepared_request.method = method\n\n\nclass Session(SessionRedirectMixin):\n    \"\"\"A Requests session.\n\n    Provides cookie persistence, connection-pooling, and configuration.\n\n    Basic Usage::\n\n      >>> import requests\n      >>> s = requests.Session()\n      >>> s.get('https://httpbin.org/get')\n      <Response [200]>\n\n    Or as a context manager::\n\n      >>> with requests.Session() as s:\n      ...     s.get('https://httpbin.org/get')\n      <Response [200]>\n    \"\"\"\n\n    __attrs__ = [\n        \"headers\",\n        \"cookies\",\n        \"auth\",\n        \"proxies\",\n        \"hooks\",\n        \"params\",\n        \"verify\",\n        \"cert\",\n        \"adapters\",\n        \"stream\",\n        \"trust_env\",\n        \"max_redirects\",\n    ]\n\n    def __init__(self):\n        #: A case-insensitive dictionary of headers to be sent on each\n        #: :class:`Request <Request>` sent from this\n        #: :class:`Session <Session>`.\n        self.headers = default_headers()\n\n        #: Default Authentication tuple or object to attach to\n        #: :class:`Request <Request>`.\n        self.auth = None\n\n        #: Dictionary mapping protocol or protocol and host to the URL of the proxy\n        #: (e.g. {'http': 'foo.bar:3128', 'http://host.name': 'foo.bar:4012'}) to\n        #: be used on each :class:`Request <Request>`.\n        self.proxies = {}\n\n        #: Event-handling hooks.\n        self.hooks = default_hooks()\n\n        #: Dictionary of querystring data to attach to each\n        #: :class:`Request <Request>`. The dictionary values may be lists for\n        #: representing multivalued query parameters.\n        self.params = {}\n\n        #: Stream response content default.\n        self.stream = False\n\n        #: SSL Verification default.\n        #: Defaults to `True`, requiring requests to verif"}, {"start_line": 0, "end_line": 2000, "belongs_to": {"file_name": "adapters.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "\"\"\"\nrequests.adapters\n~~~~~~~~~~~~~~~~~\n\nThis module contains the transport adapters that Requests uses to define\nand maintain connections.\n\"\"\"\n\nimport os.path\nimport socket  # noqa: F401\nimport typing\nimport warnings\n\nfrom urllib3.exceptions import ClosedPoolError, ConnectTimeoutError\nfrom urllib3.exceptions import HTTPError as _HTTPError\nfrom urllib3.exceptions import InvalidHeader as _InvalidHeader\nfrom urllib3.exceptions import (\n    LocationValueError,\n    MaxRetryError,\n    NewConnectionError,\n    ProtocolError,\n)\nfrom urllib3.exceptions import ProxyError as _ProxyError\nfrom urllib3.exceptions import ReadTimeoutError, ResponseError\nfrom urllib3.exceptions import SSLError as _SSLError\nfrom urllib3.poolmanager import PoolManager, proxy_from_url\nfrom urllib3.util import Timeout as TimeoutSauce\nfrom urllib3.util import parse_url\nfrom urllib3.util.retry import Retry\n\nfrom .auth import _basic_auth_str\nfrom .compat import basestring, urlparse\nfrom .cookies import extract_cookies_to_jar\nfrom .exceptions import (\n    ConnectionError,\n    ConnectTimeout,\n    InvalidHeader,\n    InvalidProxyURL,\n    InvalidSchema,\n    InvalidURL,\n    ProxyError,\n    ReadTimeout,\n    RetryError,\n    SSLError,\n)\nfrom .models import Response\nfrom .structures import CaseInsensitiveDict\nfrom .utils import (\n    DEFAULT_CA_BUNDLE_PATH,\n    extract_zipped_paths,\n    get_auth_from_url,\n    get_encoding_from_headers,\n    prepend_scheme_if_needed,\n    select_proxy,\n    urldefragauth,\n)\n\ntry:\n    from urllib3.contrib.socks import SOCKSProxyManager\nexcept ImportError:\n\n    def SOCKSProxyManager(*args, **kwargs):\n        raise InvalidSchema(\"Missing dependencies for SOCKS support.\")\n\n\nif typing.TYPE_CHECKING:\n    from .models import PreparedRequest\n\n\nDEFAULT_POOLBLOCK = False\nDEFAULT_POOLSIZE = 10\nDEFAULT_RETRIES = 0\nDEFAULT_POOL_TIMEOUT = None\n\n\ndef _urllib3_request_context(\n    request: \"PreparedRequest\",\n    verify: \"bool | str | None\",\n    client_cert: \"typing.Tuple[str, str] | str | None\",\n    po"}, {"start_line": 4000, "end_line": 6000, "belongs_to": {"file_name": "adapters.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "        :param cert: (optional) Any user-provided SSL certificate to be trusted.\n        :param proxies: (optional) The proxies dictionary to apply to the request.\n        \"\"\"\n        raise NotImplementedError\n\n    def close(self):\n        \"\"\"Cleans up adapter specific items.\"\"\"\n        raise NotImplementedError\n\n\nclass HTTPAdapter(BaseAdapter):\n    \"\"\"The built-in HTTP Adapter for urllib3.\n\n    Provides a general-case interface for Requests sessions to contact HTTP and\n    HTTPS urls by implementing the Transport Adapter interface. This class will\n    usually be created by the :class:`Session <Session>` class under the\n    covers.\n\n    :param pool_connections: The number of urllib3 connection pools to cache.\n    :param pool_maxsize: The maximum number of connections to save in the pool.\n    :param max_retries: The maximum number of retries each connection\n        should attempt. Note, this applies only to failed DNS lookups, socket\n        connections and connection timeouts, never to requests where data has\n        made it to the server. By default, Requests does not retry failed\n        connections. If you need granular control over the conditions under\n        which we retry a request, import urllib3's ``Retry`` class and pass\n        that instead.\n    :param pool_block: Whether the connection pool should block for connections.\n\n    Usage::\n\n      >>> import requests\n      >>> s = requests.Session()\n      >>> a = requests.adapters.HTTPAdapter(max_retries=3)\n      >>> s.mount('http://', a)\n    \"\"\"\n\n    __attrs__ = [\n        \"max_retries\",\n        \"config\",\n        \"_pool_connections\",\n        \"_pool_maxsize\",\n        \"_pool_block\",\n    ]\n\n    def __init__(\n        self,\n        pool_connections=DEFAULT_POOLSIZE,\n        pool_maxsize=DEFAULT_POOLSIZE,\n        max_retries=DEFAULT_RETRIES,\n        pool_block=DEFAULT_POOLBLOCK,\n    ):\n        if max_retries == DEFAULT_RETRIES:\n            self.max_retries = Retry(0, read=False)\n        else:\n            self.max_retr"}, {"start_line": 3000, "end_line": 4260, "belongs_to": {"file_name": "exceptions.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "   \"\"\"The URL scheme provided is either invalid or unsupported.\"\"\"\n\n\nclass InvalidURL(RequestException, ValueError):\n    \"\"\"The URL provided was somehow invalid.\"\"\"\n\n\nclass InvalidHeader(RequestException, ValueError):\n    \"\"\"The header value provided was somehow invalid.\"\"\"\n\n\nclass InvalidProxyURL(InvalidURL):\n    \"\"\"The proxy URL provided is invalid.\"\"\"\n\n\nclass ChunkedEncodingError(RequestException):\n    \"\"\"The server declared chunked encoding but sent an invalid chunk.\"\"\"\n\n\nclass ContentDecodingError(RequestException, BaseHTTPError):\n    \"\"\"Failed to decode response content.\"\"\"\n\n\nclass StreamConsumedError(RequestException, TypeError):\n    \"\"\"The content for this response was already consumed.\"\"\"\n\n\nclass RetryError(RequestException):\n    \"\"\"Custom retries logic failed\"\"\"\n\n\nclass UnrewindableBodyError(RequestException):\n    \"\"\"Requests encountered an error when trying to rewind a body.\"\"\"\n\n\n# Warnings\n\n\nclass RequestsWarning(Warning):\n    \"\"\"Base warning for Requests.\"\"\"\n\n\nclass FileModeWarning(RequestsWarning, DeprecationWarning):\n    \"\"\"A file was opened in text mode, but Requests determined its binary length.\"\"\"\n\n\nclass RequestsDependencyWarning(RequestsWarning):\n    \"\"\"An imported dependency doesn't match the expected version range.\"\"\"\n"}, {"start_line": 1000, "end_line": 3000, "belongs_to": {"file_name": "models.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "\nfrom .cookies import _copy_cookie_jar, cookiejar_from_dict, get_cookie_header\nfrom .exceptions import (\n    ChunkedEncodingError,\n    ConnectionError,\n    ContentDecodingError,\n    HTTPError,\n    InvalidJSONError,\n    InvalidURL,\n)\nfrom .exceptions import JSONDecodeError as RequestsJSONDecodeError\nfrom .exceptions import MissingSchema\nfrom .exceptions import SSLError as RequestsSSLError\nfrom .exceptions import StreamConsumedError\nfrom .hooks import default_hooks\nfrom .status_codes import codes\nfrom .structures import CaseInsensitiveDict\nfrom .utils import (\n    check_header_validity,\n    get_auth_from_url,\n    guess_filename,\n    guess_json_utf,\n    iter_slices,\n    parse_header_links,\n    requote_uri,\n    stream_decode_response_unicode,\n    super_len,\n    to_key_val_list,\n)\n\n#: The set of HTTP status codes that indicate an automatically\n#: processable redirect.\nREDIRECT_STATI = (\n    codes.moved,  # 301\n    codes.found,  # 302\n    codes.other,  # 303\n    codes.temporary_redirect,  # 307\n    codes.permanent_redirect,  # 308\n)\n\nDEFAULT_REDIRECT_LIMIT = 30\nCONTENT_CHUNK_SIZE = 10 * 1024\nITER_CHUNK_SIZE = 512\n\n\nclass RequestEncodingMixin:\n    @property\n    def path_url(self):\n        \"\"\"Build the path URL to use.\"\"\"\n\n        url = []\n\n        p = urlsplit(self.url)\n\n        path = p.path\n        if not path:\n            path = \"/\"\n\n        url.append(path)\n\n        query = p.query\n        if query:\n            url.append(\"?\")\n            url.append(query)\n\n        return \"\".join(url)\n\n    @staticmethod\n    def _encode_params(data):\n        \"\"\"Encode parameters in a piece of data.\n\n        Will successfully encode parameters when passed as a dict or a list of\n        2-tuples. Order is retained if data is a list of 2-tuples but arbitrary\n        if parameters are supplied as a dict.\n        \"\"\"\n\n        if isinstance(data, (str, bytes)):\n            return data\n        elif hasattr(data, \"read\"):\n            return data\n        elif hasattr(data, \"__iter__\"):\n         "}, {"start_line": 12000, "end_line": 14000, "belongs_to": {"file_name": "sessions.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "          username, password = None, None\n\n        # urllib3 handles proxy authorization for us in the standard adapter.\n        # Avoid appending this to TLS tunneled requests where it may be leaked.\n        if not scheme.startswith(\"https\") and username and password:\n            headers[\"Proxy-Authorization\"] = _basic_auth_str(username, password)\n\n        return new_proxies\n\n    def rebuild_method(self, prepared_request, response):\n        \"\"\"When being redirected we may want to change the method of the request\n        based on certain specs or browser behavior.\n        \"\"\"\n        method = prepared_request.method\n\n        # https://tools.ietf.org/html/rfc7231#section-6.4.4\n        if response.status_code == codes.see_other and method != \"HEAD\":\n            method = \"GET\"\n\n        # Do what the browsers do, despite standards...\n        # First, turn 302s into GETs.\n        if response.status_code == codes.found and method != \"HEAD\":\n            method = \"GET\"\n\n        # Second, if a POST is responded to with a 301, turn it into a GET.\n        # This bizarre behaviour is explained in Issue 1704.\n        if response.status_code == codes.moved and method == \"POST\":\n            method = \"GET\"\n\n        prepared_request.method = method\n\n\nclass Session(SessionRedirectMixin):\n    \"\"\"A Requests session.\n\n    Provides cookie persistence, connection-pooling, and configuration.\n\n    Basic Usage::\n\n      >>> import requests\n      >>> s = requests.Session()\n      >>> s.get('https://httpbin.org/get')\n      <Response [200]>\n\n    Or as a context manager::\n\n      >>> with requests.Session() as s:\n      ...     s.get('https://httpbin.org/get')\n      <Response [200]>\n    \"\"\"\n\n    __attrs__ = [\n        \"headers\",\n        \"cookies\",\n        \"auth\",\n        \"proxies\",\n        \"hooks\",\n        \"params\",\n        \"verify\",\n        \"cert\",\n        \"adapters\",\n        \"stream\",\n        \"trust_env\",\n        \"max_redirects\",\n    ]\n\n    def __init__(self):\n        #: A case-insensitive dictiona"}], "retrieved_count": 10, "cost_time": 0.943007230758667}
{"question": "How does Requests facilitate integration with popular web frameworks like Flask or Django?", "answer": null, "relative_code_list": null, "ground_truth": "Requests facilitates integration with web frameworks through several design features: 1) Session compatibility - Sessions can be used within web application contexts for making HTTP requests; 2) Thread safety - Connection pools and Sessions are thread-safe, suitable for web application environments; 3) Configuration integration - Sessions can integrate with web framework configuration systems for proxies, timeouts, and certificates; 4) Error handling - Requests exceptions integrate well with web framework error handling and logging systems; 5) Async compatibility - While Requests is synchronous, it can be used with async frameworks through thread pools or async wrappers; 6) Middleware integration - Requests can be integrated into web framework middleware for HTTP client functionality; 7) Testing support - Requests' adapter system enables easy mocking for web application testing; 8) Logging integration - Requests can integrate with web framework logging systems for request/response logging; 9) Environment variables - Requests respects environment variables that web frameworks commonly set for proxies and certificates; 10) Resource management - Sessions implement context manager protocol compatible with web framework lifecycle management.", "score": null, "retrieved_content": [{"start_line": 0, "end_line": 2000, "belongs_to": {"file_name": "api.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "\"\"\"\nrequests.api\n~~~~~~~~~~~~\n\nThis module implements the Requests API.\n\n:copyright: (c) 2012 by Kenneth Reitz.\n:license: Apache2, see LICENSE for more details.\n\"\"\"\n\nfrom . import sessions\n\n\ndef request(method, url, **kwargs):\n    \"\"\"Constructs and sends a :class:`Request <Request>`.\n\n    :param method: method for the new :class:`Request` object: ``GET``, ``OPTIONS``, ``HEAD``, ``POST``, ``PUT``, ``PATCH``, or ``DELETE``.\n    :param url: URL for the new :class:`Request` object.\n    :param params: (optional) Dictionary, list of tuples or bytes to send\n        in the query string for the :class:`Request`.\n    :param data: (optional) Dictionary, list of tuples, bytes, or file-like\n        object to send in the body of the :class:`Request`.\n    :param json: (optional) A JSON serializable Python object to send in the body of the :class:`Request`.\n    :param headers: (optional) Dictionary of HTTP Headers to send with the :class:`Request`.\n    :param cookies: (optional) Dict or CookieJar object to send with the :class:`Request`.\n    :param files: (optional) Dictionary of ``'name': file-like-objects`` (or ``{'name': file-tuple}``) for multipart encoding upload.\n        ``file-tuple`` can be a 2-tuple ``('filename', fileobj)``, 3-tuple ``('filename', fileobj, 'content_type')``\n        or a 4-tuple ``('filename', fileobj, 'content_type', custom_headers)``, where ``'content_type'`` is a string\n        defining the content type of the given file and ``custom_headers`` a dict-like object containing additional headers\n        to add for the file.\n    :param auth: (optional) Auth tuple to enable Basic/Digest/Custom HTTP Auth.\n    :param timeout: (optional) How many seconds to wait for the server to send data\n        before giving up, as a float, or a :ref:`(connect timeout, read\n        timeout) <timeouts>` tuple.\n    :type timeout: float or tuple\n    :param allow_redirects: (optional) Boolean. Enable/disable GET/OPTIONS/POST/PUT/PATCH/DELETE/HEAD redirection. Defaults to ``True``"}, {"start_line": 0, "end_line": 2000, "belongs_to": {"file_name": "conf.py", "upper_path": "/data2/raymone/swebench-repos/requests/docs", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "# -*- coding: utf-8 -*-\n#\n# Requests documentation build configuration file, created by\n# sphinx-quickstart on Fri Feb 19 00:05:47 2016.\n#\n# This file is execfile()d with the current directory set to its\n# containing dir.\n#\n# Note that not all possible configuration values are present in this\n# autogenerated file.\n#\n# All configuration values have a default; values that are commented out\n# serve to show the default.\n\nimport sys\nimport os\n\n# If extensions (or modules to document with autodoc) are in another directory,\n# add these directories to sys.path here. If the directory is relative to the\n# documentation root, use os.path.abspath to make it absolute, like shown here.\n# sys.path.insert(0, os.path.abspath('.'))\n\n# Insert Requests' path into the system.\nsys.path.insert(0, os.path.abspath(\"..\"))\nsys.path.insert(0, os.path.abspath(\"_themes\"))\n\nimport requests\n\n\n# -- General configuration ------------------------------------------------\n\n# If your documentation needs a minimal Sphinx version, state it here.\n# needs_sphinx = '1.0'\n\n# Add any Sphinx extension module names here, as strings. They can be\n# extensions coming with Sphinx (named 'sphinx.ext.*') or your custom\n# ones.\nextensions = [\n    \"sphinx.ext.autodoc\",\n    \"sphinx.ext.intersphinx\",\n    \"sphinx.ext.todo\",\n    \"sphinx.ext.viewcode\",\n]\n\n# Add any paths that contain templates here, relative to this directory.\ntemplates_path = [\"_templates\"]\n\n# The suffix(es) of source filenames.\n# You can specify multiple suffix as a list of string:\n# source_suffix = ['.rst', '.md']\nsource_suffix = \".rst\"\n\n# The encoding of source files.\n# source_encoding = 'utf-8-sig'\n\n# The master toctree document.\nmaster_doc = \"index\"\n\n# General information about the project.\nproject = u\"Requests\"\ncopyright = u'MMXVIX. A Kenneth Reitz Project'\nauthor = u\"Kenneth Reitz\"\n\n# The version info for the project you're documenting, acts as replacement for\n# |version| and |release|, also used in various other places throughout the\n# built documen"}, {"start_line": 43000, "end_line": 45000, "belongs_to": {"file_name": "test_requests.py", "upper_path": "/data2/raymone/swebench-repos/requests/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "ook})\n        prep = req.prepare()\n\n        s = requests.Session()\n        s.proxies = getproxies()\n        resp = s.send(prep)\n\n        assert hasattr(resp, \"hook_working\")\n\n    def test_prepared_from_session(self, httpbin):\n        class DummyAuth(requests.auth.AuthBase):\n            def __call__(self, r):\n                r.headers[\"Dummy-Auth-Test\"] = \"dummy-auth-test-ok\"\n                return r\n\n        req = requests.Request(\"GET\", httpbin(\"headers\"))\n        assert not req.auth\n\n        s = requests.Session()\n        s.auth = DummyAuth()\n\n        prep = s.prepare_request(req)\n        resp = s.send(prep)\n\n        assert resp.json()[\"headers\"][\"Dummy-Auth-Test\"] == \"dummy-auth-test-ok\"\n\n    def test_prepare_request_with_bytestring_url(self):\n        req = requests.Request(\"GET\", b\"https://httpbin.org/\")\n        s = requests.Session()\n        prep = s.prepare_request(req)\n        assert prep.url == \"https://httpbin.org/\"\n\n    def test_request_with_bytestring_host(self, httpbin):\n        s = requests.Session()\n        resp = s.request(\n            \"GET\",\n            httpbin(\"cookies/set?cookie=value\"),\n            allow_redirects=False,\n            headers={\"Host\": b\"httpbin.org\"},\n        )\n        assert resp.cookies.get(\"cookie\") == \"value\"\n\n    def test_links(self):\n        r = requests.Response()\n        r.headers = {\n            \"cache-control\": \"public, max-age=60, s-maxage=60\",\n            \"connection\": \"keep-alive\",\n            \"content-encoding\": \"gzip\",\n            \"content-type\": \"application/json; charset=utf-8\",\n            \"date\": \"Sat, 26 Jan 2013 16:47:56 GMT\",\n            \"etag\": '\"6ff6a73c0e446c1f61614769e3ceb778\"',\n            \"last-modified\": \"Sat, 26 Jan 2013 16:22:39 GMT\",\n            \"link\": (\n                \"<https://api.github.com/users/kennethreitz/repos?\"\n                'page=2&per_page=10>; rel=\"next\", <https://api.github.'\n                \"com/users/kennethreitz/repos?page=7&per_page=10>; \"\n                ' rel=\"last\"'\n           "}, {"start_line": 2000, "end_line": 4000, "belongs_to": {"file_name": "test_requests.py", "upper_path": "/data2/raymone/swebench-repos/requests/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": " requests.session\n        requests.session().get\n        requests.session().head\n        requests.get\n        requests.head\n        requests.put\n        requests.patch\n        requests.post\n        # Not really an entry point, but people rely on it.\n        from requests.packages.urllib3.poolmanager import PoolManager  # noqa:F401\n\n    @pytest.mark.parametrize(\n        \"exception, url\",\n        (\n            (MissingSchema, \"hiwpefhipowhefopw\"),\n            (InvalidSchema, \"localhost:3128\"),\n            (InvalidSchema, \"localhost.localdomain:3128/\"),\n            (InvalidSchema, \"10.122.1.1:3128/\"),\n            (InvalidURL, \"http://\"),\n            (InvalidURL, \"http://*example.com\"),\n            (InvalidURL, \"http://.example.com\"),\n        ),\n    )\n    def test_invalid_url(self, exception, url):\n        with pytest.raises(exception):\n            requests.get(url)\n\n    def test_basic_building(self):\n        req = requests.Request()\n        req.url = \"http://kennethreitz.org/\"\n        req.data = {\"life\": \"42\"}\n\n        pr = req.prepare()\n        assert pr.url == req.url\n        assert pr.body == \"life=42\"\n\n    @pytest.mark.parametrize(\"method\", (\"GET\", \"HEAD\"))\n    def test_no_content_length(self, httpbin, method):\n        req = requests.Request(method, httpbin(method.lower())).prepare()\n        assert \"Content-Length\" not in req.headers\n\n    @pytest.mark.parametrize(\"method\", (\"POST\", \"PUT\", \"PATCH\", \"OPTIONS\"))\n    def test_no_body_content_length(self, httpbin, method):\n        req = requests.Request(method, httpbin(method.lower())).prepare()\n        assert req.headers[\"Content-Length\"] == \"0\"\n\n    @pytest.mark.parametrize(\"method\", (\"POST\", \"PUT\", \"PATCH\", \"OPTIONS\"))\n    def test_empty_content_length(self, httpbin, method):\n        req = requests.Request(method, httpbin(method.lower()), data=\"\").prepare()\n        assert req.headers[\"Content-Length\"] == \"0\"\n\n    def test_override_content_length(self, httpbin):\n        headers = {\"Content-Length\": \"not zero\"}\n       "}, {"start_line": 1000, "end_line": 3000, "belongs_to": {"file_name": "test_requests.py", "upper_path": "/data2/raymone/swebench-repos/requests/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "ions import Timeout, TooManyRedirects, UnrewindableBodyError\nfrom requests.hooks import default_hooks\nfrom requests.models import PreparedRequest, urlencode\nfrom requests.sessions import SessionRedirectMixin\nfrom requests.structures import CaseInsensitiveDict\n\nfrom . import SNIMissingWarning\nfrom .compat import StringIO\nfrom .testserver.server import TLSServer, consume_socket_content\nfrom .utils import override_environ\n\n# Requests to this URL should always fail with a connection timeout (nothing\n# listening on that port)\nTARPIT = \"http://10.255.255.1\"\n\n# This is to avoid waiting the timeout of using TARPIT\nINVALID_PROXY = \"http://localhost:1\"\n\ntry:\n    from ssl import SSLContext\n\n    del SSLContext\n    HAS_MODERN_SSL = True\nexcept ImportError:\n    HAS_MODERN_SSL = False\n\ntry:\n    requests.pyopenssl\n    HAS_PYOPENSSL = True\nexcept AttributeError:\n    HAS_PYOPENSSL = False\n\n\nclass TestRequests:\n    digest_auth_algo = (\"MD5\", \"SHA-256\", \"SHA-512\")\n\n    def test_entry_points(self):\n        requests.session\n        requests.session().get\n        requests.session().head\n        requests.get\n        requests.head\n        requests.put\n        requests.patch\n        requests.post\n        # Not really an entry point, but people rely on it.\n        from requests.packages.urllib3.poolmanager import PoolManager  # noqa:F401\n\n    @pytest.mark.parametrize(\n        \"exception, url\",\n        (\n            (MissingSchema, \"hiwpefhipowhefopw\"),\n            (InvalidSchema, \"localhost:3128\"),\n            (InvalidSchema, \"localhost.localdomain:3128/\"),\n            (InvalidSchema, \"10.122.1.1:3128/\"),\n            (InvalidURL, \"http://\"),\n            (InvalidURL, \"http://*example.com\"),\n            (InvalidURL, \"http://.example.com\"),\n        ),\n    )\n    def test_invalid_url(self, exception, url):\n        with pytest.raises(exception):\n            requests.get(url)\n\n    def test_basic_building(self):\n        req = requests.Request()\n        req.url = \"http://kennethreitz.org/\"\n        req"}, {"start_line": 74000, "end_line": 76000, "belongs_to": {"file_name": "test_requests.py", "upper_path": "/data2/raymone/swebench-repos/requests/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "name, password)\n        assert isinstance(s, builtin_str)\n        assert s == auth_str\n\n    def test_requests_history_is_saved(self, httpbin):\n        r = requests.get(httpbin(\"redirect/5\"))\n        total = r.history[-1].history\n        i = 0\n        for item in r.history:\n            assert item.history == total[0:i]\n            i += 1\n\n    def test_json_param_post_content_type_works(self, httpbin):\n        r = requests.post(httpbin(\"post\"), json={\"life\": 42})\n        assert r.status_code == 200\n        assert \"application/json\" in r.request.headers[\"Content-Type\"]\n        assert {\"life\": 42} == r.json()[\"json\"]\n\n    def test_json_param_post_should_not_override_data_param(self, httpbin):\n        r = requests.Request(\n            method=\"POST\",\n            url=httpbin(\"post\"),\n            data={\"stuff\": \"elixr\"},\n            json={\"music\": \"flute\"},\n        )\n        prep = r.prepare()\n        assert \"stuff=elixr\" == prep.body\n\n    def test_response_iter_lines(self, httpbin):\n        r = requests.get(httpbin(\"stream/4\"), stream=True)\n        assert r.status_code == 200\n\n        it = r.iter_lines()\n        next(it)\n        assert len(list(it)) == 3\n\n    def test_response_context_manager(self, httpbin):\n        with requests.get(httpbin(\"stream/4\"), stream=True) as response:\n            assert isinstance(response, requests.Response)\n\n        assert response.raw.closed\n\n    def test_unconsumed_session_response_closes_connection(self, httpbin):\n        s = requests.session()\n\n        with contextlib.closing(s.get(httpbin(\"stream/4\"), stream=True)) as response:\n            pass\n\n        assert response._content_consumed is False\n        assert response.raw.closed\n\n    @pytest.mark.xfail\n    def test_response_iter_lines_reentrant(self, httpbin):\n        \"\"\"Response.iter_lines() is not reentrant safe\"\"\"\n        r = requests.get(httpbin(\"stream/4\"), stream=True)\n        assert r.status_code == 200\n\n        next(r.iter_lines())\n        assert len(list(r.iter_lines())) == 3\n\n"}, {"start_line": 0, "end_line": 2000, "belongs_to": {"file_name": "__init__.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "#   __\n#  /__)  _  _     _   _ _/   _\n# / (   (- (/ (/ (- _)  /  _)\n#          /\n\n\"\"\"\nRequests HTTP Library\n~~~~~~~~~~~~~~~~~~~~~\n\nRequests is an HTTP library, written in Python, for human beings.\nBasic GET usage:\n\n   >>> import requests\n   >>> r = requests.get('https://www.python.org')\n   >>> r.status_code\n   200\n   >>> b'Python is a programming language' in r.content\n   True\n\n... or POST:\n\n   >>> payload = dict(key1='value1', key2='value2')\n   >>> r = requests.post('https://httpbin.org/post', data=payload)\n   >>> print(r.text)\n   {\n     ...\n     \"form\": {\n       \"key1\": \"value1\",\n       \"key2\": \"value2\"\n     },\n     ...\n   }\n\nThe other HTTP methods are supported - see `requests.api`. Full documentation\nis at <https://requests.readthedocs.io>.\n\n:copyright: (c) 2017 by Kenneth Reitz.\n:license: Apache 2.0, see LICENSE for more details.\n\"\"\"\n\nimport warnings\n\nimport urllib3\n\nfrom .exceptions import RequestsDependencyWarning\n\ntry:\n    from charset_normalizer import __version__ as charset_normalizer_version\nexcept ImportError:\n    charset_normalizer_version = None\n\ntry:\n    from chardet import __version__ as chardet_version\nexcept ImportError:\n    chardet_version = None\n\n\ndef check_compatibility(urllib3_version, chardet_version, charset_normalizer_version):\n    urllib3_version = urllib3_version.split(\".\")\n    assert urllib3_version != [\"dev\"]  # Verify urllib3 isn't installed from git.\n\n    # Sometimes, urllib3 only reports its version as 16.1.\n    if len(urllib3_version) == 2:\n        urllib3_version.append(\"0\")\n\n    # Check urllib3 for compatibility.\n    major, minor, patch = urllib3_version  # noqa: F811\n    major, minor, patch = int(major), int(minor), int(patch)\n    # urllib3 >= 1.21.1\n    assert major >= 1\n    if major == 1:\n        assert minor >= 21\n\n    # Check charset_normalizer for compatibility.\n    if chardet_version:\n        major, minor, patch = chardet_version.split(\".\")[:3]\n        major, minor, patch = int(major), int(minor), int(patch)\n        # charde"}, {"start_line": 73000, "end_line": 75000, "belongs_to": {"file_name": "test_requests.py", "upper_path": "/data2/raymone/swebench-repos/requests/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "er.build_response\n        self._patched_response = False\n\n        def build_response(*args, **kwargs):\n            resp = org_build_response(*args, **kwargs)\n            if not self._patched_response:\n                resp.raw.headers[\"content-encoding\"] = \"gzip\"\n                self._patched_response = True\n            return resp\n\n        adapter.build_response = build_response\n\n    def test_redirect_with_wrong_gzipped_header(self, httpbin):\n        s = requests.Session()\n        url = httpbin(\"redirect/1\")\n        self._patch_adapter_gzipped_redirect(s, url)\n        s.get(url)\n\n    @pytest.mark.parametrize(\n        \"username, password, auth_str\",\n        (\n            (\"test\", \"test\", \"Basic dGVzdDp0ZXN0\"),\n            (\n                \"\".encode(),\n                \"\".encode(),\n                \"Basic 0LjQvNGPOtC/0LDRgNC+0LvRjA==\",\n            ),\n        ),\n    )\n    def test_basic_auth_str_is_always_native(self, username, password, auth_str):\n        s = _basic_auth_str(username, password)\n        assert isinstance(s, builtin_str)\n        assert s == auth_str\n\n    def test_requests_history_is_saved(self, httpbin):\n        r = requests.get(httpbin(\"redirect/5\"))\n        total = r.history[-1].history\n        i = 0\n        for item in r.history:\n            assert item.history == total[0:i]\n            i += 1\n\n    def test_json_param_post_content_type_works(self, httpbin):\n        r = requests.post(httpbin(\"post\"), json={\"life\": 42})\n        assert r.status_code == 200\n        assert \"application/json\" in r.request.headers[\"Content-Type\"]\n        assert {\"life\": 42} == r.json()[\"json\"]\n\n    def test_json_param_post_should_not_override_data_param(self, httpbin):\n        r = requests.Request(\n            method=\"POST\",\n            url=httpbin(\"post\"),\n            data={\"stuff\": \"elixr\"},\n            json={\"music\": \"flute\"},\n        )\n        prep = r.prepare()\n        assert \"stuff=elixr\" == prep.body\n\n    def test_response_iter_lines(self, httpbin):\n        r"}, {"start_line": 1000, "end_line": 3000, "belongs_to": {"file_name": "models.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "\nfrom .cookies import _copy_cookie_jar, cookiejar_from_dict, get_cookie_header\nfrom .exceptions import (\n    ChunkedEncodingError,\n    ConnectionError,\n    ContentDecodingError,\n    HTTPError,\n    InvalidJSONError,\n    InvalidURL,\n)\nfrom .exceptions import JSONDecodeError as RequestsJSONDecodeError\nfrom .exceptions import MissingSchema\nfrom .exceptions import SSLError as RequestsSSLError\nfrom .exceptions import StreamConsumedError\nfrom .hooks import default_hooks\nfrom .status_codes import codes\nfrom .structures import CaseInsensitiveDict\nfrom .utils import (\n    check_header_validity,\n    get_auth_from_url,\n    guess_filename,\n    guess_json_utf,\n    iter_slices,\n    parse_header_links,\n    requote_uri,\n    stream_decode_response_unicode,\n    super_len,\n    to_key_val_list,\n)\n\n#: The set of HTTP status codes that indicate an automatically\n#: processable redirect.\nREDIRECT_STATI = (\n    codes.moved,  # 301\n    codes.found,  # 302\n    codes.other,  # 303\n    codes.temporary_redirect,  # 307\n    codes.permanent_redirect,  # 308\n)\n\nDEFAULT_REDIRECT_LIMIT = 30\nCONTENT_CHUNK_SIZE = 10 * 1024\nITER_CHUNK_SIZE = 512\n\n\nclass RequestEncodingMixin:\n    @property\n    def path_url(self):\n        \"\"\"Build the path URL to use.\"\"\"\n\n        url = []\n\n        p = urlsplit(self.url)\n\n        path = p.path\n        if not path:\n            path = \"/\"\n\n        url.append(path)\n\n        query = p.query\n        if query:\n            url.append(\"?\")\n            url.append(query)\n\n        return \"\".join(url)\n\n    @staticmethod\n    def _encode_params(data):\n        \"\"\"Encode parameters in a piece of data.\n\n        Will successfully encode parameters when passed as a dict or a list of\n        2-tuples. Order is retained if data is a list of 2-tuples but arbitrary\n        if parameters are supplied as a dict.\n        \"\"\"\n\n        if isinstance(data, (str, bytes)):\n            return data\n        elif hasattr(data, \"read\"):\n            return data\n        elif hasattr(data, \"__iter__\"):\n         "}, {"start_line": 13000, "end_line": 15000, "belongs_to": {"file_name": "sessions.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "POST is responded to with a 301, turn it into a GET.\n        # This bizarre behaviour is explained in Issue 1704.\n        if response.status_code == codes.moved and method == \"POST\":\n            method = \"GET\"\n\n        prepared_request.method = method\n\n\nclass Session(SessionRedirectMixin):\n    \"\"\"A Requests session.\n\n    Provides cookie persistence, connection-pooling, and configuration.\n\n    Basic Usage::\n\n      >>> import requests\n      >>> s = requests.Session()\n      >>> s.get('https://httpbin.org/get')\n      <Response [200]>\n\n    Or as a context manager::\n\n      >>> with requests.Session() as s:\n      ...     s.get('https://httpbin.org/get')\n      <Response [200]>\n    \"\"\"\n\n    __attrs__ = [\n        \"headers\",\n        \"cookies\",\n        \"auth\",\n        \"proxies\",\n        \"hooks\",\n        \"params\",\n        \"verify\",\n        \"cert\",\n        \"adapters\",\n        \"stream\",\n        \"trust_env\",\n        \"max_redirects\",\n    ]\n\n    def __init__(self):\n        #: A case-insensitive dictionary of headers to be sent on each\n        #: :class:`Request <Request>` sent from this\n        #: :class:`Session <Session>`.\n        self.headers = default_headers()\n\n        #: Default Authentication tuple or object to attach to\n        #: :class:`Request <Request>`.\n        self.auth = None\n\n        #: Dictionary mapping protocol or protocol and host to the URL of the proxy\n        #: (e.g. {'http': 'foo.bar:3128', 'http://host.name': 'foo.bar:4012'}) to\n        #: be used on each :class:`Request <Request>`.\n        self.proxies = {}\n\n        #: Event-handling hooks.\n        self.hooks = default_hooks()\n\n        #: Dictionary of querystring data to attach to each\n        #: :class:`Request <Request>`. The dictionary values may be lists for\n        #: representing multivalued query parameters.\n        self.params = {}\n\n        #: Stream response content default.\n        self.stream = False\n\n        #: SSL Verification default.\n        #: Defaults to `True`, requiring requests to verif"}], "retrieved_count": 10, "cost_time": 0.8839066028594971}
{"question": "How does Requests support authentication mechanisms commonly used in APIs, such as OAuth or JWT?", "answer": null, "relative_code_list": null, "ground_truth": "Requests supports API authentication mechanisms through its extensible authentication system: 1) AuthBase extension - Custom authentication handlers can be implemented by subclassing AuthBase for OAuth, JWT, or other schemes; 2) Header-based auth - Auth handlers can add custom headers (Authorization, X-API-Key, etc.) for API authentication; 3) Token management - Custom handlers can manage token refresh, expiration, and storage for OAuth flows; 4) Session integration - API authentication can be set at session level for persistent authentication across requests; 5) Request-level auth - Individual requests can use custom authentication handlers for specific API calls; 6) Hook system - Response hooks can handle authentication challenges and token refresh automatically; 7) State management - Auth handlers can maintain state across requests for token caching and management; 8) Challenge handling - Custom handlers can implement handle_401() method for authentication challenge responses; 9) Header manipulation - Auth handlers can modify any request headers needed for API authentication; 10) Flexibility - The system supports any authentication scheme that can be implemented through HTTP headers or request modification.", "score": null, "retrieved_content": [{"start_line": 28000, "end_line": 30000, "belongs_to": {"file_name": "test_requests.py", "upper_path": "/data2/raymone/swebench-repos/requests/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "Auth(\"user\", \"pass\")\n            s = requests.Session()\n            s.get(url, auth=auth)\n            assert s.cookies[\"fake\"] == \"fake_value\"\n\n    def test_DIGEST_STREAM(self, httpbin):\n        for authtype in self.digest_auth_algo:\n            auth = HTTPDigestAuth(\"user\", \"pass\")\n            url = httpbin(\"digest-auth\", \"auth\", \"user\", \"pass\", authtype)\n\n            r = requests.get(url, auth=auth, stream=True)\n            assert r.raw.read() != b\"\"\n\n            r = requests.get(url, auth=auth, stream=False)\n            assert r.raw.read() == b\"\"\n\n    def test_DIGESTAUTH_WRONG_HTTP_401_GET(self, httpbin):\n        for authtype in self.digest_auth_algo:\n            auth = HTTPDigestAuth(\"user\", \"wrongpass\")\n            url = httpbin(\"digest-auth\", \"auth\", \"user\", \"pass\", authtype)\n\n            r = requests.get(url, auth=auth)\n            assert r.status_code == 401\n\n            r = requests.get(url)\n            assert r.status_code == 401\n\n            s = requests.session()\n            s.auth = auth\n            r = s.get(url)\n            assert r.status_code == 401\n\n    def test_DIGESTAUTH_QUOTES_QOP_VALUE(self, httpbin):\n        for authtype in self.digest_auth_algo:\n            auth = HTTPDigestAuth(\"user\", \"pass\")\n            url = httpbin(\"digest-auth\", \"auth\", \"user\", \"pass\", authtype)\n\n            r = requests.get(url, auth=auth)\n            assert '\"auth\"' in r.request.headers[\"Authorization\"]\n\n    def test_POSTBIN_GET_POST_FILES(self, httpbin):\n        url = httpbin(\"post\")\n        requests.post(url).raise_for_status()\n\n        post1 = requests.post(url, data={\"some\": \"data\"})\n        assert post1.status_code == 200\n\n        with open(\"requirements-dev.txt\") as f:\n            post2 = requests.post(url, files={\"some\": f})\n        assert post2.status_code == 200\n\n        post4 = requests.post(url, data='[{\"some\": \"json\"}]')\n        assert post4.status_code == 200\n\n        with pytest.raises(ValueError):\n            requests.post(url, files=[\"bad file data\"])\n"}, {"start_line": 43000, "end_line": 45000, "belongs_to": {"file_name": "test_requests.py", "upper_path": "/data2/raymone/swebench-repos/requests/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "ook})\n        prep = req.prepare()\n\n        s = requests.Session()\n        s.proxies = getproxies()\n        resp = s.send(prep)\n\n        assert hasattr(resp, \"hook_working\")\n\n    def test_prepared_from_session(self, httpbin):\n        class DummyAuth(requests.auth.AuthBase):\n            def __call__(self, r):\n                r.headers[\"Dummy-Auth-Test\"] = \"dummy-auth-test-ok\"\n                return r\n\n        req = requests.Request(\"GET\", httpbin(\"headers\"))\n        assert not req.auth\n\n        s = requests.Session()\n        s.auth = DummyAuth()\n\n        prep = s.prepare_request(req)\n        resp = s.send(prep)\n\n        assert resp.json()[\"headers\"][\"Dummy-Auth-Test\"] == \"dummy-auth-test-ok\"\n\n    def test_prepare_request_with_bytestring_url(self):\n        req = requests.Request(\"GET\", b\"https://httpbin.org/\")\n        s = requests.Session()\n        prep = s.prepare_request(req)\n        assert prep.url == \"https://httpbin.org/\"\n\n    def test_request_with_bytestring_host(self, httpbin):\n        s = requests.Session()\n        resp = s.request(\n            \"GET\",\n            httpbin(\"cookies/set?cookie=value\"),\n            allow_redirects=False,\n            headers={\"Host\": b\"httpbin.org\"},\n        )\n        assert resp.cookies.get(\"cookie\") == \"value\"\n\n    def test_links(self):\n        r = requests.Response()\n        r.headers = {\n            \"cache-control\": \"public, max-age=60, s-maxage=60\",\n            \"connection\": \"keep-alive\",\n            \"content-encoding\": \"gzip\",\n            \"content-type\": \"application/json; charset=utf-8\",\n            \"date\": \"Sat, 26 Jan 2013 16:47:56 GMT\",\n            \"etag\": '\"6ff6a73c0e446c1f61614769e3ceb778\"',\n            \"last-modified\": \"Sat, 26 Jan 2013 16:22:39 GMT\",\n            \"link\": (\n                \"<https://api.github.com/users/kennethreitz/repos?\"\n                'page=2&per_page=10>; rel=\"next\", <https://api.github.'\n                \"com/users/kennethreitz/repos?page=7&per_page=10>; \"\n                ' rel=\"last\"'\n           "}, {"start_line": 2000, "end_line": 4000, "belongs_to": {"file_name": "auth.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "sword))).strip()\n    )\n\n    return authstr\n\n\nclass AuthBase:\n    \"\"\"Base class that all auth implementations derive from\"\"\"\n\n    def __call__(self, r):\n        raise NotImplementedError(\"Auth hooks must be callable.\")\n\n\nclass HTTPBasicAuth(AuthBase):\n    \"\"\"Attaches HTTP Basic Authentication to the given Request object.\"\"\"\n\n    def __init__(self, username, password):\n        self.username = username\n        self.password = password\n\n    def __eq__(self, other):\n        return all(\n            [\n                self.username == getattr(other, \"username\", None),\n                self.password == getattr(other, \"password\", None),\n            ]\n        )\n\n    def __ne__(self, other):\n        return not self == other\n\n    def __call__(self, r):\n        r.headers[\"Authorization\"] = _basic_auth_str(self.username, self.password)\n        return r\n\n\nclass HTTPProxyAuth(HTTPBasicAuth):\n    \"\"\"Attaches HTTP Proxy Authentication to a given Request object.\"\"\"\n\n    def __call__(self, r):\n        r.headers[\"Proxy-Authorization\"] = _basic_auth_str(self.username, self.password)\n        return r\n\n\nclass HTTPDigestAuth(AuthBase):\n    \"\"\"Attaches HTTP Digest Authentication to the given Request object.\"\"\"\n\n    def __init__(self, username, password):\n        self.username = username\n        self.password = password\n        # Keep state in per-thread local storage\n        self._thread_local = threading.local()\n\n    def init_per_thread_state(self):\n        # Ensure state is initialized just once per-thread\n        if not hasattr(self._thread_local, \"init\"):\n            self._thread_local.init = True\n            self._thread_local.last_nonce = \"\"\n            self._thread_local.nonce_count = 0\n            self._thread_local.chal = {}\n            self._thread_local.pos = None\n            self._thread_local.num_401_calls = None\n\n    def build_digest_header(self, method, url):\n        \"\"\"\n        :rtype: str\n        \"\"\"\n\n        realm = self._thread_local.chal[\"realm\"]\n        nonce = self._threa"}, {"start_line": 67000, "end_line": 69000, "belongs_to": {"file_name": "test_requests.py", "upper_path": "/data2/raymone/swebench-repos/requests/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "    auth=(\"user\", \"pass\"),\n            verify=httpbin_ca_bundle,\n        )\n        assert r.history[0].request.headers[\"Authorization\"]\n        assert \"Authorization\" not in r.request.headers\n\n    def test_auth_is_retained_for_redirect_on_host(self, httpbin):\n        r = requests.get(httpbin(\"redirect/1\"), auth=(\"user\", \"pass\"))\n        h1 = r.history[0].request.headers[\"Authorization\"]\n        h2 = r.request.headers[\"Authorization\"]\n\n        assert h1 == h2\n\n    def test_should_strip_auth_host_change(self):\n        s = requests.Session()\n        assert s.should_strip_auth(\n            \"http://example.com/foo\", \"http://another.example.com/\"\n        )\n\n    def test_should_strip_auth_http_downgrade(self):\n        s = requests.Session()\n        assert s.should_strip_auth(\"https://example.com/foo\", \"http://example.com/bar\")\n\n    def test_should_strip_auth_https_upgrade(self):\n        s = requests.Session()\n        assert not s.should_strip_auth(\n            \"http://example.com/foo\", \"https://example.com/bar\"\n        )\n        assert not s.should_strip_auth(\n            \"http://example.com:80/foo\", \"https://example.com/bar\"\n        )\n        assert not s.should_strip_auth(\n            \"http://example.com/foo\", \"https://example.com:443/bar\"\n        )\n        # Non-standard ports should trigger stripping\n        assert s.should_strip_auth(\n            \"http://example.com:8080/foo\", \"https://example.com/bar\"\n        )\n        assert s.should_strip_auth(\n            \"http://example.com/foo\", \"https://example.com:8443/bar\"\n        )\n\n    def test_should_strip_auth_port_change(self):\n        s = requests.Session()\n        assert s.should_strip_auth(\n            \"http://example.com:1234/foo\", \"https://example.com:4321/bar\"\n        )\n\n    @pytest.mark.parametrize(\n        \"old_uri, new_uri\",\n        (\n            (\"https://example.com:443/foo\", \"https://example.com/bar\"),\n            (\"http://example.com:80/foo\", \"http://example.com/bar\"),\n            (\"https://example.com/foo\","}, {"start_line": 25000, "end_line": 27000, "belongs_to": {"file_name": "test_requests.py", "upper_path": "/data2/raymone/swebench-repos/requests/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "get_netrc_auth_mock(url):\n                return auth\n\n            requests.sessions.get_netrc_auth = get_netrc_auth_mock\n\n            # Should use netrc and work.\n            r = requests.get(url)\n            assert r.status_code == 200\n\n            # Given auth should override and fail.\n            r = requests.get(url, auth=wrong_auth)\n            assert r.status_code == 401\n\n            s = requests.session()\n\n            # Should use netrc and work.\n            r = s.get(url)\n            assert r.status_code == 200\n\n            # Given auth should override and fail.\n            s.auth = wrong_auth\n            r = s.get(url)\n            assert r.status_code == 401\n        finally:\n            requests.sessions.get_netrc_auth = old_auth\n\n    def test_basicauth_with_netrc_leak(self, httpbin):\n        url1 = httpbin(\"basic-auth\", \"user\", \"pass\")\n        url = url1[len(\"http://\") :]\n        domain = url.split(\":\")[0]\n        url = f\"http://example.com:@{url}\"\n\n        netrc_file = \"\"\n        with tempfile.NamedTemporaryFile(mode=\"w\", delete=False) as fp:\n            fp.write(\"machine example.com\\n\")\n            fp.write(\"login wronguser\\n\")\n            fp.write(\"password wrongpass\\n\")\n            fp.write(f\"machine {domain}\\n\")\n            fp.write(\"login user\\n\")\n            fp.write(\"password pass\\n\")\n            fp.close()\n            netrc_file = fp.name\n\n        old_netrc = os.environ.get(\"NETRC\", \"\")\n        os.environ[\"NETRC\"] = netrc_file\n\n        try:\n            # Should use netrc\n            # Make sure that we don't use the example.com credentails\n            # for the request\n            r = requests.get(url)\n            assert r.status_code == 200\n        finally:\n            os.environ[\"NETRC\"] = old_netrc\n            os.unlink(netrc_file)\n\n    def test_DIGEST_HTTP_200_OK_GET(self, httpbin):\n        for authtype in self.digest_auth_algo:\n            auth = HTTPDigestAuth(\"user\", \"pass\")\n            url = httpbin(\"digest-auth\", \"auth\", \"user\", \"pass\", "}, {"start_line": 0, "end_line": 2000, "belongs_to": {"file_name": "auth.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "\"\"\"\nrequests.auth\n~~~~~~~~~~~~~\n\nThis module contains the authentication handlers for Requests.\n\"\"\"\n\nimport hashlib\nimport os\nimport re\nimport threading\nimport time\nimport warnings\nfrom base64 import b64encode\n\nfrom ._internal_utils import to_native_string\nfrom .compat import basestring, str, urlparse\nfrom .cookies import extract_cookies_to_jar\nfrom .utils import parse_dict_header\n\nCONTENT_TYPE_FORM_URLENCODED = \"application/x-www-form-urlencoded\"\nCONTENT_TYPE_MULTI_PART = \"multipart/form-data\"\n\n\ndef _basic_auth_str(username, password):\n    \"\"\"Returns a Basic Auth string.\"\"\"\n\n    # \"I want us to put a big-ol' comment on top of it that\n    # says that this behaviour is dumb but we need to preserve\n    # it because people are relying on it.\"\n    #    - Lukasa\n    #\n    # These are here solely to maintain backwards compatibility\n    # for things like ints. This will be removed in 3.0.0.\n    if not isinstance(username, basestring):\n        warnings.warn(\n            \"Non-string usernames will no longer be supported in Requests \"\n            \"3.0.0. Please convert the object you've passed in ({!r}) to \"\n            \"a string or bytes object in the near future to avoid \"\n            \"problems.\".format(username),\n            category=DeprecationWarning,\n        )\n        username = str(username)\n\n    if not isinstance(password, basestring):\n        warnings.warn(\n            \"Non-string passwords will no longer be supported in Requests \"\n            \"3.0.0. Please convert the object you've passed in ({!r}) to \"\n            \"a string or bytes object in the near future to avoid \"\n            \"problems.\".format(type(password)),\n            category=DeprecationWarning,\n        )\n        password = str(password)\n    # -- End Removal --\n\n    if isinstance(username, str):\n        username = username.encode(\"latin1\")\n\n    if isinstance(password, str):\n        password = password.encode(\"latin1\")\n\n    authstr = \"Basic \" + to_native_string(\n        b64encode(b\":\".join((username, pas"}, {"start_line": 66000, "end_line": 68000, "belongs_to": {"file_name": "test_requests.py", "upper_path": "/data2/raymone/swebench-repos/requests/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "rt \"multipart/form-data\" in p.headers[\"Content-Type\"]\n\n    def test_autoset_header_values_are_native(self, httpbin):\n        data = \"this is a string\"\n        length = \"16\"\n        req = requests.Request(\"POST\", httpbin(\"post\"), data=data)\n        p = req.prepare()\n\n        assert p.headers[\"Content-Length\"] == length\n\n    def test_nonhttp_schemes_dont_check_URLs(self):\n        test_urls = (\n            \"data:image/gif;base64,R0lGODlhAQABAHAAACH5BAUAAAAALAAAAAABAAEAAAICRAEAOw==\",\n            \"file:///etc/passwd\",\n            \"magnet:?xt=urn:btih:be08f00302bc2d1d3cfa3af02024fa647a271431\",\n        )\n        for test_url in test_urls:\n            req = requests.Request(\"GET\", test_url)\n            preq = req.prepare()\n            assert test_url == preq.url\n\n    def test_auth_is_stripped_on_http_downgrade(\n        self, httpbin, httpbin_secure, httpbin_ca_bundle\n    ):\n        r = requests.get(\n            httpbin_secure(\"redirect-to\"),\n            params={\"url\": httpbin(\"get\")},\n            auth=(\"user\", \"pass\"),\n            verify=httpbin_ca_bundle,\n        )\n        assert r.history[0].request.headers[\"Authorization\"]\n        assert \"Authorization\" not in r.request.headers\n\n    def test_auth_is_retained_for_redirect_on_host(self, httpbin):\n        r = requests.get(httpbin(\"redirect/1\"), auth=(\"user\", \"pass\"))\n        h1 = r.history[0].request.headers[\"Authorization\"]\n        h2 = r.request.headers[\"Authorization\"]\n\n        assert h1 == h2\n\n    def test_should_strip_auth_host_change(self):\n        s = requests.Session()\n        assert s.should_strip_auth(\n            \"http://example.com/foo\", \"http://another.example.com/\"\n        )\n\n    def test_should_strip_auth_http_downgrade(self):\n        s = requests.Session()\n        assert s.should_strip_auth(\"https://example.com/foo\", \"http://example.com/bar\")\n\n    def test_should_strip_auth_https_upgrade(self):\n        s = requests.Session()\n        assert not s.should_strip_auth(\n            \"http://example.com/foo\", \"https"}, {"start_line": 29000, "end_line": 31000, "belongs_to": {"file_name": "test_requests.py", "upper_path": "/data2/raymone/swebench-repos/requests/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "  s.auth = auth\n            r = s.get(url)\n            assert r.status_code == 401\n\n    def test_DIGESTAUTH_QUOTES_QOP_VALUE(self, httpbin):\n        for authtype in self.digest_auth_algo:\n            auth = HTTPDigestAuth(\"user\", \"pass\")\n            url = httpbin(\"digest-auth\", \"auth\", \"user\", \"pass\", authtype)\n\n            r = requests.get(url, auth=auth)\n            assert '\"auth\"' in r.request.headers[\"Authorization\"]\n\n    def test_POSTBIN_GET_POST_FILES(self, httpbin):\n        url = httpbin(\"post\")\n        requests.post(url).raise_for_status()\n\n        post1 = requests.post(url, data={\"some\": \"data\"})\n        assert post1.status_code == 200\n\n        with open(\"requirements-dev.txt\") as f:\n            post2 = requests.post(url, files={\"some\": f})\n        assert post2.status_code == 200\n\n        post4 = requests.post(url, data='[{\"some\": \"json\"}]')\n        assert post4.status_code == 200\n\n        with pytest.raises(ValueError):\n            requests.post(url, files=[\"bad file data\"])\n\n    def test_invalid_files_input(self, httpbin):\n        url = httpbin(\"post\")\n        post = requests.post(url, files={\"random-file-1\": None, \"random-file-2\": 1})\n        assert b'name=\"random-file-1\"' not in post.request.body\n        assert b'name=\"random-file-2\"' in post.request.body\n\n    def test_POSTBIN_SEEKED_OBJECT_WITH_NO_ITER(self, httpbin):\n        class TestStream:\n            def __init__(self, data):\n                self.data = data.encode()\n                self.length = len(self.data)\n                self.index = 0\n\n            def __len__(self):\n                return self.length\n\n            def read(self, size=None):\n                if size:\n                    ret = self.data[self.index : self.index + size]\n                    self.index += size\n                else:\n                    ret = self.data[self.index :]\n                    self.index = self.length\n                return ret\n\n            def tell(self):\n                return self.index\n\n            def s"}, {"start_line": 27000, "end_line": 29000, "belongs_to": {"file_name": "test_requests.py", "upper_path": "/data2/raymone/swebench-repos/requests/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "authtype, \"never\")\n\n            r = requests.get(url, auth=auth)\n            assert r.status_code == 200\n\n            r = requests.get(url)\n            assert r.status_code == 401\n            print(r.headers[\"WWW-Authenticate\"])\n\n            s = requests.session()\n            s.auth = HTTPDigestAuth(\"user\", \"pass\")\n            r = s.get(url)\n            assert r.status_code == 200\n\n    def test_DIGEST_AUTH_RETURNS_COOKIE(self, httpbin):\n        for authtype in self.digest_auth_algo:\n            url = httpbin(\"digest-auth\", \"auth\", \"user\", \"pass\", authtype)\n            auth = HTTPDigestAuth(\"user\", \"pass\")\n            r = requests.get(url)\n            assert r.cookies[\"fake\"] == \"fake_value\"\n\n            r = requests.get(url, auth=auth)\n            assert r.status_code == 200\n\n    def test_DIGEST_AUTH_SETS_SESSION_COOKIES(self, httpbin):\n        for authtype in self.digest_auth_algo:\n            url = httpbin(\"digest-auth\", \"auth\", \"user\", \"pass\", authtype)\n            auth = HTTPDigestAuth(\"user\", \"pass\")\n            s = requests.Session()\n            s.get(url, auth=auth)\n            assert s.cookies[\"fake\"] == \"fake_value\"\n\n    def test_DIGEST_STREAM(self, httpbin):\n        for authtype in self.digest_auth_algo:\n            auth = HTTPDigestAuth(\"user\", \"pass\")\n            url = httpbin(\"digest-auth\", \"auth\", \"user\", \"pass\", authtype)\n\n            r = requests.get(url, auth=auth, stream=True)\n            assert r.raw.read() != b\"\"\n\n            r = requests.get(url, auth=auth, stream=False)\n            assert r.raw.read() == b\"\"\n\n    def test_DIGESTAUTH_WRONG_HTTP_401_GET(self, httpbin):\n        for authtype in self.digest_auth_algo:\n            auth = HTTPDigestAuth(\"user\", \"wrongpass\")\n            url = httpbin(\"digest-auth\", \"auth\", \"user\", \"pass\", authtype)\n\n            r = requests.get(url, auth=auth)\n            assert r.status_code == 401\n\n            r = requests.get(url)\n            assert r.status_code == 401\n\n            s = requests.session()\n          "}, {"start_line": 24000, "end_line": 26000, "belongs_to": {"file_name": "test_requests.py", "upper_path": "/data2/raymone/swebench-repos/requests/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "\", {})\n\n        assert sent_headers.get(\"Proxy-Authorization\") == proxy_auth_value\n\n    @pytest.mark.parametrize(\n        \"url,has_proxy_auth\",\n        (\n            (\"http://example.com\", True),\n            (\"https://example.com\", False),\n        ),\n    )\n    def test_proxy_authorization_not_appended_to_https_request(\n        self, url, has_proxy_auth\n    ):\n        session = requests.Session()\n        proxies = {\n            \"http\": \"http://test:pass@localhost:8080\",\n            \"https\": \"http://test:pass@localhost:8090\",\n        }\n        req = requests.Request(\"GET\", url)\n        prep = req.prepare()\n        session.rebuild_proxies(prep, proxies)\n\n        assert (\"Proxy-Authorization\" in prep.headers) is has_proxy_auth\n\n    def test_basicauth_with_netrc(self, httpbin):\n        auth = (\"user\", \"pass\")\n        wrong_auth = (\"wronguser\", \"wrongpass\")\n        url = httpbin(\"basic-auth\", \"user\", \"pass\")\n\n        old_auth = requests.sessions.get_netrc_auth\n\n        try:\n\n            def get_netrc_auth_mock(url):\n                return auth\n\n            requests.sessions.get_netrc_auth = get_netrc_auth_mock\n\n            # Should use netrc and work.\n            r = requests.get(url)\n            assert r.status_code == 200\n\n            # Given auth should override and fail.\n            r = requests.get(url, auth=wrong_auth)\n            assert r.status_code == 401\n\n            s = requests.session()\n\n            # Should use netrc and work.\n            r = s.get(url)\n            assert r.status_code == 200\n\n            # Given auth should override and fail.\n            s.auth = wrong_auth\n            r = s.get(url)\n            assert r.status_code == 401\n        finally:\n            requests.sessions.get_netrc_auth = old_auth\n\n    def test_basicauth_with_netrc_leak(self, httpbin):\n        url1 = httpbin(\"basic-auth\", \"user\", \"pass\")\n        url = url1[len(\"http://\") :]\n        domain = url.split(\":\")[0]\n        url = f\"http://example.com:@{url}\"\n\n        netrc_file = \"\"\n "}], "retrieved_count": 10, "cost_time": 0.8428418636322021}
{"question": "How does Requests handle API versioning and compatibility when interacting with evolving web services?", "answer": null, "relative_code_list": null, "ground_truth": "Requests handles API versioning and compatibility through several mechanisms: 1) Header customization - Custom headers can be set for API versioning (Accept, X-API-Version, etc.) at session or request level; 2) URL versioning - Different API versions can be handled by using different base URLs or URL patterns; 3) Session configuration - Sessions can be configured with version-specific headers, authentication, or base URLs; 4) Adapter customization - Custom adapters can be implemented for version-specific transport requirements; 5) Response handling - Response objects provide access to headers and status codes for version negotiation; 6) Error handling - Requests exceptions can be used to handle version-specific error responses; 7) Content negotiation - Accept headers can be customized for different API versions and content types; 8) Backward compatibility - Requests' stable API allows applications to handle multiple API versions simultaneously; 9) Configuration management - Session-level configuration enables easy switching between API versions; 10) Testing support - The adapter system enables mocking of different API versions for testing and development.", "score": null, "retrieved_content": [{"start_line": 0, "end_line": 2000, "belongs_to": {"file_name": "__init__.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "#   __\n#  /__)  _  _     _   _ _/   _\n# / (   (- (/ (/ (- _)  /  _)\n#          /\n\n\"\"\"\nRequests HTTP Library\n~~~~~~~~~~~~~~~~~~~~~\n\nRequests is an HTTP library, written in Python, for human beings.\nBasic GET usage:\n\n   >>> import requests\n   >>> r = requests.get('https://www.python.org')\n   >>> r.status_code\n   200\n   >>> b'Python is a programming language' in r.content\n   True\n\n... or POST:\n\n   >>> payload = dict(key1='value1', key2='value2')\n   >>> r = requests.post('https://httpbin.org/post', data=payload)\n   >>> print(r.text)\n   {\n     ...\n     \"form\": {\n       \"key1\": \"value1\",\n       \"key2\": \"value2\"\n     },\n     ...\n   }\n\nThe other HTTP methods are supported - see `requests.api`. Full documentation\nis at <https://requests.readthedocs.io>.\n\n:copyright: (c) 2017 by Kenneth Reitz.\n:license: Apache 2.0, see LICENSE for more details.\n\"\"\"\n\nimport warnings\n\nimport urllib3\n\nfrom .exceptions import RequestsDependencyWarning\n\ntry:\n    from charset_normalizer import __version__ as charset_normalizer_version\nexcept ImportError:\n    charset_normalizer_version = None\n\ntry:\n    from chardet import __version__ as chardet_version\nexcept ImportError:\n    chardet_version = None\n\n\ndef check_compatibility(urllib3_version, chardet_version, charset_normalizer_version):\n    urllib3_version = urllib3_version.split(\".\")\n    assert urllib3_version != [\"dev\"]  # Verify urllib3 isn't installed from git.\n\n    # Sometimes, urllib3 only reports its version as 16.1.\n    if len(urllib3_version) == 2:\n        urllib3_version.append(\"0\")\n\n    # Check urllib3 for compatibility.\n    major, minor, patch = urllib3_version  # noqa: F811\n    major, minor, patch = int(major), int(minor), int(patch)\n    # urllib3 >= 1.21.1\n    assert major >= 1\n    if major == 1:\n        assert minor >= 21\n\n    # Check charset_normalizer for compatibility.\n    if chardet_version:\n        major, minor, patch = chardet_version.split(\".\")[:3]\n        major, minor, patch = int(major), int(minor), int(patch)\n        # charde"}, {"start_line": 3000, "end_line": 5000, "belongs_to": {"file_name": "__init__.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "\n\n# Check imported dependencies for compatibility.\ntry:\n    check_compatibility(\n        urllib3.__version__, chardet_version, charset_normalizer_version\n    )\nexcept (AssertionError, ValueError):\n    warnings.warn(\n        \"urllib3 ({}) or chardet ({})/charset_normalizer ({}) doesn't match a supported \"\n        \"version!\".format(\n            urllib3.__version__, chardet_version, charset_normalizer_version\n        ),\n        RequestsDependencyWarning,\n    )\n\n# Attempt to enable urllib3's fallback for SNI support\n# if the standard library doesn't support SNI or the\n# 'ssl' library isn't available.\ntry:\n    try:\n        import ssl\n    except ImportError:\n        ssl = None\n\n    if not getattr(ssl, \"HAS_SNI\", False):\n        from urllib3.contrib import pyopenssl\n\n        pyopenssl.inject_into_urllib3()\n\n        # Check cryptography version\n        from cryptography import __version__ as cryptography_version\n\n        _check_cryptography(cryptography_version)\nexcept ImportError:\n    pass\n\n# urllib3's DependencyWarnings should be silenced.\nfrom urllib3.exceptions import DependencyWarning\n\nwarnings.simplefilter(\"ignore\", DependencyWarning)\n\n# Set default logging handler to avoid \"No handler found\" warnings.\nimport logging\nfrom logging import NullHandler\n\nfrom . import packages, utils\nfrom .__version__ import (\n    __author__,\n    __author_email__,\n    __build__,\n    __cake__,\n    __copyright__,\n    __description__,\n    __license__,\n    __title__,\n    __url__,\n    __version__,\n)\nfrom .api import delete, get, head, options, patch, post, put, request\nfrom .exceptions import (\n    ConnectionError,\n    ConnectTimeout,\n    FileModeWarning,\n    HTTPError,\n    JSONDecodeError,\n    ReadTimeout,\n    RequestException,\n    Timeout,\n    TooManyRedirects,\n    URLRequired,\n)\nfrom .models import PreparedRequest, Request, Response\nfrom .sessions import Session, session\nfrom .status_codes import codes\n\nlogging.getLogger(__name__).addHandler(NullHandler())\n\n# FileModeWarnings go off per the "}, {"start_line": 4000, "end_line": 5072, "belongs_to": {"file_name": "__init__.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": " urllib3's DependencyWarnings should be silenced.\nfrom urllib3.exceptions import DependencyWarning\n\nwarnings.simplefilter(\"ignore\", DependencyWarning)\n\n# Set default logging handler to avoid \"No handler found\" warnings.\nimport logging\nfrom logging import NullHandler\n\nfrom . import packages, utils\nfrom .__version__ import (\n    __author__,\n    __author_email__,\n    __build__,\n    __cake__,\n    __copyright__,\n    __description__,\n    __license__,\n    __title__,\n    __url__,\n    __version__,\n)\nfrom .api import delete, get, head, options, patch, post, put, request\nfrom .exceptions import (\n    ConnectionError,\n    ConnectTimeout,\n    FileModeWarning,\n    HTTPError,\n    JSONDecodeError,\n    ReadTimeout,\n    RequestException,\n    Timeout,\n    TooManyRedirects,\n    URLRequired,\n)\nfrom .models import PreparedRequest, Request, Response\nfrom .sessions import Session, session\nfrom .status_codes import codes\n\nlogging.getLogger(__name__).addHandler(NullHandler())\n\n# FileModeWarnings go off per the default.\nwarnings.simplefilter(\"default\", FileModeWarning, append=True)\n"}, {"start_line": 0, "end_line": 2000, "belongs_to": {"file_name": "api.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "\"\"\"\nrequests.api\n~~~~~~~~~~~~\n\nThis module implements the Requests API.\n\n:copyright: (c) 2012 by Kenneth Reitz.\n:license: Apache2, see LICENSE for more details.\n\"\"\"\n\nfrom . import sessions\n\n\ndef request(method, url, **kwargs):\n    \"\"\"Constructs and sends a :class:`Request <Request>`.\n\n    :param method: method for the new :class:`Request` object: ``GET``, ``OPTIONS``, ``HEAD``, ``POST``, ``PUT``, ``PATCH``, or ``DELETE``.\n    :param url: URL for the new :class:`Request` object.\n    :param params: (optional) Dictionary, list of tuples or bytes to send\n        in the query string for the :class:`Request`.\n    :param data: (optional) Dictionary, list of tuples, bytes, or file-like\n        object to send in the body of the :class:`Request`.\n    :param json: (optional) A JSON serializable Python object to send in the body of the :class:`Request`.\n    :param headers: (optional) Dictionary of HTTP Headers to send with the :class:`Request`.\n    :param cookies: (optional) Dict or CookieJar object to send with the :class:`Request`.\n    :param files: (optional) Dictionary of ``'name': file-like-objects`` (or ``{'name': file-tuple}``) for multipart encoding upload.\n        ``file-tuple`` can be a 2-tuple ``('filename', fileobj)``, 3-tuple ``('filename', fileobj, 'content_type')``\n        or a 4-tuple ``('filename', fileobj, 'content_type', custom_headers)``, where ``'content_type'`` is a string\n        defining the content type of the given file and ``custom_headers`` a dict-like object containing additional headers\n        to add for the file.\n    :param auth: (optional) Auth tuple to enable Basic/Digest/Custom HTTP Auth.\n    :param timeout: (optional) How many seconds to wait for the server to send data\n        before giving up, as a float, or a :ref:`(connect timeout, read\n        timeout) <timeouts>` tuple.\n    :type timeout: float or tuple\n    :param allow_redirects: (optional) Boolean. Enable/disable GET/OPTIONS/POST/PUT/PATCH/DELETE/HEAD redirection. Defaults to ``True``"}, {"start_line": 56000, "end_line": 58000, "belongs_to": {"file_name": "test_requests.py", "upper_path": "/data2/raymone/swebench-repos/requests/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "d(r.prepare())\n        assert r.status_code == 200\n\n    def test_fixes_1329(self, httpbin):\n        \"\"\"Ensure that header updates are done case-insensitively.\"\"\"\n        s = requests.Session()\n        s.headers.update({\"ACCEPT\": \"BOGUS\"})\n        s.headers.update({\"accept\": \"application/json\"})\n        r = s.get(httpbin(\"get\"))\n        headers = r.request.headers\n        assert headers[\"accept\"] == \"application/json\"\n        assert headers[\"Accept\"] == \"application/json\"\n        assert headers[\"ACCEPT\"] == \"application/json\"\n\n    def test_uppercase_scheme_redirect(self, httpbin):\n        parts = urlparse(httpbin(\"html\"))\n        url = \"HTTP://\" + parts.netloc + parts.path\n        r = requests.get(httpbin(\"redirect-to\"), params={\"url\": url})\n        assert r.status_code == 200\n        assert r.url.lower() == url.lower()\n\n    def test_transport_adapter_ordering(self):\n        s = requests.Session()\n        order = [\"https://\", \"http://\"]\n        assert order == list(s.adapters)\n        s.mount(\"http://git\", HTTPAdapter())\n        s.mount(\"http://github\", HTTPAdapter())\n        s.mount(\"http://github.com\", HTTPAdapter())\n        s.mount(\"http://github.com/about/\", HTTPAdapter())\n        order = [\n            \"http://github.com/about/\",\n            \"http://github.com\",\n            \"http://github\",\n            \"http://git\",\n            \"https://\",\n            \"http://\",\n        ]\n        assert order == list(s.adapters)\n        s.mount(\"http://gittip\", HTTPAdapter())\n        s.mount(\"http://gittip.com\", HTTPAdapter())\n        s.mount(\"http://gittip.com/about/\", HTTPAdapter())\n        order = [\n            \"http://github.com/about/\",\n            \"http://gittip.com/about/\",\n            \"http://github.com\",\n            \"http://gittip.com\",\n            \"http://github\",\n            \"http://gittip\",\n            \"http://git\",\n            \"https://\",\n            \"http://\",\n        ]\n        assert order == list(s.adapters)\n        s2 = requests.Session()\n        s2.adapters = {\""}, {"start_line": 14000, "end_line": 15342, "belongs_to": {"file_name": "test_lowlevel.py", "upper_path": "/data2/raymone/swebench-repos/requests/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "/path/to/thing/#view=edit&token=hunter2'\n        r = requests.get(url)\n\n        assert r.status_code == 200\n        assert len(r.history) == 2\n        assert r.history[0].request.url == url\n\n        # Verify we haven't overwritten the location with our previous fragment.\n        assert r.history[1].request.url == f'http://{host}:{port}/get#relevant-section'\n        # Verify previous fragment is used and not the original.\n        assert r.url == f'http://{host}:{port}/final-url/#relevant-section'\n\n        close_server.set()\n\n\ndef test_json_decode_compatibility_for_alt_utf_encodings():\n\n    def response_handler(sock):\n        consume_socket_content(sock, timeout=0.5)\n        sock.send(\n            b'HTTP/1.1 200 OK\\r\\n'\n            b'Content-Length: 18\\r\\n\\r\\n'\n            b'\\xff\\xfe{\\x00\"\\x00K0\"\\x00=\\x00\"\\x00\\xab0\"\\x00\\r\\n'\n        )\n\n    close_server = threading.Event()\n    server = Server(response_handler, wait_to_close_event=close_server)\n\n    with server as (host, port):\n        url = f'http://{host}:{port}/'\n        r = requests.get(url)\n    r.encoding = None\n    with pytest.raises(requests.exceptions.JSONDecodeError) as excinfo:\n        r.json()\n    assert isinstance(excinfo.value, requests.exceptions.RequestException)\n    assert isinstance(excinfo.value, JSONDecodeError)\n    assert r.text not in str(excinfo.value)\n"}, {"start_line": 1000, "end_line": 3000, "belongs_to": {"file_name": "test_requests.py", "upper_path": "/data2/raymone/swebench-repos/requests/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "ions import Timeout, TooManyRedirects, UnrewindableBodyError\nfrom requests.hooks import default_hooks\nfrom requests.models import PreparedRequest, urlencode\nfrom requests.sessions import SessionRedirectMixin\nfrom requests.structures import CaseInsensitiveDict\n\nfrom . import SNIMissingWarning\nfrom .compat import StringIO\nfrom .testserver.server import TLSServer, consume_socket_content\nfrom .utils import override_environ\n\n# Requests to this URL should always fail with a connection timeout (nothing\n# listening on that port)\nTARPIT = \"http://10.255.255.1\"\n\n# This is to avoid waiting the timeout of using TARPIT\nINVALID_PROXY = \"http://localhost:1\"\n\ntry:\n    from ssl import SSLContext\n\n    del SSLContext\n    HAS_MODERN_SSL = True\nexcept ImportError:\n    HAS_MODERN_SSL = False\n\ntry:\n    requests.pyopenssl\n    HAS_PYOPENSSL = True\nexcept AttributeError:\n    HAS_PYOPENSSL = False\n\n\nclass TestRequests:\n    digest_auth_algo = (\"MD5\", \"SHA-256\", \"SHA-512\")\n\n    def test_entry_points(self):\n        requests.session\n        requests.session().get\n        requests.session().head\n        requests.get\n        requests.head\n        requests.put\n        requests.patch\n        requests.post\n        # Not really an entry point, but people rely on it.\n        from requests.packages.urllib3.poolmanager import PoolManager  # noqa:F401\n\n    @pytest.mark.parametrize(\n        \"exception, url\",\n        (\n            (MissingSchema, \"hiwpefhipowhefopw\"),\n            (InvalidSchema, \"localhost:3128\"),\n            (InvalidSchema, \"localhost.localdomain:3128/\"),\n            (InvalidSchema, \"10.122.1.1:3128/\"),\n            (InvalidURL, \"http://\"),\n            (InvalidURL, \"http://*example.com\"),\n            (InvalidURL, \"http://.example.com\"),\n        ),\n    )\n    def test_invalid_url(self, exception, url):\n        with pytest.raises(exception):\n            requests.get(url)\n\n    def test_basic_building(self):\n        req = requests.Request()\n        req.url = \"http://kennethreitz.org/\"\n        req"}, {"start_line": 0, "end_line": 2000, "belongs_to": {"file_name": "test_requests.py", "upper_path": "/data2/raymone/swebench-repos/requests/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "\"\"\"Tests for Requests.\"\"\"\n\nimport collections\nimport contextlib\nimport io\nimport json\nimport os\nimport pickle\nimport re\nimport tempfile\nimport threading\nimport warnings\nfrom unittest import mock\n\nimport pytest\nimport urllib3\nfrom urllib3.util import Timeout as Urllib3Timeout\n\nimport requests\nfrom requests.adapters import HTTPAdapter\nfrom requests.auth import HTTPDigestAuth, _basic_auth_str\nfrom requests.compat import (\n    JSONDecodeError,\n    Morsel,\n    MutableMapping,\n    builtin_str,\n    cookielib,\n    getproxies,\n    is_urllib3_1,\n    urlparse,\n)\nfrom requests.cookies import cookiejar_from_dict, morsel_to_cookie\nfrom requests.exceptions import (\n    ChunkedEncodingError,\n    ConnectionError,\n    ConnectTimeout,\n    ContentDecodingError,\n    InvalidHeader,\n    InvalidProxyURL,\n    InvalidSchema,\n    InvalidURL,\n    MissingSchema,\n    ProxyError,\n    ReadTimeout,\n    RequestException,\n    RetryError,\n)\nfrom requests.exceptions import SSLError as RequestsSSLError\nfrom requests.exceptions import Timeout, TooManyRedirects, UnrewindableBodyError\nfrom requests.hooks import default_hooks\nfrom requests.models import PreparedRequest, urlencode\nfrom requests.sessions import SessionRedirectMixin\nfrom requests.structures import CaseInsensitiveDict\n\nfrom . import SNIMissingWarning\nfrom .compat import StringIO\nfrom .testserver.server import TLSServer, consume_socket_content\nfrom .utils import override_environ\n\n# Requests to this URL should always fail with a connection timeout (nothing\n# listening on that port)\nTARPIT = \"http://10.255.255.1\"\n\n# This is to avoid waiting the timeout of using TARPIT\nINVALID_PROXY = \"http://localhost:1\"\n\ntry:\n    from ssl import SSLContext\n\n    del SSLContext\n    HAS_MODERN_SSL = True\nexcept ImportError:\n    HAS_MODERN_SSL = False\n\ntry:\n    requests.pyopenssl\n    HAS_PYOPENSSL = True\nexcept AttributeError:\n    HAS_PYOPENSSL = False\n\n\nclass TestRequests:\n    digest_auth_algo = (\"MD5\", \"SHA-256\", \"SHA-512\")\n\n    def test_entry_points(self):\n       "}, {"start_line": 74000, "end_line": 76000, "belongs_to": {"file_name": "test_requests.py", "upper_path": "/data2/raymone/swebench-repos/requests/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "name, password)\n        assert isinstance(s, builtin_str)\n        assert s == auth_str\n\n    def test_requests_history_is_saved(self, httpbin):\n        r = requests.get(httpbin(\"redirect/5\"))\n        total = r.history[-1].history\n        i = 0\n        for item in r.history:\n            assert item.history == total[0:i]\n            i += 1\n\n    def test_json_param_post_content_type_works(self, httpbin):\n        r = requests.post(httpbin(\"post\"), json={\"life\": 42})\n        assert r.status_code == 200\n        assert \"application/json\" in r.request.headers[\"Content-Type\"]\n        assert {\"life\": 42} == r.json()[\"json\"]\n\n    def test_json_param_post_should_not_override_data_param(self, httpbin):\n        r = requests.Request(\n            method=\"POST\",\n            url=httpbin(\"post\"),\n            data={\"stuff\": \"elixr\"},\n            json={\"music\": \"flute\"},\n        )\n        prep = r.prepare()\n        assert \"stuff=elixr\" == prep.body\n\n    def test_response_iter_lines(self, httpbin):\n        r = requests.get(httpbin(\"stream/4\"), stream=True)\n        assert r.status_code == 200\n\n        it = r.iter_lines()\n        next(it)\n        assert len(list(it)) == 3\n\n    def test_response_context_manager(self, httpbin):\n        with requests.get(httpbin(\"stream/4\"), stream=True) as response:\n            assert isinstance(response, requests.Response)\n\n        assert response.raw.closed\n\n    def test_unconsumed_session_response_closes_connection(self, httpbin):\n        s = requests.session()\n\n        with contextlib.closing(s.get(httpbin(\"stream/4\"), stream=True)) as response:\n            pass\n\n        assert response._content_consumed is False\n        assert response.raw.closed\n\n    @pytest.mark.xfail\n    def test_response_iter_lines_reentrant(self, httpbin):\n        \"\"\"Response.iter_lines() is not reentrant safe\"\"\"\n        r = requests.get(httpbin(\"stream/4\"), stream=True)\n        assert r.status_code == 200\n\n        next(r.iter_lines())\n        assert len(list(r.iter_lines())) == 3\n\n"}, {"start_line": 0, "end_line": 2000, "belongs_to": {"file_name": "conf.py", "upper_path": "/data2/raymone/swebench-repos/requests/docs", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "# -*- coding: utf-8 -*-\n#\n# Requests documentation build configuration file, created by\n# sphinx-quickstart on Fri Feb 19 00:05:47 2016.\n#\n# This file is execfile()d with the current directory set to its\n# containing dir.\n#\n# Note that not all possible configuration values are present in this\n# autogenerated file.\n#\n# All configuration values have a default; values that are commented out\n# serve to show the default.\n\nimport sys\nimport os\n\n# If extensions (or modules to document with autodoc) are in another directory,\n# add these directories to sys.path here. If the directory is relative to the\n# documentation root, use os.path.abspath to make it absolute, like shown here.\n# sys.path.insert(0, os.path.abspath('.'))\n\n# Insert Requests' path into the system.\nsys.path.insert(0, os.path.abspath(\"..\"))\nsys.path.insert(0, os.path.abspath(\"_themes\"))\n\nimport requests\n\n\n# -- General configuration ------------------------------------------------\n\n# If your documentation needs a minimal Sphinx version, state it here.\n# needs_sphinx = '1.0'\n\n# Add any Sphinx extension module names here, as strings. They can be\n# extensions coming with Sphinx (named 'sphinx.ext.*') or your custom\n# ones.\nextensions = [\n    \"sphinx.ext.autodoc\",\n    \"sphinx.ext.intersphinx\",\n    \"sphinx.ext.todo\",\n    \"sphinx.ext.viewcode\",\n]\n\n# Add any paths that contain templates here, relative to this directory.\ntemplates_path = [\"_templates\"]\n\n# The suffix(es) of source filenames.\n# You can specify multiple suffix as a list of string:\n# source_suffix = ['.rst', '.md']\nsource_suffix = \".rst\"\n\n# The encoding of source files.\n# source_encoding = 'utf-8-sig'\n\n# The master toctree document.\nmaster_doc = \"index\"\n\n# General information about the project.\nproject = u\"Requests\"\ncopyright = u'MMXVIX. A Kenneth Reitz Project'\nauthor = u\"Kenneth Reitz\"\n\n# The version info for the project you're documenting, acts as replacement for\n# |version| and |release|, also used in various other places throughout the\n# built documen"}], "retrieved_count": 10, "cost_time": 0.8122296333312988}
{"question": "How does Requests implement its extension API for custom authentication handlers?", "answer": null, "relative_code_list": null, "ground_truth": "Requests implements extension API for custom authentication through the AuthBase class in src/requests/auth.py: 1) AuthBase abstract class - Defines the interface that all authentication handlers must implement; 2) __call__() method - Custom auth handlers must implement __call__(self, r) method that modifies Request objects; 3) Header modification - Auth handlers add appropriate headers (Authorization, Proxy-Authorization) to requests; 4) Integration points - Auth handlers are applied during PreparedRequest.prepare_auth() in request preparation; 5) Session integration - Custom auth handlers can be set as session.auth or passed to individual requests; 6) Challenge handling - Custom handlers can implement handle_401() method for authentication challenge responses; 7) State management - Handlers can maintain state across requests (like HTTPDigestAuth's thread-local storage); 8) Hook integration - Auth handlers can register response hooks for automatic challenge handling; 9) Flexibility - Handlers can implement any authentication scheme (OAuth, JWT, custom protocols); 10) Documentation - AuthBase serves as both interface and documentation for implementing custom authentication.", "score": null, "retrieved_content": [{"start_line": 2000, "end_line": 4000, "belongs_to": {"file_name": "auth.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "sword))).strip()\n    )\n\n    return authstr\n\n\nclass AuthBase:\n    \"\"\"Base class that all auth implementations derive from\"\"\"\n\n    def __call__(self, r):\n        raise NotImplementedError(\"Auth hooks must be callable.\")\n\n\nclass HTTPBasicAuth(AuthBase):\n    \"\"\"Attaches HTTP Basic Authentication to the given Request object.\"\"\"\n\n    def __init__(self, username, password):\n        self.username = username\n        self.password = password\n\n    def __eq__(self, other):\n        return all(\n            [\n                self.username == getattr(other, \"username\", None),\n                self.password == getattr(other, \"password\", None),\n            ]\n        )\n\n    def __ne__(self, other):\n        return not self == other\n\n    def __call__(self, r):\n        r.headers[\"Authorization\"] = _basic_auth_str(self.username, self.password)\n        return r\n\n\nclass HTTPProxyAuth(HTTPBasicAuth):\n    \"\"\"Attaches HTTP Proxy Authentication to a given Request object.\"\"\"\n\n    def __call__(self, r):\n        r.headers[\"Proxy-Authorization\"] = _basic_auth_str(self.username, self.password)\n        return r\n\n\nclass HTTPDigestAuth(AuthBase):\n    \"\"\"Attaches HTTP Digest Authentication to the given Request object.\"\"\"\n\n    def __init__(self, username, password):\n        self.username = username\n        self.password = password\n        # Keep state in per-thread local storage\n        self._thread_local = threading.local()\n\n    def init_per_thread_state(self):\n        # Ensure state is initialized just once per-thread\n        if not hasattr(self._thread_local, \"init\"):\n            self._thread_local.init = True\n            self._thread_local.last_nonce = \"\"\n            self._thread_local.nonce_count = 0\n            self._thread_local.chal = {}\n            self._thread_local.pos = None\n            self._thread_local.num_401_calls = None\n\n    def build_digest_header(self, method, url):\n        \"\"\"\n        :rtype: str\n        \"\"\"\n\n        realm = self._thread_local.chal[\"realm\"]\n        nonce = self._threa"}, {"start_line": 0, "end_line": 2000, "belongs_to": {"file_name": "auth.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "\"\"\"\nrequests.auth\n~~~~~~~~~~~~~\n\nThis module contains the authentication handlers for Requests.\n\"\"\"\n\nimport hashlib\nimport os\nimport re\nimport threading\nimport time\nimport warnings\nfrom base64 import b64encode\n\nfrom ._internal_utils import to_native_string\nfrom .compat import basestring, str, urlparse\nfrom .cookies import extract_cookies_to_jar\nfrom .utils import parse_dict_header\n\nCONTENT_TYPE_FORM_URLENCODED = \"application/x-www-form-urlencoded\"\nCONTENT_TYPE_MULTI_PART = \"multipart/form-data\"\n\n\ndef _basic_auth_str(username, password):\n    \"\"\"Returns a Basic Auth string.\"\"\"\n\n    # \"I want us to put a big-ol' comment on top of it that\n    # says that this behaviour is dumb but we need to preserve\n    # it because people are relying on it.\"\n    #    - Lukasa\n    #\n    # These are here solely to maintain backwards compatibility\n    # for things like ints. This will be removed in 3.0.0.\n    if not isinstance(username, basestring):\n        warnings.warn(\n            \"Non-string usernames will no longer be supported in Requests \"\n            \"3.0.0. Please convert the object you've passed in ({!r}) to \"\n            \"a string or bytes object in the near future to avoid \"\n            \"problems.\".format(username),\n            category=DeprecationWarning,\n        )\n        username = str(username)\n\n    if not isinstance(password, basestring):\n        warnings.warn(\n            \"Non-string passwords will no longer be supported in Requests \"\n            \"3.0.0. Please convert the object you've passed in ({!r}) to \"\n            \"a string or bytes object in the near future to avoid \"\n            \"problems.\".format(type(password)),\n            category=DeprecationWarning,\n        )\n        password = str(password)\n    # -- End Removal --\n\n    if isinstance(username, str):\n        username = username.encode(\"latin1\")\n\n    if isinstance(password, str):\n        password = password.encode(\"latin1\")\n\n    authstr = \"Basic \" + to_native_string(\n        b64encode(b\":\".join((username, pas"}, {"start_line": 8000, "end_line": 10000, "belongs_to": {"file_name": "auth.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": " it was to resend the request.\n            r.request.body.seek(self._thread_local.pos)\n        s_auth = r.headers.get(\"www-authenticate\", \"\")\n\n        if \"digest\" in s_auth.lower() and self._thread_local.num_401_calls < 2:\n            self._thread_local.num_401_calls += 1\n            pat = re.compile(r\"digest \", flags=re.IGNORECASE)\n            self._thread_local.chal = parse_dict_header(pat.sub(\"\", s_auth, count=1))\n\n            # Consume content and release the original connection\n            # to allow our new request to reuse the same one.\n            r.content\n            r.close()\n            prep = r.request.copy()\n            extract_cookies_to_jar(prep._cookies, r.request, r.raw)\n            prep.prepare_cookies(prep._cookies)\n\n            prep.headers[\"Authorization\"] = self.build_digest_header(\n                prep.method, prep.url\n            )\n            _r = r.connection.send(prep, **kwargs)\n            _r.history.append(r)\n            _r.request = prep\n\n            return _r\n\n        self._thread_local.num_401_calls = 1\n        return r\n\n    def __call__(self, r):\n        # Initialize per-thread state, if needed\n        self.init_per_thread_state()\n        # If we have a saved nonce, skip the 401\n        if self._thread_local.last_nonce:\n            r.headers[\"Authorization\"] = self.build_digest_header(r.method, r.url)\n        try:\n            self._thread_local.pos = r.body.tell()\n        except AttributeError:\n            # In the case of HTTPDigestAuth being reused and the body of\n            # the previous request was a file-like object, pos has the\n            # file position of the previous body. Ensure it's set to\n            # None.\n            self._thread_local.pos = None\n        r.register_hook(\"response\", self.handle_401)\n        r.register_hook(\"response\", self.handle_redirect)\n        self._thread_local.num_401_calls = 1\n\n        return r\n\n    def __eq__(self, other):\n        return all(\n            [\n                self.username == ge"}, {"start_line": 9000, "end_line": 10186, "belongs_to": {"file_name": "auth.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "rn _r\n\n        self._thread_local.num_401_calls = 1\n        return r\n\n    def __call__(self, r):\n        # Initialize per-thread state, if needed\n        self.init_per_thread_state()\n        # If we have a saved nonce, skip the 401\n        if self._thread_local.last_nonce:\n            r.headers[\"Authorization\"] = self.build_digest_header(r.method, r.url)\n        try:\n            self._thread_local.pos = r.body.tell()\n        except AttributeError:\n            # In the case of HTTPDigestAuth being reused and the body of\n            # the previous request was a file-like object, pos has the\n            # file position of the previous body. Ensure it's set to\n            # None.\n            self._thread_local.pos = None\n        r.register_hook(\"response\", self.handle_401)\n        r.register_hook(\"response\", self.handle_redirect)\n        self._thread_local.num_401_calls = 1\n\n        return r\n\n    def __eq__(self, other):\n        return all(\n            [\n                self.username == getattr(other, \"username\", None),\n                self.password == getattr(other, \"password\", None),\n            ]\n        )\n\n    def __ne__(self, other):\n        return not self == other\n"}, {"start_line": 1000, "end_line": 3000, "belongs_to": {"file_name": "auth.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "ill no longer be supported in Requests \"\n            \"3.0.0. Please convert the object you've passed in ({!r}) to \"\n            \"a string or bytes object in the near future to avoid \"\n            \"problems.\".format(username),\n            category=DeprecationWarning,\n        )\n        username = str(username)\n\n    if not isinstance(password, basestring):\n        warnings.warn(\n            \"Non-string passwords will no longer be supported in Requests \"\n            \"3.0.0. Please convert the object you've passed in ({!r}) to \"\n            \"a string or bytes object in the near future to avoid \"\n            \"problems.\".format(type(password)),\n            category=DeprecationWarning,\n        )\n        password = str(password)\n    # -- End Removal --\n\n    if isinstance(username, str):\n        username = username.encode(\"latin1\")\n\n    if isinstance(password, str):\n        password = password.encode(\"latin1\")\n\n    authstr = \"Basic \" + to_native_string(\n        b64encode(b\":\".join((username, password))).strip()\n    )\n\n    return authstr\n\n\nclass AuthBase:\n    \"\"\"Base class that all auth implementations derive from\"\"\"\n\n    def __call__(self, r):\n        raise NotImplementedError(\"Auth hooks must be callable.\")\n\n\nclass HTTPBasicAuth(AuthBase):\n    \"\"\"Attaches HTTP Basic Authentication to the given Request object.\"\"\"\n\n    def __init__(self, username, password):\n        self.username = username\n        self.password = password\n\n    def __eq__(self, other):\n        return all(\n            [\n                self.username == getattr(other, \"username\", None),\n                self.password == getattr(other, \"password\", None),\n            ]\n        )\n\n    def __ne__(self, other):\n        return not self == other\n\n    def __call__(self, r):\n        r.headers[\"Authorization\"] = _basic_auth_str(self.username, self.password)\n        return r\n\n\nclass HTTPProxyAuth(HTTPBasicAuth):\n    \"\"\"Attaches HTTP Proxy Authentication to a given Request object.\"\"\"\n\n    def __call__(self, r):\n        r.hea"}, {"start_line": 25000, "end_line": 27000, "belongs_to": {"file_name": "test_requests.py", "upper_path": "/data2/raymone/swebench-repos/requests/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "get_netrc_auth_mock(url):\n                return auth\n\n            requests.sessions.get_netrc_auth = get_netrc_auth_mock\n\n            # Should use netrc and work.\n            r = requests.get(url)\n            assert r.status_code == 200\n\n            # Given auth should override and fail.\n            r = requests.get(url, auth=wrong_auth)\n            assert r.status_code == 401\n\n            s = requests.session()\n\n            # Should use netrc and work.\n            r = s.get(url)\n            assert r.status_code == 200\n\n            # Given auth should override and fail.\n            s.auth = wrong_auth\n            r = s.get(url)\n            assert r.status_code == 401\n        finally:\n            requests.sessions.get_netrc_auth = old_auth\n\n    def test_basicauth_with_netrc_leak(self, httpbin):\n        url1 = httpbin(\"basic-auth\", \"user\", \"pass\")\n        url = url1[len(\"http://\") :]\n        domain = url.split(\":\")[0]\n        url = f\"http://example.com:@{url}\"\n\n        netrc_file = \"\"\n        with tempfile.NamedTemporaryFile(mode=\"w\", delete=False) as fp:\n            fp.write(\"machine example.com\\n\")\n            fp.write(\"login wronguser\\n\")\n            fp.write(\"password wrongpass\\n\")\n            fp.write(f\"machine {domain}\\n\")\n            fp.write(\"login user\\n\")\n            fp.write(\"password pass\\n\")\n            fp.close()\n            netrc_file = fp.name\n\n        old_netrc = os.environ.get(\"NETRC\", \"\")\n        os.environ[\"NETRC\"] = netrc_file\n\n        try:\n            # Should use netrc\n            # Make sure that we don't use the example.com credentails\n            # for the request\n            r = requests.get(url)\n            assert r.status_code == 200\n        finally:\n            os.environ[\"NETRC\"] = old_netrc\n            os.unlink(netrc_file)\n\n    def test_DIGEST_HTTP_200_OK_GET(self, httpbin):\n        for authtype in self.digest_auth_algo:\n            auth = HTTPDigestAuth(\"user\", \"pass\")\n            url = httpbin(\"digest-auth\", \"auth\", \"user\", \"pass\", "}, {"start_line": 21000, "end_line": 23000, "belongs_to": {"file_name": "adapters.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "ters.HTTPAdapter>`.\n\n        This should not be called from user code, and is only exposed for use\n        when subclassing the\n        :class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.\n\n        :param request: The :class:`PreparedRequest <PreparedRequest>` to add headers to.\n        :param kwargs: The keyword arguments from the call to send().\n        \"\"\"\n        pass\n\n    def proxy_headers(self, proxy):\n        \"\"\"Returns a dictionary of the headers to add to any request sent\n        through a proxy. This works with urllib3 magic to ensure that they are\n        correctly sent to the proxy, rather than in a tunnelled request if\n        CONNECT is being used.\n\n        This should not be called from user code, and is only exposed for use\n        when subclassing the\n        :class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.\n\n        :param proxy: The url of the proxy being used for this request.\n        :rtype: dict\n        \"\"\"\n        headers = {}\n        username, password = get_auth_from_url(proxy)\n\n        if username:\n            headers[\"Proxy-Authorization\"] = _basic_auth_str(username, password)\n\n        return headers\n\n    def send(\n        self, request, stream=False, timeout=None, verify=True, cert=None, proxies=None\n    ):\n        \"\"\"Sends PreparedRequest object. Returns Response object.\n\n        :param request: The :class:`PreparedRequest <PreparedRequest>` being sent.\n        :param stream: (optional) Whether to stream the request content.\n        :param timeout: (optional) How long to wait for the server to send\n            data before giving up, as a float, or a :ref:`(connect timeout,\n            read timeout) <timeouts>` tuple.\n        :type timeout: float or tuple or urllib3 Timeout object\n        :param verify: (optional) Either a boolean, in which case it controls whether\n            we verify the server's TLS certificate, or a string, in which case it\n            must be a path to a CA bundle to use\n        :param cert: (optional) Any user"}, {"start_line": 0, "end_line": 2000, "belongs_to": {"file_name": "api.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "\"\"\"\nrequests.api\n~~~~~~~~~~~~\n\nThis module implements the Requests API.\n\n:copyright: (c) 2012 by Kenneth Reitz.\n:license: Apache2, see LICENSE for more details.\n\"\"\"\n\nfrom . import sessions\n\n\ndef request(method, url, **kwargs):\n    \"\"\"Constructs and sends a :class:`Request <Request>`.\n\n    :param method: method for the new :class:`Request` object: ``GET``, ``OPTIONS``, ``HEAD``, ``POST``, ``PUT``, ``PATCH``, or ``DELETE``.\n    :param url: URL for the new :class:`Request` object.\n    :param params: (optional) Dictionary, list of tuples or bytes to send\n        in the query string for the :class:`Request`.\n    :param data: (optional) Dictionary, list of tuples, bytes, or file-like\n        object to send in the body of the :class:`Request`.\n    :param json: (optional) A JSON serializable Python object to send in the body of the :class:`Request`.\n    :param headers: (optional) Dictionary of HTTP Headers to send with the :class:`Request`.\n    :param cookies: (optional) Dict or CookieJar object to send with the :class:`Request`.\n    :param files: (optional) Dictionary of ``'name': file-like-objects`` (or ``{'name': file-tuple}``) for multipart encoding upload.\n        ``file-tuple`` can be a 2-tuple ``('filename', fileobj)``, 3-tuple ``('filename', fileobj, 'content_type')``\n        or a 4-tuple ``('filename', fileobj, 'content_type', custom_headers)``, where ``'content_type'`` is a string\n        defining the content type of the given file and ``custom_headers`` a dict-like object containing additional headers\n        to add for the file.\n    :param auth: (optional) Auth tuple to enable Basic/Digest/Custom HTTP Auth.\n    :param timeout: (optional) How many seconds to wait for the server to send data\n        before giving up, as a float, or a :ref:`(connect timeout, read\n        timeout) <timeouts>` tuple.\n    :type timeout: float or tuple\n    :param allow_redirects: (optional) Boolean. Enable/disable GET/OPTIONS/POST/PUT/PATCH/DELETE/HEAD redirection. Defaults to ``True``"}, {"start_line": 9000, "end_line": 11000, "belongs_to": {"file_name": "test_lowlevel.py", "upper_path": "/data2/raymone/swebench-repos/requests/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "uth.HTTPDigestAuth('user', 'pass')\n\n    def digest_response_handler(sock):\n        # Respond to GET with a 200 containing www-authenticate header.\n        request_content = consume_socket_content(sock, timeout=0.5)\n        assert request_content.startswith(b\"GET / HTTP/1.1\")\n        sock.send(text_200_chal)\n\n        # Verify the client didn't respond with auth.\n        request_content = consume_socket_content(sock, timeout=0.5)\n        assert request_content == b''\n\n        return request_content\n\n    close_server = threading.Event()\n    server = Server(digest_response_handler, wait_to_close_event=close_server)\n\n    with server as (host, port):\n        url = f'http://{host}:{port}/'\n        r = requests.get(url, auth=auth)\n        # Verify server didn't receive auth from us.\n        assert r.status_code == 200\n        assert len(r.history) == 0\n        close_server.set()\n\n\n_schemes_by_var_prefix = [\n    ('http', ['http']),\n    ('https', ['https']),\n    ('all', ['http', 'https']),\n]\n\n_proxy_combos = []\nfor prefix, schemes in _schemes_by_var_prefix:\n    for scheme in schemes:\n        _proxy_combos.append((f\"{prefix}_proxy\", scheme))\n\n_proxy_combos += [(var.upper(), scheme) for var, scheme in _proxy_combos]\n\n\n@pytest.mark.parametrize(\"var,scheme\", _proxy_combos)\ndef test_use_proxy_from_environment(httpbin, var, scheme):\n    url = f\"{scheme}://httpbin.org\"\n    fake_proxy = Server()  # do nothing with the requests; just close the socket\n    with fake_proxy as (host, port):\n        proxy_url = f\"socks5://{host}:{port}\"\n        kwargs = {var: proxy_url}\n        with override_environ(**kwargs):\n            # fake proxy's lack of response will cause a ConnectionError\n            with pytest.raises(requests.exceptions.ConnectionError):\n                requests.get(url)\n\n        # the fake proxy received a request\n        assert len(fake_proxy.handler_results) == 1\n\n        # it had actual content (not checking for SOCKS protocol for now)\n        assert len(fake_proxy.handler_"}, {"start_line": 9000, "end_line": 11000, "belongs_to": {"file_name": "sessions.py", "upper_path": "/data2/raymone/swebench-repos/requests/src/requests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "   # A failed tell() sets `_body_position` to `object()`. This non-None\n            # value ensures `rewindable` will be True, allowing us to raise an\n            # UnrewindableBodyError, instead of hanging the connection.\n            rewindable = prepared_request._body_position is not None and (\n                \"Content-Length\" in headers or \"Transfer-Encoding\" in headers\n            )\n\n            # Attempt to rewind consumed file-like object.\n            if rewindable:\n                rewind_body(prepared_request)\n\n            # Override the original request.\n            req = prepared_request\n\n            if yield_requests:\n                yield req\n            else:\n                resp = self.send(\n                    req,\n                    stream=stream,\n                    timeout=timeout,\n                    verify=verify,\n                    cert=cert,\n                    proxies=proxies,\n                    allow_redirects=False,\n                    **adapter_kwargs,\n                )\n\n                extract_cookies_to_jar(self.cookies, prepared_request, resp.raw)\n\n                # extract redirect url, if any, for the next loop\n                url = self.get_redirect_target(resp)\n                yield resp\n\n    def rebuild_auth(self, prepared_request, response):\n        \"\"\"When being redirected we may want to strip authentication from the\n        request to avoid leaking credentials. This method intelligently removes\n        and reapplies authentication where possible to avoid credential loss.\n        \"\"\"\n        headers = prepared_request.headers\n        url = prepared_request.url\n\n        if \"Authorization\" in headers and self.should_strip_auth(\n            response.request.url, url\n        ):\n            # If we get redirected to a new host, we should strip out any\n            # authentication headers.\n            del headers[\"Authorization\"]\n\n        # .netrc might have more auth for us on our new host.\n        new_auth = get_netrc_auth(url) if s"}], "retrieved_count": 10, "cost_time": 0.795111894607544}
