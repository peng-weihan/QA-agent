{"question": "What is the semantic contract of the Transf class's transform and inverse_transform methods when it inherits from NoInvTransf and is used within sklearn's pipeline composition system?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"start_line": 13000, "end_line": 15000, "belongs_to": {"file_name": "metadata_routing_common.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "  record_metadata_not_default(\n            self, sample_weight=sample_weight, metadata=metadata\n        )\n        self.fitted_ = True\n        return self\n\n    def transform(self, X, sample_weight=\"default\", metadata=\"default\"):\n        record_metadata_not_default(\n            self, sample_weight=sample_weight, metadata=metadata\n        )\n        return X + 1\n\n    def fit_transform(self, X, y, sample_weight=\"default\", metadata=\"default\"):\n        # implementing ``fit_transform`` is necessary since\n        # ``TransformerMixin.fit_transform`` doesn't route any metadata to\n        # ``transform``, while here we want ``transform`` to receive\n        # ``sample_weight`` and ``metadata``.\n        record_metadata_not_default(\n            self, sample_weight=sample_weight, metadata=metadata\n        )\n        return self.fit(X, y, sample_weight=sample_weight, metadata=metadata).transform(\n            X, sample_weight=sample_weight, metadata=metadata\n        )\n\n    def inverse_transform(self, X, sample_weight=None, metadata=None):\n        record_metadata_not_default(\n            self, sample_weight=sample_weight, metadata=metadata\n        )\n        return X - 1\n\n\nclass ConsumingNoFitTransformTransformer(BaseEstimator):\n    \"\"\"A metadata consuming transformer that doesn't inherit from\n    TransformerMixin, and thus doesn't implement `fit_transform`. Note that\n    TransformerMixin's `fit_transform` doesn't route metadata to `transform`.\"\"\"\n\n    def __init__(self, registry=None):\n        self.registry = registry\n\n    def fit(self, X, y=None, sample_weight=None, metadata=None):\n        if self.registry is not None:\n            self.registry.append(self)\n\n        record_metadata(self, sample_weight=sample_weight, metadata=metadata)\n\n        return self\n\n    def transform(self, X, sample_weight=None, metadata=None):\n        record_metadata(self, sample_weight=sample_weight, metadata=metadata)\n        return X\n\n\nclass ConsumingScorer(_Scorer):\n    def __init__(self, registry=None):\n"}, {"start_line": 42000, "end_line": 44000, "belongs_to": {"file_name": "pipeline.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "of each transformer in the pipeline. The transformed\n        data are finally passed to the final estimator that calls\n        `transform` method. Only valid if the final estimator\n        implements `transform`.\n\n        This also works where final estimator is `None` in which case all prior\n        transformations are applied.\n\n        Parameters\n        ----------\n        X : iterable\n            Data to transform. Must fulfill input requirements of first step\n            of the pipeline.\n\n        **params : dict of str -> object\n            Parameters requested and accepted by steps. Each step must have\n            requested certain metadata for these parameters to be forwarded to\n            them.\n\n            .. versionadded:: 1.4\n                Only available if `enable_metadata_routing=True`. See\n                :ref:`Metadata Routing User Guide <metadata_routing>` for more\n                details.\n\n        Returns\n        -------\n        Xt : ndarray of shape (n_samples, n_transformed_features)\n            Transformed data.\n        \"\"\"\n        # TODO(1.8): Remove the context manager and use check_is_fitted(self)\n        with _raise_or_warn_if_not_fitted(self):\n            _raise_for_params(params, self, \"transform\")\n\n            # not branching here since params is only available if\n            # enable_metadata_routing=True\n            routed_params = process_routing(self, \"transform\", **params)\n            Xt = X\n            for _, name, transform in self._iter():\n                Xt = transform.transform(Xt, **routed_params[name].transform)\n            return Xt\n\n    def _can_inverse_transform(self):\n        return all(hasattr(t, \"inverse_transform\") for _, _, t in self._iter())\n\n    @available_if(_can_inverse_transform)\n    def inverse_transform(self, X, **params):\n        \"\"\"Apply `inverse_transform` for each step in a reverse order.\n\n        All estimators in the pipeline must support `inverse_transform`.\n\n        Parameters\n        ----------\n       "}, {"start_line": 102000, "end_line": 104000, "belongs_to": {"file_name": "_data.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/preprocessing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "   force_writeable=True if not in_fit else None,\n            ensure_all_finite=\"allow-nan\",\n        )\n        # we only accept positive sparse matrix when ignore_implicit_zeros is\n        # false and that we call fit or transform.\n        with np.errstate(invalid=\"ignore\"):  # hide NaN comparison warnings\n            if (\n                not accept_sparse_negative\n                and not self.ignore_implicit_zeros\n                and (sparse.issparse(X) and np.any(X.data < 0))\n            ):\n                raise ValueError(\n                    \"QuantileTransformer only accepts non-negative sparse matrices.\"\n                )\n\n        return X\n\n    def _transform(self, X, inverse=False):\n        \"\"\"Forward and inverse transform.\n\n        Parameters\n        ----------\n        X : ndarray of shape (n_samples, n_features)\n            The data used to scale along the features axis.\n\n        inverse : bool, default=False\n            If False, apply forward transform. If True, apply\n            inverse transform.\n\n        Returns\n        -------\n        X : ndarray of shape (n_samples, n_features)\n            Projected data.\n        \"\"\"\n        if sparse.issparse(X):\n            for feature_idx in range(X.shape[1]):\n                column_slice = slice(X.indptr[feature_idx], X.indptr[feature_idx + 1])\n                X.data[column_slice] = self._transform_col(\n                    X.data[column_slice], self.quantiles_[:, feature_idx], inverse\n                )\n        else:\n            for feature_idx in range(X.shape[1]):\n                X[:, feature_idx] = self._transform_col(\n                    X[:, feature_idx], self.quantiles_[:, feature_idx], inverse\n                )\n\n        return X\n\n    def transform(self, X):\n        \"\"\"Feature-wise transformation of the data.\n\n        Parameters\n        ----------\n        X : {array-like, sparse matrix} of shape (n_samples, n_features)\n            The data used to scale along the features axis. If a sparse\n            matrix i"}, {"start_line": 70000, "end_line": 72000, "belongs_to": {"file_name": "estimator_checks.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/utils", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "(category=FutureWarning)\ndef check_transformers_unfitted(name, transformer):\n    X, y = _regression_dataset()\n\n    transformer = clone(transformer)\n    with raises(\n        (AttributeError, ValueError),\n        err_msg=(\n            \"The unfitted \"\n            f\"transformer {name} does not raise an error when \"\n            \"transform is called. Perhaps use \"\n            \"check_is_fitted in transform.\"\n        ),\n    ):\n        transformer.transform(X)\n\n\n@ignore_warnings(category=FutureWarning)\ndef check_transformers_unfitted_stateless(name, transformer):\n    \"\"\"Check that using transform without prior fitting\n    doesn't raise a NotFittedError for stateless transformers.\n    \"\"\"\n    rng = np.random.RandomState(0)\n    X = rng.uniform(size=(20, 5))\n    X = _enforce_estimator_tags_X(transformer, X)\n\n    transformer = clone(transformer)\n    X_trans = transformer.transform(X)\n\n    assert X_trans.shape[0] == X.shape[0]\n\n\ndef _check_transformer(name, transformer_orig, X, y):\n    n_samples, n_features = np.asarray(X).shape\n    transformer = clone(transformer_orig)\n    set_random_state(transformer)\n\n    # fit\n\n    if name in CROSS_DECOMPOSITION:\n        y_ = np.c_[np.asarray(y), np.asarray(y)]\n        y_[::2, 1] *= 2\n        if isinstance(X, _NotAnArray):\n            y_ = _NotAnArray(y_)\n    else:\n        y_ = y\n\n    transformer.fit(X, y_)\n    # fit_transform method should work on non fitted estimator\n    transformer_clone = clone(transformer)\n    X_pred = transformer_clone.fit_transform(X, y=y_)\n\n    if isinstance(X_pred, tuple):\n        for x_pred in X_pred:\n            assert x_pred.shape[0] == n_samples\n    else:\n        # check for consistent n_samples\n        assert X_pred.shape[0] == n_samples\n\n    if hasattr(transformer, \"transform\"):\n        if name in CROSS_DECOMPOSITION:\n            X_pred2 = transformer.transform(X, y_)\n            X_pred3 = transformer.fit_transform(X, y=y_)\n        else:\n            X_pred2 = transformer.transform(X)\n            X_pred3 = trans"}, {"start_line": 43000, "end_line": 45000, "belongs_to": {"file_name": "pipeline.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "ansformed_features)\n            Transformed data.\n        \"\"\"\n        # TODO(1.8): Remove the context manager and use check_is_fitted(self)\n        with _raise_or_warn_if_not_fitted(self):\n            _raise_for_params(params, self, \"transform\")\n\n            # not branching here since params is only available if\n            # enable_metadata_routing=True\n            routed_params = process_routing(self, \"transform\", **params)\n            Xt = X\n            for _, name, transform in self._iter():\n                Xt = transform.transform(Xt, **routed_params[name].transform)\n            return Xt\n\n    def _can_inverse_transform(self):\n        return all(hasattr(t, \"inverse_transform\") for _, _, t in self._iter())\n\n    @available_if(_can_inverse_transform)\n    def inverse_transform(self, X, **params):\n        \"\"\"Apply `inverse_transform` for each step in a reverse order.\n\n        All estimators in the pipeline must support `inverse_transform`.\n\n        Parameters\n        ----------\n        X : array-like of shape (n_samples, n_transformed_features)\n            Data samples, where ``n_samples`` is the number of samples and\n            ``n_features`` is the number of features. Must fulfill\n            input requirements of last step of pipeline's\n            ``inverse_transform`` method.\n\n        **params : dict of str -> object\n            Parameters requested and accepted by steps. Each step must have\n            requested certain metadata for these parameters to be forwarded to\n            them.\n\n            .. versionadded:: 1.4\n                Only available if `enable_metadata_routing=True`. See\n                :ref:`Metadata Routing User Guide <metadata_routing>` for more\n                details.\n\n        Returns\n        -------\n        X_original : ndarray of shape (n_samples, n_features)\n            Inverse transformed data, that is, data in the original feature\n            space.\n        \"\"\"\n        # TODO(1.8): Remove the context manager and use check_is_fitted"}, {"start_line": 5000, "end_line": 7000, "belongs_to": {"file_name": "_function_transformer.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/preprocessing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "]])\n    >>> transformer.transform(X)\n    array([[0.       , 0.6931],\n           [1.0986, 1.3862]])\n    \"\"\"\n\n    _parameter_constraints: dict = {\n        \"func\": [callable, None],\n        \"inverse_func\": [callable, None],\n        \"validate\": [\"boolean\"],\n        \"accept_sparse\": [\"boolean\"],\n        \"check_inverse\": [\"boolean\"],\n        \"feature_names_out\": [callable, StrOptions({\"one-to-one\"}), None],\n        \"kw_args\": [dict, None],\n        \"inv_kw_args\": [dict, None],\n    }\n\n    def __init__(\n        self,\n        func=None,\n        inverse_func=None,\n        *,\n        validate=False,\n        accept_sparse=False,\n        check_inverse=True,\n        feature_names_out=None,\n        kw_args=None,\n        inv_kw_args=None,\n    ):\n        self.func = func\n        self.inverse_func = inverse_func\n        self.validate = validate\n        self.accept_sparse = accept_sparse\n        self.check_inverse = check_inverse\n        self.feature_names_out = feature_names_out\n        self.kw_args = kw_args\n        self.inv_kw_args = inv_kw_args\n\n    def _check_inverse_transform(self, X):\n        \"\"\"Check that func and inverse_func are the inverse.\"\"\"\n        idx_selected = slice(None, None, max(1, X.shape[0] // 100))\n        X_round_trip = self.inverse_transform(self.transform(X[idx_selected]))\n\n        if hasattr(X, \"dtype\"):\n            dtypes = [X.dtype]\n        elif hasattr(X, \"dtypes\"):\n            # Dataframes can have multiple dtypes\n            dtypes = X.dtypes\n\n        # Not all dtypes are numpy dtypes, they can be pandas dtypes as well\n        if not all(\n            isinstance(d, np.dtype) and np.issubdtype(d, np.number) for d in dtypes\n        ):\n            raise ValueError(\n                \"'check_inverse' is only supported when all the elements in `X` is\"\n                \" numerical.\"\n            )\n\n        if not _allclose_dense_sparse(X[idx_selected], X_round_trip):\n            warnings.warn(\n                (\n                    \"The provided functions are not st"}, {"start_line": 69000, "end_line": 71000, "belongs_to": {"file_name": "estimator_checks.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/utils", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "adonly_memmap=False):\n    X, y = make_blobs(\n        n_samples=30,\n        centers=[[0, 0, 0], [1, 1, 1]],\n        random_state=0,\n        n_features=2,\n        cluster_std=0.1,\n    )\n    X = StandardScaler().fit_transform(X)\n    X = _enforce_estimator_tags_X(transformer, X)\n\n    if readonly_memmap:\n        X, y = create_memmap_backed_data([X, y])\n\n    _check_transformer(name, transformer, X, y)\n\n\n@ignore_warnings(category=FutureWarning)\ndef check_transformer_data_not_an_array(name, transformer):\n    X, y = make_blobs(\n        n_samples=30,\n        centers=[[0, 0, 0], [1, 1, 1]],\n        random_state=0,\n        n_features=2,\n        cluster_std=0.1,\n    )\n    X = StandardScaler().fit_transform(X)\n    X = _enforce_estimator_tags_X(transformer, X)\n    this_X = _NotAnArray(X)\n    this_y = _NotAnArray(np.asarray(y))\n    _check_transformer(name, transformer, this_X, this_y)\n    # try the same with some list\n    _check_transformer(name, transformer, X.tolist(), y.tolist())\n\n\n@ignore_warnings(category=FutureWarning)\ndef check_transformers_unfitted(name, transformer):\n    X, y = _regression_dataset()\n\n    transformer = clone(transformer)\n    with raises(\n        (AttributeError, ValueError),\n        err_msg=(\n            \"The unfitted \"\n            f\"transformer {name} does not raise an error when \"\n            \"transform is called. Perhaps use \"\n            \"check_is_fitted in transform.\"\n        ),\n    ):\n        transformer.transform(X)\n\n\n@ignore_warnings(category=FutureWarning)\ndef check_transformers_unfitted_stateless(name, transformer):\n    \"\"\"Check that using transform without prior fitting\n    doesn't raise a NotFittedError for stateless transformers.\n    \"\"\"\n    rng = np.random.RandomState(0)\n    X = rng.uniform(size=(20, 5))\n    X = _enforce_estimator_tags_X(transformer, X)\n\n    transformer = clone(transformer)\n    X_trans = transformer.transform(X)\n\n    assert X_trans.shape[0] == X.shape[0]\n\n\ndef _check_transformer(name, transformer_orig, X, y):\n    n_samples, n_"}, {"start_line": 10000, "end_line": 12000, "belongs_to": {"file_name": "_function_transformer.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/preprocessing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "  isinstance(col, str) for col in out.columns\n                )\n                if same_feature_names_in_out or not_all_str_columns:\n                    adapter = _get_adapter_from_container(out)\n                    out = adapter.create_container(\n                        X_output=out,\n                        X_original=out,\n                        columns=feature_names_out,\n                        inplace=False,\n                    )\n                else:\n                    raise ValueError(\n                        \"The output generated by `func` have different column names \"\n                        \"than the ones provided by `get_feature_names_out`. \"\n                        f\"Got output with columns names: {list(out.columns)} and \"\n                        \"`get_feature_names_out` returned: \"\n                        f\"{list(self.get_feature_names_out())}. \"\n                        \"The column names can be overridden by setting \"\n                        \"`set_output(transform='pandas')` or \"\n                        \"`set_output(transform='polars')` such that the column names \"\n                        \"are set to the names provided by `get_feature_names_out`.\"\n                    )\n\n        if self.feature_names_out is None:\n            warn_msg = (\n                \"When `set_output` is configured to be '{0}', `func` should return \"\n                \"a {0} DataFrame to follow the `set_output` API  or `feature_names_out`\"\n                \" should be defined.\"\n            )\n            if output_config == \"pandas\" and not _is_pandas_df(out):\n                warnings.warn(warn_msg.format(\"pandas\"))\n            elif output_config == \"polars\" and not _is_polars_df(out):\n                warnings.warn(warn_msg.format(\"polars\"))\n\n        return out\n\n    def inverse_transform(self, X):\n        \"\"\"Transform X using the inverse function.\n\n        Parameters\n        ----------\n        X : {array-like, sparse-matrix} of shape (n_samples, n_features) \\\n                if `validate"}, {"start_line": 11000, "end_line": 13000, "belongs_to": {"file_name": "_function_transformer.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/preprocessing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": ")` or \"\n                        \"`set_output(transform='polars')` such that the column names \"\n                        \"are set to the names provided by `get_feature_names_out`.\"\n                    )\n\n        if self.feature_names_out is None:\n            warn_msg = (\n                \"When `set_output` is configured to be '{0}', `func` should return \"\n                \"a {0} DataFrame to follow the `set_output` API  or `feature_names_out`\"\n                \" should be defined.\"\n            )\n            if output_config == \"pandas\" and not _is_pandas_df(out):\n                warnings.warn(warn_msg.format(\"pandas\"))\n            elif output_config == \"polars\" and not _is_polars_df(out):\n                warnings.warn(warn_msg.format(\"polars\"))\n\n        return out\n\n    def inverse_transform(self, X):\n        \"\"\"Transform X using the inverse function.\n\n        Parameters\n        ----------\n        X : {array-like, sparse-matrix} of shape (n_samples, n_features) \\\n                if `validate=True` else any object that `inverse_func` can handle\n            Input array.\n\n        Returns\n        -------\n        X_original : array-like, shape (n_samples, n_features)\n            Transformed input.\n        \"\"\"\n        if self.validate:\n            X = check_array(X, accept_sparse=self.accept_sparse)\n        return self._transform(X, func=self.inverse_func, kw_args=self.inv_kw_args)\n\n    @available_if(lambda self: self.feature_names_out is not None)\n    def get_feature_names_out(self, input_features=None):\n        \"\"\"Get output feature names for transformation.\n\n        This method is only defined if `feature_names_out` is not None.\n\n        Parameters\n        ----------\n        input_features : array-like of str or None, default=None\n            Input feature names.\n\n            - If `input_features` is None, then `feature_names_in_` is\n              used as the input feature names. If `feature_names_in_` is not\n              defined, then names are generated:\n              `[x"}, {"start_line": 3000, "end_line": 5000, "belongs_to": {"file_name": "_target.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/compose", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": " `func` also needs to be provided. The inverse\n        function needs to return a 2-dimensional array.\n\n    check_inverse : bool, default=True\n        Whether to check that `transform` followed by `inverse_transform`\n        or `func` followed by `inverse_func` leads to the original targets.\n\n    Attributes\n    ----------\n    regressor_ : object\n        Fitted regressor.\n\n    transformer_ : object\n        Transformer used in :meth:`fit` and :meth:`predict`.\n\n    n_features_in_ : int\n        Number of features seen during :term:`fit`. Only defined if the\n        underlying regressor exposes such an attribute when fit.\n\n        .. versionadded:: 0.24\n\n    feature_names_in_ : ndarray of shape (`n_features_in_`,)\n        Names of features seen during :term:`fit`. Defined only when `X`\n        has feature names that are all strings.\n\n        .. versionadded:: 1.0\n\n    See Also\n    --------\n    sklearn.preprocessing.FunctionTransformer : Construct a transformer from an\n        arbitrary callable.\n\n    Notes\n    -----\n    Internally, the target `y` is always converted into a 2-dimensional array\n    to be used by scikit-learn transformers. At the time of prediction, the\n    output will be reshaped to a have the same number of dimensions as `y`.\n\n    Examples\n    --------\n    >>> import numpy as np\n    >>> from sklearn.linear_model import LinearRegression\n    >>> from sklearn.compose import TransformedTargetRegressor\n    >>> tt = TransformedTargetRegressor(regressor=LinearRegression(),\n    ...                                 func=np.log, inverse_func=np.exp)\n    >>> X = np.arange(4).reshape(-1, 1)\n    >>> y = np.exp(2 * X).ravel()\n    >>> tt.fit(X, y)\n    TransformedTargetRegressor(...)\n    >>> tt.score(X, y)\n    1.0\n    >>> tt.regressor_.coef_\n    array([2.])\n\n    For a more detailed example use case refer to\n    :ref:`sphx_glr_auto_examples_compose_plot_transformed_target.py`.\n    \"\"\"\n\n    _parameter_constraints: dict = {\n        \"regressor\": [HasMethods([\"fit\", \"predict\"]"}], "retrieved_count": 10, "cost_time": 1.026289463043213}
{"question": "What is the integration mechanism between the PositiveSpectrumWarning class and the _check_psd_eigenvalues function that propagates matrix conditioning issues through the scikit-learn validation pipeline, and what downstream dependencies rely on this warning mechanism to handle numerical instability in kernel matrices?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"start_line": 51000, "end_line": 53000, "belongs_to": {"file_name": "test_validation.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/utils/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": ", PositiveSpectrumWarning, \"\"),\n    \"insignificant neg float32\": (\n        np.array([1, -1e-6], dtype=np.float32),\n        np.array([1, 0], dtype=np.float32),\n        PositiveSpectrumWarning,\n        \"There are negative eigenvalues \\\\(1e\\\\-06 of the maximum positive\",\n    ),\n    \"insignificant neg float64\": (\n        np.array([1, -1e-10], dtype=np.float64),\n        np.array([1, 0], dtype=np.float64),\n        PositiveSpectrumWarning,\n        \"There are negative eigenvalues \\\\(1e\\\\-10 of the maximum positive\",\n    ),\n    \"insignificant pos\": (\n        (5, 4e-12),\n        np.array([5, 0]),\n        PositiveSpectrumWarning,\n        \"the largest eigenvalue is more than 1e\\\\+12 times the smallest\",\n    ),\n}\n\n\n@pytest.mark.parametrize(\n    \"lambdas, expected_lambdas, w_type, w_msg\",\n    list(_psd_cases_valid.values()),\n    ids=list(_psd_cases_valid.keys()),\n)\n@pytest.mark.parametrize(\"enable_warnings\", [True, False])\ndef test_check_psd_eigenvalues_valid(\n    lambdas, expected_lambdas, w_type, w_msg, enable_warnings\n):\n    # Test that ``_check_psd_eigenvalues`` returns the right output for valid\n    # input, possibly raising the right warning\n\n    if not enable_warnings:\n        w_type = None\n\n    if w_type is None:\n        with warnings.catch_warnings():\n            warnings.simplefilter(\"error\", PositiveSpectrumWarning)\n            lambdas_fixed = _check_psd_eigenvalues(\n                lambdas, enable_warnings=enable_warnings\n            )\n    else:\n        with pytest.warns(w_type, match=w_msg):\n            lambdas_fixed = _check_psd_eigenvalues(\n                lambdas, enable_warnings=enable_warnings\n            )\n\n    assert_allclose(expected_lambdas, lambdas_fixed)\n\n\n_psd_cases_invalid = {\n    \"significant_imag\": (\n        (5, 5j),\n        ValueError,\n        \"There are significant imaginary parts in eigenv\",\n    ),\n    \"all negative\": (\n        (-5, -1),\n        ValueError,\n        \"All eigenvalues are negative \\\\(maximum is -1\",\n    ),\n    \"significant neg\": (\n    "}, {"start_line": 71000, "end_line": 73000, "belongs_to": {"file_name": "validation.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/utils", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "e eigenvalue in double (simple) precision. If this check fails,\n      it raises a ``ValueError``. Otherwise all negative eigenvalues that may\n      remain are set to zero. This operation is traced with a\n      ``PositiveSpectrumWarning`` when ``enable_warnings=True``.\n\n    Finally, all the positive eigenvalues that are too small (with a value\n    smaller than the maximum eigenvalue multiplied by 1e-12 (2e-7)) are set to\n    zero. This operation is traced with a ``PositiveSpectrumWarning`` when\n    ``enable_warnings=True``.\n\n    Parameters\n    ----------\n    lambdas : array-like of shape (n_eigenvalues,)\n        Array of eigenvalues to check / fix.\n\n    enable_warnings : bool, default=False\n        When this is set to ``True``, a ``PositiveSpectrumWarning`` will be\n        raised when there are imaginary parts, negative eigenvalues, or\n        extremely small non-zero eigenvalues. Otherwise no warning will be\n        raised. In both cases, imaginary parts, negative eigenvalues, and\n        extremely small non-zero eigenvalues will be set to zero.\n\n    Returns\n    -------\n    lambdas_fixed : ndarray of shape (n_eigenvalues,)\n        A fixed validated copy of the array of eigenvalues.\n\n    Examples\n    --------\n    >>> from sklearn.utils.validation import _check_psd_eigenvalues\n    >>> _check_psd_eigenvalues([1, 2])      # nominal case\n    array([1, 2])\n    >>> _check_psd_eigenvalues([5, 5j])     # significant imag part\n    Traceback (most recent call last):\n        ...\n    ValueError: There are significant imaginary parts in eigenvalues (1\n        of the maximum real part). Either the matrix is not PSD, or there was\n        an issue while computing the eigendecomposition of the matrix.\n    >>> _check_psd_eigenvalues([5, 5e-5j])  # insignificant imag part\n    array([5., 0.])\n    >>> _check_psd_eigenvalues([-5, -1])    # all negative\n    Traceback (most recent call last):\n        ...\n    ValueError: All eigenvalues are negative (maximum is -1). Either the\n        matrix"}, {"start_line": 75000, "end_line": 77000, "belongs_to": {"file_name": "validation.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/utils", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "          \"of the maximum real part). Either the matrix is not\"\n                \" PSD, or there was an issue while computing the \"\n                \"eigendecomposition of the matrix. Only the real \"\n                \"parts will be kept.\" % (max_imag_abs / max_real_abs),\n                PositiveSpectrumWarning,\n            )\n\n    # Remove all imaginary parts (even if zero)\n    lambdas = np.real(lambdas)\n\n    # Check that there are no significant negative eigenvalues\n    max_eig = lambdas.max()\n    if max_eig < 0:\n        raise ValueError(\n            \"All eigenvalues are negative (maximum is %g). \"\n            \"Either the matrix is not PSD, or there was an \"\n            \"issue while computing the eigendecomposition of \"\n            \"the matrix.\" % max_eig\n        )\n\n    else:\n        min_eig = lambdas.min()\n        if (\n            min_eig < -significant_neg_ratio * max_eig\n            and min_eig < -significant_neg_value\n        ):\n            raise ValueError(\n                \"There are significant negative eigenvalues (%g\"\n                \" of the maximum positive). Either the matrix is \"\n                \"not PSD, or there was an issue while computing \"\n                \"the eigendecomposition of the matrix.\" % (-min_eig / max_eig)\n            )\n        elif min_eig < 0:\n            # Remove all negative values and warn about it\n            if enable_warnings:\n                warnings.warn(\n                    \"There are negative eigenvalues (%g of the \"\n                    \"maximum positive). Either the matrix is not \"\n                    \"PSD, or there was an issue while computing the\"\n                    \" eigendecomposition of the matrix. Negative \"\n                    \"eigenvalues will be replaced with 0.\" % (-min_eig / max_eig),\n                    PositiveSpectrumWarning,\n                )\n            lambdas[lambdas < 0] = 0\n\n    # Check for conditioning (small positive non-zeros)\n    too_small_lambdas = (0 < lambdas) & (lambdas < small_pos_ratio * max_eig)\n "}, {"start_line": 52000, "end_line": 54000, "belongs_to": {"file_name": "test_validation.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/utils/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "w_msg, enable_warnings\n):\n    # Test that ``_check_psd_eigenvalues`` returns the right output for valid\n    # input, possibly raising the right warning\n\n    if not enable_warnings:\n        w_type = None\n\n    if w_type is None:\n        with warnings.catch_warnings():\n            warnings.simplefilter(\"error\", PositiveSpectrumWarning)\n            lambdas_fixed = _check_psd_eigenvalues(\n                lambdas, enable_warnings=enable_warnings\n            )\n    else:\n        with pytest.warns(w_type, match=w_msg):\n            lambdas_fixed = _check_psd_eigenvalues(\n                lambdas, enable_warnings=enable_warnings\n            )\n\n    assert_allclose(expected_lambdas, lambdas_fixed)\n\n\n_psd_cases_invalid = {\n    \"significant_imag\": (\n        (5, 5j),\n        ValueError,\n        \"There are significant imaginary parts in eigenv\",\n    ),\n    \"all negative\": (\n        (-5, -1),\n        ValueError,\n        \"All eigenvalues are negative \\\\(maximum is -1\",\n    ),\n    \"significant neg\": (\n        (5, -1),\n        ValueError,\n        \"There are significant negative eigenvalues\",\n    ),\n    \"significant neg float32\": (\n        np.array([3e-4, -2e-6], dtype=np.float32),\n        ValueError,\n        \"There are significant negative eigenvalues\",\n    ),\n    \"significant neg float64\": (\n        np.array([1e-5, -2e-10], dtype=np.float64),\n        ValueError,\n        \"There are significant negative eigenvalues\",\n    ),\n}\n\n\n@pytest.mark.parametrize(\n    \"lambdas, err_type, err_msg\",\n    list(_psd_cases_invalid.values()),\n    ids=list(_psd_cases_invalid.keys()),\n)\ndef test_check_psd_eigenvalues_invalid(lambdas, err_type, err_msg):\n    # Test that ``_check_psd_eigenvalues`` raises the right error for invalid\n    # input\n\n    with pytest.raises(err_type, match=err_msg):\n        _check_psd_eigenvalues(lambdas)\n\n\ndef _check_sample_weight_common(xp):\n    # Common checks between numpy/array api tests\n    # for check_sample_weight\n    # check None input\n    sample_weight = _check_sample_weigh"}, {"start_line": 3000, "end_line": 5000, "belongs_to": {"file_name": "exceptions.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "ntifies the dimensionality of the target\n    projection space, is higher than the number of features, which quantifies\n    the dimensionality of the original source space, to imply that the\n    dimensionality of the problem will not be reduced.\n\n    .. versionchanged:: 0.18\n       Moved from sklearn.utils.\n    \"\"\"\n\n\nclass EfficiencyWarning(UserWarning):\n    \"\"\"Warning used to notify the user of inefficient computation.\n\n    This warning notifies the user that the efficiency may not be optimal due\n    to some reason which may be included as a part of the warning message.\n    This may be subclassed into a more specific Warning class.\n\n    .. versionadded:: 0.18\n    \"\"\"\n\n\nclass FitFailedWarning(RuntimeWarning):\n    \"\"\"Warning class used if there is an error while fitting the estimator.\n\n    This Warning is used in meta estimators GridSearchCV and RandomizedSearchCV\n    and the cross-validation helper function cross_val_score to warn when there\n    is an error while fitting the estimator.\n\n    .. versionchanged:: 0.18\n       Moved from sklearn.cross_validation.\n    \"\"\"\n\n\nclass SkipTestWarning(UserWarning):\n    \"\"\"Warning class used to notify the user of a test that was skipped.\n\n    For example, one of the estimator checks requires a pandas import.\n    If the pandas package cannot be imported, the test will be skipped rather\n    than register as a failure.\n    \"\"\"\n\n\nclass UndefinedMetricWarning(UserWarning):\n    \"\"\"Warning used when the metric is invalid\n\n    .. versionchanged:: 0.18\n       Moved from sklearn.base.\n    \"\"\"\n\n\nclass PositiveSpectrumWarning(UserWarning):\n    \"\"\"Warning raised when the eigenvalues of a PSD matrix have issues\n\n    This warning is typically raised by ``_check_psd_eigenvalues`` when the\n    eigenvalues of a positive semidefinite (PSD) matrix such as a gram matrix\n    (kernel) present significant negative eigenvalues, or bad conditioning i.e.\n    very small non-zero eigenvalues compared to the largest eigenvalue.\n\n    .. versionadded:: 0.22\n   "}, {"start_line": 76000, "end_line": 78000, "belongs_to": {"file_name": "validation.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/utils", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": " significant negative eigenvalues (%g\"\n                \" of the maximum positive). Either the matrix is \"\n                \"not PSD, or there was an issue while computing \"\n                \"the eigendecomposition of the matrix.\" % (-min_eig / max_eig)\n            )\n        elif min_eig < 0:\n            # Remove all negative values and warn about it\n            if enable_warnings:\n                warnings.warn(\n                    \"There are negative eigenvalues (%g of the \"\n                    \"maximum positive). Either the matrix is not \"\n                    \"PSD, or there was an issue while computing the\"\n                    \" eigendecomposition of the matrix. Negative \"\n                    \"eigenvalues will be replaced with 0.\" % (-min_eig / max_eig),\n                    PositiveSpectrumWarning,\n                )\n            lambdas[lambdas < 0] = 0\n\n    # Check for conditioning (small positive non-zeros)\n    too_small_lambdas = (0 < lambdas) & (lambdas < small_pos_ratio * max_eig)\n    if too_small_lambdas.any():\n        if enable_warnings:\n            warnings.warn(\n                \"Badly conditioned PSD matrix spectrum: the largest \"\n                \"eigenvalue is more than %g times the smallest. \"\n                \"Small eigenvalues will be replaced with 0.\"\n                \"\" % (1 / small_pos_ratio),\n                PositiveSpectrumWarning,\n            )\n        lambdas[too_small_lambdas] = 0\n\n    return lambdas\n\n\ndef _check_sample_weight(\n    sample_weight,\n    X,\n    *,\n    dtype=None,\n    force_float_dtype=True,\n    ensure_non_negative=False,\n    copy=False,\n):\n    \"\"\"Validate sample weights.\n\n    Note that passing sample_weight=None will output an array of ones.\n    Therefore, in some cases, you may want to protect the call with:\n    if sample_weight is not None:\n        sample_weight = _check_sample_weight(...)\n\n    Parameters\n    ----------\n    sample_weight : {ndarray, Number or None}, shape (n_samples,)\n        Input sample weights.\n\n    X : {ndarray, l"}, {"start_line": 4000, "end_line": 6000, "belongs_to": {"file_name": "exceptions.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "\n    .. versionchanged:: 0.18\n       Moved from sklearn.cross_validation.\n    \"\"\"\n\n\nclass SkipTestWarning(UserWarning):\n    \"\"\"Warning class used to notify the user of a test that was skipped.\n\n    For example, one of the estimator checks requires a pandas import.\n    If the pandas package cannot be imported, the test will be skipped rather\n    than register as a failure.\n    \"\"\"\n\n\nclass UndefinedMetricWarning(UserWarning):\n    \"\"\"Warning used when the metric is invalid\n\n    .. versionchanged:: 0.18\n       Moved from sklearn.base.\n    \"\"\"\n\n\nclass PositiveSpectrumWarning(UserWarning):\n    \"\"\"Warning raised when the eigenvalues of a PSD matrix have issues\n\n    This warning is typically raised by ``_check_psd_eigenvalues`` when the\n    eigenvalues of a positive semidefinite (PSD) matrix such as a gram matrix\n    (kernel) present significant negative eigenvalues, or bad conditioning i.e.\n    very small non-zero eigenvalues compared to the largest eigenvalue.\n\n    .. versionadded:: 0.22\n    \"\"\"\n\n\nclass InconsistentVersionWarning(UserWarning):\n    \"\"\"Warning raised when an estimator is unpickled with an inconsistent version.\n\n    Parameters\n    ----------\n    estimator_name : str\n        Estimator name.\n\n    current_sklearn_version : str\n        Current scikit-learn version.\n\n    original_sklearn_version : str\n        Original scikit-learn version.\n    \"\"\"\n\n    def __init__(\n        self, *, estimator_name, current_sklearn_version, original_sklearn_version\n    ):\n        self.estimator_name = estimator_name\n        self.current_sklearn_version = current_sklearn_version\n        self.original_sklearn_version = original_sklearn_version\n\n    def __str__(self):\n        return (\n            f\"Trying to unpickle estimator {self.estimator_name} from version\"\n            f\" {self.original_sklearn_version} when \"\n            f\"using version {self.current_sklearn_version}. This might lead to breaking\"\n            \" code or \"\n            \"invalid results. Use at your own risk. \"\n    "}, {"start_line": 70000, "end_line": 72000, "belongs_to": {"file_name": "validation.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/utils", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "umerical or\n    conditioning issues and returns a fixed validated version. This method\n    should typically be used if the PSD matrix is user-provided (e.g. a\n    Gram matrix) or computed using a user-provided dissimilarity metric\n    (e.g. kernel function), or if the decomposition process uses approximation\n    methods (randomized SVD, etc.).\n\n    It checks for three things:\n\n    - that there are no significant imaginary parts in eigenvalues (more than\n      1e-5 times the maximum real part). If this check fails, it raises a\n      ``ValueError``. Otherwise all non-significant imaginary parts that may\n      remain are set to zero. This operation is traced with a\n      ``PositiveSpectrumWarning`` when ``enable_warnings=True``.\n\n    - that eigenvalues are not all negative. If this check fails, it raises a\n      ``ValueError``\n\n    - that there are no significant negative eigenvalues with absolute value\n      more than 1e-10 (1e-6) and more than 1e-5 (5e-3) times the largest\n      positive eigenvalue in double (simple) precision. If this check fails,\n      it raises a ``ValueError``. Otherwise all negative eigenvalues that may\n      remain are set to zero. This operation is traced with a\n      ``PositiveSpectrumWarning`` when ``enable_warnings=True``.\n\n    Finally, all the positive eigenvalues that are too small (with a value\n    smaller than the maximum eigenvalue multiplied by 1e-12 (2e-7)) are set to\n    zero. This operation is traced with a ``PositiveSpectrumWarning`` when\n    ``enable_warnings=True``.\n\n    Parameters\n    ----------\n    lambdas : array-like of shape (n_eigenvalues,)\n        Array of eigenvalues to check / fix.\n\n    enable_warnings : bool, default=False\n        When this is set to ``True``, a ``PositiveSpectrumWarning`` will be\n        raised when there are imaginary parts, negative eigenvalues, or\n        extremely small non-zero eigenvalues. Otherwise no warning will be\n        raised. In both cases, imaginary parts, negative eigenvalues, and\n    "}, {"start_line": 69000, "end_line": 71000, "belongs_to": {"file_name": "validation.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/utils", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "    \"`include_boundaries`='left' without specifying explicitly `min_val` \"\n            \"is inconsistent.\"\n        )\n\n    comparison_operator = (\n        operator.lt if include_boundaries in (\"left\", \"both\") else operator.le\n    )\n    if min_val is not None and comparison_operator(x, min_val):\n        raise ValueError(\n            f\"{name} == {x}, must be\"\n            f\" {'>=' if include_boundaries in ('left', 'both') else '>'} {min_val}.\"\n        )\n\n    comparison_operator = (\n        operator.gt if include_boundaries in (\"right\", \"both\") else operator.ge\n    )\n    if max_val is not None and comparison_operator(x, max_val):\n        raise ValueError(\n            f\"{name} == {x}, must be\"\n            f\" {'<=' if include_boundaries in ('right', 'both') else '<'} {max_val}.\"\n        )\n\n    return x\n\n\ndef _check_psd_eigenvalues(lambdas, enable_warnings=False):\n    \"\"\"Check the eigenvalues of a positive semidefinite (PSD) matrix.\n\n    Checks the provided array of PSD matrix eigenvalues for numerical or\n    conditioning issues and returns a fixed validated version. This method\n    should typically be used if the PSD matrix is user-provided (e.g. a\n    Gram matrix) or computed using a user-provided dissimilarity metric\n    (e.g. kernel function), or if the decomposition process uses approximation\n    methods (randomized SVD, etc.).\n\n    It checks for three things:\n\n    - that there are no significant imaginary parts in eigenvalues (more than\n      1e-5 times the maximum real part). If this check fails, it raises a\n      ``ValueError``. Otherwise all non-significant imaginary parts that may\n      remain are set to zero. This operation is traced with a\n      ``PositiveSpectrumWarning`` when ``enable_warnings=True``.\n\n    - that eigenvalues are not all negative. If this check fails, it raises a\n      ``ValueError``\n\n    - that there are no significant negative eigenvalues with absolute value\n      more than 1e-10 (1e-6) and more than 1e-5 (5e-3) times the largest\n      positiv"}, {"start_line": 74000, "end_line": 76000, "belongs_to": {"file_name": "validation.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/utils", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "_imag_ratio = 1e-5\n    significant_neg_ratio = 1e-5 if is_double_precision else 5e-3\n    significant_neg_value = 1e-10 if is_double_precision else 1e-6\n    small_pos_ratio = 1e-12 if is_double_precision else 2e-7\n\n    # Check that there are no significant imaginary parts\n    if not np.isreal(lambdas).all():\n        max_imag_abs = np.abs(np.imag(lambdas)).max()\n        max_real_abs = np.abs(np.real(lambdas)).max()\n        if max_imag_abs > significant_imag_ratio * max_real_abs:\n            raise ValueError(\n                \"There are significant imaginary parts in eigenvalues (%g \"\n                \"of the maximum real part). Either the matrix is not PSD, or \"\n                \"there was an issue while computing the eigendecomposition \"\n                \"of the matrix.\" % (max_imag_abs / max_real_abs)\n            )\n\n        # warn about imaginary parts being removed\n        if enable_warnings:\n            warnings.warn(\n                \"There are imaginary parts in eigenvalues (%g \"\n                \"of the maximum real part). Either the matrix is not\"\n                \" PSD, or there was an issue while computing the \"\n                \"eigendecomposition of the matrix. Only the real \"\n                \"parts will be kept.\" % (max_imag_abs / max_real_abs),\n                PositiveSpectrumWarning,\n            )\n\n    # Remove all imaginary parts (even if zero)\n    lambdas = np.real(lambdas)\n\n    # Check that there are no significant negative eigenvalues\n    max_eig = lambdas.max()\n    if max_eig < 0:\n        raise ValueError(\n            \"All eigenvalues are negative (maximum is %g). \"\n            \"Either the matrix is not PSD, or there was an \"\n            \"issue while computing the eigendecomposition of \"\n            \"the matrix.\" % max_eig\n        )\n\n    else:\n        min_eig = lambdas.min()\n        if (\n            min_eig < -significant_neg_ratio * max_eig\n            and min_eig < -significant_neg_value\n        ):\n            raise ValueError(\n                \"There are"}], "retrieved_count": 10, "cost_time": 1.0529634952545166}
{"question": "What is the architectural responsibility of the _local_reachability_density() method within LocalOutlierFactor's computational pipeline, and how does its encapsulation enable the separation between training-time and inference-time density calculations?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"start_line": 18000, "end_line": 20000, "belongs_to": {"file_name": "_lof.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/neighbors", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "uery sample or samples to compute the Local Outlier Factor\n            w.r.t. the training samples.\n\n        Returns\n        -------\n        opposite_lof_scores : ndarray of shape (n_samples,)\n            The opposite of the Local Outlier Factor of each input samples.\n            The lower, the more abnormal.\n        \"\"\"\n        check_is_fitted(self)\n        X = check_array(X, accept_sparse=\"csr\")\n\n        distances_X, neighbors_indices_X = self.kneighbors(\n            X, n_neighbors=self.n_neighbors_\n        )\n\n        if X.dtype == np.float32:\n            distances_X = distances_X.astype(X.dtype, copy=False)\n\n        X_lrd = self._local_reachability_density(\n            distances_X,\n            neighbors_indices_X,\n        )\n\n        lrd_ratios_array = self._lrd[neighbors_indices_X] / X_lrd[:, np.newaxis]\n\n        # as bigger is better:\n        return -np.mean(lrd_ratios_array, axis=1)\n\n    def _local_reachability_density(self, distances_X, neighbors_indices):\n        \"\"\"The local reachability density (LRD)\n\n        The LRD of a sample is the inverse of the average reachability\n        distance of its k-nearest neighbors.\n\n        Parameters\n        ----------\n        distances_X : ndarray of shape (n_queries, self.n_neighbors)\n            Distances to the neighbors (in the training samples `self._fit_X`)\n            of each query point to compute the LRD.\n\n        neighbors_indices : ndarray of shape (n_queries, self.n_neighbors)\n            Neighbors indices (of each query point) among training samples\n            self._fit_X.\n\n        Returns\n        -------\n        local_reachability_density : ndarray of shape (n_queries,)\n            The local reachability density of each sample.\n        \"\"\"\n        dist_k = self._distances_fit_X_[neighbors_indices, self.n_neighbors_ - 1]\n        reach_dist_array = np.maximum(distances_X, dist_k)\n\n        # 1e-10 to avoid `nan' when nb of duplicates > n_neighbors_:\n        return 1.0 / (np.mean(reach_dist_array, axis=1) + 1e-"}, {"start_line": 19000, "end_line": 20004, "belongs_to": {"file_name": "_lof.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/neighbors", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "achability density (LRD)\n\n        The LRD of a sample is the inverse of the average reachability\n        distance of its k-nearest neighbors.\n\n        Parameters\n        ----------\n        distances_X : ndarray of shape (n_queries, self.n_neighbors)\n            Distances to the neighbors (in the training samples `self._fit_X`)\n            of each query point to compute the LRD.\n\n        neighbors_indices : ndarray of shape (n_queries, self.n_neighbors)\n            Neighbors indices (of each query point) among training samples\n            self._fit_X.\n\n        Returns\n        -------\n        local_reachability_density : ndarray of shape (n_queries,)\n            The local reachability density of each sample.\n        \"\"\"\n        dist_k = self._distances_fit_X_[neighbors_indices, self.n_neighbors_ - 1]\n        reach_dist_array = np.maximum(distances_X, dist_k)\n\n        # 1e-10 to avoid `nan' when nb of duplicates > n_neighbors_:\n        return 1.0 / (np.mean(reach_dist_array, axis=1) + 1e-10)\n"}, {"start_line": 17000, "end_line": 19000, "belongs_to": {"file_name": "_lof.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/neighbors", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "een data.\"\n            )\n            raise AttributeError(msg)\n        return True\n\n    @available_if(_check_novelty_score_samples)\n    def score_samples(self, X):\n        \"\"\"Opposite of the Local Outlier Factor of X.\n\n        It is the opposite as bigger is better, i.e. large values correspond\n        to inliers.\n\n        **Only available for novelty detection (when novelty is set to True).**\n        The argument X is supposed to contain *new data*: if X contains a\n        point from training, it considers the later in its own neighborhood.\n        Also, the samples in X are not considered in the neighborhood of any\n        point. Because of this, the scores obtained via ``score_samples`` may\n        differ from the standard LOF scores.\n        The standard LOF scores for the training data is available via the\n        ``negative_outlier_factor_`` attribute.\n\n        Parameters\n        ----------\n        X : {array-like, sparse matrix} of shape (n_samples, n_features)\n            The query sample or samples to compute the Local Outlier Factor\n            w.r.t. the training samples.\n\n        Returns\n        -------\n        opposite_lof_scores : ndarray of shape (n_samples,)\n            The opposite of the Local Outlier Factor of each input samples.\n            The lower, the more abnormal.\n        \"\"\"\n        check_is_fitted(self)\n        X = check_array(X, accept_sparse=\"csr\")\n\n        distances_X, neighbors_indices_X = self.kneighbors(\n            X, n_neighbors=self.n_neighbors_\n        )\n\n        if X.dtype == np.float32:\n            distances_X = distances_X.astype(X.dtype, copy=False)\n\n        X_lrd = self._local_reachability_density(\n            distances_X,\n            neighbors_indices_X,\n        )\n\n        lrd_ratios_array = self._lrd[neighbors_indices_X] / X_lrd[:, np.newaxis]\n\n        # as bigger is better:\n        return -np.mean(lrd_ratios_array, axis=1)\n\n    def _local_reachability_density(self, distances_X, neighbors_indices):\n        \"\"\"The local re"}, {"start_line": 7000, "end_line": 9000, "belongs_to": {"file_name": "_lof.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/neighbors", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "  .. [1] Breunig, M. M., Kriegel, H. P., Ng, R. T., & Sander, J. (2000, May).\n           LOF: identifying density-based local outliers. In ACM sigmod record.\n\n    Examples\n    --------\n    >>> import numpy as np\n    >>> from sklearn.neighbors import LocalOutlierFactor\n    >>> X = [[-1.1], [0.2], [101.1], [0.3]]\n    >>> clf = LocalOutlierFactor(n_neighbors=2)\n    >>> clf.fit_predict(X)\n    array([ 1,  1, -1,  1])\n    >>> clf.negative_outlier_factor_\n    array([ -0.9821,  -1.0370, -73.3697,  -0.9821])\n    \"\"\"\n\n    _parameter_constraints: dict = {\n        **NeighborsBase._parameter_constraints,\n        \"contamination\": [\n            StrOptions({\"auto\"}),\n            Interval(Real, 0, 0.5, closed=\"right\"),\n        ],\n        \"novelty\": [\"boolean\"],\n    }\n    _parameter_constraints.pop(\"radius\")\n\n    def __init__(\n        self,\n        n_neighbors=20,\n        *,\n        algorithm=\"auto\",\n        leaf_size=30,\n        metric=\"minkowski\",\n        p=2,\n        metric_params=None,\n        contamination=\"auto\",\n        novelty=False,\n        n_jobs=None,\n    ):\n        super().__init__(\n            n_neighbors=n_neighbors,\n            algorithm=algorithm,\n            leaf_size=leaf_size,\n            metric=metric,\n            p=p,\n            metric_params=metric_params,\n            n_jobs=n_jobs,\n        )\n        self.contamination = contamination\n        self.novelty = novelty\n\n    def _check_novelty_fit_predict(self):\n        if self.novelty:\n            msg = (\n                \"fit_predict is not available when novelty=True. Use \"\n                \"novelty=False if you want to predict on the training set.\"\n            )\n            raise AttributeError(msg)\n        return True\n\n    @available_if(_check_novelty_fit_predict)\n    def fit_predict(self, X, y=None):\n        \"\"\"Fit the model to the training set X and return the labels.\n\n        **Not available for novelty detection (when novelty is set to True).**\n        Label is 1 for an inlier and -1 for an outlier according "}, {"start_line": 8000, "end_line": 10000, "belongs_to": {"file_name": "_lof.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/neighbors", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "mination=\"auto\",\n        novelty=False,\n        n_jobs=None,\n    ):\n        super().__init__(\n            n_neighbors=n_neighbors,\n            algorithm=algorithm,\n            leaf_size=leaf_size,\n            metric=metric,\n            p=p,\n            metric_params=metric_params,\n            n_jobs=n_jobs,\n        )\n        self.contamination = contamination\n        self.novelty = novelty\n\n    def _check_novelty_fit_predict(self):\n        if self.novelty:\n            msg = (\n                \"fit_predict is not available when novelty=True. Use \"\n                \"novelty=False if you want to predict on the training set.\"\n            )\n            raise AttributeError(msg)\n        return True\n\n    @available_if(_check_novelty_fit_predict)\n    def fit_predict(self, X, y=None):\n        \"\"\"Fit the model to the training set X and return the labels.\n\n        **Not available for novelty detection (when novelty is set to True).**\n        Label is 1 for an inlier and -1 for an outlier according to the LOF\n        score and the contamination parameter.\n\n        Parameters\n        ----------\n        X : {array-like, sparse matrix} of shape (n_samples, n_features), default=None\n            The query sample or samples to compute the Local Outlier Factor\n            w.r.t. the training samples.\n\n        y : Ignored\n            Not used, present for API consistency by convention.\n\n        Returns\n        -------\n        is_inlier : ndarray of shape (n_samples,)\n            Returns -1 for anomalies/outliers and 1 for inliers.\n        \"\"\"\n\n        # As fit_predict would be different from fit.predict, fit_predict is\n        # only available for outlier detection (novelty=False)\n\n        return self.fit(X)._predict()\n\n    @_fit_context(\n        # LocalOutlierFactor.metric is not validated yet\n        prefer_skip_nested_validation=False\n    )\n    def fit(self, X, y=None):\n        \"\"\"Fit the local outlier factor detector from the training dataset.\n\n        Parameters\n        ----------\n "}, {"start_line": 3000, "end_line": 5000, "belongs_to": {"file_name": "_lof.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/neighbors", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "only \"nonzero\" elements may be considered neighbors.\n\n        If metric is a callable function, it takes two arrays representing 1D\n        vectors as inputs and must return one value indicating the distance\n        between those vectors. This works for Scipy's metrics, but is less\n        efficient than passing the metric name as a string.\n\n    p : float, default=2\n        Parameter for the Minkowski metric from\n        :func:`sklearn.metrics.pairwise_distances`. When p = 1, this\n        is equivalent to using manhattan_distance (l1), and euclidean_distance\n        (l2) for p = 2. For arbitrary p, minkowski_distance (l_p) is used.\n\n    metric_params : dict, default=None\n        Additional keyword arguments for the metric function.\n\n    contamination : 'auto' or float, default='auto'\n        The amount of contamination of the data set, i.e. the proportion\n        of outliers in the data set. When fitting this is used to define the\n        threshold on the scores of the samples.\n\n        - if 'auto', the threshold is determined as in the\n          original paper,\n        - if a float, the contamination should be in the range (0, 0.5].\n\n        .. versionchanged:: 0.22\n           The default value of ``contamination`` changed from 0.1\n           to ``'auto'``.\n\n    novelty : bool, default=False\n        By default, LocalOutlierFactor is only meant to be used for outlier\n        detection (novelty=False). Set novelty to True if you want to use\n        LocalOutlierFactor for novelty detection. In this case be aware that\n        you should only use predict, decision_function and score_samples\n        on new unseen data and not on the training set; and note that the\n        results obtained this way may differ from the standard LOF results.\n\n        .. versionadded:: 0.20\n\n    n_jobs : int, default=None\n        The number of parallel jobs to run for neighbors search.\n        ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n        ``-1`` means using all"}, {"start_line": 9000, "end_line": 11000, "belongs_to": {"file_name": "_lof.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/neighbors", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "to the LOF\n        score and the contamination parameter.\n\n        Parameters\n        ----------\n        X : {array-like, sparse matrix} of shape (n_samples, n_features), default=None\n            The query sample or samples to compute the Local Outlier Factor\n            w.r.t. the training samples.\n\n        y : Ignored\n            Not used, present for API consistency by convention.\n\n        Returns\n        -------\n        is_inlier : ndarray of shape (n_samples,)\n            Returns -1 for anomalies/outliers and 1 for inliers.\n        \"\"\"\n\n        # As fit_predict would be different from fit.predict, fit_predict is\n        # only available for outlier detection (novelty=False)\n\n        return self.fit(X)._predict()\n\n    @_fit_context(\n        # LocalOutlierFactor.metric is not validated yet\n        prefer_skip_nested_validation=False\n    )\n    def fit(self, X, y=None):\n        \"\"\"Fit the local outlier factor detector from the training dataset.\n\n        Parameters\n        ----------\n        X : {array-like, sparse matrix} of shape (n_samples, n_features) or \\\n                (n_samples, n_samples) if metric='precomputed'\n            Training data.\n\n        y : Ignored\n            Not used, present for API consistency by convention.\n\n        Returns\n        -------\n        self : LocalOutlierFactor\n            The fitted local outlier factor detector.\n        \"\"\"\n        self._fit(X)\n\n        n_samples = self.n_samples_fit_\n        if self.n_neighbors > n_samples:\n            warnings.warn(\n                \"n_neighbors (%s) is greater than the \"\n                \"total number of samples (%s). n_neighbors \"\n                \"will be set to (n_samples - 1) for estimation.\"\n                % (self.n_neighbors, n_samples)\n            )\n        self.n_neighbors_ = max(1, min(self.n_neighbors, n_samples - 1))\n\n        self._distances_fit_X_, _neighbors_indices_fit_X_ = self.kneighbors(\n            n_neighbors=self.n_neighbors_\n        )\n\n        if self._fit_X.dtype == np.f"}, {"start_line": 0, "end_line": 2000, "belongs_to": {"file_name": "_lof.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/neighbors", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "# Authors: The scikit-learn developers\n# SPDX-License-Identifier: BSD-3-Clause\n\nimport warnings\nfrom numbers import Real\n\nimport numpy as np\n\nfrom sklearn.base import OutlierMixin, _fit_context\nfrom sklearn.neighbors._base import KNeighborsMixin, NeighborsBase\nfrom sklearn.utils import check_array\nfrom sklearn.utils._param_validation import Interval, StrOptions\nfrom sklearn.utils.metaestimators import available_if\nfrom sklearn.utils.validation import check_is_fitted\n\n__all__ = [\"LocalOutlierFactor\"]\n\n\nclass LocalOutlierFactor(KNeighborsMixin, OutlierMixin, NeighborsBase):\n    \"\"\"Unsupervised Outlier Detection using the Local Outlier Factor (LOF).\n\n    The anomaly score of each sample is called the Local Outlier Factor.\n    It measures the local deviation of the density of a given sample with respect\n    to its neighbors.\n    It is local in that the anomaly score depends on how isolated the object\n    is with respect to the surrounding neighborhood.\n    More precisely, locality is given by k-nearest neighbors, whose distance\n    is used to estimate the local density.\n    By comparing the local density of a sample to the local densities of its\n    neighbors, one can identify samples that have a substantially lower density\n    than their neighbors. These are considered outliers.\n\n    .. versionadded:: 0.19\n\n    Parameters\n    ----------\n    n_neighbors : int, default=20\n        Number of neighbors to use by default for :meth:`kneighbors` queries.\n        If n_neighbors is larger than the number of samples provided,\n        all samples will be used.\n\n    algorithm : {'auto', 'ball_tree', 'kd_tree', 'brute'}, default='auto'\n        Algorithm used to compute the nearest neighbors:\n\n        - 'ball_tree' will use :class:`BallTree`\n        - 'kd_tree' will use :class:`KDTree`\n        - 'brute' will use a brute-force search.\n        - 'auto' will attempt to decide the most appropriate algorithm\n          based on the values passed to :meth:`fit` method.\n\n        Note: fittin"}, {"start_line": 6000, "end_line": 8000, "belongs_to": {"file_name": "_lof.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/neighbors", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "pt when a\n        contamination parameter different than \"auto\" is provided. In that\n        case, the offset is defined in such a way we obtain the expected\n        number of outliers in training.\n\n        .. versionadded:: 0.20\n\n    effective_metric_ : str\n        The effective metric used for the distance computation.\n\n    effective_metric_params_ : dict\n        The effective additional keyword arguments for the metric function.\n\n    n_features_in_ : int\n        Number of features seen during :term:`fit`.\n\n        .. versionadded:: 0.24\n\n    feature_names_in_ : ndarray of shape (`n_features_in_`,)\n        Names of features seen during :term:`fit`. Defined only when `X`\n        has feature names that are all strings.\n\n        .. versionadded:: 1.0\n\n    n_samples_fit_ : int\n        It is the number of samples in the fitted data.\n\n    See Also\n    --------\n    sklearn.svm.OneClassSVM: Unsupervised Outlier Detection using\n        Support Vector Machine.\n\n    References\n    ----------\n    .. [1] Breunig, M. M., Kriegel, H. P., Ng, R. T., & Sander, J. (2000, May).\n           LOF: identifying density-based local outliers. In ACM sigmod record.\n\n    Examples\n    --------\n    >>> import numpy as np\n    >>> from sklearn.neighbors import LocalOutlierFactor\n    >>> X = [[-1.1], [0.2], [101.1], [0.3]]\n    >>> clf = LocalOutlierFactor(n_neighbors=2)\n    >>> clf.fit_predict(X)\n    array([ 1,  1, -1,  1])\n    >>> clf.negative_outlier_factor_\n    array([ -0.9821,  -1.0370, -73.3697,  -0.9821])\n    \"\"\"\n\n    _parameter_constraints: dict = {\n        **NeighborsBase._parameter_constraints,\n        \"contamination\": [\n            StrOptions({\"auto\"}),\n            Interval(Real, 0, 0.5, closed=\"right\"),\n        ],\n        \"novelty\": [\"boolean\"],\n    }\n    _parameter_constraints.pop(\"radius\")\n\n    def __init__(\n        self,\n        n_neighbors=20,\n        *,\n        algorithm=\"auto\",\n        leaf_size=30,\n        metric=\"minkowski\",\n        p=2,\n        metric_params=None,\n        conta"}, {"start_line": 4000, "end_line": 6000, "belongs_to": {"file_name": "_lof.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/neighbors", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "  - if 'auto', the threshold is determined as in the\n          original paper,\n        - if a float, the contamination should be in the range (0, 0.5].\n\n        .. versionchanged:: 0.22\n           The default value of ``contamination`` changed from 0.1\n           to ``'auto'``.\n\n    novelty : bool, default=False\n        By default, LocalOutlierFactor is only meant to be used for outlier\n        detection (novelty=False). Set novelty to True if you want to use\n        LocalOutlierFactor for novelty detection. In this case be aware that\n        you should only use predict, decision_function and score_samples\n        on new unseen data and not on the training set; and note that the\n        results obtained this way may differ from the standard LOF results.\n\n        .. versionadded:: 0.20\n\n    n_jobs : int, default=None\n        The number of parallel jobs to run for neighbors search.\n        ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n        ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n        for more details.\n\n    Attributes\n    ----------\n    negative_outlier_factor_ : ndarray of shape (n_samples,)\n        The opposite LOF of the training samples. The higher, the more normal.\n        Inliers tend to have a LOF score close to 1\n        (``negative_outlier_factor_`` close to -1), while outliers tend to have\n        a larger LOF score.\n\n        The local outlier factor (LOF) of a sample captures its\n        supposed 'degree of abnormality'.\n        It is the average of the ratio of the local reachability density of\n        a sample and those of its k-nearest neighbors.\n\n    n_neighbors_ : int\n        The actual number of neighbors used for :meth:`kneighbors` queries.\n\n    offset_ : float\n        Offset used to obtain binary labels from the raw scores.\n        Observations having a negative_outlier_factor smaller than `offset_`\n        are detected as abnormal.\n        The offset is set to -1.5 (inliers score around -1), exce"}], "retrieved_count": 10, "cost_time": 1.068674087524414}
{"question": "What is the layered validation architecture implemented by the test_docstring_parameters function that separates concerns between module discovery, class inspection, method validation, and error aggregation?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"start_line": 5000, "end_line": 6853, "belongs_to": {"file_name": "test_docstrings.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": " = numpydoc_validation.validate(function_name)\n\n    res[\"errors\"] = list(filter_errors(res[\"errors\"], method=\"function\"))\n\n    if res[\"errors\"]:\n        msg = repr_errors(res, method=f\"Tested function: {function_name}\")\n\n        raise ValueError(msg)\n\n\n@pytest.mark.parametrize(\"Klass, method\", get_all_methods())\ndef test_docstring(Klass, method, request):\n    base_import_path = Klass.__module__\n    import_path = [base_import_path, Klass.__name__]\n    if method is not None:\n        import_path.append(method)\n\n    import_path = \".\".join(import_path)\n\n    res = numpydoc_validation.validate(import_path)\n\n    res[\"errors\"] = list(filter_errors(res[\"errors\"], method, Klass=Klass))\n\n    if res[\"errors\"]:\n        msg = repr_errors(res, Klass, method)\n\n        raise ValueError(msg)\n\n\nif __name__ == \"__main__\":\n    import argparse\n    import sys\n\n    parser = argparse.ArgumentParser(description=\"Validate docstring with numpydoc.\")\n    parser.add_argument(\"import_path\", help=\"Import path to validate\")\n\n    args = parser.parse_args()\n\n    res = numpydoc_validation.validate(args.import_path)\n\n    import_path_sections = args.import_path.split(\".\")\n    # When applied to classes, detect class method. For functions\n    # method = None.\n    # TODO: this detection can be improved. Currently we assume that we have\n    # class # methods if the second path element before last is in camel case.\n    if len(import_path_sections) >= 2 and re.match(\n        r\"(?:[A-Z][a-z]*)+\", import_path_sections[-2]\n    ):\n        method = import_path_sections[-1]\n    else:\n        method = None\n\n    res[\"errors\"] = list(filter_errors(res[\"errors\"], method))\n\n    if res[\"errors\"]:\n        msg = repr_errors(res, method=args.import_path)\n\n        print(msg)\n        sys.exit(1)\n    else:\n        print(\"All docstring checks passed for {}!\".format(args.import_path))\n"}, {"start_line": 3000, "end_line": 5000, "belongs_to": {"file_name": "test_docstring_parameters.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "r cname.startswith(\"_\"):\n                continue\n            if inspect.isabstract(cls):\n                continue\n            with warnings.catch_warnings(record=True) as w:\n                cdoc = docscrape.ClassDoc(cls)\n            if len(w):\n                raise RuntimeError(\n                    \"Error for __init__ of %s in %s:\\n%s\" % (cls, name, w[0])\n                )\n\n            # Skip checks on deprecated classes\n            if _is_deprecated(cls.__new__):\n                continue\n\n            this_incorrect += check_docstring_parameters(cls.__init__, cdoc)\n\n            for method_name in cdoc.methods:\n                method = getattr(cls, method_name)\n                if _is_deprecated(method):\n                    continue\n                param_ignore = None\n                # Now skip docstring test for y when y is None\n                # by default for API reason\n                if method_name in _METHODS_IGNORE_NONE_Y:\n                    sig = signature(method)\n                    if \"y\" in sig.parameters and sig.parameters[\"y\"].default is None:\n                        param_ignore = [\"y\"]  # ignore y for fit and score\n                result = check_docstring_parameters(method, ignore=param_ignore)\n                this_incorrect += result\n\n            incorrect += this_incorrect\n\n        functions = inspect.getmembers(module, inspect.isfunction)\n        # Exclude imported functions\n        functions = [fn for fn in functions if fn[1].__module__ == name]\n        for fname, func in functions:\n            # Don't test private methods / functions\n            if fname.startswith(\"_\"):\n                continue\n            if fname == \"configuration\" and name.endswith(\"setup\"):\n                continue\n            name_ = _get_func_name(func)\n            if not any(d in name_ for d in _DOCSTRING_IGNORES) and not _is_deprecated(\n                func\n            ):\n                incorrect += check_docstring_parameters(func)\n\n    msg = \"\\n\".join(incorrect)\n    if"}, {"start_line": 4000, "end_line": 6000, "belongs_to": {"file_name": "test_docstrings.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "or\n\n    if Klass is not None:\n        obj = getattr(Klass, method)\n        try:\n            obj_signature = str(signature(obj))\n        except TypeError:\n            # In particular we can't parse the signature of properties\n            obj_signature = (\n                \"\\nParsing of the method signature failed, \"\n                \"possibly because this is a property.\"\n            )\n\n        obj_name = Klass.__name__ + \".\" + method\n    else:\n        obj_signature = \"\"\n        obj_name = method\n\n    msg = \"\\n\\n\" + \"\\n\\n\".join(\n        [\n            str(res[\"file\"]),\n            obj_name + obj_signature,\n            res[\"docstring\"],\n            \"# Errors\",\n            \"\\n\".join(\n                \" - {}: {}\".format(code, message) for code, message in res[\"errors\"]\n            ),\n        ]\n    )\n    return msg\n\n\n@pytest.mark.parametrize(\"function_name\", get_all_functions_names())\ndef test_function_docstring(function_name, request):\n    \"\"\"Check function docstrings using numpydoc.\"\"\"\n    res = numpydoc_validation.validate(function_name)\n\n    res[\"errors\"] = list(filter_errors(res[\"errors\"], method=\"function\"))\n\n    if res[\"errors\"]:\n        msg = repr_errors(res, method=f\"Tested function: {function_name}\")\n\n        raise ValueError(msg)\n\n\n@pytest.mark.parametrize(\"Klass, method\", get_all_methods())\ndef test_docstring(Klass, method, request):\n    base_import_path = Klass.__module__\n    import_path = [base_import_path, Klass.__name__]\n    if method is not None:\n        import_path.append(method)\n\n    import_path = \".\".join(import_path)\n\n    res = numpydoc_validation.validate(import_path)\n\n    res[\"errors\"] = list(filter_errors(res[\"errors\"], method, Klass=Klass))\n\n    if res[\"errors\"]:\n        msg = repr_errors(res, Klass, method)\n\n        raise ValueError(msg)\n\n\nif __name__ == \"__main__\":\n    import argparse\n    import sys\n\n    parser = argparse.ArgumentParser(description=\"Validate docstring with numpydoc.\")\n    parser.add_argument(\"import_path\", help=\"Import path to valid"}, {"start_line": 12000, "end_line": 14000, "belongs_to": {"file_name": "test_testing.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/utils/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "       \"+ ['a']\",\n        ],\n        [\n            \"In function: sklearn.utils.tests.test_testing.Klass.f_missing\",\n            (\n                \"Parameters in function docstring have less items w.r.t. function\"\n                \" signature, first missing item: X\"\n            ),\n            \"Full diff:\",\n            \"- ['X', 'y']\",\n            \"+ []\",\n        ],\n        [\n            f\"In function: sklearn.utils.tests.test_testing.{mock_meta_name}.predict\",\n            (\n                \"There's a parameter name mismatch in function docstring w.r.t.\"\n                \" function signature, at index 0 diff: 'X' != 'y'\"\n            ),\n            \"Full diff:\",\n            \"- ['X']\",\n            \"?   ^\",\n            \"+ ['y']\",\n            \"?   ^\",\n        ],\n        [\n            \"In function: \"\n            f\"sklearn.utils.tests.test_testing.{mock_meta_name}.\"\n            \"predict_proba\",\n            \"potentially wrong underline length... \",\n            \"Parameters \",\n            \"--------- in \",\n        ],\n        [\n            f\"In function: sklearn.utils.tests.test_testing.{mock_meta_name}.score\",\n            \"potentially wrong underline length... \",\n            \"Parameters \",\n            \"--------- in \",\n        ],\n        [\n            f\"In function: sklearn.utils.tests.test_testing.{mock_meta_name}.fit\",\n            (\n                \"Parameters in function docstring have less items w.r.t. function\"\n                \" signature, first missing item: X\"\n            ),\n            \"Full diff:\",\n            \"- ['X', 'y']\",\n            \"+ []\",\n        ],\n    ]\n\n    for msg, f in zip(\n        messages,\n        [\n            f_bad_order,\n            f_too_many_param_docstring,\n            f_missing,\n            Klass.f_missing,\n            mock_meta.predict,\n            mock_meta.predict_proba,\n            mock_meta.score,\n            mock_meta.fit,\n        ],\n    ):\n        incorrect = check_docstring_parameters(f)\n        assert msg == incorrect, '\\n\"%s\"\\n not in \\n\"%s\"'"}, {"start_line": 10000, "end_line": 12000, "belongs_to": {"file_name": "test_testing.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/utils/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "rror, match=\"Unknown section Results\"):\n        check_docstring_parameters(f_bad_sections)\n    with pytest.raises(RuntimeError, match=\"Unknown section Parameter\"):\n        check_docstring_parameters(Klass.f_bad_sections)\n\n    incorrect = check_docstring_parameters(f_check_param_definition)\n    mock_meta = MockMetaEstimator(delegate=MockEst())\n    mock_meta_name = mock_meta.__class__.__name__\n    assert incorrect == [\n        (\n            \"sklearn.utils.tests.test_testing.f_check_param_definition There \"\n            \"was no space between the param name and colon ('a: int')\"\n        ),\n        (\n            \"sklearn.utils.tests.test_testing.f_check_param_definition There \"\n            \"was no space between the param name and colon ('b:')\"\n        ),\n        (\n            \"sklearn.utils.tests.test_testing.f_check_param_definition There \"\n            \"was no space between the param name and colon ('d:int')\"\n        ),\n    ]\n\n    messages = [\n        [\n            \"In function: sklearn.utils.tests.test_testing.f_bad_order\",\n            (\n                \"There's a parameter name mismatch in function docstring w.r.t.\"\n                \" function signature, at index 0 diff: 'b' != 'a'\"\n            ),\n            \"Full diff:\",\n            \"- ['b', 'a']\",\n            \"+ ['a', 'b']\",\n        ],\n        [\n            \"In function: sklearn.utils.tests.test_testing.f_too_many_param_docstring\",\n            (\n                \"Parameters in function docstring have more items w.r.t. function\"\n                \" signature, first extra item: c\"\n            ),\n            \"Full diff:\",\n            \"- ['a', 'b']\",\n            \"+ ['a', 'b', 'c']\",\n            \"?          +++++\",\n        ],\n        [\n            \"In function: sklearn.utils.tests.test_testing.f_missing\",\n            (\n                \"Parameters in function docstring have less items w.r.t. function\"\n                \" signature, first missing item: b\"\n            ),\n            \"Full diff:\",\n            \"- ['a', 'b']\",\n     "}, {"start_line": 1000, "end_line": 3000, "belongs_to": {"file_name": "test_docstring_parameters.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "r_tags_y,\n)\n\n# walk_packages() ignores DeprecationWarnings, now we need to ignore\n# FutureWarnings\nwith warnings.catch_warnings():\n    warnings.simplefilter(\"ignore\", FutureWarning)\n    # mypy error: Module has no attribute \"__path__\"\n    sklearn_path = [os.path.dirname(sklearn.__file__)]\n    PUBLIC_MODULES = set(\n        [\n            pckg[1]\n            for pckg in walk_packages(prefix=\"sklearn.\", path=sklearn_path)\n            if not any(\n                substr in pckg[1] for substr in [\"._\", \".tests.\", \"sklearn.externals\"]\n            )\n        ]\n    )\n\n# functions to ignore args / docstring of\n_DOCSTRING_IGNORES = [\n    \"sklearn.utils.deprecation.load_mlcomp\",\n    \"sklearn.pipeline.make_pipeline\",\n    \"sklearn.pipeline.make_union\",\n    \"sklearn.utils.extmath.safe_sparse_dot\",\n    \"HalfBinomialLoss\",\n]\n\n# Methods where y param should be ignored if y=None by default\n_METHODS_IGNORE_NONE_Y = [\n    \"fit\",\n    \"score\",\n    \"fit_predict\",\n    \"fit_transform\",\n    \"partial_fit\",\n    \"predict\",\n]\n\n\ndef test_docstring_parameters():\n    # Test module docstring formatting\n\n    # Skip test if numpydoc is not found\n    pytest.importorskip(\n        \"numpydoc\", reason=\"numpydoc is required to test the docstrings\"\n    )\n\n    # XXX unreached code as of v0.22\n    from numpydoc import docscrape\n\n    incorrect = []\n    for name in PUBLIC_MODULES:\n        if name.endswith(\".conftest\"):\n            # pytest tooling, not part of the scikit-learn API\n            continue\n        if name == \"sklearn.utils.fixes\":\n            # We cannot always control these docstrings\n            continue\n        with warnings.catch_warnings(record=True):\n            module = importlib.import_module(name)\n        classes = inspect.getmembers(module, inspect.isclass)\n        # Exclude non-scikit-learn classes\n        classes = [cls for cls in classes if cls[1].__module__.startswith(\"sklearn\")]\n        for cname, cls in classes:\n            this_incorrect = []\n            if cname in _DOCSTRING_IGNORES o"}, {"start_line": 2000, "end_line": 4000, "belongs_to": {"file_name": "test_docstring_parameters.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "dict\",\n]\n\n\ndef test_docstring_parameters():\n    # Test module docstring formatting\n\n    # Skip test if numpydoc is not found\n    pytest.importorskip(\n        \"numpydoc\", reason=\"numpydoc is required to test the docstrings\"\n    )\n\n    # XXX unreached code as of v0.22\n    from numpydoc import docscrape\n\n    incorrect = []\n    for name in PUBLIC_MODULES:\n        if name.endswith(\".conftest\"):\n            # pytest tooling, not part of the scikit-learn API\n            continue\n        if name == \"sklearn.utils.fixes\":\n            # We cannot always control these docstrings\n            continue\n        with warnings.catch_warnings(record=True):\n            module = importlib.import_module(name)\n        classes = inspect.getmembers(module, inspect.isclass)\n        # Exclude non-scikit-learn classes\n        classes = [cls for cls in classes if cls[1].__module__.startswith(\"sklearn\")]\n        for cname, cls in classes:\n            this_incorrect = []\n            if cname in _DOCSTRING_IGNORES or cname.startswith(\"_\"):\n                continue\n            if inspect.isabstract(cls):\n                continue\n            with warnings.catch_warnings(record=True) as w:\n                cdoc = docscrape.ClassDoc(cls)\n            if len(w):\n                raise RuntimeError(\n                    \"Error for __init__ of %s in %s:\\n%s\" % (cls, name, w[0])\n                )\n\n            # Skip checks on deprecated classes\n            if _is_deprecated(cls.__new__):\n                continue\n\n            this_incorrect += check_docstring_parameters(cls.__init__, cdoc)\n\n            for method_name in cdoc.methods:\n                method = getattr(cls, method_name)\n                if _is_deprecated(method):\n                    continue\n                param_ignore = None\n                # Now skip docstring test for y when y is None\n                # by default for API reason\n                if method_name in _METHODS_IGNORE_NONE_Y:\n                    sig = signature(method)\n             "}, {"start_line": 16000, "end_line": 18000, "belongs_to": {"file_name": "_testing.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/utils", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "   # Catch warning raised as of numpydoc 1.2 when\n                    # the underline length for a section of a docstring\n                    # is not consistent.\n                    message = str(exp).split(\"\\n\")[:3]\n                    incorrect += [f\"In function: {func_name}\"] + message\n                    return incorrect\n                records.append(str(exp))\n            except Exception as exp:\n                incorrect += [func_name + \" parsing error: \" + str(exp)]\n                return incorrect\n        if len(records):\n            raise RuntimeError(\"Error for %s:\\n%s\" % (func_name, records[0]))\n\n    param_docs = []\n    for name, type_definition, param_doc in doc[\"Parameters\"]:\n        # Type hints are empty only if parameter name ended with :\n        if not type_definition.strip():\n            if \":\" in name and name[: name.index(\":\")][-1:].strip():\n                incorrect += [\n                    func_name\n                    + \" There was no space between the param name and colon (%r)\" % name\n                ]\n            elif name.rstrip().endswith(\":\"):\n                incorrect += [\n                    func_name\n                    + \" Parameter %r has an empty type spec. Remove the colon\"\n                    % (name.lstrip())\n                ]\n\n        # Create a list of parameters to compare with the parameters gotten\n        # from the func signature\n        if \"*\" not in name:\n            param_docs.append(name.split(\":\")[0].strip(\"` \"))\n\n    # If one of the docstring's parameters had an error then return that\n    # incorrect message\n    if len(incorrect) > 0:\n        return incorrect\n\n    # Remove the parameters that should be ignored from list\n    param_docs = list(filter(lambda x: x not in ignore, param_docs))\n\n    # The following is derived from pytest, Copyright (c) 2004-2017 Holger\n    # Krekel and others, Licensed under MIT License. See\n    # https://github.com/pytest-dev/pytest\n\n    message = []\n    for i in range(min(len(param_docs),"}, {"start_line": 6000, "end_line": 8000, "belongs_to": {"file_name": "test_testing.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/utils/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "h):\n        silence_warnings_func = ignore_warnings(warning_class)(_warning_function)\n        silence_warnings_func()\n\n    with pytest.raises(ValueError, match=match):\n\n        @ignore_warnings(warning_class)\n        def test():\n            pass\n\n\n# Tests for docstrings:\n\n\ndef f_ok(a, b):\n    \"\"\"Function f\n\n    Parameters\n    ----------\n    a : int\n        Parameter a\n    b : float\n        Parameter b\n\n    Returns\n    -------\n    c : list\n        Parameter c\n    \"\"\"\n    c = a + b\n    return c\n\n\ndef f_bad_sections(a, b):\n    \"\"\"Function f\n\n    Parameters\n    ----------\n    a : int\n        Parameter a\n    b : float\n        Parameter b\n\n    Results\n    -------\n    c : list\n        Parameter c\n    \"\"\"\n    c = a + b\n    return c\n\n\ndef f_bad_order(b, a):\n    \"\"\"Function f\n\n    Parameters\n    ----------\n    a : int\n        Parameter a\n    b : float\n        Parameter b\n\n    Returns\n    -------\n    c : list\n        Parameter c\n    \"\"\"\n    c = a + b\n    return c\n\n\ndef f_too_many_param_docstring(a, b):\n    \"\"\"Function f\n\n    Parameters\n    ----------\n    a : int\n        Parameter a\n    b : int\n        Parameter b\n    c : int\n        Parameter c\n\n    Returns\n    -------\n    d : list\n        Parameter c\n    \"\"\"\n    d = a + b\n    return d\n\n\ndef f_missing(a, b):\n    \"\"\"Function f\n\n    Parameters\n    ----------\n    a : int\n        Parameter a\n\n    Returns\n    -------\n    c : list\n        Parameter c\n    \"\"\"\n    c = a + b\n    return c\n\n\ndef f_check_param_definition(a, b, c, d, e):\n    \"\"\"Function f\n\n    Parameters\n    ----------\n    a: int\n        Parameter a\n    b:\n        Parameter b\n    c :\n        This is parsed correctly in numpydoc 1.2\n    d:int\n        Parameter d\n    e\n        No typespec is allowed without colon\n    \"\"\"\n    return a + b + c + d\n\n\nclass Klass:\n    def f_missing(self, X, y):\n        pass\n\n    def f_bad_sections(self, X, y):\n        \"\"\"Function f\n\n        Parameter\n        ---------\n        a : int\n            Parameter a\n        b : float\n            Paramete"}, {"start_line": 0, "end_line": 2000, "belongs_to": {"file_name": "test_docstrings.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "import re\nfrom inspect import signature\nfrom typing import Optional\n\nimport pytest\n\n# make it possible to discover experimental estimators when calling `all_estimators`\nfrom sklearn.experimental import (\n    enable_halving_search_cv,  # noqa: F401\n    enable_iterative_imputer,  # noqa: F401\n)\nfrom sklearn.utils.discovery import all_displays, all_estimators, all_functions\n\nnumpydoc_validation = pytest.importorskip(\"numpydoc.validate\")\n\n\ndef get_all_methods():\n    estimators = all_estimators()\n    displays = all_displays()\n    for name, Klass in estimators + displays:\n        if name.startswith(\"_\"):\n            # skip private classes\n            continue\n        methods = []\n        for name in dir(Klass):\n            if name.startswith(\"_\"):\n                continue\n            method_obj = getattr(Klass, name)\n            if hasattr(method_obj, \"__call__\") or isinstance(method_obj, property):\n                methods.append(name)\n        methods.append(None)\n\n        for method in sorted(methods, key=str):\n            yield Klass, method\n\n\ndef get_all_functions_names():\n    functions = all_functions()\n    for _, func in functions:\n        # exclude functions from utils.fixex since they come from external packages\n        if \"utils.fixes\" not in func.__module__:\n            yield f\"{func.__module__}.{func.__name__}\"\n\n\ndef filter_errors(errors, method, Klass=None):\n    \"\"\"\n    Ignore some errors based on the method type.\n\n    These rules are specific for scikit-learn.\"\"\"\n    for code, message in errors:\n        # We ignore following error code,\n        #  - RT02: The first line of the Returns section\n        #    should contain only the type, ..\n        #   (as we may need refer to the name of the returned\n        #    object)\n        #  - GL01: Docstring text (summary) should start in the line\n        #    immediately after the opening quotes (not in the same line,\n        #    or leaving a blank line in between)\n        #  - GL02: If there's a blank line, it should "}], "retrieved_count": 10, "cost_time": 1.0898661613464355}
{"question": "What is the semantic significance of SelectFromModel's partial_fit method enforcing max_features validation constraints differently compared to its fit method, and why does it raise validation errors during partial_fit rather than deferring validation to subsequent fit calls?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"start_line": 22000, "end_line": 23841, "belongs_to": {"file_name": "test_from_model.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/feature_selection/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "ror, err_msg, max_features):\n    \"\"\"Test that partial_fit from SelectFromModel validates `max_features`.\"\"\"\n    X, y = datasets.make_classification(\n        n_samples=100,\n        n_features=4,\n        random_state=0,\n    )\n\n    with pytest.raises(error, match=err_msg):\n        SelectFromModel(\n            estimator=SGDClassifier(), max_features=max_features\n        ).partial_fit(X, y, classes=[0, 1])\n\n\n@pytest.mark.parametrize(\"as_frame\", [True, False])\ndef test_partial_fit_validate_feature_names(as_frame):\n    \"\"\"Test that partial_fit from SelectFromModel validates `feature_names_in_`.\"\"\"\n    pytest.importorskip(\"pandas\")\n    X, y = datasets.load_iris(as_frame=as_frame, return_X_y=True)\n\n    selector = SelectFromModel(estimator=SGDClassifier(), max_features=4).partial_fit(\n        X, y, classes=[0, 1, 2]\n    )\n    if as_frame:\n        assert_array_equal(selector.feature_names_in_, X.columns)\n    else:\n        assert not hasattr(selector, \"feature_names_in_\")\n\n\ndef test_from_model_estimator_attribute_error():\n    \"\"\"Check that we raise the proper AttributeError when the estimator\n    does not implement the `partial_fit` method, which is decorated with\n    `available_if`.\n\n    Non-regression test for:\n    https://github.com/scikit-learn/scikit-learn/issues/28108\n    \"\"\"\n    # `LinearRegression` does not implement 'partial_fit' and should raise an\n    # AttributeError\n    from_model = SelectFromModel(estimator=LinearRegression())\n\n    outer_msg = \"This 'SelectFromModel' has no attribute 'partial_fit'\"\n    inner_msg = \"'LinearRegression' object has no attribute 'partial_fit'\"\n    with pytest.raises(AttributeError, match=outer_msg) as exec_info:\n        from_model.fit(data, y).partial_fit(data)\n    assert isinstance(exec_info.value.__cause__, AttributeError)\n    assert inner_msg in str(exec_info.value.__cause__)\n"}, {"start_line": 15000, "end_line": 17000, "belongs_to": {"file_name": "test_from_model.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/feature_selection/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "l_fit(data, y)\n    with pytest.raises(NotFittedError, match=err_msg):\n        model.transform(data)\n\n    # Check that the internal parameters of prefitted model are not changed\n    # when calling `fit` or `partial_fit` with `prefit=True`\n    clf = SGDClassifier(alpha=0.1, max_iter=10, shuffle=True, tol=None).fit(data, y)\n    model = SelectFromModel(clf, prefit=True)\n    model.fit(data, y)\n    assert_allclose(model.estimator_.coef_, clf.coef_)\n    model.partial_fit(data, y)\n    assert_allclose(model.estimator_.coef_, clf.coef_)\n\n\ndef test_prefit_max_features():\n    \"\"\"Check the interaction between `prefit` and `max_features`.\"\"\"\n    # case 1: an error should be raised at `transform` if `fit` was not called to\n    # validate the attributes\n    estimator = RandomForestClassifier(n_estimators=5, random_state=0)\n    estimator.fit(data, y)\n    model = SelectFromModel(estimator, prefit=True, max_features=lambda X: X.shape[1])\n\n    err_msg = (\n        \"When `prefit=True` and `max_features` is a callable, call `fit` \"\n        \"before calling `transform`.\"\n    )\n    with pytest.raises(NotFittedError, match=err_msg):\n        model.transform(data)\n\n    # case 2: `max_features` is not validated and different from an integer\n    # FIXME: we cannot validate the upper bound of the attribute at transform\n    # and we should force calling `fit` if we intend to force the attribute\n    # to have such an upper bound.\n    max_features = 2.5\n    model.set_params(max_features=max_features)\n    with pytest.raises(ValueError, match=\"`max_features` must be an integer\"):\n        model.transform(data)\n\n\ndef test_get_feature_names_out_elasticnetcv():\n    \"\"\"Check if ElasticNetCV works with a list of floats.\n\n    Non-regression test for #30936.\"\"\"\n    X, y = make_regression(n_features=5, n_informative=3, random_state=0)\n    estimator = ElasticNetCV(l1_ratio=[0.25, 0.5, 0.75], random_state=0)\n    selector = SelectFromModel(estimator=estimator)\n    selector.fit(X, y)\n\n    names_out = selector.get_f"}, {"start_line": 10000, "end_line": 12000, "belongs_to": {"file_name": "_from_model.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/feature_selection", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "timator.\"\n                ) from exc\n        if callable(max_features):\n            # This branch is executed when `transform` is called directly and thus\n            # `max_features_` is not set and we fallback using `self.max_features`\n            # that is not validated\n            raise NotFittedError(\n                \"When `prefit=True` and `max_features` is a callable, call `fit` \"\n                \"before calling `transform`.\"\n            )\n        elif max_features is not None and not isinstance(max_features, Integral):\n            raise ValueError(\n                f\"`max_features` must be an integer. Got `max_features={max_features}` \"\n                \"instead.\"\n            )\n\n        scores = _get_feature_importances(\n            estimator=estimator,\n            getter=self.importance_getter,\n            transform_func=\"norm\",\n            norm_order=self.norm_order,\n        )\n        threshold = _calculate_threshold(estimator, scores, self.threshold)\n        if self.max_features is not None:\n            mask = np.zeros_like(scores, dtype=bool)\n            candidate_indices = np.argsort(-scores, kind=\"mergesort\")[:max_features]\n            mask[candidate_indices] = True\n        else:\n            mask = np.ones_like(scores, dtype=bool)\n        mask[scores < threshold] = False\n        return mask\n\n    def _check_max_features(self, X):\n        if self.max_features is not None:\n            n_features = _num_features(X)\n\n            if callable(self.max_features):\n                max_features = self.max_features(X)\n            else:  # int\n                max_features = self.max_features\n\n            check_scalar(\n                max_features,\n                \"max_features\",\n                Integral,\n                min_val=0,\n                max_val=n_features,\n            )\n            self.max_features_ = max_features\n\n    @_fit_context(\n        # SelectFromModel.estimator is not validated yet\n        prefer_skip_nested_validation=False\n    )\n    def fit(self,"}, {"start_line": 1000, "end_line": 3000, "belongs_to": {"file_name": "test_from_model.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/feature_selection/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "elf):\n        tags = super().__sklearn_tags__()\n        tags.input_tags.allow_nan = True\n        return tags\n\n\nclass NoNaNTag(BaseEstimator):\n    def __sklearn_tags__(self):\n        tags = super().__sklearn_tags__()\n        tags.input_tags.allow_nan = False\n        return tags\n\n\nclass NaNTagRandomForest(RandomForestClassifier):\n    def __sklearn_tags__(self):\n        tags = super().__sklearn_tags__()\n        tags.input_tags.allow_nan = True\n        return tags\n\n\niris = datasets.load_iris()\ndata, y = iris.data, iris.target\n\n\ndef test_invalid_input():\n    clf = SGDClassifier(\n        alpha=0.1, max_iter=10, shuffle=True, random_state=None, tol=None\n    )\n    for threshold in [\"gobbledigook\", \".5 * gobbledigook\"]:\n        model = SelectFromModel(clf, threshold=threshold)\n        model.fit(data, y)\n        with pytest.raises(ValueError):\n            model.transform(data)\n\n\ndef test_input_estimator_unchanged():\n    # Test that SelectFromModel fits on a clone of the estimator.\n    est = RandomForestClassifier()\n    transformer = SelectFromModel(estimator=est)\n    transformer.fit(data, y)\n    assert transformer.estimator is est\n\n\n@pytest.mark.parametrize(\n    \"max_features, err_type, err_msg\",\n    [\n        (\n            data.shape[1] + 1,\n            ValueError,\n            \"max_features ==\",\n        ),\n        (\n            lambda X: 1.5,\n            TypeError,\n            \"max_features must be an instance of int, not float.\",\n        ),\n        (\n            lambda X: data.shape[1] + 1,\n            ValueError,\n            \"max_features ==\",\n        ),\n        (\n            lambda X: -1,\n            ValueError,\n            \"max_features ==\",\n        ),\n    ],\n)\ndef test_max_features_error(max_features, err_type, err_msg):\n    err_msg = re.escape(err_msg)\n    clf = RandomForestClassifier(n_estimators=5, random_state=0)\n\n    transformer = SelectFromModel(\n        estimator=clf, max_features=max_features, threshold=-np.inf\n    )\n    with pytest.raises(err_type, match=err_ms"}, {"start_line": 14000, "end_line": 16000, "belongs_to": {"file_name": "_from_model.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/feature_selection", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "timator_.feature_names_in_\n        else:\n            _check_feature_names(self, X, reset=True)\n\n        return self\n\n    @property\n    def threshold_(self):\n        \"\"\"Threshold value used for feature selection.\"\"\"\n        scores = _get_feature_importances(\n            estimator=self.estimator_,\n            getter=self.importance_getter,\n            transform_func=\"norm\",\n            norm_order=self.norm_order,\n        )\n        return _calculate_threshold(self.estimator, scores, self.threshold)\n\n    @available_if(_estimator_has(\"partial_fit\"))\n    @_fit_context(\n        # SelectFromModel.estimator is not validated yet\n        prefer_skip_nested_validation=False\n    )\n    def partial_fit(self, X, y=None, **partial_fit_params):\n        \"\"\"Fit the SelectFromModel meta-transformer only once.\n\n        Parameters\n        ----------\n        X : array-like of shape (n_samples, n_features)\n            The training input samples.\n\n        y : array-like of shape (n_samples,), default=None\n            The target values (integers that correspond to classes in\n            classification, real numbers in regression).\n\n        **partial_fit_params : dict\n            - If `enable_metadata_routing=False` (default): Parameters directly passed\n              to the `partial_fit` method of the sub-estimator.\n\n            - If `enable_metadata_routing=True`: Parameters passed to the `partial_fit`\n              method of the sub-estimator. They are ignored if `prefit=True`.\n\n            .. versionchanged:: 1.4\n\n                `**partial_fit_params` are routed to the sub-estimator, if\n                `enable_metadata_routing=True` is set via\n                :func:`~sklearn.set_config`, which allows for aliasing.\n\n                See :ref:`Metadata Routing User Guide <metadata_routing>` for\n                more details.\n\n        Returns\n        -------\n        self : object\n            Fitted estimator.\n        \"\"\"\n        first_call = not hasattr(self, \"estimator_\")\n\n        if first_cal"}, {"start_line": 14000, "end_line": 16000, "belongs_to": {"file_name": "test_from_model.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/feature_selection/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "ol=None)\n    model = SelectFromModel(clf)\n    model.fit(data, y)\n    X_transform = model.transform(data)\n    clf.fit(data, y)\n    model = SelectFromModel(clf, prefit=True)\n    assert_array_almost_equal(model.transform(data), X_transform)\n    model.fit(data, y)\n    assert model.estimator_ is not clf\n\n    # Check that the model is rewritten if prefit=False and a fitted model is\n    # passed\n    model = SelectFromModel(clf, prefit=False)\n    model.fit(data, y)\n    assert_array_almost_equal(model.transform(data), X_transform)\n\n    # Check that passing an unfitted estimator with `prefit=True` raises a\n    # `ValueError`\n    clf = SGDClassifier(alpha=0.1, max_iter=10, shuffle=True, random_state=0, tol=None)\n    model = SelectFromModel(clf, prefit=True)\n    err_msg = \"When `prefit=True`, `estimator` is expected to be a fitted estimator.\"\n    with pytest.raises(NotFittedError, match=err_msg):\n        model.fit(data, y)\n    with pytest.raises(NotFittedError, match=err_msg):\n        model.partial_fit(data, y)\n    with pytest.raises(NotFittedError, match=err_msg):\n        model.transform(data)\n\n    # Check that the internal parameters of prefitted model are not changed\n    # when calling `fit` or `partial_fit` with `prefit=True`\n    clf = SGDClassifier(alpha=0.1, max_iter=10, shuffle=True, tol=None).fit(data, y)\n    model = SelectFromModel(clf, prefit=True)\n    model.fit(data, y)\n    assert_allclose(model.estimator_.coef_, clf.coef_)\n    model.partial_fit(data, y)\n    assert_allclose(model.estimator_.coef_, clf.coef_)\n\n\ndef test_prefit_max_features():\n    \"\"\"Check the interaction between `prefit` and `max_features`.\"\"\"\n    # case 1: an error should be raised at `transform` if `fit` was not called to\n    # validate the attributes\n    estimator = RandomForestClassifier(n_estimators=5, random_state=0)\n    estimator.fit(data, y)\n    model = SelectFromModel(estimator, prefit=True, max_features=lambda X: X.shape[1])\n\n    err_msg = (\n        \"When `prefit=True` and `max_features` is "}, {"start_line": 2000, "end_line": 4000, "belongs_to": {"file_name": "test_from_model.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/feature_selection/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "omForestClassifier()\n    transformer = SelectFromModel(estimator=est)\n    transformer.fit(data, y)\n    assert transformer.estimator is est\n\n\n@pytest.mark.parametrize(\n    \"max_features, err_type, err_msg\",\n    [\n        (\n            data.shape[1] + 1,\n            ValueError,\n            \"max_features ==\",\n        ),\n        (\n            lambda X: 1.5,\n            TypeError,\n            \"max_features must be an instance of int, not float.\",\n        ),\n        (\n            lambda X: data.shape[1] + 1,\n            ValueError,\n            \"max_features ==\",\n        ),\n        (\n            lambda X: -1,\n            ValueError,\n            \"max_features ==\",\n        ),\n    ],\n)\ndef test_max_features_error(max_features, err_type, err_msg):\n    err_msg = re.escape(err_msg)\n    clf = RandomForestClassifier(n_estimators=5, random_state=0)\n\n    transformer = SelectFromModel(\n        estimator=clf, max_features=max_features, threshold=-np.inf\n    )\n    with pytest.raises(err_type, match=err_msg):\n        transformer.fit(data, y)\n\n\n@pytest.mark.parametrize(\"max_features\", [0, 2, data.shape[1], None])\ndef test_inferred_max_features_integer(max_features):\n    \"\"\"Check max_features_ and output shape for integer max_features.\"\"\"\n    clf = RandomForestClassifier(n_estimators=5, random_state=0)\n    transformer = SelectFromModel(\n        estimator=clf, max_features=max_features, threshold=-np.inf\n    )\n    X_trans = transformer.fit_transform(data, y)\n    if max_features is not None:\n        assert transformer.max_features_ == max_features\n        assert X_trans.shape[1] == transformer.max_features_\n    else:\n        assert not hasattr(transformer, \"max_features_\")\n        assert X_trans.shape[1] == data.shape[1]\n\n\n@pytest.mark.parametrize(\n    \"max_features\",\n    [lambda X: 1, lambda X: X.shape[1], lambda X: min(X.shape[1], 10000)],\n)\ndef test_inferred_max_features_callable(max_features):\n    \"\"\"Check max_features_ and output shape for callable max_features.\"\"\"\n    clf = RandomFore"}, {"start_line": 20000, "end_line": 22000, "belongs_to": {"file_name": "test_from_model.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/feature_selection/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "amed_steps.logisticregression.coef_\",\n        ),\n        (PCA(random_state=0), _pca_importances),\n    ],\n)\ndef test_importance_getter(estimator, importance_getter):\n    selector = SelectFromModel(\n        estimator, threshold=\"mean\", importance_getter=importance_getter\n    )\n    selector.fit(data, y)\n    assert selector.transform(data).shape[1] == 1\n\n\n@pytest.mark.parametrize(\"PLSEstimator\", [CCA, PLSCanonical, PLSRegression])\ndef test_select_from_model_pls(PLSEstimator):\n    \"\"\"Check the behaviour of SelectFromModel with PLS estimators.\n\n    Non-regression test for:\n    https://github.com/scikit-learn/scikit-learn/issues/12410\n    \"\"\"\n    X, y = make_friedman1(n_samples=50, n_features=10, random_state=0)\n    estimator = PLSEstimator(n_components=1)\n    model = make_pipeline(SelectFromModel(estimator), estimator).fit(X, y)\n    assert model.score(X, y) > 0.5\n\n\ndef test_estimator_does_not_support_feature_names():\n    \"\"\"SelectFromModel works with estimators that do not support feature_names_in_.\n\n    Non-regression test for #21949.\n    \"\"\"\n    pytest.importorskip(\"pandas\")\n    X, y = datasets.load_iris(as_frame=True, return_X_y=True)\n    all_feature_names = set(X.columns)\n\n    def importance_getter(estimator):\n        return np.arange(X.shape[1])\n\n    selector = SelectFromModel(\n        MinimalClassifier(), importance_getter=importance_getter\n    ).fit(X, y)\n\n    # selector learns the feature names itself\n    assert_array_equal(selector.feature_names_in_, X.columns)\n\n    feature_names_out = set(selector.get_feature_names_out())\n    assert feature_names_out < all_feature_names\n\n    with warnings.catch_warnings():\n        warnings.simplefilter(\"error\", UserWarning)\n\n        selector.transform(X.iloc[1:3])\n\n\n@pytest.mark.parametrize(\n    \"error, err_msg, max_features\",\n    (\n        [ValueError, \"max_features == 10, must be <= 4\", 10],\n        [ValueError, \"max_features == 5, must be <= 4\", lambda x: x.shape[1] + 1],\n    ),\n)\ndef test_partial_fit_validate_max_features(er"}, {"start_line": 12000, "end_line": 14000, "belongs_to": {"file_name": "test_from_model.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/feature_selection/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "ti-class problem\n            transformer = SelectFromModel(\n                estimator=LogisticRegression(), threshold=threshold, norm_order=order\n            )\n            transformer.fit(X, y)\n            assert hasattr(transformer.estimator_, \"coef_\")\n            X_new = transformer.transform(X)\n            assert X_new.shape[1] < X.shape[1]\n\n            # Manually check that the norm is correctly performed\n            est.fit(X, y)\n            importances = np.linalg.norm(est.coef_, axis=0, ord=order)\n            feature_mask = importances > func(importances)\n            assert_array_almost_equal(X_new, X[:, feature_mask])\n\n\ndef test_partial_fit():\n    est = PassiveAggressiveClassifier(\n        random_state=0, shuffle=False, max_iter=5, tol=None\n    )\n    transformer = SelectFromModel(estimator=est)\n    transformer.partial_fit(data, y, classes=np.unique(y))\n    old_model = transformer.estimator_\n    transformer.partial_fit(data, y, classes=np.unique(y))\n    new_model = transformer.estimator_\n    assert old_model is new_model\n\n    X_transform = transformer.transform(data)\n    transformer.fit(np.vstack((data, data)), np.concatenate((y, y)))\n    assert_array_almost_equal(X_transform, transformer.transform(data))\n\n    # check that if est doesn't have partial_fit, neither does SelectFromModel\n    transformer = SelectFromModel(estimator=RandomForestClassifier())\n    assert not hasattr(transformer, \"partial_fit\")\n\n\ndef test_calling_fit_reinitializes():\n    est = LinearSVC(random_state=0)\n    transformer = SelectFromModel(estimator=est)\n    transformer.fit(data, y)\n    transformer.set_params(estimator__C=100)\n    transformer.fit(data, y)\n    assert transformer.estimator_.C == 100\n\n\ndef test_prefit():\n    # Test all possible combinations of the prefit parameter.\n\n    # Passing a prefit parameter with the selected model\n    # and fitting a unfit model with prefit=False should give same results.\n    clf = SGDClassifier(alpha=0.1, max_iter=10, shuffle=True, random_state=0, t"}, {"start_line": 11000, "end_line": 13000, "belongs_to": {"file_name": "test_from_model.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/feature_selection/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "\ndef test_coef_default_threshold(estimator):\n    X, y = datasets.make_classification(\n        n_samples=100,\n        n_features=10,\n        n_informative=3,\n        n_redundant=0,\n        n_repeated=0,\n        shuffle=False,\n        random_state=0,\n    )\n\n    # For the Lasso and related models, the threshold defaults to 1e-5\n    transformer = SelectFromModel(estimator=estimator)\n    transformer.fit(X, y)\n    X_new = transformer.transform(X)\n    mask = np.abs(transformer.estimator_.coef_) > 1e-5\n    assert_array_almost_equal(X_new, X[:, mask])\n\n\n@skip_if_32bit\ndef test_2d_coef():\n    X, y = datasets.make_classification(\n        n_samples=1000,\n        n_features=10,\n        n_informative=3,\n        n_redundant=0,\n        n_repeated=0,\n        shuffle=False,\n        random_state=0,\n        n_classes=4,\n    )\n\n    est = LogisticRegression()\n    for threshold, func in zip([\"mean\", \"median\"], [np.mean, np.median]):\n        for order in [1, 2, np.inf]:\n            # Fit SelectFromModel a multi-class problem\n            transformer = SelectFromModel(\n                estimator=LogisticRegression(), threshold=threshold, norm_order=order\n            )\n            transformer.fit(X, y)\n            assert hasattr(transformer.estimator_, \"coef_\")\n            X_new = transformer.transform(X)\n            assert X_new.shape[1] < X.shape[1]\n\n            # Manually check that the norm is correctly performed\n            est.fit(X, y)\n            importances = np.linalg.norm(est.coef_, axis=0, ord=order)\n            feature_mask = importances > func(importances)\n            assert_array_almost_equal(X_new, X[:, feature_mask])\n\n\ndef test_partial_fit():\n    est = PassiveAggressiveClassifier(\n        random_state=0, shuffle=False, max_iter=5, tol=None\n    )\n    transformer = SelectFromModel(estimator=est)\n    transformer.partial_fit(data, y, classes=np.unique(y))\n    old_model = transformer.estimator_\n    transformer.partial_fit(data, y, classes=np.unique(y))\n    new_model = transformer.e"}], "retrieved_count": 10, "cost_time": 1.091362476348877}
{"question": "What is the architectural pattern established by the DictionaryLearningBenchmark class that integrates the Transformer, Estimator, and Benchmark base classes for performance measurement in the decomposition module?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"start_line": 1000, "end_line": 2406, "belongs_to": {"file_name": "decomposition.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/asv_benchmarks/benchmarks", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "ars\", \"cd\"], Benchmark.n_jobs_vals)\n\n    def setup_cache(self):\n        super().setup_cache()\n\n    def make_data(self, params):\n        return _olivetti_faces_dataset()\n\n    def make_estimator(self, params):\n        fit_algorithm, n_jobs = params\n\n        estimator = DictionaryLearning(\n            n_components=15,\n            fit_algorithm=fit_algorithm,\n            alpha=0.1,\n            transform_alpha=1,\n            max_iter=20,\n            tol=1e-16,\n            random_state=0,\n            n_jobs=n_jobs,\n        )\n\n        return estimator\n\n    def make_scorers(self):\n        make_dict_learning_scorers(self)\n\n\nclass MiniBatchDictionaryLearningBenchmark(Transformer, Estimator, Benchmark):\n    \"\"\"\n    Benchmarks for MiniBatchDictionaryLearning\n    \"\"\"\n\n    param_names = [\"fit_algorithm\", \"n_jobs\"]\n    params = ([\"lars\", \"cd\"], Benchmark.n_jobs_vals)\n\n    def setup_cache(self):\n        super().setup_cache()\n\n    def make_data(self, params):\n        return _olivetti_faces_dataset()\n\n    def make_estimator(self, params):\n        fit_algorithm, n_jobs = params\n\n        estimator = MiniBatchDictionaryLearning(\n            n_components=15,\n            fit_algorithm=fit_algorithm,\n            alpha=0.1,\n            batch_size=3,\n            random_state=0,\n            n_jobs=n_jobs,\n        )\n\n        return estimator\n\n    def make_scorers(self):\n        make_dict_learning_scorers(self)\n"}, {"start_line": 0, "end_line": 2000, "belongs_to": {"file_name": "decomposition.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/asv_benchmarks/benchmarks", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "from sklearn.decomposition import PCA, DictionaryLearning, MiniBatchDictionaryLearning\n\nfrom .common import Benchmark, Estimator, Transformer\nfrom .datasets import _mnist_dataset, _olivetti_faces_dataset\nfrom .utils import make_dict_learning_scorers, make_pca_scorers\n\n\nclass PCABenchmark(Transformer, Estimator, Benchmark):\n    \"\"\"\n    Benchmarks for PCA.\n    \"\"\"\n\n    param_names = [\"svd_solver\"]\n    params = ([\"full\", \"arpack\", \"randomized\"],)\n\n    def setup_cache(self):\n        super().setup_cache()\n\n    def make_data(self, params):\n        return _mnist_dataset()\n\n    def make_estimator(self, params):\n        (svd_solver,) = params\n\n        estimator = PCA(n_components=32, svd_solver=svd_solver, random_state=0)\n\n        return estimator\n\n    def make_scorers(self):\n        make_pca_scorers(self)\n\n\nclass DictionaryLearningBenchmark(Transformer, Estimator, Benchmark):\n    \"\"\"\n    Benchmarks for DictionaryLearning.\n    \"\"\"\n\n    param_names = [\"fit_algorithm\", \"n_jobs\"]\n    params = ([\"lars\", \"cd\"], Benchmark.n_jobs_vals)\n\n    def setup_cache(self):\n        super().setup_cache()\n\n    def make_data(self, params):\n        return _olivetti_faces_dataset()\n\n    def make_estimator(self, params):\n        fit_algorithm, n_jobs = params\n\n        estimator = DictionaryLearning(\n            n_components=15,\n            fit_algorithm=fit_algorithm,\n            alpha=0.1,\n            transform_alpha=1,\n            max_iter=20,\n            tol=1e-16,\n            random_state=0,\n            n_jobs=n_jobs,\n        )\n\n        return estimator\n\n    def make_scorers(self):\n        make_dict_learning_scorers(self)\n\n\nclass MiniBatchDictionaryLearningBenchmark(Transformer, Estimator, Benchmark):\n    \"\"\"\n    Benchmarks for MiniBatchDictionaryLearning\n    \"\"\"\n\n    param_names = [\"fit_algorithm\", \"n_jobs\"]\n    params = ([\"lars\", \"cd\"], Benchmark.n_jobs_vals)\n\n    def setup_cache(self):\n        super().setup_cache()\n\n    def make_data(self, params):\n        return _olivetti_faces_dataset()\n\n "}, {"start_line": 6000, "end_line": 7347, "belongs_to": {"file_name": "common.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/asv_benchmarks/benchmarks", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "n(self, *args):\n                est_path = get_estimator_path(self, Benchmark.base_commit, args, True)\n                with est_path.open(mode=\"rb\") as f:\n                    estimator_base = pickle.load(f)\n\n                y_val_pred_base = estimator_base.predict(self.X_val)\n                y_val_pred = self.estimator.predict(self.X_val)\n\n                return np.allclose(y_val_pred_base, y_val_pred)\n\n    @property\n    @abstractmethod\n    def params(self):\n        pass\n\n\nclass Transformer(ABC):\n    \"\"\"Abstract base class for benchmarks of estimators implementing transform\"\"\"\n\n    if Benchmark.bench_transform:\n\n        def time_transform(self, *args):\n            self.estimator.transform(self.X)\n\n        def peakmem_transform(self, *args):\n            self.estimator.transform(self.X)\n\n        if Benchmark.base_commit is not None:\n\n            def track_same_transform(self, *args):\n                est_path = get_estimator_path(self, Benchmark.base_commit, args, True)\n                with est_path.open(mode=\"rb\") as f:\n                    estimator_base = pickle.load(f)\n\n                X_val_t_base = estimator_base.transform(self.X_val)\n                X_val_t = self.estimator.transform(self.X_val)\n\n                return np.allclose(X_val_t_base, X_val_t)\n\n    @property\n    @abstractmethod\n    def params(self):\n        pass\n"}, {"start_line": 5000, "end_line": 7000, "belongs_to": {"file_name": "common.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/asv_benchmarks/benchmarks", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "       self.estimator.fit(self.X, self.y)\n\n    def peakmem_fit(self, *args):\n        self.estimator.fit(self.X, self.y)\n\n    def track_train_score(self, *args):\n        if hasattr(self.estimator, \"predict\"):\n            y_pred = self.estimator.predict(self.X)\n        else:\n            y_pred = None\n        return float(self.train_scorer(self.y, y_pred))\n\n    def track_test_score(self, *args):\n        if hasattr(self.estimator, \"predict\"):\n            y_val_pred = self.estimator.predict(self.X_val)\n        else:\n            y_val_pred = None\n        return float(self.test_scorer(self.y_val, y_val_pred))\n\n\nclass Predictor(ABC):\n    \"\"\"Abstract base class for benchmarks of estimators implementing predict\"\"\"\n\n    if Benchmark.bench_predict:\n\n        def time_predict(self, *args):\n            self.estimator.predict(self.X)\n\n        def peakmem_predict(self, *args):\n            self.estimator.predict(self.X)\n\n        if Benchmark.base_commit is not None:\n\n            def track_same_prediction(self, *args):\n                est_path = get_estimator_path(self, Benchmark.base_commit, args, True)\n                with est_path.open(mode=\"rb\") as f:\n                    estimator_base = pickle.load(f)\n\n                y_val_pred_base = estimator_base.predict(self.X_val)\n                y_val_pred = self.estimator.predict(self.X_val)\n\n                return np.allclose(y_val_pred_base, y_val_pred)\n\n    @property\n    @abstractmethod\n    def params(self):\n        pass\n\n\nclass Transformer(ABC):\n    \"\"\"Abstract base class for benchmarks of estimators implementing transform\"\"\"\n\n    if Benchmark.bench_transform:\n\n        def time_transform(self, *args):\n            self.estimator.transform(self.X)\n\n        def peakmem_transform(self, *args):\n            self.estimator.transform(self.X)\n\n        if Benchmark.base_commit is not None:\n\n            def track_same_transform(self, *args):\n                est_path = get_estimator_path(self, Benchmark.base_commit, args, True)\n                wi"}, {"start_line": 52000, "end_line": 54000, "belongs_to": {"file_name": "_dict_learning.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/decomposition", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "d_signal\n    >>> from sklearn.decomposition import DictionaryLearning\n    >>> X, dictionary, code = make_sparse_coded_signal(\n    ...     n_samples=30, n_components=15, n_features=20, n_nonzero_coefs=10,\n    ...     random_state=42,\n    ... )\n    >>> dict_learner = DictionaryLearning(\n    ...     n_components=15, transform_algorithm='lasso_lars', transform_alpha=0.1,\n    ...     random_state=42,\n    ... )\n    >>> X_transformed = dict_learner.fit(X).transform(X)\n\n    We can check the level of sparsity of `X_transformed`:\n\n    >>> np.mean(X_transformed == 0)\n    np.float64(0.527)\n\n    We can compare the average squared euclidean norm of the reconstruction\n    error of the sparse coded signal relative to the squared euclidean norm of\n    the original signal:\n\n    >>> X_hat = X_transformed @ dict_learner.components_\n    >>> np.mean(np.sum((X_hat - X) ** 2, axis=1) / np.sum(X ** 2, axis=1))\n    np.float64(0.056)\n    \"\"\"\n\n    _parameter_constraints: dict = {\n        \"n_components\": [Interval(Integral, 1, None, closed=\"left\"), None],\n        \"alpha\": [Interval(Real, 0, None, closed=\"left\")],\n        \"max_iter\": [Interval(Integral, 0, None, closed=\"left\")],\n        \"tol\": [Interval(Real, 0, None, closed=\"left\")],\n        \"fit_algorithm\": [StrOptions({\"lars\", \"cd\"})],\n        \"transform_algorithm\": [\n            StrOptions({\"lasso_lars\", \"lasso_cd\", \"lars\", \"omp\", \"threshold\"})\n        ],\n        \"transform_n_nonzero_coefs\": [Interval(Integral, 1, None, closed=\"left\"), None],\n        \"transform_alpha\": [Interval(Real, 0, None, closed=\"left\"), None],\n        \"n_jobs\": [Integral, None],\n        \"code_init\": [np.ndarray, None],\n        \"dict_init\": [np.ndarray, None],\n        \"callback\": [callable, None],\n        \"verbose\": [\"verbose\"],\n        \"split_sign\": [\"boolean\"],\n        \"random_state\": [\"random_state\"],\n        \"positive_code\": [\"boolean\"],\n        \"positive_dict\": [\"boolean\"],\n        \"transform_max_iter\": [Interval(Integral, 0, None, closed=\"left\")],\n    }\n\n    def _"}, {"start_line": 33000, "end_line": 35000, "belongs_to": {"file_name": "_dict_learning.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/decomposition", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "umpy as np\n    >>> from sklearn.datasets import make_sparse_coded_signal\n    >>> from sklearn.decomposition import dict_learning\n    >>> X, _, _ = make_sparse_coded_signal(\n    ...     n_samples=30, n_components=15, n_features=20, n_nonzero_coefs=10,\n    ...     random_state=42,\n    ... )\n    >>> U, V, errors = dict_learning(X, n_components=15, alpha=0.1, random_state=42)\n\n    We can check the level of sparsity of `U`:\n\n    >>> np.mean(U == 0)\n    np.float64(0.62)\n\n    We can compare the average squared euclidean norm of the reconstruction\n    error of the sparse coded signal relative to the squared euclidean norm of\n    the original signal:\n\n    >>> X_hat = U @ V\n    >>> np.mean(np.sum((X_hat - X) ** 2, axis=1) / np.sum(X ** 2, axis=1))\n    np.float64(0.0192)\n    \"\"\"\n    estimator = DictionaryLearning(\n        n_components=n_components,\n        alpha=alpha,\n        max_iter=max_iter,\n        tol=tol,\n        fit_algorithm=method,\n        n_jobs=n_jobs,\n        dict_init=dict_init,\n        callback=callback,\n        code_init=code_init,\n        verbose=verbose,\n        random_state=random_state,\n        positive_code=positive_code,\n        positive_dict=positive_dict,\n        transform_max_iter=method_max_iter,\n    ).set_output(transform=\"default\")\n    code = estimator.fit_transform(X)\n    if return_n_iter:\n        return (\n            code,\n            estimator.components_,\n            estimator.error_,\n            estimator.n_iter_,\n        )\n    return code, estimator.components_, estimator.error_\n\n\nclass _BaseSparseCoding(ClassNamePrefixFeaturesOutMixin, TransformerMixin):\n    \"\"\"Base class from SparseCoder and DictionaryLearning algorithms.\"\"\"\n\n    def __init__(\n        self,\n        transform_algorithm,\n        transform_n_nonzero_coefs,\n        transform_alpha,\n        split_sign,\n        n_jobs,\n        positive_code,\n        transform_max_iter,\n    ):\n        self.transform_algorithm = transform_algorithm\n        self.transform_n_nonzero_coefs = transform_"}, {"start_line": 0, "end_line": 2000, "belongs_to": {"file_name": "test_dict_learning.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/decomposition/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "import itertools\nimport warnings\nfrom functools import partial\n\nimport numpy as np\nimport pytest\n\nimport sklearn\nfrom sklearn.base import clone\nfrom sklearn.decomposition import (\n    DictionaryLearning,\n    MiniBatchDictionaryLearning,\n    SparseCoder,\n    dict_learning,\n    dict_learning_online,\n    sparse_encode,\n)\nfrom sklearn.decomposition._dict_learning import _update_dict\nfrom sklearn.exceptions import ConvergenceWarning\nfrom sklearn.utils import check_array\nfrom sklearn.utils._testing import (\n    TempMemmap,\n    assert_allclose,\n    assert_array_almost_equal,\n    assert_array_equal,\n    ignore_warnings,\n)\nfrom sklearn.utils.estimator_checks import (\n    check_transformer_data_not_an_array,\n    check_transformer_general,\n    check_transformers_unfitted,\n)\nfrom sklearn.utils.parallel import Parallel\n\nrng_global = np.random.RandomState(0)\nn_samples, n_features = 10, 8\nX = rng_global.randn(n_samples, n_features)\n\n\ndef test_sparse_encode_shapes_omp():\n    rng = np.random.RandomState(0)\n    algorithms = [\"omp\", \"lasso_lars\", \"lasso_cd\", \"lars\", \"threshold\"]\n    for n_components, n_samples in itertools.product([1, 5], [1, 9]):\n        X_ = rng.randn(n_samples, n_features)\n        dictionary = rng.randn(n_components, n_features)\n        for algorithm, n_jobs in itertools.product(algorithms, [1, 2]):\n            code = sparse_encode(X_, dictionary, algorithm=algorithm, n_jobs=n_jobs)\n            assert code.shape == (n_samples, n_components)\n\n\ndef test_dict_learning_shapes():\n    n_components = 5\n    dico = DictionaryLearning(n_components, random_state=0).fit(X)\n    assert dico.components_.shape == (n_components, n_features)\n\n    n_components = 1\n    dico = DictionaryLearning(n_components, random_state=0).fit(X)\n    assert dico.components_.shape == (n_components, n_features)\n    assert dico.transform(X).shape == (X.shape[0], n_components)\n\n\ndef test_dict_learning_overcomplete():\n    n_components = 12\n    dico = DictionaryLearning(n_components, random_state=0).fit(X)"}, {"start_line": 1000, "end_line": 3000, "belongs_to": {"file_name": "bench_random_projections.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/benchmarks", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": " # stop time\n    time_to_fit = compute_time(t_start, delta)\n\n    # start time\n    t_start = datetime.now()\n    clf.transform(X)\n    delta = datetime.now() - t_start\n    # stop time\n    time_to_transform = compute_time(t_start, delta)\n\n    return time_to_fit, time_to_transform\n\n\n# Make some random data with uniformly located non zero entries with\n# Gaussian distributed values\ndef make_sparse_random_data(n_samples, n_features, n_nonzeros, random_state=None):\n    rng = np.random.RandomState(random_state)\n    data_coo = sp.coo_matrix(\n        (\n            rng.randn(n_nonzeros),\n            (\n                rng.randint(n_samples, size=n_nonzeros),\n                rng.randint(n_features, size=n_nonzeros),\n            ),\n        ),\n        shape=(n_samples, n_features),\n    )\n    return data_coo.toarray(), data_coo.tocsr()\n\n\ndef print_row(clf_type, time_fit, time_transform):\n    print(\n        \"%s | %s | %s\"\n        % (\n            clf_type.ljust(30),\n            (\"%.4fs\" % time_fit).center(12),\n            (\"%.4fs\" % time_transform).center(12),\n        )\n    )\n\n\nif __name__ == \"__main__\":\n    ###########################################################################\n    # Option parser\n    ###########################################################################\n    op = optparse.OptionParser()\n    op.add_option(\n        \"--n-times\",\n        dest=\"n_times\",\n        default=5,\n        type=int,\n        help=\"Benchmark results are average over n_times experiments\",\n    )\n\n    op.add_option(\n        \"--n-features\",\n        dest=\"n_features\",\n        default=10**4,\n        type=int,\n        help=\"Number of features in the benchmarks\",\n    )\n\n    op.add_option(\n        \"--n-components\",\n        dest=\"n_components\",\n        default=\"auto\",\n        help=\"Size of the random subspace. ('auto' or int > 0)\",\n    )\n\n    op.add_option(\n        \"--ratio-nonzeros\",\n        dest=\"ratio_nonzeros\",\n        default=10**-3,\n        type=float,\n        help=\"Number of features in the ben"}, {"start_line": 3000, "end_line": 5000, "belongs_to": {"file_name": "common.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/asv_benchmarks/benchmarks", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "operty\n    @abstractmethod\n    def params(self):\n        pass\n\n\nclass Estimator(ABC):\n    \"\"\"Abstract base class for all benchmarks of estimators\"\"\"\n\n    @abstractmethod\n    def make_data(self, params):\n        \"\"\"Return the dataset for a combination of parameters\"\"\"\n        # The datasets are cached using joblib.Memory so it's fast and can be\n        # called for each repeat\n        pass\n\n    @abstractmethod\n    def make_estimator(self, params):\n        \"\"\"Return an instance of the estimator for a combination of parameters\"\"\"\n        pass\n\n    def skip(self, params):\n        \"\"\"Return True if the benchmark should be skipped for these params\"\"\"\n        return False\n\n    def setup_cache(self):\n        \"\"\"Pickle a fitted estimator for all combinations of parameters\"\"\"\n        # This is run once per benchmark class.\n\n        clear_tmp()\n\n        param_grid = list(itertools.product(*self.params))\n\n        for params in param_grid:\n            if self.skip(params):\n                continue\n\n            estimator = self.make_estimator(params)\n            X, _, y, _ = self.make_data(params)\n\n            estimator.fit(X, y)\n\n            est_path = get_estimator_path(\n                self, Benchmark.save_dir, params, Benchmark.save_estimators\n            )\n            with est_path.open(mode=\"wb\") as f:\n                pickle.dump(estimator, f)\n\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n\n        if self.skip(params):\n            raise NotImplementedError\n\n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n\n        est_path = get_estimator_path(\n            self, Benchmark.save_dir, params, Benchmark.save_estimators\n        )\n        with est_path.open(mode=\"rb\") as f:\n            self.estimator = pickle.load(f)\n\n        self.make_scorers()\n\n    def time_fit(self, *args):\n "}, {"start_line": 34000, "end_line": 36000, "belongs_to": {"file_name": "_dict_learning.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/decomposition", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "     callback=callback,\n        code_init=code_init,\n        verbose=verbose,\n        random_state=random_state,\n        positive_code=positive_code,\n        positive_dict=positive_dict,\n        transform_max_iter=method_max_iter,\n    ).set_output(transform=\"default\")\n    code = estimator.fit_transform(X)\n    if return_n_iter:\n        return (\n            code,\n            estimator.components_,\n            estimator.error_,\n            estimator.n_iter_,\n        )\n    return code, estimator.components_, estimator.error_\n\n\nclass _BaseSparseCoding(ClassNamePrefixFeaturesOutMixin, TransformerMixin):\n    \"\"\"Base class from SparseCoder and DictionaryLearning algorithms.\"\"\"\n\n    def __init__(\n        self,\n        transform_algorithm,\n        transform_n_nonzero_coefs,\n        transform_alpha,\n        split_sign,\n        n_jobs,\n        positive_code,\n        transform_max_iter,\n    ):\n        self.transform_algorithm = transform_algorithm\n        self.transform_n_nonzero_coefs = transform_n_nonzero_coefs\n        self.transform_alpha = transform_alpha\n        self.transform_max_iter = transform_max_iter\n        self.split_sign = split_sign\n        self.n_jobs = n_jobs\n        self.positive_code = positive_code\n\n    def _transform(self, X, dictionary):\n        \"\"\"Private method allowing to accommodate both DictionaryLearning and\n        SparseCoder.\"\"\"\n        X = validate_data(self, X, reset=False)\n\n        if hasattr(self, \"alpha\") and self.transform_alpha is None:\n            transform_alpha = self.alpha\n        else:\n            transform_alpha = self.transform_alpha\n\n        code = sparse_encode(\n            X,\n            dictionary,\n            algorithm=self.transform_algorithm,\n            n_nonzero_coefs=self.transform_n_nonzero_coefs,\n            alpha=transform_alpha,\n            max_iter=self.transform_max_iter,\n            n_jobs=self.n_jobs,\n            positive=self.positive_code,\n        )\n\n        if self.split_sign:\n            # feature vector is split"}], "retrieved_count": 10, "cost_time": 1.1146836280822754}
{"question": "What is the mechanism in the test_mean_shift function that ensures dtype consistency across both the MeanShift class instance and the standalone mean_shift function when processing the same input data with different global_dtype parameters?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"start_line": 2000, "end_line": 4000, "belongs_to": {"file_name": "test_mean_shift.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/cluster/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "pe == global_dtype\n\n    cluster_centers, labels_mean_shift = mean_shift(\n        X_with_global_dtype, cluster_all=cluster_all\n    )\n    labels_mean_shift_unique = np.unique(labels_mean_shift)\n    n_clusters_mean_shift = len(labels_mean_shift_unique)\n    assert n_clusters_mean_shift == expected\n    assert labels_mean_shift_unique[0] == first_cluster_label\n    assert cluster_centers.dtype == global_dtype\n\n\ndef test_parallel(global_dtype, global_random_seed):\n    centers = np.array([[1, 1], [-1, -1], [1, -1]]) + 10\n    X, _ = make_blobs(\n        n_samples=50,\n        n_features=2,\n        centers=centers,\n        cluster_std=0.4,\n        shuffle=True,\n        random_state=global_random_seed,\n    )\n\n    X = X.astype(global_dtype, copy=False)\n\n    ms1 = MeanShift(n_jobs=2)\n    ms1.fit(X)\n\n    ms2 = MeanShift()\n    ms2.fit(X)\n\n    assert_allclose(ms1.cluster_centers_, ms2.cluster_centers_)\n    assert ms1.cluster_centers_.dtype == ms2.cluster_centers_.dtype\n    assert_array_equal(ms1.labels_, ms2.labels_)\n\n\ndef test_meanshift_predict(global_dtype):\n    # Test MeanShift.predict\n    ms = MeanShift(bandwidth=1.2)\n    X_with_global_dtype = X.astype(global_dtype, copy=False)\n    labels = ms.fit_predict(X_with_global_dtype)\n    labels2 = ms.predict(X_with_global_dtype)\n    assert_array_equal(labels, labels2)\n\n\ndef test_meanshift_all_orphans():\n    # init away from the data, crash with a sensible warning\n    ms = MeanShift(bandwidth=0.1, seeds=[[-9, -9], [-10, -10]])\n    msg = \"No point was within bandwidth=0.1\"\n    with pytest.raises(ValueError, match=msg):\n        ms.fit(\n            X,\n        )\n\n\ndef test_unfitted():\n    # Non-regression: before fit, there should be not fitted attributes.\n    ms = MeanShift()\n    assert not hasattr(ms, \"cluster_centers_\")\n    assert not hasattr(ms, \"labels_\")\n\n\ndef test_cluster_intensity_tie(global_dtype):\n    X = np.array([[1, 1], [2, 1], [1, 0], [4, 7], [3, 5], [3, 6]], dtype=global_dtype)\n    c1 = MeanShift(bandwidth=2).fit(X)\n\n    X = np."}, {"start_line": 3000, "end_line": 5000, "belongs_to": {"file_name": "test_mean_shift.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/cluster/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": " ms2.labels_)\n\n\ndef test_meanshift_predict(global_dtype):\n    # Test MeanShift.predict\n    ms = MeanShift(bandwidth=1.2)\n    X_with_global_dtype = X.astype(global_dtype, copy=False)\n    labels = ms.fit_predict(X_with_global_dtype)\n    labels2 = ms.predict(X_with_global_dtype)\n    assert_array_equal(labels, labels2)\n\n\ndef test_meanshift_all_orphans():\n    # init away from the data, crash with a sensible warning\n    ms = MeanShift(bandwidth=0.1, seeds=[[-9, -9], [-10, -10]])\n    msg = \"No point was within bandwidth=0.1\"\n    with pytest.raises(ValueError, match=msg):\n        ms.fit(\n            X,\n        )\n\n\ndef test_unfitted():\n    # Non-regression: before fit, there should be not fitted attributes.\n    ms = MeanShift()\n    assert not hasattr(ms, \"cluster_centers_\")\n    assert not hasattr(ms, \"labels_\")\n\n\ndef test_cluster_intensity_tie(global_dtype):\n    X = np.array([[1, 1], [2, 1], [1, 0], [4, 7], [3, 5], [3, 6]], dtype=global_dtype)\n    c1 = MeanShift(bandwidth=2).fit(X)\n\n    X = np.array([[4, 7], [3, 5], [3, 6], [1, 1], [2, 1], [1, 0]], dtype=global_dtype)\n    c2 = MeanShift(bandwidth=2).fit(X)\n    assert_array_equal(c1.labels_, [1, 1, 1, 0, 0, 0])\n    assert_array_equal(c2.labels_, [0, 0, 0, 1, 1, 1])\n\n\ndef test_bin_seeds(global_dtype):\n    # Test the bin seeding technique which can be used in the mean shift\n    # algorithm\n    # Data is just 6 points in the plane\n    X = np.array(\n        [[1.0, 1.0], [1.4, 1.4], [1.8, 1.2], [2.0, 1.0], [2.1, 1.1], [0.0, 0.0]],\n        dtype=global_dtype,\n    )\n\n    # With a bin coarseness of 1.0 and min_bin_freq of 1, 3 bins should be\n    # found\n    ground_truth = {(1.0, 1.0), (2.0, 1.0), (0.0, 0.0)}\n    test_bins = get_bin_seeds(X, 1, 1)\n    test_result = set(tuple(p) for p in test_bins)\n    assert len(ground_truth.symmetric_difference(test_result)) == 0\n\n    # With a bin coarseness of 1.0 and min_bin_freq of 2, 2 bins should be\n    # found\n    ground_truth = {(1.0, 1.0), (2.0, 1.0)}\n    test_bins = get_bin_seeds(X, 1, 2)\n  "}, {"start_line": 1000, "end_line": 3000, "belongs_to": {"file_name": "test_mean_shift.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/cluster/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "<= 1.5\n\n\ndef test_estimate_bandwidth_1sample(global_dtype):\n    # Test estimate_bandwidth when n_samples=1 and quantile<1, so that\n    # n_neighbors is set to 1.\n    bandwidth = estimate_bandwidth(\n        X.astype(global_dtype, copy=False), n_samples=1, quantile=0.3\n    )\n\n    assert bandwidth.dtype == X.dtype\n    assert bandwidth == pytest.approx(0.0, abs=1e-5)\n\n\n@pytest.mark.parametrize(\n    \"bandwidth, cluster_all, expected, first_cluster_label\",\n    [(1.2, True, 3, 0), (1.2, False, 4, -1)],\n)\ndef test_mean_shift(\n    global_dtype, bandwidth, cluster_all, expected, first_cluster_label\n):\n    # Test MeanShift algorithm\n    X_with_global_dtype = X.astype(global_dtype, copy=False)\n    ms = MeanShift(bandwidth=bandwidth, cluster_all=cluster_all)\n    labels = ms.fit(X_with_global_dtype).labels_\n    labels_unique = np.unique(labels)\n    n_clusters_ = len(labels_unique)\n    assert n_clusters_ == expected\n    assert labels_unique[0] == first_cluster_label\n    assert ms.cluster_centers_.dtype == global_dtype\n\n    cluster_centers, labels_mean_shift = mean_shift(\n        X_with_global_dtype, cluster_all=cluster_all\n    )\n    labels_mean_shift_unique = np.unique(labels_mean_shift)\n    n_clusters_mean_shift = len(labels_mean_shift_unique)\n    assert n_clusters_mean_shift == expected\n    assert labels_mean_shift_unique[0] == first_cluster_label\n    assert cluster_centers.dtype == global_dtype\n\n\ndef test_parallel(global_dtype, global_random_seed):\n    centers = np.array([[1, 1], [-1, -1], [1, -1]]) + 10\n    X, _ = make_blobs(\n        n_samples=50,\n        n_features=2,\n        centers=centers,\n        cluster_std=0.4,\n        shuffle=True,\n        random_state=global_random_seed,\n    )\n\n    X = X.astype(global_dtype, copy=False)\n\n    ms1 = MeanShift(n_jobs=2)\n    ms1.fit(X)\n\n    ms2 = MeanShift()\n    ms2.fit(X)\n\n    assert_allclose(ms1.cluster_centers_, ms2.cluster_centers_)\n    assert ms1.cluster_centers_.dtype == ms2.cluster_centers_.dtype\n    assert_array_equal(ms1.labels_,"}, {"start_line": 0, "end_line": 2000, "belongs_to": {"file_name": "test_mean_shift.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/cluster/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "\"\"\"\nTesting for mean shift clustering methods\n\n\"\"\"\n\nimport warnings\n\nimport numpy as np\nimport pytest\n\nfrom sklearn.cluster import MeanShift, estimate_bandwidth, get_bin_seeds, mean_shift\nfrom sklearn.datasets import make_blobs\nfrom sklearn.metrics import v_measure_score\nfrom sklearn.utils._testing import assert_allclose, assert_array_equal\n\nn_clusters = 3\ncenters = np.array([[1, 1], [-1, -1], [1, -1]]) + 10\nX, _ = make_blobs(\n    n_samples=300,\n    n_features=2,\n    centers=centers,\n    cluster_std=0.4,\n    shuffle=True,\n    random_state=11,\n)\n\n\ndef test_convergence_of_1d_constant_data():\n    # Test convergence using 1D constant data\n    # Non-regression test for:\n    # https://github.com/scikit-learn/scikit-learn/issues/28926\n    model = MeanShift()\n    n_iter = model.fit(np.ones(10).reshape(-1, 1)).n_iter_\n    assert n_iter < model.max_iter\n\n\ndef test_estimate_bandwidth():\n    # Test estimate_bandwidth\n    bandwidth = estimate_bandwidth(X, n_samples=200)\n    assert 0.9 <= bandwidth <= 1.5\n\n\ndef test_estimate_bandwidth_1sample(global_dtype):\n    # Test estimate_bandwidth when n_samples=1 and quantile<1, so that\n    # n_neighbors is set to 1.\n    bandwidth = estimate_bandwidth(\n        X.astype(global_dtype, copy=False), n_samples=1, quantile=0.3\n    )\n\n    assert bandwidth.dtype == X.dtype\n    assert bandwidth == pytest.approx(0.0, abs=1e-5)\n\n\n@pytest.mark.parametrize(\n    \"bandwidth, cluster_all, expected, first_cluster_label\",\n    [(1.2, True, 3, 0), (1.2, False, 4, -1)],\n)\ndef test_mean_shift(\n    global_dtype, bandwidth, cluster_all, expected, first_cluster_label\n):\n    # Test MeanShift algorithm\n    X_with_global_dtype = X.astype(global_dtype, copy=False)\n    ms = MeanShift(bandwidth=bandwidth, cluster_all=cluster_all)\n    labels = ms.fit(X_with_global_dtype).labels_\n    labels_unique = np.unique(labels)\n    n_clusters_ = len(labels_unique)\n    assert n_clusters_ == expected\n    assert labels_unique[0] == first_cluster_label\n    assert ms.cluster_centers_.dty"}, {"start_line": 6000, "end_line": 7081, "belongs_to": {"file_name": "test_mean_shift.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/cluster/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "clusters2)\n\n    for c1, c2 in zip(clusters1, clusters2):\n        assert np.allclose(c1, c2)\n\n\ndef test_mean_shift_zero_bandwidth(global_dtype):\n    # Check that mean shift works when the estimated bandwidth is 0.\n    X = np.array([1, 1, 1, 2, 2, 2, 3, 3], dtype=global_dtype).reshape(-1, 1)\n\n    # estimate_bandwidth with default args returns 0 on this dataset\n    bandwidth = estimate_bandwidth(X)\n    assert bandwidth == 0\n\n    # get_bin_seeds with a 0 bin_size should return the dataset itself\n    assert get_bin_seeds(X, bin_size=bandwidth) is X\n\n    # MeanShift with binning and a 0 estimated bandwidth should be equivalent\n    # to no binning.\n    ms_binning = MeanShift(bin_seeding=True, bandwidth=None).fit(X)\n    ms_nobinning = MeanShift(bin_seeding=False).fit(X)\n    expected_labels = np.array([0, 0, 0, 1, 1, 1, 2, 2])\n\n    assert v_measure_score(ms_binning.labels_, expected_labels) == pytest.approx(1)\n    assert v_measure_score(ms_nobinning.labels_, expected_labels) == pytest.approx(1)\n    assert_allclose(ms_binning.cluster_centers_, ms_nobinning.cluster_centers_)\n"}, {"start_line": 4000, "end_line": 6000, "belongs_to": {"file_name": "test_mean_shift.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/cluster/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "array([[4, 7], [3, 5], [3, 6], [1, 1], [2, 1], [1, 0]], dtype=global_dtype)\n    c2 = MeanShift(bandwidth=2).fit(X)\n    assert_array_equal(c1.labels_, [1, 1, 1, 0, 0, 0])\n    assert_array_equal(c2.labels_, [0, 0, 0, 1, 1, 1])\n\n\ndef test_bin_seeds(global_dtype):\n    # Test the bin seeding technique which can be used in the mean shift\n    # algorithm\n    # Data is just 6 points in the plane\n    X = np.array(\n        [[1.0, 1.0], [1.4, 1.4], [1.8, 1.2], [2.0, 1.0], [2.1, 1.1], [0.0, 0.0]],\n        dtype=global_dtype,\n    )\n\n    # With a bin coarseness of 1.0 and min_bin_freq of 1, 3 bins should be\n    # found\n    ground_truth = {(1.0, 1.0), (2.0, 1.0), (0.0, 0.0)}\n    test_bins = get_bin_seeds(X, 1, 1)\n    test_result = set(tuple(p) for p in test_bins)\n    assert len(ground_truth.symmetric_difference(test_result)) == 0\n\n    # With a bin coarseness of 1.0 and min_bin_freq of 2, 2 bins should be\n    # found\n    ground_truth = {(1.0, 1.0), (2.0, 1.0)}\n    test_bins = get_bin_seeds(X, 1, 2)\n    test_result = set(tuple(p) for p in test_bins)\n    assert len(ground_truth.symmetric_difference(test_result)) == 0\n\n    # With a bin size of 0.01 and min_bin_freq of 1, 6 bins should be found\n    # we bail and use the whole data here.\n    with warnings.catch_warnings(record=True):\n        test_bins = get_bin_seeds(X, 0.01, 1)\n    assert_allclose(test_bins, X)\n\n    # tight clusters around [0, 0] and [1, 1], only get two bins\n    X, _ = make_blobs(\n        n_samples=100,\n        n_features=2,\n        centers=[[0, 0], [1, 1]],\n        cluster_std=0.1,\n        random_state=0,\n    )\n    X = X.astype(global_dtype, copy=False)\n    test_bins = get_bin_seeds(X, 1)\n    assert_array_equal(test_bins, [[0, 0], [1, 1]])\n\n\n@pytest.mark.parametrize(\"max_iter\", [1, 100])\ndef test_max_iter(max_iter):\n    clusters1, _ = mean_shift(X, max_iter=max_iter)\n    ms = MeanShift(max_iter=max_iter).fit(X)\n    clusters2 = ms.cluster_centers_\n\n    assert ms.n_iter_ <= ms.max_iter\n    assert len(clusters1) == len("}, {"start_line": 5000, "end_line": 7000, "belongs_to": {"file_name": "test_mean_shift.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/cluster/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "  test_result = set(tuple(p) for p in test_bins)\n    assert len(ground_truth.symmetric_difference(test_result)) == 0\n\n    # With a bin size of 0.01 and min_bin_freq of 1, 6 bins should be found\n    # we bail and use the whole data here.\n    with warnings.catch_warnings(record=True):\n        test_bins = get_bin_seeds(X, 0.01, 1)\n    assert_allclose(test_bins, X)\n\n    # tight clusters around [0, 0] and [1, 1], only get two bins\n    X, _ = make_blobs(\n        n_samples=100,\n        n_features=2,\n        centers=[[0, 0], [1, 1]],\n        cluster_std=0.1,\n        random_state=0,\n    )\n    X = X.astype(global_dtype, copy=False)\n    test_bins = get_bin_seeds(X, 1)\n    assert_array_equal(test_bins, [[0, 0], [1, 1]])\n\n\n@pytest.mark.parametrize(\"max_iter\", [1, 100])\ndef test_max_iter(max_iter):\n    clusters1, _ = mean_shift(X, max_iter=max_iter)\n    ms = MeanShift(max_iter=max_iter).fit(X)\n    clusters2 = ms.cluster_centers_\n\n    assert ms.n_iter_ <= ms.max_iter\n    assert len(clusters1) == len(clusters2)\n\n    for c1, c2 in zip(clusters1, clusters2):\n        assert np.allclose(c1, c2)\n\n\ndef test_mean_shift_zero_bandwidth(global_dtype):\n    # Check that mean shift works when the estimated bandwidth is 0.\n    X = np.array([1, 1, 1, 2, 2, 2, 3, 3], dtype=global_dtype).reshape(-1, 1)\n\n    # estimate_bandwidth with default args returns 0 on this dataset\n    bandwidth = estimate_bandwidth(X)\n    assert bandwidth == 0\n\n    # get_bin_seeds with a 0 bin_size should return the dataset itself\n    assert get_bin_seeds(X, bin_size=bandwidth) is X\n\n    # MeanShift with binning and a 0 estimated bandwidth should be equivalent\n    # to no binning.\n    ms_binning = MeanShift(bin_seeding=True, bandwidth=None).fit(X)\n    ms_nobinning = MeanShift(bin_seeding=False).fit(X)\n    expected_labels = np.array([0, 0, 0, 1, 1, 1, 2, 2])\n\n    assert v_measure_score(ms_binning.labels_, expected_labels) == pytest.approx(1)\n    assert v_measure_score(ms_nobinning.labels_, expected_labels) == pytest.approx(1)"}, {"start_line": 28000, "end_line": 30000, "belongs_to": {"file_name": "test_k_means.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/cluster/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "[dtype] = km.inertia_\n        Xt[dtype] = km.transform(X)\n        centers[dtype] = km.cluster_centers_\n        labels[dtype] = km.labels_\n\n        # dtype of cluster centers has to be the dtype of the input data\n        assert km.cluster_centers_.dtype == dtype\n\n        # same with partial_fit\n        if Estimator is MiniBatchKMeans:\n            km.partial_fit(X[0:3])\n            assert km.cluster_centers_.dtype == dtype\n\n    # compare arrays with low precision since the difference between 32 and\n    # 64 bit comes from an accumulation of rounding errors.\n    assert_allclose(inertia[np.float32], inertia[np.float64], rtol=1e-4)\n    assert_allclose(Xt[np.float32], Xt[np.float64], atol=Xt[np.float64].max() * 1e-4)\n    assert_allclose(\n        centers[np.float32], centers[np.float64], atol=centers[np.float64].max() * 1e-4\n    )\n    assert_array_equal(labels[np.float32], labels[np.float64])\n\n\n@pytest.mark.parametrize(\"dtype\", [np.int32, np.int64, np.float32, np.float64])\n@pytest.mark.parametrize(\"Estimator\", [KMeans, MiniBatchKMeans])\ndef test_centers_not_mutated(Estimator, dtype):\n    # Check that KMeans and MiniBatchKMeans won't mutate the user provided\n    # init centers silently even if input data and init centers have the same\n    # type.\n    X_new_type = X.astype(dtype, copy=False)\n    centers_new_type = centers.astype(dtype, copy=False)\n\n    km = Estimator(init=centers_new_type, n_clusters=n_clusters, n_init=1)\n    km.fit(X_new_type)\n\n    assert not np.may_share_memory(km.cluster_centers_, centers_new_type)\n\n\n@pytest.mark.parametrize(\n    \"input_data\",\n    [X] + X_as_any_csr,\n    ids=data_containers_ids,\n)\ndef test_kmeans_init_fitted_centers(input_data):\n    # Check that starting fitting from a local optimum shouldn't change the\n    # solution\n    km1 = KMeans(n_clusters=n_clusters).fit(input_data)\n    km2 = KMeans(n_clusters=n_clusters, init=km1.cluster_centers_, n_init=1).fit(\n        input_data\n    )\n\n    assert_allclose(km1.cluster_centers_, km2.cluster_center"}, {"start_line": 27000, "end_line": 29000, "belongs_to": {"file_name": "test_k_means.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/cluster/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "ans function directly\n    cluster_centers, labels, inertia = k_means(\n        X, n_clusters=n_clusters, sample_weight=None, random_state=global_random_seed\n    )\n\n    assert cluster_centers.shape == (n_clusters, n_features)\n    assert np.unique(labels).shape[0] == n_clusters\n\n    # check that the labels assignment are perfect (up to a permutation)\n    assert_allclose(v_measure_score(true_labels, labels), 1.0)\n    assert inertia > 0.0\n\n\n@pytest.mark.parametrize(\n    \"input_data\",\n    [X] + X_as_any_csr,\n    ids=data_containers_ids,\n)\n@pytest.mark.parametrize(\"Estimator\", [KMeans, MiniBatchKMeans])\ndef test_float_precision(Estimator, input_data, global_random_seed):\n    # Check that the results are the same for single and double precision.\n    km = Estimator(n_init=1, random_state=global_random_seed)\n\n    inertia = {}\n    Xt = {}\n    centers = {}\n    labels = {}\n\n    for dtype in [np.float64, np.float32]:\n        X = input_data.astype(dtype, copy=False)\n        km.fit(X)\n\n        inertia[dtype] = km.inertia_\n        Xt[dtype] = km.transform(X)\n        centers[dtype] = km.cluster_centers_\n        labels[dtype] = km.labels_\n\n        # dtype of cluster centers has to be the dtype of the input data\n        assert km.cluster_centers_.dtype == dtype\n\n        # same with partial_fit\n        if Estimator is MiniBatchKMeans:\n            km.partial_fit(X[0:3])\n            assert km.cluster_centers_.dtype == dtype\n\n    # compare arrays with low precision since the difference between 32 and\n    # 64 bit comes from an accumulation of rounding errors.\n    assert_allclose(inertia[np.float32], inertia[np.float64], rtol=1e-4)\n    assert_allclose(Xt[np.float32], Xt[np.float64], atol=Xt[np.float64].max() * 1e-4)\n    assert_allclose(\n        centers[np.float32], centers[np.float64], atol=centers[np.float64].max() * 1e-4\n    )\n    assert_array_equal(labels[np.float32], labels[np.float64])\n\n\n@pytest.mark.parametrize(\"dtype\", [np.int32, np.int64, np.float32, np.float64])\n@pytest.mark.parame"}, {"start_line": 25000, "end_line": 27000, "belongs_to": {"file_name": "test_k_means.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/cluster/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "_centers_.dtype == np.float64\n\n    expected_labels = [0, 1, 1, 0, 0, 1]\n    assert_allclose(v_measure_score(km.labels_, expected_labels), 1.0)\n\n    # Same with partial_fit (#14314)\n    if Estimator is MiniBatchKMeans:\n        km = clone(km).partial_fit(X)\n        assert km.cluster_centers_.dtype == np.float64\n\n\n@pytest.mark.parametrize(\"Estimator\", [KMeans, MiniBatchKMeans])\ndef test_transform(Estimator, global_random_seed):\n    # Check the transform method\n    km = Estimator(n_clusters=n_clusters, random_state=global_random_seed).fit(X)\n\n    # Transorfming cluster_centers_ should return the pairwise distances\n    # between centers\n    Xt = km.transform(km.cluster_centers_)\n    assert_allclose(Xt, pairwise_distances(km.cluster_centers_))\n    # In particular, diagonal must be 0\n    assert_array_equal(Xt.diagonal(), np.zeros(n_clusters))\n\n    # Transorfming X should return the pairwise distances between X and the\n    # centers\n    Xt = km.transform(X)\n    assert_allclose(Xt, pairwise_distances(X, km.cluster_centers_))\n\n\n@pytest.mark.parametrize(\"Estimator\", [KMeans, MiniBatchKMeans])\ndef test_fit_transform(Estimator, global_random_seed):\n    # Check equivalence between fit.transform and fit_transform\n    X1 = Estimator(random_state=global_random_seed, n_init=1).fit(X).transform(X)\n    X2 = Estimator(random_state=global_random_seed, n_init=1).fit_transform(X)\n    assert_allclose(X1, X2)\n\n\ndef test_n_init(global_random_seed):\n    # Check that increasing the number of init increases the quality\n    previous_inertia = np.inf\n    for n_init in [1, 5, 10]:\n        # set max_iter=1 to avoid finding the global minimum and get the same\n        # inertia each time\n        km = KMeans(\n            n_clusters=n_clusters,\n            init=\"random\",\n            n_init=n_init,\n            random_state=global_random_seed,\n            max_iter=1,\n        ).fit(X)\n        assert km.inertia_ <= previous_inertia\n\n\ndef test_k_means_function(global_random_seed):\n    # test calling the k_me"}], "retrieved_count": 10, "cost_time": 1.1455109119415283}
{"question": "What is the dependency resolution mechanism in _parallel_predict_regression that handles the estimator.predict method across heterogeneous base estimators with different feature selection requirements, and what internal module dependencies enable this polymorphic behavior?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"start_line": 10000, "end_line": 12000, "belongs_to": {"file_name": "multioutput.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "_outputs)\n            Multi-output targets predicted across multiple predictors.\n            Note: Separate models are generated for each predictor.\n        \"\"\"\n        check_is_fitted(self)\n        if not hasattr(self.estimators_[0], \"predict\"):\n            raise ValueError(\"The base estimator should implement a predict method\")\n\n        y = Parallel(n_jobs=self.n_jobs)(\n            delayed(e.predict)(X) for e in self.estimators_\n        )\n\n        return np.asarray(y).T\n\n    def __sklearn_tags__(self):\n        tags = super().__sklearn_tags__()\n        tags.input_tags.sparse = get_tags(self.estimator).input_tags.sparse\n        tags.target_tags.single_output = False\n        tags.target_tags.multi_output = True\n        return tags\n\n    def get_metadata_routing(self):\n        \"\"\"Get metadata routing of this object.\n\n        Please check :ref:`User Guide <metadata_routing>` on how the routing\n        mechanism works.\n\n        .. versionadded:: 1.3\n\n        Returns\n        -------\n        routing : MetadataRouter\n            A :class:`~sklearn.utils.metadata_routing.MetadataRouter` encapsulating\n            routing information.\n        \"\"\"\n        router = MetadataRouter(owner=self.__class__.__name__).add(\n            estimator=self.estimator,\n            method_mapping=MethodMapping()\n            .add(caller=\"partial_fit\", callee=\"partial_fit\")\n            .add(caller=\"fit\", callee=\"fit\"),\n        )\n        return router\n\n\nclass MultiOutputRegressor(RegressorMixin, _MultiOutputEstimator):\n    \"\"\"Multi target regression.\n\n    This strategy consists of fitting one regressor per target. This is a\n    simple strategy for extending regressors that do not natively support\n    multi-target regression.\n\n    .. versionadded:: 0.18\n\n    Parameters\n    ----------\n    estimator : estimator object\n        An estimator object implementing :term:`fit` and :term:`predict`.\n\n    n_jobs : int or None, optional (default=None)\n        The number of jobs to run in parallel.\n        :meth:`"}, {"start_line": 36000, "end_line": 38000, "belongs_to": {"file_name": "_forest.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/ensemble", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "asses\n    instead.\n    \"\"\"\n\n    @abstractmethod\n    def __init__(\n        self,\n        estimator,\n        n_estimators=100,\n        *,\n        estimator_params=tuple(),\n        bootstrap=False,\n        oob_score=False,\n        n_jobs=None,\n        random_state=None,\n        verbose=0,\n        warm_start=False,\n        max_samples=None,\n    ):\n        super().__init__(\n            estimator,\n            n_estimators=n_estimators,\n            estimator_params=estimator_params,\n            bootstrap=bootstrap,\n            oob_score=oob_score,\n            n_jobs=n_jobs,\n            random_state=random_state,\n            verbose=verbose,\n            warm_start=warm_start,\n            max_samples=max_samples,\n        )\n\n    def predict(self, X):\n        \"\"\"\n        Predict regression target for X.\n\n        The predicted regression target of an input sample is computed as the\n        mean predicted regression targets of the trees in the forest.\n\n        Parameters\n        ----------\n        X : {array-like, sparse matrix} of shape (n_samples, n_features)\n            The input samples. Internally, its dtype will be converted to\n            ``dtype=np.float32``. If a sparse matrix is provided, it will be\n            converted into a sparse ``csr_matrix``.\n\n        Returns\n        -------\n        y : ndarray of shape (n_samples,) or (n_samples, n_outputs)\n            The predicted values.\n        \"\"\"\n        check_is_fitted(self)\n        # Check data\n        X = self._validate_X_predict(X)\n\n        # Assign chunk of trees to jobs\n        n_jobs, _, _ = _partition_estimators(self.n_estimators, self.n_jobs)\n\n        # avoid storing the output of every estimator by summing them here\n        if self.n_outputs_ > 1:\n            y_hat = np.zeros((X.shape[0], self.n_outputs_), dtype=np.float64)\n        else:\n            y_hat = np.zeros((X.shape[0]), dtype=np.float64)\n\n        # Parallel loop\n        lock = threading.Lock()\n        Parallel(n_jobs=n_jobs, verbose=self.verbose, requ"}, {"start_line": 1000, "end_line": 3000, "belongs_to": {"file_name": "multioutput.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "uter,\n    MethodMapping,\n    _raise_for_params,\n    _routing_enabled,\n    process_routing,\n)\nfrom sklearn.utils.metaestimators import available_if\nfrom sklearn.utils.multiclass import check_classification_targets\nfrom sklearn.utils.parallel import Parallel, delayed\nfrom sklearn.utils.validation import (\n    _check_method_params,\n    _check_response_method,\n    check_is_fitted,\n    has_fit_parameter,\n    validate_data,\n)\n\n__all__ = [\n    \"ClassifierChain\",\n    \"MultiOutputClassifier\",\n    \"MultiOutputRegressor\",\n    \"RegressorChain\",\n]\n\n\ndef _fit_estimator(estimator, X, y, sample_weight=None, **fit_params):\n    estimator = clone(estimator)\n    if sample_weight is not None:\n        estimator.fit(X, y, sample_weight=sample_weight, **fit_params)\n    else:\n        estimator.fit(X, y, **fit_params)\n    return estimator\n\n\ndef _partial_fit_estimator(\n    estimator, X, y, classes=None, partial_fit_params=None, first_time=True\n):\n    partial_fit_params = {} if partial_fit_params is None else partial_fit_params\n    if first_time:\n        estimator = clone(estimator)\n\n    if classes is not None:\n        estimator.partial_fit(X, y, classes=classes, **partial_fit_params)\n    else:\n        estimator.partial_fit(X, y, **partial_fit_params)\n    return estimator\n\n\ndef _available_if_estimator_has(attr):\n    \"\"\"Return a function to check if the sub-estimator(s) has(have) `attr`.\n\n    Helper for Chain implementations.\n    \"\"\"\n\n    def _check(self):\n        if hasattr(self, \"estimators_\"):\n            return all(hasattr(est, attr) for est in self.estimators_)\n\n        if hasattr(self.estimator, attr):\n            return True\n\n        return False\n\n    return available_if(_check)\n\n\nclass _MultiOutputEstimator(MetaEstimatorMixin, BaseEstimator, metaclass=ABCMeta):\n    _parameter_constraints: dict = {\n        \"estimator\": [HasMethods([\"fit\", \"predict\"])],\n        \"n_jobs\": [Integral, None],\n    }\n\n    @abstractmethod\n    def __init__(self, estimator, *, n_jobs=None):\n        self.estimator "}, {"start_line": 5000, "end_line": 7000, "belongs_to": {"file_name": "_bagging.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/ensemble", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "refore, use this method\n        # if possible, otherwise use indexing.\n        if consumes_sample_weight:\n            # Row sampling by setting sample_weight\n            indices_as_sample_weight = np.bincount(indices, minlength=n_samples)\n            fit_params_[\"sample_weight\"] = indices_as_sample_weight\n            X_ = X[:, features] if requires_feature_indexing else X\n            estimator_fit(X_, y, **fit_params_)\n        else:\n            # Row sampling by indexing\n            y_ = _safe_indexing(y, indices)\n            X_ = _safe_indexing(X, indices)\n            fit_params_ = _check_method_params(X, params=fit_params_, indices=indices)\n            if requires_feature_indexing:\n                X_ = X_[:, features]\n            estimator_fit(X_, y_, **fit_params_)\n\n        estimators.append(estimator)\n        estimators_features.append(features)\n\n    return estimators, estimators_features\n\n\ndef _parallel_predict_proba(\n    estimators,\n    estimators_features,\n    X,\n    n_classes,\n    predict_params=None,\n    predict_proba_params=None,\n):\n    \"\"\"Private function used to compute (proba-)predictions within a job.\"\"\"\n    n_samples = X.shape[0]\n    proba = np.zeros((n_samples, n_classes))\n\n    for estimator, features in zip(estimators, estimators_features):\n        if hasattr(estimator, \"predict_proba\"):\n            proba_estimator = estimator.predict_proba(\n                X[:, features], **(predict_params or {})\n            )\n\n            if n_classes == len(estimator.classes_):\n                proba += proba_estimator\n\n            else:\n                proba[:, estimator.classes_] += proba_estimator[\n                    :, range(len(estimator.classes_))\n                ]\n\n        else:\n            # Resort to voting\n            predictions = estimator.predict(\n                X[:, features], **(predict_proba_params or {})\n            )\n\n            for i in range(n_samples):\n                proba[i, predictions[i]] += 1\n\n    return proba\n\n\ndef _parallel_predict_l"}, {"start_line": 51000, "end_line": 53000, "belongs_to": {"file_name": "_bagging.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/ensemble", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "     \"\"\"\n        _raise_for_params(params, self, \"predict\")\n\n        check_is_fitted(self)\n        # Check data\n        X = validate_data(\n            self,\n            X,\n            accept_sparse=[\"csr\", \"csc\"],\n            dtype=None,\n            ensure_all_finite=False,\n            reset=False,\n        )\n\n        if _routing_enabled():\n            routed_params = process_routing(self, \"predict\", **params)\n        else:\n            routed_params = Bunch()\n            routed_params.estimator = Bunch(predict=Bunch())\n\n        # Parallel loop\n        n_jobs, _, starts = _partition_estimators(self.n_estimators, self.n_jobs)\n\n        all_y_hat = Parallel(n_jobs=n_jobs, verbose=self.verbose)(\n            delayed(_parallel_predict_regression)(\n                self.estimators_[starts[i] : starts[i + 1]],\n                self.estimators_features_[starts[i] : starts[i + 1]],\n                X,\n                params=routed_params.estimator.predict,\n            )\n            for i in range(n_jobs)\n        )\n\n        # Reduce\n        y_hat = sum(all_y_hat) / self.n_estimators\n\n        return y_hat\n\n    def _set_oob_score(self, X, y):\n        n_samples = y.shape[0]\n\n        predictions = np.zeros((n_samples,))\n        n_predictions = np.zeros((n_samples,))\n\n        for estimator, samples, features in zip(\n            self.estimators_, self.estimators_samples_, self.estimators_features_\n        ):\n            # Create mask for OOB samples\n            mask = ~indices_to_mask(samples, n_samples)\n\n            predictions[mask] += estimator.predict((X[mask, :])[:, features])\n            n_predictions[mask] += 1\n\n        if (n_predictions == 0).any():\n            warn(\n                \"Some inputs do not have OOB scores. \"\n                \"This probably means too few estimators were used \"\n                \"to compute any reliable oob estimates.\"\n            )\n            n_predictions[n_predictions == 0] = 1\n\n        predictions /= n_predictions\n\n        self.oob_prediction_ = pred"}, {"start_line": 11000, "end_line": 13000, "belongs_to": {"file_name": "metadata_routing_common.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "        return 1\n\n\nclass ConsumingClassifierWithoutPredictProba(ConsumingClassifier):\n    \"\"\"ConsumingClassifier without a predict_proba method, but with predict_log_proba.\n\n    Used to mimic dynamic method selection such as in the `_parallel_predict_proba()`\n    function called by `BaggingClassifier`.\n    \"\"\"\n\n    @property\n    def predict_proba(self):\n        raise AttributeError(\"This estimator does not support predict_proba\")\n\n\nclass ConsumingClassifierWithoutPredictLogProba(ConsumingClassifier):\n    \"\"\"ConsumingClassifier without a predict_log_proba method, but with predict_proba.\n\n    Used to mimic dynamic method selection such as in\n    `BaggingClassifier.predict_log_proba()`.\n    \"\"\"\n\n    @property\n    def predict_log_proba(self):\n        raise AttributeError(\"This estimator does not support predict_log_proba\")\n\n\nclass ConsumingClassifierWithOnlyPredict(ConsumingClassifier):\n    \"\"\"ConsumingClassifier with only a predict method.\n\n    Used to mimic dynamic method selection such as in\n    `BaggingClassifier.predict_log_proba()`.\n    \"\"\"\n\n    @property\n    def predict_proba(self):\n        raise AttributeError(\"This estimator does not support predict_proba\")\n\n    @property\n    def predict_log_proba(self):\n        raise AttributeError(\"This estimator does not support predict_log_proba\")\n\n\nclass ConsumingTransformer(TransformerMixin, BaseEstimator):\n    \"\"\"A transformer which accepts metadata on fit and transform.\n\n    Parameters\n    ----------\n    registry : list, default=None\n        If a list, the estimator will append itself to the list in order to have\n        a reference to the estimator later on. Since that reference is not\n        required in all tests, registration can be skipped by leaving this value\n        as None.\n    \"\"\"\n\n    def __init__(self, registry=None):\n        self.registry = registry\n\n    def fit(self, X, y=None, sample_weight=\"default\", metadata=\"default\"):\n        if self.registry is not None:\n            self.registry.append(self)\n\n      "}, {"start_line": 23000, "end_line": 24916, "belongs_to": {"file_name": "_voting.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/ensemble", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "ow=[\"sample_weight\"])\n\n        y = column_or_1d(y, warn=True)\n\n        return super().fit(X, y, **fit_params)\n\n    def predict(self, X):\n        \"\"\"Predict regression target for X.\n\n        The predicted regression target of an input sample is computed as the\n        mean predicted regression targets of the estimators in the ensemble.\n\n        Parameters\n        ----------\n        X : {array-like, sparse matrix} of shape (n_samples, n_features)\n            The input samples.\n\n        Returns\n        -------\n        y : ndarray of shape (n_samples,)\n            The predicted values.\n        \"\"\"\n        check_is_fitted(self)\n        return np.average(self._predict(X), axis=1, weights=self._weights_not_none)\n\n    def transform(self, X):\n        \"\"\"Return predictions for X for each estimator.\n\n        Parameters\n        ----------\n        X : {array-like, sparse matrix} of shape (n_samples, n_features)\n            The input samples.\n\n        Returns\n        -------\n        predictions : ndarray of shape (n_samples, n_classifiers)\n            Values predicted by each regressor.\n        \"\"\"\n        check_is_fitted(self)\n        return self._predict(X)\n\n    def get_feature_names_out(self, input_features=None):\n        \"\"\"Get output feature names for transformation.\n\n        Parameters\n        ----------\n        input_features : array-like of str or None, default=None\n            Not used, present here for API consistency by convention.\n\n        Returns\n        -------\n        feature_names_out : ndarray of str objects\n            Transformed feature names.\n        \"\"\"\n        check_is_fitted(self, \"n_features_in_\")\n        _check_feature_names_in(self, input_features, generate_names=False)\n        class_name = self.__class__.__name__.lower()\n        return np.asarray(\n            [f\"{class_name}_{name}\" for name, est in self.estimators if est != \"drop\"],\n            dtype=object,\n        )\n"}, {"start_line": 14000, "end_line": 16000, "belongs_to": {"file_name": "_partial_dependence.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/inspection", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "        averaged_predictions.append(np.average(pred, axis=0, weights=sample_weight))\n\n    n_samples = X.shape[0]\n\n    # reshape to (n_targets, n_instances, n_points) where n_targets is:\n    # - 1 for non-multioutput regression and binary classification (shape is\n    #   already correct in those cases)\n    # - n_tasks for multi-output regression\n    # - n_classes for multiclass classification.\n    predictions = np.array(predictions).T\n    if is_regressor(est) and predictions.ndim == 2:\n        # non-multioutput regression, shape is (n_instances, n_points,)\n        predictions = predictions.reshape(n_samples, -1)\n    elif is_classifier(est) and predictions.shape[0] == 2:\n        # Binary classification, shape is (2, n_instances, n_points).\n        # we output the effect of **positive** class\n        predictions = predictions[1]\n        predictions = predictions.reshape(n_samples, -1)\n\n    # reshape averaged_predictions to (n_targets, n_points) where n_targets is:\n    # - 1 for non-multioutput regression and binary classification (shape is\n    #   already correct in those cases)\n    # - n_tasks for multi-output regression\n    # - n_classes for multiclass classification.\n    averaged_predictions = np.array(averaged_predictions).T\n    if averaged_predictions.ndim == 1:\n        # reshape to (1, n_points) for consistency with\n        # _partial_dependence_recursion\n        averaged_predictions = averaged_predictions.reshape(1, -1)\n\n    return averaged_predictions, predictions\n\n\n@validate_params(\n    {\n        \"estimator\": [\n            HasMethods([\"fit\", \"predict\"]),\n            HasMethods([\"fit\", \"predict_proba\"]),\n            HasMethods([\"fit\", \"decision_function\"]),\n        ],\n        \"X\": [\"array-like\", \"sparse matrix\"],\n        \"features\": [\"array-like\", Integral, str],\n        \"sample_weight\": [\"array-like\", None],\n        \"categorical_features\": [\"array-like\", None],\n        \"feature_names\": [\"array-like\", None],\n        \"response_method\": [StrOptions({\"auto\", \"pred"}, {"start_line": 16000, "end_line": 18000, "belongs_to": {"file_name": "multiclass.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "         partial_fit_params=routed_params.estimator.partial_fit,\n            )\n            for estimator, column in zip(self.estimators_, columns)\n        )\n\n        if hasattr(self.estimators_[0], \"n_features_in_\"):\n            self.n_features_in_ = self.estimators_[0].n_features_in_\n\n        return self\n\n    def predict(self, X):\n        \"\"\"Predict multi-class targets using underlying estimators.\n\n        Parameters\n        ----------\n        X : {array-like, sparse matrix} of shape (n_samples, n_features)\n            Data.\n\n        Returns\n        -------\n        y : {array-like, sparse matrix} of shape (n_samples,) or (n_samples, n_classes)\n            Predicted multi-class targets.\n        \"\"\"\n        check_is_fitted(self)\n\n        n_samples = _num_samples(X)\n        if self.label_binarizer_.y_type_ == \"multiclass\":\n            maxima = np.empty(n_samples, dtype=float)\n            maxima.fill(-np.inf)\n            argmaxima = np.zeros(n_samples, dtype=int)\n            n_classes = len(self.estimators_)\n            # Iterate in reverse order to match np.argmax tie-breaking behavior\n            for i, e in enumerate(reversed(self.estimators_)):\n                pred = _predict_binary(e, X)\n                np.maximum(maxima, pred, out=maxima)\n                argmaxima[maxima == pred] = n_classes - i - 1\n            return self.classes_[argmaxima]\n        else:\n            thresh = _threshold_for_binary_predict(self.estimators_[0])\n            indices = array.array(\"i\")\n            indptr = array.array(\"i\", [0])\n            for e in self.estimators_:\n                indices.extend(np.where(_predict_binary(e, X) > thresh)[0])\n                indptr.append(len(indices))\n            data = np.ones(len(indices), dtype=int)\n            indicator = sp.csc_matrix(\n                (data, indices, indptr), shape=(n_samples, len(self.estimators_))\n            )\n            return self.label_binarizer_.inverse_transform(indicator)\n\n    @available_if(_estimators_has(\"predict_prob"}, {"start_line": 21000, "end_line": 23000, "belongs_to": {"file_name": "multioutput.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "r of outputs of Y for fit {0} and\"\n                \" score {1} should be same\".format(n_outputs_, y.shape[1])\n            )\n        y_pred = self.predict(X)\n        return np.mean(np.all(y == y_pred, axis=1))\n\n    def __sklearn_tags__(self):\n        tags = super().__sklearn_tags__()\n        # FIXME\n        tags._skip_test = True\n        return tags\n\n\ndef _available_if_base_estimator_has(attr):\n    \"\"\"Return a function to check if `base_estimator` or `estimators_` has `attr`.\n\n    Helper for Chain implementations.\n    \"\"\"\n\n    def _check(self):\n        return hasattr(self._get_estimator(), attr) or all(\n            hasattr(est, attr) for est in self.estimators_\n        )\n\n    return available_if(_check)\n\n\nclass _BaseChain(BaseEstimator, metaclass=ABCMeta):\n    _parameter_constraints: dict = {\n        \"base_estimator\": [\n            HasMethods([\"fit\", \"predict\"]),\n            StrOptions({\"deprecated\"}),\n        ],\n        \"estimator\": [\n            HasMethods([\"fit\", \"predict\"]),\n            Hidden(None),\n        ],\n        \"order\": [\"array-like\", StrOptions({\"random\"}), None],\n        \"cv\": [\"cv_object\", StrOptions({\"prefit\"})],\n        \"random_state\": [\"random_state\"],\n        \"verbose\": [\"boolean\"],\n    }\n\n    # TODO(1.9): Remove base_estimator\n    def __init__(\n        self,\n        estimator=None,\n        *,\n        order=None,\n        cv=None,\n        random_state=None,\n        verbose=False,\n        base_estimator=\"deprecated\",\n    ):\n        self.estimator = estimator\n        self.base_estimator = base_estimator\n        self.order = order\n        self.cv = cv\n        self.random_state = random_state\n        self.verbose = verbose\n\n    # TODO(1.8): This is a temporary getter method to validate input wrt deprecation.\n    # It was only included to avoid relying on the presence of self.estimator_\n    def _get_estimator(self):\n        \"\"\"Get and validate estimator.\"\"\"\n\n        if self.estimator is not None and (self.base_estimator != \"deprecated\"):\n            rais"}], "retrieved_count": 10, "cost_time": 1.1391432285308838}
{"question": "How does the shrink_threshold parameter implementation in the fit method employ soft thresholding to achieve feature selection, and what data consistency guarantees must be maintained between the deviations_ and centroids_ attributes during this transformation?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"start_line": 8000, "end_line": 10000, "belongs_to": {"file_name": "_nearest_centroid.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/neighbors", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "       self.centroids_[cur_class] = np.median(X[center_mask], axis=0)\n                else:\n                    self.centroids_[cur_class] = csc_median_axis_0(X[center_mask])\n            else:  # metric == \"euclidean\"\n                self.centroids_[cur_class] = X[center_mask].mean(axis=0)\n\n        # Compute within-class std_dev with unshrunked centroids\n        variance = np.array(X - self.centroids_[y_ind], copy=False) ** 2\n        self.within_class_std_dev_ = np.array(\n            np.sqrt(variance.sum(axis=0) / (n_samples - n_classes)), copy=False\n        )\n        if any(self.within_class_std_dev_ == 0):\n            warnings.warn(\n                \"self.within_class_std_dev_ has at least 1 zero standard deviation.\"\n                \"Inputs within the same classes for at least 1 feature are identical.\"\n            )\n\n        err_msg = \"All features have zero variance. Division by zero.\"\n        if is_X_sparse and np.all((X.max(axis=0) - X.min(axis=0)).toarray() == 0):\n            raise ValueError(err_msg)\n        elif not is_X_sparse and np.all(np.ptp(X, axis=0) == 0):\n            raise ValueError(err_msg)\n\n        dataset_centroid_ = X.mean(axis=0)\n        # m parameter for determining deviation\n        m = np.sqrt((1.0 / nk) - (1.0 / n_samples))\n        # Calculate deviation using the standard deviation of centroids.\n        # To deter outliers from affecting the results.\n        s = self.within_class_std_dev_ + np.median(self.within_class_std_dev_)\n        mm = m.reshape(len(m), 1)  # Reshape to allow broadcasting.\n        ms = mm * s\n        self.deviations_ = np.array(\n            (self.centroids_ - dataset_centroid_) / ms, copy=False\n        )\n        # Soft thresholding: if the deviation crosses 0 during shrinking,\n        # it becomes zero.\n        if self.shrink_threshold:\n            signs = np.sign(self.deviations_)\n            self.deviations_ = np.abs(self.deviations_) - self.shrink_threshold\n            np.clip(self.deviations_, 0, None, out=self.devi"}, {"start_line": 8000, "end_line": 10000, "belongs_to": {"file_name": "_shrunk_covariance.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/covariance", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "nkCovariance().fit(X)\n    >>> cov.covariance_\n    array([[0.7387, 0.2536],\n           [0.2536, 0.4110]])\n    >>> cov.location_\n    array([0.0622, 0.0193])\n    \"\"\"\n\n    _parameter_constraints: dict = {\n        **EmpiricalCovariance._parameter_constraints,\n        \"shrinkage\": [Interval(Real, 0, 1, closed=\"both\")],\n    }\n\n    def __init__(self, *, store_precision=True, assume_centered=False, shrinkage=0.1):\n        super().__init__(\n            store_precision=store_precision, assume_centered=assume_centered\n        )\n        self.shrinkage = shrinkage\n\n    @_fit_context(prefer_skip_nested_validation=True)\n    def fit(self, X, y=None):\n        \"\"\"Fit the shrunk covariance model to X.\n\n        Parameters\n        ----------\n        X : array-like of shape (n_samples, n_features)\n            Training data, where `n_samples` is the number of samples\n            and `n_features` is the number of features.\n\n        y : Ignored\n            Not used, present for API consistency by convention.\n\n        Returns\n        -------\n        self : object\n            Returns the instance itself.\n        \"\"\"\n        X = validate_data(self, X)\n        # Not calling the parent object to fit, to avoid a potential\n        # matrix inversion when setting the precision\n        if self.assume_centered:\n            self.location_ = np.zeros(X.shape[1])\n        else:\n            self.location_ = X.mean(0)\n        covariance = empirical_covariance(X, assume_centered=self.assume_centered)\n        covariance = shrunk_covariance(covariance, self.shrinkage)\n        self._set_covariance(covariance)\n\n        return self\n\n\n# Ledoit-Wolf estimator\n\n\n@validate_params(\n    {\n        \"X\": [\"array-like\"],\n        \"assume_centered\": [\"boolean\"],\n        \"block_size\": [Interval(Integral, 1, None, closed=\"left\")],\n    },\n    prefer_skip_nested_validation=True,\n)\ndef ledoit_wolf_shrinkage(X, assume_centered=False, block_size=1000):\n    \"\"\"Estimate the shrunk Ledoit-Wolf covariance matrix.\n\n    Read more in the "}, {"start_line": 26000, "end_line": 28000, "belongs_to": {"file_name": "_shrunk_covariance.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/covariance", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "mation.\",\n           Chen, Y., Wiesel, A., Eldar, Y. C., & Hero, A. O.\n           IEEE Transactions on Signal Processing, 58(10), 5016-5029, 2010.\n           <0907.4698>`\n\n    Examples\n    --------\n    >>> import numpy as np\n    >>> from sklearn.covariance import OAS\n    >>> from sklearn.datasets import make_gaussian_quantiles\n    >>> real_cov = np.array([[.8, .3],\n    ...                      [.3, .4]])\n    >>> rng = np.random.RandomState(0)\n    >>> X = rng.multivariate_normal(mean=[0, 0],\n    ...                             cov=real_cov,\n    ...                             size=500)\n    >>> oas = OAS().fit(X)\n    >>> oas.covariance_\n    array([[0.7533, 0.2763],\n           [0.2763, 0.3964]])\n    >>> oas.precision_\n    array([[ 1.7833, -1.2431 ],\n           [-1.2431,  3.3889]])\n    >>> oas.shrinkage_\n    np.float64(0.0195)\n\n    See also :ref:`sphx_glr_auto_examples_covariance_plot_covariance_estimation.py`\n    and :ref:`sphx_glr_auto_examples_covariance_plot_lw_vs_oas.py`\n    for more detailed examples.\n    \"\"\"\n\n    @_fit_context(prefer_skip_nested_validation=True)\n    def fit(self, X, y=None):\n        \"\"\"Fit the Oracle Approximating Shrinkage covariance model to X.\n\n        Parameters\n        ----------\n        X : array-like of shape (n_samples, n_features)\n            Training data, where `n_samples` is the number of samples\n            and `n_features` is the number of features.\n        y : Ignored\n            Not used, present for API consistency by convention.\n\n        Returns\n        -------\n        self : object\n            Returns the instance itself.\n        \"\"\"\n        X = validate_data(self, X)\n        # Not calling the parent object to fit, to avoid computing the\n        # covariance matrix (and potentially the precision)\n        if self.assume_centered:\n            self.location_ = np.zeros(X.shape[1])\n        else:\n            self.location_ = X.mean(0)\n\n        covariance, shrinkage = _oas(X - self.location_, assume_centered=True)\n        self.shrink"}, {"start_line": 7000, "end_line": 9000, "belongs_to": {"file_name": "_nearest_centroid.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/neighbors", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "array(self.priors)\n\n        if (self.class_prior_ < 0).any():\n            raise ValueError(\"priors must be non-negative\")\n        if not np.isclose(self.class_prior_.sum(), 1.0):\n            warnings.warn(\n                \"The priors do not sum to 1. Normalizing such that it sums to one.\",\n                UserWarning,\n            )\n            self.class_prior_ = self.class_prior_ / self.class_prior_.sum()\n\n        # Mask mapping each class to its members.\n        self.centroids_ = np.empty((n_classes, n_features), dtype=np.float64)\n\n        # Number of clusters in each class.\n        nk = np.zeros(n_classes)\n\n        for cur_class in range(n_classes):\n            center_mask = y_ind == cur_class\n            nk[cur_class] = np.sum(center_mask)\n            if is_X_sparse:\n                center_mask = np.where(center_mask)[0]\n\n            if self.metric == \"manhattan\":\n                # NumPy does not calculate median of sparse matrices.\n                if not is_X_sparse:\n                    self.centroids_[cur_class] = np.median(X[center_mask], axis=0)\n                else:\n                    self.centroids_[cur_class] = csc_median_axis_0(X[center_mask])\n            else:  # metric == \"euclidean\"\n                self.centroids_[cur_class] = X[center_mask].mean(axis=0)\n\n        # Compute within-class std_dev with unshrunked centroids\n        variance = np.array(X - self.centroids_[y_ind], copy=False) ** 2\n        self.within_class_std_dev_ = np.array(\n            np.sqrt(variance.sum(axis=0) / (n_samples - n_classes)), copy=False\n        )\n        if any(self.within_class_std_dev_ == 0):\n            warnings.warn(\n                \"self.within_class_std_dev_ has at least 1 zero standard deviation.\"\n                \"Inputs within the same classes for at least 1 feature are identical.\"\n            )\n\n        err_msg = \"All features have zero variance. Division by zero.\"\n        if is_X_sparse and np.all((X.max(axis=0) - X.min(axis=0)).toarray() == 0):\n            rais"}, {"start_line": 20000, "end_line": 22000, "belongs_to": {"file_name": "_shrunk_covariance.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/covariance", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "oit-Wolf shrunk covariance model to X.\n\n        Parameters\n        ----------\n        X : array-like of shape (n_samples, n_features)\n            Training data, where `n_samples` is the number of samples\n            and `n_features` is the number of features.\n        y : Ignored\n            Not used, present for API consistency by convention.\n\n        Returns\n        -------\n        self : object\n            Returns the instance itself.\n        \"\"\"\n        # Not calling the parent object to fit, to avoid computing the\n        # covariance matrix (and potentially the precision)\n        X = validate_data(self, X)\n        if self.assume_centered:\n            self.location_ = np.zeros(X.shape[1])\n        else:\n            self.location_ = X.mean(0)\n        covariance, shrinkage = _ledoit_wolf(\n            X - self.location_, assume_centered=True, block_size=self.block_size\n        )\n        self.shrinkage_ = shrinkage\n        self._set_covariance(covariance)\n\n        return self\n\n\n# OAS estimator\n@validate_params(\n    {\"X\": [\"array-like\"]},\n    prefer_skip_nested_validation=False,\n)\ndef oas(X, *, assume_centered=False):\n    \"\"\"Estimate covariance with the Oracle Approximating Shrinkage.\n\n    Read more in the :ref:`User Guide <shrunk_covariance>`.\n\n    Parameters\n    ----------\n    X : array-like of shape (n_samples, n_features)\n        Data from which to compute the covariance estimate.\n\n    assume_centered : bool, default=False\n      If True, data will not be centered before computation.\n      Useful to work with data whose mean is significantly equal to\n      zero but is not exactly zero.\n      If False, data will be centered before computation.\n\n    Returns\n    -------\n    shrunk_cov : array-like of shape (n_features, n_features)\n        Shrunk covariance.\n\n    shrinkage : float\n        Coefficient in the convex combination used for the computation\n        of the shrunk estimate.\n\n    Notes\n    -----\n    The regularised covariance is:\n\n    (1 - shrinkage) * cov + shr"}, {"start_line": 71000, "end_line": 73000, "belongs_to": {"file_name": "_kmeans.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/cluster", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "rue\n\n        # Early stopping heuristic due to lack of improvement on smoothed\n        # inertia\n        if self._ewa_inertia_min is None or self._ewa_inertia < self._ewa_inertia_min:\n            self._no_improvement = 0\n            self._ewa_inertia_min = self._ewa_inertia\n        else:\n            self._no_improvement += 1\n\n        if (\n            self.max_no_improvement is not None\n            and self._no_improvement >= self.max_no_improvement\n        ):\n            if self.verbose:\n                print(\n                    \"Converged (lack of improvement in inertia) at step \"\n                    f\"{step}/{n_steps}\"\n                )\n            return True\n\n        return False\n\n    def _random_reassign(self):\n        \"\"\"Check if a random reassignment needs to be done.\n\n        Do random reassignments each time 10 * n_clusters samples have been\n        processed.\n\n        If there are empty clusters we always want to reassign.\n        \"\"\"\n        self._n_since_last_reassign += self._batch_size\n        if (self._counts == 0).any() or self._n_since_last_reassign >= (\n            10 * self.n_clusters\n        ):\n            self._n_since_last_reassign = 0\n            return True\n        return False\n\n    @_fit_context(prefer_skip_nested_validation=True)\n    def fit(self, X, y=None, sample_weight=None):\n        \"\"\"Compute the centroids on X by chunking it into mini-batches.\n\n        Parameters\n        ----------\n        X : {array-like, sparse matrix} of shape (n_samples, n_features)\n            Training instances to cluster. It must be noted that the data\n            will be converted to C ordering, which will cause a memory copy\n            if the given data is not C-contiguous.\n            If a sparse matrix is passed, a copy will be made if it's not in\n            CSR format.\n\n        y : Ignored\n            Not used, present here for API consistency by convention.\n\n        sample_weight : array-like of shape (n_samples,), default=None\n            The weights "}, {"start_line": 2000, "end_line": 4000, "belongs_to": {"file_name": "_variance_threshold.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/feature_selection", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "r features, two of which are the same\n    in every sample. These are removed with the default setting for threshold::\n\n        >>> from sklearn.feature_selection import VarianceThreshold\n        >>> X = [[0, 2, 0, 3], [0, 1, 4, 3], [0, 1, 1, 3]]\n        >>> selector = VarianceThreshold()\n        >>> selector.fit_transform(X)\n        array([[2, 0],\n               [1, 4],\n               [1, 1]])\n    \"\"\"\n\n    _parameter_constraints: dict = {\n        \"threshold\": [Interval(Real, 0, None, closed=\"left\")]\n    }\n\n    def __init__(self, threshold=0.0):\n        self.threshold = threshold\n\n    @_fit_context(prefer_skip_nested_validation=True)\n    def fit(self, X, y=None):\n        \"\"\"Learn empirical variances from X.\n\n        Parameters\n        ----------\n        X : {array-like, sparse matrix}, shape (n_samples, n_features)\n            Data from which to compute variances, where `n_samples` is\n            the number of samples and `n_features` is the number of features.\n\n        y : any, default=None\n            Ignored. This parameter exists only for compatibility with\n            sklearn.pipeline.Pipeline.\n\n        Returns\n        -------\n        self : object\n            Returns the instance itself.\n        \"\"\"\n        X = validate_data(\n            self,\n            X,\n            accept_sparse=(\"csr\", \"csc\"),\n            dtype=np.float64,\n            ensure_all_finite=\"allow-nan\",\n        )\n\n        if hasattr(X, \"toarray\"):  # sparse matrix\n            _, self.variances_ = mean_variance_axis(X, axis=0)\n            if self.threshold == 0:\n                mins, maxes = min_max_axis(X, axis=0)\n                peak_to_peaks = maxes - mins\n        else:\n            self.variances_ = np.nanvar(X, axis=0)\n            if self.threshold == 0:\n                peak_to_peaks = np.ptp(X, axis=0)\n\n        if self.threshold == 0:\n            # Use peak-to-peak to avoid numeric precision issues\n            # for constant features\n            compare_arr = np.array([self.variances_, pea"}, {"start_line": 19000, "end_line": 21000, "belongs_to": {"file_name": "_bicluster.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/cluster", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "lueError, TypeError) as e:\n                raise ValueError(\n                    \"Incorrect parameter n_clusters has value:\"\n                    f\" {self.n_clusters}. It should either be a single integer\"\n                    \" or an iterable with two integers:\"\n                    \" (n_row_clusters, n_column_clusters)\"\n                    \" And the values are should be in the\"\n                    \" range: (1, n_samples)\"\n                ) from e\n\n        if self.n_best > self.n_components:\n            raise ValueError(\n                f\"n_best={self.n_best} must be <= n_components={self.n_components}.\"\n            )\n\n    def _fit(self, X):\n        n_sv = self.n_components\n        if self.method == \"bistochastic\":\n            normalized_data = _bistochastic_normalize(X)\n            n_sv += 1\n        elif self.method == \"scale\":\n            normalized_data, _, _ = _scale_normalize(X)\n            n_sv += 1\n        elif self.method == \"log\":\n            normalized_data = _log_normalize(X)\n        n_discard = 0 if self.method == \"log\" else 1\n        u, v = self._svd(normalized_data, n_sv, n_discard)\n        ut = u.T\n        vt = v.T\n\n        try:\n            n_row_clusters, n_col_clusters = self.n_clusters\n        except TypeError:\n            n_row_clusters = n_col_clusters = self.n_clusters\n\n        best_ut = self._fit_best_piecewise(ut, self.n_best, n_row_clusters)\n\n        best_vt = self._fit_best_piecewise(vt, self.n_best, n_col_clusters)\n\n        self.row_labels_ = self._project_and_cluster(X, best_vt.T, n_row_clusters)\n\n        self.column_labels_ = self._project_and_cluster(X.T, best_ut.T, n_col_clusters)\n\n        self.rows_ = np.vstack(\n            [\n                self.row_labels_ == label\n                for label in range(n_row_clusters)\n                for _ in range(n_col_clusters)\n            ]\n        )\n        self.columns_ = np.vstack(\n            [\n                self.column_labels_ == label\n                for _ in range(n_row_clusters)\n            "}, {"start_line": 21000, "end_line": 23000, "belongs_to": {"file_name": "hdbscan.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/cluster/_hdbscan", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "he output will be\n          an observed data point.\n        - `\"medoid\"` which calculates the center by taking the point in the\n          fitted data which minimizes the distance to all other points in\n          the cluster. This is slower than \"centroid\" since it requires\n          computing additional pairwise distances between points of the\n          same cluster but guarantees the output is an observed data point.\n          The medoid is also well-defined for arbitrary metrics, and does not\n          depend on a euclidean metric.\n        - `\"both\"` which computes and stores both forms of centers.\n\n    copy : bool, default=False\n        If `copy=True` then any time an in-place modifications would be made\n        that would overwrite data passed to :term:`fit`, a copy will first be\n        made, guaranteeing that the original data will be unchanged.\n        Currently, it only applies when `metric=\"precomputed\"`, when passing\n        a dense array or a CSR sparse matrix and when `algorithm=\"brute\"`.\n\n    Attributes\n    ----------\n    labels_ : ndarray of shape (n_samples,)\n        Cluster labels for each point in the dataset given to :term:`fit`.\n        Outliers are labeled as follows:\n\n        - Noisy samples are given the label -1.\n        - Samples with infinite elements (+/- np.inf) are given the label -2.\n        - Samples with missing data are given the label -3, even if they\n          also have infinite elements.\n\n    probabilities_ : ndarray of shape (n_samples,)\n        The strength with which each sample is a member of its assigned\n        cluster.\n\n        - Clustered samples have probabilities proportional to the degree that\n          they persist as part of the cluster.\n        - Noisy samples have probability zero.\n        - Samples with infinite elements (+/- np.inf) have probability 0.\n        - Samples with missing data have probability `np.nan`.\n\n    n_features_in_ : int\n        Number of features seen during :term:`fit`.\n\n    feature_names_in_ :"}, {"start_line": 79000, "end_line": 81000, "belongs_to": {"file_name": "_data.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/preprocessing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "ored.\n\n        Returns\n        -------\n        self : object\n            Fitted transformer.\n        \"\"\"\n        validate_data(self, X, accept_sparse=\"csr\")\n        return self\n\n    def transform(self, X, copy=None):\n        \"\"\"Binarize each element of X.\n\n        Parameters\n        ----------\n        X : {array-like, sparse matrix} of shape (n_samples, n_features)\n            The data to binarize, element by element.\n            scipy.sparse matrices should be in CSR format to avoid an\n            un-necessary copy.\n\n        copy : bool\n            Copy the input X or not.\n\n        Returns\n        -------\n        X_tr : {ndarray, sparse matrix} of shape (n_samples, n_features)\n            Transformed array.\n        \"\"\"\n        copy = copy if copy is not None else self.copy\n        # TODO: This should be refactored because binarize also calls\n        # check_array\n        X = validate_data(\n            self,\n            X,\n            accept_sparse=[\"csr\", \"csc\"],\n            force_writeable=True,\n            copy=copy,\n            reset=False,\n        )\n        return binarize(X, threshold=self.threshold, copy=False)\n\n    def __sklearn_tags__(self):\n        tags = super().__sklearn_tags__()\n        tags.requires_fit = False\n        tags.array_api_support = True\n        tags.input_tags.sparse = True\n        return tags\n\n\nclass KernelCenterer(ClassNamePrefixFeaturesOutMixin, TransformerMixin, BaseEstimator):\n    r\"\"\"Center an arbitrary kernel matrix :math:`K`.\n\n    Let define a kernel :math:`K` such that:\n\n    .. math::\n        K(X, Y) = \\phi(X) . \\phi(Y)^{T}\n\n    :math:`\\phi(X)` is a function mapping of rows of :math:`X` to a\n    Hilbert space and :math:`K` is of shape `(n_samples, n_samples)`.\n\n    This class allows to compute :math:`\\tilde{K}(X, Y)` such that:\n\n    .. math::\n        \\tilde{K(X, Y)} = \\tilde{\\phi}(X) . \\tilde{\\phi}(Y)^{T}\n\n    :math:`\\tilde{\\phi}(X)` is the centered mapped data in the Hilbert\n    space.\n\n    `KernelCenterer` centers the features wi"}], "retrieved_count": 10, "cost_time": 1.1381967067718506}
{"question": "What is the semantic mismatch created by the conditional logic in the fit method's type checking mechanism between the declared accept_large_sparse=True parameter and the actual runtime behavior when processing sparse data with 64-bit indices?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"start_line": 43000, "end_line": 45000, "belongs_to": {"file_name": "validation.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/utils", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "put is requested. This is an ambiguous setting so we chose\n            # to always (except for one specific setting, see below) make a copy to\n            # ensure that the output is writeable, even if avoidable, to not overwrite\n            # the user's data by surprise.\n\n            if _is_pandas_df_or_series(array_orig):\n                try:\n                    # In pandas >= 3, np.asarray(df), called earlier in check_array,\n                    # returns a read-only intermediate array. It can be made writeable\n                    # safely without copy because if the original DataFrame was backed\n                    # by a read-only array, trying to change the flag would raise an\n                    # error, in which case we make a copy.\n                    array_data.flags.writeable = True\n                except ValueError:\n                    array = array.copy(**copy_params)\n            else:\n                array = array.copy(**copy_params)\n\n    return array\n\n\ndef _check_large_sparse(X, accept_large_sparse=False):\n    \"\"\"Raise a ValueError if X has 64bit indices and accept_large_sparse=False\"\"\"\n    if not accept_large_sparse:\n        supported_indices = [\"int32\"]\n        if X.format == \"coo\":\n            index_keys = [\"col\", \"row\"]\n        elif X.format in [\"csr\", \"csc\", \"bsr\"]:\n            index_keys = [\"indices\", \"indptr\"]\n        else:\n            return\n        for key in index_keys:\n            indices_datatype = getattr(X, key).dtype\n            if indices_datatype not in supported_indices:\n                raise ValueError(\n                    \"Only sparse matrices with 32-bit integer indices are accepted.\"\n                    f\" Got {indices_datatype} indices. Please do report a minimal\"\n                    \" reproducer on scikit-learn issue tracker so that support for\"\n                    \" your use-case can be studied by maintainers. See:\"\n                    \" https://scikit-learn.org/dev/developers/minimal_reproducer.html\"\n                )\n\n\ndef ch"}, {"start_line": 44000, "end_line": 46000, "belongs_to": {"file_name": "validation.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/utils", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "arse(X, accept_large_sparse=False):\n    \"\"\"Raise a ValueError if X has 64bit indices and accept_large_sparse=False\"\"\"\n    if not accept_large_sparse:\n        supported_indices = [\"int32\"]\n        if X.format == \"coo\":\n            index_keys = [\"col\", \"row\"]\n        elif X.format in [\"csr\", \"csc\", \"bsr\"]:\n            index_keys = [\"indices\", \"indptr\"]\n        else:\n            return\n        for key in index_keys:\n            indices_datatype = getattr(X, key).dtype\n            if indices_datatype not in supported_indices:\n                raise ValueError(\n                    \"Only sparse matrices with 32-bit integer indices are accepted.\"\n                    f\" Got {indices_datatype} indices. Please do report a minimal\"\n                    \" reproducer on scikit-learn issue tracker so that support for\"\n                    \" your use-case can be studied by maintainers. See:\"\n                    \" https://scikit-learn.org/dev/developers/minimal_reproducer.html\"\n                )\n\n\ndef check_X_y(\n    X,\n    y,\n    accept_sparse=False,\n    *,\n    accept_large_sparse=True,\n    dtype=\"numeric\",\n    order=None,\n    copy=False,\n    force_writeable=False,\n    force_all_finite=\"deprecated\",\n    ensure_all_finite=None,\n    ensure_2d=True,\n    allow_nd=False,\n    multi_output=False,\n    ensure_min_samples=1,\n    ensure_min_features=1,\n    y_numeric=False,\n    estimator=None,\n):\n    \"\"\"Input validation for standard estimators.\n\n    Checks X and y for consistent length, enforces X to be 2D and y 1D. By\n    default, X is checked to be non-empty and containing only finite values.\n    Standard input checks are also applied to y, such as checking that y\n    does not have np.nan or np.inf targets. For multi-label y, set\n    multi_output=True to allow 2D and sparse y. If the dtype of X is\n    object, attempt converting to float, raising on failure.\n\n    Parameters\n    ----------\n    X : {ndarray, list, sparse matrix}\n        Input data.\n\n    y : {ndarray, list, sparse matrix}\n        L"}, {"start_line": 23000, "end_line": 25000, "belongs_to": {"file_name": "test_validation.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/utils/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "eck_array(X_csr, accept_sparse=False)\n\n    msg = (\n        \"Parameter 'accept_sparse' should be a string, \"\n        \"boolean or list of strings. You provided 'accept_sparse=.*'.\"\n    )\n    with pytest.raises(ValueError, match=msg):\n        check_array(X_csr, accept_sparse=invalid_type)\n\n    msg = (\n        \"When providing 'accept_sparse' as a tuple or list, \"\n        \"it must contain at least one string value.\"\n    )\n    with pytest.raises(ValueError, match=msg):\n        check_array(X_csr, accept_sparse=[])\n    with pytest.raises(ValueError, match=msg):\n        check_array(X_csr, accept_sparse=())\n    with pytest.raises(TypeError, match=\"SVR\"):\n        check_array(X_csr, accept_sparse=[invalid_type])\n\n\ndef test_check_array_accept_sparse_no_exception():\n    X = [[1, 2], [3, 4]]\n    X_csr = sp.csr_matrix(X)\n\n    check_array(X_csr, accept_sparse=True)\n    check_array(X_csr, accept_sparse=\"csr\")\n    check_array(X_csr, accept_sparse=[\"csr\"])\n    check_array(X_csr, accept_sparse=(\"csr\",))\n\n\n@pytest.fixture(params=[\"csr\", \"csc\", \"coo\", \"bsr\"])\ndef X_64bit(request):\n    X = sp.random(20, 10, format=request.param)\n\n    if request.param == \"coo\":\n        if hasattr(X, \"coords\"):\n            # for scipy >= 1.13 .coords is a new attribute and is a tuple. The\n            # .col and .row attributes do not seem to be able to change the\n            # dtype, for more details see https://github.com/scipy/scipy/pull/18530/\n            # and https://github.com/scipy/scipy/pull/20003 where .indices was\n            # renamed to .coords\n            X.coords = tuple(v.astype(\"int64\") for v in X.coords)\n        else:\n            # scipy < 1.13\n            X.row = X.row.astype(\"int64\")\n            X.col = X.col.astype(\"int64\")\n    else:\n        X.indices = X.indices.astype(\"int64\")\n        X.indptr = X.indptr.astype(\"int64\")\n\n    yield X\n\n\ndef test_check_array_accept_large_sparse_no_exception(X_64bit):\n    # When large sparse are allowed\n    check_array(X_64bit, accept_large_sparse=True, acc"}, {"start_line": 11000, "end_line": 13000, "belongs_to": {"file_name": "test_estimator_checks.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/utils/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "s_ < 2 and self.raise_when_single_class:\n            self.has_single_class_ = True\n            raise ValueError(\"normal class error\")\n\n        # find the number of class after trimming\n        if sample_weight is not None:\n            if isinstance(sample_weight, np.ndarray) and len(sample_weight) > 0:\n                n_classes_ = np.count_nonzero(np.bincount(y, sample_weight))\n            if n_classes_ < 2:\n                self.has_single_class_ = True\n                raise ValueError(\"Nonsensical Error\")\n\n        return self\n\n    def predict(self, X):\n        check_is_fitted(self)\n        X = check_array(X)\n        if self.has_single_class_:\n            return np.zeros(X.shape[0])\n        return np.ones(X.shape[0])\n\n\nclass LargeSparseNotSupportedClassifier(BaseEstimator):\n    \"\"\"Estimator that claims to support large sparse data\n    (accept_large_sparse=True), but doesn't\"\"\"\n\n    def __init__(self, raise_for_type=None):\n        # raise_for_type : str, expects \"sparse_array\" or \"sparse_matrix\"\n        self.raise_for_type = raise_for_type\n\n    def fit(self, X, y):\n        X, y = validate_data(\n            self,\n            X,\n            y,\n            accept_sparse=(\"csr\", \"csc\", \"coo\"),\n            accept_large_sparse=True,\n            multi_output=True,\n            y_numeric=True,\n        )\n        if self.raise_for_type == \"sparse_array\":\n            correct_type = isinstance(X, sp.sparray)\n        elif self.raise_for_type == \"sparse_matrix\":\n            correct_type = isinstance(X, sp.spmatrix)\n        if correct_type:\n            if X.format == \"coo\":\n                if X.row.dtype == \"int64\" or X.col.dtype == \"int64\":\n                    raise ValueError(\"Estimator doesn't support 64-bit indices\")\n            elif X.format in [\"csc\", \"csr\"]:\n                assert \"int64\" not in (\n                    X.indices.dtype,\n                    X.indptr.dtype,\n                ), \"Estimator doesn't support 64-bit indices\"\n\n        return self\n\n\nclass SparseTransformer"}, {"start_line": 12000, "end_line": 14000, "belongs_to": {"file_name": "test_estimator_checks.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/utils/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "e_matrix\"\n        self.raise_for_type = raise_for_type\n\n    def fit(self, X, y):\n        X, y = validate_data(\n            self,\n            X,\n            y,\n            accept_sparse=(\"csr\", \"csc\", \"coo\"),\n            accept_large_sparse=True,\n            multi_output=True,\n            y_numeric=True,\n        )\n        if self.raise_for_type == \"sparse_array\":\n            correct_type = isinstance(X, sp.sparray)\n        elif self.raise_for_type == \"sparse_matrix\":\n            correct_type = isinstance(X, sp.spmatrix)\n        if correct_type:\n            if X.format == \"coo\":\n                if X.row.dtype == \"int64\" or X.col.dtype == \"int64\":\n                    raise ValueError(\"Estimator doesn't support 64-bit indices\")\n            elif X.format in [\"csc\", \"csr\"]:\n                assert \"int64\" not in (\n                    X.indices.dtype,\n                    X.indptr.dtype,\n                ), \"Estimator doesn't support 64-bit indices\"\n\n        return self\n\n\nclass SparseTransformer(TransformerMixin, BaseEstimator):\n    def __init__(self, sparse_container=None):\n        self.sparse_container = sparse_container\n\n    def fit(self, X, y=None):\n        validate_data(self, X)\n        return self\n\n    def fit_transform(self, X, y=None):\n        return self.fit(X, y).transform(X)\n\n    def transform(self, X):\n        check_is_fitted(self)\n        X = validate_data(self, X, accept_sparse=True, reset=False)\n        return self.sparse_container(X)\n\n\nclass EstimatorInconsistentForPandas(BaseEstimator):\n    def fit(self, X, y):\n        try:\n            from pandas import DataFrame\n\n            if isinstance(X, DataFrame):\n                self.value_ = X.iloc[0, 0]\n            else:\n                X = check_array(X)\n                self.value_ = X[1, 0]\n            return self\n\n        except ImportError:\n            X = check_array(X)\n            self.value_ = X[1, 0]\n            return self\n\n    def predict(self, X):\n        X = check_array(X)\n        return np.array([self."}, {"start_line": 44000, "end_line": 46000, "belongs_to": {"file_name": "estimator_checks.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/utils", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "`accept_sparse`\"\n                \" in `validate_data` or `check_array` functions).\"\n            )\n            raise AssertionError(err_msg) from e\n    else:\n        err_msg = (\n            f\"Estimator {name} raised an exception. \"\n            \"The estimator failed when fitted on sparse data in accordance \"\n            f\"with its tag self.input_tags.sparse={tags.input_tags.sparse} \"\n            \"but didn't raise the appropriate error: error message should \"\n            \"state explicitly that sparse input is not supported if this is \"\n            \"not the case, e.g. by using check_array(X, accept_sparse=False).\"\n        )\n        try:\n            estimator.fit(X, y)  # should fail with appropriate error\n        except (ValueError, TypeError) as e:\n            if re.search(\"[Ss]parse\", str(e)):\n                # Got the right error type and mentioning sparse issue\n                return\n            raise AssertionError(err_msg) from e\n        except Exception as e:\n            raise AssertionError(err_msg) from e\n        raise AssertionError(\n            f\"Estimator {name} didn't fail when fitted on sparse data \"\n            \"but should have according to its tag \"\n            f\"self.input_tags.sparse={tags.input_tags.sparse}. \"\n            f\"The tag is inconsistent and must be fixed.\"\n        )\n\n\ndef _check_estimator_sparse_container(name, estimator_orig, sparse_type):\n    rng = np.random.RandomState(0)\n    X = rng.uniform(size=(40, 3))\n    X[X < 0.6] = 0\n    X = _enforce_estimator_tags_X(estimator_orig, X)\n    y = (4 * rng.uniform(size=X.shape[0])).astype(np.int32)\n    # catch deprecation warnings\n    with ignore_warnings(category=FutureWarning):\n        estimator = clone(estimator_orig)\n    y = _enforce_estimator_tags_y(estimator, y)\n    tags = get_tags(estimator_orig)\n    for matrix_format, X in _generate_sparse_data(sparse_type(X)):\n        # catch deprecation warnings\n        with ignore_warnings(category=FutureWarning):\n            estimator = clone(estimator_ori"}, {"start_line": 45000, "end_line": 47000, "belongs_to": {"file_name": "estimator_checks.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/utils", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "tionError(err_msg) from e\n        raise AssertionError(\n            f\"Estimator {name} didn't fail when fitted on sparse data \"\n            \"but should have according to its tag \"\n            f\"self.input_tags.sparse={tags.input_tags.sparse}. \"\n            f\"The tag is inconsistent and must be fixed.\"\n        )\n\n\ndef _check_estimator_sparse_container(name, estimator_orig, sparse_type):\n    rng = np.random.RandomState(0)\n    X = rng.uniform(size=(40, 3))\n    X[X < 0.6] = 0\n    X = _enforce_estimator_tags_X(estimator_orig, X)\n    y = (4 * rng.uniform(size=X.shape[0])).astype(np.int32)\n    # catch deprecation warnings\n    with ignore_warnings(category=FutureWarning):\n        estimator = clone(estimator_orig)\n    y = _enforce_estimator_tags_y(estimator, y)\n    tags = get_tags(estimator_orig)\n    for matrix_format, X in _generate_sparse_data(sparse_type(X)):\n        # catch deprecation warnings\n        with ignore_warnings(category=FutureWarning):\n            estimator = clone(estimator_orig)\n            if name in [\"Scaler\", \"StandardScaler\"]:\n                estimator.set_params(with_mean=False)\n        # fit and predict\n        if \"64\" in matrix_format:\n            err_msg = (\n                f\"Estimator {name} doesn't seem to support {matrix_format} \"\n                \"matrix, and is not failing gracefully, e.g. by using \"\n                \"check_array(X, accept_large_sparse=False).\"\n            )\n        else:\n            err_msg = (\n                f\"Estimator {name} doesn't seem to fail gracefully on sparse \"\n                \"data: error message should state explicitly that sparse \"\n                \"input is not supported if this is not the case, e.g. by using \"\n                \"check_array(X, accept_sparse=False).\"\n            )\n        with raises(\n            (TypeError, ValueError),\n            match=[\"sparse\", \"Sparse\"],\n            may_pass=True,\n            err_msg=err_msg,\n        ):\n            with ignore_warnings(category=FutureWarning):\n                e"}, {"start_line": 24000, "end_line": 26000, "belongs_to": {"file_name": "test_validation.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/utils/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "@pytest.fixture(params=[\"csr\", \"csc\", \"coo\", \"bsr\"])\ndef X_64bit(request):\n    X = sp.random(20, 10, format=request.param)\n\n    if request.param == \"coo\":\n        if hasattr(X, \"coords\"):\n            # for scipy >= 1.13 .coords is a new attribute and is a tuple. The\n            # .col and .row attributes do not seem to be able to change the\n            # dtype, for more details see https://github.com/scipy/scipy/pull/18530/\n            # and https://github.com/scipy/scipy/pull/20003 where .indices was\n            # renamed to .coords\n            X.coords = tuple(v.astype(\"int64\") for v in X.coords)\n        else:\n            # scipy < 1.13\n            X.row = X.row.astype(\"int64\")\n            X.col = X.col.astype(\"int64\")\n    else:\n        X.indices = X.indices.astype(\"int64\")\n        X.indptr = X.indptr.astype(\"int64\")\n\n    yield X\n\n\ndef test_check_array_accept_large_sparse_no_exception(X_64bit):\n    # When large sparse are allowed\n    check_array(X_64bit, accept_large_sparse=True, accept_sparse=True)\n\n\ndef test_check_array_accept_large_sparse_raise_exception(X_64bit):\n    # When large sparse are not allowed\n    msg = (\n        \"Only sparse matrices with 32-bit integer indices \"\n        \"are accepted. Got int64 indices. Please do report\"\n    )\n    with pytest.raises(ValueError, match=msg):\n        check_array(X_64bit, accept_sparse=True, accept_large_sparse=False)\n\n\ndef test_check_array_min_samples_and_features_messages():\n    # empty list is considered 2D by default:\n    msg = r\"0 feature\\(s\\) \\(shape=\\(1, 0\\)\\) while a minimum of 1 is required.\"\n    with pytest.raises(ValueError, match=msg):\n        check_array([[]])\n\n    # If considered a 1D collection when ensure_2d=False, then the minimum\n    # number of samples will break:\n    msg = r\"0 sample\\(s\\) \\(shape=\\(0,\\)\\) while a minimum of 1 is required.\"\n    with pytest.raises(ValueError, match=msg):\n        check_array([], ensure_2d=False)\n\n    # Invalid edge case when checking the default minimum sample of a scal"}, {"start_line": 19000, "end_line": 21000, "belongs_to": {"file_name": "validation.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/utils", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "ormat, it will be converted to the first listed\n        format. True allows the input to be any format. False means\n        that a sparse matrix input will raise an error.\n\n    dtype : str, type or None\n        Data type of result. If None, the dtype of the input is preserved.\n\n    copy : bool\n        Whether a forced copy will be triggered. If copy=False, a copy might\n        be triggered by a conversion.\n\n    ensure_all_finite : bool or 'allow-nan'\n        Whether to raise an error on np.inf, np.nan, pd.NA in X. The\n        possibilities are:\n\n        - True: Force all values of X to be finite.\n        - False: accepts np.inf, np.nan, pd.NA in X.\n        - 'allow-nan': accepts only np.nan and pd.NA values in X. Values cannot\n          be infinite.\n\n        .. versionadded:: 0.20\n           ``ensure_all_finite`` accepts the string ``'allow-nan'``.\n\n        .. versionchanged:: 0.23\n           Accepts `pd.NA` and converts it into `np.nan`\n\n\n    estimator_name : str, default=None\n        The estimator name, used to construct the error message.\n\n    input_name : str, default=\"\"\n        The data name used to construct the error message. In particular\n        if `input_name` is \"X\" and the data has NaN values and\n        allow_nan is False, the error message will link to the imputer\n        documentation.\n\n    Returns\n    -------\n    sparse_container_converted : sparse matrix or array\n        Sparse container (matrix/array) that is ensured to have an allowed type.\n    \"\"\"\n    if dtype is None:\n        dtype = sparse_container.dtype\n\n    changed_format = False\n    sparse_container_type_name = type(sparse_container).__name__\n\n    if isinstance(accept_sparse, str):\n        accept_sparse = [accept_sparse]\n\n    # Indices dtype validation\n    _check_large_sparse(sparse_container, accept_large_sparse)\n\n    if accept_sparse is False:\n        padded_input = \" for \" + input_name if input_name else \"\"\n        raise TypeError(\n            f\"Sparse data was passed{padded_input}, but "}, {"start_line": 21000, "end_line": 23000, "belongs_to": {"file_name": "validation.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/utils", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "dense data is required. \"\n            \"Use '.toarray()' to convert to a dense numpy array.\"\n        )\n    elif isinstance(accept_sparse, (list, tuple)):\n        if len(accept_sparse) == 0:\n            raise ValueError(\n                \"When providing 'accept_sparse' as a tuple or list, it must contain at \"\n                \"least one string value.\"\n            )\n        # ensure correct sparse format\n        if sparse_container.format not in accept_sparse:\n            # create new with correct sparse\n            sparse_container = sparse_container.asformat(accept_sparse[0])\n            changed_format = True\n    elif accept_sparse is not True:\n        # any other type\n        raise ValueError(\n            \"Parameter 'accept_sparse' should be a string, boolean or list of strings.\"\n            f\" You provided 'accept_sparse={accept_sparse}'.\"\n        )\n\n    if dtype != sparse_container.dtype:\n        # convert dtype\n        sparse_container = sparse_container.astype(dtype)\n    elif copy and not changed_format:\n        # force copy\n        sparse_container = sparse_container.copy()\n\n    if ensure_all_finite:\n        if not hasattr(sparse_container, \"data\"):\n            warnings.warn(\n                f\"Can't check {sparse_container.format} sparse matrix for nan or inf.\",\n                stacklevel=2,\n            )\n        else:\n            _assert_all_finite(\n                sparse_container.data,\n                allow_nan=ensure_all_finite == \"allow-nan\",\n                estimator_name=estimator_name,\n                input_name=input_name,\n            )\n\n    # TODO: Remove when the minimum version of SciPy supported is 1.12\n    # With SciPy sparse arrays, conversion from DIA format to COO, CSR, or BSR\n    # triggers the use of `np.int64` indices even if the data is such that it could\n    # be more efficiently represented with `np.int32` indices.\n    # https://github.com/scipy/scipy/issues/19245 Since not all scikit-learn\n    # algorithms support large indices, the follow"}], "retrieved_count": 10, "cost_time": 1.1483759880065918}
{"question": "How does SpectralEmbedding's _get_affinity_matrix method implement a fallback strategy when sparse input is detected for nearest_neighbors affinity, and what are the implications of this runtime exception handling for the algorithm's behavior?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"start_line": 24000, "end_line": 26000, "belongs_to": {"file_name": "_spectral_embedding.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/manifold", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "ions(\n                {\n                    \"nearest_neighbors\",\n                    \"rbf\",\n                    \"precomputed\",\n                    \"precomputed_nearest_neighbors\",\n                },\n            ),\n            callable,\n        ],\n        \"gamma\": [Interval(Real, 0, None, closed=\"left\"), None],\n        \"random_state\": [\"random_state\"],\n        \"eigen_solver\": [StrOptions({\"arpack\", \"lobpcg\", \"amg\"}), None],\n        \"eigen_tol\": [Interval(Real, 0, None, closed=\"left\"), StrOptions({\"auto\"})],\n        \"n_neighbors\": [Interval(Integral, 1, None, closed=\"left\"), None],\n        \"n_jobs\": [None, Integral],\n    }\n\n    def __init__(\n        self,\n        n_components=2,\n        *,\n        affinity=\"nearest_neighbors\",\n        gamma=None,\n        random_state=None,\n        eigen_solver=None,\n        eigen_tol=\"auto\",\n        n_neighbors=None,\n        n_jobs=None,\n    ):\n        self.n_components = n_components\n        self.affinity = affinity\n        self.gamma = gamma\n        self.random_state = random_state\n        self.eigen_solver = eigen_solver\n        self.eigen_tol = eigen_tol\n        self.n_neighbors = n_neighbors\n        self.n_jobs = n_jobs\n\n    def __sklearn_tags__(self):\n        tags = super().__sklearn_tags__()\n        tags.input_tags.sparse = True\n        tags.input_tags.pairwise = self.affinity in [\n            \"precomputed\",\n            \"precomputed_nearest_neighbors\",\n        ]\n        return tags\n\n    def _get_affinity_matrix(self, X, Y=None):\n        \"\"\"Calculate the affinity matrix from data\n        Parameters\n        ----------\n        X : array-like of shape (n_samples, n_features)\n            Training vector, where `n_samples` is the number of samples\n            and `n_features` is the number of features.\n\n            If affinity is \"precomputed\"\n            X : array-like of shape (n_samples, n_samples),\n            Interpret X as precomputed adjacency graph computed from\n            samples.\n\n        Y: Ignored\n\n        Returns\n      "}, {"start_line": 7000, "end_line": 9000, "belongs_to": {"file_name": "test_spectral_embedding.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/manifold/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "\n    for additional_neighbors in [0, 10]:\n        nn = NearestNeighbors(n_neighbors=n_neighbors + additional_neighbors).fit(S)\n        graph = nn.kneighbors_graph(S, mode=\"connectivity\")\n        embedding = (\n            SpectralEmbedding(\n                random_state=0,\n                n_components=2,\n                affinity=\"precomputed_nearest_neighbors\",\n                n_neighbors=n_neighbors,\n            )\n            .fit(graph)\n            .embedding_\n        )\n        results.append(embedding)\n\n    assert_array_equal(results[0], results[1])\n\n\n@pytest.mark.parametrize(\"sparse_container\", [None, *CSR_CONTAINERS])\ndef test_spectral_embedding_callable_affinity(sparse_container, seed=36):\n    # Test spectral embedding with callable affinity\n    gamma = 0.9\n    kern = rbf_kernel(S, gamma=gamma)\n    X = S if sparse_container is None else sparse_container(S)\n\n    se_callable = SpectralEmbedding(\n        n_components=2,\n        affinity=(lambda x: rbf_kernel(x, gamma=gamma)),\n        gamma=gamma,\n        random_state=np.random.RandomState(seed),\n    )\n    se_rbf = SpectralEmbedding(\n        n_components=2,\n        affinity=\"rbf\",\n        gamma=gamma,\n        random_state=np.random.RandomState(seed),\n    )\n    embed_rbf = se_rbf.fit_transform(X)\n    embed_callable = se_callable.fit_transform(X)\n    assert_array_almost_equal(se_callable.affinity_matrix_, se_rbf.affinity_matrix_)\n    assert_array_almost_equal(kern, se_rbf.affinity_matrix_)\n    _assert_equal_with_sign_flipping(embed_rbf, embed_callable, 0.05)\n\n\n@pytest.mark.skipif(\n    not pyamg_available, reason=\"PyAMG is required for the tests in this function.\"\n)\n@pytest.mark.parametrize(\"dtype\", (np.float32, np.float64))\n@pytest.mark.parametrize(\"coo_container\", COO_CONTAINERS)\ndef test_spectral_embedding_amg_solver(dtype, coo_container, seed=36):\n    se_amg = SpectralEmbedding(\n        n_components=2,\n        affinity=\"nearest_neighbors\",\n        eigen_solver=\"amg\",\n        n_neighbors=5,\n        random_state=np.r"}, {"start_line": 21000, "end_line": 23000, "belongs_to": {"file_name": "_spectral_embedding.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/manifold", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "e problems.\n        If None, then ``'arpack'`` is used.\n\n    eigen_tol : float, default=\"auto\"\n        Stopping criterion for eigendecomposition of the Laplacian matrix.\n        If `eigen_tol=\"auto\"` then the passed tolerance will depend on the\n        `eigen_solver`:\n\n        - If `eigen_solver=\"arpack\"`, then `eigen_tol=0.0`;\n        - If `eigen_solver=\"lobpcg\"` or `eigen_solver=\"amg\"`, then\n          `eigen_tol=None` which configures the underlying `lobpcg` solver to\n          automatically resolve the value according to their heuristics. See,\n          :func:`scipy.sparse.linalg.lobpcg` for details.\n\n        Note that when using `eigen_solver=\"lobpcg\"` or `eigen_solver=\"amg\"`\n        values of `tol<1e-5` may lead to convergence issues and should be\n        avoided.\n\n        .. versionadded:: 1.2\n\n    n_neighbors : int, default=None\n        Number of nearest neighbors for nearest_neighbors graph building.\n        If None, n_neighbors will be set to max(n_samples/10, 1).\n\n    n_jobs : int, default=None\n        The number of parallel jobs to run.\n        ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n        ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n        for more details.\n\n    Attributes\n    ----------\n    embedding_ : ndarray of shape (n_samples, n_components)\n        Spectral embedding of the training matrix.\n\n    affinity_matrix_ : ndarray of shape (n_samples, n_samples)\n        Affinity_matrix constructed from samples or precomputed.\n\n    n_features_in_ : int\n        Number of features seen during :term:`fit`.\n\n        .. versionadded:: 0.24\n\n    feature_names_in_ : ndarray of shape (`n_features_in_`,)\n        Names of features seen during :term:`fit`. Defined only when `X`\n        has feature names that are all strings.\n\n        .. versionadded:: 1.0\n\n    n_neighbors_ : int\n        Number of nearest neighbors effectively used.\n\n    See Also\n    --------\n    Isomap : Non-linear dimensionality reduction through Iso"}, {"start_line": 18000, "end_line": 20000, "belongs_to": {"file_name": "_spectral_embedding.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/manifold", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "False, maxiter=2000\n            )\n            embedding = diffusion_map.T[:n_components]\n            if norm_laplacian:\n                # recover u = D^-1/2 x from the eigenvector output x\n                embedding = embedding / dd\n            if embedding.shape[0] == 1:\n                raise ValueError\n\n    embedding = _deterministic_vector_sign_flip(embedding)\n    if drop_first:\n        return embedding[1:n_components].T\n    else:\n        return embedding[:n_components].T\n\n\nclass SpectralEmbedding(BaseEstimator):\n    \"\"\"Spectral embedding for non-linear dimensionality reduction.\n\n    Forms an affinity matrix given by the specified function and\n    applies spectral decomposition to the corresponding graph laplacian.\n    The resulting transformation is given by the value of the\n    eigenvectors for each data point.\n\n    Note : Laplacian Eigenmaps is the actual algorithm implemented here.\n\n    Read more in the :ref:`User Guide <spectral_embedding>`.\n\n    Parameters\n    ----------\n    n_components : int, default=2\n        The dimension of the projected subspace.\n\n    affinity : {'nearest_neighbors', 'rbf', 'precomputed', \\\n                'precomputed_nearest_neighbors'} or callable, \\\n                default='nearest_neighbors'\n        How to construct the affinity matrix.\n         - 'nearest_neighbors' : construct the affinity matrix by computing a\n           graph of nearest neighbors.\n         - 'rbf' : construct the affinity matrix by computing a radial basis\n           function (RBF) kernel.\n         - 'precomputed' : interpret ``X`` as a precomputed affinity matrix.\n         - 'precomputed_nearest_neighbors' : interpret ``X`` as a sparse graph\n           of precomputed nearest neighbors, and constructs the affinity matrix\n           by selecting the ``n_neighbors`` nearest neighbors.\n         - callable : use passed in function as affinity\n           the function takes in data matrix (n_samples, n_features)\n           and return affinity matrix (n_samples, n_sa"}, {"start_line": 9000, "end_line": 11000, "belongs_to": {"file_name": "test_spectral_embedding.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/manifold/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "andom.RandomState(seed),\n    )\n    se_arpack = SpectralEmbedding(\n        n_components=2,\n        affinity=\"nearest_neighbors\",\n        eigen_solver=\"arpack\",\n        n_neighbors=5,\n        random_state=np.random.RandomState(seed),\n    )\n    embed_amg = se_amg.fit_transform(S.astype(dtype))\n    embed_arpack = se_arpack.fit_transform(S.astype(dtype))\n    _assert_equal_with_sign_flipping(embed_amg, embed_arpack, 1e-5)\n\n    # same with special case in which amg is not actually used\n    # regression test for #10715\n    # affinity between nodes\n    row = np.array([0, 0, 1, 2, 3, 3, 4], dtype=np.int32)\n    col = np.array([1, 2, 2, 3, 4, 5, 5], dtype=np.int32)\n    val = np.array([100, 100, 100, 1, 100, 100, 100], dtype=np.int64)\n\n    affinity = coo_container(\n        (np.hstack([val, val]), (np.hstack([row, col]), np.hstack([col, row]))),\n        shape=(6, 6),\n    )\n    se_amg.affinity = \"precomputed\"\n    se_arpack.affinity = \"precomputed\"\n    embed_amg = se_amg.fit_transform(affinity.astype(dtype))\n    embed_arpack = se_arpack.fit_transform(affinity.astype(dtype))\n    _assert_equal_with_sign_flipping(embed_amg, embed_arpack, 1e-5)\n\n    # Check that passing a sparse matrix with `np.int64` indices dtype raises an error\n    # or is successful based on the version of SciPy which is installed.\n    # Use a CSR matrix to avoid any conversion during the validation\n    affinity = affinity.tocsr()\n    affinity.indptr = affinity.indptr.astype(np.int64)\n    affinity.indices = affinity.indices.astype(np.int64)\n\n    # PR: https://github.com/scipy/scipy/pull/18913\n    # First integration in 1.11.3: https://github.com/scipy/scipy/pull/19279\n    scipy_graph_traversal_supports_int64_index = sp_version >= parse_version(\"1.11.3\")\n    if scipy_graph_traversal_supports_int64_index:\n        se_amg.fit_transform(affinity)\n    else:\n        err_msg = \"Only sparse matrices with 32-bit integer indices are accepted\"\n        with pytest.raises(ValueError, match=err_msg):\n            se_amg.fit_transf"}, {"start_line": 10000, "end_line": 12000, "belongs_to": {"file_name": "_spectral_embedding.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/manifold", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "econditioned Conjugate Gradient Method\",\n      Andrew V. Knyazev\n      <10.1137/S1064827500366124>`\n\n    Examples\n    --------\n    >>> from sklearn.datasets import load_digits\n    >>> from sklearn.neighbors import kneighbors_graph\n    >>> from sklearn.manifold import spectral_embedding\n    >>> X, _ = load_digits(return_X_y=True)\n    >>> X = X[:100]\n    >>> affinity_matrix = kneighbors_graph(\n    ...     X, n_neighbors=int(X.shape[0] / 10), include_self=True\n    ... )\n    >>> # make the matrix symmetric\n    >>> affinity_matrix = 0.5 * (affinity_matrix + affinity_matrix.T)\n    >>> embedding = spectral_embedding(affinity_matrix, n_components=2, random_state=42)\n    >>> embedding.shape\n    (100, 2)\n    \"\"\"\n    random_state = check_random_state(random_state)\n\n    return _spectral_embedding(\n        adjacency,\n        n_components=n_components,\n        eigen_solver=eigen_solver,\n        random_state=random_state,\n        eigen_tol=eigen_tol,\n        norm_laplacian=norm_laplacian,\n        drop_first=drop_first,\n    )\n\n\ndef _spectral_embedding(\n    adjacency,\n    *,\n    n_components=8,\n    eigen_solver=None,\n    random_state=None,\n    eigen_tol=\"auto\",\n    norm_laplacian=True,\n    drop_first=True,\n):\n    adjacency = check_symmetric(adjacency)\n\n    if eigen_solver == \"amg\":\n        try:\n            from pyamg import smoothed_aggregation_solver\n        except ImportError as e:\n            raise ValueError(\n                \"The eigen_solver was set to 'amg', but pyamg is not available.\"\n            ) from e\n\n    if eigen_solver is None:\n        eigen_solver = \"arpack\"\n\n    n_nodes = adjacency.shape[0]\n    # Whether to drop the first eigenvector\n    if drop_first:\n        n_components = n_components + 1\n\n    if not _graph_is_connected(adjacency):\n        warnings.warn(\n            \"Graph is not fully connected, spectral embedding may not work as expected.\"\n        )\n\n    laplacian, dd = csgraph_laplacian(\n        adjacency, normed=norm_laplacian, return_diag=True\n    )\n    if e"}, {"start_line": 17000, "end_line": 19000, "belongs_to": {"file_name": "_spectral_embedding.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/manifold", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "k to eigh, so we short circuit it\n            if sparse.issparse(laplacian):\n                laplacian = laplacian.toarray()\n            _, diffusion_map = eigh(laplacian, check_finite=False)\n            embedding = diffusion_map.T[:n_components]\n            if norm_laplacian:\n                # recover u = D^-1/2 x from the eigenvector output x\n                embedding = embedding / dd\n        else:\n            laplacian = _set_diag(laplacian, 1, norm_laplacian)\n            # We increase the number of eigenvectors requested, as lobpcg\n            # doesn't behave well in low dimension and create initial\n            # approximation X to eigenvectors\n            X = random_state.standard_normal(\n                size=(laplacian.shape[0], n_components + 1)\n            )\n            X[:, 0] = dd.ravel()\n            X = X.astype(laplacian.dtype)\n            tol = None if eigen_tol == \"auto\" else eigen_tol\n            _, diffusion_map = lobpcg(\n                laplacian, X, tol=tol, largest=False, maxiter=2000\n            )\n            embedding = diffusion_map.T[:n_components]\n            if norm_laplacian:\n                # recover u = D^-1/2 x from the eigenvector output x\n                embedding = embedding / dd\n            if embedding.shape[0] == 1:\n                raise ValueError\n\n    embedding = _deterministic_vector_sign_flip(embedding)\n    if drop_first:\n        return embedding[1:n_components].T\n    else:\n        return embedding[:n_components].T\n\n\nclass SpectralEmbedding(BaseEstimator):\n    \"\"\"Spectral embedding for non-linear dimensionality reduction.\n\n    Forms an affinity matrix given by the specified function and\n    applies spectral decomposition to the corresponding graph laplacian.\n    The resulting transformation is given by the value of the\n    eigenvectors for each data point.\n\n    Note : Laplacian Eigenmaps is the actual algorithm implemented here.\n\n    Read more in the :ref:`User Guide <spectral_embedding>`.\n\n    Parameters\n    ----------\n    n_"}, {"start_line": 25000, "end_line": 27000, "belongs_to": {"file_name": "_spectral_embedding.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/manifold", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "lf.random_state = random_state\n        self.eigen_solver = eigen_solver\n        self.eigen_tol = eigen_tol\n        self.n_neighbors = n_neighbors\n        self.n_jobs = n_jobs\n\n    def __sklearn_tags__(self):\n        tags = super().__sklearn_tags__()\n        tags.input_tags.sparse = True\n        tags.input_tags.pairwise = self.affinity in [\n            \"precomputed\",\n            \"precomputed_nearest_neighbors\",\n        ]\n        return tags\n\n    def _get_affinity_matrix(self, X, Y=None):\n        \"\"\"Calculate the affinity matrix from data\n        Parameters\n        ----------\n        X : array-like of shape (n_samples, n_features)\n            Training vector, where `n_samples` is the number of samples\n            and `n_features` is the number of features.\n\n            If affinity is \"precomputed\"\n            X : array-like of shape (n_samples, n_samples),\n            Interpret X as precomputed adjacency graph computed from\n            samples.\n\n        Y: Ignored\n\n        Returns\n        -------\n        affinity_matrix of shape (n_samples, n_samples)\n        \"\"\"\n        if self.affinity == \"precomputed\":\n            self.affinity_matrix_ = X\n            return self.affinity_matrix_\n        if self.affinity == \"precomputed_nearest_neighbors\":\n            estimator = NearestNeighbors(\n                n_neighbors=self.n_neighbors, n_jobs=self.n_jobs, metric=\"precomputed\"\n            ).fit(X)\n            connectivity = estimator.kneighbors_graph(X=X, mode=\"connectivity\")\n            self.affinity_matrix_ = 0.5 * (connectivity + connectivity.T)\n            return self.affinity_matrix_\n        if self.affinity == \"nearest_neighbors\":\n            if sparse.issparse(X):\n                warnings.warn(\n                    \"Nearest neighbors affinity currently does \"\n                    \"not support sparse input, falling back to \"\n                    \"rbf affinity\"\n                )\n                self.affinity = \"rbf\"\n            else:\n                self.n_neighbors_ = (\n  "}, {"start_line": 14000, "end_line": 16000, "belongs_to": {"file_name": "_spectral_embedding.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/manifold", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "        laplacian, k=n_components, sigma=1.0, which=\"LM\", tol=tol, v0=v0\n            )\n            embedding = diffusion_map.T[n_components::-1]\n            if norm_laplacian:\n                # recover u = D^-1/2 x from the eigenvector output x\n                embedding = embedding / dd\n        except RuntimeError:\n            # When submatrices are exactly singular, an LU decomposition\n            # in arpack fails. We fallback to lobpcg\n            eigen_solver = \"lobpcg\"\n            # Revert the laplacian to its opposite to have lobpcg work\n            laplacian *= -1\n\n    elif eigen_solver == \"amg\":\n        # Use AMG to get a preconditioner and speed up the eigenvalue\n        # problem.\n        if not sparse.issparse(laplacian):\n            warnings.warn(\"AMG works better for sparse matrices\")\n        laplacian = check_array(\n            laplacian, dtype=[np.float64, np.float32], accept_sparse=True\n        )\n        laplacian = _set_diag(laplacian, 1, norm_laplacian)\n\n        # The Laplacian matrix is always singular, having at least one zero\n        # eigenvalue, corresponding to the trivial eigenvector, which is a\n        # constant. Using a singular matrix for preconditioning may result in\n        # random failures in LOBPCG and is not supported by the existing\n        # theory:\n        #     see https://doi.org/10.1007/s10208-015-9297-1\n        # Shift the Laplacian so its diagononal is not all ones. The shift\n        # does change the eigenpairs however, so we'll feed the shifted\n        # matrix to the solver and afterward set it back to the original.\n        diag_shift = 1e-5 * sparse.eye(laplacian.shape[0])\n        laplacian += diag_shift\n        if hasattr(sparse, \"csr_array\") and isinstance(laplacian, sparse.csr_array):\n            # `pyamg` does not work with `csr_array` and we need to convert it to a\n            # `csr_matrix` object.\n            laplacian = sparse.csr_matrix(laplacian)\n        ml = smoothed_aggregation_solver(check_array(laplacian, "}, {"start_line": 6000, "end_line": 8000, "belongs_to": {"file_name": "_locally_linear.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/manifold", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": " v0=v0\n            )\n        except RuntimeError as e:\n            raise ValueError(\n                \"Error in determining null-space with ARPACK. Error message: \"\n                \"'%s'. Note that eigen_solver='arpack' can fail when the \"\n                \"weight matrix is singular or otherwise ill-behaved. In that \"\n                \"case, eigen_solver='dense' is recommended. See online \"\n                \"documentation for more information.\" % e\n            ) from e\n\n        return eigen_vectors[:, k_skip:], np.sum(eigen_values[k_skip:])\n    elif eigen_solver == \"dense\":\n        if hasattr(M, \"toarray\"):\n            M = M.toarray()\n        eigen_values, eigen_vectors = eigh(\n            M, subset_by_index=(k_skip, k + k_skip - 1), overwrite_a=True\n        )\n        index = np.argsort(np.abs(eigen_values))\n        return eigen_vectors[:, index], np.sum(eigen_values)\n    else:\n        raise ValueError(\"Unrecognized eigen_solver '%s'\" % eigen_solver)\n\n\ndef _locally_linear_embedding(\n    X,\n    *,\n    n_neighbors,\n    n_components,\n    reg=1e-3,\n    eigen_solver=\"auto\",\n    tol=1e-6,\n    max_iter=100,\n    method=\"standard\",\n    hessian_tol=1e-4,\n    modified_tol=1e-12,\n    random_state=None,\n    n_jobs=None,\n):\n    nbrs = NearestNeighbors(n_neighbors=n_neighbors + 1, n_jobs=n_jobs)\n    nbrs.fit(X)\n    X = nbrs._fit_X\n\n    N, d_in = X.shape\n\n    if n_components > d_in:\n        raise ValueError(\n            \"output dimension must be less than or equal to input dimension\"\n        )\n    if n_neighbors >= N:\n        raise ValueError(\n            \"Expected n_neighbors < n_samples, but n_samples = %d, n_neighbors = %d\"\n            % (N, n_neighbors)\n        )\n\n    M_sparse = eigen_solver != \"dense\"\n    M_container_constructor = lil_matrix if M_sparse else np.zeros\n\n    if method == \"standard\":\n        W = barycenter_kneighbors_graph(\n            nbrs, n_neighbors=n_neighbors, reg=reg, n_jobs=n_jobs\n        )\n\n        # we'll compute M = (I-W)'(I-W)\n        # depending on the so"}], "retrieved_count": 10, "cost_time": 1.1623914241790771}
{"question": "What is the impact of the dependency on StandardScaler within the _fit method on the correctness of PowerTransformer's standardization logic when standardize=True, and what would break if StandardScaler's fit_transform behavior changed?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"start_line": 91000, "end_line": 93000, "belongs_to": {"file_name": "test_data.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/preprocessing/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "lace but transform,\n    # fit_transform and inverse_transform do.\n    X = X_1col\n    if method == \"box-cox\":\n        X = np.abs(X)\n\n    X_original = X.copy()\n    assert X is not X_original  # sanity checks\n    assert_array_almost_equal(X, X_original)\n\n    pt = PowerTransformer(method, standardize=standardize, copy=False)\n\n    pt.fit(X)\n    assert_array_almost_equal(X, X_original)  # fit didn't change X\n\n    X_trans = pt.transform(X)\n    assert X_trans is X\n\n    if method == \"box-cox\":\n        X = np.abs(X)\n    X_trans = pt.fit_transform(X)\n    assert X_trans is X\n\n    X_inv_trans = pt.inverse_transform(X_trans)\n    assert X_trans is X_inv_trans\n\n\ndef test_power_transformer_box_cox_raise_all_nans_col():\n    \"\"\"Check that box-cox raises informative when a column contains all nans.\n\n    Non-regression test for gh-26303\n    \"\"\"\n    X = rng.random_sample((4, 5))\n    X[:, 0] = np.nan\n\n    err_msg = \"Column must not be all nan.\"\n\n    pt = PowerTransformer(method=\"box-cox\")\n    with pytest.raises(ValueError, match=err_msg):\n        pt.fit_transform(X)\n\n\n@pytest.mark.parametrize(\n    \"X_2\",\n    [sparse.random(10, 1, density=0.8, random_state=0)]\n    + [\n        csr_container(np.full((10, 1), fill_value=np.nan))\n        for csr_container in CSR_CONTAINERS\n    ],\n)\ndef test_standard_scaler_sparse_partial_fit_finite_variance(X_2):\n    # non-regression test for:\n    # https://github.com/scikit-learn/scikit-learn/issues/16448\n    X_1 = sparse.random(5, 1, density=0.8)\n    scaler = StandardScaler(with_mean=False)\n    scaler.fit(X_1).partial_fit(X_2)\n    assert np.isfinite(scaler.var_[0])\n\n\n@pytest.mark.parametrize(\"feature_range\", [(0, 1), (-10, 10)])\ndef test_minmax_scaler_clip(feature_range):\n    # test behaviour of the parameter 'clip' in MinMaxScaler\n    X = iris.data\n    scaler = MinMaxScaler(feature_range=feature_range, clip=True).fit(X)\n    # create a test sample with features outside the training feature range:\n    # first 2 features < min(X) and last 2 features > max(X)\n "}, {"start_line": 113000, "end_line": 115000, "belongs_to": {"file_name": "_data.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/preprocessing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "- 'box-cox' [2]_, only works with strictly positive values\n\n    standardize : bool, default=True\n        Set to True to apply zero-mean, unit-variance normalization to the\n        transformed output.\n\n    copy : bool, default=True\n        Set to False to perform inplace computation during transformation.\n\n    Attributes\n    ----------\n    lambdas_ : ndarray of float of shape (n_features,)\n        The parameters of the power transformation for the selected features.\n\n    n_features_in_ : int\n        Number of features seen during :term:`fit`.\n\n        .. versionadded:: 0.24\n\n    feature_names_in_ : ndarray of shape (`n_features_in_`,)\n        Names of features seen during :term:`fit`. Defined only when `X`\n        has feature names that are all strings.\n\n        .. versionadded:: 1.0\n\n    See Also\n    --------\n    power_transform : Equivalent function without the estimator API.\n\n    QuantileTransformer : Maps data to a standard normal distribution with\n        the parameter `output_distribution='normal'`.\n\n    Notes\n    -----\n    NaNs are treated as missing values: disregarded in ``fit``, and maintained\n    in ``transform``.\n\n    References\n    ----------\n\n    .. [1] :doi:`I.K. Yeo and R.A. Johnson, \"A new family of power\n           transformations to improve normality or symmetry.\" Biometrika,\n           87(4), pp.954-959, (2000). <10.1093/biomet/87.4.954>`\n\n    .. [2] :doi:`G.E.P. Box and D.R. Cox, \"An Analysis of Transformations\",\n           Journal of the Royal Statistical Society B, 26, 211-252 (1964).\n           <10.1111/j.2517-6161.1964.tb00553.x>`\n\n    Examples\n    --------\n    >>> import numpy as np\n    >>> from sklearn.preprocessing import PowerTransformer\n    >>> pt = PowerTransformer()\n    >>> data = [[1, 2], [3, 2], [4, 5]]\n    >>> print(pt.fit(data))\n    PowerTransformer()\n    >>> print(pt.lambdas_)\n    [ 1.386 -3.100]\n    >>> print(pt.transform(data))\n    [[-1.316 -0.707]\n     [ 0.209 -0.707]\n     [ 1.106  1.414]]\n    \"\"\"\n\n    _parameter_constraints: d"}, {"start_line": 115000, "end_line": 117000, "belongs_to": {"file_name": "_data.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/preprocessing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "ict = {\n        \"method\": [StrOptions({\"yeo-johnson\", \"box-cox\"})],\n        \"standardize\": [\"boolean\"],\n        \"copy\": [\"boolean\"],\n    }\n\n    def __init__(self, method=\"yeo-johnson\", *, standardize=True, copy=True):\n        self.method = method\n        self.standardize = standardize\n        self.copy = copy\n\n    @_fit_context(prefer_skip_nested_validation=True)\n    def fit(self, X, y=None):\n        \"\"\"Estimate the optimal parameter lambda for each feature.\n\n        The optimal lambda parameter for minimizing skewness is estimated on\n        each feature independently using maximum likelihood.\n\n        Parameters\n        ----------\n        X : array-like of shape (n_samples, n_features)\n            The data used to estimate the optimal transformation parameters.\n\n        y : None\n            Ignored.\n\n        Returns\n        -------\n        self : object\n            Fitted transformer.\n        \"\"\"\n        self._fit(X, y=y, force_transform=False)\n        return self\n\n    @_fit_context(prefer_skip_nested_validation=True)\n    def fit_transform(self, X, y=None):\n        \"\"\"Fit `PowerTransformer` to `X`, then transform `X`.\n\n        Parameters\n        ----------\n        X : array-like of shape (n_samples, n_features)\n            The data used to estimate the optimal transformation parameters\n            and to be transformed using a power transformation.\n\n        y : Ignored\n            Not used, present for API consistency by convention.\n\n        Returns\n        -------\n        X_new : ndarray of shape (n_samples, n_features)\n            Transformed data.\n        \"\"\"\n        return self._fit(X, y, force_transform=True)\n\n    def _fit(self, X, y=None, force_transform=False):\n        X = self._check_input(X, in_fit=True, check_positive=True)\n\n        if not self.copy and not force_transform:  # if call from fit()\n            X = X.copy()  # force copy so that fit does not change X inplace\n\n        n_samples = X.shape[0]\n        mean = np.mean(X, axis=0, dtype=np.float64)\n"}, {"start_line": 114000, "end_line": 116000, "belongs_to": {"file_name": "_data.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/preprocessing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "ribution='normal'`.\n\n    Notes\n    -----\n    NaNs are treated as missing values: disregarded in ``fit``, and maintained\n    in ``transform``.\n\n    References\n    ----------\n\n    .. [1] :doi:`I.K. Yeo and R.A. Johnson, \"A new family of power\n           transformations to improve normality or symmetry.\" Biometrika,\n           87(4), pp.954-959, (2000). <10.1093/biomet/87.4.954>`\n\n    .. [2] :doi:`G.E.P. Box and D.R. Cox, \"An Analysis of Transformations\",\n           Journal of the Royal Statistical Society B, 26, 211-252 (1964).\n           <10.1111/j.2517-6161.1964.tb00553.x>`\n\n    Examples\n    --------\n    >>> import numpy as np\n    >>> from sklearn.preprocessing import PowerTransformer\n    >>> pt = PowerTransformer()\n    >>> data = [[1, 2], [3, 2], [4, 5]]\n    >>> print(pt.fit(data))\n    PowerTransformer()\n    >>> print(pt.lambdas_)\n    [ 1.386 -3.100]\n    >>> print(pt.transform(data))\n    [[-1.316 -0.707]\n     [ 0.209 -0.707]\n     [ 1.106  1.414]]\n    \"\"\"\n\n    _parameter_constraints: dict = {\n        \"method\": [StrOptions({\"yeo-johnson\", \"box-cox\"})],\n        \"standardize\": [\"boolean\"],\n        \"copy\": [\"boolean\"],\n    }\n\n    def __init__(self, method=\"yeo-johnson\", *, standardize=True, copy=True):\n        self.method = method\n        self.standardize = standardize\n        self.copy = copy\n\n    @_fit_context(prefer_skip_nested_validation=True)\n    def fit(self, X, y=None):\n        \"\"\"Estimate the optimal parameter lambda for each feature.\n\n        The optimal lambda parameter for minimizing skewness is estimated on\n        each feature independently using maximum likelihood.\n\n        Parameters\n        ----------\n        X : array-like of shape (n_samples, n_features)\n            The data used to estimate the optimal transformation parameters.\n\n        y : None\n            Ignored.\n\n        Returns\n        -------\n        self : object\n            Fitted transformer.\n        \"\"\"\n        self._fit(X, y=y, force_transform=False)\n        return self\n\n    @_fit_context("}, {"start_line": 89000, "end_line": 91000, "belongs_to": {"file_name": "test_data.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/preprocessing/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "l)\n    pt = PowerTransformer(method=method)\n    pt.fit(X)\n    lmbda_no_nans = pt.lambdas_[0]\n\n    # concat nans at the end and check lambda stays the same\n    X = np.concatenate([X, np.full_like(X, np.nan)])\n    X = shuffle(X, random_state=0)\n\n    pt.fit(X)\n    lmbda_nans = pt.lambdas_[0]\n\n    assert_almost_equal(lmbda_no_nans, lmbda_nans, decimal=5)\n\n    X_trans = pt.transform(X)\n    assert_array_equal(np.isnan(X_trans), np.isnan(X))\n\n\n@pytest.mark.parametrize(\"method\", [\"box-cox\", \"yeo-johnson\"])\n@pytest.mark.parametrize(\"standardize\", [True, False])\ndef test_power_transformer_fit_transform(method, standardize):\n    # check that fit_transform() and fit().transform() return the same values\n    X = X_1col\n    if method == \"box-cox\":\n        X = np.abs(X)\n\n    pt = PowerTransformer(method, standardize=standardize)\n    assert_array_almost_equal(pt.fit(X).transform(X), pt.fit_transform(X))\n\n\n@pytest.mark.parametrize(\"method\", [\"box-cox\", \"yeo-johnson\"])\n@pytest.mark.parametrize(\"standardize\", [True, False])\ndef test_power_transformer_copy_True(method, standardize):\n    # Check that neither fit, transform, fit_transform nor inverse_transform\n    # modify X inplace when copy=True\n    X = X_1col\n    if method == \"box-cox\":\n        X = np.abs(X)\n\n    X_original = X.copy()\n    assert X is not X_original  # sanity checks\n    assert_array_almost_equal(X, X_original)\n\n    pt = PowerTransformer(method, standardize=standardize, copy=True)\n\n    pt.fit(X)\n    assert_array_almost_equal(X, X_original)\n    X_trans = pt.transform(X)\n    assert X_trans is not X\n\n    X_trans = pt.fit_transform(X)\n    assert_array_almost_equal(X, X_original)\n    assert X_trans is not X\n\n    X_inv_trans = pt.inverse_transform(X_trans)\n    assert X_trans is not X_inv_trans\n\n\n@pytest.mark.parametrize(\"method\", [\"box-cox\", \"yeo-johnson\"])\n@pytest.mark.parametrize(\"standardize\", [True, False])\ndef test_power_transformer_copy_False(method, standardize):\n    # check that when copy=False fit doesn't change X inp"}, {"start_line": 82000, "end_line": 84000, "belongs_to": {"file_name": "test_data.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/preprocessing/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "erTransformer(method=method)\n    X = np.abs(X_1col)\n    with pytest.raises(NotFittedError):\n        pt.transform(X)\n    with pytest.raises(NotFittedError):\n        pt.inverse_transform(X)\n\n\n@pytest.mark.parametrize(\"method\", [\"box-cox\", \"yeo-johnson\"])\n@pytest.mark.parametrize(\"standardize\", [True, False])\n@pytest.mark.parametrize(\"X\", [X_1col, X_2d])\ndef test_power_transformer_inverse(method, standardize, X):\n    # Make sure we get the original input when applying transform and then\n    # inverse transform\n    X = np.abs(X) if method == \"box-cox\" else X\n    pt = PowerTransformer(method=method, standardize=standardize)\n    X_trans = pt.fit_transform(X)\n    assert_almost_equal(X, pt.inverse_transform(X_trans))\n\n\ndef test_power_transformer_1d():\n    X = np.abs(X_1col)\n\n    for standardize in [True, False]:\n        pt = PowerTransformer(method=\"box-cox\", standardize=standardize)\n\n        X_trans = pt.fit_transform(X)\n        X_trans_func = power_transform(X, method=\"box-cox\", standardize=standardize)\n\n        X_expected, lambda_expected = stats.boxcox(X.flatten())\n\n        if standardize:\n            X_expected = scale(X_expected)\n\n        assert_almost_equal(X_expected.reshape(-1, 1), X_trans)\n        assert_almost_equal(X_expected.reshape(-1, 1), X_trans_func)\n\n        assert_almost_equal(X, pt.inverse_transform(X_trans))\n        assert_almost_equal(lambda_expected, pt.lambdas_[0])\n\n        assert len(pt.lambdas_) == X.shape[1]\n        assert isinstance(pt.lambdas_, np.ndarray)\n\n\ndef test_power_transformer_2d():\n    X = np.abs(X_2d)\n\n    for standardize in [True, False]:\n        pt = PowerTransformer(method=\"box-cox\", standardize=standardize)\n\n        X_trans_class = pt.fit_transform(X)\n        X_trans_func = power_transform(X, method=\"box-cox\", standardize=standardize)\n\n        for X_trans in [X_trans_class, X_trans_func]:\n            for j in range(X_trans.shape[1]):\n                X_expected, lmbda = stats.boxcox(X[:, j].flatten())\n\n                if standardize"}, {"start_line": 81000, "end_line": 83000, "belongs_to": {"file_name": "test_data.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/preprocessing/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": " [[1, 1, 0], [1, 0, 1], [1, 0, 1]])\n\n\n@pytest.mark.parametrize(\n    \"sparse_container\", COO_CONTAINERS + CSC_CONTAINERS + CSR_CONTAINERS\n)\ndef test_add_dummy_feature_sparse(sparse_container):\n    X = sparse_container([[1, 0], [0, 1], [0, 1]])\n    desired_format = X.format\n    X = add_dummy_feature(X)\n    assert sparse.issparse(X) and X.format == desired_format, X\n    assert_array_equal(X.toarray(), [[1, 1, 0], [1, 0, 1], [1, 0, 1]])\n\n\ndef test_fit_cold_start():\n    X = iris.data\n    X_2d = X[:, :2]\n\n    # Scalers that have a partial_fit method\n    scalers = [\n        StandardScaler(with_mean=False, with_std=False),\n        MinMaxScaler(),\n        MaxAbsScaler(),\n    ]\n\n    for scaler in scalers:\n        scaler.fit_transform(X)\n        # with a different shape, this may break the scaler unless the internal\n        # state is reset\n        scaler.fit_transform(X_2d)\n\n\n@pytest.mark.parametrize(\"method\", [\"box-cox\", \"yeo-johnson\"])\ndef test_power_transformer_notfitted(method):\n    pt = PowerTransformer(method=method)\n    X = np.abs(X_1col)\n    with pytest.raises(NotFittedError):\n        pt.transform(X)\n    with pytest.raises(NotFittedError):\n        pt.inverse_transform(X)\n\n\n@pytest.mark.parametrize(\"method\", [\"box-cox\", \"yeo-johnson\"])\n@pytest.mark.parametrize(\"standardize\", [True, False])\n@pytest.mark.parametrize(\"X\", [X_1col, X_2d])\ndef test_power_transformer_inverse(method, standardize, X):\n    # Make sure we get the original input when applying transform and then\n    # inverse transform\n    X = np.abs(X) if method == \"box-cox\" else X\n    pt = PowerTransformer(method=method, standardize=standardize)\n    X_trans = pt.fit_transform(X)\n    assert_almost_equal(X, pt.inverse_transform(X_trans))\n\n\ndef test_power_transformer_1d():\n    X = np.abs(X_1col)\n\n    for standardize in [True, False]:\n        pt = PowerTransformer(method=\"box-cox\", standardize=standardize)\n\n        X_trans = pt.fit_transform(X)\n        X_trans_func = power_transform(X, method=\"box-cox\", standardize="}, {"start_line": 90000, "end_line": 92000, "belongs_to": {"file_name": "test_data.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/preprocessing/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "ze\", [True, False])\ndef test_power_transformer_copy_True(method, standardize):\n    # Check that neither fit, transform, fit_transform nor inverse_transform\n    # modify X inplace when copy=True\n    X = X_1col\n    if method == \"box-cox\":\n        X = np.abs(X)\n\n    X_original = X.copy()\n    assert X is not X_original  # sanity checks\n    assert_array_almost_equal(X, X_original)\n\n    pt = PowerTransformer(method, standardize=standardize, copy=True)\n\n    pt.fit(X)\n    assert_array_almost_equal(X, X_original)\n    X_trans = pt.transform(X)\n    assert X_trans is not X\n\n    X_trans = pt.fit_transform(X)\n    assert_array_almost_equal(X, X_original)\n    assert X_trans is not X\n\n    X_inv_trans = pt.inverse_transform(X_trans)\n    assert X_trans is not X_inv_trans\n\n\n@pytest.mark.parametrize(\"method\", [\"box-cox\", \"yeo-johnson\"])\n@pytest.mark.parametrize(\"standardize\", [True, False])\ndef test_power_transformer_copy_False(method, standardize):\n    # check that when copy=False fit doesn't change X inplace but transform,\n    # fit_transform and inverse_transform do.\n    X = X_1col\n    if method == \"box-cox\":\n        X = np.abs(X)\n\n    X_original = X.copy()\n    assert X is not X_original  # sanity checks\n    assert_array_almost_equal(X, X_original)\n\n    pt = PowerTransformer(method, standardize=standardize, copy=False)\n\n    pt.fit(X)\n    assert_array_almost_equal(X, X_original)  # fit didn't change X\n\n    X_trans = pt.transform(X)\n    assert X_trans is X\n\n    if method == \"box-cox\":\n        X = np.abs(X)\n    X_trans = pt.fit_transform(X)\n    assert X_trans is X\n\n    X_inv_trans = pt.inverse_transform(X_trans)\n    assert X_trans is X_inv_trans\n\n\ndef test_power_transformer_box_cox_raise_all_nans_col():\n    \"\"\"Check that box-cox raises informative when a column contains all nans.\n\n    Non-regression test for gh-26303\n    \"\"\"\n    X = rng.random_sample((4, 5))\n    X[:, 0] = np.nan\n\n    err_msg = \"Column must not be all nan.\"\n\n    pt = PowerTransformer(method=\"box-cox\")\n    with pytest.rai"}, {"start_line": 88000, "end_line": 90000, "belongs_to": {"file_name": "test_data.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/preprocessing/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "mal=2)\n    assert_almost_equal(0, X_inv_trans.mean(), decimal=1)\n    assert_almost_equal(1, X_inv_trans.std(), decimal=1)\n\n\ndef test_invserse_box_cox():\n    # output nan if the input is invalid\n    pt = PowerTransformer(method=\"box-cox\", standardize=False)\n    pt.lambdas_ = [0.5]\n    X_inv = pt.inverse_transform([[-2.1]])\n    assert np.isnan(X_inv)\n\n\ndef test_yeo_johnson_darwin_example():\n    # test from original paper \"A new family of power transformations to\n    # improve normality or symmetry\" by Yeo and Johnson.\n    X = [6.1, -8.4, 1.0, 2.0, 0.7, 2.9, 3.5, 5.1, 1.8, 3.6, 7.0, 3.0, 9.3, 7.5, -6.0]\n    X = np.array(X).reshape(-1, 1)\n    lmbda = PowerTransformer(method=\"yeo-johnson\").fit(X).lambdas_\n    assert np.allclose(lmbda, 1.305, atol=1e-3)\n\n\n@pytest.mark.parametrize(\"method\", [\"box-cox\", \"yeo-johnson\"])\ndef test_power_transformer_nans(method):\n    # Make sure lambda estimation is not influenced by NaN values\n    # and that transform() supports NaN silently\n\n    X = np.abs(X_1col)\n    pt = PowerTransformer(method=method)\n    pt.fit(X)\n    lmbda_no_nans = pt.lambdas_[0]\n\n    # concat nans at the end and check lambda stays the same\n    X = np.concatenate([X, np.full_like(X, np.nan)])\n    X = shuffle(X, random_state=0)\n\n    pt.fit(X)\n    lmbda_nans = pt.lambdas_[0]\n\n    assert_almost_equal(lmbda_no_nans, lmbda_nans, decimal=5)\n\n    X_trans = pt.transform(X)\n    assert_array_equal(np.isnan(X_trans), np.isnan(X))\n\n\n@pytest.mark.parametrize(\"method\", [\"box-cox\", \"yeo-johnson\"])\n@pytest.mark.parametrize(\"standardize\", [True, False])\ndef test_power_transformer_fit_transform(method, standardize):\n    # check that fit_transform() and fit().transform() return the same values\n    X = X_1col\n    if method == \"box-cox\":\n        X = np.abs(X)\n\n    pt = PowerTransformer(method, standardize=standardize)\n    assert_array_almost_equal(pt.fit(X).transform(X), pt.fit_transform(X))\n\n\n@pytest.mark.parametrize(\"method\", [\"box-cox\", \"yeo-johnson\"])\n@pytest.mark.parametrize(\"standardi"}, {"start_line": 83000, "end_line": 85000, "belongs_to": {"file_name": "test_data.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/preprocessing/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "standardize)\n\n        X_expected, lambda_expected = stats.boxcox(X.flatten())\n\n        if standardize:\n            X_expected = scale(X_expected)\n\n        assert_almost_equal(X_expected.reshape(-1, 1), X_trans)\n        assert_almost_equal(X_expected.reshape(-1, 1), X_trans_func)\n\n        assert_almost_equal(X, pt.inverse_transform(X_trans))\n        assert_almost_equal(lambda_expected, pt.lambdas_[0])\n\n        assert len(pt.lambdas_) == X.shape[1]\n        assert isinstance(pt.lambdas_, np.ndarray)\n\n\ndef test_power_transformer_2d():\n    X = np.abs(X_2d)\n\n    for standardize in [True, False]:\n        pt = PowerTransformer(method=\"box-cox\", standardize=standardize)\n\n        X_trans_class = pt.fit_transform(X)\n        X_trans_func = power_transform(X, method=\"box-cox\", standardize=standardize)\n\n        for X_trans in [X_trans_class, X_trans_func]:\n            for j in range(X_trans.shape[1]):\n                X_expected, lmbda = stats.boxcox(X[:, j].flatten())\n\n                if standardize:\n                    X_expected = scale(X_expected)\n\n                assert_almost_equal(X_trans[:, j], X_expected)\n                assert_almost_equal(lmbda, pt.lambdas_[j])\n\n            # Test inverse transformation\n            X_inv = pt.inverse_transform(X_trans)\n            assert_array_almost_equal(X_inv, X)\n\n        assert len(pt.lambdas_) == X.shape[1]\n        assert isinstance(pt.lambdas_, np.ndarray)\n\n\ndef test_power_transformer_boxcox_strictly_positive_exception():\n    # Exceptions should be raised for negative arrays and zero arrays when\n    # method is boxcox\n\n    pt = PowerTransformer(method=\"box-cox\")\n    pt.fit(np.abs(X_2d))\n    X_with_negatives = X_2d\n    not_positive_message = \"strictly positive\"\n\n    with pytest.raises(ValueError, match=not_positive_message):\n        pt.transform(X_with_negatives)\n\n    with pytest.raises(ValueError, match=not_positive_message):\n        pt.fit(X_with_negatives)\n\n    with pytest.raises(ValueError, match=not_positive_message):\n        "}], "retrieved_count": 10, "cost_time": 1.1713168621063232}
{"question": "What are the consequences of dtype incompatibility at each transformation stage in the dataflow dependency chain from fetch_20newsgroups through TfidfVectorizer to train_test_split, and how does this chain constrain dtype parameter propagation?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"start_line": 40000, "end_line": 42000, "belongs_to": {"file_name": "test_text.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/feature_extraction/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "world!\")\n\n\n@pytest.mark.parametrize(\"X_dtype\", [np.float32, np.float64])\ndef test_tfidf_transformer_type(X_dtype):\n    X = sparse.rand(10, 20000, dtype=X_dtype, random_state=42)\n    X_trans = TfidfTransformer().fit_transform(X)\n    assert X_trans.dtype == X.dtype\n\n\n@pytest.mark.parametrize(\n    \"csc_container, csr_container\", product(CSC_CONTAINERS, CSR_CONTAINERS)\n)\ndef test_tfidf_transformer_sparse(csc_container, csr_container):\n    X = sparse.rand(10, 20000, dtype=np.float64, random_state=42)\n    X_csc = csc_container(X)\n    X_csr = csr_container(X)\n\n    X_trans_csc = TfidfTransformer().fit_transform(X_csc)\n    X_trans_csr = TfidfTransformer().fit_transform(X_csr)\n    assert_allclose_dense_sparse(X_trans_csc, X_trans_csr)\n    assert X_trans_csc.format == X_trans_csr.format\n\n\n@pytest.mark.parametrize(\n    \"vectorizer_dtype, output_dtype, warning_expected\",\n    [\n        (np.int32, np.float64, True),\n        (np.int64, np.float64, True),\n        (np.float32, np.float32, False),\n        (np.float64, np.float64, False),\n    ],\n)\ndef test_tfidf_vectorizer_type(vectorizer_dtype, output_dtype, warning_expected):\n    X = np.array([\"numpy\", \"scipy\", \"sklearn\"])\n    vectorizer = TfidfVectorizer(dtype=vectorizer_dtype)\n\n    warning_msg_match = \"'dtype' should be used.\"\n    if warning_expected:\n        with pytest.warns(UserWarning, match=warning_msg_match):\n            X_idf = vectorizer.fit_transform(X)\n    else:\n        with warnings.catch_warnings():\n            warnings.simplefilter(\"error\", UserWarning)\n            X_idf = vectorizer.fit_transform(X)\n    assert X_idf.dtype == output_dtype\n\n\n@pytest.mark.parametrize(\n    \"vec\",\n    [\n        HashingVectorizer(ngram_range=(2, 1)),\n        CountVectorizer(ngram_range=(2, 1)),\n        TfidfVectorizer(ngram_range=(2, 1)),\n    ],\n)\ndef test_vectorizers_invalid_ngram_range(vec):\n    # vectorizers could be initialized with invalid ngram range\n    # test for raising error message\n    invalid_range = vec.ngram_range\n    message "}, {"start_line": 44000, "end_line": 46000, "belongs_to": {"file_name": "test_text.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/feature_extraction/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "that CountVectorizer._sort_features preserves the dtype of its sparse\n    feature matrix.\n\n    This test is skipped on 32bit platforms, see:\n        https://github.com/scikit-learn/scikit-learn/pull/11295\n    for more details.\n    \"\"\"\n\n    X = csr_container((5, 5), dtype=np.int64)\n\n    # force indices and indptr to int64.\n    INDICES_DTYPE = np.int64\n    X.indices = X.indices.astype(INDICES_DTYPE)\n    X.indptr = X.indptr.astype(INDICES_DTYPE)\n\n    vocabulary = {\"scikit-learn\": 0, \"is\": 1, \"great!\": 2}\n\n    Xs = CountVectorizer()._sort_features(X, vocabulary)\n\n    assert INDICES_DTYPE == Xs.indices.dtype\n\n\n@pytest.mark.parametrize(\n    \"Estimator\", [CountVectorizer, TfidfVectorizer, HashingVectorizer]\n)\ndef test_stop_word_validation_custom_preprocessor(Estimator):\n    data = [{\"text\": \"some text\"}]\n\n    vec = Estimator()\n    assert _check_stop_words_consistency(vec) is True\n\n    vec = Estimator(preprocessor=lambda x: x[\"text\"], stop_words=[\"and\"])\n    assert _check_stop_words_consistency(vec) == \"error\"\n    # checks are cached\n    assert _check_stop_words_consistency(vec) is None\n    vec.fit_transform(data)\n\n    class CustomEstimator(Estimator):\n        def build_preprocessor(self):\n            return lambda x: x[\"text\"]\n\n    vec = CustomEstimator(stop_words=[\"and\"])\n    assert _check_stop_words_consistency(vec) == \"error\"\n\n    vec = Estimator(\n        tokenizer=lambda doc: re.compile(r\"\\w{1,}\").findall(doc), stop_words=[\"and\"]\n    )\n    assert _check_stop_words_consistency(vec) is True\n\n\n@pytest.mark.parametrize(\n    \"Estimator\", [CountVectorizer, TfidfVectorizer, HashingVectorizer]\n)\n@pytest.mark.parametrize(\n    \"input_type, err_type, err_msg\",\n    [\n        (\"filename\", FileNotFoundError, \"\"),\n        (\"file\", AttributeError, \"'str' object has no attribute 'read'\"),\n    ],\n)\ndef test_callable_analyzer_error(Estimator, input_type, err_type, err_msg):\n    data = [\"this is text, not file or filename\"]\n    with pytest.raises(err_type, match=err_msg):\n        Estimato"}, {"start_line": 79000, "end_line": 81000, "belongs_to": {"file_name": "estimator_checks.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/utils", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "nput X is of some dtype\n    # X_transformed should be from the same dtype.\n    transformer = clone(transformer_orig)\n    if hasattr(transformer, \"set_output\"):\n        transformer.set_output(transform=\"default\")\n    X, y = make_blobs(\n        n_samples=30,\n        centers=[[0, 0, 0], [1, 1, 1]],\n        random_state=0,\n        cluster_std=0.1,\n    )\n    X = StandardScaler().fit_transform(X)\n    X = _enforce_estimator_tags_X(transformer_orig, X)\n\n    for dtype in get_tags(transformer_orig).transformer_tags.preserves_dtype:\n        X_cast = X.astype(dtype)\n        set_random_state(transformer)\n        X_trans1 = transformer.fit_transform(X_cast, y)\n        X_trans2 = transformer.fit(X_cast, y).transform(X_cast)\n\n        for Xt, method in zip([X_trans1, X_trans2], [\"fit_transform\", \"transform\"]):\n            if isinstance(Xt, tuple):\n                # cross-decompostion returns a tuple of (x_scores, y_scores)\n                # when given y with fit_transform; only check the first element\n                Xt = Xt[0]\n\n            # check that the output dtype is preserved\n            assert Xt.dtype == dtype, (\n                f\"{name} (method={method}) does not preserve dtype. \"\n                f\"Original/Expected dtype={dtype}, got dtype={Xt.dtype}.\"\n            )\n\n\n@ignore_warnings(category=FutureWarning)\ndef check_estimators_empty_data_messages(name, estimator_orig):\n    e = clone(estimator_orig)\n    set_random_state(e, 1)\n\n    X_zero_samples = np.empty(0).reshape(0, 3)\n    # The precise message can change depending on whether X or y is\n    # validated first. Let us test the type of exception only:\n    err_msg = (\n        f\"The estimator {name} does not raise a ValueError when an \"\n        \"empty data is used to train. Perhaps use check_array in train.\"\n    )\n    with raises(ValueError, err_msg=err_msg):\n        e.fit(X_zero_samples, [])\n\n    X_zero_features = np.empty(0).reshape(12, 0)\n    # the following y should be accepted by both classifiers and regressors\n    # "}, {"start_line": 78000, "end_line": 80000, "belongs_to": {"file_name": "estimator_checks.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/utils", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": ")\n\n\n@ignore_warnings\ndef check_estimators_dtypes(name, estimator_orig):\n    rnd = np.random.RandomState(0)\n    X_train_32 = 3 * rnd.uniform(size=(20, 5)).astype(np.float32)\n    X_train_32 = _enforce_estimator_tags_X(estimator_orig, X_train_32)\n    X_train_64 = X_train_32.astype(np.float64)\n    X_train_int_64 = X_train_32.astype(np.int64)\n    X_train_int_32 = X_train_32.astype(np.int32)\n    y = np.array([1, 2] * 10, dtype=np.int64)\n    y = _enforce_estimator_tags_y(estimator_orig, y)\n\n    methods = [\"predict\", \"transform\", \"decision_function\", \"predict_proba\"]\n\n    for X_train in [X_train_32, X_train_64, X_train_int_64, X_train_int_32]:\n        estimator = clone(estimator_orig)\n        set_random_state(estimator, 1)\n        estimator.fit(X_train, y)\n\n        for method in methods:\n            if hasattr(estimator, method):\n                getattr(estimator, method)(X_train)\n\n\ndef check_transformer_preserve_dtypes(name, transformer_orig):\n    # check that dtype are preserved meaning if input X is of some dtype\n    # X_transformed should be from the same dtype.\n    transformer = clone(transformer_orig)\n    if hasattr(transformer, \"set_output\"):\n        transformer.set_output(transform=\"default\")\n    X, y = make_blobs(\n        n_samples=30,\n        centers=[[0, 0, 0], [1, 1, 1]],\n        random_state=0,\n        cluster_std=0.1,\n    )\n    X = StandardScaler().fit_transform(X)\n    X = _enforce_estimator_tags_X(transformer_orig, X)\n\n    for dtype in get_tags(transformer_orig).transformer_tags.preserves_dtype:\n        X_cast = X.astype(dtype)\n        set_random_state(transformer)\n        X_trans1 = transformer.fit_transform(X_cast, y)\n        X_trans2 = transformer.fit(X_cast, y).transform(X_cast)\n\n        for Xt, method in zip([X_trans1, X_trans2], [\"fit_transform\", \"transform\"]):\n            if isinstance(Xt, tuple):\n                # cross-decompostion returns a tuple of (x_scores, y_scores)\n                # when given y with fit_transform; only check the first element\n"}, {"start_line": 41000, "end_line": 43000, "belongs_to": {"file_name": "test_text.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/feature_extraction/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "  (np.float64, np.float64, False),\n    ],\n)\ndef test_tfidf_vectorizer_type(vectorizer_dtype, output_dtype, warning_expected):\n    X = np.array([\"numpy\", \"scipy\", \"sklearn\"])\n    vectorizer = TfidfVectorizer(dtype=vectorizer_dtype)\n\n    warning_msg_match = \"'dtype' should be used.\"\n    if warning_expected:\n        with pytest.warns(UserWarning, match=warning_msg_match):\n            X_idf = vectorizer.fit_transform(X)\n    else:\n        with warnings.catch_warnings():\n            warnings.simplefilter(\"error\", UserWarning)\n            X_idf = vectorizer.fit_transform(X)\n    assert X_idf.dtype == output_dtype\n\n\n@pytest.mark.parametrize(\n    \"vec\",\n    [\n        HashingVectorizer(ngram_range=(2, 1)),\n        CountVectorizer(ngram_range=(2, 1)),\n        TfidfVectorizer(ngram_range=(2, 1)),\n    ],\n)\ndef test_vectorizers_invalid_ngram_range(vec):\n    # vectorizers could be initialized with invalid ngram range\n    # test for raising error message\n    invalid_range = vec.ngram_range\n    message = re.escape(\n        f\"Invalid value for ngram_range={invalid_range} \"\n        \"lower boundary larger than the upper boundary.\"\n    )\n\n    with pytest.raises(ValueError, match=message):\n        vec.fit([\"good news everyone\"])\n\n    with pytest.raises(ValueError, match=message):\n        vec.fit_transform([\"good news everyone\"])\n\n    if isinstance(vec, HashingVectorizer):\n        with pytest.raises(ValueError, match=message):\n            vec.transform([\"good news everyone\"])\n\n\ndef _check_stop_words_consistency(estimator):\n    stop_words = estimator.get_stop_words()\n    tokenize = estimator.build_tokenizer()\n    preprocess = estimator.build_preprocessor()\n    return estimator._check_stop_words_consistency(stop_words, preprocess, tokenize)\n\n\ndef test_vectorizer_stop_words_inconsistent():\n    lstr = r\"\\['and', 'll', 've'\\]\"\n    message = (\n        \"Your stop_words may be inconsistent with your \"\n        \"preprocessing. Tokenizing the stop words generated \"\n        \"tokens %s not in stop_word"}, {"start_line": 27000, "end_line": 29000, "belongs_to": {"file_name": "test_text.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/feature_extraction/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "HashingVectorizer(\n        analyzer=\"char\", alternate_sign=False, binary=True, norm=None\n    )\n    X = vect.transform(test_data)\n    assert np.max(X.data) == 1\n    assert X.dtype == np.float64\n\n    # check the ability to change the dtype\n    vect = HashingVectorizer(\n        analyzer=\"char\", alternate_sign=False, binary=True, norm=None, dtype=np.float64\n    )\n    X = vect.transform(test_data)\n    assert X.dtype == np.float64\n\n\n@pytest.mark.parametrize(\"Vectorizer\", (CountVectorizer, TfidfVectorizer))\ndef test_vectorizer_inverse_transform(Vectorizer):\n    # raw documents\n    data = ALL_FOOD_DOCS\n    vectorizer = Vectorizer()\n    transformed_data = vectorizer.fit_transform(data)\n    inversed_data = vectorizer.inverse_transform(transformed_data)\n    assert isinstance(inversed_data, list)\n\n    analyze = vectorizer.build_analyzer()\n    for doc, inversed_terms in zip(data, inversed_data):\n        terms = np.sort(np.unique(analyze(doc)))\n        inversed_terms = np.sort(np.unique(inversed_terms))\n        assert_array_equal(terms, inversed_terms)\n\n    assert sparse.issparse(transformed_data)\n    assert transformed_data.format == \"csr\"\n\n    # Test that inverse_transform also works with numpy arrays and\n    # scipy\n    transformed_data2 = transformed_data.toarray()\n    inversed_data2 = vectorizer.inverse_transform(transformed_data2)\n    for terms, terms2 in zip(inversed_data, inversed_data2):\n        assert_array_equal(np.sort(terms), np.sort(terms2))\n\n    # Check that inverse_transform also works on non CSR sparse data:\n    transformed_data3 = transformed_data.tocsc()\n    inversed_data3 = vectorizer.inverse_transform(transformed_data3)\n    for terms, terms3 in zip(inversed_data, inversed_data3):\n        assert_array_equal(np.sort(terms), np.sort(terms3))\n\n\ndef test_count_vectorizer_pipeline_grid_selection():\n    # raw documents\n    data = JUNK_FOOD_DOCS + NOTJUNK_FOOD_DOCS\n\n    # label junk food as -1, the others as +1\n    target = [-1] * len(JUNK_FOOD_DOCS) + [1] * len(NOTJ"}, {"start_line": 39000, "end_line": 41000, "belongs_to": {"file_name": "test_text.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/feature_extraction/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "_tfidfvectorizer_export_idf():\n    vect = TfidfVectorizer(use_idf=True)\n    vect.fit(JUNK_FOOD_DOCS)\n    assert_array_almost_equal(vect.idf_, vect._tfidf.idf_)\n\n\ndef test_vectorizer_vocab_clone():\n    vect_vocab = TfidfVectorizer(vocabulary=[\"the\"])\n    vect_vocab_clone = clone(vect_vocab)\n    vect_vocab.fit(ALL_FOOD_DOCS)\n    vect_vocab_clone.fit(ALL_FOOD_DOCS)\n    assert vect_vocab_clone.vocabulary_ == vect_vocab.vocabulary_\n\n\n@pytest.mark.parametrize(\n    \"Vectorizer\", (CountVectorizer, TfidfVectorizer, HashingVectorizer)\n)\ndef test_vectorizer_string_object_as_input(Vectorizer):\n    message = \"Iterable over raw text documents expected, string object received.\"\n    vec = Vectorizer()\n\n    with pytest.raises(ValueError, match=message):\n        vec.fit_transform(\"hello world!\")\n\n    with pytest.raises(ValueError, match=message):\n        vec.fit(\"hello world!\")\n    vec.fit([\"some text\", \"some other text\"])\n\n    with pytest.raises(ValueError, match=message):\n        vec.transform(\"hello world!\")\n\n\n@pytest.mark.parametrize(\"X_dtype\", [np.float32, np.float64])\ndef test_tfidf_transformer_type(X_dtype):\n    X = sparse.rand(10, 20000, dtype=X_dtype, random_state=42)\n    X_trans = TfidfTransformer().fit_transform(X)\n    assert X_trans.dtype == X.dtype\n\n\n@pytest.mark.parametrize(\n    \"csc_container, csr_container\", product(CSC_CONTAINERS, CSR_CONTAINERS)\n)\ndef test_tfidf_transformer_sparse(csc_container, csr_container):\n    X = sparse.rand(10, 20000, dtype=np.float64, random_state=42)\n    X_csc = csc_container(X)\n    X_csr = csr_container(X)\n\n    X_trans_csc = TfidfTransformer().fit_transform(X_csc)\n    X_trans_csr = TfidfTransformer().fit_transform(X_csr)\n    assert_allclose_dense_sparse(X_trans_csc, X_trans_csr)\n    assert X_trans_csc.format == X_trans_csr.format\n\n\n@pytest.mark.parametrize(\n    \"vectorizer_dtype, output_dtype, warning_expected\",\n    [\n        (np.int32, np.float64, True),\n        (np.int64, np.float64, True),\n        (np.float32, np.float32, False),\n      "}, {"start_line": 2000, "end_line": 4000, "belongs_to": {"file_name": "test_base.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/feature_selection/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "p)\n    assert_array_equal(Xt, Xt_actual.toarray())\n    assert_array_equal(Xt, Xt_actual2.toarray())\n\n    # Check dtype matches\n    assert np.int32 == sel.transform(X_sp.astype(np.int32)).dtype\n    assert np.float32 == sel.transform(X_sp.astype(np.float32)).dtype\n\n    # Check wrong shape raises error\n    with pytest.raises(ValueError):\n        sel.transform(np.array([[1], [2]]))\n\n\ndef test_inverse_transform_dense():\n    sel = StepSelector()\n    Xinv_actual = sel.fit(X, y).inverse_transform(Xt)\n    assert_array_equal(Xinv, Xinv_actual)\n\n    # Check dtype matches\n    assert np.int32 == sel.inverse_transform(Xt.astype(np.int32)).dtype\n    assert np.float32 == sel.inverse_transform(Xt.astype(np.float32)).dtype\n\n    # Check 1d list and other dtype:\n    names_inv_actual = sel.inverse_transform([feature_names_t])\n    assert_array_equal(feature_names_inv, names_inv_actual.ravel())\n\n    # Check wrong shape raises error\n    with pytest.raises(ValueError):\n        sel.inverse_transform(np.array([[1], [2]]))\n\n\n@pytest.mark.parametrize(\"csc_container\", CSC_CONTAINERS)\ndef test_inverse_transform_sparse(csc_container):\n    X_sp = csc_container(X)\n    Xt_sp = csc_container(Xt)\n    sel = StepSelector()\n    Xinv_actual = sel.fit(X_sp).inverse_transform(Xt_sp)\n    assert_array_equal(Xinv, Xinv_actual.toarray())\n\n    # Check dtype matches\n    assert np.int32 == sel.inverse_transform(Xt_sp.astype(np.int32)).dtype\n    assert np.float32 == sel.inverse_transform(Xt_sp.astype(np.float32)).dtype\n\n    # Check wrong shape raises error\n    with pytest.raises(ValueError):\n        sel.inverse_transform(np.array([[1], [2]]))\n\n\ndef test_get_support():\n    sel = StepSelector()\n    sel.fit(X, y)\n    assert_array_equal(support, sel.get_support())\n    assert_array_equal(support_inds, sel.get_support(indices=True))\n\n\ndef test_output_dataframe():\n    \"\"\"Check output dtypes for dataframes is consistent with the input dtypes.\"\"\"\n    pd = pytest.importorskip(\"pandas\")\n\n    X = pd.DataFrame(\n        {\n       "}, {"start_line": 51000, "end_line": 52571, "belongs_to": {"file_name": "test_text.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/feature_extraction/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "transform with the copy parameter.\"\"\"\n    X = sparse.rand(10, 20000, dtype=np.float64, random_state=42)\n    X_csr = csr_container(X)\n\n    # keep a copy of the original matrix for later comparison\n    X_csr_original = X_csr.copy()\n\n    transformer = TfidfTransformer().fit(X_csr)\n\n    X_transform = transformer.transform(X_csr, copy=True)\n    assert_allclose_dense_sparse(X_csr, X_csr_original)\n    assert X_transform is not X_csr\n\n    X_transform = transformer.transform(X_csr, copy=False)\n    assert X_transform is X_csr\n    with pytest.raises(AssertionError):\n        assert_allclose_dense_sparse(X_csr, X_csr_original)\n\n\n@pytest.mark.parametrize(\"dtype\", [np.float32, np.float64])\ndef test_tfidf_vectorizer_perserve_dtype_idf(dtype):\n    \"\"\"Check that `idf_` has the same dtype as the input data.\n\n    Non-regression test for:\n    https://github.com/scikit-learn/scikit-learn/issues/30016\n    \"\"\"\n    X = [str(uuid.uuid4()) for i in range(100_000)]\n    vectorizer = TfidfVectorizer(dtype=dtype).fit(X)\n    assert vectorizer.idf_.dtype == dtype\n\n\ndef test_hashing_vectorizer_requires_fit_tag():\n    \"\"\"Test that HashingVectorizer has requires_fit=False tag.\"\"\"\n    vectorizer = HashingVectorizer()\n    tags = vectorizer.__sklearn_tags__()\n    assert not tags.requires_fit\n\n\ndef test_hashing_vectorizer_transform_without_fit():\n    \"\"\"Test that HashingVectorizer can transform without fitting.\"\"\"\n    vectorizer = HashingVectorizer(n_features=10)\n    corpus = [\"This is test\", \"Another test\"]\n    result = vectorizer.transform(corpus)\n    assert result.shape == (2, 10)\n"}, {"start_line": 77000, "end_line": 79000, "belongs_to": {"file_name": "estimator_checks.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/utils", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "d = np.random.RandomState(0)\n    n_samples = 30\n    X = rnd.uniform(size=(n_samples, 3))\n    X = _enforce_estimator_tags_X(estimator_orig, X)\n    y = np.arange(n_samples) % 3\n    estimator = clone(estimator_orig)\n    y = _enforce_estimator_tags_y(estimator, y)\n    set_random_state(estimator)\n\n    funcs = [\"fit\", \"score\", \"partial_fit\", \"fit_predict\", \"fit_transform\"]\n    for func_name in funcs:\n        func = getattr(estimator, func_name, None)\n        if func is not None:\n            func(X, y)\n            args = [p.name for p in signature(func).parameters.values()]\n            if args[0] == \"self\":\n                # available_if makes methods into functions\n                # with an explicit \"self\", so need to shift arguments\n                args = args[1:]\n            assert args[1] in [\"y\", \"Y\"], (\n                \"Expected y or Y as second argument for method \"\n                \"%s of %s. Got arguments: %r.\"\n                % (func_name, type(estimator).__name__, args)\n            )\n\n\n@ignore_warnings\ndef check_estimators_dtypes(name, estimator_orig):\n    rnd = np.random.RandomState(0)\n    X_train_32 = 3 * rnd.uniform(size=(20, 5)).astype(np.float32)\n    X_train_32 = _enforce_estimator_tags_X(estimator_orig, X_train_32)\n    X_train_64 = X_train_32.astype(np.float64)\n    X_train_int_64 = X_train_32.astype(np.int64)\n    X_train_int_32 = X_train_32.astype(np.int32)\n    y = np.array([1, 2] * 10, dtype=np.int64)\n    y = _enforce_estimator_tags_y(estimator_orig, y)\n\n    methods = [\"predict\", \"transform\", \"decision_function\", \"predict_proba\"]\n\n    for X_train in [X_train_32, X_train_64, X_train_int_64, X_train_int_32]:\n        estimator = clone(estimator_orig)\n        set_random_state(estimator, 1)\n        estimator.fit(X_train, y)\n\n        for method in methods:\n            if hasattr(estimator, method):\n                getattr(estimator, method)(X_train)\n\n\ndef check_transformer_preserve_dtypes(name, transformer_orig):\n    # check that dtype are preserved meaning if i"}], "retrieved_count": 10, "cost_time": 1.2031528949737549}
{"question": "How does the delegation of the actual curve computation to `from_predictions` after response value extraction enable code reuse between estimator-based and prediction-based visualization workflows, and what is the significance of this design pattern?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"start_line": 15000, "end_line": 17000, "belongs_to": {"file_name": "roc_curve.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/metrics/_plot", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "_train, y_test = train_test_split(\n        ...     X, y, random_state=0)\n        >>> clf = SVC(random_state=0).fit(X_train, y_train)\n        >>> RocCurveDisplay.from_estimator(\n        ...    clf, X_test, y_test)\n        <...>\n        >>> plt.show()\n        \"\"\"\n        y_score, pos_label, name = cls._validate_and_get_response_values(\n            estimator,\n            X,\n            y,\n            response_method=response_method,\n            pos_label=pos_label,\n            name=name,\n        )\n\n        return cls.from_predictions(\n            y_true=y,\n            y_score=y_score,\n            sample_weight=sample_weight,\n            drop_intermediate=drop_intermediate,\n            pos_label=pos_label,\n            name=name,\n            ax=ax,\n            curve_kwargs=curve_kwargs,\n            plot_chance_level=plot_chance_level,\n            chance_level_kw=chance_level_kw,\n            despine=despine,\n            **kwargs,\n        )\n\n    @classmethod\n    def from_predictions(\n        cls,\n        y_true,\n        y_score=None,\n        *,\n        sample_weight=None,\n        drop_intermediate=True,\n        pos_label=None,\n        name=None,\n        ax=None,\n        curve_kwargs=None,\n        plot_chance_level=False,\n        chance_level_kw=None,\n        despine=False,\n        y_pred=\"deprecated\",\n        **kwargs,\n    ):\n        \"\"\"Plot ROC curve given the true and predicted values.\n\n        For general information regarding `scikit-learn` visualization tools,\n        see the :ref:`Visualization Guide <visualizations>`.\n        For guidance on interpreting these plots, refer to the :ref:`Model\n        Evaluation Guide <roc_metrics>`.\n\n        .. versionadded:: 1.0\n\n        Parameters\n        ----------\n        y_true : array-like of shape (n_samples,)\n            True labels.\n\n        y_score : array-like of shape (n_samples,)\n            Target scores, can either be probability estimates of the positive\n            class, confidence values, or non-thresholded measure"}, {"start_line": 14000, "end_line": 16000, "belongs_to": {"file_name": "roc_curve.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/metrics/_plot", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "\n\n            .. deprecated:: 1.7\n                kwargs is deprecated and will be removed in 1.9. Pass matplotlib\n                arguments to `curve_kwargs` as a dictionary instead.\n\n        Returns\n        -------\n        display : :class:`~sklearn.metrics.RocCurveDisplay`\n            The ROC Curve display.\n\n        See Also\n        --------\n        roc_curve : Compute Receiver operating characteristic (ROC) curve.\n        RocCurveDisplay.from_predictions : ROC Curve visualization given the\n            probabilities of scores of a classifier.\n        roc_auc_score : Compute the area under the ROC curve.\n\n        Examples\n        --------\n        >>> import matplotlib.pyplot as plt\n        >>> from sklearn.datasets import make_classification\n        >>> from sklearn.metrics import RocCurveDisplay\n        >>> from sklearn.model_selection import train_test_split\n        >>> from sklearn.svm import SVC\n        >>> X, y = make_classification(random_state=0)\n        >>> X_train, X_test, y_train, y_test = train_test_split(\n        ...     X, y, random_state=0)\n        >>> clf = SVC(random_state=0).fit(X_train, y_train)\n        >>> RocCurveDisplay.from_estimator(\n        ...    clf, X_test, y_test)\n        <...>\n        >>> plt.show()\n        \"\"\"\n        y_score, pos_label, name = cls._validate_and_get_response_values(\n            estimator,\n            X,\n            y,\n            response_method=response_method,\n            pos_label=pos_label,\n            name=name,\n        )\n\n        return cls.from_predictions(\n            y_true=y,\n            y_score=y_score,\n            sample_weight=sample_weight,\n            drop_intermediate=drop_intermediate,\n            pos_label=pos_label,\n            name=name,\n            ax=ax,\n            curve_kwargs=curve_kwargs,\n            plot_chance_level=plot_chance_level,\n            chance_level_kw=chance_level_kw,\n            despine=despine,\n            **kwargs,\n        )\n\n    @classmethod\n    def from_predictions(\n        "}, {"start_line": 1000, "end_line": 3000, "belongs_to": {"file_name": "_plotting.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/utils", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "= plt.subplots()\n\n        # Display classes are in process of changing from `estimator_name` to `name`.\n        # Try old attr name: `estimator_name` first.\n        if name is None:\n            name = getattr(self, \"estimator_name\", getattr(self, \"name\", None))\n        return ax, ax.figure, name\n\n    @classmethod\n    def _validate_and_get_response_values(\n        cls, estimator, X, y, *, response_method=\"auto\", pos_label=None, name=None\n    ):\n        check_matplotlib_support(f\"{cls.__name__}.from_estimator\")\n\n        name = estimator.__class__.__name__ if name is None else name\n\n        y_pred, pos_label = _get_response_values_binary(\n            estimator,\n            X,\n            response_method=response_method,\n            pos_label=pos_label,\n        )\n\n        return y_pred, pos_label, name\n\n    @classmethod\n    def _validate_from_predictions_params(\n        cls, y_true, y_pred, *, sample_weight=None, pos_label=None, name=None\n    ):\n        check_matplotlib_support(f\"{cls.__name__}.from_predictions\")\n\n        if type_of_target(y_true) != \"binary\":\n            raise ValueError(\n                f\"The target y is not binary. Got {type_of_target(y_true)} type of\"\n                \" target.\"\n            )\n\n        check_consistent_length(y_true, y_pred, sample_weight)\n        pos_label = _check_pos_label_consistency(pos_label, y_true)\n\n        name = name if name is not None else \"Classifier\"\n\n        return pos_label, name\n\n    @classmethod\n    def _validate_from_cv_results_params(\n        cls,\n        cv_results,\n        X,\n        y,\n        *,\n        sample_weight,\n        pos_label,\n    ):\n        check_matplotlib_support(f\"{cls.__name__}.from_cv_results\")\n\n        required_keys = {\"estimator\", \"indices\"}\n        if not all(key in cv_results for key in required_keys):\n            raise ValueError(\n                \"`cv_results` does not contain one of the following required keys: \"\n                f\"{required_keys}. Set explicitly the parameters \"\n          "}, {"start_line": 14000, "end_line": 16000, "belongs_to": {"file_name": "_partial_dependence.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/inspection", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "        averaged_predictions.append(np.average(pred, axis=0, weights=sample_weight))\n\n    n_samples = X.shape[0]\n\n    # reshape to (n_targets, n_instances, n_points) where n_targets is:\n    # - 1 for non-multioutput regression and binary classification (shape is\n    #   already correct in those cases)\n    # - n_tasks for multi-output regression\n    # - n_classes for multiclass classification.\n    predictions = np.array(predictions).T\n    if is_regressor(est) and predictions.ndim == 2:\n        # non-multioutput regression, shape is (n_instances, n_points,)\n        predictions = predictions.reshape(n_samples, -1)\n    elif is_classifier(est) and predictions.shape[0] == 2:\n        # Binary classification, shape is (2, n_instances, n_points).\n        # we output the effect of **positive** class\n        predictions = predictions[1]\n        predictions = predictions.reshape(n_samples, -1)\n\n    # reshape averaged_predictions to (n_targets, n_points) where n_targets is:\n    # - 1 for non-multioutput regression and binary classification (shape is\n    #   already correct in those cases)\n    # - n_tasks for multi-output regression\n    # - n_classes for multiclass classification.\n    averaged_predictions = np.array(averaged_predictions).T\n    if averaged_predictions.ndim == 1:\n        # reshape to (1, n_points) for consistency with\n        # _partial_dependence_recursion\n        averaged_predictions = averaged_predictions.reshape(1, -1)\n\n    return averaged_predictions, predictions\n\n\n@validate_params(\n    {\n        \"estimator\": [\n            HasMethods([\"fit\", \"predict\"]),\n            HasMethods([\"fit\", \"predict_proba\"]),\n            HasMethods([\"fit\", \"decision_function\"]),\n        ],\n        \"X\": [\"array-like\", \"sparse matrix\"],\n        \"features\": [\"array-like\", Integral, str],\n        \"sample_weight\": [\"array-like\", None],\n        \"categorical_features\": [\"array-like\", None],\n        \"feature_names\": [\"array-like\", None],\n        \"response_method\": [StrOptions({\"auto\", \"pred"}, {"start_line": 11000, "end_line": 13000, "belongs_to": {"file_name": "roc_curve.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/metrics/_plot", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "       y,\n        *,\n        sample_weight=None,\n        drop_intermediate=True,\n        response_method=\"auto\",\n        pos_label=None,\n        name=None,\n        ax=None,\n        curve_kwargs=None,\n        plot_chance_level=False,\n        chance_level_kw=None,\n        despine=False,\n        **kwargs,\n    ):\n        \"\"\"Create a ROC Curve display from an estimator.\n\n        For general information regarding `scikit-learn` visualization tools,\n        see the :ref:`Visualization Guide <visualizations>`.\n        For guidance on interpreting these plots, refer to the :ref:`Model\n        Evaluation Guide <roc_metrics>`.\n\n        Parameters\n        ----------\n        estimator : estimator instance\n            Fitted classifier or a fitted :class:`~sklearn.pipeline.Pipeline`\n            in which the last estimator is a classifier.\n\n        X : {array-like, sparse matrix} of shape (n_samples, n_features)\n            Input values.\n\n        y : array-like of shape (n_samples,)\n            Target values.\n\n        sample_weight : array-like of shape (n_samples,), default=None\n            Sample weights.\n\n        drop_intermediate : bool, default=True\n            Whether to drop thresholds where the resulting point is collinear\n            with its neighbors in ROC space. This has no effect on the ROC AUC\n            or visual shape of the curve, but reduces the number of plotted\n            points.\n\n        response_method : {'predict_proba', 'decision_function', 'auto'} \\\n                default='auto'\n            Specifies whether to use :term:`predict_proba` or\n            :term:`decision_function` as the target response. If set to 'auto',\n            :term:`predict_proba` is tried first and if it does not exist\n            :term:`decision_function` is tried next.\n\n        pos_label : int, float, bool or str, default=None\n            The class considered as the positive class when computing the ROC AUC.\n            By default, `estimators.classes_[1]` is considered\n        "}, {"start_line": 13000, "end_line": 15000, "belongs_to": {"file_name": "precision_recall_curve.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/metrics/_plot", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "        Examples\n        --------\n        >>> import matplotlib.pyplot as plt\n        >>> from sklearn.datasets import make_classification\n        >>> from sklearn.metrics import PrecisionRecallDisplay\n        >>> from sklearn.model_selection import train_test_split\n        >>> from sklearn.linear_model import LogisticRegression\n        >>> X, y = make_classification(random_state=0)\n        >>> X_train, X_test, y_train, y_test = train_test_split(\n        ...         X, y, random_state=0)\n        >>> clf = LogisticRegression()\n        >>> clf.fit(X_train, y_train)\n        LogisticRegression()\n        >>> PrecisionRecallDisplay.from_estimator(\n        ...    clf, X_test, y_test)\n        <...>\n        >>> plt.show()\n        \"\"\"\n        y_score, pos_label, name = cls._validate_and_get_response_values(\n            estimator,\n            X,\n            y,\n            response_method=response_method,\n            pos_label=pos_label,\n            name=name,\n        )\n\n        return cls.from_predictions(\n            y,\n            y_score,\n            sample_weight=sample_weight,\n            name=name,\n            pos_label=pos_label,\n            drop_intermediate=drop_intermediate,\n            ax=ax,\n            plot_chance_level=plot_chance_level,\n            chance_level_kw=chance_level_kw,\n            despine=despine,\n            **kwargs,\n        )\n\n    @classmethod\n    def from_predictions(\n        cls,\n        y_true,\n        y_score=None,\n        *,\n        sample_weight=None,\n        drop_intermediate=False,\n        pos_label=None,\n        name=None,\n        ax=None,\n        plot_chance_level=False,\n        chance_level_kw=None,\n        despine=False,\n        y_pred=\"deprecated\",\n        **kwargs,\n    ):\n        \"\"\"Plot precision-recall curve given binary class predictions.\n\n        For general information regarding `scikit-learn` visualization tools, see\n        the :ref:`Visualization Guide <visualizations>`.\n        For guidance on interpreting these plots, refer"}, {"start_line": 9000, "end_line": 11000, "belongs_to": {"file_name": "roc_curve.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/metrics/_plot", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "_auc)}\n            else:\n                legend_metric = {\"mean\": None, \"std\": None}\n        else:\n            roc_auc = roc_auc if roc_auc is not None else [None] * n_curves\n            legend_metric = {\"metric\": roc_auc}\n\n        curve_kwargs = self._validate_curve_kwargs(\n            n_curves,\n            name,\n            legend_metric,\n            \"AUC\",\n            curve_kwargs=curve_kwargs,\n            **kwargs,\n        )\n\n        default_chance_level_line_kw = {\n            \"label\": \"Chance level (AUC = 0.5)\",\n            \"color\": \"k\",\n            \"linestyle\": \"--\",\n        }\n\n        if chance_level_kw is None:\n            chance_level_kw = {}\n\n        chance_level_kw = _validate_style_kwargs(\n            default_chance_level_line_kw, chance_level_kw\n        )\n\n        self.line_ = []\n        for fpr, tpr, line_kw in zip(fpr, tpr, curve_kwargs):\n            self.line_.extend(self.ax_.plot(fpr, tpr, **line_kw))\n        # Return single artist if only one curve is plotted\n        if len(self.line_) == 1:\n            self.line_ = self.line_[0]\n\n        info_pos_label = (\n            f\" (Positive label: {self.pos_label})\" if self.pos_label is not None else \"\"\n        )\n\n        xlabel = \"False Positive Rate\" + info_pos_label\n        ylabel = \"True Positive Rate\" + info_pos_label\n        self.ax_.set(\n            xlabel=xlabel,\n            xlim=(-0.01, 1.01),\n            ylabel=ylabel,\n            ylim=(-0.01, 1.01),\n            aspect=\"equal\",\n        )\n\n        if plot_chance_level:\n            (self.chance_level_,) = self.ax_.plot((0, 1), (0, 1), **chance_level_kw)\n        else:\n            self.chance_level_ = None\n\n        if despine:\n            _despine(self.ax_)\n\n        if curve_kwargs[0].get(\"label\") is not None or (\n            plot_chance_level and chance_level_kw.get(\"label\") is not None\n        ):\n            self.ax_.legend(loc=\"lower right\")\n\n        return self\n\n    @classmethod\n    def from_estimator(\n        cls,\n        estimator,\n        X,\n "}, {"start_line": 55000, "end_line": 57000, "belongs_to": {"file_name": "calibration.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "imator is\n            used.\n\n        ax : matplotlib axes, default=None\n            Axes object to plot on. If `None`, a new figure and axes is\n            created.\n\n        ref_line : bool, default=True\n            If `True`, plots a reference line representing a perfectly\n            calibrated classifier.\n\n        **kwargs : dict\n            Keyword arguments to be passed to :func:`matplotlib.pyplot.plot`.\n\n        Returns\n        -------\n        display : :class:`~sklearn.calibration.CalibrationDisplay`.\n            Object that stores computed values.\n\n        See Also\n        --------\n        CalibrationDisplay.from_predictions : Plot calibration curve using true\n            and predicted labels.\n\n        Examples\n        --------\n        >>> import matplotlib.pyplot as plt\n        >>> from sklearn.datasets import make_classification\n        >>> from sklearn.model_selection import train_test_split\n        >>> from sklearn.linear_model import LogisticRegression\n        >>> from sklearn.calibration import CalibrationDisplay\n        >>> X, y = make_classification(random_state=0)\n        >>> X_train, X_test, y_train, y_test = train_test_split(\n        ...     X, y, random_state=0)\n        >>> clf = LogisticRegression(random_state=0)\n        >>> clf.fit(X_train, y_train)\n        LogisticRegression(random_state=0)\n        >>> disp = CalibrationDisplay.from_estimator(clf, X_test, y_test)\n        >>> plt.show()\n        \"\"\"\n        y_prob, pos_label, name = cls._validate_and_get_response_values(\n            estimator,\n            X,\n            y,\n            response_method=\"predict_proba\",\n            pos_label=pos_label,\n            name=name,\n        )\n\n        return cls.from_predictions(\n            y,\n            y_prob,\n            n_bins=n_bins,\n            strategy=strategy,\n            pos_label=pos_label,\n            name=name,\n            ref_line=ref_line,\n            ax=ax,\n            **kwargs,\n        )\n\n    @classmethod\n    def from_predictions(\n      "}, {"start_line": 20000, "end_line": 22000, "belongs_to": {"file_name": "decision_boundary.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/inspection/_plot", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "\n                pos_label=class_of_interest,\n                return_response_method_used=True,\n            )\n        except ValueError as exc:\n            if \"is not a valid label\" in str(exc):\n                # re-raise a more informative error message since `pos_label` is unknown\n                # to our user when interacting with\n                # `DecisionBoundaryDisplay.from_estimator`\n                raise ValueError(\n                    f\"class_of_interest={class_of_interest} is not a valid label: It \"\n                    f\"should be one of {estimator.classes_}\"\n                ) from exc\n            raise\n\n        # convert classes predictions into integers\n        if response_method_used == \"predict\" and hasattr(estimator, \"classes_\"):\n            encoder = LabelEncoder()\n            encoder.classes_ = estimator.classes_\n            response = encoder.transform(response)\n\n        if response.ndim == 1:\n            response = response.reshape(*xx0.shape)\n        else:\n            if is_regressor(estimator):\n                raise ValueError(\"Multi-output regressors are not supported\")\n\n            if class_of_interest is not None:\n                # For the multiclass case, `_get_response_values` returns the response\n                # as-is. Thus, we have a column per class and we need to select the\n                # column corresponding to the positive class.\n                col_idx = np.flatnonzero(estimator.classes_ == class_of_interest)[0]\n                response = response[:, col_idx].reshape(*xx0.shape)\n            else:\n                response = response.reshape(*xx0.shape, response.shape[-1])\n\n        if xlabel is None:\n            xlabel = X.columns[0] if hasattr(X, \"columns\") else \"\"\n\n        if ylabel is None:\n            ylabel = X.columns[1] if hasattr(X, \"columns\") else \"\"\n\n        display = cls(\n            xx0=xx0,\n            xx1=xx1,\n            response=response,\n            multiclass_colors=multiclass_colors,\n            xlabel=xlabel,\n"}, {"start_line": 6000, "end_line": 8000, "belongs_to": {"file_name": "det_curve.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/metrics/_plot", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": " = SVC(random_state=0).fit(X_train, y_train)\n        >>> DetCurveDisplay.from_estimator(\n        ...    clf, X_test, y_test)\n        <...>\n        >>> plt.show()\n        \"\"\"\n        y_score, pos_label, name = cls._validate_and_get_response_values(\n            estimator,\n            X,\n            y,\n            response_method=response_method,\n            pos_label=pos_label,\n            name=name,\n        )\n\n        return cls.from_predictions(\n            y_true=y,\n            y_score=y_score,\n            sample_weight=sample_weight,\n            drop_intermediate=drop_intermediate,\n            name=name,\n            ax=ax,\n            pos_label=pos_label,\n            **kwargs,\n        )\n\n    @classmethod\n    def from_predictions(\n        cls,\n        y_true,\n        y_score=None,\n        *,\n        sample_weight=None,\n        drop_intermediate=True,\n        pos_label=None,\n        name=None,\n        ax=None,\n        y_pred=\"deprecated\",\n        **kwargs,\n    ):\n        \"\"\"Plot the DET curve given the true and predicted labels.\n\n        For general information regarding `scikit-learn` visualization tools, see\n        the :ref:`Visualization Guide <visualizations>`.\n        For guidance on interpreting these plots, refer to the\n        :ref:`Model Evaluation Guide <det_curve>`.\n\n        .. versionadded:: 1.0\n\n        Parameters\n        ----------\n        y_true : array-like of shape (n_samples,)\n            True labels.\n\n        y_score : array-like of shape (n_samples,)\n            Target scores, can either be probability estimates of the positive\n            class, confidence values, or non-thresholded measure of decisions\n            (as returned by `decision_function` on some classifiers).\n\n            .. versionadded:: 1.8\n                `y_pred` has been renamed to `y_score`.\n\n        sample_weight : array-like of shape (n_samples,), default=None\n            Sample weights.\n\n        drop_intermediate : bool, default=True\n            Whether to drop thresholds"}], "retrieved_count": 10, "cost_time": 1.1858320236206055}
{"question": "How does _get_visual_block implement the extraction and validation of parallel estimator metadata from a FeatureUnion's transformer_list structure?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"start_line": 3000, "end_line": 5000, "belongs_to": {"file_name": "test_estimator.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/utils/_repr_html/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "assert est_html_info.names == est.__class__.__name__\n    assert est_html_info.name_details == str(est)\n\n\ndef test_get_visual_block_pipeline():\n    pipe = Pipeline(\n        [\n            (\"imputer\", SimpleImputer()),\n            (\"do_nothing\", \"passthrough\"),\n            (\"do_nothing_more\", None),\n            (\"classifier\", LogisticRegression()),\n        ]\n    )\n    est_html_info = _get_visual_block(pipe)\n    assert est_html_info.kind == \"serial\"\n    assert est_html_info.estimators == tuple(step[1] for step in pipe.steps)\n    assert est_html_info.names == (\n        \"imputer: SimpleImputer\",\n        \"do_nothing: passthrough\",\n        \"do_nothing_more: passthrough\",\n        \"classifier: LogisticRegression\",\n    )\n    assert est_html_info.name_details == [str(est) for _, est in pipe.steps]\n\n\ndef test_get_visual_block_feature_union():\n    f_union = FeatureUnion([(\"pca\", PCA()), (\"svd\", TruncatedSVD())])\n    est_html_info = _get_visual_block(f_union)\n    assert est_html_info.kind == \"parallel\"\n    assert est_html_info.names == (\"pca\", \"svd\")\n    assert est_html_info.estimators == tuple(\n        trans[1] for trans in f_union.transformer_list\n    )\n    assert est_html_info.name_details == (None, None)\n\n\ndef test_get_visual_block_voting():\n    clf = VotingClassifier(\n        [(\"log_reg\", LogisticRegression()), (\"mlp\", MLPClassifier())]\n    )\n    est_html_info = _get_visual_block(clf)\n    assert est_html_info.kind == \"parallel\"\n    assert est_html_info.estimators == tuple(trans[1] for trans in clf.estimators)\n    assert est_html_info.names == (\"log_reg\", \"mlp\")\n    assert est_html_info.name_details == (None, None)\n\n\ndef test_get_visual_block_column_transformer():\n    ct = ColumnTransformer(\n        [(\"pca\", PCA(), [\"num1\", \"num2\"]), (\"svd\", TruncatedSVD, [0, 3])]\n    )\n    est_html_info = _get_visual_block(ct)\n    assert est_html_info.kind == \"parallel\"\n    assert est_html_info.estimators == tuple(trans[1] for trans in ct.transformers)\n    assert est_html_info.names == (\"pca\""}, {"start_line": 7000, "end_line": 9000, "belongs_to": {"file_name": "estimator.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/utils/_repr_html", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "            else \"\"\n        )\n\n        label_html = (\n            f'<label for=\"{est_id}\" class=\"sk-toggleable__label {is_fitted_css_class} '\n            f'sk-toggleable__label-arrow\">{name_caption_div}{links_div}</label>'\n        )\n\n        fmt_str = (\n            f'<input class=\"sk-toggleable__control sk-hidden--visually\" id=\"{est_id}\" '\n            f'type=\"checkbox\" {checked_str}>{label_html}<div '\n            f'class=\"sk-toggleable__content {is_fitted_css_class}\" '\n            f'data-param-prefix=\"{html.escape(param_prefix)}\">'\n        )\n\n        if params:\n            fmt_str = \"\".join([fmt_str, f\"{params}</div>\"])\n        elif name_details and (\"Pipeline\" not in name):\n            fmt_str = \"\".join([fmt_str, f\"<pre>{name_details}</pre></div>\"])\n\n        out.write(fmt_str)\n    else:\n        out.write(f\"<label>{name}</label>\")\n    out.write(\"</div></div>\")  # outer_class inner_class\n\n\ndef _get_visual_block(estimator):\n    \"\"\"Generate information about how to display an estimator.\"\"\"\n    if hasattr(estimator, \"_sk_visual_block_\"):\n        try:\n            return estimator._sk_visual_block_()\n        except Exception:\n            return _VisualBlock(\n                \"single\",\n                estimator,\n                names=estimator.__class__.__name__,\n                name_details=str(estimator),\n            )\n\n    if isinstance(estimator, str):\n        return _VisualBlock(\n            \"single\", estimator, names=estimator, name_details=estimator\n        )\n    elif estimator is None:\n        return _VisualBlock(\"single\", estimator, names=\"None\", name_details=\"None\")\n\n    # check if estimator looks like a meta estimator (wraps estimators)\n    if hasattr(estimator, \"get_params\") and not isclass(estimator):\n        estimators = [\n            (key, est)\n            for key, est in estimator.get_params(deep=False).items()\n            if hasattr(est, \"get_params\") and hasattr(est, \"fit\") and not isclass(est)\n        ]\n        if estimators:\n            return _VisualBlo"}, {"start_line": 8000, "end_line": 10000, "belongs_to": {"file_name": "estimator.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/utils/_repr_html", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "\"\n    if hasattr(estimator, \"_sk_visual_block_\"):\n        try:\n            return estimator._sk_visual_block_()\n        except Exception:\n            return _VisualBlock(\n                \"single\",\n                estimator,\n                names=estimator.__class__.__name__,\n                name_details=str(estimator),\n            )\n\n    if isinstance(estimator, str):\n        return _VisualBlock(\n            \"single\", estimator, names=estimator, name_details=estimator\n        )\n    elif estimator is None:\n        return _VisualBlock(\"single\", estimator, names=\"None\", name_details=\"None\")\n\n    # check if estimator looks like a meta estimator (wraps estimators)\n    if hasattr(estimator, \"get_params\") and not isclass(estimator):\n        estimators = [\n            (key, est)\n            for key, est in estimator.get_params(deep=False).items()\n            if hasattr(est, \"get_params\") and hasattr(est, \"fit\") and not isclass(est)\n        ]\n        if estimators:\n            return _VisualBlock(\n                \"parallel\",\n                [est for _, est in estimators],\n                names=[f\"{key}: {est.__class__.__name__}\" for key, est in estimators],\n                name_details=[str(est) for _, est in estimators],\n            )\n\n    return _VisualBlock(\n        \"single\",\n        estimator,\n        names=estimator.__class__.__name__,\n        name_details=str(estimator),\n    )\n\n\ndef _write_estimator_html(\n    out,\n    estimator,\n    estimator_label,\n    estimator_label_details,\n    is_fitted_css_class,\n    is_fitted_icon=\"\",\n    first_call=False,\n    param_prefix=\"\",\n):\n    \"\"\"Write estimator to html in serial, parallel, or by itself (single).\n\n    For multiple estimators, this function is called recursively.\n\n    Parameters\n    ----------\n    out : file-like object\n        The file to write the HTML representation to.\n    estimator : estimator object\n        The estimator to visualize.\n    estimator_label : str\n        The label for the estimator. It corresponds eithe"}, {"start_line": 80000, "end_line": 82000, "belongs_to": {"file_name": "pipeline.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "urn sparse.hstack(Xs).tocsr()\n\n        return np.hstack(Xs)\n\n    def _update_transformer_list(self, transformers):\n        transformers = iter(transformers)\n        self.transformer_list[:] = [\n            (name, old if old == \"drop\" else next(transformers))\n            for name, old in self.transformer_list\n        ]\n\n    @property\n    def n_features_in_(self):\n        \"\"\"Number of features seen during :term:`fit`.\"\"\"\n\n        # X is passed to all transformers so we just delegate to the first one\n        return self.transformer_list[0][1].n_features_in_\n\n    @property\n    def feature_names_in_(self):\n        \"\"\"Names of features seen during :term:`fit`.\"\"\"\n        # X is passed to all transformers -- delegate to the first one\n        return self.transformer_list[0][1].feature_names_in_\n\n    def __sklearn_is_fitted__(self):\n        # Delegate whether feature union was fitted\n        for _, transformer, _ in self._iter():\n            check_is_fitted(transformer)\n        return True\n\n    def _sk_visual_block_(self):\n        names, transformers = zip(*self.transformer_list)\n        return _VisualBlock(\"parallel\", transformers, names=names)\n\n    def __getitem__(self, name):\n        \"\"\"Return transformer with name.\"\"\"\n        if not isinstance(name, str):\n            raise KeyError(\"Only string keys are supported\")\n        return self.named_transformers[name]\n\n    def get_metadata_routing(self):\n        \"\"\"Get metadata routing of this object.\n\n        Please check :ref:`User Guide <metadata_routing>` on how the routing\n        mechanism works.\n\n        .. versionadded:: 1.5\n\n        Returns\n        -------\n        routing : MetadataRouter\n            A :class:`~sklearn.utils.metadata_routing.MetadataRouter` encapsulating\n            routing information.\n        \"\"\"\n        router = MetadataRouter(owner=self.__class__.__name__)\n\n        for name, transformer in self.transformer_list:\n            router.add(\n                **{name: transformer},\n                method_map"}, {"start_line": 4000, "end_line": 6000, "belongs_to": {"file_name": "test_estimator.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/utils/_repr_html/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "l\"\n    assert est_html_info.names == (\"pca\", \"svd\")\n    assert est_html_info.estimators == tuple(\n        trans[1] for trans in f_union.transformer_list\n    )\n    assert est_html_info.name_details == (None, None)\n\n\ndef test_get_visual_block_voting():\n    clf = VotingClassifier(\n        [(\"log_reg\", LogisticRegression()), (\"mlp\", MLPClassifier())]\n    )\n    est_html_info = _get_visual_block(clf)\n    assert est_html_info.kind == \"parallel\"\n    assert est_html_info.estimators == tuple(trans[1] for trans in clf.estimators)\n    assert est_html_info.names == (\"log_reg\", \"mlp\")\n    assert est_html_info.name_details == (None, None)\n\n\ndef test_get_visual_block_column_transformer():\n    ct = ColumnTransformer(\n        [(\"pca\", PCA(), [\"num1\", \"num2\"]), (\"svd\", TruncatedSVD, [0, 3])]\n    )\n    est_html_info = _get_visual_block(ct)\n    assert est_html_info.kind == \"parallel\"\n    assert est_html_info.estimators == tuple(trans[1] for trans in ct.transformers)\n    assert est_html_info.names == (\"pca\", \"svd\")\n    assert est_html_info.name_details == ([\"num1\", \"num2\"], [0, 3])\n\n\ndef test_estimator_html_repr_an_empty_pipeline():\n    \"\"\"Check that the representation of an empty Pipeline does not fail.\n\n    Non-regression test for:\n    https://github.com/scikit-learn/scikit-learn/issues/30197\n    \"\"\"\n    empty_pipeline = Pipeline([])\n    estimator_html_repr(empty_pipeline)\n\n\ndef test_estimator_html_repr_pipeline():\n    num_trans = Pipeline(\n        steps=[(\"pass\", \"passthrough\"), (\"imputer\", SimpleImputer(strategy=\"median\"))]\n    )\n\n    cat_trans = Pipeline(\n        steps=[\n            (\"imputer\", SimpleImputer(strategy=\"constant\", missing_values=\"empty\")),\n            (\"one-hot\", OneHotEncoder(drop=\"first\")),\n        ]\n    )\n\n    preprocess = ColumnTransformer(\n        [\n            (\"num\", num_trans, [\"a\", \"b\", \"c\", \"d\", \"e\"]),\n            (\"cat\", cat_trans, [0, 1, 2, 3]),\n        ]\n    )\n\n    feat_u = FeatureUnion(\n        [\n            (\"pca\", PCA(n_components=1)),\n            (\n  "}, {"start_line": 2000, "end_line": 4000, "belongs_to": {"file_name": "test_estimator.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/utils/_repr_html/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "gleable__label (fitted)? sk-toggleable__label-arrow\">'\n            r\"<div><div>LogisticRegression</div></div>\"\n        )\n        re_compiled = re.compile(p)\n        assert re_compiled.search(html_label)\n        assert html_label.startswith('<div class=\"sk-label-container\">')\n        assert \"<pre>hello-world</pre>\" in html_label\n\n        if checked:\n            assert \"checked>\" in html_label\n\n\n@pytest.mark.parametrize(\"est\", [\"passthrough\", \"drop\", None])\ndef test_get_visual_block_single_str_none(est):\n    # Test estimators that are represented by strings\n    est_html_info = _get_visual_block(est)\n    assert est_html_info.kind == \"single\"\n    assert est_html_info.estimators == est\n    assert est_html_info.names == str(est)\n    assert est_html_info.name_details == str(est)\n\n\ndef test_get_visual_block_single_estimator():\n    est = LogisticRegression(C=10.0)\n    est_html_info = _get_visual_block(est)\n    assert est_html_info.kind == \"single\"\n    assert est_html_info.estimators == est\n    assert est_html_info.names == est.__class__.__name__\n    assert est_html_info.name_details == str(est)\n\n\ndef test_get_visual_block_pipeline():\n    pipe = Pipeline(\n        [\n            (\"imputer\", SimpleImputer()),\n            (\"do_nothing\", \"passthrough\"),\n            (\"do_nothing_more\", None),\n            (\"classifier\", LogisticRegression()),\n        ]\n    )\n    est_html_info = _get_visual_block(pipe)\n    assert est_html_info.kind == \"serial\"\n    assert est_html_info.estimators == tuple(step[1] for step in pipe.steps)\n    assert est_html_info.names == (\n        \"imputer: SimpleImputer\",\n        \"do_nothing: passthrough\",\n        \"do_nothing_more: passthrough\",\n        \"classifier: LogisticRegression\",\n    )\n    assert est_html_info.name_details == [str(est) for _, est in pipe.steps]\n\n\ndef test_get_visual_block_feature_union():\n    f_union = FeatureUnion([(\"pca\", PCA()), (\"svd\", TruncatedSVD())])\n    est_html_info = _get_visual_block(f_union)\n    assert est_html_info.kind == \"paralle"}, {"start_line": 9000, "end_line": 11000, "belongs_to": {"file_name": "estimator.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/utils/_repr_html", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "ck(\n                \"parallel\",\n                [est for _, est in estimators],\n                names=[f\"{key}: {est.__class__.__name__}\" for key, est in estimators],\n                name_details=[str(est) for _, est in estimators],\n            )\n\n    return _VisualBlock(\n        \"single\",\n        estimator,\n        names=estimator.__class__.__name__,\n        name_details=str(estimator),\n    )\n\n\ndef _write_estimator_html(\n    out,\n    estimator,\n    estimator_label,\n    estimator_label_details,\n    is_fitted_css_class,\n    is_fitted_icon=\"\",\n    first_call=False,\n    param_prefix=\"\",\n):\n    \"\"\"Write estimator to html in serial, parallel, or by itself (single).\n\n    For multiple estimators, this function is called recursively.\n\n    Parameters\n    ----------\n    out : file-like object\n        The file to write the HTML representation to.\n    estimator : estimator object\n        The estimator to visualize.\n    estimator_label : str\n        The label for the estimator. It corresponds either to the estimator class name\n        for simple estimator or in the case of `Pipeline` and `ColumnTransformer`, it\n        corresponds to the name of the step.\n    estimator_label_details : str\n        The details to show as content in the dropdown part of the toggleable label.\n        It can contain information as non-default parameters or column information for\n        `ColumnTransformer`.\n    is_fitted_css_class : {\"\", \"fitted\"}\n        The CSS class to indicate whether or not the estimator is fitted or not. The\n        empty string means that the estimator is not fitted and \"fitted\" means that the\n        estimator is fitted.\n    is_fitted_icon : str, default=\"\"\n        The HTML representation to show the fitted information in the diagram. An empty\n        string means that no information is shown. If the estimator to be shown is not\n        the first estimator (i.e. `first_call=False`), `is_fitted_icon` is always an\n        empty string.\n    first_call : bool, default=False\n     "}, {"start_line": 67000, "end_line": 69000, "belongs_to": {"file_name": "pipeline.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": ":\n        # Use Bunch object to improve autocomplete\n        return Bunch(**dict(self.transformer_list))\n\n    def get_params(self, deep=True):\n        \"\"\"Get parameters for this estimator.\n\n        Returns the parameters given in the constructor as well as the\n        estimators contained within the `transformer_list` of the\n        `FeatureUnion`.\n\n        Parameters\n        ----------\n        deep : bool, default=True\n            If True, will return the parameters for this estimator and\n            contained subobjects that are estimators.\n\n        Returns\n        -------\n        params : mapping of string to any\n            Parameter names mapped to their values.\n        \"\"\"\n        return self._get_params(\"transformer_list\", deep=deep)\n\n    def set_params(self, **kwargs):\n        \"\"\"Set the parameters of this estimator.\n\n        Valid parameter keys can be listed with ``get_params()``. Note that\n        you can directly set the parameters of the estimators contained in\n        `transformer_list`.\n\n        Parameters\n        ----------\n        **kwargs : dict\n            Parameters of this estimator or parameters of estimators contained\n            in `transform_list`. Parameters of the transformers may be set\n            using its name and the parameter name separated by a '__'.\n\n        Returns\n        -------\n        self : object\n            FeatureUnion class instance.\n        \"\"\"\n        self._set_params(\"transformer_list\", **kwargs)\n        return self\n\n    def _validate_transformers(self):\n        names, transformers = zip(*self.transformer_list)\n\n        # validate names\n        self._validate_names(names)\n\n        # validate estimators\n        for t in transformers:\n            if t in (\"drop\", \"passthrough\"):\n                continue\n            if not (hasattr(t, \"fit\") or hasattr(t, \"fit_transform\")) or not hasattr(\n                t, \"transform\"\n            ):\n                raise TypeError(\n                    \"All estimators should implement fit"}, {"start_line": 1000, "end_line": 3000, "belongs_to": {"file_name": "estimator.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/utils/_repr_html", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "\"HTML Representation of Estimator\n\n    Parameters\n    ----------\n    kind : {'serial', 'parallel', 'single'}\n        kind of HTML block\n\n    estimators : list of estimators or `_VisualBlock`s or a single estimator\n        If kind != 'single', then `estimators` is a list of\n        estimators.\n        If kind == 'single', then `estimators` is a single estimator.\n\n    names : list of str, default=None\n        If kind != 'single', then `names` corresponds to estimators.\n        If kind == 'single', then `names` is a single string corresponding to\n        the single estimator.\n\n    name_details : list of str, str, or None, default=None\n        If kind != 'single', then `name_details` corresponds to `names`.\n        If kind == 'single', then `name_details` is a single string\n        corresponding to the single estimator.\n\n    name_caption : str, default=None\n        The caption below the name. `None` stands for no caption.\n        Only active when kind == 'single'.\n\n    doc_link_label : str, default=None\n        The label for the documentation link. If provided, the label would be\n        \"Documentation for {doc_link_label}\". Otherwise it will look for `names`.\n        Only active when kind == 'single'.\n\n    dash_wrapped : bool, default=True\n        If true, wrapped HTML element will be wrapped with a dashed border.\n        Only active when kind != 'single'.\n    \"\"\"\n\n    def __init__(\n        self,\n        kind,\n        estimators,\n        *,\n        names=None,\n        name_details=None,\n        name_caption=None,\n        doc_link_label=None,\n        dash_wrapped=True,\n    ):\n        self.kind = kind\n        self.estimators = estimators\n        self.dash_wrapped = dash_wrapped\n        self.name_caption = name_caption\n        self.doc_link_label = doc_link_label\n\n        if self.kind in (\"parallel\", \"serial\"):\n            if names is None:\n                names = (None,) * len(estimators)\n            if name_details is None:\n                name_details = (None,) * len(e"}, {"start_line": 81000, "end_line": 83000, "belongs_to": {"file_name": "pipeline.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": " def _sk_visual_block_(self):\n        names, transformers = zip(*self.transformer_list)\n        return _VisualBlock(\"parallel\", transformers, names=names)\n\n    def __getitem__(self, name):\n        \"\"\"Return transformer with name.\"\"\"\n        if not isinstance(name, str):\n            raise KeyError(\"Only string keys are supported\")\n        return self.named_transformers[name]\n\n    def get_metadata_routing(self):\n        \"\"\"Get metadata routing of this object.\n\n        Please check :ref:`User Guide <metadata_routing>` on how the routing\n        mechanism works.\n\n        .. versionadded:: 1.5\n\n        Returns\n        -------\n        routing : MetadataRouter\n            A :class:`~sklearn.utils.metadata_routing.MetadataRouter` encapsulating\n            routing information.\n        \"\"\"\n        router = MetadataRouter(owner=self.__class__.__name__)\n\n        for name, transformer in self.transformer_list:\n            router.add(\n                **{name: transformer},\n                method_mapping=MethodMapping()\n                .add(caller=\"fit\", callee=\"fit\")\n                .add(caller=\"fit_transform\", callee=\"fit_transform\")\n                .add(caller=\"fit_transform\", callee=\"fit\")\n                .add(caller=\"fit_transform\", callee=\"transform\")\n                .add(caller=\"transform\", callee=\"transform\"),\n            )\n\n        return router\n\n    def __sklearn_tags__(self):\n        tags = super().__sklearn_tags__()\n        try:\n            tags.input_tags.sparse = all(\n                get_tags(trans).input_tags.sparse\n                for name, trans in self.transformer_list\n                if trans not in {\"passthrough\", \"drop\"}\n            )\n        except Exception:\n            # If `transformer_list` does not comply with our API (list of tuples)\n            # then it will fail. In this case, we assume that `sparse` is False\n            # but the parameter validation will raise an error during `fit`.\n            pass  # pragma: no cover\n        return tags\n\n\ndef mak"}], "retrieved_count": 10, "cost_time": 1.1978254318237305}
{"question": "What is the architectural rationale for LocalOutlierFactor's decision to cache _distances_fit_X_, _neighbors_indices_fit_X_, and _lrd as instance attributes during fit(), and how does this caching strategy impact the control flow of predict() versus score_samples()?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"start_line": 9000, "end_line": 11000, "belongs_to": {"file_name": "_lof.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/neighbors", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "to the LOF\n        score and the contamination parameter.\n\n        Parameters\n        ----------\n        X : {array-like, sparse matrix} of shape (n_samples, n_features), default=None\n            The query sample or samples to compute the Local Outlier Factor\n            w.r.t. the training samples.\n\n        y : Ignored\n            Not used, present for API consistency by convention.\n\n        Returns\n        -------\n        is_inlier : ndarray of shape (n_samples,)\n            Returns -1 for anomalies/outliers and 1 for inliers.\n        \"\"\"\n\n        # As fit_predict would be different from fit.predict, fit_predict is\n        # only available for outlier detection (novelty=False)\n\n        return self.fit(X)._predict()\n\n    @_fit_context(\n        # LocalOutlierFactor.metric is not validated yet\n        prefer_skip_nested_validation=False\n    )\n    def fit(self, X, y=None):\n        \"\"\"Fit the local outlier factor detector from the training dataset.\n\n        Parameters\n        ----------\n        X : {array-like, sparse matrix} of shape (n_samples, n_features) or \\\n                (n_samples, n_samples) if metric='precomputed'\n            Training data.\n\n        y : Ignored\n            Not used, present for API consistency by convention.\n\n        Returns\n        -------\n        self : LocalOutlierFactor\n            The fitted local outlier factor detector.\n        \"\"\"\n        self._fit(X)\n\n        n_samples = self.n_samples_fit_\n        if self.n_neighbors > n_samples:\n            warnings.warn(\n                \"n_neighbors (%s) is greater than the \"\n                \"total number of samples (%s). n_neighbors \"\n                \"will be set to (n_samples - 1) for estimation.\"\n                % (self.n_neighbors, n_samples)\n            )\n        self.n_neighbors_ = max(1, min(self.n_neighbors, n_samples - 1))\n\n        self._distances_fit_X_, _neighbors_indices_fit_X_ = self.kneighbors(\n            n_neighbors=self.n_neighbors_\n        )\n\n        if self._fit_X.dtype == np.f"}, {"start_line": 18000, "end_line": 20000, "belongs_to": {"file_name": "_lof.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/neighbors", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "uery sample or samples to compute the Local Outlier Factor\n            w.r.t. the training samples.\n\n        Returns\n        -------\n        opposite_lof_scores : ndarray of shape (n_samples,)\n            The opposite of the Local Outlier Factor of each input samples.\n            The lower, the more abnormal.\n        \"\"\"\n        check_is_fitted(self)\n        X = check_array(X, accept_sparse=\"csr\")\n\n        distances_X, neighbors_indices_X = self.kneighbors(\n            X, n_neighbors=self.n_neighbors_\n        )\n\n        if X.dtype == np.float32:\n            distances_X = distances_X.astype(X.dtype, copy=False)\n\n        X_lrd = self._local_reachability_density(\n            distances_X,\n            neighbors_indices_X,\n        )\n\n        lrd_ratios_array = self._lrd[neighbors_indices_X] / X_lrd[:, np.newaxis]\n\n        # as bigger is better:\n        return -np.mean(lrd_ratios_array, axis=1)\n\n    def _local_reachability_density(self, distances_X, neighbors_indices):\n        \"\"\"The local reachability density (LRD)\n\n        The LRD of a sample is the inverse of the average reachability\n        distance of its k-nearest neighbors.\n\n        Parameters\n        ----------\n        distances_X : ndarray of shape (n_queries, self.n_neighbors)\n            Distances to the neighbors (in the training samples `self._fit_X`)\n            of each query point to compute the LRD.\n\n        neighbors_indices : ndarray of shape (n_queries, self.n_neighbors)\n            Neighbors indices (of each query point) among training samples\n            self._fit_X.\n\n        Returns\n        -------\n        local_reachability_density : ndarray of shape (n_queries,)\n            The local reachability density of each sample.\n        \"\"\"\n        dist_k = self._distances_fit_X_[neighbors_indices, self.n_neighbors_ - 1]\n        reach_dist_array = np.maximum(distances_X, dist_k)\n\n        # 1e-10 to avoid `nan' when nb of duplicates > n_neighbors_:\n        return 1.0 / (np.mean(reach_dist_array, axis=1) + 1e-"}, {"start_line": 8000, "end_line": 10000, "belongs_to": {"file_name": "_lof.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/neighbors", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "mination=\"auto\",\n        novelty=False,\n        n_jobs=None,\n    ):\n        super().__init__(\n            n_neighbors=n_neighbors,\n            algorithm=algorithm,\n            leaf_size=leaf_size,\n            metric=metric,\n            p=p,\n            metric_params=metric_params,\n            n_jobs=n_jobs,\n        )\n        self.contamination = contamination\n        self.novelty = novelty\n\n    def _check_novelty_fit_predict(self):\n        if self.novelty:\n            msg = (\n                \"fit_predict is not available when novelty=True. Use \"\n                \"novelty=False if you want to predict on the training set.\"\n            )\n            raise AttributeError(msg)\n        return True\n\n    @available_if(_check_novelty_fit_predict)\n    def fit_predict(self, X, y=None):\n        \"\"\"Fit the model to the training set X and return the labels.\n\n        **Not available for novelty detection (when novelty is set to True).**\n        Label is 1 for an inlier and -1 for an outlier according to the LOF\n        score and the contamination parameter.\n\n        Parameters\n        ----------\n        X : {array-like, sparse matrix} of shape (n_samples, n_features), default=None\n            The query sample or samples to compute the Local Outlier Factor\n            w.r.t. the training samples.\n\n        y : Ignored\n            Not used, present for API consistency by convention.\n\n        Returns\n        -------\n        is_inlier : ndarray of shape (n_samples,)\n            Returns -1 for anomalies/outliers and 1 for inliers.\n        \"\"\"\n\n        # As fit_predict would be different from fit.predict, fit_predict is\n        # only available for outlier detection (novelty=False)\n\n        return self.fit(X)._predict()\n\n    @_fit_context(\n        # LocalOutlierFactor.metric is not validated yet\n        prefer_skip_nested_validation=False\n    )\n    def fit(self, X, y=None):\n        \"\"\"Fit the local outlier factor detector from the training dataset.\n\n        Parameters\n        ----------\n "}, {"start_line": 11000, "end_line": 13000, "belongs_to": {"file_name": "_lof.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/neighbors", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "loat32:\n            self._distances_fit_X_ = self._distances_fit_X_.astype(\n                self._fit_X.dtype,\n                copy=False,\n            )\n\n        self._lrd = self._local_reachability_density(\n            self._distances_fit_X_, _neighbors_indices_fit_X_\n        )\n\n        # Compute lof score over training samples to define offset_:\n        lrd_ratios_array = (\n            self._lrd[_neighbors_indices_fit_X_] / self._lrd[:, np.newaxis]\n        )\n\n        self.negative_outlier_factor_ = -np.mean(lrd_ratios_array, axis=1)\n\n        if self.contamination == \"auto\":\n            # inliers score around -1 (the higher, the less abnormal).\n            self.offset_ = -1.5\n        else:\n            self.offset_ = np.percentile(\n                self.negative_outlier_factor_, 100.0 * self.contamination\n            )\n\n        # Verify if negative_outlier_factor_ values are within acceptable range.\n        # Novelty must also be false to detect outliers\n        if np.min(self.negative_outlier_factor_) < -1e7 and not self.novelty:\n            warnings.warn(\n                \"Duplicate values are leading to incorrect results. \"\n                \"Increase the number of neighbors for more accurate results.\"\n            )\n\n        return self\n\n    def _check_novelty_predict(self):\n        if not self.novelty:\n            msg = (\n                \"predict is not available when novelty=False, use \"\n                \"fit_predict if you want to predict on training data. Use \"\n                \"novelty=True if you want to use LOF for novelty detection \"\n                \"and predict on new unseen data.\"\n            )\n            raise AttributeError(msg)\n        return True\n\n    @available_if(_check_novelty_predict)\n    def predict(self, X=None):\n        \"\"\"Predict the labels (1 inlier, -1 outlier) of X according to LOF.\n\n        **Only available for novelty detection (when novelty is set to True).**\n        This method allows to generalize prediction to *new observations* (not\n   "}, {"start_line": 4000, "end_line": 6000, "belongs_to": {"file_name": "test_lof.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/neighbors/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "rs=3, algorithm=\"brute\", metric=\"precomputed\", novelty=True\n    )\n    lof_D.fit(DXX)\n    pred_D_X = lof_D._predict()\n    pred_D_Y = lof_D.predict(DYX)\n\n    assert_allclose(pred_X_X, pred_D_X)\n    assert_allclose(pred_X_Y, pred_D_Y)\n\n\ndef test_n_neighbors_attribute():\n    X = iris.data\n    clf = neighbors.LocalOutlierFactor(n_neighbors=500).fit(X)\n    assert clf.n_neighbors_ == X.shape[0] - 1\n\n    clf = neighbors.LocalOutlierFactor(n_neighbors=500)\n    msg = \"n_neighbors will be set to (n_samples - 1)\"\n    with pytest.warns(UserWarning, match=re.escape(msg)):\n        clf.fit(X)\n    assert clf.n_neighbors_ == X.shape[0] - 1\n\n\ndef test_score_samples(global_dtype):\n    X_train = np.asarray([[1, 1], [1, 2], [2, 1]], dtype=global_dtype)\n    X_test = np.asarray([[2.0, 2.0]], dtype=global_dtype)\n    clf1 = neighbors.LocalOutlierFactor(\n        n_neighbors=2, contamination=0.1, novelty=True\n    ).fit(X_train)\n    clf2 = neighbors.LocalOutlierFactor(n_neighbors=2, novelty=True).fit(X_train)\n\n    clf1_scores = clf1.score_samples(X_test)\n    clf1_decisions = clf1.decision_function(X_test)\n\n    clf2_scores = clf2.score_samples(X_test)\n    clf2_decisions = clf2.decision_function(X_test)\n\n    assert_allclose(\n        clf1_scores,\n        clf1_decisions + clf1.offset_,\n    )\n    assert_allclose(\n        clf2_scores,\n        clf2_decisions + clf2.offset_,\n    )\n    assert_allclose(clf1_scores, clf2_scores)\n\n\ndef test_novelty_errors():\n    X = iris.data\n\n    # check errors for novelty=False\n    clf = neighbors.LocalOutlierFactor()\n    clf.fit(X)\n    # predict, decision_function and score_samples raise ValueError\n    for method in [\"predict\", \"decision_function\", \"score_samples\"]:\n        outer_msg = f\"'LocalOutlierFactor' has no attribute '{method}'\"\n        inner_msg = \"{} is not available when novelty=False\".format(method)\n        with pytest.raises(AttributeError, match=outer_msg) as exec_info:\n            getattr(clf, method)\n\n        assert isinstance(exec_info.value.__cause__, "}, {"start_line": 17000, "end_line": 19000, "belongs_to": {"file_name": "_lof.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/neighbors", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "een data.\"\n            )\n            raise AttributeError(msg)\n        return True\n\n    @available_if(_check_novelty_score_samples)\n    def score_samples(self, X):\n        \"\"\"Opposite of the Local Outlier Factor of X.\n\n        It is the opposite as bigger is better, i.e. large values correspond\n        to inliers.\n\n        **Only available for novelty detection (when novelty is set to True).**\n        The argument X is supposed to contain *new data*: if X contains a\n        point from training, it considers the later in its own neighborhood.\n        Also, the samples in X are not considered in the neighborhood of any\n        point. Because of this, the scores obtained via ``score_samples`` may\n        differ from the standard LOF scores.\n        The standard LOF scores for the training data is available via the\n        ``negative_outlier_factor_`` attribute.\n\n        Parameters\n        ----------\n        X : {array-like, sparse matrix} of shape (n_samples, n_features)\n            The query sample or samples to compute the Local Outlier Factor\n            w.r.t. the training samples.\n\n        Returns\n        -------\n        opposite_lof_scores : ndarray of shape (n_samples,)\n            The opposite of the Local Outlier Factor of each input samples.\n            The lower, the more abnormal.\n        \"\"\"\n        check_is_fitted(self)\n        X = check_array(X, accept_sparse=\"csr\")\n\n        distances_X, neighbors_indices_X = self.kneighbors(\n            X, n_neighbors=self.n_neighbors_\n        )\n\n        if X.dtype == np.float32:\n            distances_X = distances_X.astype(X.dtype, copy=False)\n\n        X_lrd = self._local_reachability_density(\n            distances_X,\n            neighbors_indices_X,\n        )\n\n        lrd_ratios_array = self._lrd[neighbors_indices_X] / X_lrd[:, np.newaxis]\n\n        # as bigger is better:\n        return -np.mean(lrd_ratios_array, axis=1)\n\n    def _local_reachability_density(self, distances_X, neighbors_indices):\n        \"\"\"The local re"}, {"start_line": 7000, "end_line": 9000, "belongs_to": {"file_name": "_lof.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/neighbors", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "  .. [1] Breunig, M. M., Kriegel, H. P., Ng, R. T., & Sander, J. (2000, May).\n           LOF: identifying density-based local outliers. In ACM sigmod record.\n\n    Examples\n    --------\n    >>> import numpy as np\n    >>> from sklearn.neighbors import LocalOutlierFactor\n    >>> X = [[-1.1], [0.2], [101.1], [0.3]]\n    >>> clf = LocalOutlierFactor(n_neighbors=2)\n    >>> clf.fit_predict(X)\n    array([ 1,  1, -1,  1])\n    >>> clf.negative_outlier_factor_\n    array([ -0.9821,  -1.0370, -73.3697,  -0.9821])\n    \"\"\"\n\n    _parameter_constraints: dict = {\n        **NeighborsBase._parameter_constraints,\n        \"contamination\": [\n            StrOptions({\"auto\"}),\n            Interval(Real, 0, 0.5, closed=\"right\"),\n        ],\n        \"novelty\": [\"boolean\"],\n    }\n    _parameter_constraints.pop(\"radius\")\n\n    def __init__(\n        self,\n        n_neighbors=20,\n        *,\n        algorithm=\"auto\",\n        leaf_size=30,\n        metric=\"minkowski\",\n        p=2,\n        metric_params=None,\n        contamination=\"auto\",\n        novelty=False,\n        n_jobs=None,\n    ):\n        super().__init__(\n            n_neighbors=n_neighbors,\n            algorithm=algorithm,\n            leaf_size=leaf_size,\n            metric=metric,\n            p=p,\n            metric_params=metric_params,\n            n_jobs=n_jobs,\n        )\n        self.contamination = contamination\n        self.novelty = novelty\n\n    def _check_novelty_fit_predict(self):\n        if self.novelty:\n            msg = (\n                \"fit_predict is not available when novelty=True. Use \"\n                \"novelty=False if you want to predict on the training set.\"\n            )\n            raise AttributeError(msg)\n        return True\n\n    @available_if(_check_novelty_fit_predict)\n    def fit_predict(self, X, y=None):\n        \"\"\"Fit the model to the training set X and return the labels.\n\n        **Not available for novelty detection (when novelty is set to True).**\n        Label is 1 for an inlier and -1 for an outlier according "}, {"start_line": 13000, "end_line": 15000, "belongs_to": {"file_name": "_lof.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/neighbors", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "     in the training set). Note that the result of ``clf.fit(X)`` then\n        ``clf.predict(X)`` with ``novelty=True`` may differ from the result\n        obtained by ``clf.fit_predict(X)`` with ``novelty=False``.\n\n        Parameters\n        ----------\n        X : {array-like, sparse matrix} of shape (n_samples, n_features)\n            The query sample or samples to compute the Local Outlier Factor\n            w.r.t. the training samples.\n\n        Returns\n        -------\n        is_inlier : ndarray of shape (n_samples,)\n            Returns -1 for anomalies/outliers and +1 for inliers.\n        \"\"\"\n        return self._predict(X)\n\n    def _predict(self, X=None):\n        \"\"\"Predict the labels (1 inlier, -1 outlier) of X according to LOF.\n\n        If X is None, returns the same as fit_predict(X_train).\n\n        Parameters\n        ----------\n        X : {array-like, sparse matrix} of shape (n_samples, n_features), default=None\n            The query sample or samples to compute the Local Outlier Factor\n            w.r.t. the training samples. If None, makes prediction on the\n            training data without considering them as their own neighbors.\n\n        Returns\n        -------\n        is_inlier : ndarray of shape (n_samples,)\n            Returns -1 for anomalies/outliers and +1 for inliers.\n        \"\"\"\n        check_is_fitted(self)\n\n        if X is not None:\n            shifted_opposite_lof_scores = self.decision_function(X)\n            is_inlier = np.ones(shifted_opposite_lof_scores.shape[0], dtype=int)\n            is_inlier[shifted_opposite_lof_scores < 0] = -1\n        else:\n            is_inlier = np.ones(self.n_samples_fit_, dtype=int)\n            is_inlier[self.negative_outlier_factor_ < self.offset_] = -1\n\n        return is_inlier\n\n    def _check_novelty_decision_function(self):\n        if not self.novelty:\n            msg = (\n                \"decision_function is not available when novelty=False. \"\n                \"Use novelty=True if you want to use LOF for no"}, {"start_line": 6000, "end_line": 8000, "belongs_to": {"file_name": "_lof.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/neighbors", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "pt when a\n        contamination parameter different than \"auto\" is provided. In that\n        case, the offset is defined in such a way we obtain the expected\n        number of outliers in training.\n\n        .. versionadded:: 0.20\n\n    effective_metric_ : str\n        The effective metric used for the distance computation.\n\n    effective_metric_params_ : dict\n        The effective additional keyword arguments for the metric function.\n\n    n_features_in_ : int\n        Number of features seen during :term:`fit`.\n\n        .. versionadded:: 0.24\n\n    feature_names_in_ : ndarray of shape (`n_features_in_`,)\n        Names of features seen during :term:`fit`. Defined only when `X`\n        has feature names that are all strings.\n\n        .. versionadded:: 1.0\n\n    n_samples_fit_ : int\n        It is the number of samples in the fitted data.\n\n    See Also\n    --------\n    sklearn.svm.OneClassSVM: Unsupervised Outlier Detection using\n        Support Vector Machine.\n\n    References\n    ----------\n    .. [1] Breunig, M. M., Kriegel, H. P., Ng, R. T., & Sander, J. (2000, May).\n           LOF: identifying density-based local outliers. In ACM sigmod record.\n\n    Examples\n    --------\n    >>> import numpy as np\n    >>> from sklearn.neighbors import LocalOutlierFactor\n    >>> X = [[-1.1], [0.2], [101.1], [0.3]]\n    >>> clf = LocalOutlierFactor(n_neighbors=2)\n    >>> clf.fit_predict(X)\n    array([ 1,  1, -1,  1])\n    >>> clf.negative_outlier_factor_\n    array([ -0.9821,  -1.0370, -73.3697,  -0.9821])\n    \"\"\"\n\n    _parameter_constraints: dict = {\n        **NeighborsBase._parameter_constraints,\n        \"contamination\": [\n            StrOptions({\"auto\"}),\n            Interval(Real, 0, 0.5, closed=\"right\"),\n        ],\n        \"novelty\": [\"boolean\"],\n    }\n    _parameter_constraints.pop(\"radius\")\n\n    def __init__(\n        self,\n        n_neighbors=20,\n        *,\n        algorithm=\"auto\",\n        leaf_size=30,\n        metric=\"minkowski\",\n        p=2,\n        metric_params=None,\n        conta"}, {"start_line": 7000, "end_line": 9000, "belongs_to": {"file_name": "test_lof.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/neighbors/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "  scores_2 = clf_2.negative_outlier_factor_\n\n    assert_allclose(scores_1, scores_2)\n\n\ndef test_hasattr_prediction():\n    # check availability of prediction methods depending on novelty value.\n    X = [[1, 1], [1, 2], [2, 1]]\n\n    # when novelty=True\n    clf = neighbors.LocalOutlierFactor(novelty=True)\n    clf.fit(X)\n    assert hasattr(clf, \"predict\")\n    assert hasattr(clf, \"decision_function\")\n    assert hasattr(clf, \"score_samples\")\n    assert not hasattr(clf, \"fit_predict\")\n\n    # when novelty=False\n    clf = neighbors.LocalOutlierFactor(novelty=False)\n    clf.fit(X)\n    assert hasattr(clf, \"fit_predict\")\n    assert not hasattr(clf, \"predict\")\n    assert not hasattr(clf, \"decision_function\")\n    assert not hasattr(clf, \"score_samples\")\n\n\n@parametrize_with_checks([neighbors.LocalOutlierFactor(novelty=True)])\ndef test_novelty_true_common_tests(estimator, check):\n    # the common tests are run for the default LOF (novelty=False).\n    # here we run these common tests for LOF when novelty=True\n    check(estimator)\n\n\n@pytest.mark.parametrize(\"expected_outliers\", [30, 53])\ndef test_predicted_outlier_number(expected_outliers):\n    # the number of predicted outliers should be equal to the number of\n    # expected outliers unless there are ties in the abnormality scores.\n    X = iris.data\n    n_samples = X.shape[0]\n    contamination = float(expected_outliers) / n_samples\n\n    clf = neighbors.LocalOutlierFactor(contamination=contamination)\n    y_pred = clf.fit_predict(X)\n\n    num_outliers = np.sum(y_pred != 1)\n    if num_outliers != expected_outliers:\n        y_dec = clf.negative_outlier_factor_\n        check_outlier_corruption(num_outliers, expected_outliers, y_dec)\n\n\n@pytest.mark.parametrize(\"csr_container\", CSR_CONTAINERS)\ndef test_sparse(csr_container):\n    # LocalOutlierFactor must support CSR inputs\n    # TODO: compare results on dense and sparse data as proposed in:\n    # https://github.com/scikit-learn/scikit-learn/pull/23585#discussion_r968388186\n    X = csr_conta"}], "retrieved_count": 10, "cost_time": 1.2331202030181885}
{"question": "How does the test_check_n_classes function construct allowed_dtypes by combining both int32 and int64 with their byte-order variants, and what would be the consequence of removing the newbyteorder() transformation step for detecting endianness-related validation failures?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"start_line": 75000, "end_line": 77000, "belongs_to": {"file_name": "test_tree.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/tree/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "table = copyreg.dispatch_table.copy()\n        p.dispatch_table[CythonTree] = reduce_tree_with_different_bitness\n\n        p.dump(clf)\n        f.seek(0)\n        return f\n\n    new_clf = joblib.load(joblib_dump_with_different_bitness())\n    new_score = new_clf.score(X, y)\n    assert score == pytest.approx(new_score)\n\n\ndef test_check_n_classes():\n    expected_dtype = np.dtype(np.int32) if _IS_32BIT else np.dtype(np.int64)\n    allowed_dtypes = [np.dtype(np.int32), np.dtype(np.int64)]\n    allowed_dtypes += [dt.newbyteorder() for dt in allowed_dtypes]\n\n    n_classes = np.array([0, 1], dtype=expected_dtype)\n    for dt in allowed_dtypes:\n        _check_n_classes(n_classes.astype(dt), expected_dtype)\n\n    with pytest.raises(ValueError, match=\"Wrong dimensions.+n_classes\"):\n        wrong_dim_n_classes = np.array([[0, 1]], dtype=expected_dtype)\n        _check_n_classes(wrong_dim_n_classes, expected_dtype)\n\n    with pytest.raises(ValueError, match=\"n_classes.+incompatible dtype\"):\n        wrong_dtype_n_classes = n_classes.astype(np.float64)\n        _check_n_classes(wrong_dtype_n_classes, expected_dtype)\n\n\ndef test_check_value_ndarray():\n    expected_dtype = np.dtype(np.float64)\n    expected_shape = (5, 1, 2)\n    value_ndarray = np.zeros(expected_shape, dtype=expected_dtype)\n\n    allowed_dtypes = [expected_dtype, expected_dtype.newbyteorder()]\n\n    for dt in allowed_dtypes:\n        _check_value_ndarray(\n            value_ndarray, expected_dtype=dt, expected_shape=expected_shape\n        )\n\n    with pytest.raises(ValueError, match=\"Wrong shape.+value array\"):\n        _check_value_ndarray(\n            value_ndarray, expected_dtype=expected_dtype, expected_shape=(1, 2)\n        )\n\n    for problematic_arr in [value_ndarray[:, :, :1], np.asfortranarray(value_ndarray)]:\n        with pytest.raises(ValueError, match=\"value array.+C-contiguous\"):\n            _check_value_ndarray(\n                problematic_arr,\n                expected_dtype=expected_dtype,\n                expected_shape=pr"}, {"start_line": 74000, "end_line": 76000, "belongs_to": {"file_name": "test_tree.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/tree/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "kle.Pickler(f)\n        p.dispatch_table = copyreg.dispatch_table.copy()\n        p.dispatch_table[CythonTree] = reduce_tree_with_different_bitness\n\n        p.dump(clf)\n        f.seek(0)\n        return f\n\n    new_clf = pickle.load(pickle_dump_with_different_bitness())\n    new_score = new_clf.score(X, y)\n    assert score == pytest.approx(new_score)\n\n\ndef test_different_bitness_joblib_pickle():\n    # Make sure that a platform specific pickle generated on a 64 bit\n    # platform can be converted at pickle load time into an estimator\n    # with Cython code that works with the host's native integer precision\n    # to index nodes in the tree data structure when the host is a 32 bit\n    # platform (and vice versa).\n    X, y = datasets.make_classification(random_state=0)\n\n    clf = DecisionTreeClassifier(random_state=0, max_depth=3)\n    clf.fit(X, y)\n    score = clf.score(X, y)\n\n    def joblib_dump_with_different_bitness():\n        f = io.BytesIO()\n        p = NumpyPickler(f)\n        p.dispatch_table = copyreg.dispatch_table.copy()\n        p.dispatch_table[CythonTree] = reduce_tree_with_different_bitness\n\n        p.dump(clf)\n        f.seek(0)\n        return f\n\n    new_clf = joblib.load(joblib_dump_with_different_bitness())\n    new_score = new_clf.score(X, y)\n    assert score == pytest.approx(new_score)\n\n\ndef test_check_n_classes():\n    expected_dtype = np.dtype(np.int32) if _IS_32BIT else np.dtype(np.int64)\n    allowed_dtypes = [np.dtype(np.int32), np.dtype(np.int64)]\n    allowed_dtypes += [dt.newbyteorder() for dt in allowed_dtypes]\n\n    n_classes = np.array([0, 1], dtype=expected_dtype)\n    for dt in allowed_dtypes:\n        _check_n_classes(n_classes.astype(dt), expected_dtype)\n\n    with pytest.raises(ValueError, match=\"Wrong dimensions.+n_classes\"):\n        wrong_dim_n_classes = np.array([[0, 1]], dtype=expected_dtype)\n        _check_n_classes(wrong_dim_n_classes, expected_dtype)\n\n    with pytest.raises(ValueError, match=\"n_classes.+incompatible dtype\"):\n        wrong_dtyp"}, {"start_line": 76000, "end_line": 78000, "belongs_to": {"file_name": "test_tree.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/tree/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "e_n_classes = n_classes.astype(np.float64)\n        _check_n_classes(wrong_dtype_n_classes, expected_dtype)\n\n\ndef test_check_value_ndarray():\n    expected_dtype = np.dtype(np.float64)\n    expected_shape = (5, 1, 2)\n    value_ndarray = np.zeros(expected_shape, dtype=expected_dtype)\n\n    allowed_dtypes = [expected_dtype, expected_dtype.newbyteorder()]\n\n    for dt in allowed_dtypes:\n        _check_value_ndarray(\n            value_ndarray, expected_dtype=dt, expected_shape=expected_shape\n        )\n\n    with pytest.raises(ValueError, match=\"Wrong shape.+value array\"):\n        _check_value_ndarray(\n            value_ndarray, expected_dtype=expected_dtype, expected_shape=(1, 2)\n        )\n\n    for problematic_arr in [value_ndarray[:, :, :1], np.asfortranarray(value_ndarray)]:\n        with pytest.raises(ValueError, match=\"value array.+C-contiguous\"):\n            _check_value_ndarray(\n                problematic_arr,\n                expected_dtype=expected_dtype,\n                expected_shape=problematic_arr.shape,\n            )\n\n    with pytest.raises(ValueError, match=\"value array.+incompatible dtype\"):\n        _check_value_ndarray(\n            value_ndarray.astype(np.float32),\n            expected_dtype=expected_dtype,\n            expected_shape=expected_shape,\n        )\n\n\ndef test_check_node_ndarray():\n    expected_dtype = NODE_DTYPE\n\n    node_ndarray = np.zeros((5,), dtype=expected_dtype)\n\n    valid_node_ndarrays = [\n        node_ndarray,\n        get_different_bitness_node_ndarray(node_ndarray),\n        get_different_alignment_node_ndarray(node_ndarray),\n    ]\n    valid_node_ndarrays += [\n        arr.astype(arr.dtype.newbyteorder()) for arr in valid_node_ndarrays\n    ]\n\n    for arr in valid_node_ndarrays:\n        _check_node_ndarray(node_ndarray, expected_dtype=expected_dtype)\n\n    with pytest.raises(ValueError, match=\"Wrong dimensions.+node array\"):\n        problematic_node_ndarray = np.zeros((5, 2), dtype=expected_dtype)\n        _check_node_ndarray(problematic_node_nda"}, {"start_line": 77000, "end_line": 79000, "belongs_to": {"file_name": "test_tree.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/tree/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "oblematic_arr.shape,\n            )\n\n    with pytest.raises(ValueError, match=\"value array.+incompatible dtype\"):\n        _check_value_ndarray(\n            value_ndarray.astype(np.float32),\n            expected_dtype=expected_dtype,\n            expected_shape=expected_shape,\n        )\n\n\ndef test_check_node_ndarray():\n    expected_dtype = NODE_DTYPE\n\n    node_ndarray = np.zeros((5,), dtype=expected_dtype)\n\n    valid_node_ndarrays = [\n        node_ndarray,\n        get_different_bitness_node_ndarray(node_ndarray),\n        get_different_alignment_node_ndarray(node_ndarray),\n    ]\n    valid_node_ndarrays += [\n        arr.astype(arr.dtype.newbyteorder()) for arr in valid_node_ndarrays\n    ]\n\n    for arr in valid_node_ndarrays:\n        _check_node_ndarray(node_ndarray, expected_dtype=expected_dtype)\n\n    with pytest.raises(ValueError, match=\"Wrong dimensions.+node array\"):\n        problematic_node_ndarray = np.zeros((5, 2), dtype=expected_dtype)\n        _check_node_ndarray(problematic_node_ndarray, expected_dtype=expected_dtype)\n\n    with pytest.raises(ValueError, match=\"node array.+C-contiguous\"):\n        problematic_node_ndarray = node_ndarray[::2]\n        _check_node_ndarray(problematic_node_ndarray, expected_dtype=expected_dtype)\n\n    dtype_dict = {name: dtype for name, (dtype, _) in node_ndarray.dtype.fields.items()}\n\n    # array with wrong 'threshold' field dtype (int64 rather than float64)\n    new_dtype_dict = dtype_dict.copy()\n    new_dtype_dict[\"threshold\"] = np.int64\n\n    new_dtype = np.dtype(\n        {\"names\": list(new_dtype_dict.keys()), \"formats\": list(new_dtype_dict.values())}\n    )\n    problematic_node_ndarray = node_ndarray.astype(new_dtype)\n\n    with pytest.raises(ValueError, match=\"node array.+incompatible dtype\"):\n        _check_node_ndarray(problematic_node_ndarray, expected_dtype=expected_dtype)\n\n    # array with wrong 'left_child' field dtype (float64 rather than int64 or int32)\n    new_dtype_dict = dtype_dict.copy()\n    new_dtype_dict[\"left_child\"] = "}, {"start_line": 78000, "end_line": 80000, "belongs_to": {"file_name": "test_tree.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/tree/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "rray, expected_dtype=expected_dtype)\n\n    with pytest.raises(ValueError, match=\"node array.+C-contiguous\"):\n        problematic_node_ndarray = node_ndarray[::2]\n        _check_node_ndarray(problematic_node_ndarray, expected_dtype=expected_dtype)\n\n    dtype_dict = {name: dtype for name, (dtype, _) in node_ndarray.dtype.fields.items()}\n\n    # array with wrong 'threshold' field dtype (int64 rather than float64)\n    new_dtype_dict = dtype_dict.copy()\n    new_dtype_dict[\"threshold\"] = np.int64\n\n    new_dtype = np.dtype(\n        {\"names\": list(new_dtype_dict.keys()), \"formats\": list(new_dtype_dict.values())}\n    )\n    problematic_node_ndarray = node_ndarray.astype(new_dtype)\n\n    with pytest.raises(ValueError, match=\"node array.+incompatible dtype\"):\n        _check_node_ndarray(problematic_node_ndarray, expected_dtype=expected_dtype)\n\n    # array with wrong 'left_child' field dtype (float64 rather than int64 or int32)\n    new_dtype_dict = dtype_dict.copy()\n    new_dtype_dict[\"left_child\"] = np.float64\n    new_dtype = np.dtype(\n        {\"names\": list(new_dtype_dict.keys()), \"formats\": list(new_dtype_dict.values())}\n    )\n\n    problematic_node_ndarray = node_ndarray.astype(new_dtype)\n\n    with pytest.raises(ValueError, match=\"node array.+incompatible dtype\"):\n        _check_node_ndarray(problematic_node_ndarray, expected_dtype=expected_dtype)\n\n\n@pytest.mark.parametrize(\n    \"Splitter\", chain(DENSE_SPLITTERS.values(), SPARSE_SPLITTERS.values())\n)\ndef test_splitter_serializable(Splitter):\n    \"\"\"Check that splitters are serializable.\"\"\"\n    rng = np.random.RandomState(42)\n    max_features = 10\n    n_outputs, n_classes = 2, np.array([3, 2], dtype=np.intp)\n\n    criterion = CRITERIA_CLF[\"gini\"](n_outputs, n_classes)\n    splitter = Splitter(criterion, max_features, 5, 0.5, rng, monotonic_cst=None)\n    splitter_serialize = pickle.dumps(splitter)\n\n    splitter_back = pickle.loads(splitter_serialize)\n    assert splitter_back.max_features == max_features\n    assert isinstance(splitte"}, {"start_line": 72000, "end_line": 74000, "belongs_to": {"file_name": "test_tree.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/tree/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "rt np.isclose(score, new_score)\n\n\ndef get_different_bitness_node_ndarray(node_ndarray):\n    new_dtype_for_indexing_fields = np.int64 if _IS_32BIT else np.int32\n\n    # field names in Node struct with SIZE_t types (see sklearn/tree/_tree.pxd)\n    indexing_field_names = [\"left_child\", \"right_child\", \"feature\", \"n_node_samples\"]\n\n    new_dtype_dict = {\n        name: dtype for name, (dtype, _) in node_ndarray.dtype.fields.items()\n    }\n    for name in indexing_field_names:\n        new_dtype_dict[name] = new_dtype_for_indexing_fields\n\n    new_dtype = np.dtype(\n        {\"names\": list(new_dtype_dict.keys()), \"formats\": list(new_dtype_dict.values())}\n    )\n    return node_ndarray.astype(new_dtype, casting=\"same_kind\")\n\n\ndef get_different_alignment_node_ndarray(node_ndarray):\n    new_dtype_dict = {\n        name: dtype for name, (dtype, _) in node_ndarray.dtype.fields.items()\n    }\n    offsets = [offset for dtype, offset in node_ndarray.dtype.fields.values()]\n    shifted_offsets = [8 + offset for offset in offsets]\n\n    new_dtype = np.dtype(\n        {\n            \"names\": list(new_dtype_dict.keys()),\n            \"formats\": list(new_dtype_dict.values()),\n            \"offsets\": shifted_offsets,\n        }\n    )\n    return node_ndarray.astype(new_dtype, casting=\"same_kind\")\n\n\ndef reduce_tree_with_different_bitness(tree):\n    new_dtype = np.int64 if _IS_32BIT else np.int32\n    tree_cls, (n_features, n_classes, n_outputs), state = tree.__reduce__()\n    new_n_classes = n_classes.astype(new_dtype, casting=\"same_kind\")\n\n    new_state = state.copy()\n    new_state[\"nodes\"] = get_different_bitness_node_ndarray(new_state[\"nodes\"])\n\n    return (tree_cls, (n_features, new_n_classes, n_outputs), new_state)\n\n\ndef test_different_bitness_pickle():\n    X, y = datasets.make_classification(random_state=0)\n\n    clf = DecisionTreeClassifier(random_state=0, max_depth=3)\n    clf.fit(X, y)\n    score = clf.score(X, y)\n\n    def pickle_dump_with_different_bitness():\n        f = io.BytesIO()\n        p = pic"}, {"start_line": 91000, "end_line": 93000, "belongs_to": {"file_name": "estimator_checks.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/utils", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": " and labels_ should be of type int\n    assert pred.dtype in [np.dtype(\"int32\"), np.dtype(\"int64\")]\n    assert pred2.dtype in [np.dtype(\"int32\"), np.dtype(\"int64\")]\n\n    # Add noise to X to test the possible values of the labels\n    labels = clusterer.fit_predict(X_noise)\n\n    # There should be at least one sample in every cluster. Equivalently\n    # labels_ should contain all the consecutive values between its\n    # min and its max.\n    labels_sorted = np.unique(labels)\n    assert_array_equal(\n        labels_sorted, np.arange(labels_sorted[0], labels_sorted[-1] + 1)\n    )\n\n    # Labels are expected to start at 0 (no noise) or -1 (if noise)\n    assert labels_sorted[0] in [0, -1]\n    # Labels should be less than n_clusters - 1\n    if hasattr(clusterer, \"n_clusters\"):\n        n_clusters = getattr(clusterer, \"n_clusters\")\n        assert n_clusters - 1 >= labels_sorted[-1]\n    # else labels should be less than max(labels_) which is necessarily true\n\n\n@ignore_warnings(category=FutureWarning)\ndef check_clusterer_compute_labels_predict(name, clusterer_orig):\n    \"\"\"Check that predict is invariant of compute_labels.\"\"\"\n    X, y = make_blobs(n_samples=20, random_state=0)\n    clusterer = clone(clusterer_orig)\n    set_random_state(clusterer)\n\n    if hasattr(clusterer, \"compute_labels\"):\n        # MiniBatchKMeans\n        X_pred1 = clusterer.fit(X).predict(X)\n        clusterer.set_params(compute_labels=False)\n        X_pred2 = clusterer.fit(X).predict(X)\n        assert_array_equal(X_pred1, X_pred2)\n\n\n@ignore_warnings(category=FutureWarning)\ndef check_classifiers_one_label(name, classifier_orig):\n    error_string_fit = \"Classifier can't train when only one class is present.\"\n    error_string_predict = \"Classifier can't predict when only one class is present.\"\n    classifier = clone(classifier_orig)\n    rnd = np.random.RandomState(0)\n    X_train = rnd.uniform(size=(10, 3))\n    X_test = rnd.uniform(size=(10, 3))\n    X_train, X_test = _enforce_estimator_tags_X(classifier, X_train, X_"}, {"start_line": 95000, "end_line": 97000, "belongs_to": {"file_name": "estimator_checks.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/utils", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "ual(\n            classifier.predict(X_test), np.ones(10), err_msg=error_predict\n        )\n\n\n@ignore_warnings  # Warnings are raised by decision function\ndef check_classifiers_train(\n    name, classifier_orig, readonly_memmap=False, X_dtype=\"float64\"\n):\n    X_m, y_m = make_blobs(n_samples=300, random_state=0)\n    X_m = X_m.astype(X_dtype)\n    X_m, y_m = shuffle(X_m, y_m, random_state=7)\n    X_m = StandardScaler().fit_transform(X_m)\n    # generate binary problem from multi-class one\n    y_b = y_m[y_m != 2]\n    X_b = X_m[y_m != 2]\n\n    if name in [\"BernoulliNB\", \"MultinomialNB\", \"ComplementNB\", \"CategoricalNB\"]:\n        X_m -= X_m.min()\n        X_b -= X_b.min()\n\n    if readonly_memmap:\n        X_m, y_m, X_b, y_b = create_memmap_backed_data([X_m, y_m, X_b, y_b])\n\n    problems = [(X_b, y_b)]\n    tags = get_tags(classifier_orig)\n    if tags.classifier_tags.multi_class:\n        problems.append((X_m, y_m))\n\n    for X, y in problems:\n        classes = np.unique(y)\n        n_classes = len(classes)\n        n_samples, n_features = X.shape\n        classifier = clone(classifier_orig)\n        X = _enforce_estimator_tags_X(classifier, X)\n        y = _enforce_estimator_tags_y(classifier, y)\n\n        set_random_state(classifier)\n        # raises error on malformed input for fit\n        if not tags.no_validation:\n            with raises(\n                ValueError,\n                err_msg=(\n                    f\"The classifier {name} does not raise an error when \"\n                    \"incorrect/malformed input data for fit is passed. The number \"\n                    \"of training examples is not the same as the number of \"\n                    \"labels. Perhaps use check_X_y in fit.\"\n                ),\n            ):\n                classifier.fit(X, y[:-1])\n\n        # fit\n        classifier.fit(X, y)\n        # with lists\n        classifier.fit(X.tolist(), y.tolist())\n        assert hasattr(classifier, \"classes_\")\n        y_pred = classifier.predict(X)\n\n        assert y_pred.shape == (n_"}, {"start_line": 71000, "end_line": 73000, "belongs_to": {"file_name": "test_tree.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/tree/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "_table.copy()\n        p.dispatch_table[np.ndarray] = reduce_ndarray\n\n        p.dump(clf)\n        f.seek(0)\n        return f\n\n    new_clf = pickle.load(get_pickle_non_native_endianness())\n    new_score = new_clf.score(X, y)\n    assert np.isclose(score, new_score)\n\n\ndef test_different_endianness_joblib_pickle():\n    X, y = datasets.make_classification(random_state=0)\n\n    clf = DecisionTreeClassifier(random_state=0, max_depth=3)\n    clf.fit(X, y)\n    score = clf.score(X, y)\n\n    class NonNativeEndiannessNumpyPickler(NumpyPickler):\n        def save(self, obj):\n            if isinstance(obj, np.ndarray):\n                obj = obj.byteswap().view(obj.dtype.newbyteorder())\n            super().save(obj)\n\n    def get_joblib_pickle_non_native_endianness():\n        f = io.BytesIO()\n        p = NonNativeEndiannessNumpyPickler(f)\n\n        p.dump(clf)\n        f.seek(0)\n        return f\n\n    new_clf = joblib.load(get_joblib_pickle_non_native_endianness())\n    new_score = new_clf.score(X, y)\n    assert np.isclose(score, new_score)\n\n\ndef get_different_bitness_node_ndarray(node_ndarray):\n    new_dtype_for_indexing_fields = np.int64 if _IS_32BIT else np.int32\n\n    # field names in Node struct with SIZE_t types (see sklearn/tree/_tree.pxd)\n    indexing_field_names = [\"left_child\", \"right_child\", \"feature\", \"n_node_samples\"]\n\n    new_dtype_dict = {\n        name: dtype for name, (dtype, _) in node_ndarray.dtype.fields.items()\n    }\n    for name in indexing_field_names:\n        new_dtype_dict[name] = new_dtype_for_indexing_fields\n\n    new_dtype = np.dtype(\n        {\"names\": list(new_dtype_dict.keys()), \"formats\": list(new_dtype_dict.values())}\n    )\n    return node_ndarray.astype(new_dtype, casting=\"same_kind\")\n\n\ndef get_different_alignment_node_ndarray(node_ndarray):\n    new_dtype_dict = {\n        name: dtype for name, (dtype, _) in node_ndarray.dtype.fields.items()\n    }\n    offsets = [offset for dtype, offset in node_ndarray.dtype.fields.values()]\n    shifted_offsets = [8 + offset for"}, {"start_line": 27000, "end_line": 29000, "belongs_to": {"file_name": "test_mlp.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/neural_network/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": " data splitting for early stopping is stratified\n    X = [[1, 2], [2, 3], [3, 4], [4, 5]]\n    y = [0, 0, 0, 1]\n\n    mlp = MLPClassifier(early_stopping=True)\n    with pytest.raises(\n        ValueError, match=\"The least populated class in y has only 1 member\"\n    ):\n        mlp.fit(X, y)\n\n\ndef test_mlp_classifier_dtypes_casting():\n    # Compare predictions for different dtypes\n    mlp_64 = MLPClassifier(\n        alpha=1e-5, hidden_layer_sizes=(5, 3), random_state=1, max_iter=100, tol=1e-1\n    )\n    mlp_64.fit(X_digits[:300], y_digits[:300])\n    pred_64 = mlp_64.predict(X_digits[300:])\n    proba_64 = mlp_64.predict_proba(X_digits[300:])\n\n    mlp_32 = MLPClassifier(\n        alpha=1e-5, hidden_layer_sizes=(5, 3), random_state=1, max_iter=100, tol=1e-1\n    )\n    mlp_32.fit(X_digits[:300].astype(np.float32), y_digits[:300])\n    pred_32 = mlp_32.predict(X_digits[300:].astype(np.float32))\n    proba_32 = mlp_32.predict_proba(X_digits[300:].astype(np.float32))\n\n    assert_array_equal(pred_64, pred_32)\n    assert_allclose(proba_64, proba_32, rtol=1e-02)\n\n\ndef test_mlp_regressor_dtypes_casting():\n    mlp_64 = MLPRegressor(\n        alpha=1e-5, hidden_layer_sizes=(5, 3), random_state=1, max_iter=150, tol=1e-3\n    )\n    mlp_64.fit(X_digits[:300], y_digits[:300])\n    pred_64 = mlp_64.predict(X_digits[300:])\n\n    mlp_32 = MLPRegressor(\n        alpha=1e-5, hidden_layer_sizes=(5, 3), random_state=1, max_iter=150, tol=1e-3\n    )\n    mlp_32.fit(X_digits[:300].astype(np.float32), y_digits[:300])\n    pred_32 = mlp_32.predict(X_digits[300:].astype(np.float32))\n\n    assert_allclose(pred_64, pred_32, rtol=5e-04)\n\n\n@pytest.mark.parametrize(\"dtype\", [np.float32, np.float64])\n@pytest.mark.parametrize(\"Estimator\", [MLPClassifier, MLPRegressor])\ndef test_mlp_param_dtypes(dtype, Estimator):\n    # Checks if input dtype is used for network parameters\n    # and predictions\n    X, y = X_digits.astype(dtype), y_digits\n    mlp = Estimator(\n        alpha=1e-5, hidden_layer_sizes=(5, 3), random_state=1, ma"}], "retrieved_count": 10, "cost_time": 1.2268192768096924}
{"question": "How does the convergence detection mechanism in the `fit` method handle the trade-off between numerical precision and computational efficiency when comparing label distribution changes across iterations?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"start_line": 10000, "end_line": 12000, "belongs_to": {"file_name": "_label_propagation.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/semi_supervised", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "= label] = 1\n\n        y_static = np.copy(self.label_distributions_)\n        if self._variant == \"propagation\":\n            # LabelPropagation\n            y_static[unlabeled] = 0\n        else:\n            # LabelSpreading\n            y_static *= 1 - self.alpha\n\n        l_previous = np.zeros((self.X_.shape[0], n_classes))\n\n        unlabeled = unlabeled[:, np.newaxis]\n        if sparse.issparse(graph_matrix):\n            graph_matrix = graph_matrix.tocsr()\n\n        for self.n_iter_ in range(self.max_iter):\n            if np.abs(self.label_distributions_ - l_previous).sum() < self.tol:\n                break\n\n            l_previous = self.label_distributions_\n            self.label_distributions_ = safe_sparse_dot(\n                graph_matrix, self.label_distributions_\n            )\n\n            if self._variant == \"propagation\":\n                normalizer = np.sum(self.label_distributions_, axis=1)[:, np.newaxis]\n                normalizer[normalizer == 0] = 1\n                self.label_distributions_ /= normalizer\n                self.label_distributions_ = np.where(\n                    unlabeled, self.label_distributions_, y_static\n                )\n            else:\n                # clamp\n                self.label_distributions_ = (\n                    np.multiply(self.alpha, self.label_distributions_) + y_static\n                )\n        else:\n            warnings.warn(\n                \"max_iter=%d was reached without convergence.\" % self.max_iter,\n                category=ConvergenceWarning,\n            )\n            self.n_iter_ += 1\n\n        normalizer = np.sum(self.label_distributions_, axis=1)[:, np.newaxis]\n        normalizer[normalizer == 0] = 1\n        self.label_distributions_ /= normalizer\n\n        # set the transduction item\n        transduction = self.classes_[np.argmax(self.label_distributions_, axis=1)]\n        self.transduction_ = transduction.ravel()\n        return self\n\n    def __sklearn_tags__(self):\n        tags = super().__sklearn_tags__()\n   "}, {"start_line": 19000, "end_line": 21000, "belongs_to": {"file_name": "_kmeans.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/cluster", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "     centers,\n        center_half_distances,\n        labels,\n        upper_bounds,\n        lower_bounds,\n        n_threads=n_threads,\n    )\n\n    strict_convergence = False\n\n    for i in range(max_iter):\n        elkan_iter(\n            X,\n            sample_weight,\n            centers,\n            centers_new,\n            weight_in_clusters,\n            center_half_distances,\n            distance_next_center,\n            upper_bounds,\n            lower_bounds,\n            labels,\n            center_shift,\n            n_threads,\n        )\n\n        # compute new pairwise distances between centers and closest other\n        # center of each center for next iterations\n        center_half_distances = euclidean_distances(centers_new) / 2\n        distance_next_center = np.partition(\n            np.asarray(center_half_distances), kth=1, axis=0\n        )[1]\n\n        if verbose:\n            inertia = _inertia(X, sample_weight, centers, labels, n_threads)\n            print(f\"Iteration {i}, inertia {inertia}\")\n\n        centers, centers_new = centers_new, centers\n\n        if np.array_equal(labels, labels_old):\n            # First check the labels for strict convergence.\n            if verbose:\n                print(f\"Converged at iteration {i}: strict convergence.\")\n            strict_convergence = True\n            break\n        else:\n            # No strict convergence, check for tol based convergence.\n            center_shift_tot = (center_shift**2).sum()\n            if center_shift_tot <= tol:\n                if verbose:\n                    print(\n                        f\"Converged at iteration {i}: center shift \"\n                        f\"{center_shift_tot} within tolerance {tol}.\"\n                    )\n                break\n\n        labels_old[:] = labels\n\n    if not strict_convergence:\n        # rerun E-step so that predicted labels match cluster centers\n        elkan_iter(\n            X,\n            sample_weight,\n            centers,\n            centers,\n            weigh"}, {"start_line": 4000, "end_line": 6000, "belongs_to": {"file_name": "test_label_propagation.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/semi_supervised/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "= (Y[:, (-1,)] == 0).nonzero()[0]\n\n    clf = label_propagation.LabelPropagation(max_iter=100, tol=1e-10, gamma=0.1)\n    clf.fit(X, y)\n    # adopting notation from Zhu et al 2002\n    T_bar = clf._build_graph()\n    Tuu = T_bar[tuple(np.meshgrid(unlabelled_idx, unlabelled_idx, indexing=\"ij\"))]\n    Tul = T_bar[tuple(np.meshgrid(unlabelled_idx, labelled_idx, indexing=\"ij\"))]\n    Y = Y[:, :-1]\n    Y_l = Y[labelled_idx, :]\n    Y_u = np.dot(np.dot(np.linalg.inv(np.eye(Tuu.shape[0]) - Tuu), Tul), Y_l)\n\n    expected = Y.copy()\n    expected[unlabelled_idx, :] = Y_u\n    expected /= expected.sum(axis=1)[:, np.newaxis]\n\n    assert_allclose(expected, clf.label_distributions_, atol=1e-4)\n\n\n@pytest.mark.parametrize(\"accepted_sparse_type\", [\"sparse_csr\", \"sparse_csc\"])\n@pytest.mark.parametrize(\"index_dtype\", [np.int32, np.int64])\n@pytest.mark.parametrize(\"dtype\", [np.float32, np.float64])\n@pytest.mark.parametrize(\"Estimator, parameters\", ESTIMATORS)\ndef test_sparse_input_types(\n    accepted_sparse_type, index_dtype, dtype, Estimator, parameters\n):\n    # This is non-regression test for #17085\n    X = _convert_container([[1.0, 0.0], [0.0, 2.0], [1.0, 3.0]], accepted_sparse_type)\n    X.data = X.data.astype(dtype, copy=False)\n    X.indices = X.indices.astype(index_dtype, copy=False)\n    X.indptr = X.indptr.astype(index_dtype, copy=False)\n    labels = [0, 1, -1]\n    clf = Estimator(**parameters).fit(X, labels)\n    assert_array_equal(clf.predict([[0.5, 2.5]]), np.array([1]))\n\n\n@pytest.mark.parametrize(\"constructor_type\", CONSTRUCTOR_TYPES)\ndef test_convergence_speed(constructor_type):\n    # This is a non-regression test for #5774\n    X = _convert_container([[1.0, 0.0], [0.0, 1.0], [1.0, 2.5]], constructor_type)\n    y = np.array([0, 1, -1])\n    mdl = label_propagation.LabelSpreading(kernel=\"rbf\", max_iter=5000)\n    mdl.fit(X, y)\n\n    # this should converge quickly:\n    assert mdl.n_iter_ < 10\n    assert_array_equal(mdl.predict(X), [0, 1, 1])\n\n\ndef test_convergence_warning():\n    # This is a"}, {"start_line": 24000, "end_line": 26000, "belongs_to": {"file_name": "_kmeans.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/cluster", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "      lloyd_iter(\n            X,\n            sample_weight,\n            centers,\n            centers_new,\n            weight_in_clusters,\n            labels,\n            center_shift,\n            n_threads,\n        )\n\n        if verbose:\n            inertia = _inertia(X, sample_weight, centers, labels, n_threads)\n            print(f\"Iteration {i}, inertia {inertia}.\")\n\n        centers, centers_new = centers_new, centers\n\n        if np.array_equal(labels, labels_old):\n            # First check the labels for strict convergence.\n            if verbose:\n                print(f\"Converged at iteration {i}: strict convergence.\")\n            strict_convergence = True\n            break\n        else:\n            # No strict convergence, check for tol based convergence.\n            center_shift_tot = (center_shift**2).sum()\n            if center_shift_tot <= tol:\n                if verbose:\n                    print(\n                        f\"Converged at iteration {i}: center shift \"\n                        f\"{center_shift_tot} within tolerance {tol}.\"\n                    )\n                break\n\n        labels_old[:] = labels\n\n    if not strict_convergence:\n        # rerun E-step so that predicted labels match cluster centers\n        lloyd_iter(\n            X,\n            sample_weight,\n            centers,\n            centers,\n            weight_in_clusters,\n            labels,\n            center_shift,\n            n_threads,\n            update_centers=False,\n        )\n\n    inertia = _inertia(X, sample_weight, centers, labels, n_threads)\n\n    return labels, inertia, centers, i + 1\n\n\ndef _labels_inertia(X, sample_weight, centers, n_threads=1, return_inertia=True):\n    \"\"\"E step of the K-means EM algorithm.\n\n    Compute the labels and the inertia of the given samples and centers.\n\n    Parameters\n    ----------\n    X : {ndarray, sparse matrix} of shape (n_samples, n_features)\n        The input samples to assign to the labels. If sparse matrix, must\n        be in CSR format.\n\n"}, {"start_line": 11000, "end_line": 13000, "belongs_to": {"file_name": "_label_propagation.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/semi_supervised", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "istributions_ /= normalizer\n                self.label_distributions_ = np.where(\n                    unlabeled, self.label_distributions_, y_static\n                )\n            else:\n                # clamp\n                self.label_distributions_ = (\n                    np.multiply(self.alpha, self.label_distributions_) + y_static\n                )\n        else:\n            warnings.warn(\n                \"max_iter=%d was reached without convergence.\" % self.max_iter,\n                category=ConvergenceWarning,\n            )\n            self.n_iter_ += 1\n\n        normalizer = np.sum(self.label_distributions_, axis=1)[:, np.newaxis]\n        normalizer[normalizer == 0] = 1\n        self.label_distributions_ /= normalizer\n\n        # set the transduction item\n        transduction = self.classes_[np.argmax(self.label_distributions_, axis=1)]\n        self.transduction_ = transduction.ravel()\n        return self\n\n    def __sklearn_tags__(self):\n        tags = super().__sklearn_tags__()\n        tags.input_tags.sparse = True\n        return tags\n\n\nclass LabelPropagation(BaseLabelPropagation):\n    \"\"\"Label Propagation classifier.\n\n    Read more in the :ref:`User Guide <label_propagation>`.\n\n    Parameters\n    ----------\n    kernel : {'knn', 'rbf'} or callable, default='rbf'\n        String identifier for kernel function to use or the kernel function\n        itself. Only 'rbf' and 'knn' strings are valid inputs. The function\n        passed should take two inputs, each of shape (n_samples, n_features),\n        and return a (n_samples, n_samples) shaped weight matrix.\n\n    gamma : float, default=20\n        Parameter for rbf kernel.\n\n    n_neighbors : int, default=7\n        Parameter for knn kernel which need to be strictly positive.\n\n    max_iter : int, default=1000\n        Change maximum number of iterations allowed.\n\n    tol : float, default=1e-3\n        Convergence tolerance: threshold to consider the system at steady\n        state.\n\n    n_jobs : int, default=None\n        Th"}, {"start_line": 23000, "end_line": 25000, "belongs_to": {"file_name": "_kmeans.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/cluster", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "\n\n    label : ndarray of shape (n_samples,)\n        label[i] is the code or index of the centroid the\n        i'th observation is closest to.\n\n    inertia : float\n        The final value of the inertia criterion (sum of squared distances to\n        the closest centroid for all observations in the training set).\n\n    n_iter : int\n        Number of iterations run.\n    \"\"\"\n    n_clusters = centers_init.shape[0]\n\n    # Buffers to avoid new allocations at each iteration.\n    centers = centers_init\n    centers_new = np.zeros_like(centers)\n    labels = np.full(X.shape[0], -1, dtype=np.int32)\n    labels_old = labels.copy()\n    weight_in_clusters = np.zeros(n_clusters, dtype=X.dtype)\n    center_shift = np.zeros(n_clusters, dtype=X.dtype)\n\n    if sp.issparse(X):\n        lloyd_iter = lloyd_iter_chunked_sparse\n        _inertia = _inertia_sparse\n    else:\n        lloyd_iter = lloyd_iter_chunked_dense\n        _inertia = _inertia_dense\n\n    strict_convergence = False\n\n    for i in range(max_iter):\n        lloyd_iter(\n            X,\n            sample_weight,\n            centers,\n            centers_new,\n            weight_in_clusters,\n            labels,\n            center_shift,\n            n_threads,\n        )\n\n        if verbose:\n            inertia = _inertia(X, sample_weight, centers, labels, n_threads)\n            print(f\"Iteration {i}, inertia {inertia}.\")\n\n        centers, centers_new = centers_new, centers\n\n        if np.array_equal(labels, labels_old):\n            # First check the labels for strict convergence.\n            if verbose:\n                print(f\"Converged at iteration {i}: strict convergence.\")\n            strict_convergence = True\n            break\n        else:\n            # No strict convergence, check for tol based convergence.\n            center_shift_tot = (center_shift**2).sum()\n            if center_shift_tot <= tol:\n                if verbose:\n                    print(\n                        f\"Converged at iteration {i}: center shift \"\n          "}, {"start_line": 25000, "end_line": 27000, "belongs_to": {"file_name": "_nmf.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/decomposition", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "he convergence criterion\n    error_at_init = _beta_divergence(X, W, H, beta_loss, square_root=True)\n    previous_error = error_at_init\n\n    H_sum, HHt, XHt = None, None, None\n    for n_iter in range(1, max_iter + 1):\n        # update W\n        # H_sum, HHt and XHt are saved and reused if not update_H\n        W, H_sum, HHt, XHt = _multiplicative_update_w(\n            X,\n            W,\n            H,\n            beta_loss=beta_loss,\n            l1_reg_W=l1_reg_W,\n            l2_reg_W=l2_reg_W,\n            gamma=gamma,\n            H_sum=H_sum,\n            HHt=HHt,\n            XHt=XHt,\n            update_H=update_H,\n        )\n\n        # necessary for stability with beta_loss < 1\n        if beta_loss < 1:\n            W[W < np.finfo(np.float64).eps] = 0.0\n\n        # update H (only at fit or fit_transform)\n        if update_H:\n            H = _multiplicative_update_h(\n                X,\n                W,\n                H,\n                beta_loss=beta_loss,\n                l1_reg_H=l1_reg_H,\n                l2_reg_H=l2_reg_H,\n                gamma=gamma,\n            )\n\n            # These values will be recomputed since H changed\n            H_sum, HHt, XHt = None, None, None\n\n            # necessary for stability with beta_loss < 1\n            if beta_loss <= 1:\n                H[H < np.finfo(np.float64).eps] = 0.0\n\n        # test convergence criterion every 10 iterations\n        if tol > 0 and n_iter % 10 == 0:\n            error = _beta_divergence(X, W, H, beta_loss, square_root=True)\n\n            if verbose:\n                iter_time = time.time()\n                print(\n                    \"Epoch %02d reached after %.3f seconds, error: %f\"\n                    % (n_iter, iter_time - start_time, error)\n                )\n\n            if (previous_error - error) / error_at_init < tol:\n                break\n            previous_error = error\n\n    # do not print if we have already printed in the convergence test\n    if verbose and (tol == 0 or n_iter % 10 != 0):\n        en"}, {"start_line": 17000, "end_line": 19000, "belongs_to": {"file_name": "_kmeans.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/cluster", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "regards to Frobenius norm of the difference\n        in the cluster centers of two consecutive iterations to declare\n        convergence.\n        It's not advised to set `tol=0` since convergence might never be\n        declared due to rounding errors. Use a very small number instead.\n\n    n_threads : int, default=1\n        The number of OpenMP threads to use for the computation. Parallelism is\n        sample-wise on the main cython loop which assigns each sample to its\n        closest center.\n\n    Returns\n    -------\n    centroid : ndarray of shape (n_clusters, n_features)\n        Centroids found at the last iteration of k-means.\n\n    label : ndarray of shape (n_samples,)\n        label[i] is the code or index of the centroid the\n        i'th observation is closest to.\n\n    inertia : float\n        The final value of the inertia criterion (sum of squared distances to\n        the closest centroid for all observations in the training set).\n\n    n_iter : int\n        Number of iterations run.\n    \"\"\"\n    n_samples = X.shape[0]\n    n_clusters = centers_init.shape[0]\n\n    # Buffers to avoid new allocations at each iteration.\n    centers = centers_init\n    centers_new = np.zeros_like(centers)\n    weight_in_clusters = np.zeros(n_clusters, dtype=X.dtype)\n    labels = np.full(n_samples, -1, dtype=np.int32)\n    labels_old = labels.copy()\n    center_half_distances = euclidean_distances(centers) / 2\n    distance_next_center = np.partition(\n        np.asarray(center_half_distances), kth=1, axis=0\n    )[1]\n    upper_bounds = np.zeros(n_samples, dtype=X.dtype)\n    lower_bounds = np.zeros((n_samples, n_clusters), dtype=X.dtype)\n    center_shift = np.zeros(n_clusters, dtype=X.dtype)\n\n    if sp.issparse(X):\n        init_bounds = init_bounds_sparse\n        elkan_iter = elkan_iter_chunked_sparse\n        _inertia = _inertia_sparse\n    else:\n        init_bounds = init_bounds_dense\n        elkan_iter = elkan_iter_chunked_dense\n        _inertia = _inertia_dense\n\n    init_bounds(\n        X,\n   "}, {"start_line": 3000, "end_line": 5000, "belongs_to": {"file_name": "test_label_propagation.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/semi_supervised/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "0)\n    X = X.astype(global_dtype, copy=False)\n    y[::3] = -1\n\n    gamma = 0.1\n    clf = label_propagation.LabelSpreading(gamma=gamma).fit(X, y)\n    # adopting notation from Zhou et al (2004):\n    S = clf._build_graph()\n    Y = np.zeros((len(y), n_classes + 1), dtype=X.dtype)\n    Y[np.arange(len(y)), y] = 1\n    Y = Y[:, :-1]\n\n    expected = np.dot(np.linalg.inv(np.eye(len(S), dtype=S.dtype) - alpha * S), Y)\n    expected /= expected.sum(axis=1)[:, np.newaxis]\n\n    clf = label_propagation.LabelSpreading(\n        max_iter=100, alpha=alpha, tol=1e-10, gamma=gamma\n    )\n    clf.fit(X, y)\n\n    assert_allclose(expected, clf.label_distributions_)\n\n\ndef test_label_propagation_closed_form(global_dtype):\n    n_classes = 2\n    X, y = make_classification(n_classes=n_classes, n_samples=200, random_state=0)\n    X = X.astype(global_dtype, copy=False)\n    y[::3] = -1\n    Y = np.zeros((len(y), n_classes + 1))\n    Y[np.arange(len(y)), y] = 1\n    unlabelled_idx = Y[:, (-1,)].nonzero()[0]\n    labelled_idx = (Y[:, (-1,)] == 0).nonzero()[0]\n\n    clf = label_propagation.LabelPropagation(max_iter=100, tol=1e-10, gamma=0.1)\n    clf.fit(X, y)\n    # adopting notation from Zhu et al 2002\n    T_bar = clf._build_graph()\n    Tuu = T_bar[tuple(np.meshgrid(unlabelled_idx, unlabelled_idx, indexing=\"ij\"))]\n    Tul = T_bar[tuple(np.meshgrid(unlabelled_idx, labelled_idx, indexing=\"ij\"))]\n    Y = Y[:, :-1]\n    Y_l = Y[labelled_idx, :]\n    Y_u = np.dot(np.dot(np.linalg.inv(np.eye(Tuu.shape[0]) - Tuu), Tul), Y_l)\n\n    expected = Y.copy()\n    expected[unlabelled_idx, :] = Y_u\n    expected /= expected.sum(axis=1)[:, np.newaxis]\n\n    assert_allclose(expected, clf.label_distributions_, atol=1e-4)\n\n\n@pytest.mark.parametrize(\"accepted_sparse_type\", [\"sparse_csr\", \"sparse_csc\"])\n@pytest.mark.parametrize(\"index_dtype\", [np.int32, np.int64])\n@pytest.mark.parametrize(\"dtype\", [np.float32, np.float64])\n@pytest.mark.parametrize(\"Estimator, parameters\", ESTIMATORS)\ndef test_sparse_input_types(\n    accepted_sparse_type,"}, {"start_line": 18000, "end_line": 20000, "belongs_to": {"file_name": "_kmeans.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/cluster", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "\n    \"\"\"\n    n_samples = X.shape[0]\n    n_clusters = centers_init.shape[0]\n\n    # Buffers to avoid new allocations at each iteration.\n    centers = centers_init\n    centers_new = np.zeros_like(centers)\n    weight_in_clusters = np.zeros(n_clusters, dtype=X.dtype)\n    labels = np.full(n_samples, -1, dtype=np.int32)\n    labels_old = labels.copy()\n    center_half_distances = euclidean_distances(centers) / 2\n    distance_next_center = np.partition(\n        np.asarray(center_half_distances), kth=1, axis=0\n    )[1]\n    upper_bounds = np.zeros(n_samples, dtype=X.dtype)\n    lower_bounds = np.zeros((n_samples, n_clusters), dtype=X.dtype)\n    center_shift = np.zeros(n_clusters, dtype=X.dtype)\n\n    if sp.issparse(X):\n        init_bounds = init_bounds_sparse\n        elkan_iter = elkan_iter_chunked_sparse\n        _inertia = _inertia_sparse\n    else:\n        init_bounds = init_bounds_dense\n        elkan_iter = elkan_iter_chunked_dense\n        _inertia = _inertia_dense\n\n    init_bounds(\n        X,\n        centers,\n        center_half_distances,\n        labels,\n        upper_bounds,\n        lower_bounds,\n        n_threads=n_threads,\n    )\n\n    strict_convergence = False\n\n    for i in range(max_iter):\n        elkan_iter(\n            X,\n            sample_weight,\n            centers,\n            centers_new,\n            weight_in_clusters,\n            center_half_distances,\n            distance_next_center,\n            upper_bounds,\n            lower_bounds,\n            labels,\n            center_shift,\n            n_threads,\n        )\n\n        # compute new pairwise distances between centers and closest other\n        # center of each center for next iterations\n        center_half_distances = euclidean_distances(centers_new) / 2\n        distance_next_center = np.partition(\n            np.asarray(center_half_distances), kth=1, axis=0\n        )[1]\n\n        if verbose:\n            inertia = _inertia(X, sample_weight, centers, labels, n_threads)\n            print(f\"Iteration {i}, inertia "}], "retrieved_count": 10, "cost_time": 1.2446677684783936}
{"question": "Why does the Version class defer the extraction of numeric components from pre, post, and dev tuples until property access time rather than storing them directly during initialization?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"start_line": 11000, "end_line": 13000, "belongs_to": {"file_name": "version.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/externals/_packaging", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "post else None\n\n    @property\n    def dev(self) -> Optional[int]:\n        return self._version.dev[1] if self._version.dev else None\n\n    @property\n    def local(self) -> Optional[str]:\n        if self._version.local:\n            return \".\".join(str(x) for x in self._version.local)\n        else:\n            return None\n\n    @property\n    def public(self) -> str:\n        return str(self).split(\"+\", 1)[0]\n\n    @property\n    def base_version(self) -> str:\n        parts = []\n\n        # Epoch\n        if self.epoch != 0:\n            parts.append(f\"{self.epoch}!\")\n\n        # Release segment\n        parts.append(\".\".join(str(x) for x in self.release))\n\n        return \"\".join(parts)\n\n    @property\n    def is_prerelease(self) -> bool:\n        return self.dev is not None or self.pre is not None\n\n    @property\n    def is_postrelease(self) -> bool:\n        return self.post is not None\n\n    @property\n    def is_devrelease(self) -> bool:\n        return self.dev is not None\n\n    @property\n    def major(self) -> int:\n        return self.release[0] if len(self.release) >= 1 else 0\n\n    @property\n    def minor(self) -> int:\n        return self.release[1] if len(self.release) >= 2 else 0\n\n    @property\n    def micro(self) -> int:\n        return self.release[2] if len(self.release) >= 3 else 0\n\n\ndef _parse_letter_version(\n    letter: str, number: Union[str, bytes, SupportsInt]\n) -> Optional[Tuple[str, int]]:\n\n    if letter:\n        # We consider there to be an implicit 0 in a pre-release if there is\n        # not a numeral associated with it.\n        if number is None:\n            number = 0\n\n        # We normalize any letters to their lower case form\n        letter = letter.lower()\n\n        # We consider some words to be alternate spellings of other words and\n        # in those cases we want to normalize the spellings to our preferred\n        # spelling.\n        if letter == \"alpha\":\n            letter = \"a\"\n        elif letter == \"beta\":\n            letter = \"b\"\n        elif letter in"}, {"start_line": 12000, "end_line": 14000, "belongs_to": {"file_name": "version.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/externals/_packaging", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "r(self) -> int:\n        return self.release[0] if len(self.release) >= 1 else 0\n\n    @property\n    def minor(self) -> int:\n        return self.release[1] if len(self.release) >= 2 else 0\n\n    @property\n    def micro(self) -> int:\n        return self.release[2] if len(self.release) >= 3 else 0\n\n\ndef _parse_letter_version(\n    letter: str, number: Union[str, bytes, SupportsInt]\n) -> Optional[Tuple[str, int]]:\n\n    if letter:\n        # We consider there to be an implicit 0 in a pre-release if there is\n        # not a numeral associated with it.\n        if number is None:\n            number = 0\n\n        # We normalize any letters to their lower case form\n        letter = letter.lower()\n\n        # We consider some words to be alternate spellings of other words and\n        # in those cases we want to normalize the spellings to our preferred\n        # spelling.\n        if letter == \"alpha\":\n            letter = \"a\"\n        elif letter == \"beta\":\n            letter = \"b\"\n        elif letter in [\"c\", \"pre\", \"preview\"]:\n            letter = \"rc\"\n        elif letter in [\"rev\", \"r\"]:\n            letter = \"post\"\n\n        return letter, int(number)\n    if not letter and number:\n        # We assume if we are given a number, but we are not given a letter\n        # then this is using the implicit post release syntax (e.g. 1.0-1)\n        letter = \"post\"\n\n        return letter, int(number)\n\n    return None\n\n\n_local_version_separators = re.compile(r\"[\\._-]\")\n\n\ndef _parse_local_version(local: str) -> Optional[LocalType]:\n    \"\"\"\n    Takes a string like abc.1.twelve and turns it into (\"abc\", 1, \"twelve\").\n    \"\"\"\n    if local is not None:\n        return tuple(\n            part.lower() if not part.isdigit() else int(part)\n            for part in _local_version_separators.split(local)\n        )\n    return None\n\n\ndef _cmpkey(\n    epoch: int,\n    release: Tuple[int, ...],\n    pre: Optional[Tuple[str, int]],\n    post: Optional[Tuple[str, int]],\n    dev: Optional[Tuple[str, int]],\n    local: O"}, {"start_line": 9000, "end_line": 11000, "belongs_to": {"file_name": "version.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/externals/_packaging", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": " release=tuple(int(i) for i in match.group(\"release\").split(\".\")),\n            pre=_parse_letter_version(match.group(\"pre_l\"), match.group(\"pre_n\")),\n            post=_parse_letter_version(\n                match.group(\"post_l\"), match.group(\"post_n1\") or match.group(\"post_n2\")\n            ),\n            dev=_parse_letter_version(match.group(\"dev_l\"), match.group(\"dev_n\")),\n            local=_parse_local_version(match.group(\"local\")),\n        )\n\n        # Generate a key which will be used for sorting\n        self._key = _cmpkey(\n            self._version.epoch,\n            self._version.release,\n            self._version.pre,\n            self._version.post,\n            self._version.dev,\n            self._version.local,\n        )\n\n    def __repr__(self) -> str:\n        return f\"<Version('{self}')>\"\n\n    def __str__(self) -> str:\n        parts = []\n\n        # Epoch\n        if self.epoch != 0:\n            parts.append(f\"{self.epoch}!\")\n\n        # Release segment\n        parts.append(\".\".join(str(x) for x in self.release))\n\n        # Pre-release\n        if self.pre is not None:\n            parts.append(\"\".join(str(x) for x in self.pre))\n\n        # Post-release\n        if self.post is not None:\n            parts.append(f\".post{self.post}\")\n\n        # Development release\n        if self.dev is not None:\n            parts.append(f\".dev{self.dev}\")\n\n        # Local version segment\n        if self.local is not None:\n            parts.append(f\"+{self.local}\")\n\n        return \"\".join(parts)\n\n    @property\n    def epoch(self) -> int:\n        _epoch: int = self._version.epoch\n        return _epoch\n\n    @property\n    def release(self) -> Tuple[int, ...]:\n        _release: Tuple[int, ...] = self._version.release\n        return _release\n\n    @property\n    def pre(self) -> Optional[Tuple[str, int]]:\n        _pre: Optional[Tuple[str, int]] = self._version.pre\n        return _pre\n\n    @property\n    def post(self) -> Optional[int]:\n        return self._version.post[1] if self._version."}, {"start_line": 10000, "end_line": 12000, "belongs_to": {"file_name": "version.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/externals/_packaging", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "oin(str(x) for x in self.release))\n\n        # Pre-release\n        if self.pre is not None:\n            parts.append(\"\".join(str(x) for x in self.pre))\n\n        # Post-release\n        if self.post is not None:\n            parts.append(f\".post{self.post}\")\n\n        # Development release\n        if self.dev is not None:\n            parts.append(f\".dev{self.dev}\")\n\n        # Local version segment\n        if self.local is not None:\n            parts.append(f\"+{self.local}\")\n\n        return \"\".join(parts)\n\n    @property\n    def epoch(self) -> int:\n        _epoch: int = self._version.epoch\n        return _epoch\n\n    @property\n    def release(self) -> Tuple[int, ...]:\n        _release: Tuple[int, ...] = self._version.release\n        return _release\n\n    @property\n    def pre(self) -> Optional[Tuple[str, int]]:\n        _pre: Optional[Tuple[str, int]] = self._version.pre\n        return _pre\n\n    @property\n    def post(self) -> Optional[int]:\n        return self._version.post[1] if self._version.post else None\n\n    @property\n    def dev(self) -> Optional[int]:\n        return self._version.dev[1] if self._version.dev else None\n\n    @property\n    def local(self) -> Optional[str]:\n        if self._version.local:\n            return \".\".join(str(x) for x in self._version.local)\n        else:\n            return None\n\n    @property\n    def public(self) -> str:\n        return str(self).split(\"+\", 1)[0]\n\n    @property\n    def base_version(self) -> str:\n        parts = []\n\n        # Epoch\n        if self.epoch != 0:\n            parts.append(f\"{self.epoch}!\")\n\n        # Release segment\n        parts.append(\".\".join(str(x) for x in self.release))\n\n        return \"\".join(parts)\n\n    @property\n    def is_prerelease(self) -> bool:\n        return self.dev is not None or self.pre is not None\n\n    @property\n    def is_postrelease(self) -> bool:\n        return self.post is not None\n\n    @property\n    def is_devrelease(self) -> bool:\n        return self.dev is not None\n\n    @property\n    def majo"}, {"start_line": 7000, "end_line": 9000, "belongs_to": {"file_name": "version.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/externals/_packaging", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "   if part.startswith(\"*\"):\n            # remove \"-\" before a prerelease tag\n            if part < \"*final\":\n                while parts and parts[-1] == \"*final-\":\n                    parts.pop()\n\n            # remove trailing zeros from each series of numeric parts\n            while parts and parts[-1] == \"00000000\":\n                parts.pop()\n\n        parts.append(part)\n\n    return epoch, tuple(parts)\n\n\n# Deliberately not anchored to the start and end of the string, to make it\n# easier for 3rd party code to reuse\nVERSION_PATTERN = r\"\"\"\n    v?\n    (?:\n        (?:(?P<epoch>[0-9]+)!)?                           # epoch\n        (?P<release>[0-9]+(?:\\.[0-9]+)*)                  # release segment\n        (?P<pre>                                          # pre-release\n            [-_\\.]?\n            (?P<pre_l>(a|b|c|rc|alpha|beta|pre|preview))\n            [-_\\.]?\n            (?P<pre_n>[0-9]+)?\n        )?\n        (?P<post>                                         # post release\n            (?:-(?P<post_n1>[0-9]+))\n            |\n            (?:\n                [-_\\.]?\n                (?P<post_l>post|rev|r)\n                [-_\\.]?\n                (?P<post_n2>[0-9]+)?\n            )\n        )?\n        (?P<dev>                                          # dev release\n            [-_\\.]?\n            (?P<dev_l>dev)\n            [-_\\.]?\n            (?P<dev_n>[0-9]+)?\n        )?\n    )\n    (?:\\+(?P<local>[a-z0-9]+(?:[-_\\.][a-z0-9]+)*))?       # local version\n\"\"\"\n\n\nclass Version(_BaseVersion):\n\n    _regex = re.compile(r\"^\\s*\" + VERSION_PATTERN + r\"\\s*$\", re.VERBOSE | re.IGNORECASE)\n\n    def __init__(self, version: str) -> None:\n\n        # Validate the version and parse it into pieces\n        match = self._regex.search(version)\n        if not match:\n            raise InvalidVersion(f\"Invalid version: '{version}'\")\n\n        # Store the parsed out pieces of the version\n        self._version = _Version(\n            epoch=int(match.group(\"epoch\")) if match.group(\"epoch\") else 0,\n           "}, {"start_line": 5000, "end_line": 7000, "belongs_to": {"file_name": "version.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/externals/_packaging", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": " f\"<LegacyVersion('{self}')>\"\n\n    @property\n    def public(self) -> str:\n        return self._version\n\n    @property\n    def base_version(self) -> str:\n        return self._version\n\n    @property\n    def epoch(self) -> int:\n        return -1\n\n    @property\n    def release(self) -> None:\n        return None\n\n    @property\n    def pre(self) -> None:\n        return None\n\n    @property\n    def post(self) -> None:\n        return None\n\n    @property\n    def dev(self) -> None:\n        return None\n\n    @property\n    def local(self) -> None:\n        return None\n\n    @property\n    def is_prerelease(self) -> bool:\n        return False\n\n    @property\n    def is_postrelease(self) -> bool:\n        return False\n\n    @property\n    def is_devrelease(self) -> bool:\n        return False\n\n\n_legacy_version_component_re = re.compile(r\"(\\d+ | [a-z]+ | \\.| -)\", re.VERBOSE)\n\n_legacy_version_replacement_map = {\n    \"pre\": \"c\",\n    \"preview\": \"c\",\n    \"-\": \"final-\",\n    \"rc\": \"c\",\n    \"dev\": \"@\",\n}\n\n\ndef _parse_version_parts(s: str) -> Iterator[str]:\n    for part in _legacy_version_component_re.split(s):\n        part = _legacy_version_replacement_map.get(part, part)\n\n        if not part or part == \".\":\n            continue\n\n        if part[:1] in \"0123456789\":\n            # pad for numeric comparison\n            yield part.zfill(8)\n        else:\n            yield \"*\" + part\n\n    # ensure that alpha/beta/candidate are before final\n    yield \"*final\"\n\n\ndef _legacy_cmpkey(version: str) -> LegacyCmpKey:\n\n    # We hardcode an epoch of -1 here. A PEP 440 version can only have a epoch\n    # greater than or equal to 0. This will effectively put the LegacyVersion,\n    # which uses the defacto standard originally implemented by setuptools,\n    # as before all PEP 440 versions.\n    epoch = -1\n\n    # This scheme is taken from pkg_resources.parse_version setuptools prior to\n    # it's adoption of the packaging library.\n    parts: List[str] = []\n    for part in _parse_version_parts(version.lower()):\n     "}, {"start_line": 13000, "end_line": 15000, "belongs_to": {"file_name": "version.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/externals/_packaging", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": " [\"c\", \"pre\", \"preview\"]:\n            letter = \"rc\"\n        elif letter in [\"rev\", \"r\"]:\n            letter = \"post\"\n\n        return letter, int(number)\n    if not letter and number:\n        # We assume if we are given a number, but we are not given a letter\n        # then this is using the implicit post release syntax (e.g. 1.0-1)\n        letter = \"post\"\n\n        return letter, int(number)\n\n    return None\n\n\n_local_version_separators = re.compile(r\"[\\._-]\")\n\n\ndef _parse_local_version(local: str) -> Optional[LocalType]:\n    \"\"\"\n    Takes a string like abc.1.twelve and turns it into (\"abc\", 1, \"twelve\").\n    \"\"\"\n    if local is not None:\n        return tuple(\n            part.lower() if not part.isdigit() else int(part)\n            for part in _local_version_separators.split(local)\n        )\n    return None\n\n\ndef _cmpkey(\n    epoch: int,\n    release: Tuple[int, ...],\n    pre: Optional[Tuple[str, int]],\n    post: Optional[Tuple[str, int]],\n    dev: Optional[Tuple[str, int]],\n    local: Optional[Tuple[SubLocalType]],\n) -> CmpKey:\n\n    # When we compare a release version, we want to compare it with all of the\n    # trailing zeros removed. So we'll use a reverse the list, drop all the now\n    # leading zeros until we come to something non zero, then take the rest\n    # re-reverse it back into the correct order and make it a tuple and use\n    # that for our sorting key.\n    _release = tuple(\n        reversed(list(itertools.dropwhile(lambda x: x == 0, reversed(release))))\n    )\n\n    # We need to \"trick\" the sorting algorithm to put 1.0.dev0 before 1.0a0.\n    # We'll do this by abusing the pre segment, but we _only_ want to do this\n    # if there is not a pre or a post segment. If we have one of those then\n    # the normal sorting rules will handle this case correctly.\n    if pre is None and post is None and dev is not None:\n        _pre: PrePostDevType = NegativeInfinity\n    # Versions without a pre-release (except as noted above) should sort after\n    # those with one.\n  "}, {"start_line": 8000, "end_line": 10000, "belongs_to": {"file_name": "version.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/externals/_packaging", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "?:-(?P<post_n1>[0-9]+))\n            |\n            (?:\n                [-_\\.]?\n                (?P<post_l>post|rev|r)\n                [-_\\.]?\n                (?P<post_n2>[0-9]+)?\n            )\n        )?\n        (?P<dev>                                          # dev release\n            [-_\\.]?\n            (?P<dev_l>dev)\n            [-_\\.]?\n            (?P<dev_n>[0-9]+)?\n        )?\n    )\n    (?:\\+(?P<local>[a-z0-9]+(?:[-_\\.][a-z0-9]+)*))?       # local version\n\"\"\"\n\n\nclass Version(_BaseVersion):\n\n    _regex = re.compile(r\"^\\s*\" + VERSION_PATTERN + r\"\\s*$\", re.VERBOSE | re.IGNORECASE)\n\n    def __init__(self, version: str) -> None:\n\n        # Validate the version and parse it into pieces\n        match = self._regex.search(version)\n        if not match:\n            raise InvalidVersion(f\"Invalid version: '{version}'\")\n\n        # Store the parsed out pieces of the version\n        self._version = _Version(\n            epoch=int(match.group(\"epoch\")) if match.group(\"epoch\") else 0,\n            release=tuple(int(i) for i in match.group(\"release\").split(\".\")),\n            pre=_parse_letter_version(match.group(\"pre_l\"), match.group(\"pre_n\")),\n            post=_parse_letter_version(\n                match.group(\"post_l\"), match.group(\"post_n1\") or match.group(\"post_n2\")\n            ),\n            dev=_parse_letter_version(match.group(\"dev_l\"), match.group(\"dev_n\")),\n            local=_parse_local_version(match.group(\"local\")),\n        )\n\n        # Generate a key which will be used for sorting\n        self._key = _cmpkey(\n            self._version.epoch,\n            self._version.release,\n            self._version.pre,\n            self._version.post,\n            self._version.dev,\n            self._version.local,\n        )\n\n    def __repr__(self) -> str:\n        return f\"<Version('{self}')>\"\n\n    def __str__(self) -> str:\n        parts = []\n\n        # Epoch\n        if self.epoch != 0:\n            parts.append(f\"{self.epoch}!\")\n\n        # Release segment\n        parts.append(\".\".j"}, {"start_line": 15000, "end_line": 16134, "belongs_to": {"file_name": "version.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/externals/_packaging", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "  elif pre is None:\n        _pre = Infinity\n    else:\n        _pre = pre\n\n    # Versions without a post segment should sort before those with one.\n    if post is None:\n        _post: PrePostDevType = NegativeInfinity\n\n    else:\n        _post = post\n\n    # Versions without a development segment should sort after those with one.\n    if dev is None:\n        _dev: PrePostDevType = Infinity\n\n    else:\n        _dev = dev\n\n    if local is None:\n        # Versions without a local segment should sort before those with one.\n        _local: LocalType = NegativeInfinity\n    else:\n        # Versions with a local segment need that segment parsed to implement\n        # the sorting rules in PEP440.\n        # - Alpha numeric segments sort before numeric segments\n        # - Alpha numeric segments sort lexicographically\n        # - Numeric segments sort numerically\n        # - Shorter versions sort before longer versions when the prefixes\n        #   match exactly\n        _local = tuple(\n            (i, \"\") if isinstance(i, int) else (NegativeInfinity, i) for i in local\n        )\n\n    return epoch, _release, _pre, _post, _dev, _local\n"}, {"start_line": 6000, "end_line": 8000, "belongs_to": {"file_name": "version.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/externals/_packaging", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "_version_parts(s: str) -> Iterator[str]:\n    for part in _legacy_version_component_re.split(s):\n        part = _legacy_version_replacement_map.get(part, part)\n\n        if not part or part == \".\":\n            continue\n\n        if part[:1] in \"0123456789\":\n            # pad for numeric comparison\n            yield part.zfill(8)\n        else:\n            yield \"*\" + part\n\n    # ensure that alpha/beta/candidate are before final\n    yield \"*final\"\n\n\ndef _legacy_cmpkey(version: str) -> LegacyCmpKey:\n\n    # We hardcode an epoch of -1 here. A PEP 440 version can only have a epoch\n    # greater than or equal to 0. This will effectively put the LegacyVersion,\n    # which uses the defacto standard originally implemented by setuptools,\n    # as before all PEP 440 versions.\n    epoch = -1\n\n    # This scheme is taken from pkg_resources.parse_version setuptools prior to\n    # it's adoption of the packaging library.\n    parts: List[str] = []\n    for part in _parse_version_parts(version.lower()):\n        if part.startswith(\"*\"):\n            # remove \"-\" before a prerelease tag\n            if part < \"*final\":\n                while parts and parts[-1] == \"*final-\":\n                    parts.pop()\n\n            # remove trailing zeros from each series of numeric parts\n            while parts and parts[-1] == \"00000000\":\n                parts.pop()\n\n        parts.append(part)\n\n    return epoch, tuple(parts)\n\n\n# Deliberately not anchored to the start and end of the string, to make it\n# easier for 3rd party code to reuse\nVERSION_PATTERN = r\"\"\"\n    v?\n    (?:\n        (?:(?P<epoch>[0-9]+)!)?                           # epoch\n        (?P<release>[0-9]+(?:\\.[0-9]+)*)                  # release segment\n        (?P<pre>                                          # pre-release\n            [-_\\.]?\n            (?P<pre_l>(a|b|c|rc|alpha|beta|pre|preview))\n            [-_\\.]?\n            (?P<pre_n>[0-9]+)?\n        )?\n        (?P<post>                                         # post release\n            ("}], "retrieved_count": 10, "cost_time": 1.2338221073150635}
{"question": "How does AdditiveChi2Sampler's design decouple the mathematical transformation logic from input validation and sparse/dense matrix handling to maintain separation of concerns?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"start_line": 3000, "end_line": 5000, "belongs_to": {"file_name": "test_kernel_approximation.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "rnel on random data\n\n    # compute exact kernel\n    # abbreviations for easier formula\n    X_ = X[:, np.newaxis, :].copy()\n    Y_ = Y[np.newaxis, :, :].copy()\n\n    large_kernel = 2 * X_ * Y_ / (X_ + Y_)\n\n    # reduce to n_samples_x x n_samples_y by summing over features\n    kernel = large_kernel.sum(axis=2)\n\n    # approximate kernel mapping\n    transform = AdditiveChi2Sampler(sample_steps=3)\n    X_trans = transform.fit_transform(X)\n    Y_trans = transform.transform(Y)\n\n    kernel_approx = np.dot(X_trans, Y_trans.T)\n\n    assert_array_almost_equal(kernel, kernel_approx, 1)\n\n    X_sp_trans = transform.fit_transform(csr_container(X))\n    Y_sp_trans = transform.transform(csr_container(Y))\n\n    assert_array_equal(X_trans, X_sp_trans.toarray())\n    assert_array_equal(Y_trans, Y_sp_trans.toarray())\n\n    # test error is raised on negative input\n    Y_neg = Y.copy()\n    Y_neg[0, 0] = -1\n    msg = \"Negative values in data passed to\"\n    with pytest.raises(ValueError, match=msg):\n        transform.fit(Y_neg)\n\n\n@pytest.mark.parametrize(\"method\", [\"fit\", \"fit_transform\", \"transform\"])\n@pytest.mark.parametrize(\"sample_steps\", range(1, 4))\ndef test_additive_chi2_sampler_sample_steps(method, sample_steps):\n    \"\"\"Check that the input sample step doesn't raise an error\n    and that sample interval doesn't change after fit.\n    \"\"\"\n    transformer = AdditiveChi2Sampler(sample_steps=sample_steps)\n    getattr(transformer, method)(X)\n\n    sample_interval = 0.5\n    transformer = AdditiveChi2Sampler(\n        sample_steps=sample_steps,\n        sample_interval=sample_interval,\n    )\n    getattr(transformer, method)(X)\n    assert transformer.sample_interval == sample_interval\n\n\n@pytest.mark.parametrize(\"method\", [\"fit\", \"fit_transform\", \"transform\"])\ndef test_additive_chi2_sampler_wrong_sample_steps(method):\n    \"\"\"Check that we raise a ValueError on invalid sample_steps\"\"\"\n    transformer = AdditiveChi2Sampler(sample_steps=4)\n    msg = re.escape(\n        \"If sample_steps is not in [1, 2, 3],"}, {"start_line": 20000, "end_line": 22000, "belongs_to": {"file_name": "kernel_approximation.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": " samples\n            and `n_features` is the number of features. All values of X must be\n            strictly greater than \"-skewedness\".\n\n        Returns\n        -------\n        X_new : array-like, shape (n_samples, n_components)\n            Returns the instance itself.\n        \"\"\"\n        check_is_fitted(self)\n        X = validate_data(\n            self, X, copy=True, dtype=[np.float64, np.float32], reset=False\n        )\n        if (X <= -self.skewedness).any():\n            raise ValueError(\"X may not contain entries smaller than -skewedness.\")\n\n        X += self.skewedness\n        np.log(X, X)\n        projection = safe_sparse_dot(X, self.random_weights_)\n        projection += self.random_offset_\n        np.cos(projection, projection)\n        projection *= np.sqrt(2.0) / np.sqrt(self.n_components)\n        return projection\n\n    def __sklearn_tags__(self):\n        tags = super().__sklearn_tags__()\n        tags.transformer_tags.preserves_dtype = [\"float64\", \"float32\"]\n        return tags\n\n\nclass AdditiveChi2Sampler(TransformerMixin, BaseEstimator):\n    \"\"\"Approximate feature map for additive chi2 kernel.\n\n    Uses sampling the fourier transform of the kernel characteristic\n    at regular intervals.\n\n    Since the kernel that is to be approximated is additive, the components of\n    the input vectors can be treated separately.  Each entry in the original\n    space is transformed into 2*sample_steps-1 features, where sample_steps is\n    a parameter of the method. Typical values of sample_steps include 1, 2 and\n    3.\n\n    Optimal choices for the sampling interval for certain data ranges can be\n    computed (see the reference). The default values should be reasonable.\n\n    Read more in the :ref:`User Guide <additive_chi_kernel_approx>`.\n\n    Parameters\n    ----------\n    sample_steps : int, default=2\n        Gives the number of (complex) sampling points.\n\n    sample_interval : float, default=None\n        Sampling interval. Must be specified when sample_steps not in {1,2"}, {"start_line": 22000, "end_line": 24000, "belongs_to": {"file_name": "kernel_approximation.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": ",3}.\n\n    Attributes\n    ----------\n    n_features_in_ : int\n        Number of features seen during :term:`fit`.\n\n        .. versionadded:: 0.24\n\n    feature_names_in_ : ndarray of shape (`n_features_in_`,)\n        Names of features seen during :term:`fit`. Defined only when `X`\n        has feature names that are all strings.\n\n        .. versionadded:: 1.0\n\n    See Also\n    --------\n    SkewedChi2Sampler : A Fourier-approximation to a non-additive variant of\n        the chi squared kernel.\n\n    sklearn.metrics.pairwise.chi2_kernel : The exact chi squared kernel.\n\n    sklearn.metrics.pairwise.additive_chi2_kernel : The exact additive chi\n        squared kernel.\n\n    Notes\n    -----\n    This estimator approximates a slightly different version of the additive\n    chi squared kernel then ``metric.additive_chi2`` computes.\n\n    This estimator is stateless and does not need to be fitted. However, we\n    recommend to call :meth:`fit_transform` instead of :meth:`transform`, as\n    parameter validation is only performed in :meth:`fit`.\n\n    References\n    ----------\n    See `\"Efficient additive kernels via explicit feature maps\"\n    <http://www.robots.ox.ac.uk/~vedaldi/assets/pubs/vedaldi11efficient.pdf>`_\n    A. Vedaldi and A. Zisserman, Pattern Analysis and Machine Intelligence,\n    2011\n\n    Examples\n    --------\n    >>> from sklearn.datasets import load_digits\n    >>> from sklearn.linear_model import SGDClassifier\n    >>> from sklearn.kernel_approximation import AdditiveChi2Sampler\n    >>> X, y = load_digits(return_X_y=True)\n    >>> chi2sampler = AdditiveChi2Sampler(sample_steps=2)\n    >>> X_transformed = chi2sampler.fit_transform(X, y)\n    >>> clf = SGDClassifier(max_iter=5, random_state=0, tol=1e-3)\n    >>> clf.fit(X_transformed, y)\n    SGDClassifier(max_iter=5, random_state=0)\n    >>> clf.score(X_transformed, y)\n    0.9499...\n    \"\"\"\n\n    _parameter_constraints: dict = {\n        \"sample_steps\": [Interval(Integral, 1, None, closed=\"left\")],\n        \"sample_interval\": ["}, {"start_line": 13000, "end_line": 15000, "belongs_to": {"file_name": "kernel_approximation.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "\n        n_features = X.shape[1]\n        sparse = sp.issparse(X)\n        if self.gamma == \"scale\":\n            # var = E[X^2] - E[X]^2 if sparse\n            X_var = (X.multiply(X)).mean() - (X.mean()) ** 2 if sparse else X.var()\n            self._gamma = 1.0 / (n_features * X_var) if X_var != 0 else 1.0\n        else:\n            self._gamma = self.gamma\n        self.random_weights_ = (2.0 * self._gamma) ** 0.5 * random_state.normal(\n            size=(n_features, self.n_components)\n        )\n\n        self.random_offset_ = random_state.uniform(0, 2 * np.pi, size=self.n_components)\n\n        if X.dtype == np.float32:\n            # Setting the data type of the fitted attribute will ensure the\n            # output data type during `transform`.\n            self.random_weights_ = self.random_weights_.astype(X.dtype, copy=False)\n            self.random_offset_ = self.random_offset_.astype(X.dtype, copy=False)\n\n        self._n_features_out = self.n_components\n        return self\n\n    def transform(self, X):\n        \"\"\"Apply the approximate feature map to X.\n\n        Parameters\n        ----------\n        X : {array-like, sparse matrix}, shape (n_samples, n_features)\n            New data, where `n_samples` is the number of samples\n            and `n_features` is the number of features.\n\n        Returns\n        -------\n        X_new : array-like, shape (n_samples, n_components)\n            Returns the instance itself.\n        \"\"\"\n        check_is_fitted(self)\n\n        X = validate_data(self, X, accept_sparse=\"csr\", reset=False)\n        projection = safe_sparse_dot(X, self.random_weights_)\n        projection += self.random_offset_\n        np.cos(projection, projection)\n        projection *= (2.0 / self.n_components) ** 0.5\n        return projection\n\n    def __sklearn_tags__(self):\n        tags = super().__sklearn_tags__()\n        tags.input_tags.sparse = True\n        tags.transformer_tags.preserves_dtype = [\"float64\", \"float32\"]\n        return tags\n\n\nclass SkewedChi2Sampler(\n    "}, {"start_line": 4000, "end_line": 6000, "belongs_to": {"file_name": "test_kernel_approximation.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": ".fit(Y_neg)\n\n\n@pytest.mark.parametrize(\"method\", [\"fit\", \"fit_transform\", \"transform\"])\n@pytest.mark.parametrize(\"sample_steps\", range(1, 4))\ndef test_additive_chi2_sampler_sample_steps(method, sample_steps):\n    \"\"\"Check that the input sample step doesn't raise an error\n    and that sample interval doesn't change after fit.\n    \"\"\"\n    transformer = AdditiveChi2Sampler(sample_steps=sample_steps)\n    getattr(transformer, method)(X)\n\n    sample_interval = 0.5\n    transformer = AdditiveChi2Sampler(\n        sample_steps=sample_steps,\n        sample_interval=sample_interval,\n    )\n    getattr(transformer, method)(X)\n    assert transformer.sample_interval == sample_interval\n\n\n@pytest.mark.parametrize(\"method\", [\"fit\", \"fit_transform\", \"transform\"])\ndef test_additive_chi2_sampler_wrong_sample_steps(method):\n    \"\"\"Check that we raise a ValueError on invalid sample_steps\"\"\"\n    transformer = AdditiveChi2Sampler(sample_steps=4)\n    msg = re.escape(\n        \"If sample_steps is not in [1, 2, 3], you need to provide sample_interval\"\n    )\n    with pytest.raises(ValueError, match=msg):\n        getattr(transformer, method)(X)\n\n\ndef test_skewed_chi2_sampler():\n    # test that RBFSampler approximates kernel on random data\n\n    # compute exact kernel\n    c = 0.03\n    # set on negative component but greater than c to ensure that the kernel\n    # approximation is valid on the group (-c; +\\infty) endowed with the skewed\n    # multiplication.\n    Y_ = Y.copy()\n    Y_[0, 0] = -c / 2.0\n\n    # abbreviations for easier formula\n    X_c = (X + c)[:, np.newaxis, :]\n    Y_c = (Y_ + c)[np.newaxis, :, :]\n\n    # we do it in log-space in the hope that it's more stable\n    # this array is n_samples_x x n_samples_y big x n_features\n    log_kernel = (\n        (np.log(X_c) / 2.0) + (np.log(Y_c) / 2.0) + np.log(2.0) - np.log(X_c + Y_c)\n    )\n    # reduce to n_samples_x x n_samples_y by summing over features in log-space\n    kernel = np.exp(log_kernel.sum(axis=2))\n\n    # approximate kernel mapping\n    t"}, {"start_line": 2000, "end_line": 4000, "belongs_to": {"file_name": "test_kernel_approximation.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "ametrize(\"degree\", [1, 2, 3])\n@pytest.mark.parametrize(\"coef0\", [0, 2.5])\ndef test_polynomial_count_sketch_dense_sparse(gamma, degree, coef0, csr_container):\n    \"\"\"Check that PolynomialCountSketch results are the same for dense and sparse\n    input.\n    \"\"\"\n    ps_dense = PolynomialCountSketch(\n        n_components=500, gamma=gamma, degree=degree, coef0=coef0, random_state=42\n    )\n    Xt_dense = ps_dense.fit_transform(X)\n    Yt_dense = ps_dense.transform(Y)\n\n    ps_sparse = PolynomialCountSketch(\n        n_components=500, gamma=gamma, degree=degree, coef0=coef0, random_state=42\n    )\n    Xt_sparse = ps_sparse.fit_transform(csr_container(X))\n    Yt_sparse = ps_sparse.transform(csr_container(Y))\n\n    assert_allclose(Xt_dense, Xt_sparse)\n    assert_allclose(Yt_dense, Yt_sparse)\n\n\ndef _linear_kernel(X, Y):\n    return np.dot(X, Y.T)\n\n\n@pytest.mark.parametrize(\"csr_container\", CSR_CONTAINERS)\ndef test_additive_chi2_sampler(csr_container):\n    # test that AdditiveChi2Sampler approximates kernel on random data\n\n    # compute exact kernel\n    # abbreviations for easier formula\n    X_ = X[:, np.newaxis, :].copy()\n    Y_ = Y[np.newaxis, :, :].copy()\n\n    large_kernel = 2 * X_ * Y_ / (X_ + Y_)\n\n    # reduce to n_samples_x x n_samples_y by summing over features\n    kernel = large_kernel.sum(axis=2)\n\n    # approximate kernel mapping\n    transform = AdditiveChi2Sampler(sample_steps=3)\n    X_trans = transform.fit_transform(X)\n    Y_trans = transform.transform(Y)\n\n    kernel_approx = np.dot(X_trans, Y_trans.T)\n\n    assert_array_almost_equal(kernel, kernel_approx, 1)\n\n    X_sp_trans = transform.fit_transform(csr_container(X))\n    Y_sp_trans = transform.transform(csr_container(Y))\n\n    assert_array_equal(X_trans, X_sp_trans.toarray())\n    assert_array_equal(Y_trans, Y_sp_trans.toarray())\n\n    # test error is raised on negative input\n    Y_neg = Y.copy()\n    Y_neg[0, 0] = -1\n    msg = \"Negative values in data passed to\"\n    with pytest.raises(ValueError, match=msg):\n        transform"}, {"start_line": 21000, "end_line": 23000, "belongs_to": {"file_name": "kernel_approximation.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "gs\n\n\nclass AdditiveChi2Sampler(TransformerMixin, BaseEstimator):\n    \"\"\"Approximate feature map for additive chi2 kernel.\n\n    Uses sampling the fourier transform of the kernel characteristic\n    at regular intervals.\n\n    Since the kernel that is to be approximated is additive, the components of\n    the input vectors can be treated separately.  Each entry in the original\n    space is transformed into 2*sample_steps-1 features, where sample_steps is\n    a parameter of the method. Typical values of sample_steps include 1, 2 and\n    3.\n\n    Optimal choices for the sampling interval for certain data ranges can be\n    computed (see the reference). The default values should be reasonable.\n\n    Read more in the :ref:`User Guide <additive_chi_kernel_approx>`.\n\n    Parameters\n    ----------\n    sample_steps : int, default=2\n        Gives the number of (complex) sampling points.\n\n    sample_interval : float, default=None\n        Sampling interval. Must be specified when sample_steps not in {1,2,3}.\n\n    Attributes\n    ----------\n    n_features_in_ : int\n        Number of features seen during :term:`fit`.\n\n        .. versionadded:: 0.24\n\n    feature_names_in_ : ndarray of shape (`n_features_in_`,)\n        Names of features seen during :term:`fit`. Defined only when `X`\n        has feature names that are all strings.\n\n        .. versionadded:: 1.0\n\n    See Also\n    --------\n    SkewedChi2Sampler : A Fourier-approximation to a non-additive variant of\n        the chi squared kernel.\n\n    sklearn.metrics.pairwise.chi2_kernel : The exact chi squared kernel.\n\n    sklearn.metrics.pairwise.additive_chi2_kernel : The exact additive chi\n        squared kernel.\n\n    Notes\n    -----\n    This estimator approximates a slightly different version of the additive\n    chi squared kernel then ``metric.additive_chi2`` computes.\n\n    This estimator is stateless and does not need to be fitted. However, we\n    recommend to call :meth:`fit_transform` instead of :meth:`transform`, as\n    parameter va"}, {"start_line": 25000, "end_line": 27000, "belongs_to": {"file_name": "kernel_approximation.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "a(self, X, accept_sparse=\"csr\", ensure_non_negative=True)\n\n        if self.sample_interval is None and self.sample_steps not in (1, 2, 3):\n            raise ValueError(\n                \"If sample_steps is not in [1, 2, 3],\"\n                \" you need to provide sample_interval\"\n            )\n\n        return self\n\n    def transform(self, X):\n        \"\"\"Apply approximate feature map to X.\n\n        Parameters\n        ----------\n        X : {array-like, sparse matrix}, shape (n_samples, n_features)\n            Training data, where `n_samples` is the number of samples\n            and `n_features` is the number of features.\n\n        Returns\n        -------\n        X_new : {ndarray, sparse matrix}, \\\n               shape = (n_samples, n_features * (2*sample_steps - 1))\n            Whether the return value is an array or sparse matrix depends on\n            the type of the input X.\n        \"\"\"\n        X = validate_data(\n            self, X, accept_sparse=\"csr\", reset=False, ensure_non_negative=True\n        )\n        sparse = sp.issparse(X)\n\n        if self.sample_interval is None:\n            # See figure 2 c) of \"Efficient additive kernels via explicit feature maps\"\n            # <http://www.robots.ox.ac.uk/~vedaldi/assets/pubs/vedaldi11efficient.pdf>\n            # A. Vedaldi and A. Zisserman, Pattern Analysis and Machine Intelligence,\n            # 2011\n            if self.sample_steps == 1:\n                sample_interval = 0.8\n            elif self.sample_steps == 2:\n                sample_interval = 0.5\n            elif self.sample_steps == 3:\n                sample_interval = 0.4\n            else:\n                raise ValueError(\n                    \"If sample_steps is not in [1, 2, 3],\"\n                    \" you need to provide sample_interval\"\n                )\n        else:\n            sample_interval = self.sample_interval\n\n        # zeroth component\n        # 1/cosh = sech\n        # cosh(0) = 1.0\n        transf = self._transform_sparse if sparse else self._trans"}, {"start_line": 9000, "end_line": 11000, "belongs_to": {"file_name": "test_kernel_approximation.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "of X.\"\"\"\n    skewed_chi2_sampler = SkewedChi2Sampler()\n\n    X = np.array([[1, 2], [3, 4], [5, 6]], dtype=global_dtype)\n\n    skewed_chi2_sampler.fit(X)\n\n    assert skewed_chi2_sampler.random_offset_.dtype == global_dtype\n    assert skewed_chi2_sampler.random_weights_.dtype == global_dtype\n\n\ndef test_skewed_chi2_sampler_dtype_equivalence():\n    \"\"\"Check the equivalence of the results with 32 and 64 bits input.\"\"\"\n    skewed_chi2_sampler_32 = SkewedChi2Sampler(random_state=42)\n    X_32 = np.array([[1, 2], [3, 4], [5, 6]], dtype=np.float32)\n    skewed_chi2_sampler_32.fit(X_32)\n\n    skewed_chi2_sampler_64 = SkewedChi2Sampler(random_state=42)\n    X_64 = np.array([[1, 2], [3, 4], [5, 6]], dtype=np.float64)\n    skewed_chi2_sampler_64.fit(X_64)\n\n    assert_allclose(\n        skewed_chi2_sampler_32.random_offset_, skewed_chi2_sampler_64.random_offset_\n    )\n    assert_allclose(\n        skewed_chi2_sampler_32.random_weights_, skewed_chi2_sampler_64.random_weights_\n    )\n\n\n@pytest.mark.parametrize(\"csr_container\", CSR_CONTAINERS)\ndef test_input_validation(csr_container):\n    # Regression test: kernel approx. transformers should work on lists\n    # No assertions; the old versions would simply crash\n    X = [[1, 2], [3, 4], [5, 6]]\n    AdditiveChi2Sampler().fit(X).transform(X)\n    SkewedChi2Sampler().fit(X).transform(X)\n    RBFSampler().fit(X).transform(X)\n\n    X = csr_container(X)\n    RBFSampler().fit(X).transform(X)\n\n\ndef test_nystroem_approximation():\n    # some basic tests\n    rnd = np.random.RandomState(0)\n    X = rnd.uniform(size=(10, 4))\n\n    # With n_components = n_samples this is exact\n    X_transformed = Nystroem(n_components=X.shape[0]).fit_transform(X)\n    K = rbf_kernel(X)\n    assert_array_almost_equal(np.dot(X_transformed, X_transformed.T), K)\n\n    trans = Nystroem(n_components=2, random_state=rnd)\n    X_transformed = trans.fit(X).transform(X)\n    assert X_transformed.shape == (X.shape[0], 2)\n\n    # test callable kernel\n    trans = Nystroem(n_components=2, kernel=_li"}, {"start_line": 101000, "end_line": 103000, "belongs_to": {"file_name": "_data.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/preprocessing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": " mapping to\n                    # infinity. Clip such that the inverse transform will be\n                    # consistent\n                    clip_min = stats.norm.ppf(BOUNDS_THRESHOLD - np.spacing(1))\n                    clip_max = stats.norm.ppf(1 - (BOUNDS_THRESHOLD - np.spacing(1)))\n                    X_col = np.clip(X_col, clip_min, clip_max)\n                # else output distribution is uniform and the ppf is the\n                # identity function so we let X_col unchanged\n\n        return X_col\n\n    def _check_inputs(self, X, in_fit, accept_sparse_negative=False, copy=False):\n        \"\"\"Check inputs before fit and transform.\"\"\"\n        X = validate_data(\n            self,\n            X,\n            reset=in_fit,\n            accept_sparse=\"csc\",\n            copy=copy,\n            dtype=FLOAT_DTYPES,\n            # only set force_writeable for the validation at transform time because\n            # it's the only place where QuantileTransformer performs inplace operations.\n            force_writeable=True if not in_fit else None,\n            ensure_all_finite=\"allow-nan\",\n        )\n        # we only accept positive sparse matrix when ignore_implicit_zeros is\n        # false and that we call fit or transform.\n        with np.errstate(invalid=\"ignore\"):  # hide NaN comparison warnings\n            if (\n                not accept_sparse_negative\n                and not self.ignore_implicit_zeros\n                and (sparse.issparse(X) and np.any(X.data < 0))\n            ):\n                raise ValueError(\n                    \"QuantileTransformer only accepts non-negative sparse matrices.\"\n                )\n\n        return X\n\n    def _transform(self, X, inverse=False):\n        \"\"\"Forward and inverse transform.\n\n        Parameters\n        ----------\n        X : ndarray of shape (n_samples, n_features)\n            The data used to scale along the features axis.\n\n        inverse : bool, default=False\n            If False, apply forward transform. If True, apply\n        "}], "retrieved_count": 10, "cost_time": 1.2682788372039795}
{"question": "Why does BaseShuffleSplit delegate the actual index generation logic to the _iter_indices method rather than implementing it directly within the split method, and what design constraints does this separation impose on subclass implementations?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"start_line": 66000, "end_line": 68000, "belongs_to": {"file_name": "_split.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/model_selection", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "variable for supervised learning problems.\n            Stratification is done based on the y labels.\n\n        groups : object\n            Always ignored, exists for compatibility.\n\n        Yields\n        ------\n        train : ndarray\n            The training set indices for that split.\n\n        test : ndarray\n            The testing set indices for that split.\n\n        Notes\n        -----\n        Randomized CV splitters may return different results for each call of\n        split. You can make the results identical by setting `random_state`\n        to an integer.\n        \"\"\"\n        y = check_array(y, input_name=\"y\", ensure_2d=False, dtype=None)\n        return super().split(X, y, groups=groups)\n\n\nclass BaseShuffleSplit(_MetadataRequester, metaclass=ABCMeta):\n    \"\"\"Base class for *ShuffleSplit.\n\n    Parameters\n    ----------\n    n_splits : int, default=10\n        Number of re-shuffling & splitting iterations.\n\n    test_size : float or int, default=None\n        If float, should be between 0.0 and 1.0 and represent the proportion\n        of the dataset to include in the test split. If int, represents the\n        absolute number of test samples. If None, the value is set to the\n        complement of the train size. If ``train_size`` is also None, it will\n        be set to 0.1.\n\n    train_size : float or int, default=None\n        If float, should be between 0.0 and 1.0 and represent the\n        proportion of the dataset to include in the train split. If\n        int, represents the absolute number of train samples. If None,\n        the value is automatically set to the complement of the test size.\n\n    random_state : int, RandomState instance or None, default=None\n        Controls the randomness of the training and testing indices produced.\n        Pass an int for reproducible output across multiple function calls.\n        See :term:`Glossary <random_state>`.\n    \"\"\"\n\n    # This indicates that by default CV splitters don't have a \"groups\" kwarg,\n    # unless indicated by"}, {"start_line": 69000, "end_line": 71000, "belongs_to": {"file_name": "_split.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/model_selection", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "pe (n_samples,), default=None\n            Group labels for the samples used while splitting the dataset into\n            train/test set.\n\n        Yields\n        ------\n        train : ndarray\n            The training set indices for that split.\n\n        test : ndarray\n            The testing set indices for that split.\n\n        Notes\n        -----\n        Randomized CV splitters may return different results for each call of\n        split. You can make the results identical by setting `random_state`\n        to an integer.\n        \"\"\"\n        X, y, groups = indexable(X, y, groups)\n        for train, test in self._iter_indices(X, y, groups):\n            yield train, test\n\n    def _iter_indices(self, X, y=None, groups=None):\n        \"\"\"Generate (train, test) indices\"\"\"\n        n_samples = _num_samples(X)\n        n_train, n_test = _validate_shuffle_split(\n            n_samples,\n            self.test_size,\n            self.train_size,\n            default_test_size=self._default_test_size,\n        )\n\n        rng = check_random_state(self.random_state)\n        for i in range(self.n_splits):\n            # random partition\n            permutation = rng.permutation(n_samples)\n            ind_test = permutation[:n_test]\n            ind_train = permutation[n_test : (n_test + n_train)]\n            yield ind_train, ind_test\n\n    def get_n_splits(self, X=None, y=None, groups=None):\n        \"\"\"Returns the number of splitting iterations in the cross-validator.\n\n        Parameters\n        ----------\n        X : object\n            Always ignored, exists for compatibility.\n\n        y : object\n            Always ignored, exists for compatibility.\n\n        groups : object\n            Always ignored, exists for compatibility.\n\n        Returns\n        -------\n        n_splits : int\n            Returns the number of splitting iterations in the cross-validator.\n        \"\"\"\n        return self.n_splits\n\n    def __repr__(self):\n        return _build_repr(self)\n\n\nclass ShuffleSplit(_UnsupportedG"}, {"start_line": 79000, "end_line": 81000, "belongs_to": {"file_name": "_split.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/model_selection", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "array(groups, input_name=\"groups\", ensure_2d=False, dtype=None)\n        classes, group_indices = np.unique(groups, return_inverse=True)\n        for group_train, group_test in super()._iter_indices(X=classes):\n            # these are the indices of classes in the partition\n            # invert them into data indices\n\n            train = np.flatnonzero(np.isin(group_indices, group_train))\n            test = np.flatnonzero(np.isin(group_indices, group_test))\n\n            yield train, test\n\n    def split(self, X, y=None, groups=None):\n        \"\"\"Generate indices to split data into training and test set.\n\n        Parameters\n        ----------\n        X : array-like of shape (n_samples, n_features)\n            Training data, where `n_samples` is the number of samples\n            and `n_features` is the number of features.\n\n        y : array-like of shape (n_samples,), default=None\n            The target variable for supervised learning problems.\n\n        groups : array-like of shape (n_samples,)\n            Group labels for the samples used while splitting the dataset into\n            train/test set.\n\n        Yields\n        ------\n        train : ndarray\n            The training set indices for that split.\n\n        test : ndarray\n            The testing set indices for that split.\n\n        Notes\n        -----\n        Randomized CV splitters may return different results for each call of\n        split. You can make the results identical by setting `random_state`\n        to an integer.\n        \"\"\"\n        return super().split(X, y, groups)\n\n\nclass StratifiedShuffleSplit(BaseShuffleSplit):\n    \"\"\"Class-wise stratified ShuffleSplit cross-validator.\n\n    Provides train/test indices to split data in train/test sets.\n\n    This cross-validation object is a merge of :class:`StratifiedKFold` and\n    :class:`ShuffleSplit`, which returns stratified randomized folds. The folds\n    are made by preserving the percentage of samples for each class in `y` in a\n    binary or multiclass class"}, {"start_line": 68000, "end_line": 70000, "belongs_to": {"file_name": "_split.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/model_selection", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": " inheriting from ``GroupsConsumerMixin``.\n    # This also prevents ``set_split_request`` to be generated for splitters\n    # which don't support ``groups``.\n    __metadata_request__split = {\"groups\": metadata_routing.UNUSED}\n\n    def __init__(\n        self, n_splits=10, *, test_size=None, train_size=None, random_state=None\n    ):\n        self.n_splits = n_splits\n        self.test_size = test_size\n        self.train_size = train_size\n        self.random_state = random_state\n        self._default_test_size = 0.1\n\n    def split(self, X, y=None, groups=None):\n        \"\"\"Generate indices to split data into training and test set.\n\n        Parameters\n        ----------\n        X : array-like of shape (n_samples, n_features)\n            Training data, where `n_samples` is the number of samples\n            and `n_features` is the number of features.\n\n        y : array-like of shape (n_samples,)\n            The target variable for supervised learning problems.\n\n        groups : array-like of shape (n_samples,), default=None\n            Group labels for the samples used while splitting the dataset into\n            train/test set.\n\n        Yields\n        ------\n        train : ndarray\n            The training set indices for that split.\n\n        test : ndarray\n            The testing set indices for that split.\n\n        Notes\n        -----\n        Randomized CV splitters may return different results for each call of\n        split. You can make the results identical by setting `random_state`\n        to an integer.\n        \"\"\"\n        X, y, groups = indexable(X, y, groups)\n        for train, test in self._iter_indices(X, y, groups):\n            yield train, test\n\n    def _iter_indices(self, X, y=None, groups=None):\n        \"\"\"Generate (train, test) indices\"\"\"\n        n_samples = _num_samples(X)\n        n_train, n_test = _validate_shuffle_split(\n            n_samples,\n            self.test_size,\n            self.train_size,\n            default_test_size=self._default_test_size,\n  "}, {"start_line": 65000, "end_line": 67000, "belongs_to": {"file_name": "_split.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/model_selection", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": " make the results identical by setting `random_state`\n    to an integer.\n\n    See Also\n    --------\n    RepeatedKFold : Repeats K-Fold n times.\n    \"\"\"\n\n    def __init__(self, *, n_splits=5, n_repeats=10, random_state=None):\n        super().__init__(\n            StratifiedKFold,\n            n_repeats=n_repeats,\n            random_state=random_state,\n            n_splits=n_splits,\n        )\n\n    def split(self, X, y, groups=None):\n        \"\"\"Generate indices to split data into training and test set.\n\n        Parameters\n        ----------\n        X : array-like of shape (n_samples, n_features)\n            Training data, where `n_samples` is the number of samples\n            and `n_features` is the number of features.\n\n            Note that providing ``y`` is sufficient to generate the splits and\n            hence ``np.zeros(n_samples)`` may be used as a placeholder for\n            ``X`` instead of actual training data.\n\n        y : array-like of shape (n_samples,)\n            The target variable for supervised learning problems.\n            Stratification is done based on the y labels.\n\n        groups : object\n            Always ignored, exists for compatibility.\n\n        Yields\n        ------\n        train : ndarray\n            The training set indices for that split.\n\n        test : ndarray\n            The testing set indices for that split.\n\n        Notes\n        -----\n        Randomized CV splitters may return different results for each call of\n        split. You can make the results identical by setting `random_state`\n        to an integer.\n        \"\"\"\n        y = check_array(y, input_name=\"y\", ensure_2d=False, dtype=None)\n        return super().split(X, y, groups=groups)\n\n\nclass BaseShuffleSplit(_MetadataRequester, metaclass=ABCMeta):\n    \"\"\"Base class for *ShuffleSplit.\n\n    Parameters\n    ----------\n    n_splits : int, default=10\n        Number of re-shuffling & splitting iterations.\n\n    test_size : float or int, default=None\n        If float, should be betwe"}, {"start_line": 12000, "end_line": 14000, "belongs_to": {"file_name": "_split.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/model_selection", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "True.\"\n                ),\n            )\n\n        self.n_splits = n_splits\n        self.shuffle = shuffle\n        self.random_state = random_state\n\n    def split(self, X, y=None, groups=None):\n        \"\"\"Generate indices to split data into training and test set.\n\n        Parameters\n        ----------\n        X : array-like of shape (n_samples, n_features)\n            Training data, where `n_samples` is the number of samples\n            and `n_features` is the number of features.\n\n        y : array-like of shape (n_samples,), default=None\n            The target variable for supervised learning problems.\n\n        groups : array-like of shape (n_samples,), default=None\n            Group labels for the samples used while splitting the dataset into\n            train/test set.\n\n        Yields\n        ------\n        train : ndarray\n            The training set indices for that split.\n\n        test : ndarray\n            The testing set indices for that split.\n        \"\"\"\n        X, y, groups = indexable(X, y, groups)\n        n_samples = _num_samples(X)\n        if self.n_splits > n_samples:\n            raise ValueError(\n                (\n                    \"Cannot have number of splits n_splits={0} greater\"\n                    \" than the number of samples: n_samples={1}.\"\n                ).format(self.n_splits, n_samples)\n            )\n\n        for train, test in super().split(X, y, groups):\n            yield train, test\n\n    def get_n_splits(self, X=None, y=None, groups=None):\n        \"\"\"Returns the number of splitting iterations in the cross-validator.\n\n        Parameters\n        ----------\n        X : object\n            Always ignored, exists for compatibility.\n\n        y : object\n            Always ignored, exists for compatibility.\n\n        groups : object\n            Always ignored, exists for compatibility.\n\n        Returns\n        -------\n        n_splits : int\n            Returns the number of splitting iterations in the cross-validator.\n        \"\"\"\n        return s"}, {"start_line": 29000, "end_line": 31000, "belongs_to": {"file_name": "_split.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/model_selection", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "thin\n        # the stratification constraint, we assign samples from each class in\n        # blocks (and then mess that up when shuffle=True).\n        test_folds = np.empty(len(y), dtype=\"i\")\n        for k in range(n_classes):\n            # since the kth column of allocation stores the number of samples\n            # of class k in each test set, this generates blocks of fold\n            # indices corresponding to the allocation for class k.\n            folds_for_class = np.arange(self.n_splits).repeat(allocation[:, k])\n            if self.shuffle:\n                rng.shuffle(folds_for_class)\n            test_folds[y_encoded == k] = folds_for_class\n        return test_folds\n\n    def _iter_test_masks(self, X, y=None, groups=None):\n        test_folds = self._make_test_folds(X, y)\n        for i in range(self.n_splits):\n            yield test_folds == i\n\n    def split(self, X, y, groups=None):\n        \"\"\"Generate indices to split data into training and test set.\n\n        Parameters\n        ----------\n        X : array-like of shape (n_samples, n_features)\n            Training data, where `n_samples` is the number of samples\n            and `n_features` is the number of features.\n\n            Note that providing ``y`` is sufficient to generate the splits and\n            hence ``np.zeros(n_samples)`` may be used as a placeholder for\n            ``X`` instead of actual training data.\n\n        y : array-like of shape (n_samples,)\n            The target variable for supervised learning problems.\n            Stratification is done based on the y labels.\n\n        groups : object\n            Always ignored, exists for compatibility.\n\n        Yields\n        ------\n        train : ndarray\n            The training set indices for that split.\n\n        test : ndarray\n            The testing set indices for that split.\n\n        Notes\n        -----\n        Randomized CV splitters may return different results for each call of\n        split. You can make the results identical by setting "}, {"start_line": 11000, "end_line": 13000, "belongs_to": {"file_name": "_split.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/model_selection", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "shuffle, random_state):\n        if not isinstance(n_splits, numbers.Integral):\n            raise ValueError(\n                \"The number of folds must be of Integral type. \"\n                \"%s of type %s was passed.\" % (n_splits, type(n_splits))\n            )\n        n_splits = int(n_splits)\n\n        if n_splits <= 1:\n            raise ValueError(\n                \"k-fold cross-validation requires at least one\"\n                \" train/test split by setting n_splits=2 or more,\"\n                \" got n_splits={0}.\".format(n_splits)\n            )\n\n        if not isinstance(shuffle, bool):\n            raise TypeError(\"shuffle must be True or False; got {0}\".format(shuffle))\n\n        if not shuffle and random_state is not None:  # None is the default\n            raise ValueError(\n                (\n                    \"Setting a random_state has no effect since shuffle is \"\n                    \"False. You should leave \"\n                    \"random_state to its default (None), or set shuffle=True.\"\n                ),\n            )\n\n        self.n_splits = n_splits\n        self.shuffle = shuffle\n        self.random_state = random_state\n\n    def split(self, X, y=None, groups=None):\n        \"\"\"Generate indices to split data into training and test set.\n\n        Parameters\n        ----------\n        X : array-like of shape (n_samples, n_features)\n            Training data, where `n_samples` is the number of samples\n            and `n_features` is the number of features.\n\n        y : array-like of shape (n_samples,), default=None\n            The target variable for supervised learning problems.\n\n        groups : array-like of shape (n_samples,), default=None\n            Group labels for the samples used while splitting the dataset into\n            train/test set.\n\n        Yields\n        ------\n        train : ndarray\n            The training set indices for that split.\n\n        test : ndarray\n            The testing set indices for that split.\n        \"\"\"\n        X, y, groups = "}, {"start_line": 28000, "end_line": 30000, "belongs_to": {"file_name": "_split.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/model_selection", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "    if np.all(self.n_splits > y_counts):\n            raise ValueError(\n                \"n_splits=%d cannot be greater than the\"\n                \" number of members in each class.\" % (self.n_splits)\n            )\n        if self.n_splits > min_groups:\n            warnings.warn(\n                \"The least populated class in y has only %d\"\n                \" members, which is less than n_splits=%d.\"\n                % (min_groups, self.n_splits),\n                UserWarning,\n            )\n\n        # Determine the optimal number of samples from each class in each fold,\n        # using round robin over the sorted y. (This can be done direct from\n        # counts, but that code is unreadable.)\n        y_order = np.sort(y_encoded)\n        allocation = np.asarray(\n            [\n                np.bincount(y_order[i :: self.n_splits], minlength=n_classes)\n                for i in range(self.n_splits)\n            ]\n        )\n\n        # To maintain the data order dependencies as best as possible within\n        # the stratification constraint, we assign samples from each class in\n        # blocks (and then mess that up when shuffle=True).\n        test_folds = np.empty(len(y), dtype=\"i\")\n        for k in range(n_classes):\n            # since the kth column of allocation stores the number of samples\n            # of class k in each test set, this generates blocks of fold\n            # indices corresponding to the allocation for class k.\n            folds_for_class = np.arange(self.n_splits).repeat(allocation[:, k])\n            if self.shuffle:\n                rng.shuffle(folds_for_class)\n            test_folds[y_encoded == k] = folds_for_class\n        return test_folds\n\n    def _iter_test_masks(self, X, y=None, groups=None):\n        test_folds = self._make_test_folds(X, y)\n        for i in range(self.n_splits):\n            yield test_folds == i\n\n    def split(self, X, y, groups=None):\n        \"\"\"Generate indices to split data into training and test set.\n\n        Parameters\n        "}, {"start_line": 3000, "end_line": 5000, "belongs_to": {"file_name": "_split.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/model_selection", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "V splitters don't have a \"groups\" kwarg,\n    # unless indicated by inheriting from ``GroupsConsumerMixin``.\n    # This also prevents ``set_split_request`` to be generated for splitters\n    # which don't support ``groups``.\n    __metadata_request__split = {\"groups\": metadata_routing.UNUSED}\n\n    def split(self, X, y=None, groups=None):\n        \"\"\"Generate indices to split data into training and test set.\n\n        Parameters\n        ----------\n        X : array-like of shape (n_samples, n_features)\n            Training data, where `n_samples` is the number of samples\n            and `n_features` is the number of features.\n\n        y : array-like of shape (n_samples,)\n            The target variable for supervised learning problems.\n\n        groups : array-like of shape (n_samples,), default=None\n            Group labels for the samples used while splitting the dataset into\n            train/test set.\n\n        Yields\n        ------\n        train : ndarray\n            The training set indices for that split.\n\n        test : ndarray\n            The testing set indices for that split.\n        \"\"\"\n        X, y, groups = indexable(X, y, groups)\n        indices = np.arange(_num_samples(X))\n        for test_index in self._iter_test_masks(X, y, groups):\n            train_index = indices[np.logical_not(test_index)]\n            test_index = indices[test_index]\n            yield train_index, test_index\n\n    # Since subclasses must implement either _iter_test_masks or\n    # _iter_test_indices, neither can be abstract.\n    def _iter_test_masks(self, X=None, y=None, groups=None):\n        \"\"\"Generates boolean masks corresponding to test sets.\n\n        By default, delegates to _iter_test_indices(X, y, groups)\n        \"\"\"\n        for test_index in self._iter_test_indices(X, y, groups):\n            test_mask = np.zeros(_num_samples(X), dtype=bool)\n            test_mask[test_index] = True\n            yield test_mask\n\n    def _iter_test_indices(self, X=None, y=None, groups=None):\n        "}], "retrieved_count": 10, "cost_time": 1.256932258605957}
{"question": "Why does the exception handling mechanism in OpenMLError impact the performance of HTTP error recovery operations when processing large-scale dataset downloads with retry logic?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"start_line": 5000, "end_line": 7000, "belongs_to": {"file_name": "_openml.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/datasets", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "zip_encoded(fsrc):\n            return gzip.GzipFile(fileobj=fsrc, mode=\"rb\")\n        return fsrc\n\n    openml_path = urlparse(url).path.lstrip(\"/\")\n    local_path = _get_local_path(openml_path, data_home)\n    dir_name, file_name = os.path.split(local_path)\n    if not os.path.exists(local_path):\n        os.makedirs(dir_name, exist_ok=True)\n        try:\n            # Create a tmpdir as a subfolder of dir_name where the final file will\n            # be moved to if the download is successful. This guarantees that the\n            # renaming operation to the final location is atomic to ensure the\n            # concurrence safety of the dataset caching mechanism.\n            with TemporaryDirectory(dir=dir_name) as tmpdir:\n                with closing(\n                    _retry_on_network_error(n_retries, delay, req.full_url)(urlopen)(\n                        req\n                    )\n                ) as fsrc:\n                    opener: Callable\n                    if is_gzip_encoded(fsrc):\n                        opener = open\n                    else:\n                        opener = gzip.GzipFile\n                    with opener(os.path.join(tmpdir, file_name), \"wb\") as fdst:\n                        shutil.copyfileobj(fsrc, fdst)\n                shutil.move(fdst.name, local_path)\n        except Exception:\n            if os.path.exists(local_path):\n                os.unlink(local_path)\n            raise\n\n    # XXX: First time, decompression will not be necessary (by using fsrc), but\n    # it will happen nonetheless\n    return gzip.GzipFile(local_path, \"rb\")\n\n\nclass OpenMLError(ValueError):\n    \"\"\"HTTP 412 is a specific OpenML error code, indicating a generic error\"\"\"\n\n    pass\n\n\ndef _get_json_content_from_openml_api(\n    url: str,\n    error_message: Optional[str],\n    data_home: Optional[str],\n    n_retries: int = 3,\n    delay: float = 1.0,\n) -> Dict:\n    \"\"\"\n    Loads json data from the openml api.\n\n    Parameters\n    ----------\n    url : str\n        The URL to load fr"}, {"start_line": 6000, "end_line": 8000, "belongs_to": {"file_name": "_openml.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/datasets", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "\n                        opener = open\n                    else:\n                        opener = gzip.GzipFile\n                    with opener(os.path.join(tmpdir, file_name), \"wb\") as fdst:\n                        shutil.copyfileobj(fsrc, fdst)\n                shutil.move(fdst.name, local_path)\n        except Exception:\n            if os.path.exists(local_path):\n                os.unlink(local_path)\n            raise\n\n    # XXX: First time, decompression will not be necessary (by using fsrc), but\n    # it will happen nonetheless\n    return gzip.GzipFile(local_path, \"rb\")\n\n\nclass OpenMLError(ValueError):\n    \"\"\"HTTP 412 is a specific OpenML error code, indicating a generic error\"\"\"\n\n    pass\n\n\ndef _get_json_content_from_openml_api(\n    url: str,\n    error_message: Optional[str],\n    data_home: Optional[str],\n    n_retries: int = 3,\n    delay: float = 1.0,\n) -> Dict:\n    \"\"\"\n    Loads json data from the openml api.\n\n    Parameters\n    ----------\n    url : str\n        The URL to load from. Should be an official OpenML endpoint.\n\n    error_message : str or None\n        The error message to raise if an acceptable OpenML error is thrown\n        (acceptable error is, e.g., data id not found. Other errors, like 404's\n        will throw the native error message).\n\n    data_home : str or None\n        Location to cache the response. None if no cache is required.\n\n    n_retries : int, default=3\n        Number of retries when HTTP errors are encountered. Error with status\n        code 412 won't be retried as they represent OpenML generic errors.\n\n    delay : float, default=1.0\n        Number of seconds between retries.\n\n    Returns\n    -------\n    json_data : json\n        the json result from the OpenML server if the call was successful.\n        An exception otherwise.\n    \"\"\"\n\n    @_retry_with_clean_cache(url, data_home=data_home)\n    def _load_json():\n        with closing(\n            _open_openml_url(url, data_home, n_retries=n_retries, delay=delay)\n        ) as response:\n "}, {"start_line": 2000, "end_line": 4000, "belongs_to": {"file_name": "_openml.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/datasets", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "\n                return f(*args, **kw)\n            except URLError:\n                raise\n            except Exception as exc:\n                if no_retry_exception is not None and isinstance(\n                    exc, no_retry_exception\n                ):\n                    raise\n                warn(\"Invalid cache, redownloading file\", RuntimeWarning)\n                local_path = _get_local_path(openml_path, data_home)\n                if os.path.exists(local_path):\n                    os.unlink(local_path)\n                return f(*args, **kw)\n\n        return wrapper\n\n    return decorator\n\n\ndef _retry_on_network_error(\n    n_retries: int = 3, delay: float = 1.0, url: str = \"\"\n) -> Callable:\n    \"\"\"If the function call results in a network error, call the function again\n    up to ``n_retries`` times with a ``delay`` between each call. If the error\n    has a 412 status code, don't call the function again as this is a specific\n    OpenML error.\n    The url parameter is used to give more information to the user about the\n    error.\n    \"\"\"\n\n    def decorator(f):\n        @wraps(f)\n        def wrapper(*args, **kwargs):\n            retry_counter = n_retries\n            while True:\n                try:\n                    return f(*args, **kwargs)\n                except (URLError, TimeoutError) as e:\n                    # 412 is a specific OpenML error code.\n                    if isinstance(e, HTTPError) and e.code == 412:\n                        raise\n                    if retry_counter == 0:\n                        raise\n                    warn(\n                        f\"A network error occurred while downloading {url}. Retrying...\"\n                    )\n                    retry_counter -= 1\n                    time.sleep(delay)\n\n        return wrapper\n\n    return decorator\n\n\ndef _open_openml_url(\n    url: str, data_home: Optional[str], n_retries: int = 3, delay: float = 1.0\n):\n    \"\"\"\n    Returns a resource from OpenML.org. Caches it to data_home if required.\n\n    "}, {"start_line": 3000, "end_line": 5000, "belongs_to": {"file_name": "_openml.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/datasets", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": " information to the user about the\n    error.\n    \"\"\"\n\n    def decorator(f):\n        @wraps(f)\n        def wrapper(*args, **kwargs):\n            retry_counter = n_retries\n            while True:\n                try:\n                    return f(*args, **kwargs)\n                except (URLError, TimeoutError) as e:\n                    # 412 is a specific OpenML error code.\n                    if isinstance(e, HTTPError) and e.code == 412:\n                        raise\n                    if retry_counter == 0:\n                        raise\n                    warn(\n                        f\"A network error occurred while downloading {url}. Retrying...\"\n                    )\n                    retry_counter -= 1\n                    time.sleep(delay)\n\n        return wrapper\n\n    return decorator\n\n\ndef _open_openml_url(\n    url: str, data_home: Optional[str], n_retries: int = 3, delay: float = 1.0\n):\n    \"\"\"\n    Returns a resource from OpenML.org. Caches it to data_home if required.\n\n    Parameters\n    ----------\n    url : str\n        OpenML URL that will be downloaded and cached locally. The path component\n        of the URL is used to replicate the tree structure as sub-folders of the local\n        cache folder.\n\n    data_home : str\n        Directory to which the files will be cached. If None, no caching will\n        be applied.\n\n    n_retries : int, default=3\n        Number of retries when HTTP errors are encountered. Error with status\n        code 412 won't be retried as they represent OpenML generic errors.\n\n    delay : float, default=1.0\n        Number of seconds between retries.\n\n    Returns\n    -------\n    result : stream\n        A stream to the OpenML resource.\n    \"\"\"\n\n    def is_gzip_encoded(_fsrc):\n        return _fsrc.info().get(\"Content-Encoding\", \"\") == \"gzip\"\n\n    req = Request(url)\n    req.add_header(\"Accept-encoding\", \"gzip\")\n\n    if data_home is None:\n        fsrc = _retry_on_network_error(n_retries, delay, req.full_url)(urlopen)(req)\n        if is_g"}, {"start_line": 1000, "end_line": 3000, "belongs_to": {"file_name": "_openml.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/datasets", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "g/api/v1/json/data/{}\"\n_DATA_FEATURES = \"https://api.openml.org/api/v1/json/data/features/{}\"\n_DATA_QUALITIES = \"https://api.openml.org/api/v1/json/data/qualities/{}\"\n\nOpenmlQualitiesType = List[Dict[str, str]]\nOpenmlFeaturesType = List[Dict[str, str]]\n\n\ndef _get_local_path(openml_path: str, data_home: str) -> str:\n    return os.path.join(data_home, \"openml.org\", openml_path + \".gz\")\n\n\ndef _retry_with_clean_cache(\n    openml_path: str,\n    data_home: Optional[str],\n    no_retry_exception: Optional[Exception] = None,\n) -> Callable:\n    \"\"\"If the first call to the decorated function fails, the local cached\n    file is removed, and the function is called again. If ``data_home`` is\n    ``None``, then the function is called once. We can provide a specific\n    exception to not retry on using `no_retry_exception` parameter.\n    \"\"\"\n\n    def decorator(f):\n        @wraps(f)\n        def wrapper(*args, **kw):\n            if data_home is None:\n                return f(*args, **kw)\n            try:\n                return f(*args, **kw)\n            except URLError:\n                raise\n            except Exception as exc:\n                if no_retry_exception is not None and isinstance(\n                    exc, no_retry_exception\n                ):\n                    raise\n                warn(\"Invalid cache, redownloading file\", RuntimeWarning)\n                local_path = _get_local_path(openml_path, data_home)\n                if os.path.exists(local_path):\n                    os.unlink(local_path)\n                return f(*args, **kw)\n\n        return wrapper\n\n    return decorator\n\n\ndef _retry_on_network_error(\n    n_retries: int = 3, delay: float = 1.0, url: str = \"\"\n) -> Callable:\n    \"\"\"If the function call results in a network error, call the function again\n    up to ``n_retries`` times with a ``delay`` between each call. If the error\n    has a 412 status code, don't call the function again as this is a specific\n    OpenML error.\n    The url parameter is used to give more"}, {"start_line": 45000, "end_line": 47000, "belongs_to": {"file_name": "test_openml.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/datasets/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "\"/filename.arff\"\n    url = f\"https://www.openml.org/{openml_path}\"\n    cache_directory = str(tmpdir.mkdir(\"scikit_learn_data\"))\n    location = _get_local_path(openml_path, cache_directory)\n\n    def _mock_urlopen(request, *args, **kwargs):\n        if write_to_disk:\n            with open(location, \"w\") as f:\n                f.write(\"\")\n        raise ValueError(\"Invalid request\")\n\n    monkeypatch.setattr(sklearn.datasets._openml, \"urlopen\", _mock_urlopen)\n\n    with pytest.raises(ValueError, match=\"Invalid request\"):\n        _open_openml_url(url, cache_directory)\n\n    assert not os.path.exists(location)\n\n\ndef test_retry_with_clean_cache(tmpdir):\n    data_id = 61\n    openml_path = _MONKEY_PATCH_LOCAL_OPENML_PATH.format(data_id)\n    cache_directory = str(tmpdir.mkdir(\"scikit_learn_data\"))\n    location = _get_local_path(openml_path, cache_directory)\n    os.makedirs(os.path.dirname(location))\n\n    with open(location, \"w\") as f:\n        f.write(\"\")\n\n    @_retry_with_clean_cache(openml_path, cache_directory)\n    def _load_data():\n        # The first call will raise an error since location exists\n        if os.path.exists(location):\n            raise Exception(\"File exist!\")\n        return 1\n\n    warn_msg = \"Invalid cache, redownloading file\"\n    with pytest.warns(RuntimeWarning, match=warn_msg):\n        result = _load_data()\n    assert result == 1\n\n\ndef test_retry_with_clean_cache_http_error(tmpdir):\n    data_id = 61\n    openml_path = _MONKEY_PATCH_LOCAL_OPENML_PATH.format(data_id)\n    cache_directory = str(tmpdir.mkdir(\"scikit_learn_data\"))\n\n    @_retry_with_clean_cache(openml_path, cache_directory)\n    def _load_data():\n        raise HTTPError(\n            url=None, code=412, msg=\"Simulated mock error\", hdrs=None, fp=BytesIO()\n        )\n\n    error_msg = \"Simulated mock error\"\n    with pytest.raises(HTTPError, match=error_msg):\n        _load_data()\n\n\n@pytest.mark.parametrize(\"gzip_response\", [True, False])\ndef test_fetch_openml_cache(monkeypatch, gzip_response, tmpdir):\n    "}, {"start_line": 7000, "end_line": 9000, "belongs_to": {"file_name": "_openml.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/datasets", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "om. Should be an official OpenML endpoint.\n\n    error_message : str or None\n        The error message to raise if an acceptable OpenML error is thrown\n        (acceptable error is, e.g., data id not found. Other errors, like 404's\n        will throw the native error message).\n\n    data_home : str or None\n        Location to cache the response. None if no cache is required.\n\n    n_retries : int, default=3\n        Number of retries when HTTP errors are encountered. Error with status\n        code 412 won't be retried as they represent OpenML generic errors.\n\n    delay : float, default=1.0\n        Number of seconds between retries.\n\n    Returns\n    -------\n    json_data : json\n        the json result from the OpenML server if the call was successful.\n        An exception otherwise.\n    \"\"\"\n\n    @_retry_with_clean_cache(url, data_home=data_home)\n    def _load_json():\n        with closing(\n            _open_openml_url(url, data_home, n_retries=n_retries, delay=delay)\n        ) as response:\n            return json.loads(response.read().decode(\"utf-8\"))\n\n    try:\n        return _load_json()\n    except HTTPError as error:\n        # 412 is an OpenML specific error code, indicating a generic error\n        # (e.g., data not found)\n        if error.code != 412:\n            raise error\n\n    # 412 error, not in except for nicer traceback\n    raise OpenMLError(error_message)\n\n\ndef _get_data_info_by_name(\n    name: str,\n    version: Union[int, str],\n    data_home: Optional[str],\n    n_retries: int = 3,\n    delay: float = 1.0,\n):\n    \"\"\"\n    Utilizes the openml dataset listing api to find a dataset by\n    name/version\n    OpenML api function:\n    https://www.openml.org/api_docs#!/data/get_data_list_data_name_data_name\n\n    Parameters\n    ----------\n    name : str\n        name of the dataset\n\n    version : int or str\n        If version is an integer, the exact name/version will be obtained from\n        OpenML. If version is a string (value: \"active\") it will take the first\n        ver"}, {"start_line": 50000, "end_line": 52000, "belongs_to": {"file_name": "test_openml.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/datasets/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "r\n        )\n    # exception message should have file-path\n    assert exc.match(\"1666876\")\n\n\ndef test_open_openml_url_retry_on_network_error(monkeypatch):\n    def _mock_urlopen_network_error(request, *args, **kwargs):\n        raise HTTPError(\n            url=None, code=404, msg=\"Simulated network error\", hdrs=None, fp=BytesIO()\n        )\n\n    monkeypatch.setattr(\n        sklearn.datasets._openml, \"urlopen\", _mock_urlopen_network_error\n    )\n\n    invalid_openml_url = \"https://api.openml.org/invalid-url\"\n\n    with pytest.warns(\n        UserWarning,\n        match=re.escape(\n            \"A network error occurred while downloading\"\n            f\" {invalid_openml_url}. Retrying...\"\n        ),\n    ) as record:\n        with pytest.raises(HTTPError, match=\"Simulated network error\"):\n            _open_openml_url(invalid_openml_url, None, delay=0)\n        assert len(record) == 3\n\n\n###############################################################################\n# Non-regressiont tests\n\n\n@pytest.mark.parametrize(\"gzip_response\", [True, False])\n@pytest.mark.parametrize(\"parser\", (\"liac-arff\", \"pandas\"))\ndef test_fetch_openml_with_ignored_feature(monkeypatch, gzip_response, parser):\n    \"\"\"Check that we can load the \"zoo\" dataset.\n    Non-regression test for:\n    https://github.com/scikit-learn/scikit-learn/issues/14340\n    \"\"\"\n    if parser == \"pandas\":\n        pytest.importorskip(\"pandas\")\n    data_id = 62\n    _monkey_patch_webbased_functions(monkeypatch, data_id, gzip_response)\n\n    dataset = sklearn.datasets.fetch_openml(\n        data_id=data_id, cache=False, as_frame=False, parser=parser\n    )\n    assert dataset is not None\n    # The dataset has 17 features, including 1 ignored (animal),\n    # so we assert that we don't have the ignored feature in the final Bunch\n    assert dataset[\"data\"].shape == (101, 16)\n    assert \"animal\" not in dataset[\"feature_names\"]\n\n\ndef test_fetch_openml_strip_quotes(monkeypatch):\n    \"\"\"Check that we strip the single quotes when used as a string de"}, {"start_line": 49000, "end_line": 51000, "belongs_to": {"file_name": "test_openml.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/datasets/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "ith gzip.GzipFile(corrupt_copy_path, \"wb\") as modified_gzip:\n        modified_gzip.write(data)\n\n    # Requests are already mocked by monkey_patch_webbased_functions.\n    # We want to reuse that mock for all requests except file download,\n    # hence creating a thin mock over the original mock\n    mocked_openml_url = sklearn.datasets._openml.urlopen\n\n    def swap_file_mock(request, *args, **kwargs):\n        url = request.get_full_url()\n        if url.endswith(\"data/v1/download/1666876/anneal.arff\"):\n            with open(corrupt_copy_path, \"rb\") as f:\n                corrupted_data = f.read()\n            return _MockHTTPResponse(BytesIO(corrupted_data), is_gzip=True)\n        else:\n            return mocked_openml_url(request)\n\n    monkeypatch.setattr(sklearn.datasets._openml, \"urlopen\", swap_file_mock)\n\n    # validate failed checksum\n    with pytest.raises(ValueError) as exc:\n        sklearn.datasets.fetch_openml(\n            data_id=data_id, cache=False, as_frame=as_frame, parser=parser\n        )\n    # exception message should have file-path\n    assert exc.match(\"1666876\")\n\n\ndef test_open_openml_url_retry_on_network_error(monkeypatch):\n    def _mock_urlopen_network_error(request, *args, **kwargs):\n        raise HTTPError(\n            url=None, code=404, msg=\"Simulated network error\", hdrs=None, fp=BytesIO()\n        )\n\n    monkeypatch.setattr(\n        sklearn.datasets._openml, \"urlopen\", _mock_urlopen_network_error\n    )\n\n    invalid_openml_url = \"https://api.openml.org/invalid-url\"\n\n    with pytest.warns(\n        UserWarning,\n        match=re.escape(\n            \"A network error occurred while downloading\"\n            f\" {invalid_openml_url}. Retrying...\"\n        ),\n    ) as record:\n        with pytest.raises(HTTPError, match=\"Simulated network error\"):\n            _open_openml_url(invalid_openml_url, None, delay=0)\n        assert len(record) == 3\n\n\n###############################################################################\n# Non-regressiont tests\n\n\n@pytest.mark"}, {"start_line": 5000, "end_line": 7000, "belongs_to": {"file_name": "test_openml.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/datasets/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "      # sklearn/datasets/tests/data/openml/id_1/data-v1-dl-1.arff.gz.\n        # We only keep the part of the url before the last /\n        url_without_filename = url.rsplit(\"/\", 1)[0]\n\n        return _mock_urlopen_shared(\n            url=url_without_filename,\n            has_gzip_header=has_gzip_header,\n            expected_prefix=url_prefix_download_data,\n            suffix=\".arff\",\n        )\n\n    def _mock_urlopen_data_list(url, has_gzip_header):\n        assert url.startswith(url_prefix_data_list), (\n            f\"{url_prefix_data_list!r} does not match {url!r}\"\n        )\n\n        data_file_name = _file_name(url, \".json\")\n        data_file_path = resources.files(data_module) / data_file_name\n\n        # load the file itself, to simulate a http error\n        with data_file_path.open(\"rb\") as f:\n            decompressed_f = read_fn(f, \"rb\")\n            decoded_s = decompressed_f.read().decode(\"utf-8\")\n            json_data = json.loads(decoded_s)\n        if \"error\" in json_data:\n            raise HTTPError(\n                url=None, code=412, msg=\"Simulated mock error\", hdrs=None, fp=BytesIO()\n            )\n\n        with data_file_path.open(\"rb\") as f:\n            if has_gzip_header:\n                fp = BytesIO(f.read())\n                return _MockHTTPResponse(fp, True)\n            else:\n                decompressed_f = read_fn(f, \"rb\")\n                fp = BytesIO(decompressed_f.read())\n                return _MockHTTPResponse(fp, False)\n\n    def _mock_urlopen(request, *args, **kwargs):\n        url = request.get_full_url()\n        has_gzip_header = request.get_header(\"Accept-encoding\") == \"gzip\"\n        if url.startswith(url_prefix_data_list):\n            return _mock_urlopen_data_list(url, has_gzip_header)\n        elif url.startswith(url_prefix_data_features):\n            return _mock_urlopen_data_features(url, has_gzip_header)\n        elif url.startswith(url_prefix_download_data):\n            return _mock_urlopen_download_data(url, has_gzip_header)\n        elif "}], "retrieved_count": 10, "cost_time": 1.2776951789855957}
{"question": "How does the NearestCentroid classifier reconcile the different centroid computation strategies between euclidean and manhattan metrics during the fit phase, and what architectural implications does this dual-path approach have for maintaining consistency across sparse and dense data representations?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"start_line": 4000, "end_line": 6000, "belongs_to": {"file_name": "_nearest_centroid.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/neighbors", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "g Data Mining, Inference, and Prediction. 2nd Edition. New York, Springer.\n\n    Examples\n    --------\n    >>> from sklearn.neighbors import NearestCentroid\n    >>> import numpy as np\n    >>> X = np.array([[-1, -1], [-2, -1], [-3, -2], [1, 1], [2, 1], [3, 2]])\n    >>> y = np.array([1, 1, 1, 2, 2, 2])\n    >>> clf = NearestCentroid()\n    >>> clf.fit(X, y)\n    NearestCentroid()\n    >>> print(clf.predict([[-0.8, -1]]))\n    [1]\n    \"\"\"\n\n    _parameter_constraints: dict = {\n        \"metric\": [StrOptions({\"manhattan\", \"euclidean\"})],\n        \"shrink_threshold\": [Interval(Real, 0, None, closed=\"neither\"), None],\n        \"priors\": [\"array-like\", StrOptions({\"empirical\", \"uniform\"})],\n    }\n\n    def __init__(\n        self,\n        metric=\"euclidean\",\n        *,\n        shrink_threshold=None,\n        priors=\"uniform\",\n    ):\n        self.metric = metric\n        self.shrink_threshold = shrink_threshold\n        self.priors = priors\n\n    @_fit_context(prefer_skip_nested_validation=True)\n    def fit(self, X, y):\n        \"\"\"\n        Fit the NearestCentroid model according to the given training data.\n\n        Parameters\n        ----------\n        X : {array-like, sparse matrix} of shape (n_samples, n_features)\n            Training vector, where `n_samples` is the number of samples and\n            `n_features` is the number of features.\n            Note that centroid shrinking cannot be used with sparse matrices.\n        y : array-like of shape (n_samples,)\n            Target values.\n\n        Returns\n        -------\n        self : object\n            Fitted estimator.\n        \"\"\"\n        # If X is sparse and the metric is \"manhattan\", store it in a csc\n        # format is easier to calculate the median.\n        if self.metric == \"manhattan\":\n            X, y = validate_data(self, X, y, accept_sparse=[\"csc\"])\n        else:\n            ensure_all_finite = (\n                \"allow-nan\" if get_tags(self).input_tags.allow_nan else True\n            )\n            X, y = validate_data(\n       "}, {"start_line": 1000, "end_line": 3000, "belongs_to": {"file_name": "_nearest_centroid.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/neighbors", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "d by its centroid, with test samples classified to\n    the class with the nearest centroid.\n\n    Read more in the :ref:`User Guide <nearest_centroid_classifier>`.\n\n    Parameters\n    ----------\n    metric : {\"euclidean\", \"manhattan\"}, default=\"euclidean\"\n        Metric to use for distance computation.\n\n        If `metric=\"euclidean\"`, the centroid for the samples corresponding to each\n        class is the arithmetic mean, which minimizes the sum of squared L1 distances.\n        If `metric=\"manhattan\"`, the centroid is the feature-wise median, which\n        minimizes the sum of L1 distances.\n\n        .. versionchanged:: 1.5\n            All metrics but `\"euclidean\"` and `\"manhattan\"` were deprecated and\n            now raise an error.\n\n        .. versionchanged:: 0.19\n            `metric='precomputed'` was deprecated and now raises an error\n\n    shrink_threshold : float, default=None\n        Threshold for shrinking centroids to remove features.\n\n    priors : {\"uniform\", \"empirical\"} or array-like of shape (n_classes,), \\\n        default=\"uniform\"\n        The class prior probabilities. By default, the class proportions are\n        inferred from the training data.\n\n        .. versionadded:: 1.6\n\n    Attributes\n    ----------\n    centroids_ : array-like of shape (n_classes, n_features)\n        Centroid of each class.\n\n    classes_ : array of shape (n_classes,)\n        The unique classes labels.\n\n    n_features_in_ : int\n        Number of features seen during :term:`fit`.\n\n        .. versionadded:: 0.24\n\n    feature_names_in_ : ndarray of shape (`n_features_in_`,)\n        Names of features seen during :term:`fit`. Defined only when `X`\n        has feature names that are all strings.\n\n        .. versionadded:: 1.0\n\n    deviations_ : ndarray of shape (n_classes, n_features)\n        Deviations (or shrinkages) of the centroids of each class from the\n        overall centroid. Equal to eq. (18.4) if `shrink_threshold=None`,\n        else (18.5) p. 653 of [2]. Can be used to iden"}, {"start_line": 4000, "end_line": 6000, "belongs_to": {"file_name": "test_nearest_centroid.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/neighbors/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "rect.\n    # The expected result is calculated by R (pamr),\n    # which is implemented by the author of the original paper.\n    # (One need to modify the code to output the new centroid in pamr.predict)\n\n    X = np.array([[0, 1], [1, 0], [1, 1], [2, 0], [6, 8]])\n    y = np.array([1, 1, 2, 2, 2])\n    clf = NearestCentroid(shrink_threshold=0.1)\n    clf.fit(X, y)\n    expected_result = np.array([[0.7787310, 0.8545292], [2.814179, 2.763647]])\n    np.testing.assert_array_almost_equal(clf.centroids_, expected_result)\n\n\ndef test_shrinkage_threshold_decoded_y():\n    clf = NearestCentroid(shrink_threshold=0.01)\n    y_ind = np.asarray(y)\n    y_ind[y_ind == -1] = 0\n    clf.fit(X, y_ind)\n    centroid_encoded = clf.centroids_\n    clf.fit(X, y)\n    assert_array_equal(centroid_encoded, clf.centroids_)\n\n\ndef test_predict_translated_data():\n    # Test that NearestCentroid gives same results on translated data\n\n    rng = np.random.RandomState(0)\n    X = rng.rand(50, 50)\n    y = rng.randint(0, 3, 50)\n    noise = rng.rand(50)\n    clf = NearestCentroid(shrink_threshold=0.1)\n    clf.fit(X, y)\n    y_init = clf.predict(X)\n    clf = NearestCentroid(shrink_threshold=0.1)\n    X_noise = X + noise\n    clf.fit(X_noise, y)\n    y_translate = clf.predict(X_noise)\n    assert_array_equal(y_init, y_translate)\n\n\n@pytest.mark.parametrize(\"csr_container\", CSR_CONTAINERS)\ndef test_manhattan_metric(csr_container):\n    # Test the manhattan metric.\n    X_csr = csr_container(X)\n\n    clf = NearestCentroid(metric=\"manhattan\")\n    clf.fit(X, y)\n    dense_centroid = clf.centroids_\n    clf.fit(X_csr, y)\n    assert_array_equal(clf.centroids_, dense_centroid)\n    assert_array_equal(dense_centroid, [[-1, -1], [1, 1]])\n\n\ndef test_features_zero_var():\n    # Test that features with 0 variance throw error\n\n    X = np.empty((10, 2))\n    X[:, 0] = -0.13725701\n    X[:, 1] = -0.9853293\n    y = np.zeros((10))\n    y[0] = 1\n\n    clf = NearestCentroid(shrink_threshold=0.1)\n    with pytest.raises(ValueError):\n        clf.fit(X, y)\n"}, {"start_line": 5000, "end_line": 7000, "belongs_to": {"file_name": "test_nearest_centroid.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/neighbors/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "oise = rng.rand(50)\n    clf = NearestCentroid(shrink_threshold=0.1)\n    clf.fit(X, y)\n    y_init = clf.predict(X)\n    clf = NearestCentroid(shrink_threshold=0.1)\n    X_noise = X + noise\n    clf.fit(X_noise, y)\n    y_translate = clf.predict(X_noise)\n    assert_array_equal(y_init, y_translate)\n\n\n@pytest.mark.parametrize(\"csr_container\", CSR_CONTAINERS)\ndef test_manhattan_metric(csr_container):\n    # Test the manhattan metric.\n    X_csr = csr_container(X)\n\n    clf = NearestCentroid(metric=\"manhattan\")\n    clf.fit(X, y)\n    dense_centroid = clf.centroids_\n    clf.fit(X_csr, y)\n    assert_array_equal(clf.centroids_, dense_centroid)\n    assert_array_equal(dense_centroid, [[-1, -1], [1, 1]])\n\n\ndef test_features_zero_var():\n    # Test that features with 0 variance throw error\n\n    X = np.empty((10, 2))\n    X[:, 0] = -0.13725701\n    X[:, 1] = -0.9853293\n    y = np.zeros((10))\n    y[0] = 1\n\n    clf = NearestCentroid(shrink_threshold=0.1)\n    with pytest.raises(ValueError):\n        clf.fit(X, y)\n\n\ndef test_negative_priors_error():\n    \"\"\"Check that we raise an error when the user-defined priors are negative.\"\"\"\n    clf = NearestCentroid(priors=[-2, 4])\n    with pytest.raises(ValueError, match=\"priors must be non-negative\"):\n        clf.fit(X, y)\n\n\ndef test_warn_non_normalized_priors():\n    \"\"\"Check that we raise a warning and normalize the user-defined priors when they\n    don't sum to 1.\n    \"\"\"\n    priors = [2, 4]\n    clf = NearestCentroid(priors=priors)\n    with pytest.warns(\n        UserWarning,\n        match=\"The priors do not sum to 1. Normalizing such that it sums to one.\",\n    ):\n        clf.fit(X, y)\n\n    assert_allclose(clf.class_prior_, np.asarray(priors) / np.asarray(priors).sum())\n\n\n@pytest.mark.parametrize(\n    \"response_method\", [\"decision_function\", \"predict_proba\", \"predict_log_proba\"]\n)\ndef test_method_not_available_with_manhattan(response_method):\n    \"\"\"Check that we raise an AttributeError with Manhattan metric when trying\n    to call a non-thresholded res"}, {"start_line": 0, "end_line": 2000, "belongs_to": {"file_name": "_nearest_centroid.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/neighbors", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "\"\"\"\nNearest Centroid Classification\n\"\"\"\n\n# Authors: The scikit-learn developers\n# SPDX-License-Identifier: BSD-3-Clause\n\nimport warnings\nfrom numbers import Real\n\nimport numpy as np\nfrom scipy import sparse as sp\n\nfrom sklearn.base import BaseEstimator, ClassifierMixin, _fit_context\nfrom sklearn.discriminant_analysis import DiscriminantAnalysisPredictionMixin\nfrom sklearn.metrics.pairwise import pairwise_distances, pairwise_distances_argmin\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.utils import get_tags\nfrom sklearn.utils._available_if import available_if\nfrom sklearn.utils._param_validation import Interval, StrOptions\nfrom sklearn.utils.multiclass import check_classification_targets\nfrom sklearn.utils.sparsefuncs import csc_median_axis_0\nfrom sklearn.utils.validation import check_is_fitted, validate_data\n\n\nclass NearestCentroid(\n    DiscriminantAnalysisPredictionMixin, ClassifierMixin, BaseEstimator\n):\n    \"\"\"Nearest centroid classifier.\n\n    Each class is represented by its centroid, with test samples classified to\n    the class with the nearest centroid.\n\n    Read more in the :ref:`User Guide <nearest_centroid_classifier>`.\n\n    Parameters\n    ----------\n    metric : {\"euclidean\", \"manhattan\"}, default=\"euclidean\"\n        Metric to use for distance computation.\n\n        If `metric=\"euclidean\"`, the centroid for the samples corresponding to each\n        class is the arithmetic mean, which minimizes the sum of squared L1 distances.\n        If `metric=\"manhattan\"`, the centroid is the feature-wise median, which\n        minimizes the sum of L1 distances.\n\n        .. versionchanged:: 1.5\n            All metrics but `\"euclidean\"` and `\"manhattan\"` were deprecated and\n            now raise an error.\n\n        .. versionchanged:: 0.19\n            `metric='precomputed'` was deprecated and now raises an error\n\n    shrink_threshold : float, default=None\n        Threshold for shrinking centroids to remove features.\n\n    priors : {\"uniform\", \"empirical\"} or a"}, {"start_line": 3000, "end_line": 5000, "belongs_to": {"file_name": "_nearest_centroid.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/neighbors", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "tify features used\n        for classification.\n\n        .. versionadded:: 1.6\n\n    within_class_std_dev_ : ndarray of shape (n_features,)\n        Pooled or within-class standard deviation of input data.\n\n        .. versionadded:: 1.6\n\n    class_prior_ : ndarray of shape (n_classes,)\n        The class prior probabilities.\n\n        .. versionadded:: 1.6\n\n    See Also\n    --------\n    KNeighborsClassifier : Nearest neighbors classifier.\n\n    Notes\n    -----\n    When used for text classification with tf-idf vectors, this classifier is\n    also known as the Rocchio classifier.\n\n    References\n    ----------\n    [1] Tibshirani, R., Hastie, T., Narasimhan, B., & Chu, G. (2002). Diagnosis of\n    multiple cancer types by shrunken centroids of gene expression. Proceedings\n    of the National Academy of Sciences of the United States of America,\n    99(10), 6567-6572. The National Academy of Sciences.\n\n    [2] Hastie, T., Tibshirani, R., Friedman, J. (2009). The Elements of Statistical\n    Learning Data Mining, Inference, and Prediction. 2nd Edition. New York, Springer.\n\n    Examples\n    --------\n    >>> from sklearn.neighbors import NearestCentroid\n    >>> import numpy as np\n    >>> X = np.array([[-1, -1], [-2, -1], [-3, -2], [1, 1], [2, 1], [3, 2]])\n    >>> y = np.array([1, 1, 1, 2, 2, 2])\n    >>> clf = NearestCentroid()\n    >>> clf.fit(X, y)\n    NearestCentroid()\n    >>> print(clf.predict([[-0.8, -1]]))\n    [1]\n    \"\"\"\n\n    _parameter_constraints: dict = {\n        \"metric\": [StrOptions({\"manhattan\", \"euclidean\"})],\n        \"shrink_threshold\": [Interval(Real, 0, None, closed=\"neither\"), None],\n        \"priors\": [\"array-like\", StrOptions({\"empirical\", \"uniform\"})],\n    }\n\n    def __init__(\n        self,\n        metric=\"euclidean\",\n        *,\n        shrink_threshold=None,\n        priors=\"uniform\",\n    ):\n        self.metric = metric\n        self.shrink_threshold = shrink_threshold\n        self.priors = priors\n\n    @_fit_context(prefer_skip_nested_validation=True)\n    def fit(s"}, {"start_line": 1000, "end_line": 3000, "belongs_to": {"file_name": "test_nearest_centroid.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/neighbors/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": " versions.\n    X_csr = csr_container(X)\n    T_csr = csr_container(T)\n\n    # Check classification on a toy dataset, including sparse versions.\n    clf = NearestCentroid()\n    clf.fit(X, y)\n    assert_array_equal(clf.predict(T), true_result)\n    assert_array_almost_equal(clf.decision_function(T), true_discriminant_scores)\n    assert_array_almost_equal(clf.predict_proba(T), true_proba)\n\n    # Test uniform priors\n    clf = NearestCentroid(priors=\"uniform\")\n    clf.fit(X, y)\n    assert_array_equal(clf.predict(T), true_result)\n    assert_array_almost_equal(clf.decision_function(T), true_discriminant_scores)\n    assert_array_almost_equal(clf.predict_proba(T), true_proba)\n\n    clf = NearestCentroid(priors=\"empirical\")\n    clf.fit(X, y)\n    assert_array_equal(clf.predict(T), true_result)\n    assert_array_almost_equal(clf.decision_function(T), true_discriminant_scores)\n    assert_array_almost_equal(clf.predict_proba(T), true_proba)\n\n    # Test custom priors\n    clf = NearestCentroid(priors=[0.25, 0.75])\n    clf.fit(X, y)\n    assert_array_equal(clf.predict(T), true_result_prior1)\n\n    # Same test, but with a sparse matrix to fit and test.\n    clf = NearestCentroid()\n    clf.fit(X_csr, y)\n    assert_array_equal(clf.predict(T_csr), true_result)\n\n    # Fit with sparse, test with non-sparse\n    clf = NearestCentroid()\n    clf.fit(X_csr, y)\n    assert_array_equal(clf.predict(T), true_result)\n\n    # Fit with non-sparse, test with sparse\n    clf = NearestCentroid()\n    clf.fit(X, y)\n    assert_array_equal(clf.predict(T_csr), true_result)\n\n    # Fit and predict with non-CSR sparse matrices\n    clf = NearestCentroid()\n    clf.fit(X_csr.tocoo(), y)\n    assert_array_equal(clf.predict(T_csr.tolil()), true_result)\n\n\ndef test_iris():\n    # Check consistency on dataset iris.\n    for metric in (\"euclidean\", \"manhattan\"):\n        clf = NearestCentroid(metric=metric).fit(iris.data, iris.target)\n        score = np.mean(clf.predict(iris.data) == iris.target)\n        assert score > 0.9, \"Failed wi"}, {"start_line": 0, "end_line": 2000, "belongs_to": {"file_name": "test_nearest_centroid.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/neighbors/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "\"\"\"\nTesting for the nearest centroid module.\n\"\"\"\n\nimport numpy as np\nimport pytest\n\nfrom sklearn import datasets\nfrom sklearn.neighbors import NearestCentroid\nfrom sklearn.utils._testing import (\n    assert_allclose,\n    assert_array_almost_equal,\n    assert_array_equal,\n)\nfrom sklearn.utils.fixes import CSR_CONTAINERS\n\n# toy sample\nX = [[-2, -1], [-1, -1], [-1, -2], [1, 1], [1, 2], [2, 1]]\ny = [-1, -1, -1, 1, 1, 1]\nT = [[-1, -1], [2, 2], [3, 2]]\ntrue_result = [-1, 1, 1]\ntrue_result_prior1 = [-1, 1, 1]\n\ntrue_discriminant_scores = [-32, 64, 80]\ntrue_proba = [[1, 1.26642e-14], [1.60381e-28, 1], [1.80485e-35, 1]]\n\n\n# also load the iris dataset\n# and randomly permute it\niris = datasets.load_iris()\nrng = np.random.RandomState(1)\nperm = rng.permutation(iris.target.size)\niris.data = iris.data[perm]\niris.target = iris.target[perm]\n\n\n@pytest.mark.parametrize(\"csr_container\", CSR_CONTAINERS)\ndef test_classification_toy(csr_container):\n    # Check classification on a toy dataset, including sparse versions.\n    X_csr = csr_container(X)\n    T_csr = csr_container(T)\n\n    # Check classification on a toy dataset, including sparse versions.\n    clf = NearestCentroid()\n    clf.fit(X, y)\n    assert_array_equal(clf.predict(T), true_result)\n    assert_array_almost_equal(clf.decision_function(T), true_discriminant_scores)\n    assert_array_almost_equal(clf.predict_proba(T), true_proba)\n\n    # Test uniform priors\n    clf = NearestCentroid(priors=\"uniform\")\n    clf.fit(X, y)\n    assert_array_equal(clf.predict(T), true_result)\n    assert_array_almost_equal(clf.decision_function(T), true_discriminant_scores)\n    assert_array_almost_equal(clf.predict_proba(T), true_proba)\n\n    clf = NearestCentroid(priors=\"empirical\")\n    clf.fit(X, y)\n    assert_array_equal(clf.predict(T), true_result)\n    assert_array_almost_equal(clf.decision_function(T), true_discriminant_scores)\n    assert_array_almost_equal(clf.predict_proba(T), true_proba)\n\n    # Test custom priors\n    clf = NearestCentroid(priors=[0.25"}, {"start_line": 2000, "end_line": 4000, "belongs_to": {"file_name": "test_nearest_centroid.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/neighbors/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": ", 0.75])\n    clf.fit(X, y)\n    assert_array_equal(clf.predict(T), true_result_prior1)\n\n    # Same test, but with a sparse matrix to fit and test.\n    clf = NearestCentroid()\n    clf.fit(X_csr, y)\n    assert_array_equal(clf.predict(T_csr), true_result)\n\n    # Fit with sparse, test with non-sparse\n    clf = NearestCentroid()\n    clf.fit(X_csr, y)\n    assert_array_equal(clf.predict(T), true_result)\n\n    # Fit with non-sparse, test with sparse\n    clf = NearestCentroid()\n    clf.fit(X, y)\n    assert_array_equal(clf.predict(T_csr), true_result)\n\n    # Fit and predict with non-CSR sparse matrices\n    clf = NearestCentroid()\n    clf.fit(X_csr.tocoo(), y)\n    assert_array_equal(clf.predict(T_csr.tolil()), true_result)\n\n\ndef test_iris():\n    # Check consistency on dataset iris.\n    for metric in (\"euclidean\", \"manhattan\"):\n        clf = NearestCentroid(metric=metric).fit(iris.data, iris.target)\n        score = np.mean(clf.predict(iris.data) == iris.target)\n        assert score > 0.9, \"Failed with score = \" + str(score)\n\n\ndef test_iris_shrinkage():\n    # Check consistency on dataset iris, when using shrinkage.\n    for metric in (\"euclidean\", \"manhattan\"):\n        for shrink_threshold in [None, 0.1, 0.5]:\n            clf = NearestCentroid(metric=metric, shrink_threshold=shrink_threshold)\n            clf = clf.fit(iris.data, iris.target)\n            score = np.mean(clf.predict(iris.data) == iris.target)\n            assert score > 0.8, \"Failed with score = \" + str(score)\n\n\ndef test_pickle():\n    import pickle\n\n    # classification\n    obj = NearestCentroid()\n    obj.fit(iris.data, iris.target)\n    score = obj.score(iris.data, iris.target)\n    s = pickle.dumps(obj)\n\n    obj2 = pickle.loads(s)\n    assert type(obj2) == obj.__class__\n    score2 = obj2.score(iris.data, iris.target)\n    assert_array_equal(\n        score,\n        score2,\n        \"Failed to generate same score after pickling (classification).\",\n    )\n\n\ndef test_shrinkage_correct():\n    # Ensure that the shrinking is cor"}, {"start_line": 38000, "end_line": 40000, "belongs_to": {"file_name": "pairwise.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/metrics", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "ot already\n    in canonical format, this function modifies them in-place to\n    make them canonical.\n\n    Examples\n    --------\n    >>> from sklearn.metrics.pairwise import manhattan_distances\n    >>> manhattan_distances([[3]], [[3]])\n    array([[0.]])\n    >>> manhattan_distances([[3]], [[2]])\n    array([[1.]])\n    >>> manhattan_distances([[2]], [[3]])\n    array([[1.]])\n    >>> manhattan_distances([[1, 2], [3, 4]],\\\n         [[1, 2], [0, 3]])\n    array([[0., 2.],\n           [4., 4.]])\n    \"\"\"\n    X, Y = check_pairwise_arrays(X, Y)\n\n    if issparse(X) or issparse(Y):\n        X = csr_matrix(X, copy=False)\n        Y = csr_matrix(Y, copy=False)\n        X.sum_duplicates()  # this also sorts indices in-place\n        Y.sum_duplicates()\n        D = np.zeros((X.shape[0], Y.shape[0]))\n        _sparse_manhattan(X.data, X.indices, X.indptr, Y.data, Y.indices, Y.indptr, D)\n        return D\n\n    return distance.cdist(X, Y, \"cityblock\")\n\n\n@validate_params(\n    {\n        \"X\": [\"array-like\", \"sparse matrix\"],\n        \"Y\": [\"array-like\", \"sparse matrix\", None],\n    },\n    prefer_skip_nested_validation=True,\n)\ndef cosine_distances(X, Y=None):\n    \"\"\"Compute cosine distance between samples in X and Y.\n\n    Cosine distance is defined as 1.0 minus the cosine similarity.\n\n    Read more in the :ref:`User Guide <metrics>`.\n\n    Parameters\n    ----------\n    X : {array-like, sparse matrix} of shape (n_samples_X, n_features)\n        Matrix `X`.\n\n    Y : {array-like, sparse matrix} of shape (n_samples_Y, n_features), \\\n            default=None\n        Matrix `Y`.\n\n    Returns\n    -------\n    distances : ndarray of shape (n_samples_X, n_samples_Y)\n        Returns the cosine distance between samples in X and Y.\n\n    See Also\n    --------\n    cosine_similarity : Compute cosine similarity between samples in X and Y.\n    scipy.spatial.distance.cosine : Dense matrices only.\n\n    Examples\n    --------\n    >>> from sklearn.metrics.pairwise import cosine_distances\n    >>> X = [[0, 0, 0], [1, 1, 1]]\n   "}], "retrieved_count": 10, "cost_time": 1.2920539379119873}
{"question": "How does the NearestCentroid class leverage the available_if decorator pattern to conditionally expose decision_function, predict_proba, and predict_log_proba methods only for euclidean metrics, and what are the implications for API consistency across different metric configurations?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"start_line": 12000, "end_line": 13095, "belongs_to": {"file_name": "_nearest_centroid.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/neighbors", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "td_dev_[mask]\n\n        for class_idx in range(self.classes_.size):\n            distances = pairwise_distances(\n                X_normalized, centroids_normalized[[class_idx]], metric=self.metric\n            ).ravel()\n            distances **= 2\n            discriminant_score[:, class_idx] = np.squeeze(\n                -distances + 2.0 * np.log(self.class_prior_[class_idx])\n            )\n\n        return discriminant_score\n\n    def _check_euclidean_metric(self):\n        return self.metric == \"euclidean\"\n\n    decision_function = available_if(_check_euclidean_metric)(\n        DiscriminantAnalysisPredictionMixin.decision_function\n    )\n\n    predict_proba = available_if(_check_euclidean_metric)(\n        DiscriminantAnalysisPredictionMixin.predict_proba\n    )\n\n    predict_log_proba = available_if(_check_euclidean_metric)(\n        DiscriminantAnalysisPredictionMixin.predict_log_proba\n    )\n\n    def __sklearn_tags__(self):\n        tags = super().__sklearn_tags__()\n        tags.input_tags.allow_nan = self.metric == \"nan_euclidean\"\n        tags.input_tags.sparse = True\n        return tags\n"}, {"start_line": 11000, "end_line": 13000, "belongs_to": {"file_name": "_nearest_centroid.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/neighbors", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "data(\n                self,\n                X,\n                ensure_all_finite=ensure_all_finite,\n                accept_sparse=\"csr\",\n                reset=False,\n            )\n            return self.classes_[\n                pairwise_distances_argmin(X, self.centroids_, metric=self.metric)\n            ]\n        else:\n            return super().predict(X)\n\n    def _decision_function(self, X):\n        # return discriminant scores, see eq. (18.2) p. 652 of the ESL.\n        check_is_fitted(self, \"centroids_\")\n\n        X_normalized = validate_data(\n            self, X, copy=True, reset=False, accept_sparse=\"csr\", dtype=np.float64\n        )\n\n        discriminant_score = np.empty(\n            (X_normalized.shape[0], self.classes_.size), dtype=np.float64\n        )\n\n        mask = self.within_class_std_dev_ != 0\n        X_normalized[:, mask] /= self.within_class_std_dev_[mask]\n        centroids_normalized = self.centroids_.copy()\n        centroids_normalized[:, mask] /= self.within_class_std_dev_[mask]\n\n        for class_idx in range(self.classes_.size):\n            distances = pairwise_distances(\n                X_normalized, centroids_normalized[[class_idx]], metric=self.metric\n            ).ravel()\n            distances **= 2\n            discriminant_score[:, class_idx] = np.squeeze(\n                -distances + 2.0 * np.log(self.class_prior_[class_idx])\n            )\n\n        return discriminant_score\n\n    def _check_euclidean_metric(self):\n        return self.metric == \"euclidean\"\n\n    decision_function = available_if(_check_euclidean_metric)(\n        DiscriminantAnalysisPredictionMixin.decision_function\n    )\n\n    predict_proba = available_if(_check_euclidean_metric)(\n        DiscriminantAnalysisPredictionMixin.predict_proba\n    )\n\n    predict_log_proba = available_if(_check_euclidean_metric)(\n        DiscriminantAnalysisPredictionMixin.predict_log_proba\n    )\n\n    def __sklearn_tags__(self):\n        tags = super().__sklearn_tags__()\n        tags.input_tags.allow_"}, {"start_line": 3000, "end_line": 5000, "belongs_to": {"file_name": "_nearest_centroid.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/neighbors", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "tify features used\n        for classification.\n\n        .. versionadded:: 1.6\n\n    within_class_std_dev_ : ndarray of shape (n_features,)\n        Pooled or within-class standard deviation of input data.\n\n        .. versionadded:: 1.6\n\n    class_prior_ : ndarray of shape (n_classes,)\n        The class prior probabilities.\n\n        .. versionadded:: 1.6\n\n    See Also\n    --------\n    KNeighborsClassifier : Nearest neighbors classifier.\n\n    Notes\n    -----\n    When used for text classification with tf-idf vectors, this classifier is\n    also known as the Rocchio classifier.\n\n    References\n    ----------\n    [1] Tibshirani, R., Hastie, T., Narasimhan, B., & Chu, G. (2002). Diagnosis of\n    multiple cancer types by shrunken centroids of gene expression. Proceedings\n    of the National Academy of Sciences of the United States of America,\n    99(10), 6567-6572. The National Academy of Sciences.\n\n    [2] Hastie, T., Tibshirani, R., Friedman, J. (2009). The Elements of Statistical\n    Learning Data Mining, Inference, and Prediction. 2nd Edition. New York, Springer.\n\n    Examples\n    --------\n    >>> from sklearn.neighbors import NearestCentroid\n    >>> import numpy as np\n    >>> X = np.array([[-1, -1], [-2, -1], [-3, -2], [1, 1], [2, 1], [3, 2]])\n    >>> y = np.array([1, 1, 1, 2, 2, 2])\n    >>> clf = NearestCentroid()\n    >>> clf.fit(X, y)\n    NearestCentroid()\n    >>> print(clf.predict([[-0.8, -1]]))\n    [1]\n    \"\"\"\n\n    _parameter_constraints: dict = {\n        \"metric\": [StrOptions({\"manhattan\", \"euclidean\"})],\n        \"shrink_threshold\": [Interval(Real, 0, None, closed=\"neither\"), None],\n        \"priors\": [\"array-like\", StrOptions({\"empirical\", \"uniform\"})],\n    }\n\n    def __init__(\n        self,\n        metric=\"euclidean\",\n        *,\n        shrink_threshold=None,\n        priors=\"uniform\",\n    ):\n        self.metric = metric\n        self.shrink_threshold = shrink_threshold\n        self.priors = priors\n\n    @_fit_context(prefer_skip_nested_validation=True)\n    def fit(s"}, {"start_line": 6000, "end_line": 8000, "belongs_to": {"file_name": "discriminant_analysis.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "raticDiscriminantAnalysis and NearestCentroid.\"\"\"\n\n    def decision_function(self, X):\n        \"\"\"Apply decision function to an array of samples.\n\n        Parameters\n        ----------\n        X : {array-like, sparse matrix} of shape (n_samples, n_features)\n            Array of samples (test vectors).\n\n        Returns\n        -------\n        y_scores : ndarray of shape (n_samples,) or (n_samples, n_classes)\n            Decision function values related to each class, per sample.\n            In the two-class case, the shape is `(n_samples,)`, giving the\n            log likelihood ratio of the positive class.\n        \"\"\"\n        y_scores = self._decision_function(X)\n        if len(self.classes_) == 2:\n            return y_scores[:, 1] - y_scores[:, 0]\n        return y_scores\n\n    def predict(self, X):\n        \"\"\"Perform classification on an array of vectors `X`.\n\n        Returns the class label for each sample.\n\n        Parameters\n        ----------\n        X : {array-like, sparse matrix} of shape (n_samples, n_features)\n            Input vectors, where `n_samples` is the number of samples and\n            `n_features` is the number of features.\n\n        Returns\n        -------\n        y_pred : ndarray of shape (n_samples,)\n            Class label for each sample.\n        \"\"\"\n        scores = self._decision_function(X)\n        return self.classes_.take(scores.argmax(axis=1))\n\n    def predict_proba(self, X):\n        \"\"\"Estimate class probabilities.\n\n        Parameters\n        ----------\n        X : {array-like, sparse matrix} of shape (n_samples, n_features)\n            Input data.\n\n        Returns\n        -------\n        y_proba : ndarray of shape (n_samples, n_classes)\n            Probability estimate of the sample for each class in the\n            model, where classes are ordered as they are in `self.classes_`.\n        \"\"\"\n        return np.exp(self.predict_log_proba(X))\n\n    def predict_log_proba(self, X):\n        \"\"\"Estimate log class probabilities.\n\n        Paramet"}, {"start_line": 5000, "end_line": 7000, "belongs_to": {"file_name": "test_nearest_centroid.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/neighbors/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "oise = rng.rand(50)\n    clf = NearestCentroid(shrink_threshold=0.1)\n    clf.fit(X, y)\n    y_init = clf.predict(X)\n    clf = NearestCentroid(shrink_threshold=0.1)\n    X_noise = X + noise\n    clf.fit(X_noise, y)\n    y_translate = clf.predict(X_noise)\n    assert_array_equal(y_init, y_translate)\n\n\n@pytest.mark.parametrize(\"csr_container\", CSR_CONTAINERS)\ndef test_manhattan_metric(csr_container):\n    # Test the manhattan metric.\n    X_csr = csr_container(X)\n\n    clf = NearestCentroid(metric=\"manhattan\")\n    clf.fit(X, y)\n    dense_centroid = clf.centroids_\n    clf.fit(X_csr, y)\n    assert_array_equal(clf.centroids_, dense_centroid)\n    assert_array_equal(dense_centroid, [[-1, -1], [1, 1]])\n\n\ndef test_features_zero_var():\n    # Test that features with 0 variance throw error\n\n    X = np.empty((10, 2))\n    X[:, 0] = -0.13725701\n    X[:, 1] = -0.9853293\n    y = np.zeros((10))\n    y[0] = 1\n\n    clf = NearestCentroid(shrink_threshold=0.1)\n    with pytest.raises(ValueError):\n        clf.fit(X, y)\n\n\ndef test_negative_priors_error():\n    \"\"\"Check that we raise an error when the user-defined priors are negative.\"\"\"\n    clf = NearestCentroid(priors=[-2, 4])\n    with pytest.raises(ValueError, match=\"priors must be non-negative\"):\n        clf.fit(X, y)\n\n\ndef test_warn_non_normalized_priors():\n    \"\"\"Check that we raise a warning and normalize the user-defined priors when they\n    don't sum to 1.\n    \"\"\"\n    priors = [2, 4]\n    clf = NearestCentroid(priors=priors)\n    with pytest.warns(\n        UserWarning,\n        match=\"The priors do not sum to 1. Normalizing such that it sums to one.\",\n    ):\n        clf.fit(X, y)\n\n    assert_allclose(clf.class_prior_, np.asarray(priors) / np.asarray(priors).sum())\n\n\n@pytest.mark.parametrize(\n    \"response_method\", [\"decision_function\", \"predict_proba\", \"predict_log_proba\"]\n)\ndef test_method_not_available_with_manhattan(response_method):\n    \"\"\"Check that we raise an AttributeError with Manhattan metric when trying\n    to call a non-thresholded res"}, {"start_line": 4000, "end_line": 6000, "belongs_to": {"file_name": "_nearest_centroid.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/neighbors", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "g Data Mining, Inference, and Prediction. 2nd Edition. New York, Springer.\n\n    Examples\n    --------\n    >>> from sklearn.neighbors import NearestCentroid\n    >>> import numpy as np\n    >>> X = np.array([[-1, -1], [-2, -1], [-3, -2], [1, 1], [2, 1], [3, 2]])\n    >>> y = np.array([1, 1, 1, 2, 2, 2])\n    >>> clf = NearestCentroid()\n    >>> clf.fit(X, y)\n    NearestCentroid()\n    >>> print(clf.predict([[-0.8, -1]]))\n    [1]\n    \"\"\"\n\n    _parameter_constraints: dict = {\n        \"metric\": [StrOptions({\"manhattan\", \"euclidean\"})],\n        \"shrink_threshold\": [Interval(Real, 0, None, closed=\"neither\"), None],\n        \"priors\": [\"array-like\", StrOptions({\"empirical\", \"uniform\"})],\n    }\n\n    def __init__(\n        self,\n        metric=\"euclidean\",\n        *,\n        shrink_threshold=None,\n        priors=\"uniform\",\n    ):\n        self.metric = metric\n        self.shrink_threshold = shrink_threshold\n        self.priors = priors\n\n    @_fit_context(prefer_skip_nested_validation=True)\n    def fit(self, X, y):\n        \"\"\"\n        Fit the NearestCentroid model according to the given training data.\n\n        Parameters\n        ----------\n        X : {array-like, sparse matrix} of shape (n_samples, n_features)\n            Training vector, where `n_samples` is the number of samples and\n            `n_features` is the number of features.\n            Note that centroid shrinking cannot be used with sparse matrices.\n        y : array-like of shape (n_samples,)\n            Target values.\n\n        Returns\n        -------\n        self : object\n            Fitted estimator.\n        \"\"\"\n        # If X is sparse and the metric is \"manhattan\", store it in a csc\n        # format is easier to calculate the median.\n        if self.metric == \"manhattan\":\n            X, y = validate_data(self, X, y, accept_sparse=[\"csc\"])\n        else:\n            ensure_all_finite = (\n                \"allow-nan\" if get_tags(self).input_tags.allow_nan else True\n            )\n            X, y = validate_data(\n       "}, {"start_line": 0, "end_line": 2000, "belongs_to": {"file_name": "test_metaestimators.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/utils/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "import pickle\n\nimport pytest\n\nfrom sklearn.utils.metaestimators import available_if\n\n\nclass AvailableParameterEstimator:\n    \"\"\"This estimator's `available` parameter toggles the presence of a method\"\"\"\n\n    def __init__(self, available=True, return_value=1):\n        self.available = available\n        self.return_value = return_value\n\n    @available_if(lambda est: est.available)\n    def available_func(self):\n        \"\"\"This is a mock available_if function\"\"\"\n        return self.return_value\n\n\ndef test_available_if_docstring():\n    assert \"This is a mock available_if function\" in str(\n        AvailableParameterEstimator.__dict__[\"available_func\"].__doc__\n    )\n    assert \"This is a mock available_if function\" in str(\n        AvailableParameterEstimator.available_func.__doc__\n    )\n    assert \"This is a mock available_if function\" in str(\n        AvailableParameterEstimator().available_func.__doc__\n    )\n\n\ndef test_available_if():\n    assert hasattr(AvailableParameterEstimator(), \"available_func\")\n    assert not hasattr(AvailableParameterEstimator(available=False), \"available_func\")\n\n\ndef test_available_if_unbound_method():\n    # This is a non regression test for:\n    # https://github.com/scikit-learn/scikit-learn/issues/20614\n    # to make sure that decorated functions can be used as an unbound method,\n    # for instance when monkeypatching.\n    est = AvailableParameterEstimator()\n    AvailableParameterEstimator.available_func(est)\n\n    est = AvailableParameterEstimator(available=False)\n    with pytest.raises(\n        AttributeError,\n        match=\"This 'AvailableParameterEstimator' has no attribute 'available_func'\",\n    ):\n        AvailableParameterEstimator.available_func(est)\n\n\ndef test_available_if_methods_can_be_pickled():\n    \"\"\"Check that available_if methods can be pickled.\n\n    Non-regression test for #21344.\n    \"\"\"\n    return_value = 10\n    est = AvailableParameterEstimator(available=True, return_value=return_value)\n    pickled_bytes = pickle.dumps(est.av"}, {"start_line": 16000, "end_line": 18000, "belongs_to": {"file_name": "_rfe.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/feature_selection", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": ", **routed_params.estimator.score\n        )\n\n    def _get_support_mask(self):\n        check_is_fitted(self)\n        return self.support_\n\n    @available_if(_estimator_has(\"decision_function\"))\n    def decision_function(self, X):\n        \"\"\"Compute the decision function of ``X``.\n\n        Parameters\n        ----------\n        X : {array-like or sparse matrix} of shape (n_samples, n_features)\n            The input samples. Internally, it will be converted to\n            ``dtype=np.float32`` and if a sparse matrix is provided\n            to a sparse ``csr_matrix``.\n\n        Returns\n        -------\n        score : array, shape = [n_samples, n_classes] or [n_samples]\n            The decision function of the input samples. The order of the\n            classes corresponds to that in the attribute :term:`classes_`.\n            Regression and binary classification produce an array of shape\n            [n_samples].\n        \"\"\"\n        check_is_fitted(self)\n        return self.estimator_.decision_function(self.transform(X))\n\n    @available_if(_estimator_has(\"predict_proba\"))\n    def predict_proba(self, X):\n        \"\"\"Predict class probabilities for X.\n\n        Parameters\n        ----------\n        X : {array-like or sparse matrix} of shape (n_samples, n_features)\n            The input samples. Internally, it will be converted to\n            ``dtype=np.float32`` and if a sparse matrix is provided\n            to a sparse ``csr_matrix``.\n\n        Returns\n        -------\n        p : array of shape (n_samples, n_classes)\n            The class probabilities of the input samples. The order of the\n            classes corresponds to that in the attribute :term:`classes_`.\n        \"\"\"\n        check_is_fitted(self)\n        return self.estimator_.predict_proba(self.transform(X))\n\n    @available_if(_estimator_has(\"predict_log_proba\"))\n    def predict_log_proba(self, X):\n        \"\"\"Predict class log-probabilities for X.\n\n        Parameters\n        ----------\n        X : array of shape [n_sa"}, {"start_line": 1000, "end_line": 3000, "belongs_to": {"file_name": "_nearest_centroid.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/neighbors", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "d by its centroid, with test samples classified to\n    the class with the nearest centroid.\n\n    Read more in the :ref:`User Guide <nearest_centroid_classifier>`.\n\n    Parameters\n    ----------\n    metric : {\"euclidean\", \"manhattan\"}, default=\"euclidean\"\n        Metric to use for distance computation.\n\n        If `metric=\"euclidean\"`, the centroid for the samples corresponding to each\n        class is the arithmetic mean, which minimizes the sum of squared L1 distances.\n        If `metric=\"manhattan\"`, the centroid is the feature-wise median, which\n        minimizes the sum of L1 distances.\n\n        .. versionchanged:: 1.5\n            All metrics but `\"euclidean\"` and `\"manhattan\"` were deprecated and\n            now raise an error.\n\n        .. versionchanged:: 0.19\n            `metric='precomputed'` was deprecated and now raises an error\n\n    shrink_threshold : float, default=None\n        Threshold for shrinking centroids to remove features.\n\n    priors : {\"uniform\", \"empirical\"} or array-like of shape (n_classes,), \\\n        default=\"uniform\"\n        The class prior probabilities. By default, the class proportions are\n        inferred from the training data.\n\n        .. versionadded:: 1.6\n\n    Attributes\n    ----------\n    centroids_ : array-like of shape (n_classes, n_features)\n        Centroid of each class.\n\n    classes_ : array of shape (n_classes,)\n        The unique classes labels.\n\n    n_features_in_ : int\n        Number of features seen during :term:`fit`.\n\n        .. versionadded:: 0.24\n\n    feature_names_in_ : ndarray of shape (`n_features_in_`,)\n        Names of features seen during :term:`fit`. Defined only when `X`\n        has feature names that are all strings.\n\n        .. versionadded:: 1.0\n\n    deviations_ : ndarray of shape (n_classes, n_features)\n        Deviations (or shrinkages) of the centroids of each class from the\n        overall centroid. Equal to eq. (18.4) if `shrink_threshold=None`,\n        else (18.5) p. 653 of [2]. Can be used to iden"}, {"start_line": 2000, "end_line": 4000, "belongs_to": {"file_name": "test_nearest_centroid.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/neighbors/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": ", 0.75])\n    clf.fit(X, y)\n    assert_array_equal(clf.predict(T), true_result_prior1)\n\n    # Same test, but with a sparse matrix to fit and test.\n    clf = NearestCentroid()\n    clf.fit(X_csr, y)\n    assert_array_equal(clf.predict(T_csr), true_result)\n\n    # Fit with sparse, test with non-sparse\n    clf = NearestCentroid()\n    clf.fit(X_csr, y)\n    assert_array_equal(clf.predict(T), true_result)\n\n    # Fit with non-sparse, test with sparse\n    clf = NearestCentroid()\n    clf.fit(X, y)\n    assert_array_equal(clf.predict(T_csr), true_result)\n\n    # Fit and predict with non-CSR sparse matrices\n    clf = NearestCentroid()\n    clf.fit(X_csr.tocoo(), y)\n    assert_array_equal(clf.predict(T_csr.tolil()), true_result)\n\n\ndef test_iris():\n    # Check consistency on dataset iris.\n    for metric in (\"euclidean\", \"manhattan\"):\n        clf = NearestCentroid(metric=metric).fit(iris.data, iris.target)\n        score = np.mean(clf.predict(iris.data) == iris.target)\n        assert score > 0.9, \"Failed with score = \" + str(score)\n\n\ndef test_iris_shrinkage():\n    # Check consistency on dataset iris, when using shrinkage.\n    for metric in (\"euclidean\", \"manhattan\"):\n        for shrink_threshold in [None, 0.1, 0.5]:\n            clf = NearestCentroid(metric=metric, shrink_threshold=shrink_threshold)\n            clf = clf.fit(iris.data, iris.target)\n            score = np.mean(clf.predict(iris.data) == iris.target)\n            assert score > 0.8, \"Failed with score = \" + str(score)\n\n\ndef test_pickle():\n    import pickle\n\n    # classification\n    obj = NearestCentroid()\n    obj.fit(iris.data, iris.target)\n    score = obj.score(iris.data, iris.target)\n    s = pickle.dumps(obj)\n\n    obj2 = pickle.loads(s)\n    assert type(obj2) == obj.__class__\n    score2 = obj2.score(iris.data, iris.target)\n    assert_array_equal(\n        score,\n        score2,\n        \"Failed to generate same score after pickling (classification).\",\n    )\n\n\ndef test_shrinkage_correct():\n    # Ensure that the shrinking is cor"}], "retrieved_count": 10, "cost_time": 1.2898478507995605}
{"question": "How does the `response_method` parameter's 'auto' fallback mechanism interact with the `_validate_and_get_response_values` method to determine which scoring function to use when an estimator lacks `predict_proba`?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"start_line": 6000, "end_line": 8000, "belongs_to": {"file_name": "test_response.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/utils/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "thod_used:\n        assert results[2] == \"decision_function\"\n\n\n@pytest.mark.parametrize(\"return_response_method_used\", [True, False])\n@pytest.mark.parametrize(\"response_method\", [\"predict_proba\", \"predict_log_proba\"])\ndef test_get_response_values_binary_classifier_predict_proba(\n    return_response_method_used, response_method\n):\n    \"\"\"Check that `_get_response_values` with `predict_proba` and binary\n    classifier.\"\"\"\n    X, y = make_classification(\n        n_samples=10,\n        n_classes=2,\n        weights=[0.3, 0.7],\n        random_state=0,\n    )\n    classifier = LogisticRegression().fit(X, y)\n\n    # default `pos_label`\n    results = _get_response_values(\n        classifier,\n        X,\n        response_method=response_method,\n        pos_label=None,\n        return_response_method_used=return_response_method_used,\n    )\n    assert_allclose(results[0], getattr(classifier, response_method)(X)[:, 1])\n    assert results[1] == 1\n    if return_response_method_used:\n        assert len(results) == 3\n        assert results[2] == response_method\n    else:\n        assert len(results) == 2\n\n    # when forcing `pos_label=classifier.classes_[0]`\n    y_pred, pos_label, *_ = _get_response_values(\n        classifier,\n        X,\n        response_method=response_method,\n        pos_label=classifier.classes_[0],\n        return_response_method_used=return_response_method_used,\n    )\n    assert_allclose(y_pred, getattr(classifier, response_method)(X)[:, 0])\n    assert pos_label == 0\n\n\n@pytest.mark.parametrize(\n    \"estimator, X, y, err_msg, params\",\n    [\n        (\n            DecisionTreeRegressor(),\n            X_binary,\n            y_binary,\n            \"Expected 'estimator' to be a binary classifier\",\n            {\"response_method\": \"auto\"},\n        ),\n        (\n            DecisionTreeClassifier(),\n            X_binary,\n            y_binary,\n            r\"pos_label=unknown is not a valid label: It should be one of \\[0 1\\]\",\n            {\"response_method\": \"auto\", \"pos_label\": \"unk"}, {"start_line": 4000, "end_line": 6000, "belongs_to": {"file_name": "test_response.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/utils/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "dict_log_proba\"])\ndef test_get_response_values_classifier_inconsistent_y_pred_for_binary_proba(\n    response_method,\n):\n    \"\"\"Check that `_get_response_values` will raise an error when `y_pred` has a\n    single class with `predict_proba`.\"\"\"\n    X, y_two_class = make_classification(n_samples=10, n_classes=2, random_state=0)\n    y_single_class = np.zeros_like(y_two_class)\n    classifier = DecisionTreeClassifier().fit(X, y_single_class)\n\n    err_msg = (\n        r\"Got predict_proba of shape \\(10, 1\\), but need classifier with \"\n        r\"two classes\"\n    )\n    with pytest.raises(ValueError, match=err_msg):\n        _get_response_values(classifier, X, response_method=response_method)\n\n\n@pytest.mark.parametrize(\"return_response_method_used\", [True, False])\ndef test_get_response_values_binary_classifier_decision_function(\n    return_response_method_used,\n):\n    \"\"\"Check the behaviour of `_get_response_values` with `decision_function`\n    and binary classifier.\"\"\"\n    X, y = make_classification(\n        n_samples=10,\n        n_classes=2,\n        weights=[0.3, 0.7],\n        random_state=0,\n    )\n    classifier = LogisticRegression().fit(X, y)\n    response_method = \"decision_function\"\n\n    # default `pos_label`\n    results = _get_response_values(\n        classifier,\n        X,\n        response_method=response_method,\n        pos_label=None,\n        return_response_method_used=return_response_method_used,\n    )\n    assert_allclose(results[0], classifier.decision_function(X))\n    assert results[1] == 1\n    if return_response_method_used:\n        assert results[2] == \"decision_function\"\n\n    # when forcing `pos_label=classifier.classes_[0]`\n    results = _get_response_values(\n        classifier,\n        X,\n        response_method=response_method,\n        pos_label=classifier.classes_[0],\n        return_response_method_used=return_response_method_used,\n    )\n    assert_allclose(results[0], classifier.decision_function(X) * -1)\n    assert results[1] == 0\n    if return_response_me"}, {"start_line": 12000, "end_line": 14000, "belongs_to": {"file_name": "_scorer.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/metrics", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "  \"overridden by passed metadata if provided. Please pass them either \"\n                \"as metadata or kwargs to `make_scorer`.\"\n            ),\n            kwargs=kwargs,\n        )\n        self._metadata_request = MetadataRequest(owner=self.__class__.__name__)\n        for param, alias in kwargs.items():\n            self._metadata_request.score.add_request(param=param, alias=alias)\n        return self\n\n\nclass _Scorer(_BaseScorer):\n    def _score(self, method_caller, estimator, X, y_true, **kwargs):\n        \"\"\"Evaluate the response method of `estimator` on `X` and `y_true`.\n\n        Parameters\n        ----------\n        method_caller : callable\n            Returns predictions given an estimator, method name, and other\n            arguments, potentially caching results.\n\n        estimator : object\n            Trained estimator to use for scoring.\n\n        X : {array-like, sparse matrix}\n            Test data that will be fed to clf.decision_function or\n            clf.predict_proba.\n\n        y_true : array-like\n            Gold standard target values for X. These must be class labels,\n            not decision function values.\n\n        **kwargs : dict\n            Other parameters passed to the scorer. Refer to\n            :func:`set_score_request` for more details.\n\n        Returns\n        -------\n        score : float\n            Score function applied to prediction of estimator on X.\n        \"\"\"\n        self._warn_overlap(\n            message=(\n                \"There is an overlap between set kwargs of this scorer instance and\"\n                \" passed metadata. Please pass them either as kwargs to `make_scorer`\"\n                \" or metadata, but not both.\"\n            ),\n            kwargs=kwargs,\n        )\n\n        pos_label = None if is_regressor(estimator) else self._get_pos_label()\n        response_method = _check_response_method(estimator, self._response_method)\n        y_pred = method_caller(\n            estimator,\n            _get_response_method_name(respon"}, {"start_line": 82000, "end_line": 84000, "belongs_to": {"file_name": "validation.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/utils", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "nction\",\n            \"predict\"} or list of such str\n        Specifies the response method to use get prediction from an estimator\n        (i.e. :term:`predict_proba`, :term:`predict_log_proba`,\n        :term:`decision_function` or :term:`predict`). Possible choices are:\n        - if `str`, it corresponds to the name to the method to return;\n        - if a list of `str`, it provides the method names in order of\n          preference. The method returned corresponds to the first method in\n          the list and which is implemented by `estimator`.\n\n    Returns\n    -------\n    prediction_method : callable\n        Prediction method of estimator.\n\n    Raises\n    ------\n    AttributeError\n        If `response_method` is not available in `estimator`.\n    \"\"\"\n    if isinstance(response_method, str):\n        list_methods = [response_method]\n    else:\n        list_methods = response_method\n\n    prediction_method = [getattr(estimator, method, None) for method in list_methods]\n    prediction_method = reduce(lambda x, y: x or y, prediction_method)\n    if prediction_method is None:\n        raise AttributeError(\n            f\"{estimator.__class__.__name__} has none of the following attributes: \"\n            f\"{', '.join(list_methods)}.\"\n        )\n\n    return prediction_method\n\n\ndef _check_method_params(X, params, indices=None):\n    \"\"\"Check and validate the parameters passed to a specific\n    method like `fit`.\n\n    Parameters\n    ----------\n    X : array-like of shape (n_samples, n_features)\n        Data array.\n\n    params : dict\n        Dictionary containing the parameters passed to the method.\n\n    indices : array-like of shape (n_samples,), default=None\n        Indices to be selected if the parameter has the same size as `X`.\n\n    Returns\n    -------\n    method_params_validated : dict\n        Validated parameters. We ensure that the values support indexing.\n    \"\"\"\n    from sklearn.utils import _safe_indexing\n\n    method_params_validated = {}\n    for param_key, param_value in p"}, {"start_line": 12000, "end_line": 14000, "belongs_to": {"file_name": "test_response.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/utils/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "tion\"],\n        return_response_method_used=True,\n    )\n    assert_allclose(y_pred, classifier.predict_proba(X_binary)[:, 1])\n    assert pos_label == 1\n    assert response_method == \"predict_proba\"\n\n    # it should use `decision_function`\n    y_pred, pos_label, response_method = _get_response_values(\n        classifier,\n        X_binary,\n        response_method=[\"decision_function\", \"predict_proba\"],\n        return_response_method_used=True,\n    )\n    assert_allclose(y_pred, classifier.decision_function(X_binary))\n    assert pos_label == 1\n    assert response_method == \"decision_function\"\n\n\n@pytest.mark.parametrize(\n    \"response_method\", [\"predict_proba\", \"decision_function\", \"predict\"]\n)\ndef test_get_response_values_multilabel_indicator(response_method):\n    X, Y = make_multilabel_classification(random_state=0)\n    estimator = ClassifierChain(LogisticRegression()).fit(X, Y)\n\n    y_pred, pos_label = _get_response_values(\n        estimator, X, response_method=response_method\n    )\n    assert pos_label is None\n    assert y_pred.shape == Y.shape\n\n    if response_method == \"predict_proba\":\n        assert np.logical_and(y_pred >= 0, y_pred <= 1).all()\n    elif response_method == \"decision_function\":\n        # values returned by `decision_function` are not bounded in [0, 1]\n        assert (y_pred < 0).sum() > 0\n        assert (y_pred > 1).sum() > 0\n    else:  # response_method == \"predict\"\n        assert np.logical_or(y_pred == 0, y_pred == 1).all()\n\n\ndef test_response_values_type_of_target_on_classes_no_warning():\n    \"\"\"\n    Ensure `_get_response_values` doesn't raise spurious warning.\n\n    \"The number of unique classes is greater than > 50% of samples\"\n    warning should not be raised when calling `type_of_target(classes_)`.\n\n    Non-regression test for issue #31583.\n    \"\"\"\n    X = np.random.RandomState(0).randn(120, 3)\n    # 30 classes, less than 50% of number of samples\n    y = np.repeat(np.arange(30), 4)\n\n    clf = LogisticRegression().fit(X, y)\n\n    with warnings"}, {"start_line": 10000, "end_line": 12000, "belongs_to": {"file_name": "test_response.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/utils/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "      return_response_method_used=return_response_method_used,\n    )\n    assert_allclose(results[0], classifier.decision_function(X_binary))\n    assert results[1] == 1\n    if return_response_method_used:\n        assert results[2] == \"decision_function\"\n\n    results = _get_response_values_binary(\n        classifier,\n        X_binary,\n        response_method=\"decision_function\",\n        pos_label=0,\n        return_response_method_used=return_response_method_used,\n    )\n    assert_allclose(results[0], classifier.decision_function(X_binary) * -1)\n    assert results[1] == 0\n    if return_response_method_used:\n        assert results[2] == \"decision_function\"\n\n\n@pytest.mark.parametrize(\n    \"estimator, response_method\",\n    [\n        (DecisionTreeClassifier(max_depth=2, random_state=0), \"predict_proba\"),\n        (DecisionTreeClassifier(max_depth=2, random_state=0), \"predict_log_proba\"),\n        (LogisticRegression(), \"decision_function\"),\n    ],\n)\ndef test_get_response_values_multiclass(estimator, response_method):\n    \"\"\"Check that we can call `_get_response_values` with a multiclass estimator.\n    It should return the predictions untouched.\n    \"\"\"\n    estimator.fit(X, y)\n    predictions, pos_label = _get_response_values(\n        estimator, X, response_method=response_method\n    )\n\n    assert pos_label is None\n    assert predictions.shape == (X.shape[0], len(estimator.classes_))\n    if response_method == \"predict_proba\":\n        assert np.logical_and(predictions >= 0, predictions <= 1).all()\n    elif response_method == \"predict_log_proba\":\n        assert (predictions <= 0.0).all()\n\n\ndef test_get_response_values_with_response_list():\n    \"\"\"Check the behaviour of passing a list of responses to `_get_response_values`.\"\"\"\n    classifier = LogisticRegression().fit(X_binary, y_binary)\n\n    # it should use `predict_proba`\n    y_pred, pos_label, response_method = _get_response_values(\n        classifier,\n        X_binary,\n        response_method=[\"predict_proba\", \"decision_func"}, {"start_line": 3000, "end_line": 5000, "belongs_to": {"file_name": "test_response.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/utils/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "array_equal(results[0], prediction_method(X))\n    assert results[1] is None\n    if return_response_method_used:\n        assert results[2] == chosen_response_method\n\n\n@pytest.mark.parametrize(\n    \"response_method\",\n    [\"predict_proba\", \"decision_function\", \"predict\", \"predict_log_proba\"],\n)\ndef test_get_response_values_classifier_unknown_pos_label(response_method):\n    \"\"\"Check that `_get_response_values` raises the proper error message with\n    classifier.\"\"\"\n    X, y = make_classification(n_samples=10, n_classes=2, random_state=0)\n    classifier = LogisticRegression().fit(X, y)\n\n    # provide a `pos_label` which is not in `y`\n    err_msg = r\"pos_label=whatever is not a valid label: It should be one of \\[0 1\\]\"\n    with pytest.raises(ValueError, match=err_msg):\n        _get_response_values(\n            classifier,\n            X,\n            response_method=response_method,\n            pos_label=\"whatever\",\n        )\n\n\n@pytest.mark.parametrize(\"response_method\", [\"predict_proba\", \"predict_log_proba\"])\ndef test_get_response_values_classifier_inconsistent_y_pred_for_binary_proba(\n    response_method,\n):\n    \"\"\"Check that `_get_response_values` will raise an error when `y_pred` has a\n    single class with `predict_proba`.\"\"\"\n    X, y_two_class = make_classification(n_samples=10, n_classes=2, random_state=0)\n    y_single_class = np.zeros_like(y_two_class)\n    classifier = DecisionTreeClassifier().fit(X, y_single_class)\n\n    err_msg = (\n        r\"Got predict_proba of shape \\(10, 1\\), but need classifier with \"\n        r\"two classes\"\n    )\n    with pytest.raises(ValueError, match=err_msg):\n        _get_response_values(classifier, X, response_method=response_method)\n\n\n@pytest.mark.parametrize(\"return_response_method_used\", [True, False])\ndef test_get_response_values_binary_classifier_decision_function(\n    return_response_method_used,\n):\n    \"\"\"Check the behaviour of `_get_response_values` with `decision_function`\n    and binary classifier.\"\"\"\n    X, y = make_classificati"}, {"start_line": 11000, "end_line": 13000, "belongs_to": {"file_name": "test_response.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/utils/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "ator, response_method):\n    \"\"\"Check that we can call `_get_response_values` with a multiclass estimator.\n    It should return the predictions untouched.\n    \"\"\"\n    estimator.fit(X, y)\n    predictions, pos_label = _get_response_values(\n        estimator, X, response_method=response_method\n    )\n\n    assert pos_label is None\n    assert predictions.shape == (X.shape[0], len(estimator.classes_))\n    if response_method == \"predict_proba\":\n        assert np.logical_and(predictions >= 0, predictions <= 1).all()\n    elif response_method == \"predict_log_proba\":\n        assert (predictions <= 0.0).all()\n\n\ndef test_get_response_values_with_response_list():\n    \"\"\"Check the behaviour of passing a list of responses to `_get_response_values`.\"\"\"\n    classifier = LogisticRegression().fit(X_binary, y_binary)\n\n    # it should use `predict_proba`\n    y_pred, pos_label, response_method = _get_response_values(\n        classifier,\n        X_binary,\n        response_method=[\"predict_proba\", \"decision_function\"],\n        return_response_method_used=True,\n    )\n    assert_allclose(y_pred, classifier.predict_proba(X_binary)[:, 1])\n    assert pos_label == 1\n    assert response_method == \"predict_proba\"\n\n    # it should use `decision_function`\n    y_pred, pos_label, response_method = _get_response_values(\n        classifier,\n        X_binary,\n        response_method=[\"decision_function\", \"predict_proba\"],\n        return_response_method_used=True,\n    )\n    assert_allclose(y_pred, classifier.decision_function(X_binary))\n    assert pos_label == 1\n    assert response_method == \"decision_function\"\n\n\n@pytest.mark.parametrize(\n    \"response_method\", [\"predict_proba\", \"decision_function\", \"predict\"]\n)\ndef test_get_response_values_multilabel_indicator(response_method):\n    X, Y = make_multilabel_classification(random_state=0)\n    estimator = ClassifierChain(LogisticRegression()).fit(X, Y)\n\n    y_pred, pos_label = _get_response_values(\n        estimator, X, response_method=response_method\n    )\n    "}, {"start_line": 20000, "end_line": 22000, "belongs_to": {"file_name": "_scorer.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/metrics", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "Error(\n                f\"{err_msg} Duplicate elements were found in\"\n                f\" the given list. {scoring!r}\"\n            )\n        elif len(keys) > 0:\n            if not all(isinstance(k, str) for k in keys):\n                if any(callable(k) for k in keys):\n                    raise ValueError(\n                        f\"{err_msg} One or more of the elements \"\n                        \"were callables. Use a dict of score \"\n                        \"name mapped to the scorer callable. \"\n                        f\"Got {scoring!r}\"\n                    )\n                else:\n                    raise ValueError(\n                        f\"{err_msg} Non-string types were found \"\n                        f\"in the given list. Got {scoring!r}\"\n                    )\n            scorers = {\n                scorer: check_scoring(estimator, scoring=scorer) for scorer in scoring\n            }\n        else:\n            raise ValueError(f\"{err_msg} Empty list was given. {scoring!r}\")\n\n    elif isinstance(scoring, dict):\n        keys = set(scoring)\n        if not all(isinstance(k, str) for k in keys):\n            raise ValueError(\n                \"Non-string types were found in the keys of \"\n                f\"the given dict. scoring={scoring!r}\"\n            )\n        if len(keys) == 0:\n            raise ValueError(f\"An empty dict was passed. {scoring!r}\")\n        scorers = {\n            key: check_scoring(estimator, scoring=scorer)\n            for key, scorer in scoring.items()\n        }\n    else:\n        raise ValueError(err_msg_generic)\n\n    return scorers\n\n\ndef _get_response_method_name(response_method):\n    try:\n        return response_method.__name__\n    except AttributeError:\n        return _get_response_method_name(response_method.func)\n\n\n@validate_params(\n    {\n        \"score_func\": [callable],\n        \"response_method\": [\n            None,\n            list,\n            tuple,\n            StrOptions({\"predict\", \"predict_proba\", \"decision_function\"}),\n            Hidden"}, {"start_line": 0, "end_line": 2000, "belongs_to": {"file_name": "test_response.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/utils/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "import warnings\n\nimport numpy as np\nimport pytest\n\nfrom sklearn.datasets import (\n    load_iris,\n    make_classification,\n    make_multilabel_classification,\n    make_regression,\n)\nfrom sklearn.ensemble import IsolationForest\nfrom sklearn.linear_model import (\n    LinearRegression,\n    LogisticRegression,\n)\nfrom sklearn.multioutput import ClassifierChain\nfrom sklearn.preprocessing import scale\nfrom sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\nfrom sklearn.utils._mocking import _MockEstimatorOnOffPrediction\nfrom sklearn.utils._response import _get_response_values, _get_response_values_binary\nfrom sklearn.utils._testing import assert_allclose, assert_array_equal\n\nX, y = load_iris(return_X_y=True)\n# scale the data to avoid ConvergenceWarning with LogisticRegression\nX = scale(X, copy=False)\nX_binary, y_binary = X[:100], y[:100]\n\n\n@pytest.mark.parametrize(\n    \"response_method\", [\"decision_function\", \"predict_proba\", \"predict_log_proba\"]\n)\ndef test_get_response_values_regressor_error(response_method):\n    \"\"\"Check the error message with regressor an not supported response\n    method.\"\"\"\n    my_estimator = _MockEstimatorOnOffPrediction(response_methods=[response_method])\n    X = \"mocking_data\", \"mocking_target\"\n    err_msg = f\"{my_estimator.__class__.__name__} should either be a classifier\"\n    with pytest.raises(ValueError, match=err_msg):\n        _get_response_values(my_estimator, X, response_method=response_method)\n\n\n@pytest.mark.parametrize(\"return_response_method_used\", [True, False])\ndef test_get_response_values_regressor(return_response_method_used):\n    \"\"\"Check the behaviour of `_get_response_values` with regressor.\"\"\"\n    X, y = make_regression(n_samples=10, random_state=0)\n    regressor = LinearRegression().fit(X, y)\n    results = _get_response_values(\n        regressor,\n        X,\n        response_method=\"predict\",\n        return_response_method_used=return_response_method_used,\n    )\n    assert_array_equal(results[0], regressor.predict(X)"}], "retrieved_count": 10, "cost_time": 1.3199741840362549}
{"question": "How does the `pos_label` parameter resolution process handle the case where a user provides an explicit `pos_label` value versus relying on the default `estimators.classes_[1]` assumption in multi-class classification scenarios?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"start_line": 96000, "end_line": 98000, "belongs_to": {"file_name": "validation.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/utils", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "it will be returned.\n\n    Raises\n    ------\n    ValueError\n        In the case that `y_true` does not have label in {-1, 1} or {0, 1},\n        it will raise a `ValueError`.\n    \"\"\"\n    # ensure binary classification if pos_label is not specified\n    # classes.dtype.kind in ('O', 'U', 'S') is required to avoid\n    # triggering a FutureWarning by calling np.array_equal(a, b)\n    # when elements in the two arrays are not comparable.\n    if pos_label is None:\n        # Compute classes only if pos_label is not specified:\n        xp, _, device = get_namespace_and_device(y_true)\n        classes = xp.unique_values(y_true)\n        if (\n            (_is_numpy_namespace(xp) and classes.dtype.kind in \"OUS\")\n            or classes.shape[0] > 2\n            or not (\n                xp.all(classes == xp.asarray([0, 1], device=device))\n                or xp.all(classes == xp.asarray([-1, 1], device=device))\n                or xp.all(classes == xp.asarray([0], device=device))\n                or xp.all(classes == xp.asarray([-1], device=device))\n                or xp.all(classes == xp.asarray([1], device=device))\n            )\n        ):\n            classes = _convert_to_numpy(classes, xp=xp)\n            classes_repr = \", \".join([repr(c) for c in classes.tolist()])\n            raise ValueError(\n                f\"y_true takes value in {{{classes_repr}}} and pos_label is not \"\n                \"specified: either make y_true take value in {0, 1} or \"\n                \"{-1, 1} or pass pos_label explicitly.\"\n            )\n        pos_label = 1\n\n    return pos_label\n\n\ndef _to_object_array(sequence):\n    \"\"\"Convert sequence to a 1-D NumPy array of object dtype.\n\n    numpy.array constructor has a similar use but it's output\n    is ambiguous. It can be 1-D NumPy array of object dtype if\n    the input is a ragged array, but if the input is a list of\n    equal length arrays, then the output is a 2D numpy.array.\n    _to_object_array solves this ambiguity by guarantying that\n    the output is a 1-D "}, {"start_line": 95000, "end_line": 97000, "belongs_to": {"file_name": "validation.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/utils", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": " Observed \"\n                f\"values: {unexpected_cst.tolist()}.\"\n            )\n\n        monotonic_cst = np.asarray(monotonic_cst, dtype=np.int8)\n        if monotonic_cst.shape[0] != estimator.n_features_in_:\n            raise ValueError(\n                f\"monotonic_cst has shape {monotonic_cst.shape} but the input data \"\n                f\"X has {estimator.n_features_in_} features.\"\n            )\n    return monotonic_cst\n\n\ndef _check_pos_label_consistency(pos_label, y_true):\n    \"\"\"Check if `pos_label` need to be specified or not.\n\n    In binary classification, we fix `pos_label=1` if the labels are in the set\n    {-1, 1} or {0, 1}. Otherwise, we raise an error asking to specify the\n    `pos_label` parameters.\n\n    Parameters\n    ----------\n    pos_label : int, float, bool, str or None\n        The positive label.\n    y_true : ndarray of shape (n_samples,)\n        The target vector.\n\n    Returns\n    -------\n    pos_label : int, float, bool or str\n        If `pos_label` can be inferred, it will be returned.\n\n    Raises\n    ------\n    ValueError\n        In the case that `y_true` does not have label in {-1, 1} or {0, 1},\n        it will raise a `ValueError`.\n    \"\"\"\n    # ensure binary classification if pos_label is not specified\n    # classes.dtype.kind in ('O', 'U', 'S') is required to avoid\n    # triggering a FutureWarning by calling np.array_equal(a, b)\n    # when elements in the two arrays are not comparable.\n    if pos_label is None:\n        # Compute classes only if pos_label is not specified:\n        xp, _, device = get_namespace_and_device(y_true)\n        classes = xp.unique_values(y_true)\n        if (\n            (_is_numpy_namespace(xp) and classes.dtype.kind in \"OUS\")\n            or classes.shape[0] > 2\n            or not (\n                xp.all(classes == xp.asarray([0, 1], device=device))\n                or xp.all(classes == xp.asarray([-1, 1], device=device))\n                or xp.all(classes == xp.asarray([0], device=device))\n                or xp.all(c"}, {"start_line": 7000, "end_line": 9000, "belongs_to": {"file_name": "_response.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/utils", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "label : int, float, bool, str or None\n        The class considered as the positive class when computing\n        the metrics. Returns `None` if `estimator` is a regressor or an outlier\n        detector.\n\n    response_method_used : str\n        The response method used to compute the response values. Only returned\n        if `return_response_method_used` is `True`.\n\n        .. versionadded:: 1.4\n\n    Raises\n    ------\n    ValueError\n        If `pos_label` is not a valid label.\n        If the shape of `y_pred` is not consistent for binary classifier.\n        If the response method can be applied to a classifier only and\n        `estimator` is a regressor.\n    \"\"\"\n    from sklearn.base import is_classifier, is_outlier_detector\n\n    if is_classifier(estimator):\n        prediction_method = _check_response_method(estimator, response_method)\n        classes = estimator.classes_\n        target_type = type_of_target(classes)\n\n        if target_type in (\"binary\", \"multiclass\"):\n            if pos_label is not None and pos_label not in classes.tolist():\n                raise ValueError(\n                    f\"pos_label={pos_label} is not a valid label: It should be \"\n                    f\"one of {classes}\"\n                )\n            elif pos_label is None and target_type == \"binary\":\n                pos_label = classes[-1]\n\n        y_pred = prediction_method(X)\n\n        if prediction_method.__name__ in (\"predict_proba\", \"predict_log_proba\"):\n            y_pred = _process_predict_proba(\n                y_pred=y_pred,\n                target_type=target_type,\n                classes=classes,\n                pos_label=pos_label,\n            )\n        elif prediction_method.__name__ == \"decision_function\":\n            y_pred = _process_decision_function(\n                y_pred=y_pred,\n                target_type=target_type,\n                classes=classes,\n                pos_label=pos_label,\n            )\n    elif is_outlier_detector(estimator):\n        prediction_method = _check"}, {"start_line": 11000, "end_line": 12149, "belongs_to": {"file_name": "_response.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/utils", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": " (n_samples,)\n        Target scores calculated from the provided response_method\n        and pos_label.\n\n    pos_label : int, float, bool or str\n        The class considered as the positive class when computing\n        the metrics.\n\n    response_method_used : str\n        The response method used to compute the response values. Only returned\n        if `return_response_method_used` is `True`.\n\n        .. versionadded:: 1.5\n    \"\"\"\n    classification_error = \"Expected 'estimator' to be a binary classifier.\"\n\n    check_is_fitted(estimator)\n    if not is_classifier(estimator):\n        raise ValueError(\n            classification_error + f\" Got {estimator.__class__.__name__} instead.\"\n        )\n    elif len(estimator.classes_) != 2:\n        raise ValueError(\n            classification_error + f\" Got {len(estimator.classes_)} classes instead.\"\n        )\n\n    if response_method == \"auto\":\n        response_method = [\"predict_proba\", \"decision_function\"]\n\n    return _get_response_values(\n        estimator,\n        X,\n        response_method,\n        pos_label=pos_label,\n        return_response_method_used=return_response_method_used,\n    )\n"}, {"start_line": 6000, "end_line": 8000, "belongs_to": {"file_name": "_response.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/utils", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "ecision_function` or :term:`predict`). Possible choices are:\n\n        - if `str`, it corresponds to the name to the method to return;\n        - if a list of `str`, it provides the method names in order of\n          preference. The method returned corresponds to the first method in\n          the list and which is implemented by `estimator`.\n\n    pos_label : int, float, bool or str, default=None\n        The class considered as the positive class when computing\n        the metrics. If `None` and target is 'binary', `estimators.classes_[1]` is\n        considered as the positive class.\n\n    return_response_method_used : bool, default=False\n        Whether to return the response method used to compute the response\n        values.\n\n        .. versionadded:: 1.4\n\n    Returns\n    -------\n    y_pred : ndarray of shape (n_samples,), (n_samples, n_classes) or \\\n            (n_samples, n_outputs)\n        Target scores calculated from the provided `response_method`\n        and `pos_label`.\n\n    pos_label : int, float, bool, str or None\n        The class considered as the positive class when computing\n        the metrics. Returns `None` if `estimator` is a regressor or an outlier\n        detector.\n\n    response_method_used : str\n        The response method used to compute the response values. Only returned\n        if `return_response_method_used` is `True`.\n\n        .. versionadded:: 1.4\n\n    Raises\n    ------\n    ValueError\n        If `pos_label` is not a valid label.\n        If the shape of `y_pred` is not consistent for binary classifier.\n        If the response method can be applied to a classifier only and\n        `estimator` is a regressor.\n    \"\"\"\n    from sklearn.base import is_classifier, is_outlier_detector\n\n    if is_classifier(estimator):\n        prediction_method = _check_response_method(estimator, response_method)\n        classes = estimator.classes_\n        target_type = type_of_target(classes)\n\n        if target_type in (\"binary\", \"multiclass\"):\n            if pos_"}, {"start_line": 5000, "end_line": 7000, "belongs_to": {"file_name": "_response.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/utils", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": ")`;\n    - for outlier detection, it is a 1d array of shape `(n_samples,)`;\n    - for regression, it is a 1d array of shape `(n_samples,)`.\n\n    If `estimator` is a binary classifier, also return the label for the\n    effective positive class.\n\n    This utility is used primarily in the displays and the scikit-learn scorers.\n\n    .. versionadded:: 1.3\n\n    Parameters\n    ----------\n    estimator : estimator instance\n        Fitted classifier, outlier detector, or regressor or a\n        fitted :class:`~sklearn.pipeline.Pipeline` in which the last estimator is a\n        classifier, an outlier detector, or a regressor.\n\n    X : {array-like, sparse matrix} of shape (n_samples, n_features)\n        Input values.\n\n    response_method : {\"predict_proba\", \"predict_log_proba\", \"decision_function\", \\\n            \"predict\"} or list of such str\n        Specifies the response method to use get prediction from an estimator\n        (i.e. :term:`predict_proba`, :term:`predict_log_proba`,\n        :term:`decision_function` or :term:`predict`). Possible choices are:\n\n        - if `str`, it corresponds to the name to the method to return;\n        - if a list of `str`, it provides the method names in order of\n          preference. The method returned corresponds to the first method in\n          the list and which is implemented by `estimator`.\n\n    pos_label : int, float, bool or str, default=None\n        The class considered as the positive class when computing\n        the metrics. If `None` and target is 'binary', `estimators.classes_[1]` is\n        considered as the positive class.\n\n    return_response_method_used : bool, default=False\n        Whether to return the response method used to compute the response\n        values.\n\n        .. versionadded:: 1.4\n\n    Returns\n    -------\n    y_pred : ndarray of shape (n_samples,), (n_samples, n_classes) or \\\n            (n_samples, n_outputs)\n        Target scores calculated from the provided `response_method`\n        and `pos_label`.\n\n    pos_"}, {"start_line": 8000, "end_line": 10000, "belongs_to": {"file_name": "_response.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/utils", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "label is not None and pos_label not in classes.tolist():\n                raise ValueError(\n                    f\"pos_label={pos_label} is not a valid label: It should be \"\n                    f\"one of {classes}\"\n                )\n            elif pos_label is None and target_type == \"binary\":\n                pos_label = classes[-1]\n\n        y_pred = prediction_method(X)\n\n        if prediction_method.__name__ in (\"predict_proba\", \"predict_log_proba\"):\n            y_pred = _process_predict_proba(\n                y_pred=y_pred,\n                target_type=target_type,\n                classes=classes,\n                pos_label=pos_label,\n            )\n        elif prediction_method.__name__ == \"decision_function\":\n            y_pred = _process_decision_function(\n                y_pred=y_pred,\n                target_type=target_type,\n                classes=classes,\n                pos_label=pos_label,\n            )\n    elif is_outlier_detector(estimator):\n        prediction_method = _check_response_method(estimator, response_method)\n        y_pred, pos_label = prediction_method(X), None\n    else:  # estimator is a regressor\n        if response_method != \"predict\":\n            raise ValueError(\n                f\"{estimator.__class__.__name__} should either be a classifier to be \"\n                f\"used with response_method={response_method} or the response_method \"\n                \"should be 'predict'. Got a regressor with response_method=\"\n                f\"{response_method} instead.\"\n            )\n        prediction_method = estimator.predict\n        y_pred, pos_label = prediction_method(X), None\n\n    if return_response_method_used:\n        return y_pred, pos_label, prediction_method.__name__\n    return y_pred, pos_label\n\n\ndef _get_response_values_binary(\n    estimator, X, response_method, pos_label=None, return_response_method_used=False\n):\n    \"\"\"Compute the response values of a binary classifier.\n\n    Parameters\n    ----------\n    estimator : estimator instance\n    "}, {"start_line": 10000, "end_line": 12000, "belongs_to": {"file_name": "_response.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/utils", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "    Fitted classifier or a fitted :class:`~sklearn.pipeline.Pipeline`\n        in which the last estimator is a binary classifier.\n\n    X : {array-like, sparse matrix} of shape (n_samples, n_features)\n        Input values.\n\n    response_method : {'auto', 'predict_proba', 'decision_function'}\n        Specifies whether to use :term:`predict_proba` or\n        :term:`decision_function` as the target response. If set to 'auto',\n        :term:`predict_proba` is tried first and if it does not exist\n        :term:`decision_function` is tried next.\n\n    pos_label : int, float, bool or str, default=None\n        The class considered as the positive class when computing\n        the metrics. By default, `estimators.classes_[1]` is\n        considered as the positive class.\n\n    return_response_method_used : bool, default=False\n        Whether to return the response method used to compute the response\n        values.\n\n        .. versionadded:: 1.5\n\n    Returns\n    -------\n    y_pred : ndarray of shape (n_samples,)\n        Target scores calculated from the provided response_method\n        and pos_label.\n\n    pos_label : int, float, bool or str\n        The class considered as the positive class when computing\n        the metrics.\n\n    response_method_used : str\n        The response method used to compute the response values. Only returned\n        if `return_response_method_used` is `True`.\n\n        .. versionadded:: 1.5\n    \"\"\"\n    classification_error = \"Expected 'estimator' to be a binary classifier.\"\n\n    check_is_fitted(estimator)\n    if not is_classifier(estimator):\n        raise ValueError(\n            classification_error + f\" Got {estimator.__class__.__name__} instead.\"\n        )\n    elif len(estimator.classes_) != 2:\n        raise ValueError(\n            classification_error + f\" Got {len(estimator.classes_)} classes instead.\"\n        )\n\n    if response_method == \"auto\":\n        response_method = [\"predict_proba\", \"decision_function\"]\n\n    return _get_response_values(\n      "}, {"start_line": 4000, "end_line": 6000, "belongs_to": {"file_name": "_response.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/utils", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "s as reported by `estimator.classes_`.\n\n    pos_label : int, float, bool or str\n        Only used with binary and multiclass targets.\n\n    Returns\n    -------\n    y_pred : ndarray of shape (n_samples,), (n_samples, n_classes) or \\\n            (n_samples, n_output)\n        Compressed predictions format as requested by the metrics.\n    \"\"\"\n    if target_type == \"binary\" and pos_label == classes[0]:\n        return -1 * y_pred\n    return y_pred\n\n\ndef _get_response_values(\n    estimator,\n    X,\n    response_method,\n    pos_label=None,\n    return_response_method_used=False,\n):\n    \"\"\"Compute the response values of a classifier, an outlier detector, or a regressor.\n\n    The response values are predictions such that it follows the following shape:\n\n    - for binary classification, it is a 1d array of shape `(n_samples,)`;\n    - for multiclass classification, it is a 2d array of shape `(n_samples, n_classes)`;\n    - for multilabel classification, it is a 2d array of shape `(n_samples, n_outputs)`;\n    - for outlier detection, it is a 1d array of shape `(n_samples,)`;\n    - for regression, it is a 1d array of shape `(n_samples,)`.\n\n    If `estimator` is a binary classifier, also return the label for the\n    effective positive class.\n\n    This utility is used primarily in the displays and the scikit-learn scorers.\n\n    .. versionadded:: 1.3\n\n    Parameters\n    ----------\n    estimator : estimator instance\n        Fitted classifier, outlier detector, or regressor or a\n        fitted :class:`~sklearn.pipeline.Pipeline` in which the last estimator is a\n        classifier, an outlier detector, or a regressor.\n\n    X : {array-like, sparse matrix} of shape (n_samples, n_features)\n        Input values.\n\n    response_method : {\"predict_proba\", \"predict_log_proba\", \"decision_function\", \\\n            \"predict\"} or list of such str\n        Specifies the response method to use get prediction from an estimator\n        (i.e. :term:`predict_proba`, :term:`predict_log_proba`,\n        :term:`d"}, {"start_line": 2000, "end_line": 4000, "belongs_to": {"file_name": "_response.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/utils", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "ed.shape[1] < 2:\n        # We don't handle classifiers trained on a single class.\n        raise ValueError(\n            f\"Got predict_proba of shape {y_pred.shape}, but need \"\n            \"classifier with two classes.\"\n        )\n\n    if target_type == \"binary\":\n        col_idx = np.flatnonzero(classes == pos_label)[0]\n        return y_pred[:, col_idx]\n    elif target_type == \"multilabel-indicator\":\n        # Use a compress format of shape `(n_samples, n_output)`.\n        # Only `MLPClassifier` and `RidgeClassifier` return an array of shape\n        # `(n_samples, n_outputs)`.\n        if isinstance(y_pred, list):\n            # list of arrays of shape `(n_samples, 2)`\n            return np.vstack([p[:, -1] for p in y_pred]).T\n        else:\n            # array of shape `(n_samples, n_outputs)`\n            return y_pred\n\n    return y_pred\n\n\ndef _process_decision_function(*, y_pred, target_type, classes, pos_label):\n    \"\"\"Get the response values when the response method is `decision_function`.\n\n    This function process the `y_pred` array in the binary and multi-label cases.\n    In the binary case, it inverts the sign of the score if the positive label\n    is not `classes[1]`. In the multi-label case, it stacks the predictions if\n    they are not in the \"compressed\" format `(n_samples, n_outputs)`.\n\n    Parameters\n    ----------\n    y_pred : ndarray\n        Output of `estimator.decision_function`. The shape depends on the target type:\n\n        - for binary classification, it is a 1d array of shape `(n_samples,)` where the\n          sign is assuming that `classes[1]` is the positive class;\n        - for multiclass classification, it is a 2d array of shape\n          `(n_samples, n_classes)`;\n        - for multilabel classification, it is a 2d array of shape `(n_samples,\n          n_outputs)`.\n\n    target_type : {\"binary\", \"multiclass\", \"multilabel-indicator\"}\n        Type of the target.\n\n    classes : ndarray of shape (n_classes,) or list of such arrays\n        Class label"}], "retrieved_count": 10, "cost_time": 1.329270839691162}
{"question": "Why does the cache lookup strategy in _cached_call affect the performance characteristics of repeated metric computations across multiple cross-validation folds, and what are the trade-offs between cache hit rates and memory overhead for large-scale datasets?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"start_line": 4000, "end_line": 6000, "belongs_to": {"file_name": "_scorer.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/metrics", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "le_weight.\n            # Only the ones having `sample_weight` in their signature will receive it.\n            # This does not work for metadata other than sample_weight, and for those\n            # users have to enable metadata routing.\n            common_kwargs = {\n                arg: value for arg, value in kwargs.items() if arg != \"sample_weight\"\n            }\n            routed_params = Bunch(\n                **{name: Bunch(score=common_kwargs.copy()) for name in self._scorers}\n            )\n            if \"sample_weight\" in kwargs:\n                for name, scorer in self._scorers.items():\n                    if scorer._accept_sample_weight():\n                        routed_params[name].score[\"sample_weight\"] = kwargs[\n                            \"sample_weight\"\n                        ]\n\n        for name, scorer in self._scorers.items():\n            try:\n                if isinstance(scorer, _BaseScorer):\n                    score = scorer._score(\n                        cached_call, estimator, *args, **routed_params.get(name).score\n                    )\n                else:\n                    score = scorer(estimator, *args, **routed_params.get(name).score)\n                scores[name] = score\n            except Exception as e:\n                if self._raise_exc:\n                    raise e\n                else:\n                    scores[name] = format_exc()\n        return scores\n\n    def __repr__(self):\n        scorers = \", \".join([f'\"{s}\"' for s in self._scorers])\n        return f\"MultiMetricScorer({scorers})\"\n\n    def _accept_sample_weight(self):\n        # TODO(slep006): remove when metadata routing is the only way\n        return any(scorer._accept_sample_weight() for scorer in self._scorers.values())\n\n    def _use_cache(self, estimator):\n        \"\"\"Return True if using a cache is beneficial, thus when a response method will\n        be called several time.\n        \"\"\"\n        if len(self._scorers) == 1:  # Only one scorer\n            return False\n\n    "}, {"start_line": 1000, "end_line": 3000, "belongs_to": {"file_name": "_scorer.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/metrics", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "nced_accuracy_score,\n    brier_score_loss,\n    class_likelihood_ratios,\n    d2_absolute_error_score,\n    explained_variance_score,\n    f1_score,\n    jaccard_score,\n    log_loss,\n    matthews_corrcoef,\n    max_error,\n    mean_absolute_error,\n    mean_absolute_percentage_error,\n    mean_gamma_deviance,\n    mean_poisson_deviance,\n    mean_squared_error,\n    mean_squared_log_error,\n    median_absolute_error,\n    precision_score,\n    r2_score,\n    recall_score,\n    roc_auc_score,\n    root_mean_squared_error,\n    root_mean_squared_log_error,\n    top_k_accuracy_score,\n)\nfrom sklearn.metrics.cluster import (\n    adjusted_mutual_info_score,\n    adjusted_rand_score,\n    completeness_score,\n    fowlkes_mallows_score,\n    homogeneity_score,\n    mutual_info_score,\n    normalized_mutual_info_score,\n    rand_score,\n    v_measure_score,\n)\nfrom sklearn.utils import Bunch\nfrom sklearn.utils._param_validation import (\n    HasMethods,\n    Hidden,\n    StrOptions,\n    validate_params,\n)\nfrom sklearn.utils._response import _get_response_values\nfrom sklearn.utils.metadata_routing import (\n    MetadataRequest,\n    MetadataRouter,\n    MethodMapping,\n    _MetadataRequester,\n    _raise_for_params,\n    _routing_enabled,\n    get_routing_for_object,\n    process_routing,\n)\nfrom sklearn.utils.validation import _check_response_method\n\n\ndef _cached_call(cache, estimator, response_method, *args, **kwargs):\n    \"\"\"Call estimator with method and args and kwargs.\"\"\"\n    if cache is not None and response_method in cache:\n        return cache[response_method]\n\n    result, _ = _get_response_values(\n        estimator, *args, response_method=response_method, **kwargs\n    )\n\n    if cache is not None:\n        cache[response_method] = result\n\n    return result\n\n\nclass _MultimetricScorer:\n    \"\"\"Callable for multimetric scoring used to avoid repeated calls\n    to `predict_proba`, `predict`, and `decision_function`.\n\n    `_MultimetricScorer` will return a dictionary of scores corresponding to\n    the scorers in th"}, {"start_line": 2000, "end_line": 4000, "belongs_to": {"file_name": "_scorer.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/metrics", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "response import _get_response_values\nfrom sklearn.utils.metadata_routing import (\n    MetadataRequest,\n    MetadataRouter,\n    MethodMapping,\n    _MetadataRequester,\n    _raise_for_params,\n    _routing_enabled,\n    get_routing_for_object,\n    process_routing,\n)\nfrom sklearn.utils.validation import _check_response_method\n\n\ndef _cached_call(cache, estimator, response_method, *args, **kwargs):\n    \"\"\"Call estimator with method and args and kwargs.\"\"\"\n    if cache is not None and response_method in cache:\n        return cache[response_method]\n\n    result, _ = _get_response_values(\n        estimator, *args, response_method=response_method, **kwargs\n    )\n\n    if cache is not None:\n        cache[response_method] = result\n\n    return result\n\n\nclass _MultimetricScorer:\n    \"\"\"Callable for multimetric scoring used to avoid repeated calls\n    to `predict_proba`, `predict`, and `decision_function`.\n\n    `_MultimetricScorer` will return a dictionary of scores corresponding to\n    the scorers in the dictionary. Note that `_MultimetricScorer` can be\n    created with a dictionary with one key  (i.e. only one actual scorer).\n\n    Parameters\n    ----------\n    scorers : dict\n        Dictionary mapping names to callable scorers.\n\n    raise_exc : bool, default=True\n        Whether to raise the exception in `__call__` or not. If set to `False`\n        a formatted string of the exception details is passed as result of\n        the failing scorer.\n    \"\"\"\n\n    def __init__(self, *, scorers, raise_exc=True):\n        self._scorers = scorers\n        self._raise_exc = raise_exc\n\n    def __call__(self, estimator, *args, **kwargs):\n        \"\"\"Evaluate predicted target values.\"\"\"\n        scores = {}\n        cache = {} if self._use_cache(estimator) else None\n        cached_call = partial(_cached_call, cache)\n\n        if _routing_enabled():\n            routed_params = process_routing(self, \"score\", **kwargs)\n        else:\n            # Scorers all get the same args, and get all of them except samp"}, {"start_line": 5000, "end_line": 7000, "belongs_to": {"file_name": "_scorer.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/metrics", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "call, estimator, *args, **routed_params.get(name).score\n                    )\n                else:\n                    score = scorer(estimator, *args, **routed_params.get(name).score)\n                scores[name] = score\n            except Exception as e:\n                if self._raise_exc:\n                    raise e\n                else:\n                    scores[name] = format_exc()\n        return scores\n\n    def __repr__(self):\n        scorers = \", \".join([f'\"{s}\"' for s in self._scorers])\n        return f\"MultiMetricScorer({scorers})\"\n\n    def _accept_sample_weight(self):\n        # TODO(slep006): remove when metadata routing is the only way\n        return any(scorer._accept_sample_weight() for scorer in self._scorers.values())\n\n    def _use_cache(self, estimator):\n        \"\"\"Return True if using a cache is beneficial, thus when a response method will\n        be called several time.\n        \"\"\"\n        if len(self._scorers) == 1:  # Only one scorer\n            return False\n\n        counter = Counter(\n            [\n                _check_response_method(estimator, scorer._response_method).__name__\n                for scorer in self._scorers.values()\n                if isinstance(scorer, _BaseScorer)\n            ]\n        )\n        if any(val > 1 for val in counter.values()):\n            # The exact same response method or iterable of response methods\n            # will be called more than once.\n            return True\n\n        return False\n\n    def get_metadata_routing(self):\n        \"\"\"Get metadata routing of this object.\n\n        Please check :ref:`User Guide <metadata_routing>` on how the routing\n        mechanism works.\n\n        .. versionadded:: 1.3\n\n        Returns\n        -------\n        routing : MetadataRouter\n            A :class:`~utils.metadata_routing.MetadataRouter` encapsulating\n            routing information.\n        \"\"\"\n        return MetadataRouter(owner=self.__class__.__name__).add(\n            **self._scorers,\n            method_mapping=Me"}, {"start_line": 15000, "end_line": 17000, "belongs_to": {"file_name": "test_validation.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/model_selection/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "suffer from\n        # large statistical fluctuations due to slicing small datasets,\n        # we pass the cross-validation instance\n        check_cross_validate_single_metric(est, X, y, scores, cv)\n        check_cross_validate_multi_metric(est, X, y, scores, cv)\n\n\ndef check_cross_validate_single_metric(clf, X, y, scores, cv):\n    (\n        train_mse_scores,\n        test_mse_scores,\n        train_r2_scores,\n        test_r2_scores,\n        fitted_estimators,\n    ) = scores\n    # Test single metric evaluation when scoring is string or singleton list\n    for return_train_score, dict_len in ((True, 4), (False, 3)):\n        # Single metric passed as a string\n        if return_train_score:\n            mse_scores_dict = cross_validate(\n                clf,\n                X,\n                y,\n                scoring=\"neg_mean_squared_error\",\n                return_train_score=True,\n                cv=cv,\n            )\n            assert_array_almost_equal(mse_scores_dict[\"train_score\"], train_mse_scores)\n        else:\n            mse_scores_dict = cross_validate(\n                clf,\n                X,\n                y,\n                scoring=\"neg_mean_squared_error\",\n                return_train_score=False,\n                cv=cv,\n            )\n        assert isinstance(mse_scores_dict, dict)\n        assert len(mse_scores_dict) == dict_len\n        assert_array_almost_equal(mse_scores_dict[\"test_score\"], test_mse_scores)\n\n        # Single metric passed as a list\n        if return_train_score:\n            # It must be True by default - deprecated\n            r2_scores_dict = cross_validate(\n                clf, X, y, scoring=[\"r2\"], return_train_score=True, cv=cv\n            )\n            assert_array_almost_equal(r2_scores_dict[\"train_r2\"], train_r2_scores, True)\n        else:\n            r2_scores_dict = cross_validate(\n                clf, X, y, scoring=[\"r2\"], return_train_score=False, cv=cv\n            )\n        assert isinstance(r2_scores_dict, dict)\n        assert "}, {"start_line": 14000, "end_line": 16000, "belongs_to": {"file_name": "_validation.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/model_selection", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "        # the user is not calling `fit` directly, so we change the message\n            # to make it more suitable for this case.\n            raise UnsetMetadataPassedError(\n                message=str(e).replace(\"cross_validate.fit\", \"cross_validate\"),\n                unrequested_params=e.unrequested_params,\n                routed_params=e.routed_params,\n            )\n    else:\n        routed_params = Bunch()\n        routed_params.splitter = Bunch(split={\"groups\": groups})\n        routed_params.estimator = Bunch(fit=params)\n        routed_params.scorer = Bunch(score={})\n\n    indices = cv.split(X, y, **routed_params.splitter.split)\n    if return_indices:\n        # materialize the indices since we need to store them in the returned dict\n        indices = list(indices)\n\n    # We clone the estimator to make sure that all the folds are\n    # independent, and that it is pickle-able.\n    parallel = Parallel(n_jobs=n_jobs, verbose=verbose, pre_dispatch=pre_dispatch)\n    results = parallel(\n        delayed(_fit_and_score)(\n            clone(estimator),\n            X,\n            y,\n            scorer=scorers,\n            train=train,\n            test=test,\n            verbose=verbose,\n            parameters=None,\n            fit_params=routed_params.estimator.fit,\n            score_params=routed_params.scorer.score,\n            return_train_score=return_train_score,\n            return_times=True,\n            return_estimator=return_estimator,\n            error_score=error_score,\n        )\n        for train, test in indices\n    )\n\n    _warn_or_raise_about_fit_failures(results, error_score)\n\n    # For callable scoring, the return type is only know after calling. If the\n    # return type is a dictionary, the error scores can now be inserted with\n    # the correct key.\n    if callable(scoring):\n        _insert_error_scores(results, error_score)\n\n    results = _aggregate_score_dicts(results)\n\n    ret = {}\n    ret[\"fit_time\"] = results[\"fit_time\"]\n    ret[\"score_time\"] = results[\""}, {"start_line": 67000, "end_line": 69000, "belongs_to": {"file_name": "pairwise.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/metrics", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "           out[i, j] = metric(x, y, **kwds)\n\n    return out\n\n\ndef _check_chunk_size(reduced, chunk_size):\n    \"\"\"Checks chunk is a sequence of expected size or a tuple of same.\"\"\"\n    if reduced is None:\n        return\n    is_tuple = isinstance(reduced, tuple)\n    if not is_tuple:\n        reduced = (reduced,)\n    if any(isinstance(r, tuple) or not hasattr(r, \"__iter__\") for r in reduced):\n        raise TypeError(\n            \"reduce_func returned %r. Expected sequence(s) of length %d.\"\n            % (reduced if is_tuple else reduced[0], chunk_size)\n        )\n    if any(_num_samples(r) != chunk_size for r in reduced):\n        actual_size = tuple(_num_samples(r) for r in reduced)\n        raise ValueError(\n            \"reduce_func returned object of length %s. \"\n            \"Expected same length as input: %d.\"\n            % (actual_size if is_tuple else actual_size[0], chunk_size)\n        )\n\n\ndef _precompute_metric_params(X, Y, metric=None, **kwds):\n    \"\"\"Precompute data-derived metric parameters if not provided.\"\"\"\n    if metric == \"seuclidean\" and \"V\" not in kwds:\n        if X is Y:\n            V = np.var(X, axis=0, ddof=1)\n        else:\n            raise ValueError(\n                \"The 'V' parameter is required for the seuclidean metric \"\n                \"when Y is passed.\"\n            )\n        return {\"V\": V}\n    if metric == \"mahalanobis\" and \"VI\" not in kwds:\n        if X is Y:\n            VI = np.linalg.inv(np.cov(X.T)).T\n        else:\n            raise ValueError(\n                \"The 'VI' parameter is required for the mahalanobis metric \"\n                \"when Y is passed.\"\n            )\n        return {\"VI\": VI}\n    return {}\n\n\n@validate_params(\n    {\n        \"X\": [\"array-like\", \"sparse matrix\"],\n        \"Y\": [\"array-like\", \"sparse matrix\", None],\n        \"reduce_func\": [callable, None],\n        \"metric\": [StrOptions({\"precomputed\"}.union(_VALID_METRICS)), callable],\n        \"n_jobs\": [Integral, None],\n        \"working_memory\": [Interval(Real, 0, None, clo"}, {"start_line": 38000, "end_line": 40000, "belongs_to": {"file_name": "test_search.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/model_selection/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "e a weighted mean irrespective of\n    # i.i.d. or not\n    assert train_mean == pytest.approx(1)\n    assert train_std == pytest.approx(0)\n\n\ndef test_grid_search_cv_results_multimetric():\n    X, y = make_classification(n_samples=50, n_features=4, random_state=42)\n\n    n_splits = 3\n    params = [\n        dict(\n            kernel=[\n                \"rbf\",\n            ],\n            C=[1, 10],\n            gamma=[0.1, 1],\n        ),\n        dict(\n            kernel=[\n                \"poly\",\n            ],\n            degree=[1, 2],\n        ),\n    ]\n\n    grid_searches = []\n    for scoring in (\n        {\"accuracy\": make_scorer(accuracy_score), \"recall\": make_scorer(recall_score)},\n        \"accuracy\",\n        \"recall\",\n    ):\n        grid_search = GridSearchCV(\n            SVC(), cv=n_splits, param_grid=params, scoring=scoring, refit=False\n        )\n        grid_search.fit(X, y)\n        grid_searches.append(grid_search)\n\n    compare_cv_results_multimetric_with_single(*grid_searches)\n\n\ndef test_random_search_cv_results_multimetric():\n    X, y = make_classification(n_samples=50, n_features=4, random_state=42)\n\n    n_splits = 3\n    n_search_iter = 30\n\n    # Scipy 0.12's stats dists do not accept seed, hence we use param grid\n    params = dict(C=np.logspace(-4, 1, 3), gamma=np.logspace(-5, 0, 3, base=0.1))\n    for refit in (True, False):\n        random_searches = []\n        for scoring in ((\"accuracy\", \"recall\"), \"accuracy\", \"recall\"):\n            # If True, for multi-metric pass refit='accuracy'\n            if refit:\n                probability = True\n                refit = \"accuracy\" if isinstance(scoring, tuple) else refit\n            else:\n                probability = False\n            clf = SVC(probability=probability, random_state=42)\n            random_search = RandomizedSearchCV(\n                clf,\n                n_iter=n_search_iter,\n                cv=n_splits,\n                param_distributions=params,\n                scoring=scoring,\n                refit=refit,"}, {"start_line": 14000, "end_line": 16000, "belongs_to": {"file_name": "test_validation.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/model_selection/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "= []\n        train_r2_scores = []\n        test_r2_scores = []\n        fitted_estimators = []\n\n        for train, test in cv.split(X, y):\n            est = clone(est).fit(X[train], y[train])\n            train_mse_scores.append(mse_scorer(est, X[train], y[train]))\n            train_r2_scores.append(r2_scorer(est, X[train], y[train]))\n            test_mse_scores.append(mse_scorer(est, X[test], y[test]))\n            test_r2_scores.append(r2_scorer(est, X[test], y[test]))\n            fitted_estimators.append(est)\n\n        train_mse_scores = np.array(train_mse_scores)\n        test_mse_scores = np.array(test_mse_scores)\n        train_r2_scores = np.array(train_r2_scores)\n        test_r2_scores = np.array(test_r2_scores)\n        fitted_estimators = np.array(fitted_estimators)\n\n        scores = (\n            train_mse_scores,\n            test_mse_scores,\n            train_r2_scores,\n            test_r2_scores,\n            fitted_estimators,\n        )\n\n        # To ensure that the test does not suffer from\n        # large statistical fluctuations due to slicing small datasets,\n        # we pass the cross-validation instance\n        check_cross_validate_single_metric(est, X, y, scores, cv)\n        check_cross_validate_multi_metric(est, X, y, scores, cv)\n\n\ndef check_cross_validate_single_metric(clf, X, y, scores, cv):\n    (\n        train_mse_scores,\n        test_mse_scores,\n        train_r2_scores,\n        test_r2_scores,\n        fitted_estimators,\n    ) = scores\n    # Test single metric evaluation when scoring is string or singleton list\n    for return_train_score, dict_len in ((True, 4), (False, 3)):\n        # Single metric passed as a string\n        if return_train_score:\n            mse_scores_dict = cross_validate(\n                clf,\n                X,\n                y,\n                scoring=\"neg_mean_squared_error\",\n                return_train_score=True,\n                cv=cv,\n            )\n            assert_array_almost_equal(mse_scores_dict[\"train_score\"], train"}, {"start_line": 16000, "end_line": 18000, "belongs_to": {"file_name": "test_validation.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/model_selection/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "_mse_scores)\n        else:\n            mse_scores_dict = cross_validate(\n                clf,\n                X,\n                y,\n                scoring=\"neg_mean_squared_error\",\n                return_train_score=False,\n                cv=cv,\n            )\n        assert isinstance(mse_scores_dict, dict)\n        assert len(mse_scores_dict) == dict_len\n        assert_array_almost_equal(mse_scores_dict[\"test_score\"], test_mse_scores)\n\n        # Single metric passed as a list\n        if return_train_score:\n            # It must be True by default - deprecated\n            r2_scores_dict = cross_validate(\n                clf, X, y, scoring=[\"r2\"], return_train_score=True, cv=cv\n            )\n            assert_array_almost_equal(r2_scores_dict[\"train_r2\"], train_r2_scores, True)\n        else:\n            r2_scores_dict = cross_validate(\n                clf, X, y, scoring=[\"r2\"], return_train_score=False, cv=cv\n            )\n        assert isinstance(r2_scores_dict, dict)\n        assert len(r2_scores_dict) == dict_len\n        assert_array_almost_equal(r2_scores_dict[\"test_r2\"], test_r2_scores)\n\n    # Test return_estimator option\n    mse_scores_dict = cross_validate(\n        clf, X, y, scoring=\"neg_mean_squared_error\", return_estimator=True, cv=cv\n    )\n    for k, est in enumerate(mse_scores_dict[\"estimator\"]):\n        est_coef = est.coef_.copy()\n        if issparse(est_coef):\n            est_coef = est_coef.toarray()\n\n        fitted_est_coef = fitted_estimators[k].coef_.copy()\n        if issparse(fitted_est_coef):\n            fitted_est_coef = fitted_est_coef.toarray()\n\n        assert_almost_equal(est_coef, fitted_est_coef)\n        assert_almost_equal(est.intercept_, fitted_estimators[k].intercept_)\n\n\ndef check_cross_validate_multi_metric(clf, X, y, scores, cv):\n    # Test multimetric evaluation when scoring is a list / dict\n    (\n        train_mse_scores,\n        test_mse_scores,\n        train_r2_scores,\n        test_r2_scores,\n        fitted_estimators,\n    ) = scor"}], "retrieved_count": 10, "cost_time": 1.329671859741211}
{"question": "How does the Splitter API handle the interaction between categorical feature splitting and missing value routing when the missing_values_bin_idx parameter is combined with the is_categorical flag, and what determines whether missing samples are routed to the left or right child node during the find_node_split operation?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"start_line": 20000, "end_line": 22000, "belongs_to": {"file_name": "test_splitting.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/ensemble/_hist_gradient_boosting/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": ".find_node_split(\n        n_samples, histograms, sum_gradients, sum_hessians, value\n    )\n\n    assert split_info.bin_idx == expected_bin_idx\n    if has_missing_values:\n        assert split_info.missing_go_to_left == expected_go_to_left\n\n    split_on_nan = split_info.bin_idx == n_bins_non_missing[0] - 1\n    assert split_on_nan == expected_split_on_nan\n\n    # Make sure the split is properly computed.\n    # This also make sure missing values are properly assigned to the correct\n    # child in split_indices()\n    samples_left, samples_right, _ = splitter.split_indices(\n        split_info, splitter.partition\n    )\n\n    if not expected_split_on_nan:\n        # When we don't split on nans, the split should always be the same.\n        assert set(samples_left) == set([0, 1, 2, 3])\n        assert set(samples_right) == set([4, 5, 6, 7, 8, 9])\n    else:\n        # When we split on nans, samples with missing values are always mapped\n        # to the right child.\n        missing_samples_indices = np.flatnonzero(\n            np.array(X_binned) == missing_values_bin_idx\n        )\n        non_missing_samples_indices = np.flatnonzero(\n            np.array(X_binned) != missing_values_bin_idx\n        )\n\n        assert set(samples_right) == set(missing_samples_indices)\n        assert set(samples_left) == set(non_missing_samples_indices)\n\n\n@pytest.mark.parametrize(\n    \"X_binned, has_missing_values, n_bins_non_missing, \",\n    [\n        # one category\n        ([0] * 20, False, 1),\n        # all categories appear less than MIN_CAT_SUPPORT (hardcoded to 10)\n        ([0] * 9 + [1] * 8, False, 2),\n        # only one category appears more than MIN_CAT_SUPPORT\n        ([0] * 12 + [1] * 8, False, 2),\n        # missing values + category appear less than MIN_CAT_SUPPORT\n        # 9 is missing\n        ([0] * 9 + [1] * 8 + [9] * 4, True, 2),\n        # no non-missing category\n        ([9] * 11, True, 0),\n    ],\n)\ndef test_splitting_categorical_cat_smooth(\n    X_binned, has_missing_values, n_bins_non_mi"}, {"start_line": 29000, "end_line": 31000, "belongs_to": {"file_name": "test_splitting.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/ensemble/_hist_gradient_boosting/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "\n\n    X_binned = np.array(X_binned, dtype=X_BINNED_DTYPE).reshape(-1, 1)\n    X_binned = np.asfortranarray(X_binned)\n\n    l2_regularization = 0.0\n    min_hessian_to_split = 1e-3\n    min_samples_leaf = 1\n    min_gain_to_split = 0.0\n\n    sample_indices = np.arange(n_samples, dtype=np.uint32)\n    all_gradients = np.array(all_gradients, dtype=G_H_DTYPE)\n    all_hessians = np.ones(1, dtype=G_H_DTYPE)\n    has_missing_values = np.array([has_missing_values], dtype=np.uint8)\n    sum_gradients = all_gradients.sum()\n    sum_hessians = n_samples\n    hessians_are_constant = True\n\n    builder = HistogramBuilder(\n        X_binned, n_bins, all_gradients, all_hessians, hessians_are_constant, n_threads\n    )\n\n    n_bins_non_missing = np.array([n_bins_non_missing], dtype=np.uint32)\n    monotonic_cst = np.array(\n        [MonotonicConstraint.NO_CST] * X_binned.shape[1], dtype=np.int8\n    )\n    is_categorical = np.ones_like(monotonic_cst, dtype=np.uint8)\n\n    splitter = Splitter(\n        X_binned,\n        n_bins_non_missing,\n        missing_values_bin_idx,\n        has_missing_values,\n        is_categorical,\n        monotonic_cst,\n        l2_regularization,\n        min_hessian_to_split,\n        min_samples_leaf,\n        min_gain_to_split,\n        hessians_are_constant,\n    )\n\n    histograms = builder.compute_histograms_brute(sample_indices)\n\n    value = compute_node_value(\n        sum_gradients, sum_hessians, -np.inf, np.inf, l2_regularization\n    )\n    split_info = splitter.find_node_split(\n        n_samples, histograms, sum_gradients, sum_hessians, value\n    )\n\n    assert split_info.is_categorical\n    assert split_info.gain > 0\n    _assert_categories_equals_bitset(\n        expected_categories_left, split_info.left_cat_bitset\n    )\n    if has_missing_values:\n        assert split_info.missing_go_to_left == expected_missing_go_to_left\n    # If there is no missing value during training, the flag missing_go_to_left\n    # is set later in the grower.\n\n    # make sure samples are split correctly"}, {"start_line": 23000, "end_line": 25000, "belongs_to": {"file_name": "test_splitting.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/ensemble/_hist_gradient_boosting/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "straint.NO_CST] * X_binned.shape[1], dtype=np.int8\n    )\n    is_categorical = np.ones_like(monotonic_cst, dtype=np.uint8)\n    missing_values_bin_idx = n_bins - 1\n\n    splitter = Splitter(\n        X_binned,\n        n_bins_non_missing,\n        missing_values_bin_idx,\n        has_missing_values,\n        is_categorical,\n        monotonic_cst,\n        l2_regularization,\n        min_hessian_to_split,\n        min_samples_leaf,\n        min_gain_to_split,\n        hessians_are_constant,\n    )\n\n    histograms = builder.compute_histograms_brute(sample_indices)\n    value = compute_node_value(\n        sum_gradients, sum_hessians, -np.inf, np.inf, l2_regularization\n    )\n    split_info = splitter.find_node_split(\n        n_samples, histograms, sum_gradients, sum_hessians, value\n    )\n\n    # no split found\n    assert split_info.gain == -1\n\n\ndef _assert_categories_equals_bitset(categories, bitset):\n    # assert that the bitset exactly corresponds to the categories\n    # bitset is assumed to be an array of 8 uint32 elements\n\n    # form bitset from threshold\n    expected_bitset = np.zeros(8, dtype=np.uint32)\n    for cat in categories:\n        idx = cat // 32\n        shift = cat % 32\n        expected_bitset[idx] |= 1 << shift\n\n    # check for equality\n    assert_array_equal(expected_bitset, bitset)\n\n\n@pytest.mark.parametrize(\n    (\n        \"X_binned, all_gradients, expected_categories_left, n_bins_non_missing,\"\n        \"missing_values_bin_idx, has_missing_values, expected_missing_go_to_left\"\n    ),\n    [\n        # 4 categories\n        (\n            [0, 1, 2, 3] * 11,  # X_binned\n            [10, 1, 10, 10] * 11,  # all_gradients\n            [1],  # expected_categories_left\n            4,  # n_bins_non_missing\n            4,  # missing_values_bin_idx\n            False,  # has_missing_values\n            None,\n        ),  # expected_missing_go_to_left, unchecked\n        # Make sure that the categories that are on the right (second half) of\n        # the sorted categories array can still g"}, {"start_line": 13000, "end_line": 15000, "belongs_to": {"file_name": "test_splitting.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/ensemble/_hist_gradient_boosting/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "_binned.shape[1], dtype=np.int8\n    )\n    is_categorical = np.zeros_like(monotonic_cst, dtype=np.uint8)\n    missing_values_bin_idx = n_bins - 1\n    splitter = Splitter(\n        X_binned,\n        n_bins_non_missing,\n        missing_values_bin_idx,\n        has_missing_values,\n        is_categorical,\n        monotonic_cst,\n        l2_regularization,\n        min_hessian_to_split,\n        min_samples_leaf,\n        min_gain_to_split,\n        hessians_are_constant,\n    )\n\n    histograms = builder.compute_histograms_brute(sample_indices)\n    value = compute_node_value(\n        sum_gradients, sum_hessians, -np.inf, np.inf, l2_regularization\n    )\n    split_info = splitter.find_node_split(\n        n_samples, histograms, sum_gradients, sum_hessians, value\n    )\n    assert split_info.gain == -1\n\n\n@pytest.mark.parametrize(\n    (\n        \"X_binned, all_gradients, has_missing_values, n_bins_non_missing, \"\n        \" expected_split_on_nan, expected_bin_idx, expected_go_to_left\"\n    ),\n    [\n        # basic sanity check with no missing values: given the gradient\n        # values, the split must occur on bin_idx=3\n        (\n            [0, 1, 2, 3, 4, 5, 6, 7, 8, 9],  # X_binned\n            [1, 1, 1, 1, 5, 5, 5, 5, 5, 5],  # gradients\n            False,  # no missing values\n            10,  # n_bins_non_missing\n            False,  # don't split on nans\n            3,  # expected_bin_idx\n            \"not_applicable\",\n        ),\n        # We replace 2 samples by NaNs (bin_idx=8)\n        # These 2 samples were mapped to the left node before, so they should\n        # be mapped to left node again\n        # Notice how the bin_idx threshold changes from 3 to 1.\n        (\n            [8, 0, 1, 8, 2, 3, 4, 5, 6, 7],  # 8 <=> missing\n            [1, 1, 1, 1, 5, 5, 5, 5, 5, 5],\n            True,  # missing values\n            8,  # n_bins_non_missing\n            False,  # don't split on nans\n            1,  # cut on bin_idx=1\n            True,\n        ),  # missing values go to left\n        # sam"}, {"start_line": 18000, "end_line": 20000, "belongs_to": {"file_name": "test_splitting.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/ensemble/_hist_gradient_boosting/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "    # we build an artificial example with gradients such that the best split\n    # is on bin_idx=3, when there are no missing values.\n    # Then we introduce missing values and:\n    #   - make sure the chosen bin is correct (find_best_bin()): it's\n    #     still the same split, even though the index of the bin may change\n    #   - make sure the missing values are mapped to the correct child\n    #     (split_indices())\n\n    n_bins = max(X_binned) + 1\n    n_samples = len(X_binned)\n    l2_regularization = 0.0\n    min_hessian_to_split = 1e-3\n    min_samples_leaf = 1\n    min_gain_to_split = 0.0\n\n    sample_indices = np.arange(n_samples, dtype=np.uint32)\n    X_binned = np.array(X_binned, dtype=X_BINNED_DTYPE).reshape(-1, 1)\n    X_binned = np.asfortranarray(X_binned)\n    all_gradients = np.array(all_gradients, dtype=G_H_DTYPE)\n    has_missing_values = np.array([has_missing_values], dtype=np.uint8)\n    all_hessians = np.ones(1, dtype=G_H_DTYPE)\n    sum_gradients = all_gradients.sum()\n    sum_hessians = 1 * n_samples\n    hessians_are_constant = True\n\n    builder = HistogramBuilder(\n        X_binned, n_bins, all_gradients, all_hessians, hessians_are_constant, n_threads\n    )\n\n    n_bins_non_missing = np.array([n_bins_non_missing], dtype=np.uint32)\n    monotonic_cst = np.array(\n        [MonotonicConstraint.NO_CST] * X_binned.shape[1], dtype=np.int8\n    )\n    is_categorical = np.zeros_like(monotonic_cst, dtype=np.uint8)\n    missing_values_bin_idx = n_bins - 1\n    splitter = Splitter(\n        X_binned,\n        n_bins_non_missing,\n        missing_values_bin_idx,\n        has_missing_values,\n        is_categorical,\n        monotonic_cst,\n        l2_regularization,\n        min_hessian_to_split,\n        min_samples_leaf,\n        min_gain_to_split,\n        hessians_are_constant,\n    )\n\n    histograms = builder.compute_histograms_brute(sample_indices)\n    value = compute_node_value(\n        sum_gradients, sum_hessians, -np.inf, np.inf, l2_regularization\n    )\n    split_info = splitter"}, {"start_line": 19000, "end_line": 21000, "belongs_to": {"file_name": "test_splitting.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/ensemble/_hist_gradient_boosting/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "hessians = 1 * n_samples\n    hessians_are_constant = True\n\n    builder = HistogramBuilder(\n        X_binned, n_bins, all_gradients, all_hessians, hessians_are_constant, n_threads\n    )\n\n    n_bins_non_missing = np.array([n_bins_non_missing], dtype=np.uint32)\n    monotonic_cst = np.array(\n        [MonotonicConstraint.NO_CST] * X_binned.shape[1], dtype=np.int8\n    )\n    is_categorical = np.zeros_like(monotonic_cst, dtype=np.uint8)\n    missing_values_bin_idx = n_bins - 1\n    splitter = Splitter(\n        X_binned,\n        n_bins_non_missing,\n        missing_values_bin_idx,\n        has_missing_values,\n        is_categorical,\n        monotonic_cst,\n        l2_regularization,\n        min_hessian_to_split,\n        min_samples_leaf,\n        min_gain_to_split,\n        hessians_are_constant,\n    )\n\n    histograms = builder.compute_histograms_brute(sample_indices)\n    value = compute_node_value(\n        sum_gradients, sum_hessians, -np.inf, np.inf, l2_regularization\n    )\n    split_info = splitter.find_node_split(\n        n_samples, histograms, sum_gradients, sum_hessians, value\n    )\n\n    assert split_info.bin_idx == expected_bin_idx\n    if has_missing_values:\n        assert split_info.missing_go_to_left == expected_go_to_left\n\n    split_on_nan = split_info.bin_idx == n_bins_non_missing[0] - 1\n    assert split_on_nan == expected_split_on_nan\n\n    # Make sure the split is properly computed.\n    # This also make sure missing values are properly assigned to the correct\n    # child in split_indices()\n    samples_left, samples_right, _ = splitter.split_indices(\n        split_info, splitter.partition\n    )\n\n    if not expected_split_on_nan:\n        # When we don't split on nans, the split should always be the same.\n        assert set(samples_left) == set([0, 1, 2, 3])\n        assert set(samples_right) == set([4, 5, 6, 7, 8, 9])\n    else:\n        # When we split on nans, samples with missing values are always mapped\n        # to the right child.\n        missing_samples_indices = np.f"}, {"start_line": 30000, "end_line": 32000, "belongs_to": {"file_name": "test_splitting.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/ensemble/_hist_gradient_boosting/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "bins_non_missing,\n        missing_values_bin_idx,\n        has_missing_values,\n        is_categorical,\n        monotonic_cst,\n        l2_regularization,\n        min_hessian_to_split,\n        min_samples_leaf,\n        min_gain_to_split,\n        hessians_are_constant,\n    )\n\n    histograms = builder.compute_histograms_brute(sample_indices)\n\n    value = compute_node_value(\n        sum_gradients, sum_hessians, -np.inf, np.inf, l2_regularization\n    )\n    split_info = splitter.find_node_split(\n        n_samples, histograms, sum_gradients, sum_hessians, value\n    )\n\n    assert split_info.is_categorical\n    assert split_info.gain > 0\n    _assert_categories_equals_bitset(\n        expected_categories_left, split_info.left_cat_bitset\n    )\n    if has_missing_values:\n        assert split_info.missing_go_to_left == expected_missing_go_to_left\n    # If there is no missing value during training, the flag missing_go_to_left\n    # is set later in the grower.\n\n    # make sure samples are split correctly\n    samples_left, samples_right, _ = splitter.split_indices(\n        split_info, splitter.partition\n    )\n\n    left_mask = np.isin(X_binned.ravel(), expected_categories_left)\n    assert_array_equal(sample_indices[left_mask], samples_left)\n    assert_array_equal(sample_indices[~left_mask], samples_right)\n\n\ndef test_split_interaction_constraints():\n    \"\"\"Check that allowed_features are respected.\"\"\"\n    n_features = 4\n    # features 1 and 2 are not allowed to be split on\n    allowed_features = np.array([0, 3], dtype=np.uint32)\n    n_bins = 5\n    n_samples = 10\n    l2_regularization = 0.0\n    min_hessian_to_split = 1e-3\n    min_samples_leaf = 1\n    min_gain_to_split = 0.0\n\n    sample_indices = np.arange(n_samples, dtype=np.uint32)\n    all_hessians = np.ones(1, dtype=G_H_DTYPE)\n    sum_hessians = n_samples\n    hessians_are_constant = True\n\n    split_features = []\n\n    # The loop is to ensure that we split at least once on each allowed feature (0, 3).\n    # This is tracked by split_featur"}, {"start_line": 27000, "end_line": 29000, "belongs_to": {"file_name": "test_splitting.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/ensemble/_hist_gradient_boosting/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "s\n            False,\n        ),  # expected_missing_go_to_left\n        # 4 categories with missing values that go to the left\n        (\n            [0, 1, 2] * 11 + [9] * 11,  # X_binned\n            [10, 1, 10] * 11 + [1] * 11,  # all_gradients\n            [1, 9],  # expected_categories_left\n            3,  # n_bins_non_missing\n            9,  # missing_values_bin_idx\n            True,  # has_missing_values\n            True,\n        ),  # expected_missing_go_to_left\n        # split is on the missing value\n        (\n            [0, 1, 2, 3, 4] * 11 + [255] * 12,  # X_binned\n            [10, 10, 10, 10, 10] * 11 + [1] * 12,  # all_gradients\n            [255],  # expected_categories_left\n            5,  # n_bins_non_missing\n            255,  # missing_values_bin_idx\n            True,  # has_missing_values\n            True,\n        ),  # expected_missing_go_to_left\n        # split on even categories\n        (\n            list(range(60)) * 12,  # X_binned\n            [10, 1] * 360,  # all_gradients\n            list(range(1, 60, 2)),  # expected_categories_left\n            59,  # n_bins_non_missing\n            59,  # missing_values_bin_idx\n            True,  # has_missing_values\n            True,\n        ),  # expected_missing_go_to_left\n        # split on every 8 categories\n        (\n            list(range(256)) * 12,  # X_binned\n            [10, 10, 10, 10, 10, 10, 10, 1] * 384,  # all_gradients\n            list(range(7, 256, 8)),  # expected_categories_left\n            255,  # n_bins_non_missing\n            255,  # missing_values_bin_idx\n            True,  # has_missing_values\n            True,\n        ),  # expected_missing_go_to_left\n    ],\n)\ndef test_splitting_categorical_sanity(\n    X_binned,\n    all_gradients,\n    expected_categories_left,\n    n_bins_non_missing,\n    missing_values_bin_idx,\n    has_missing_values,\n    expected_missing_go_to_left,\n):\n    # Tests various combinations of categorical splits\n\n    n_samples = len(X_binned)\n    n_bins = max(X_binned) + 1"}, {"start_line": 16000, "end_line": 18000, "belongs_to": {"file_name": "test_splitting.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/ensemble/_hist_gradient_boosting/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "g values\n            8,  # n_bins_non_missing\n            False,  # don't split on nans\n            3,  # cut on bin_idx=3 (like in first case)\n            False,\n        ),  # missing values go to right\n        # For the following cases, split_on_nans is True (we replace all of\n        # the samples with nans, instead of just 2).\n        (\n            [0, 1, 2, 3, 4, 4, 4, 4, 4, 4],  # 4 <=> missing\n            [1, 1, 1, 1, 5, 5, 5, 5, 5, 5],\n            True,  # missing values\n            4,  # n_bins_non_missing\n            True,  # split on nans\n            3,  # cut on bin_idx=3\n            False,\n        ),  # missing values go to right\n        # same as above, but with non-consecutive missing_values_bin\n        (\n            [0, 1, 2, 3, 9, 9, 9, 9, 9, 9],  # 9 <=> missing\n            [1, 1, 1, 1, 1, 1, 5, 5, 5, 5],\n            True,  # missing values\n            4,  # n_bins_non_missing\n            True,  # split on nans\n            3,  # cut on bin_idx=3\n            False,\n        ),  # missing values go to right\n        (\n            [6, 6, 6, 6, 0, 1, 2, 3, 4, 5],  # 6 <=> missing\n            [1, 1, 1, 1, 5, 5, 5, 5, 5, 5],\n            True,  # missing values\n            6,  # n_bins_non_missing\n            True,  # split on nans\n            5,  # cut on bin_idx=5\n            False,\n        ),  # missing values go to right\n        # same as above, but with non-consecutive missing_values_bin\n        (\n            [9, 9, 9, 9, 0, 1, 2, 3, 4, 5],  # 9 <=> missing\n            [1, 1, 1, 1, 5, 5, 5, 5, 5, 5],\n            True,  # missing values\n            6,  # n_bins_non_missing\n            True,  # split on nans\n            5,  # cut on bin_idx=5\n            False,\n        ),  # missing values go to right\n    ],\n)\ndef test_splitting_missing_values(\n    X_binned,\n    all_gradients,\n    has_missing_values,\n    n_bins_non_missing,\n    expected_split_on_nan,\n    expected_bin_idx,\n    expected_go_to_left,\n):\n    # Make sure missing values are properly supported.\n"}, {"start_line": 28000, "end_line": 30000, "belongs_to": {"file_name": "test_splitting.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/ensemble/_hist_gradient_boosting/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "radients\n            list(range(1, 60, 2)),  # expected_categories_left\n            59,  # n_bins_non_missing\n            59,  # missing_values_bin_idx\n            True,  # has_missing_values\n            True,\n        ),  # expected_missing_go_to_left\n        # split on every 8 categories\n        (\n            list(range(256)) * 12,  # X_binned\n            [10, 10, 10, 10, 10, 10, 10, 1] * 384,  # all_gradients\n            list(range(7, 256, 8)),  # expected_categories_left\n            255,  # n_bins_non_missing\n            255,  # missing_values_bin_idx\n            True,  # has_missing_values\n            True,\n        ),  # expected_missing_go_to_left\n    ],\n)\ndef test_splitting_categorical_sanity(\n    X_binned,\n    all_gradients,\n    expected_categories_left,\n    n_bins_non_missing,\n    missing_values_bin_idx,\n    has_missing_values,\n    expected_missing_go_to_left,\n):\n    # Tests various combinations of categorical splits\n\n    n_samples = len(X_binned)\n    n_bins = max(X_binned) + 1\n\n    X_binned = np.array(X_binned, dtype=X_BINNED_DTYPE).reshape(-1, 1)\n    X_binned = np.asfortranarray(X_binned)\n\n    l2_regularization = 0.0\n    min_hessian_to_split = 1e-3\n    min_samples_leaf = 1\n    min_gain_to_split = 0.0\n\n    sample_indices = np.arange(n_samples, dtype=np.uint32)\n    all_gradients = np.array(all_gradients, dtype=G_H_DTYPE)\n    all_hessians = np.ones(1, dtype=G_H_DTYPE)\n    has_missing_values = np.array([has_missing_values], dtype=np.uint8)\n    sum_gradients = all_gradients.sum()\n    sum_hessians = n_samples\n    hessians_are_constant = True\n\n    builder = HistogramBuilder(\n        X_binned, n_bins, all_gradients, all_hessians, hessians_are_constant, n_threads\n    )\n\n    n_bins_non_missing = np.array([n_bins_non_missing], dtype=np.uint32)\n    monotonic_cst = np.array(\n        [MonotonicConstraint.NO_CST] * X_binned.shape[1], dtype=np.int8\n    )\n    is_categorical = np.ones_like(monotonic_cst, dtype=np.uint8)\n\n    splitter = Splitter(\n        X_binned,\n        n_"}], "retrieved_count": 10, "cost_time": 1.3555629253387451}
{"question": "Why does the Normalizer class's __sklearn_tags__ method set requires_fit to False despite inheriting from TransformerMixin, and how does this design choice reflect the fundamental algorithmic nature of row normalization?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"start_line": 71000, "end_line": 73000, "belongs_to": {"file_name": "_data.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/preprocessing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "o be fitted.\n    However, we recommend to call :meth:`fit_transform` instead of\n    :meth:`transform`, as parameter validation is only performed in\n    :meth:`fit`.\n\n    Examples\n    --------\n    >>> from sklearn.preprocessing import Normalizer\n    >>> X = [[4, 1, 2, 2],\n    ...      [1, 3, 9, 3],\n    ...      [5, 7, 5, 1]]\n    >>> transformer = Normalizer().fit(X)  # fit does nothing.\n    >>> transformer\n    Normalizer()\n    >>> transformer.transform(X)\n    array([[0.8, 0.2, 0.4, 0.4],\n           [0.1, 0.3, 0.9, 0.3],\n           [0.5, 0.7, 0.5, 0.1]])\n    \"\"\"\n\n    _parameter_constraints: dict = {\n        \"norm\": [StrOptions({\"l1\", \"l2\", \"max\"})],\n        \"copy\": [\"boolean\"],\n    }\n\n    def __init__(self, norm=\"l2\", *, copy=True):\n        self.norm = norm\n        self.copy = copy\n\n    @_fit_context(prefer_skip_nested_validation=True)\n    def fit(self, X, y=None):\n        \"\"\"Only validates estimator's parameters.\n\n        This method allows to: (i) validate the estimator's parameters and\n        (ii) be consistent with the scikit-learn transformer API.\n\n        Parameters\n        ----------\n        X : {array-like, sparse matrix} of shape (n_samples, n_features)\n            The data to estimate the normalization parameters.\n\n        y : Ignored\n            Not used, present here for API consistency by convention.\n\n        Returns\n        -------\n        self : object\n            Fitted transformer.\n        \"\"\"\n        validate_data(self, X, accept_sparse=\"csr\")\n        return self\n\n    def transform(self, X, copy=None):\n        \"\"\"Scale each non zero row of X to unit norm.\n\n        Parameters\n        ----------\n        X : {array-like, sparse matrix} of shape (n_samples, n_features)\n            The data to normalize, row by row. scipy.sparse matrices should be\n            in CSR format to avoid an un-necessary copy.\n\n        copy : bool, default=None\n            Copy the input X or not.\n\n        Returns\n        -------\n        X_tr : {ndarray, sparse matrix} of shape"}, {"start_line": 70000, "end_line": 72000, "belongs_to": {"file_name": "_data.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/preprocessing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "ef:`User Guide <preprocessing_normalization>`.\n\n    Parameters\n    ----------\n    norm : {'l1', 'l2', 'max'}, default='l2'\n        The norm to use to normalize each non zero sample. If norm='max'\n        is used, values will be rescaled by the maximum of the absolute\n        values.\n\n    copy : bool, default=True\n        Set to False to perform inplace row normalization and avoid a\n        copy (if the input is already a numpy array or a scipy.sparse\n        CSR matrix).\n\n    Attributes\n    ----------\n    n_features_in_ : int\n        Number of features seen during :term:`fit`.\n\n        .. versionadded:: 0.24\n\n    feature_names_in_ : ndarray of shape (`n_features_in_`,)\n        Names of features seen during :term:`fit`. Defined only when `X`\n        has feature names that are all strings.\n\n        .. versionadded:: 1.0\n\n    See Also\n    --------\n    normalize : Equivalent function without the estimator API.\n\n    Notes\n    -----\n    This estimator is :term:`stateless` and does not need to be fitted.\n    However, we recommend to call :meth:`fit_transform` instead of\n    :meth:`transform`, as parameter validation is only performed in\n    :meth:`fit`.\n\n    Examples\n    --------\n    >>> from sklearn.preprocessing import Normalizer\n    >>> X = [[4, 1, 2, 2],\n    ...      [1, 3, 9, 3],\n    ...      [5, 7, 5, 1]]\n    >>> transformer = Normalizer().fit(X)  # fit does nothing.\n    >>> transformer\n    Normalizer()\n    >>> transformer.transform(X)\n    array([[0.8, 0.2, 0.4, 0.4],\n           [0.1, 0.3, 0.9, 0.3],\n           [0.5, 0.7, 0.5, 0.1]])\n    \"\"\"\n\n    _parameter_constraints: dict = {\n        \"norm\": [StrOptions({\"l1\", \"l2\", \"max\"})],\n        \"copy\": [\"boolean\"],\n    }\n\n    def __init__(self, norm=\"l2\", *, copy=True):\n        self.norm = norm\n        self.copy = copy\n\n    @_fit_context(prefer_skip_nested_validation=True)\n    def fit(self, X, y=None):\n        \"\"\"Only validates estimator's parameters.\n\n        This method allows to: (i) validate the estimator's parameters an"}, {"start_line": 72000, "end_line": 74000, "belongs_to": {"file_name": "_data.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/preprocessing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "d\n        (ii) be consistent with the scikit-learn transformer API.\n\n        Parameters\n        ----------\n        X : {array-like, sparse matrix} of shape (n_samples, n_features)\n            The data to estimate the normalization parameters.\n\n        y : Ignored\n            Not used, present here for API consistency by convention.\n\n        Returns\n        -------\n        self : object\n            Fitted transformer.\n        \"\"\"\n        validate_data(self, X, accept_sparse=\"csr\")\n        return self\n\n    def transform(self, X, copy=None):\n        \"\"\"Scale each non zero row of X to unit norm.\n\n        Parameters\n        ----------\n        X : {array-like, sparse matrix} of shape (n_samples, n_features)\n            The data to normalize, row by row. scipy.sparse matrices should be\n            in CSR format to avoid an un-necessary copy.\n\n        copy : bool, default=None\n            Copy the input X or not.\n\n        Returns\n        -------\n        X_tr : {ndarray, sparse matrix} of shape (n_samples, n_features)\n            Transformed array.\n        \"\"\"\n        copy = copy if copy is not None else self.copy\n        X = validate_data(\n            self, X, accept_sparse=\"csr\", force_writeable=True, copy=copy, reset=False\n        )\n        return normalize(X, norm=self.norm, axis=1, copy=False)\n\n    def __sklearn_tags__(self):\n        tags = super().__sklearn_tags__()\n        tags.input_tags.sparse = True\n        tags.requires_fit = False\n        tags.array_api_support = True\n        return tags\n\n\n@validate_params(\n    {\n        \"X\": [\"array-like\", \"sparse matrix\"],\n        \"threshold\": [Interval(Real, None, None, closed=\"neither\")],\n        \"copy\": [\"boolean\"],\n    },\n    prefer_skip_nested_validation=True,\n)\ndef binarize(X, *, threshold=0.0, copy=True):\n    \"\"\"Boolean thresholding of array-like or scipy.sparse matrix.\n\n    Read more in the :ref:`User Guide <preprocessing_binarization>`.\n\n    Parameters\n    ----------\n    X : {array-like, sparse matrix} of shape (n_samp"}, {"start_line": 69000, "end_line": 71000, "belongs_to": {"file_name": "_data.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/preprocessing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "       return X\n\n\nclass Normalizer(OneToOneFeatureMixin, TransformerMixin, BaseEstimator):\n    \"\"\"Normalize samples individually to unit norm.\n\n    Each sample (i.e. each row of the data matrix) with at least one\n    non zero component is rescaled independently of other samples so\n    that its norm (l1, l2 or inf) equals one.\n\n    This transformer is able to work both with dense numpy arrays and\n    scipy.sparse matrix (use CSR format if you want to avoid the burden of\n    a copy / conversion).\n\n    Scaling inputs to unit norms is a common operation for text\n    classification or clustering for instance. For instance the dot\n    product of two l2-normalized TF-IDF vectors is the cosine similarity\n    of the vectors and is the base similarity metric for the Vector\n    Space Model commonly used by the Information Retrieval community.\n\n    For an example visualization, refer to :ref:`Compare Normalizer with other\n    scalers <plot_all_scaling_normalizer_section>`.\n\n    Read more in the :ref:`User Guide <preprocessing_normalization>`.\n\n    Parameters\n    ----------\n    norm : {'l1', 'l2', 'max'}, default='l2'\n        The norm to use to normalize each non zero sample. If norm='max'\n        is used, values will be rescaled by the maximum of the absolute\n        values.\n\n    copy : bool, default=True\n        Set to False to perform inplace row normalization and avoid a\n        copy (if the input is already a numpy array or a scipy.sparse\n        CSR matrix).\n\n    Attributes\n    ----------\n    n_features_in_ : int\n        Number of features seen during :term:`fit`.\n\n        .. versionadded:: 0.24\n\n    feature_names_in_ : ndarray of shape (`n_features_in_`,)\n        Names of features seen during :term:`fit`. Defined only when `X`\n        has feature names that are all strings.\n\n        .. versionadded:: 1.0\n\n    See Also\n    --------\n    normalize : Equivalent function without the estimator API.\n\n    Notes\n    -----\n    This estimator is :term:`stateless` and does not need t"}, {"start_line": 68000, "end_line": 70000, "belongs_to": {"file_name": "_data.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/preprocessing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "       raise NotImplementedError(\n                \"return_norm=True is not implemented \"\n                \"for sparse matrices with norm 'l1' \"\n                \"or norm 'l2'\"\n            )\n        if norm == \"l1\":\n            inplace_csr_row_normalize_l1(X)\n        elif norm == \"l2\":\n            inplace_csr_row_normalize_l2(X)\n        elif norm == \"max\":\n            mins, maxes = min_max_axis(X, 1)\n            norms = np.maximum(abs(mins), maxes)\n            norms_elementwise = norms.repeat(np.diff(X.indptr))\n            mask = norms_elementwise != 0\n            X.data[mask] /= norms_elementwise[mask]\n    else:\n        if norm == \"l1\":\n            norms = xp.sum(xp.abs(X), axis=1)\n        elif norm == \"l2\":\n            norms = row_norms(X)\n        elif norm == \"max\":\n            norms = xp.max(xp.abs(X), axis=1)\n        norms = _handle_zeros_in_scale(norms, copy=False)\n        X /= norms[:, None]\n\n    if axis == 0:\n        X = X.T\n\n    if return_norm:\n        return X, norms\n    else:\n        return X\n\n\nclass Normalizer(OneToOneFeatureMixin, TransformerMixin, BaseEstimator):\n    \"\"\"Normalize samples individually to unit norm.\n\n    Each sample (i.e. each row of the data matrix) with at least one\n    non zero component is rescaled independently of other samples so\n    that its norm (l1, l2 or inf) equals one.\n\n    This transformer is able to work both with dense numpy arrays and\n    scipy.sparse matrix (use CSR format if you want to avoid the burden of\n    a copy / conversion).\n\n    Scaling inputs to unit norms is a common operation for text\n    classification or clustering for instance. For instance the dot\n    product of two l2-normalized TF-IDF vectors is the cosine similarity\n    of the vectors and is the base similarity metric for the Vector\n    Space Model commonly used by the Information Retrieval community.\n\n    For an example visualization, refer to :ref:`Compare Normalizer with other\n    scalers <plot_all_scaling_normalizer_section>`.\n\n    Read more in the :r"}, {"start_line": 69000, "end_line": 71000, "belongs_to": {"file_name": "test_data.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/preprocessing/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": ".0)\n        assert_almost_equal(la.norm(X_norm[3]), 0.0)\n    elif norm == \"max\":\n        row_maxs = abs(X_norm).max(axis=1)\n        for i in range(3):\n            assert_almost_equal(row_maxs[i], 1.0)\n        assert_almost_equal(row_maxs[3], 0.0)\n\n\n@pytest.mark.parametrize(\"norm\", [\"l1\", \"l2\", \"max\"])\n@pytest.mark.parametrize(\"csr_container\", CSR_CONTAINERS)\ndef test_normalizer_l1_l2_max(norm, csr_container):\n    rng = np.random.RandomState(0)\n    X_dense = rng.randn(4, 5)\n    X_sparse_unpruned = csr_container(X_dense)\n\n    # set the row number 3 to zero\n    X_dense[3, :] = 0.0\n\n    # set the row number 3 to zero without pruning (can happen in real life)\n    indptr_3 = X_sparse_unpruned.indptr[3]\n    indptr_4 = X_sparse_unpruned.indptr[4]\n    X_sparse_unpruned.data[indptr_3:indptr_4] = 0.0\n\n    # build the pruned variant using the regular constructor\n    X_sparse_pruned = csr_container(X_dense)\n\n    # check inputs that support the no-copy optim\n    for X in (X_dense, X_sparse_pruned, X_sparse_unpruned):\n        normalizer = Normalizer(norm=norm, copy=True)\n        X_norm1 = normalizer.transform(X)\n        assert X_norm1 is not X\n        X_norm1 = toarray(X_norm1)\n\n        normalizer = Normalizer(norm=norm, copy=False)\n        X_norm2 = normalizer.transform(X)\n        assert X_norm2 is X\n        X_norm2 = toarray(X_norm2)\n\n        for X_norm in (X_norm1, X_norm2):\n            check_normalizer(norm, X_norm)\n\n\n@pytest.mark.parametrize(\"norm\", [\"l1\", \"l2\", \"max\"])\n@pytest.mark.parametrize(\n    \"sparse_container\", COO_CONTAINERS + CSC_CONTAINERS + LIL_CONTAINERS\n)\ndef test_normalizer_l1_l2_max_non_csr(norm, sparse_container):\n    rng = np.random.RandomState(0)\n    X_dense = rng.randn(4, 5)\n\n    # set the row number 3 to zero\n    X_dense[3, :] = 0.0\n\n    X = sparse_container(X_dense)\n    X_norm = Normalizer(norm=norm, copy=False).transform(X)\n\n    assert X_norm is not X\n    assert sparse.issparse(X_norm) and X_norm.format == \"csr\"\n\n    X_norm = toarray(X_norm)\n    check_n"}, {"start_line": 70000, "end_line": 72000, "belongs_to": {"file_name": "test_data.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/preprocessing/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "_sparse_unpruned):\n        normalizer = Normalizer(norm=norm, copy=True)\n        X_norm1 = normalizer.transform(X)\n        assert X_norm1 is not X\n        X_norm1 = toarray(X_norm1)\n\n        normalizer = Normalizer(norm=norm, copy=False)\n        X_norm2 = normalizer.transform(X)\n        assert X_norm2 is X\n        X_norm2 = toarray(X_norm2)\n\n        for X_norm in (X_norm1, X_norm2):\n            check_normalizer(norm, X_norm)\n\n\n@pytest.mark.parametrize(\"norm\", [\"l1\", \"l2\", \"max\"])\n@pytest.mark.parametrize(\n    \"sparse_container\", COO_CONTAINERS + CSC_CONTAINERS + LIL_CONTAINERS\n)\ndef test_normalizer_l1_l2_max_non_csr(norm, sparse_container):\n    rng = np.random.RandomState(0)\n    X_dense = rng.randn(4, 5)\n\n    # set the row number 3 to zero\n    X_dense[3, :] = 0.0\n\n    X = sparse_container(X_dense)\n    X_norm = Normalizer(norm=norm, copy=False).transform(X)\n\n    assert X_norm is not X\n    assert sparse.issparse(X_norm) and X_norm.format == \"csr\"\n\n    X_norm = toarray(X_norm)\n    check_normalizer(norm, X_norm)\n\n\n@pytest.mark.parametrize(\"csr_container\", CSR_CONTAINERS)\ndef test_normalizer_max_sign(csr_container):\n    # check that we normalize by a positive number even for negative data\n    rng = np.random.RandomState(0)\n    X_dense = rng.randn(4, 5)\n    # set the row number 3 to zero\n    X_dense[3, :] = 0.0\n    # check for mixed data where the value with\n    # largest magnitude is negative\n    X_dense[2, abs(X_dense[2, :]).argmax()] *= -1\n    X_all_neg = -np.abs(X_dense)\n    X_all_neg_sparse = csr_container(X_all_neg)\n\n    for X in (X_dense, X_all_neg, X_all_neg_sparse):\n        normalizer = Normalizer(norm=\"max\")\n        X_norm = normalizer.transform(X)\n        assert X_norm is not X\n        X_norm = toarray(X_norm)\n        assert_array_equal(np.sign(X_norm), np.sign(toarray(X)))\n\n\n@pytest.mark.parametrize(\"csr_container\", CSR_CONTAINERS)\ndef test_normalize(csr_container):\n    # Test normalize function\n    # Only tests functionality not used by the tests for Normaliz"}, {"start_line": 68000, "end_line": 70000, "belongs_to": {"file_name": "test_data.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/preprocessing/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "        # Test std until the end of partial fits, and\n        scaler_batch = MaxAbsScaler().fit(X)\n        scaler_incr = MaxAbsScaler()  # Clean estimator\n        for i, batch in enumerate(gen_batches(n, chunk_size)):\n            scaler_incr = scaler_incr.partial_fit(X[batch])\n            assert_correct_incr(\n                i,\n                batch_start=batch.start,\n                batch_stop=batch.stop,\n                n=n,\n                chunk_size=chunk_size,\n                n_samples_seen=scaler_incr.n_samples_seen_,\n            )\n\n\ndef check_normalizer(norm, X_norm):\n    \"\"\"\n    Convenient checking function for `test_normalizer_l1_l2_max` and\n    `test_normalizer_l1_l2_max_non_csr`\n    \"\"\"\n    if norm == \"l1\":\n        row_sums = np.abs(X_norm).sum(axis=1)\n        for i in range(3):\n            assert_almost_equal(row_sums[i], 1.0)\n        assert_almost_equal(row_sums[3], 0.0)\n    elif norm == \"l2\":\n        for i in range(3):\n            assert_almost_equal(la.norm(X_norm[i]), 1.0)\n        assert_almost_equal(la.norm(X_norm[3]), 0.0)\n    elif norm == \"max\":\n        row_maxs = abs(X_norm).max(axis=1)\n        for i in range(3):\n            assert_almost_equal(row_maxs[i], 1.0)\n        assert_almost_equal(row_maxs[3], 0.0)\n\n\n@pytest.mark.parametrize(\"norm\", [\"l1\", \"l2\", \"max\"])\n@pytest.mark.parametrize(\"csr_container\", CSR_CONTAINERS)\ndef test_normalizer_l1_l2_max(norm, csr_container):\n    rng = np.random.RandomState(0)\n    X_dense = rng.randn(4, 5)\n    X_sparse_unpruned = csr_container(X_dense)\n\n    # set the row number 3 to zero\n    X_dense[3, :] = 0.0\n\n    # set the row number 3 to zero without pruning (can happen in real life)\n    indptr_3 = X_sparse_unpruned.indptr[3]\n    indptr_4 = X_sparse_unpruned.indptr[4]\n    X_sparse_unpruned.data[indptr_3:indptr_4] = 0.0\n\n    # build the pruned variant using the regular constructor\n    X_sparse_pruned = csr_container(X_dense)\n\n    # check inputs that support the no-copy optim\n    for X in (X_dense, X_sparse_pruned, X"}, {"start_line": 71000, "end_line": 73000, "belongs_to": {"file_name": "test_data.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/preprocessing/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "ormalizer(norm, X_norm)\n\n\n@pytest.mark.parametrize(\"csr_container\", CSR_CONTAINERS)\ndef test_normalizer_max_sign(csr_container):\n    # check that we normalize by a positive number even for negative data\n    rng = np.random.RandomState(0)\n    X_dense = rng.randn(4, 5)\n    # set the row number 3 to zero\n    X_dense[3, :] = 0.0\n    # check for mixed data where the value with\n    # largest magnitude is negative\n    X_dense[2, abs(X_dense[2, :]).argmax()] *= -1\n    X_all_neg = -np.abs(X_dense)\n    X_all_neg_sparse = csr_container(X_all_neg)\n\n    for X in (X_dense, X_all_neg, X_all_neg_sparse):\n        normalizer = Normalizer(norm=\"max\")\n        X_norm = normalizer.transform(X)\n        assert X_norm is not X\n        X_norm = toarray(X_norm)\n        assert_array_equal(np.sign(X_norm), np.sign(toarray(X)))\n\n\n@pytest.mark.parametrize(\"csr_container\", CSR_CONTAINERS)\ndef test_normalize(csr_container):\n    # Test normalize function\n    # Only tests functionality not used by the tests for Normalizer.\n    X = np.random.RandomState(37).randn(3, 2)\n    assert_array_equal(normalize(X, copy=False), normalize(X.T, axis=0, copy=False).T)\n\n    rs = np.random.RandomState(0)\n    X_dense = rs.randn(10, 5)\n    X_sparse = csr_container(X_dense)\n    ones = np.ones((10))\n    for X in (X_dense, X_sparse):\n        for dtype in (np.float32, np.float64):\n            for norm in (\"l1\", \"l2\"):\n                X = X.astype(dtype)\n                X_norm = normalize(X, norm=norm)\n                assert X_norm.dtype == dtype\n\n                X_norm = toarray(X_norm)\n                if norm == \"l1\":\n                    row_sums = np.abs(X_norm).sum(axis=1)\n                else:\n                    X_norm_squared = X_norm**2\n                    row_sums = X_norm_squared.sum(axis=1)\n\n                assert_array_almost_equal(row_sums, ones)\n\n    # Test return_norm\n    X_dense = np.array([[3.0, 0, 4.0], [1.0, 0.0, 0.0], [2.0, 3.0, 0.0]])\n    for norm in (\"l1\", \"l2\", \"max\"):\n        _, norms = normalize(X_d"}, {"start_line": 72000, "end_line": 74000, "belongs_to": {"file_name": "test_data.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/preprocessing/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "er.\n    X = np.random.RandomState(37).randn(3, 2)\n    assert_array_equal(normalize(X, copy=False), normalize(X.T, axis=0, copy=False).T)\n\n    rs = np.random.RandomState(0)\n    X_dense = rs.randn(10, 5)\n    X_sparse = csr_container(X_dense)\n    ones = np.ones((10))\n    for X in (X_dense, X_sparse):\n        for dtype in (np.float32, np.float64):\n            for norm in (\"l1\", \"l2\"):\n                X = X.astype(dtype)\n                X_norm = normalize(X, norm=norm)\n                assert X_norm.dtype == dtype\n\n                X_norm = toarray(X_norm)\n                if norm == \"l1\":\n                    row_sums = np.abs(X_norm).sum(axis=1)\n                else:\n                    X_norm_squared = X_norm**2\n                    row_sums = X_norm_squared.sum(axis=1)\n\n                assert_array_almost_equal(row_sums, ones)\n\n    # Test return_norm\n    X_dense = np.array([[3.0, 0, 4.0], [1.0, 0.0, 0.0], [2.0, 3.0, 0.0]])\n    for norm in (\"l1\", \"l2\", \"max\"):\n        _, norms = normalize(X_dense, norm=norm, return_norm=True)\n        if norm == \"l1\":\n            assert_array_almost_equal(norms, np.array([7.0, 1.0, 5.0]))\n        elif norm == \"l2\":\n            assert_array_almost_equal(norms, np.array([5.0, 1.0, 3.60555127]))\n        else:\n            assert_array_almost_equal(norms, np.array([4.0, 1.0, 3.0]))\n\n    X_sparse = csr_container(X_dense)\n    for norm in (\"l1\", \"l2\"):\n        with pytest.raises(NotImplementedError):\n            normalize(X_sparse, norm=norm, return_norm=True)\n    _, norms = normalize(X_sparse, norm=\"max\", return_norm=True)\n    assert_array_almost_equal(norms, np.array([4.0, 1.0, 3.0]))\n\n\n@pytest.mark.parametrize(\n    \"constructor\", [np.array, list] + CSC_CONTAINERS + CSR_CONTAINERS\n)\ndef test_binarizer(constructor):\n    X_ = np.array([[1, 0, 5], [2, 3, -1]])\n    X = constructor(X_.copy())\n\n    binarizer = Binarizer(threshold=2.0, copy=True)\n    X_bin = toarray(binarizer.transform(X))\n    assert np.sum(X_bin == 0) == 4\n    assert np.sum(X_bin == 1)"}], "retrieved_count": 10, "cost_time": 1.3487489223480225}
{"question": "Why does the SplineTransformer use a diagonal coefficient matrix during fit, and how does this design choice enable the generation of the spline basis functions?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"start_line": 22000, "end_line": 24000, "belongs_to": {"file_name": "_polynomial.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/preprocessing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "          X[:, feature_idx : feature_idx + 1],\n                            out=XP[:, current_col:next_col],\n                            casting=\"no\",\n                        )\n                    else:\n                        XP[:, current_col:next_col] = xp.multiply(\n                            XP[:, start:end], X[:, feature_idx : feature_idx + 1]\n                        )\n                    current_col = next_col\n\n                new_index.append(current_col)\n                index = new_index\n\n            if self._min_degree > 1:\n                n_XP, n_Xout = self._n_out_full, self.n_output_features_\n                if self.include_bias:\n                    Xout = xp.empty(\n                        shape=(n_samples, n_Xout),\n                        dtype=XP.dtype,\n                        device=device_,\n                        **order_kwargs,\n                    )\n                    Xout[:, 0] = 1\n                    Xout[:, 1:] = XP[:, n_XP - n_Xout + 1 :]\n                else:\n                    Xout = xp.asarray(XP[:, n_XP - n_Xout :], copy=True)\n                XP = Xout\n        return XP\n\n    def __sklearn_tags__(self):\n        tags = super().__sklearn_tags__()\n        tags.input_tags.sparse = True\n        tags.array_api_support = True\n        return tags\n\n\nclass SplineTransformer(TransformerMixin, BaseEstimator):\n    \"\"\"Generate univariate B-spline bases for features.\n\n    Generate a new feature matrix consisting of\n    `n_splines=n_knots + degree - 1` (`n_knots - 1` for\n    `extrapolation=\"periodic\"`) spline basis functions\n    (B-splines) of polynomial order=`degree` for each feature.\n\n    In order to learn more about the SplineTransformer class go to:\n    :ref:`sphx_glr_auto_examples_applications_plot_cyclical_feature_engineering.py`\n\n    Read more in the :ref:`User Guide <spline_transformer>`.\n\n    .. versionadded:: 1.0\n\n    Parameters\n    ----------\n    n_knots : int, default=5\n        Number of knots of the splines if `knots` equals one of\n        {"}, {"start_line": 27000, "end_line": 29000, "belongs_to": {"file_name": "_polynomial.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/preprocessing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "option simply sets all spline basis function values to zero at the\n        missing values.\n\n        .. versionadded:: 1.8\n\n    sparse_output : bool, default=False\n        Will return sparse CSR matrix if set True else will return an array.\n\n        .. versionadded:: 1.2\n\n    Attributes\n    ----------\n    bsplines_ : list of shape (n_features,)\n        List of BSplines objects, one for each feature.\n\n    n_features_in_ : int\n        The total number of input features.\n\n    feature_names_in_ : ndarray of shape (`n_features_in_`,)\n        Names of features seen during :term:`fit`. Defined only when `X`\n        has feature names that are all strings.\n\n        .. versionadded:: 1.0\n\n    n_features_out_ : int\n        The total number of output features, which is computed as\n        `n_features * n_splines`, where `n_splines` is\n        the number of bases elements of the B-splines,\n        `n_knots + degree - 1` for non-periodic splines and\n        `n_knots - 1` for periodic ones.\n        If `include_bias=False`, then it is only\n        `n_features * (n_splines - 1)`.\n\n    See Also\n    --------\n    KBinsDiscretizer : Transformer that bins continuous data into intervals.\n\n    PolynomialFeatures : Transformer that generates polynomial and interaction\n        features.\n\n    Notes\n    -----\n    High degrees and a high number of knots can cause overfitting.\n\n    See :ref:`examples/linear_model/plot_polynomial_interpolation.py\n    <sphx_glr_auto_examples_linear_model_plot_polynomial_interpolation.py>`.\n\n    Examples\n    --------\n    >>> import numpy as np\n    >>> from sklearn.preprocessing import SplineTransformer\n    >>> X = np.arange(6).reshape(6, 1)\n    >>> spline = SplineTransformer(degree=2, n_knots=3)\n    >>> spline.fit_transform(X)\n    array([[0.5 , 0.5 , 0.  , 0.  ],\n           [0.18, 0.74, 0.08, 0.  ],\n           [0.02, 0.66, 0.32, 0.  ],\n           [0.  , 0.32, 0.66, 0.02],\n           [0.  , 0.08, 0.74, 0.18],\n           [0.  , 0.  , 0.5 , 0.5 ]])\n    \"\"\"\n\n    _parame"}, {"start_line": 23000, "end_line": 25000, "belongs_to": {"file_name": "_polynomial.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/preprocessing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "                  Xout = xp.asarray(XP[:, n_XP - n_Xout :], copy=True)\n                XP = Xout\n        return XP\n\n    def __sklearn_tags__(self):\n        tags = super().__sklearn_tags__()\n        tags.input_tags.sparse = True\n        tags.array_api_support = True\n        return tags\n\n\nclass SplineTransformer(TransformerMixin, BaseEstimator):\n    \"\"\"Generate univariate B-spline bases for features.\n\n    Generate a new feature matrix consisting of\n    `n_splines=n_knots + degree - 1` (`n_knots - 1` for\n    `extrapolation=\"periodic\"`) spline basis functions\n    (B-splines) of polynomial order=`degree` for each feature.\n\n    In order to learn more about the SplineTransformer class go to:\n    :ref:`sphx_glr_auto_examples_applications_plot_cyclical_feature_engineering.py`\n\n    Read more in the :ref:`User Guide <spline_transformer>`.\n\n    .. versionadded:: 1.0\n\n    Parameters\n    ----------\n    n_knots : int, default=5\n        Number of knots of the splines if `knots` equals one of\n        {'uniform', 'quantile'}. Must be larger or equal 2. Ignored if `knots`\n        is array-like.\n\n    degree : int, default=3\n        The polynomial degree of the spline basis. Must be a non-negative\n        integer.\n\n    knots : {'uniform', 'quantile'} or array-like of shape \\\n        (n_knots, n_features), default='uniform'\n        Set knot positions such that first knot <= features <= last knot.\n\n        - If 'uniform', `n_knots` number of knots are distributed uniformly\n          from min to max values of the features.\n        - If 'quantile', they are distributed uniformly along the quantiles of\n          the features.\n        - If an array-like is given, it directly specifies the sorted knot\n          positions including the boundary knots. Note that, internally,\n          `degree` number of knots are added before the first knot, the same\n          after the last knot.\n\n    extrapolation : {'error', 'constant', 'linear', 'continue', 'periodic'}, \\\n        default='constant'\n        I"}, {"start_line": 28000, "end_line": 30000, "belongs_to": {"file_name": "_polynomial.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/preprocessing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": " `include_bias=False`, then it is only\n        `n_features * (n_splines - 1)`.\n\n    See Also\n    --------\n    KBinsDiscretizer : Transformer that bins continuous data into intervals.\n\n    PolynomialFeatures : Transformer that generates polynomial and interaction\n        features.\n\n    Notes\n    -----\n    High degrees and a high number of knots can cause overfitting.\n\n    See :ref:`examples/linear_model/plot_polynomial_interpolation.py\n    <sphx_glr_auto_examples_linear_model_plot_polynomial_interpolation.py>`.\n\n    Examples\n    --------\n    >>> import numpy as np\n    >>> from sklearn.preprocessing import SplineTransformer\n    >>> X = np.arange(6).reshape(6, 1)\n    >>> spline = SplineTransformer(degree=2, n_knots=3)\n    >>> spline.fit_transform(X)\n    array([[0.5 , 0.5 , 0.  , 0.  ],\n           [0.18, 0.74, 0.08, 0.  ],\n           [0.02, 0.66, 0.32, 0.  ],\n           [0.  , 0.32, 0.66, 0.02],\n           [0.  , 0.08, 0.74, 0.18],\n           [0.  , 0.  , 0.5 , 0.5 ]])\n    \"\"\"\n\n    _parameter_constraints: dict = {\n        \"n_knots\": [Interval(Integral, 2, None, closed=\"left\")],\n        \"degree\": [Interval(Integral, 0, None, closed=\"left\")],\n        \"knots\": [StrOptions({\"uniform\", \"quantile\"}), \"array-like\"],\n        \"extrapolation\": [\n            StrOptions({\"error\", \"constant\", \"linear\", \"continue\", \"periodic\"})\n        ],\n        \"include_bias\": [\"boolean\"],\n        \"order\": [StrOptions({\"C\", \"F\"})],\n        \"handle_missing\": [StrOptions({\"error\", \"zeros\"})],\n        \"sparse_output\": [\"boolean\"],\n    }\n\n    def __init__(\n        self,\n        n_knots=5,\n        degree=3,\n        *,\n        knots=\"uniform\",\n        extrapolation=\"constant\",\n        include_bias=True,\n        order=\"C\",\n        handle_missing=\"error\",\n        sparse_output=False,\n    ):\n        self.n_knots = n_knots\n        self.degree = degree\n        self.knots = knots\n        self.extrapolation = extrapolation\n        self.include_bias = include_bias\n        self.order = order\n        self.handle_m"}, {"start_line": 37000, "end_line": 39000, "belongs_to": {"file_name": "_polynomial.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/preprocessing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "            ]\n\n        else:\n            # Eilers & Marx in \"Flexible smoothing with B-splines and\n            # penalties\" https://doi.org/10.1214/ss/1038425655 advice\n            # against repeating first and last knot several times, which\n            # would have inferior behaviour at boundaries if combined with\n            # a penalty (hence P-Spline). We follow this advice even if our\n            # splines are unpenalized. Meaning we do not:\n            # knots = np.r_[\n            #     np.tile(base_knots.min(axis=0), reps=[degree, 1]),\n            #     base_knots,\n            #     np.tile(base_knots.max(axis=0), reps=[degree, 1])\n            # ]\n            # Instead, we reuse the distance of the 2 fist/last knots.\n            dist_min = base_knots[1] - base_knots[0]\n            dist_max = base_knots[-1] - base_knots[-2]\n\n            knots = np.r_[\n                np.linspace(\n                    base_knots[0] - degree * dist_min,\n                    base_knots[0] - dist_min,\n                    num=degree,\n                ),\n                base_knots,\n                np.linspace(\n                    base_knots[-1] + dist_max,\n                    base_knots[-1] + degree * dist_max,\n                    num=degree,\n                ),\n            ]\n\n        # With a diagonal coefficient matrix, we get back the spline basis\n        # elements, i.e. the design matrix of the spline.\n        # Note, BSpline appreciates C-contiguous float64 arrays as c=coef.\n        coef = np.eye(n_splines, dtype=np.float64)\n        if self.extrapolation == \"periodic\":\n            coef = np.concatenate((coef, coef[:degree, :]))\n\n        extrapolate = self.extrapolation in [\"periodic\", \"continue\"]\n\n        bsplines = [\n            BSpline.construct_fast(\n                knots[:, i], coef, self.degree, extrapolate=extrapolate\n            )\n            for i in range(n_features)\n        ]\n        self.bsplines_ = bsplines\n\n        self.n_features_out_ = n_out - n_features * (1 - self"}, {"start_line": 44000, "end_line": 46000, "belongs_to": {"file_name": "_polynomial.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/preprocessing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "fit. We need to add the last\n                        # degree spline basis function to the first degree ones and\n                        # then drop the last ones.\n                        # Note: See comment about SparseEfficiencyWarning below.\n                        XBS_sparse = XBS_sparse.tolil()\n                        XBS_sparse[:, :degree] += XBS_sparse[:, -degree:]\n                        XBS_sparse = XBS_sparse[:, :-degree]\n\n                    if nan_row_indices.shape[0] > 0:\n                        # Note: See comment about SparseEfficiencyWarning below.\n                        XBS = XBS_sparse.tolil()\n\n                else:\n                    XBS[\n                        :, (feature_idx * n_splines) : ((feature_idx + 1) * n_splines)\n                    ] = spl(x)\n\n                # Replace any indicated values with 0:\n                if nan_row_indices.shape[0] > 0:\n                    for spline_idx in range(n_splines):\n                        output_feature_idx = n_splines * feature_idx + spline_idx\n                        XBS[\n                            nan_row_indices, output_feature_idx : output_feature_idx + 1\n                        ] = 0\n                    if use_sparse:\n                        XBS_sparse = XBS\n\n            else:  # extrapolation in (\"constant\", \"linear\")\n                xmin, xmax = spl.t[degree], spl.t[-degree - 1]\n                # spline values at boundaries\n                f_min, f_max = spl(xmin), spl(xmax)\n                # Values outside of the feature range during fit and nan values get\n                # filtered out:\n                inside_range_mask = (xmin <= X[:, feature_idx]) & (\n                    X[:, feature_idx] <= xmax\n                )\n\n                if use_sparse:\n                    outside_range_mask = ~inside_range_mask\n                    x = X[:, feature_idx].copy()\n                    # Set to some arbitrary value within the range of values\n                    # observed on the training set before "}, {"start_line": 45000, "end_line": 47000, "belongs_to": {"file_name": "_polynomial.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/preprocessing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "s * feature_idx + spline_idx\n                        XBS[\n                            nan_row_indices, output_feature_idx : output_feature_idx + 1\n                        ] = 0\n                    if use_sparse:\n                        XBS_sparse = XBS\n\n            else:  # extrapolation in (\"constant\", \"linear\")\n                xmin, xmax = spl.t[degree], spl.t[-degree - 1]\n                # spline values at boundaries\n                f_min, f_max = spl(xmin), spl(xmax)\n                # Values outside of the feature range during fit and nan values get\n                # filtered out:\n                inside_range_mask = (xmin <= X[:, feature_idx]) & (\n                    X[:, feature_idx] <= xmax\n                )\n\n                if use_sparse:\n                    outside_range_mask = ~inside_range_mask\n                    x = X[:, feature_idx].copy()\n                    # Set to some arbitrary value within the range of values\n                    # observed on the training set before calling\n                    # BSpline.design_matrix. Those transformed will be\n                    # reassigned later when handling with extrapolation.\n                    x[outside_range_mask] = xmin\n                    XBS_sparse = BSpline.design_matrix(x, spl.t, spl.k)\n                    # Note: Without converting to lil_matrix we would get:\n                    # scipy.sparse._base.SparseEfficiencyWarning: Changing the sparsity\n                    # structure of a csr_matrix is expensive. lil_matrix is more\n                    # efficient.\n                    if np.any(outside_range_mask):\n                        XBS_sparse = XBS_sparse.tolil()\n                        XBS_sparse[outside_range_mask, :] = 0\n\n                else:\n                    XBS[\n                        inside_range_mask,\n                        (feature_idx * n_splines) : ((feature_idx + 1) * n_splines),\n                    ] = spl(X[inside_range_mask, feature_idx])\n\n            # Note for extrapolation:\n   "}, {"start_line": 38000, "end_line": 40000, "belongs_to": {"file_name": "_polynomial.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/preprocessing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "                    num=degree,\n                ),\n                base_knots,\n                np.linspace(\n                    base_knots[-1] + dist_max,\n                    base_knots[-1] + degree * dist_max,\n                    num=degree,\n                ),\n            ]\n\n        # With a diagonal coefficient matrix, we get back the spline basis\n        # elements, i.e. the design matrix of the spline.\n        # Note, BSpline appreciates C-contiguous float64 arrays as c=coef.\n        coef = np.eye(n_splines, dtype=np.float64)\n        if self.extrapolation == \"periodic\":\n            coef = np.concatenate((coef, coef[:degree, :]))\n\n        extrapolate = self.extrapolation in [\"periodic\", \"continue\"]\n\n        bsplines = [\n            BSpline.construct_fast(\n                knots[:, i], coef, self.degree, extrapolate=extrapolate\n            )\n            for i in range(n_features)\n        ]\n        self.bsplines_ = bsplines\n\n        self.n_features_out_ = n_out - n_features * (1 - self.include_bias)\n        return self\n\n    def transform(self, X):\n        \"\"\"Transform each feature data to B-splines.\n\n        Parameters\n        ----------\n        X : array-like of shape (n_samples, n_features)\n            The data to transform.\n\n        Returns\n        -------\n        XBS : {ndarray, sparse matrix} of shape (n_samples, n_features * n_splines)\n            The matrix of features, where n_splines is the number of bases\n            elements of the B-splines, n_knots + degree - 1.\n        \"\"\"\n        check_is_fitted(self)\n\n        X = validate_data(\n            self,\n            X,\n            reset=False,\n            accept_sparse=False,\n            ensure_2d=True,\n            ensure_all_finite=(self.handle_missing != \"zeros\"),\n        )\n\n        n_samples, n_features = X.shape\n        n_splines = self.bsplines_[0].c.shape[1]\n        degree = self.degree\n\n        # TODO: Remove this condition, once scipy 1.10 is the minimum version.\n        #       Only scipy >= 1.10 sup"}, {"start_line": 43000, "end_line": 45000, "belongs_to": {"file_name": "_polynomial.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/preprocessing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "  # when `extrapolation == \"error\"`. Any other choice of\n                    # in-range value would have worked work since the\n                    # corresponding values in the array are replaced by zeros.\n                    if nan_row_indices.size == x.size:\n                        # The column is all np.nan valued. Replace it by a\n                        # constant column with an arbitrary non-nan value\n                        # inside so that it is encoded as constant column.\n                        x = np.zeros_like(x)  # avoid mutation of input data\n                    elif nan_row_indices.shape[0] > 0:\n                        x = x.copy()  # avoid mutation of input data\n                        x[nan_row_indices] = np.nanmin(x)\n                    XBS_sparse = BSpline.design_matrix(\n                        x, spl.t, spl.k, **kwargs_extrapolate\n                    )\n\n                    if self.extrapolation == \"periodic\":\n                        # See the construction of coef in fit. We need to add the last\n                        # degree spline basis function to the first degree ones and\n                        # then drop the last ones.\n                        # Note: See comment about SparseEfficiencyWarning below.\n                        XBS_sparse = XBS_sparse.tolil()\n                        XBS_sparse[:, :degree] += XBS_sparse[:, -degree:]\n                        XBS_sparse = XBS_sparse[:, :-degree]\n\n                    if nan_row_indices.shape[0] > 0:\n                        # Note: See comment about SparseEfficiencyWarning below.\n                        XBS = XBS_sparse.tolil()\n\n                else:\n                    XBS[\n                        :, (feature_idx * n_splines) : ((feature_idx + 1) * n_splines)\n                    ] = spl(x)\n\n                # Replace any indicated values with 0:\n                if nan_row_indices.shape[0] > 0:\n                    for spline_idx in range(n_splines):\n                        output_feature_idx = n_spline"}, {"start_line": 4000, "end_line": 6000, "belongs_to": {"file_name": "test_polynomial.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/preprocessing/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": " splt.n_features_out_\n\n    X_trans = splt.transform(X)\n    assert X_trans.shape[1] == len(feature_names)\n\n\n@pytest.mark.parametrize(\"degree\", range(1, 5))\n@pytest.mark.parametrize(\"n_knots\", range(3, 5))\n@pytest.mark.parametrize(\"knots\", [\"uniform\", \"quantile\"])\n@pytest.mark.parametrize(\"extrapolation\", [\"constant\", \"periodic\"])\ndef test_spline_transformer_unity_decomposition(degree, n_knots, knots, extrapolation):\n    \"\"\"Test that B-splines are indeed a decomposition of unity.\n\n    Splines basis functions must sum up to 1 per row, if we stay in between boundaries.\n    \"\"\"\n    X = np.linspace(0, 1, 100)[:, None]\n    # make the boundaries 0 and 1 part of X_train, for sure.\n    X_train = np.r_[[[0]], X[::2, :], [[1]]]\n    X_test = X[1::2, :]\n\n    if extrapolation == \"periodic\":\n        n_knots = n_knots + degree  # periodic splines require degree < n_knots\n\n    splt = SplineTransformer(\n        n_knots=n_knots,\n        degree=degree,\n        knots=knots,\n        include_bias=True,\n        extrapolation=extrapolation,\n    )\n    splt.fit(X_train)\n    for X in [X_train, X_test]:\n        assert_allclose(np.sum(splt.transform(X), axis=1), 1)\n\n\n@pytest.mark.parametrize([\"bias\", \"intercept\"], [(True, False), (False, True)])\ndef test_spline_transformer_linear_regression(bias, intercept):\n    \"\"\"Test that B-splines fit a sinusodial curve pretty well.\"\"\"\n    X = np.linspace(0, 10, 100)[:, None]\n    y = np.sin(X[:, 0]) + 2  # +2 to avoid the value 0 in assert_allclose\n    pipe = Pipeline(\n        steps=[\n            (\n                \"spline\",\n                SplineTransformer(\n                    n_knots=15,\n                    degree=3,\n                    include_bias=bias,\n                    extrapolation=\"constant\",\n                ),\n            ),\n            (\"ols\", LinearRegression(fit_intercept=intercept)),\n        ]\n    )\n    pipe.fit(X, y)\n    assert_allclose(pipe.predict(X), y, rtol=1e-3)\n\n\n@pytest.mark.parametrize(\n    [\"knots\", \"n_knots\", \"sample_weight\", \"expect"}], "retrieved_count": 10, "cost_time": 1.3611152172088623}
{"question": "Why does the SplineTransformer add degree number of knots both before and after the base knots during the fit process, and why does the periodic extrapolation mode require a fundamentally different knot extension strategy?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"start_line": 36000, "end_line": 38000, "belongs_to": {"file_name": "_polynomial.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/preprocessing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "                f\"{n_knots} and degree={self.degree}.\"\n            )\n\n        # number of splines basis functions\n        if self.extrapolation != \"periodic\":\n            n_splines = n_knots + self.degree - 1\n        else:\n            # periodic splines have self.degree less degrees of freedom\n            n_splines = n_knots - 1\n\n        degree = self.degree\n        n_out = n_features * n_splines\n        # We have to add degree number of knots below, and degree number knots\n        # above the base knots in order to make the spline basis complete.\n        if self.extrapolation == \"periodic\":\n            # For periodic splines the spacing of the first / last degree knots\n            # needs to be a continuation of the spacing of the last / first\n            # base knots.\n            period = base_knots[-1] - base_knots[0]\n            knots = np.r_[\n                base_knots[-(degree + 1) : -1] - period,\n                base_knots,\n                base_knots[1 : (degree + 1)] + period,\n            ]\n\n        else:\n            # Eilers & Marx in \"Flexible smoothing with B-splines and\n            # penalties\" https://doi.org/10.1214/ss/1038425655 advice\n            # against repeating first and last knot several times, which\n            # would have inferior behaviour at boundaries if combined with\n            # a penalty (hence P-Spline). We follow this advice even if our\n            # splines are unpenalized. Meaning we do not:\n            # knots = np.r_[\n            #     np.tile(base_knots.min(axis=0), reps=[degree, 1]),\n            #     base_knots,\n            #     np.tile(base_knots.max(axis=0), reps=[degree, 1])\n            # ]\n            # Instead, we reuse the distance of the 2 fist/last knots.\n            dist_min = base_knots[1] - base_knots[0]\n            dist_max = base_knots[-1] - base_knots[-2]\n\n            knots = np.r_[\n                np.linspace(\n                    base_knots[0] - degree * dist_min,\n                    base_knots[0] - dist_min,\n"}, {"start_line": 37000, "end_line": 39000, "belongs_to": {"file_name": "_polynomial.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/preprocessing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "            ]\n\n        else:\n            # Eilers & Marx in \"Flexible smoothing with B-splines and\n            # penalties\" https://doi.org/10.1214/ss/1038425655 advice\n            # against repeating first and last knot several times, which\n            # would have inferior behaviour at boundaries if combined with\n            # a penalty (hence P-Spline). We follow this advice even if our\n            # splines are unpenalized. Meaning we do not:\n            # knots = np.r_[\n            #     np.tile(base_knots.min(axis=0), reps=[degree, 1]),\n            #     base_knots,\n            #     np.tile(base_knots.max(axis=0), reps=[degree, 1])\n            # ]\n            # Instead, we reuse the distance of the 2 fist/last knots.\n            dist_min = base_knots[1] - base_knots[0]\n            dist_max = base_knots[-1] - base_knots[-2]\n\n            knots = np.r_[\n                np.linspace(\n                    base_knots[0] - degree * dist_min,\n                    base_knots[0] - dist_min,\n                    num=degree,\n                ),\n                base_knots,\n                np.linspace(\n                    base_knots[-1] + dist_max,\n                    base_knots[-1] + degree * dist_max,\n                    num=degree,\n                ),\n            ]\n\n        # With a diagonal coefficient matrix, we get back the spline basis\n        # elements, i.e. the design matrix of the spline.\n        # Note, BSpline appreciates C-contiguous float64 arrays as c=coef.\n        coef = np.eye(n_splines, dtype=np.float64)\n        if self.extrapolation == \"periodic\":\n            coef = np.concatenate((coef, coef[:degree, :]))\n\n        extrapolate = self.extrapolation in [\"periodic\", \"continue\"]\n\n        bsplines = [\n            BSpline.construct_fast(\n                knots[:, i], coef, self.degree, extrapolate=extrapolate\n            )\n            for i in range(n_features)\n        ]\n        self.bsplines_ = bsplines\n\n        self.n_features_out_ = n_out - n_features * (1 - self"}, {"start_line": 5000, "end_line": 7000, "belongs_to": {"file_name": "plot_polynomial_interpolation.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/examples/linear_model", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "umber of additional\n# knots each to the left and to the right of the fitted interval. These are\n# there for technical reasons, so we refrain from showing them. Every basis\n# function has local support and is continued as a constant beyond the fitted\n# range. This extrapolating behaviour could be changed by the argument\n# ``extrapolation``.\n\n# %%\n# Periodic Splines\n# ----------------\n# In the previous example we saw the limitations of polynomials and splines for\n# extrapolation beyond the range of the training observations. In some\n# settings, e.g. with seasonal effects, we expect a periodic continuation of\n# the underlying signal. Such effects can be modelled using periodic splines,\n# which have equal function value and equal derivatives at the first and last\n# knot. In the following case we show how periodic splines provide a better fit\n# both within and outside of the range of training data given the additional\n# information of periodicity. The splines period is the distance between\n# the first and last knot, which we specify manually.\n#\n# Periodic splines can also be useful for naturally periodic features (such as\n# day of the year), as the smoothness at the boundary knots prevents a jump in\n# the transformed values (e.g. from Dec 31st to Jan 1st). For such naturally\n# periodic features or more generally features where the period is known, it is\n# advised to explicitly pass this information to the `SplineTransformer` by\n# setting the knots manually.\n\n\n# %%\ndef g(x):\n    \"\"\"Function to be approximated by periodic spline interpolation.\"\"\"\n    return np.sin(x) - 0.7 * np.cos(x * 3)\n\n\ny_train = g(x_train)\n\n# Extend the test data into the future:\nx_plot_ext = np.linspace(-1, 21, 200)\nX_plot_ext = x_plot_ext[:, np.newaxis]\n\nlw = 2\nfig, ax = plt.subplots()\nax.set_prop_cycle(color=[\"black\", \"tomato\", \"teal\"])\nax.plot(x_plot_ext, g(x_plot_ext), linewidth=lw, label=\"ground truth\")\nax.scatter(x_train, y_train, label=\"training points\")\n\nfor transformer, label in [\n    (Splin"}, {"start_line": 23000, "end_line": 25000, "belongs_to": {"file_name": "_polynomial.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/preprocessing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "                  Xout = xp.asarray(XP[:, n_XP - n_Xout :], copy=True)\n                XP = Xout\n        return XP\n\n    def __sklearn_tags__(self):\n        tags = super().__sklearn_tags__()\n        tags.input_tags.sparse = True\n        tags.array_api_support = True\n        return tags\n\n\nclass SplineTransformer(TransformerMixin, BaseEstimator):\n    \"\"\"Generate univariate B-spline bases for features.\n\n    Generate a new feature matrix consisting of\n    `n_splines=n_knots + degree - 1` (`n_knots - 1` for\n    `extrapolation=\"periodic\"`) spline basis functions\n    (B-splines) of polynomial order=`degree` for each feature.\n\n    In order to learn more about the SplineTransformer class go to:\n    :ref:`sphx_glr_auto_examples_applications_plot_cyclical_feature_engineering.py`\n\n    Read more in the :ref:`User Guide <spline_transformer>`.\n\n    .. versionadded:: 1.0\n\n    Parameters\n    ----------\n    n_knots : int, default=5\n        Number of knots of the splines if `knots` equals one of\n        {'uniform', 'quantile'}. Must be larger or equal 2. Ignored if `knots`\n        is array-like.\n\n    degree : int, default=3\n        The polynomial degree of the spline basis. Must be a non-negative\n        integer.\n\n    knots : {'uniform', 'quantile'} or array-like of shape \\\n        (n_knots, n_features), default='uniform'\n        Set knot positions such that first knot <= features <= last knot.\n\n        - If 'uniform', `n_knots` number of knots are distributed uniformly\n          from min to max values of the features.\n        - If 'quantile', they are distributed uniformly along the quantiles of\n          the features.\n        - If an array-like is given, it directly specifies the sorted knot\n          positions including the boundary knots. Note that, internally,\n          `degree` number of knots are added before the first knot, the same\n          after the last knot.\n\n    extrapolation : {'error', 'constant', 'linear', 'continue', 'periodic'}, \\\n        default='constant'\n        I"}, {"start_line": 28000, "end_line": 30000, "belongs_to": {"file_name": "_polynomial.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/preprocessing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": " `include_bias=False`, then it is only\n        `n_features * (n_splines - 1)`.\n\n    See Also\n    --------\n    KBinsDiscretizer : Transformer that bins continuous data into intervals.\n\n    PolynomialFeatures : Transformer that generates polynomial and interaction\n        features.\n\n    Notes\n    -----\n    High degrees and a high number of knots can cause overfitting.\n\n    See :ref:`examples/linear_model/plot_polynomial_interpolation.py\n    <sphx_glr_auto_examples_linear_model_plot_polynomial_interpolation.py>`.\n\n    Examples\n    --------\n    >>> import numpy as np\n    >>> from sklearn.preprocessing import SplineTransformer\n    >>> X = np.arange(6).reshape(6, 1)\n    >>> spline = SplineTransformer(degree=2, n_knots=3)\n    >>> spline.fit_transform(X)\n    array([[0.5 , 0.5 , 0.  , 0.  ],\n           [0.18, 0.74, 0.08, 0.  ],\n           [0.02, 0.66, 0.32, 0.  ],\n           [0.  , 0.32, 0.66, 0.02],\n           [0.  , 0.08, 0.74, 0.18],\n           [0.  , 0.  , 0.5 , 0.5 ]])\n    \"\"\"\n\n    _parameter_constraints: dict = {\n        \"n_knots\": [Interval(Integral, 2, None, closed=\"left\")],\n        \"degree\": [Interval(Integral, 0, None, closed=\"left\")],\n        \"knots\": [StrOptions({\"uniform\", \"quantile\"}), \"array-like\"],\n        \"extrapolation\": [\n            StrOptions({\"error\", \"constant\", \"linear\", \"continue\", \"periodic\"})\n        ],\n        \"include_bias\": [\"boolean\"],\n        \"order\": [StrOptions({\"C\", \"F\"})],\n        \"handle_missing\": [StrOptions({\"error\", \"zeros\"})],\n        \"sparse_output\": [\"boolean\"],\n    }\n\n    def __init__(\n        self,\n        n_knots=5,\n        degree=3,\n        *,\n        knots=\"uniform\",\n        extrapolation=\"constant\",\n        include_bias=True,\n        order=\"C\",\n        handle_missing=\"error\",\n        sparse_output=False,\n    ):\n        self.n_knots = n_knots\n        self.degree = degree\n        self.knots = knots\n        self.extrapolation = extrapolation\n        self.include_bias = include_bias\n        self.order = order\n        self.handle_m"}, {"start_line": 24000, "end_line": 26000, "belongs_to": {"file_name": "_polynomial.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/preprocessing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "'uniform', 'quantile'}. Must be larger or equal 2. Ignored if `knots`\n        is array-like.\n\n    degree : int, default=3\n        The polynomial degree of the spline basis. Must be a non-negative\n        integer.\n\n    knots : {'uniform', 'quantile'} or array-like of shape \\\n        (n_knots, n_features), default='uniform'\n        Set knot positions such that first knot <= features <= last knot.\n\n        - If 'uniform', `n_knots` number of knots are distributed uniformly\n          from min to max values of the features.\n        - If 'quantile', they are distributed uniformly along the quantiles of\n          the features.\n        - If an array-like is given, it directly specifies the sorted knot\n          positions including the boundary knots. Note that, internally,\n          `degree` number of knots are added before the first knot, the same\n          after the last knot.\n\n    extrapolation : {'error', 'constant', 'linear', 'continue', 'periodic'}, \\\n        default='constant'\n        If 'error', values outside the min and max values of the training\n        features raises a `ValueError`. If 'constant', the value of the\n        splines at minimum and maximum value of the features is used as\n        constant extrapolation. If 'linear', a linear extrapolation is used.\n        If 'continue', the splines are extrapolated as is, i.e. option\n        `extrapolate=True` in :class:`scipy.interpolate.BSpline`. If\n        'periodic', periodic splines with a periodicity equal to the distance\n        between the first and last knot are used. Periodic splines enforce\n        equal function values and derivatives at the first and last knot.\n        For example, this makes it possible to avoid introducing an arbitrary\n        jump between Dec 31st and Jan 1st in spline features derived from a\n        naturally periodic \"day-of-year\" input feature. In this case it is\n        recommended to manually set the knot values to control the period.\n\n    include_bias : bool, default=True\n    "}, {"start_line": 8000, "end_line": 10000, "belongs_to": {"file_name": "test_polynomial.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/preprocessing/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": " assert_allclose(predictions[0:100], predictions[100:200], rtol=1e-3)\n\n\ndef test_spline_transformer_periodic_spline_backport():\n    \"\"\"Test that the backport of extrapolate=\"periodic\" works correctly\"\"\"\n    X = np.linspace(-2, 3.5, 10)[:, None]\n    degree = 2\n\n    # Use periodic extrapolation backport in SplineTransformer\n    transformer = SplineTransformer(\n        degree=degree, extrapolation=\"periodic\", knots=[[-1.0], [0.0], [1.0]]\n    )\n    Xt = transformer.fit_transform(X)\n\n    # Use periodic extrapolation in BSpline\n    coef = np.array([[1.0, 0.0], [0.0, 1.0], [1.0, 0.0], [0.0, 1.0]])\n    spl = BSpline(np.arange(-3, 4), coef, degree, \"periodic\")\n    Xspl = spl(X[:, 0])\n    assert_allclose(Xt, Xspl)\n\n\ndef test_spline_transformer_periodic_splines_periodicity():\n    \"\"\"Test if shifted knots result in the same transformation up to permutation.\"\"\"\n    X = np.linspace(0, 10, 101)[:, None]\n\n    transformer_1 = SplineTransformer(\n        degree=3,\n        extrapolation=\"periodic\",\n        knots=[[0.0], [1.0], [3.0], [4.0], [5.0], [8.0]],\n    )\n\n    transformer_2 = SplineTransformer(\n        degree=3,\n        extrapolation=\"periodic\",\n        knots=[[1.0], [3.0], [4.0], [5.0], [8.0], [9.0]],\n    )\n\n    Xt_1 = transformer_1.fit_transform(X)\n    Xt_2 = transformer_2.fit_transform(X)\n\n    assert_allclose(Xt_1, Xt_2[:, [4, 0, 1, 2, 3]])\n\n\n@pytest.mark.parametrize(\"degree\", [3, 5])\ndef test_spline_transformer_periodic_splines_smoothness(degree):\n    \"\"\"Test that spline transformation is smooth at first / last knot.\"\"\"\n    X = np.linspace(-2, 10, 10_000)[:, None]\n\n    transformer = SplineTransformer(\n        degree=degree,\n        extrapolation=\"periodic\",\n        knots=[[0.0], [1.0], [3.0], [4.0], [5.0], [8.0]],\n    )\n    Xt = transformer.fit_transform(X)\n\n    delta = (X.max() - X.min()) / len(X)\n    tol = 10 * delta\n\n    dXt = Xt\n    # We expect splines of degree `degree` to be (`degree`-1) times\n    # continuously differentiable. I.e. for d = 0, ..., `degree` - 1 the d-th"}, {"start_line": 27000, "end_line": 29000, "belongs_to": {"file_name": "_polynomial.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/preprocessing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "option simply sets all spline basis function values to zero at the\n        missing values.\n\n        .. versionadded:: 1.8\n\n    sparse_output : bool, default=False\n        Will return sparse CSR matrix if set True else will return an array.\n\n        .. versionadded:: 1.2\n\n    Attributes\n    ----------\n    bsplines_ : list of shape (n_features,)\n        List of BSplines objects, one for each feature.\n\n    n_features_in_ : int\n        The total number of input features.\n\n    feature_names_in_ : ndarray of shape (`n_features_in_`,)\n        Names of features seen during :term:`fit`. Defined only when `X`\n        has feature names that are all strings.\n\n        .. versionadded:: 1.0\n\n    n_features_out_ : int\n        The total number of output features, which is computed as\n        `n_features * n_splines`, where `n_splines` is\n        the number of bases elements of the B-splines,\n        `n_knots + degree - 1` for non-periodic splines and\n        `n_knots - 1` for periodic ones.\n        If `include_bias=False`, then it is only\n        `n_features * (n_splines - 1)`.\n\n    See Also\n    --------\n    KBinsDiscretizer : Transformer that bins continuous data into intervals.\n\n    PolynomialFeatures : Transformer that generates polynomial and interaction\n        features.\n\n    Notes\n    -----\n    High degrees and a high number of knots can cause overfitting.\n\n    See :ref:`examples/linear_model/plot_polynomial_interpolation.py\n    <sphx_glr_auto_examples_linear_model_plot_polynomial_interpolation.py>`.\n\n    Examples\n    --------\n    >>> import numpy as np\n    >>> from sklearn.preprocessing import SplineTransformer\n    >>> X = np.arange(6).reshape(6, 1)\n    >>> spline = SplineTransformer(degree=2, n_knots=3)\n    >>> spline.fit_transform(X)\n    array([[0.5 , 0.5 , 0.  , 0.  ],\n           [0.18, 0.74, 0.08, 0.  ],\n           [0.02, 0.66, 0.32, 0.  ],\n           [0.  , 0.32, 0.66, 0.02],\n           [0.  , 0.08, 0.74, 0.18],\n           [0.  , 0.  , 0.5 , 0.5 ]])\n    \"\"\"\n\n    _parame"}, {"start_line": 22000, "end_line": 24000, "belongs_to": {"file_name": "_polynomial.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/preprocessing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "          X[:, feature_idx : feature_idx + 1],\n                            out=XP[:, current_col:next_col],\n                            casting=\"no\",\n                        )\n                    else:\n                        XP[:, current_col:next_col] = xp.multiply(\n                            XP[:, start:end], X[:, feature_idx : feature_idx + 1]\n                        )\n                    current_col = next_col\n\n                new_index.append(current_col)\n                index = new_index\n\n            if self._min_degree > 1:\n                n_XP, n_Xout = self._n_out_full, self.n_output_features_\n                if self.include_bias:\n                    Xout = xp.empty(\n                        shape=(n_samples, n_Xout),\n                        dtype=XP.dtype,\n                        device=device_,\n                        **order_kwargs,\n                    )\n                    Xout[:, 0] = 1\n                    Xout[:, 1:] = XP[:, n_XP - n_Xout + 1 :]\n                else:\n                    Xout = xp.asarray(XP[:, n_XP - n_Xout :], copy=True)\n                XP = Xout\n        return XP\n\n    def __sklearn_tags__(self):\n        tags = super().__sklearn_tags__()\n        tags.input_tags.sparse = True\n        tags.array_api_support = True\n        return tags\n\n\nclass SplineTransformer(TransformerMixin, BaseEstimator):\n    \"\"\"Generate univariate B-spline bases for features.\n\n    Generate a new feature matrix consisting of\n    `n_splines=n_knots + degree - 1` (`n_knots - 1` for\n    `extrapolation=\"periodic\"`) spline basis functions\n    (B-splines) of polynomial order=`degree` for each feature.\n\n    In order to learn more about the SplineTransformer class go to:\n    :ref:`sphx_glr_auto_examples_applications_plot_cyclical_feature_engineering.py`\n\n    Read more in the :ref:`User Guide <spline_transformer>`.\n\n    .. versionadded:: 1.0\n\n    Parameters\n    ----------\n    n_knots : int, default=5\n        Number of knots of the splines if `knots` equals one of\n        {"}, {"start_line": 9000, "end_line": 11000, "belongs_to": {"file_name": "test_polynomial.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/preprocessing/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "  knots=[[0.0], [1.0], [3.0], [4.0], [5.0], [8.0]],\n    )\n\n    transformer_2 = SplineTransformer(\n        degree=3,\n        extrapolation=\"periodic\",\n        knots=[[1.0], [3.0], [4.0], [5.0], [8.0], [9.0]],\n    )\n\n    Xt_1 = transformer_1.fit_transform(X)\n    Xt_2 = transformer_2.fit_transform(X)\n\n    assert_allclose(Xt_1, Xt_2[:, [4, 0, 1, 2, 3]])\n\n\n@pytest.mark.parametrize(\"degree\", [3, 5])\ndef test_spline_transformer_periodic_splines_smoothness(degree):\n    \"\"\"Test that spline transformation is smooth at first / last knot.\"\"\"\n    X = np.linspace(-2, 10, 10_000)[:, None]\n\n    transformer = SplineTransformer(\n        degree=degree,\n        extrapolation=\"periodic\",\n        knots=[[0.0], [1.0], [3.0], [4.0], [5.0], [8.0]],\n    )\n    Xt = transformer.fit_transform(X)\n\n    delta = (X.max() - X.min()) / len(X)\n    tol = 10 * delta\n\n    dXt = Xt\n    # We expect splines of degree `degree` to be (`degree`-1) times\n    # continuously differentiable. I.e. for d = 0, ..., `degree` - 1 the d-th\n    # derivative should be continuous. This is the case if the (d+1)-th\n    # numerical derivative is reasonably small (smaller than `tol` in absolute\n    # value). We thus compute d-th numeric derivatives for d = 1, ..., `degree`\n    # and compare them to `tol`.\n    #\n    # Note that the 0-th derivative is the function itself, such that we are\n    # also checking its continuity.\n    for d in range(1, degree + 1):\n        # Check continuity of the (d-1)-th derivative\n        diff = np.diff(dXt, axis=0)\n        assert np.abs(diff).max() < tol\n        # Compute d-th numeric derivative\n        dXt = diff / delta\n\n    # As degree `degree` splines are not `degree` times continuously\n    # differentiable at the knots, the `degree + 1`-th numeric derivative\n    # should have spikes at the knots.\n    diff = np.diff(dXt, axis=0)\n    assert np.abs(diff).max() > 1\n\n\n@pytest.mark.parametrize([\"bias\", \"intercept\"], [(True, False), (False, True)])\n@pytest.mark.parametrize(\"degree\", [1, 2, 3, 4, 5])"}], "retrieved_count": 10, "cost_time": 1.3589072227478027}
{"question": "Why does the warm_start mechanism in _posterior_mode() reduce computational overhead during hyperparameter optimization, and what performance trade-offs occur when caching the latent function values across multiple log_marginal_likelihood evaluations?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"start_line": 18000, "end_line": 20000, "belongs_to": {"file_name": "_gpc.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/gaussian_process", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "ior of the latent function values for given\n        inputs and target observations with a Gaussian approximation and uses\n        Newton's iteration to find the mode of this approximation.\n        \"\"\"\n        # Based on Algorithm 3.1 of GPML\n\n        # If warm_start are enabled, we reuse the last solution for the\n        # posterior mode as initialization; otherwise, we initialize with 0\n        if (\n            self.warm_start\n            and hasattr(self, \"f_cached\")\n            and self.f_cached.shape == self.y_train_.shape\n        ):\n            f = self.f_cached\n        else:\n            f = np.zeros_like(self.y_train_, dtype=np.float64)\n\n        # Use Newton's iteration method to find mode of Laplace approximation\n        log_marginal_likelihood = -np.inf\n        for _ in range(self.max_iter_predict):\n            # Line 4\n            pi = expit(f)\n            W = pi * (1 - pi)\n            # Line 5\n            W_sr = np.sqrt(W)\n            W_sr_K = W_sr[:, np.newaxis] * K\n            B = np.eye(W.shape[0]) + W_sr_K * W_sr\n            L = cholesky(B, lower=True)\n            # Line 6\n            b = W * f + (self.y_train_ - pi)\n            # Line 7\n            a = b - W_sr * cho_solve((L, True), W_sr_K.dot(b))\n            # Line 8\n            f = K.dot(a)\n\n            # Line 10: Compute log marginal likelihood in loop and use as\n            #          convergence criterion\n            lml = (\n                -0.5 * a.T.dot(f)\n                - np.log1p(np.exp(-(self.y_train_ * 2 - 1) * f)).sum()\n                - np.log(np.diag(L)).sum()\n            )\n            # Check if we have converged (log marginal likelihood does\n            # not decrease)\n            # XXX: more complex convergence criterion\n            if lml - log_marginal_likelihood < 1e-10:\n                break\n            log_marginal_likelihood = lml\n\n        self.f_cached = f  # Remember solution for later warm-starts\n        if return_temporaries:\n            return log_marginal_likelihood, (pi"}, {"start_line": 17000, "end_line": 19000, "belongs_to": {"file_name": "_gpc.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/gaussian_process", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": " list of object\n            Query points where the GP is evaluated for classification.\n\n        Returns\n        -------\n        latent_mean : array-like of shape (n_samples,)\n            Mean of the latent function values at the query points.\n\n        latent_var : array-like of shape (n_samples,)\n            Variance of the latent function values at the query points.\n        \"\"\"\n        check_is_fitted(self)\n\n        # Based on Algorithm 3.2 of GPML\n        K_star = self.kernel_(self.X_train_, X)  # K_star =k(x_star)\n        latent_mean = K_star.T.dot(self.y_train_ - self.pi_)  # Line 4\n        v = solve(self.L_, self.W_sr_[:, np.newaxis] * K_star)  # Line 5\n        # Line 6 (compute np.diag(v.T.dot(v)) via einsum)\n        latent_var = self.kernel_.diag(X) - np.einsum(\"ij,ij->j\", v, v)\n\n        return latent_mean, latent_var\n\n    def _posterior_mode(self, K, return_temporaries=False):\n        \"\"\"Mode-finding for binary Laplace GPC and fixed kernel.\n\n        This approximates the posterior of the latent function values for given\n        inputs and target observations with a Gaussian approximation and uses\n        Newton's iteration to find the mode of this approximation.\n        \"\"\"\n        # Based on Algorithm 3.1 of GPML\n\n        # If warm_start are enabled, we reuse the last solution for the\n        # posterior mode as initialization; otherwise, we initialize with 0\n        if (\n            self.warm_start\n            and hasattr(self, \"f_cached\")\n            and self.f_cached.shape == self.y_train_.shape\n        ):\n            f = self.f_cached\n        else:\n            f = np.zeros_like(self.y_train_, dtype=np.float64)\n\n        # Use Newton's iteration method to find mode of Laplace approximation\n        log_marginal_likelihood = -np.inf\n        for _ in range(self.max_iter_predict):\n            # Line 4\n            pi = expit(f)\n            W = pi * (1 - pi)\n            # Line 5\n            W_sr = np.sqrt(W)\n            W_sr_K = W_sr[:, np.newaxis] * K\n        "}, {"start_line": 4000, "end_line": 6000, "belongs_to": {"file_name": "_gpc.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/gaussian_process", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "\n        the posterior during predict. Smaller values will reduce computation\n        time at the cost of worse results.\n\n    warm_start : bool, default=False\n        If warm-starts are enabled, the solution of the last Newton iteration\n        on the Laplace approximation of the posterior mode is used as\n        initialization for the next call of _posterior_mode(). This can speed\n        up convergence when _posterior_mode is called several times on similar\n        problems as in hyperparameter optimization. See :term:`the Glossary\n        <warm_start>`.\n\n    copy_X_train : bool, default=True\n        If True, a persistent copy of the training data is stored in the\n        object. Otherwise, just a reference to the training data is stored,\n        which might cause predictions to change if the data is modified\n        externally.\n\n    random_state : int, RandomState instance or None, default=None\n        Determines random number generation used to initialize the centers.\n        Pass an int for reproducible results across multiple function calls.\n        See :term:`Glossary <random_state>`.\n\n    Attributes\n    ----------\n    X_train_ : array-like of shape (n_samples, n_features) or list of object\n        Feature vectors or other representations of training data (also\n        required for prediction).\n\n    y_train_ : array-like of shape (n_samples,)\n        Target values in training data (also required for prediction)\n\n    classes_ : array-like of shape (n_classes,)\n        Unique class labels.\n\n    kernel_ : kernl instance\n        The kernel used for prediction. The structure of the kernel is the\n        same as the one passed as parameter but with optimized hyperparameters\n\n    L_ : array-like of shape (n_samples, n_samples)\n        Lower-triangular Cholesky decomposition of the kernel in X_train_\n\n    pi_ : array-like of shape (n_samples,)\n        The probabilities of the positive class for the training points\n        X_train_\n\n    W_sr_ : array-like of shape (n_"}, {"start_line": 9000, "end_line": 11000, "belongs_to": {"file_name": "_gpc.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/gaussian_process", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": ", clone_kernel=False\n                    )\n                    return -lml, -grad\n                else:\n                    return -self.log_marginal_likelihood(theta, clone_kernel=False)\n\n            # First optimize starting from theta specified in kernel\n            optima = [\n                self._constrained_optimization(\n                    obj_func, self.kernel_.theta, self.kernel_.bounds\n                )\n            ]\n\n            # Additional runs are performed from log-uniform chosen initial\n            # theta\n            if self.n_restarts_optimizer > 0:\n                if not np.isfinite(self.kernel_.bounds).all():\n                    raise ValueError(\n                        \"Multiple optimizer restarts (n_restarts_optimizer>0) \"\n                        \"requires that all bounds are finite.\"\n                    )\n                bounds = self.kernel_.bounds\n                for iteration in range(self.n_restarts_optimizer):\n                    theta_initial = np.exp(self.rng.uniform(bounds[:, 0], bounds[:, 1]))\n                    optima.append(\n                        self._constrained_optimization(obj_func, theta_initial, bounds)\n                    )\n            # Select result from run with minimal (negative) log-marginal\n            # likelihood\n            lml_values = list(map(itemgetter(1), optima))\n            self.kernel_.theta = optima[np.argmin(lml_values)][0]\n            self.kernel_._check_bounds_params()\n\n            self.log_marginal_likelihood_value_ = -np.min(lml_values)\n        else:\n            self.log_marginal_likelihood_value_ = self.log_marginal_likelihood(\n                self.kernel_.theta\n            )\n\n        # Precompute quantities required for predictions which are independent\n        # of actual query points\n        K = self.kernel_(self.X_train_)\n\n        _, (self.pi_, self.W_sr_, self.L_, _, _) = self._posterior_mode(\n            K, return_temporaries=True\n        )\n\n        return self\n\n    def predict(self, X):\n     "}, {"start_line": 3000, "end_line": 5000, "belongs_to": {"file_name": "_gpc.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/gaussian_process", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "perparameters theta and\n                # the corresponding value of the target function.\n                return theta_opt, func_min\n\n        Per default, the 'L-BFGS-B' algorithm from scipy.optimize.minimize\n        is used. If None is passed, the kernel's parameters are kept fixed.\n        Available internal optimizers are::\n\n            'fmin_l_bfgs_b'\n\n    n_restarts_optimizer : int, default=0\n        The number of restarts of the optimizer for finding the kernel's\n        parameters which maximize the log-marginal likelihood. The first run\n        of the optimizer is performed from the kernel's initial parameters,\n        the remaining ones (if any) from thetas sampled log-uniform randomly\n        from the space of allowed theta-values. If greater than 0, all bounds\n        must be finite. Note that n_restarts_optimizer=0 implies that one\n        run is performed.\n\n    max_iter_predict : int, default=100\n        The maximum number of iterations in Newton's method for approximating\n        the posterior during predict. Smaller values will reduce computation\n        time at the cost of worse results.\n\n    warm_start : bool, default=False\n        If warm-starts are enabled, the solution of the last Newton iteration\n        on the Laplace approximation of the posterior mode is used as\n        initialization for the next call of _posterior_mode(). This can speed\n        up convergence when _posterior_mode is called several times on similar\n        problems as in hyperparameter optimization. See :term:`the Glossary\n        <warm_start>`.\n\n    copy_X_train : bool, default=True\n        If True, a persistent copy of the training data is stored in the\n        object. Otherwise, just a reference to the training data is stored,\n        which might cause predictions to change if the data is modified\n        externally.\n\n    random_state : int, RandomState instance or None, default=None\n        Determines random number generation used to initialize the centers.\n        Pass "}, {"start_line": 24000, "end_line": 26000, "belongs_to": {"file_name": "_gpc.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/gaussian_process", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "d as\n        initialization for the next call of _posterior_mode(). This can speed\n        up convergence when _posterior_mode is called several times on similar\n        problems as in hyperparameter optimization. See :term:`the Glossary\n        <warm_start>`.\n\n    copy_X_train : bool, default=True\n        If True, a persistent copy of the training data is stored in the\n        object. Otherwise, just a reference to the training data is stored,\n        which might cause predictions to change if the data is modified\n        externally.\n\n    random_state : int, RandomState instance or None, default=None\n        Determines random number generation used to initialize the centers.\n        Pass an int for reproducible results across multiple function calls.\n        See :term:`Glossary <random_state>`.\n\n    multi_class : {'one_vs_rest', 'one_vs_one'}, default='one_vs_rest'\n        Specifies how multi-class classification problems are handled.\n        Supported are 'one_vs_rest' and 'one_vs_one'. In 'one_vs_rest',\n        one binary Gaussian process classifier is fitted for each class, which\n        is trained to separate this class from the rest. In 'one_vs_one', one\n        binary Gaussian process classifier is fitted for each pair of classes,\n        which is trained to separate these two classes. The predictions of\n        these binary predictors are combined into multi-class predictions.\n        Note that 'one_vs_one' does not support predicting probability\n        estimates.\n\n    n_jobs : int, default=None\n        The number of jobs to use for the computation: the specified\n        multiclass problems are computed in parallel.\n        ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n        ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n        for more details.\n\n    Attributes\n    ----------\n    base_estimator_ : ``Estimator`` instance\n        The estimator instance that defines the likelihood function\n        using the observed "}, {"start_line": 15000, "end_line": 17000, "belongs_to": {"file_name": "_gpc.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/gaussian_process", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "hood_value_\n\n        if clone_kernel:\n            kernel = self.kernel_.clone_with_theta(theta)\n        else:\n            kernel = self.kernel_\n            kernel.theta = theta\n\n        if eval_gradient:\n            K, K_gradient = kernel(self.X_train_, eval_gradient=True)\n        else:\n            K = kernel(self.X_train_)\n\n        # Compute log-marginal-likelihood Z and also store some temporaries\n        # which can be reused for computing Z's gradient\n        Z, (pi, W_sr, L, b, a) = self._posterior_mode(K, return_temporaries=True)\n\n        if not eval_gradient:\n            return Z\n\n        # Compute gradient based on Algorithm 5.1 of GPML\n        d_Z = np.empty(theta.shape[0])\n        # XXX: Get rid of the np.diag() in the next line\n        R = W_sr[:, np.newaxis] * cho_solve((L, True), np.diag(W_sr))  # Line 7\n        C = solve(L, W_sr[:, np.newaxis] * K)  # Line 8\n        # Line 9: (use einsum to compute np.diag(C.T.dot(C))))\n        s_2 = (\n            -0.5\n            * (np.diag(K) - np.einsum(\"ij, ij -> j\", C, C))\n            * (pi * (1 - pi) * (1 - 2 * pi))\n        )  # third derivative\n\n        for j in range(d_Z.shape[0]):\n            C = K_gradient[:, :, j]  # Line 11\n            # Line 12: (R.T.ravel().dot(C.ravel()) = np.trace(R.dot(C)))\n            s_1 = 0.5 * a.T.dot(C).dot(a) - 0.5 * R.T.ravel().dot(C.ravel())\n\n            b = C.dot(self.y_train_ - pi)  # Line 13\n            s_3 = b - K.dot(R.dot(b))  # Line 14\n\n            d_Z[j] = s_1 + s_2.T.dot(s_3)  # Line 15\n\n        return Z, d_Z\n\n    def latent_mean_and_variance(self, X):\n        \"\"\"Compute the mean and variance of the latent function values.\n\n        Based on algorithm 3.2 of [RW2006]_, this function returns the latent\n        mean (Line 4) and variance (Line 6) of the Gaussian process\n        classification model.\n\n        Note that this function is only supported for binary classification.\n\n        Parameters\n        ----------\n        X : array-like of shape (n_samples, n_features) or"}, {"start_line": 22000, "end_line": 24000, "belongs_to": {"file_name": "_gpc.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/gaussian_process", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": " as a callable. If a callable is passed, it\n        must have the  signature::\n\n            def optimizer(obj_func, initial_theta, bounds):\n                # * 'obj_func' is the objective function to be maximized, which\n                #   takes the hyperparameters theta as parameter and an\n                #   optional flag eval_gradient, which determines if the\n                #   gradient is returned additionally to the function value\n                # * 'initial_theta': the initial value for theta, which can be\n                #   used by local optimizers\n                # * 'bounds': the bounds on the values of theta\n                ....\n                # Returned are the best found hyperparameters theta and\n                # the corresponding value of the target function.\n                return theta_opt, func_min\n\n        Per default, the 'L-BFGS-B' algorithm from scipy.optimize.minimize\n        is used. If None is passed, the kernel's parameters are kept fixed.\n        Available internal optimizers are::\n\n            'fmin_l_bfgs_b'\n\n    n_restarts_optimizer : int, default=0\n        The number of restarts of the optimizer for finding the kernel's\n        parameters which maximize the log-marginal likelihood. The first run\n        of the optimizer is performed from the kernel's initial parameters,\n        the remaining ones (if any) from thetas sampled log-uniform randomly\n        from the space of allowed theta-values. If greater than 0, all bounds\n        must be finite. Note that n_restarts_optimizer=0 implies that one\n        run is performed.\n\n    max_iter_predict : int, default=100\n        The maximum number of iterations in Newton's method for approximating\n        the posterior during predict. Smaller values will reduce computation\n        time at the cost of worse results.\n\n    warm_start : bool, default=False\n        If warm-starts are enabled, the solution of the last Newton iteration\n        on the Laplace approximation of the posterior mode is use"}, {"start_line": 23000, "end_line": 25000, "belongs_to": {"file_name": "_gpc.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/gaussian_process", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": " internal optimizers are::\n\n            'fmin_l_bfgs_b'\n\n    n_restarts_optimizer : int, default=0\n        The number of restarts of the optimizer for finding the kernel's\n        parameters which maximize the log-marginal likelihood. The first run\n        of the optimizer is performed from the kernel's initial parameters,\n        the remaining ones (if any) from thetas sampled log-uniform randomly\n        from the space of allowed theta-values. If greater than 0, all bounds\n        must be finite. Note that n_restarts_optimizer=0 implies that one\n        run is performed.\n\n    max_iter_predict : int, default=100\n        The maximum number of iterations in Newton's method for approximating\n        the posterior during predict. Smaller values will reduce computation\n        time at the cost of worse results.\n\n    warm_start : bool, default=False\n        If warm-starts are enabled, the solution of the last Newton iteration\n        on the Laplace approximation of the posterior mode is used as\n        initialization for the next call of _posterior_mode(). This can speed\n        up convergence when _posterior_mode is called several times on similar\n        problems as in hyperparameter optimization. See :term:`the Glossary\n        <warm_start>`.\n\n    copy_X_train : bool, default=True\n        If True, a persistent copy of the training data is stored in the\n        object. Otherwise, just a reference to the training data is stored,\n        which might cause predictions to change if the data is modified\n        externally.\n\n    random_state : int, RandomState instance or None, default=None\n        Determines random number generation used to initialize the centers.\n        Pass an int for reproducible results across multiple function calls.\n        See :term:`Glossary <random_state>`.\n\n    multi_class : {'one_vs_rest', 'one_vs_one'}, default='one_vs_rest'\n        Specifies how multi-class classification problems are handled.\n        Supported are 'one_vs_rest' and 'one_vs_on"}, {"start_line": 16000, "end_line": 18000, "belongs_to": {"file_name": "_gpc.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/gaussian_process", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "iag(K) - np.einsum(\"ij, ij -> j\", C, C))\n            * (pi * (1 - pi) * (1 - 2 * pi))\n        )  # third derivative\n\n        for j in range(d_Z.shape[0]):\n            C = K_gradient[:, :, j]  # Line 11\n            # Line 12: (R.T.ravel().dot(C.ravel()) = np.trace(R.dot(C)))\n            s_1 = 0.5 * a.T.dot(C).dot(a) - 0.5 * R.T.ravel().dot(C.ravel())\n\n            b = C.dot(self.y_train_ - pi)  # Line 13\n            s_3 = b - K.dot(R.dot(b))  # Line 14\n\n            d_Z[j] = s_1 + s_2.T.dot(s_3)  # Line 15\n\n        return Z, d_Z\n\n    def latent_mean_and_variance(self, X):\n        \"\"\"Compute the mean and variance of the latent function values.\n\n        Based on algorithm 3.2 of [RW2006]_, this function returns the latent\n        mean (Line 4) and variance (Line 6) of the Gaussian process\n        classification model.\n\n        Note that this function is only supported for binary classification.\n\n        Parameters\n        ----------\n        X : array-like of shape (n_samples, n_features) or list of object\n            Query points where the GP is evaluated for classification.\n\n        Returns\n        -------\n        latent_mean : array-like of shape (n_samples,)\n            Mean of the latent function values at the query points.\n\n        latent_var : array-like of shape (n_samples,)\n            Variance of the latent function values at the query points.\n        \"\"\"\n        check_is_fitted(self)\n\n        # Based on Algorithm 3.2 of GPML\n        K_star = self.kernel_(self.X_train_, X)  # K_star =k(x_star)\n        latent_mean = K_star.T.dot(self.y_train_ - self.pi_)  # Line 4\n        v = solve(self.L_, self.W_sr_[:, np.newaxis] * K_star)  # Line 5\n        # Line 6 (compute np.diag(v.T.dot(v)) via einsum)\n        latent_var = self.kernel_.diag(X) - np.einsum(\"ij,ij->j\", v, v)\n\n        return latent_mean, latent_var\n\n    def _posterior_mode(self, K, return_temporaries=False):\n        \"\"\"Mode-finding for binary Laplace GPC and fixed kernel.\n\n        This approximates the poster"}], "retrieved_count": 10, "cost_time": 1.3744871616363525}
{"question": "Why does the repeated instantiation of SelectKBest and GenericUnivariateSelect objects in test_mutual_info_regression impact memory allocation and computational overhead compared to reusing a single fitted estimator instance across multiple transform operations?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"start_line": 28000, "end_line": 30000, "belongs_to": {"file_name": "test_feature_select.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/feature_selection/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "ssert_array_equal(selector.get_support(), np.zeros(10))\n        with pytest.warns(UserWarning, match=\"No features were selected\"):\n            X_selected = selector.transform(X)\n        assert X_selected.shape == (40, 0)\n\n\ndef test_mutual_info_classif():\n    X, y = make_classification(\n        n_samples=100,\n        n_features=5,\n        n_informative=1,\n        n_redundant=1,\n        n_repeated=0,\n        n_classes=2,\n        n_clusters_per_class=1,\n        flip_y=0.0,\n        class_sep=10,\n        shuffle=False,\n        random_state=0,\n    )\n\n    # Test in KBest mode.\n    univariate_filter = SelectKBest(mutual_info_classif, k=2)\n    X_r = univariate_filter.fit(X, y).transform(X)\n    X_r2 = (\n        GenericUnivariateSelect(mutual_info_classif, mode=\"k_best\", param=2)\n        .fit(X, y)\n        .transform(X)\n    )\n    assert_array_equal(X_r, X_r2)\n    support = univariate_filter.get_support()\n    gtruth = np.zeros(5)\n    gtruth[:2] = 1\n    assert_array_equal(support, gtruth)\n\n    # Test in Percentile mode.\n    univariate_filter = SelectPercentile(mutual_info_classif, percentile=40)\n    X_r = univariate_filter.fit(X, y).transform(X)\n    X_r2 = (\n        GenericUnivariateSelect(mutual_info_classif, mode=\"percentile\", param=40)\n        .fit(X, y)\n        .transform(X)\n    )\n    assert_array_equal(X_r, X_r2)\n    support = univariate_filter.get_support()\n    gtruth = np.zeros(5)\n    gtruth[:2] = 1\n    assert_array_equal(support, gtruth)\n\n\ndef test_mutual_info_regression():\n    X, y = make_regression(\n        n_samples=100,\n        n_features=10,\n        n_informative=2,\n        shuffle=False,\n        random_state=0,\n        noise=10,\n    )\n\n    # Test in KBest mode.\n    univariate_filter = SelectKBest(mutual_info_regression, k=2)\n    X_r = univariate_filter.fit(X, y).transform(X)\n    assert_best_scores_kept(univariate_filter)\n    X_r2 = (\n        GenericUnivariateSelect(mutual_info_regression, mode=\"k_best\", param=2)\n        .fit(X, y)\n        .transform(X)\n    )\n    as"}, {"start_line": 29000, "end_line": 31000, "belongs_to": {"file_name": "test_feature_select.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/feature_selection/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "st in Percentile mode.\n    univariate_filter = SelectPercentile(mutual_info_classif, percentile=40)\n    X_r = univariate_filter.fit(X, y).transform(X)\n    X_r2 = (\n        GenericUnivariateSelect(mutual_info_classif, mode=\"percentile\", param=40)\n        .fit(X, y)\n        .transform(X)\n    )\n    assert_array_equal(X_r, X_r2)\n    support = univariate_filter.get_support()\n    gtruth = np.zeros(5)\n    gtruth[:2] = 1\n    assert_array_equal(support, gtruth)\n\n\ndef test_mutual_info_regression():\n    X, y = make_regression(\n        n_samples=100,\n        n_features=10,\n        n_informative=2,\n        shuffle=False,\n        random_state=0,\n        noise=10,\n    )\n\n    # Test in KBest mode.\n    univariate_filter = SelectKBest(mutual_info_regression, k=2)\n    X_r = univariate_filter.fit(X, y).transform(X)\n    assert_best_scores_kept(univariate_filter)\n    X_r2 = (\n        GenericUnivariateSelect(mutual_info_regression, mode=\"k_best\", param=2)\n        .fit(X, y)\n        .transform(X)\n    )\n    assert_array_equal(X_r, X_r2)\n    support = univariate_filter.get_support()\n    gtruth = np.zeros(10)\n    gtruth[:2] = 1\n    assert_array_equal(support, gtruth)\n\n    # Test in Percentile mode.\n    univariate_filter = SelectPercentile(mutual_info_regression, percentile=20)\n    X_r = univariate_filter.fit(X, y).transform(X)\n    X_r2 = (\n        GenericUnivariateSelect(mutual_info_regression, mode=\"percentile\", param=20)\n        .fit(X, y)\n        .transform(X)\n    )\n    assert_array_equal(X_r, X_r2)\n    support = univariate_filter.get_support()\n    gtruth = np.zeros(10)\n    gtruth[:2] = 1\n    assert_array_equal(support, gtruth)\n\n\ndef test_dataframe_output_dtypes():\n    \"\"\"Check that the output datafarme dtypes are the same as the input.\n\n    Non-regression test for gh-24860.\n    \"\"\"\n    pd = pytest.importorskip(\"pandas\")\n\n    X, y = load_iris(return_X_y=True, as_frame=True)\n    X = X.astype(\n        {\n            \"petal length (cm)\": np.float32,\n            \"petal width (cm)\": np.float64,\n"}, {"start_line": 27000, "end_line": 29000, "belongs_to": {"file_name": "test_feature_select.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/feature_selection/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "All the features will be returned.\"\n    with pytest.warns(UserWarning, match=msg):\n        SelectKBest(k=4).fit(X, y)\n    with pytest.warns(UserWarning, match=msg):\n        GenericUnivariateSelect(mode=\"k_best\", param=4).fit(X, y)\n\n\ndef test_f_classif_constant_feature():\n    # Test that f_classif warns if a feature is constant throughout.\n\n    X, y = make_classification(n_samples=10, n_features=5)\n    X[:, 0] = 2.0\n    with pytest.warns(UserWarning):\n        f_classif(X, y)\n\n\ndef test_no_feature_selected():\n    rng = np.random.RandomState(0)\n\n    # Generate random uncorrelated data: a strict univariate test should\n    # rejects all the features\n    X = rng.rand(40, 10)\n    y = rng.randint(0, 4, size=40)\n    strict_selectors = [\n        SelectFwe(alpha=0.01).fit(X, y),\n        SelectFdr(alpha=0.01).fit(X, y),\n        SelectFpr(alpha=0.01).fit(X, y),\n        SelectPercentile(percentile=0).fit(X, y),\n        SelectKBest(k=0).fit(X, y),\n    ]\n    for selector in strict_selectors:\n        assert_array_equal(selector.get_support(), np.zeros(10))\n        with pytest.warns(UserWarning, match=\"No features were selected\"):\n            X_selected = selector.transform(X)\n        assert X_selected.shape == (40, 0)\n\n\ndef test_mutual_info_classif():\n    X, y = make_classification(\n        n_samples=100,\n        n_features=5,\n        n_informative=1,\n        n_redundant=1,\n        n_repeated=0,\n        n_classes=2,\n        n_clusters_per_class=1,\n        flip_y=0.0,\n        class_sep=10,\n        shuffle=False,\n        random_state=0,\n    )\n\n    # Test in KBest mode.\n    univariate_filter = SelectKBest(mutual_info_classif, k=2)\n    X_r = univariate_filter.fit(X, y).transform(X)\n    X_r2 = (\n        GenericUnivariateSelect(mutual_info_classif, mode=\"k_best\", param=2)\n        .fit(X, y)\n        .transform(X)\n    )\n    assert_array_equal(X_r, X_r2)\n    support = univariate_filter.get_support()\n    gtruth = np.zeros(5)\n    gtruth[:2] = 1\n    assert_array_equal(support, gtruth)\n\n    # Te"}, {"start_line": 23000, "end_line": 25000, "belongs_to": {"file_name": "test_feature_select.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/feature_selection/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "ction\n    # gets the correct items in a simple regression problem\n    # with the fwe heuristic\n    X, y = make_regression(\n        n_samples=200, n_features=20, n_informative=5, shuffle=False, random_state=0\n    )\n\n    univariate_filter = SelectFwe(f_regression, alpha=0.01)\n    X_r = univariate_filter.fit(X, y).transform(X)\n    X_r2 = (\n        GenericUnivariateSelect(f_regression, mode=\"fwe\", param=0.01)\n        .fit(X, y)\n        .transform(X)\n    )\n    assert_array_equal(X_r, X_r2)\n    support = univariate_filter.get_support()\n    gtruth = np.zeros(20)\n    gtruth[:5] = 1\n    assert_array_equal(support[:5], np.ones((5,), dtype=bool))\n    assert np.sum(support[5:] == 1) < 2\n\n\ndef test_selectkbest_tiebreaking():\n    # Test whether SelectKBest actually selects k features in case of ties.\n    # Prior to 0.11, SelectKBest would return more features than requested.\n    Xs = [[0, 1, 1], [0, 0, 1], [1, 0, 0], [1, 1, 0]]\n    y = [1]\n    dummy_score = lambda X, y: (X[0], X[0])\n    for X in Xs:\n        sel = SelectKBest(dummy_score, k=1)\n        X1 = ignore_warnings(sel.fit_transform)([X], y)\n        assert X1.shape[1] == 1\n        assert_best_scores_kept(sel)\n\n        sel = SelectKBest(dummy_score, k=2)\n        X2 = ignore_warnings(sel.fit_transform)([X], y)\n        assert X2.shape[1] == 2\n        assert_best_scores_kept(sel)\n\n\ndef test_selectpercentile_tiebreaking():\n    # Test if SelectPercentile selects the right n_features in case of ties.\n    Xs = [[0, 1, 1], [0, 0, 1], [1, 0, 0], [1, 1, 0]]\n    y = [1]\n    dummy_score = lambda X, y: (X[0], X[0])\n    for X in Xs:\n        sel = SelectPercentile(dummy_score, percentile=34)\n        X1 = ignore_warnings(sel.fit_transform)([X], y)\n        assert X1.shape[1] == 1\n        assert_best_scores_kept(sel)\n\n        sel = SelectPercentile(dummy_score, percentile=67)\n        X2 = ignore_warnings(sel.fit_transform)([X], y)\n        assert X2.shape[1] == 2\n        assert_best_scores_kept(sel)\n\n\ndef test_tied_pvalues():\n    # Test whethe"}, {"start_line": 13000, "end_line": 15000, "belongs_to": {"file_name": "test_feature_select.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/feature_selection/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "n_features=20,\n        n_informative=3,\n        n_redundant=2,\n        n_repeated=0,\n        n_classes=8,\n        n_clusters_per_class=1,\n        flip_y=0.0,\n        class_sep=10,\n        shuffle=False,\n        random_state=0,\n    )\n\n    univariate_filter = SelectKBest(f_classif, k=5)\n    X_r = univariate_filter.fit(X, y).transform(X)\n    X_r2 = (\n        GenericUnivariateSelect(f_classif, mode=\"k_best\", param=5)\n        .fit(X, y)\n        .transform(X)\n    )\n    assert_array_equal(X_r, X_r2)\n    support = univariate_filter.get_support()\n    gtruth = np.zeros(20)\n    gtruth[:5] = 1\n    assert_array_equal(support, gtruth)\n\n\ndef test_select_kbest_all():\n    # Test whether k=\"all\" correctly returns all features.\n    X, y = make_classification(\n        n_samples=20, n_features=10, shuffle=False, random_state=0\n    )\n\n    univariate_filter = SelectKBest(f_classif, k=\"all\")\n    X_r = univariate_filter.fit(X, y).transform(X)\n    assert_array_equal(X, X_r)\n    # Non-regression test for:\n    # https://github.com/scikit-learn/scikit-learn/issues/24949\n    X_r2 = (\n        GenericUnivariateSelect(f_classif, mode=\"k_best\", param=\"all\")\n        .fit(X, y)\n        .transform(X)\n    )\n    assert_array_equal(X_r, X_r2)\n\n\n@pytest.mark.parametrize(\"dtype_in\", [np.float32, np.float64])\ndef test_select_kbest_zero(dtype_in):\n    # Test whether k=0 correctly returns no features.\n    X, y = make_classification(\n        n_samples=20, n_features=10, shuffle=False, random_state=0\n    )\n    X = X.astype(dtype_in)\n\n    univariate_filter = SelectKBest(f_classif, k=0)\n    univariate_filter.fit(X, y)\n    support = univariate_filter.get_support()\n    gtruth = np.zeros(10, dtype=bool)\n    assert_array_equal(support, gtruth)\n    with pytest.warns(UserWarning, match=\"No features were selected\"):\n        X_selected = univariate_filter.transform(X)\n    assert X_selected.shape == (20, 0)\n    assert X_selected.dtype == dtype_in\n\n\ndef test_select_heuristics_classif():\n    # Test whether the relative univa"}, {"start_line": 0, "end_line": 2000, "belongs_to": {"file_name": "test_mutual_info.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/feature_selection/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "import numpy as np\nimport pytest\n\nfrom sklearn.datasets import make_classification, make_regression\nfrom sklearn.feature_selection import mutual_info_classif, mutual_info_regression\nfrom sklearn.feature_selection._mutual_info import _compute_mi\nfrom sklearn.utils import check_random_state\nfrom sklearn.utils._testing import (\n    assert_allclose,\n    assert_array_equal,\n)\nfrom sklearn.utils.fixes import CSR_CONTAINERS\n\n\ndef test_compute_mi_dd():\n    # In discrete case computations are straightforward and can be done\n    # by hand on given vectors.\n    x = np.array([0, 1, 1, 0, 0])\n    y = np.array([1, 0, 0, 0, 1])\n\n    H_x = H_y = -(3 / 5) * np.log(3 / 5) - (2 / 5) * np.log(2 / 5)\n    H_xy = -1 / 5 * np.log(1 / 5) - 2 / 5 * np.log(2 / 5) - 2 / 5 * np.log(2 / 5)\n    I_xy = H_x + H_y - H_xy\n\n    assert_allclose(_compute_mi(x, y, x_discrete=True, y_discrete=True), I_xy)\n\n\ndef test_compute_mi_cc(global_dtype):\n    # For two continuous variables a good approach is to test on bivariate\n    # normal distribution, where mutual information is known.\n\n    # Mean of the distribution, irrelevant for mutual information.\n    mean = np.zeros(2)\n\n    # Setup covariance matrix with correlation coeff. equal 0.5.\n    sigma_1 = 1\n    sigma_2 = 10\n    corr = 0.5\n    cov = np.array(\n        [\n            [sigma_1**2, corr * sigma_1 * sigma_2],\n            [corr * sigma_1 * sigma_2, sigma_2**2],\n        ]\n    )\n\n    # True theoretical mutual information.\n    I_theory = np.log(sigma_1) + np.log(sigma_2) - 0.5 * np.log(np.linalg.det(cov))\n\n    rng = check_random_state(0)\n    Z = rng.multivariate_normal(mean, cov, size=1000).astype(global_dtype, copy=False)\n\n    x, y = Z[:, 0], Z[:, 1]\n\n    # Theory and computed values won't be very close\n    # We here check with a large relative tolerance\n    for n_neighbors in [3, 5, 7]:\n        I_computed = _compute_mi(\n            x, y, x_discrete=False, y_discrete=False, n_neighbors=n_neighbors\n        )\n        assert_allclose(I_computed, I_theory, rtol"}, {"start_line": 17000, "end_line": 19000, "belongs_to": {"file_name": "test_feature_select.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/feature_selection/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "upport, gtruth)\n    X_2 = X.copy()\n    X_2[:, np.logical_not(support)] = 0\n    assert_array_equal(X_2, univariate_filter.inverse_transform(X_r))\n    # Check inverse_transform respects dtype\n    assert_array_equal(\n        X_2.astype(bool), univariate_filter.inverse_transform(X_r.astype(bool))\n    )\n\n\ndef test_select_percentile_regression_full():\n    # Test whether the relative univariate feature selection\n    # selects all features when '100%' is asked.\n    X, y = make_regression(\n        n_samples=200, n_features=20, n_informative=5, shuffle=False, random_state=0\n    )\n\n    univariate_filter = SelectPercentile(f_regression, percentile=100)\n    X_r = univariate_filter.fit(X, y).transform(X)\n    assert_best_scores_kept(univariate_filter)\n    X_r2 = (\n        GenericUnivariateSelect(f_regression, mode=\"percentile\", param=100)\n        .fit(X, y)\n        .transform(X)\n    )\n    assert_array_equal(X_r, X_r2)\n    support = univariate_filter.get_support()\n    gtruth = np.ones(20)\n    assert_array_equal(support, gtruth)\n\n\ndef test_select_kbest_regression():\n    # Test whether the relative univariate feature selection\n    # gets the correct items in a simple regression problem\n    # with the k best heuristic\n    X, y = make_regression(\n        n_samples=200,\n        n_features=20,\n        n_informative=5,\n        shuffle=False,\n        random_state=0,\n        noise=10,\n    )\n\n    univariate_filter = SelectKBest(f_regression, k=5)\n    X_r = univariate_filter.fit(X, y).transform(X)\n    assert_best_scores_kept(univariate_filter)\n    X_r2 = (\n        GenericUnivariateSelect(f_regression, mode=\"k_best\", param=5)\n        .fit(X, y)\n        .transform(X)\n    )\n    assert_array_equal(X_r, X_r2)\n    support = univariate_filter.get_support()\n    gtruth = np.zeros(20)\n    gtruth[:5] = 1\n    assert_array_equal(support, gtruth)\n\n\ndef test_select_heuristics_regression():\n    # Test whether the relative univariate feature selection\n    # gets the correct items in a simple regression proble"}, {"start_line": 18000, "end_line": 20000, "belongs_to": {"file_name": "test_feature_select.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/feature_selection/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "rray_equal(support, gtruth)\n\n\ndef test_select_kbest_regression():\n    # Test whether the relative univariate feature selection\n    # gets the correct items in a simple regression problem\n    # with the k best heuristic\n    X, y = make_regression(\n        n_samples=200,\n        n_features=20,\n        n_informative=5,\n        shuffle=False,\n        random_state=0,\n        noise=10,\n    )\n\n    univariate_filter = SelectKBest(f_regression, k=5)\n    X_r = univariate_filter.fit(X, y).transform(X)\n    assert_best_scores_kept(univariate_filter)\n    X_r2 = (\n        GenericUnivariateSelect(f_regression, mode=\"k_best\", param=5)\n        .fit(X, y)\n        .transform(X)\n    )\n    assert_array_equal(X_r, X_r2)\n    support = univariate_filter.get_support()\n    gtruth = np.zeros(20)\n    gtruth[:5] = 1\n    assert_array_equal(support, gtruth)\n\n\ndef test_select_heuristics_regression():\n    # Test whether the relative univariate feature selection\n    # gets the correct items in a simple regression problem\n    # with the fpr, fdr or fwe heuristics\n    X, y = make_regression(\n        n_samples=200,\n        n_features=20,\n        n_informative=5,\n        shuffle=False,\n        random_state=0,\n        noise=10,\n    )\n\n    univariate_filter = SelectFpr(f_regression, alpha=0.01)\n    X_r = univariate_filter.fit(X, y).transform(X)\n    gtruth = np.zeros(20)\n    gtruth[:5] = 1\n    for mode in [\"fdr\", \"fpr\", \"fwe\"]:\n        X_r2 = (\n            GenericUnivariateSelect(f_regression, mode=mode, param=0.01)\n            .fit(X, y)\n            .transform(X)\n        )\n        assert_array_equal(X_r, X_r2)\n        support = univariate_filter.get_support()\n        assert_array_equal(support[:5], np.ones((5,), dtype=bool))\n        assert np.sum(support[5:] == 1) < 3\n\n\ndef test_boundary_case_ch2():\n    # Test boundary case, and always aim to select 1 feature.\n    X = np.array([[10, 20], [20, 20], [20, 30]])\n    y = np.array([[1], [0], [0]])\n    scores, pvalues = chi2(X, y)\n    assert_array_almost_equal(sc"}, {"start_line": 3000, "end_line": 5000, "belongs_to": {"file_name": "test_mutual_info.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/feature_selection/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "   ) - np.log(2)\n\n        # Assert the same tolerance.\n        for n_neighbors in [3, 5, 7]:\n            I_computed = _compute_mi(\n                x, y, x_discrete=True, y_discrete=False, n_neighbors=n_neighbors\n            )\n            assert_allclose(I_computed, I_theory, rtol=1e-1)\n\n\ndef test_compute_mi_cd_unique_label(global_dtype):\n    # Test that adding unique label doesn't change MI.\n    n_samples = 100\n    x = np.random.uniform(size=n_samples) > 0.5\n\n    y = np.empty(n_samples, global_dtype)\n    mask = x == 0\n    y[mask] = np.random.uniform(-1, 1, size=np.sum(mask))\n    y[~mask] = np.random.uniform(0, 2, size=np.sum(~mask))\n\n    mi_1 = _compute_mi(x, y, x_discrete=True, y_discrete=False)\n\n    x = np.hstack((x, 2))\n    y = np.hstack((y, 10))\n    mi_2 = _compute_mi(x, y, x_discrete=True, y_discrete=False)\n\n    assert_allclose(mi_1, mi_2)\n\n\n# We are going test that feature ordering by MI matches our expectations.\ndef test_mutual_info_classif_discrete(global_dtype):\n    X = np.array(\n        [[0, 0, 0], [1, 1, 0], [2, 0, 1], [2, 0, 1], [2, 0, 1]], dtype=global_dtype\n    )\n    y = np.array([0, 1, 2, 2, 1])\n\n    # Here X[:, 0] is the most informative feature, and X[:, 1] is weakly\n    # informative.\n    mi = mutual_info_classif(X, y, discrete_features=True)\n    assert_array_equal(np.argsort(-mi), np.array([0, 2, 1]))\n\n\ndef test_mutual_info_regression(global_dtype):\n    # We generate sample from multivariate normal distribution, using\n    # transformation from initially uncorrelated variables. The zero\n    # variables after transformation is selected as the target vector,\n    # it has the strongest correlation with the variable 2, and\n    # the weakest correlation with the variable 1.\n    T = np.array([[1, 0.5, 2, 1], [0, 1, 0.1, 0.0], [0, 0.1, 1, 0.1], [0, 0.1, 0.1, 1]])\n    cov = T.dot(T.T)\n    mean = np.zeros(4)\n\n    rng = check_random_state(0)\n    Z = rng.multivariate_normal(mean, cov, size=1000).astype(global_dtype, copy=False)\n    X = Z[:, 1:]\n    y = Z[:, 0"}, {"start_line": 22000, "end_line": 24000, "belongs_to": {"file_name": "test_feature_select.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/feature_selection/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": " assert_array_equal(X_r, X_r2)\n        support = univariate_filter.get_support()\n        num_false_positives = np.sum(support[n_informative:] == 1)\n        num_true_positives = np.sum(support[:n_informative] == 1)\n\n        if num_false_positives == 0:\n            return 0.0\n        false_discovery_rate = num_false_positives / (\n            num_true_positives + num_false_positives\n        )\n        return false_discovery_rate\n\n    # As per Benjamini-Hochberg, the expected false discovery rate\n    # should be lower than alpha:\n    # FDR = E(FP / (TP + FP)) <= alpha\n    false_discovery_rate = np.mean(\n        [single_fdr(alpha, n_informative, random_state) for random_state in range(100)]\n    )\n    assert alpha >= false_discovery_rate\n\n    # Make sure that the empirical false discovery rate increases\n    # with alpha:\n    if false_discovery_rate != 0:\n        assert false_discovery_rate > alpha / 10\n\n\ndef test_select_fwe_regression():\n    # Test whether the relative univariate feature selection\n    # gets the correct items in a simple regression problem\n    # with the fwe heuristic\n    X, y = make_regression(\n        n_samples=200, n_features=20, n_informative=5, shuffle=False, random_state=0\n    )\n\n    univariate_filter = SelectFwe(f_regression, alpha=0.01)\n    X_r = univariate_filter.fit(X, y).transform(X)\n    X_r2 = (\n        GenericUnivariateSelect(f_regression, mode=\"fwe\", param=0.01)\n        .fit(X, y)\n        .transform(X)\n    )\n    assert_array_equal(X_r, X_r2)\n    support = univariate_filter.get_support()\n    gtruth = np.zeros(20)\n    gtruth[:5] = 1\n    assert_array_equal(support[:5], np.ones((5,), dtype=bool))\n    assert np.sum(support[5:] == 1) < 2\n\n\ndef test_selectkbest_tiebreaking():\n    # Test whether SelectKBest actually selects k features in case of ties.\n    # Prior to 0.11, SelectKBest would return more features than requested.\n    Xs = [[0, 1, 1], [0, 0, 1], [1, 0, 0], [1, 1, 0]]\n    y = [1]\n    dummy_score = lambda X, y: (X[0], X[0])\n    for X in Xs:"}], "retrieved_count": 10, "cost_time": 0.40468859672546387}
{"question": "Why does the Pipeline class explicitly reject the sample_weight parameter during fit when the underlying estimator does not declare support for it through metadata routing?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"start_line": 74000, "end_line": 76000, "belongs_to": {"file_name": "test_pipeline.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "quest(est, method, sample_weight=True, prop=True)\n    est = set_request(est, \"fit\", sample_weight=True, prop=True)\n    trs = (\n        ConsumingTransformer()\n        .set_fit_request(sample_weight=True, metadata=True)\n        .set_transform_request(sample_weight=True, metadata=True)\n        .set_inverse_transform_request(sample_weight=True, metadata=True)\n    )\n    pipeline = Pipeline([(\"trs\", trs), (\"estimator\", est)])\n\n    if \"fit\" not in method:\n        pipeline = pipeline.fit(X, y, sample_weight=sample_weight, prop=prop)\n\n    try:\n        getattr(pipeline, method)(\n            X, y, sample_weight=sample_weight, prop=prop, metadata=metadata\n        )\n    except TypeError:\n        # Some methods don't accept y\n        getattr(pipeline, method)(\n            X, sample_weight=sample_weight, prop=prop, metadata=metadata\n        )\n\n    # Make sure the transformer has received the metadata\n    # For the transformer, always only `fit` and `transform` are called.\n    check_recorded_metadata(\n        obj=trs,\n        method=\"fit\",\n        parent=\"fit\",\n        sample_weight=sample_weight,\n        metadata=metadata,\n    )\n    check_recorded_metadata(\n        obj=trs,\n        method=\"transform\",\n        parent=\"transform\",\n        sample_weight=sample_weight,\n        metadata=metadata,\n    )\n\n\n# split and partial_fit not relevant for pipelines\n# sorted is here needed to make `pytest -nX` work. W/o it, tests are collected\n# in different orders between workers and that makes it fail.\n@pytest.mark.parametrize(\"method\", sorted(set(METHODS) - {\"split\", \"partial_fit\"}))\n@config_context(enable_metadata_routing=True)\ndef test_metadata_routing_error_for_pipeline(method):\n    \"\"\"Test that metadata is not routed for pipelines when not requested.\"\"\"\n    X, y = [[1]], [1]\n    sample_weight, prop = [1], \"a\"\n    est = SimpleEstimator()\n    # here not setting sample_weight request and leaving it as None\n    pipeline = Pipeline([(\"estimator\", est)])\n    error_message = (\n        \"[sample_wei"}, {"start_line": 75000, "end_line": 77000, "belongs_to": {"file_name": "test_pipeline.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "\n        obj=trs,\n        method=\"fit\",\n        parent=\"fit\",\n        sample_weight=sample_weight,\n        metadata=metadata,\n    )\n    check_recorded_metadata(\n        obj=trs,\n        method=\"transform\",\n        parent=\"transform\",\n        sample_weight=sample_weight,\n        metadata=metadata,\n    )\n\n\n# split and partial_fit not relevant for pipelines\n# sorted is here needed to make `pytest -nX` work. W/o it, tests are collected\n# in different orders between workers and that makes it fail.\n@pytest.mark.parametrize(\"method\", sorted(set(METHODS) - {\"split\", \"partial_fit\"}))\n@config_context(enable_metadata_routing=True)\ndef test_metadata_routing_error_for_pipeline(method):\n    \"\"\"Test that metadata is not routed for pipelines when not requested.\"\"\"\n    X, y = [[1]], [1]\n    sample_weight, prop = [1], \"a\"\n    est = SimpleEstimator()\n    # here not setting sample_weight request and leaving it as None\n    pipeline = Pipeline([(\"estimator\", est)])\n    error_message = (\n        \"[sample_weight, prop] are passed but are not explicitly set as requested\"\n        f\" or not requested for SimpleEstimator.{method}\"\n    )\n    with pytest.raises(ValueError, match=re.escape(error_message)):\n        try:\n            # passing X, y positional as the first two arguments\n            getattr(pipeline, method)(X, y, sample_weight=sample_weight, prop=prop)\n        except TypeError:\n            # not all methods accept y (like `predict`), so here we only\n            # pass X as a positional arg.\n            getattr(pipeline, method)(X, sample_weight=sample_weight, prop=prop)\n\n\n@pytest.mark.parametrize(\n    \"method\", [\"decision_function\", \"transform\", \"inverse_transform\"]\n)\ndef test_routing_passed_metadata_not_supported(method):\n    \"\"\"Test that the right error message is raised when metadata is passed while\n    not supported when `enable_metadata_routing=False`.\"\"\"\n\n    pipe = Pipeline([(\"estimator\", SimpleEstimator())])\n\n    with pytest.raises(\n        ValueError, match=\"is only supporte"}, {"start_line": 10000, "end_line": 12000, "belongs_to": {"file_name": "test_metadata_routing.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "stimator=ConsumingClassifier())\n    err_message = (\n        \"[sample_weight] are passed but are not explicitly set as requested or\"\n        \" not requested for ConsumingClassifier.fit\"\n    )\n    with pytest.raises(ValueError, match=re.escape(err_message)):\n        clf.fit(X, y, sample_weight=my_weights)\n\n    # Explicitly saying the estimator doesn't need it, makes the error go away,\n    # because in this case `WeightedMetaClassifier` consumes `sample_weight`. If\n    # there was no consumer of sample_weight, passing it would result in an\n    # error.\n    clf = WeightedMetaClassifier(\n        estimator=ConsumingClassifier().set_fit_request(sample_weight=False)\n    )\n    # this doesn't raise since WeightedMetaClassifier itself is a consumer,\n    # and passing metadata to the consumer directly is fine regardless of its\n    # metadata_request values.\n    clf.fit(X, y, sample_weight=my_weights)\n    check_recorded_metadata(clf.estimator_, method=\"fit\", parent=\"fit\")\n\n    # Requesting a metadata will make the meta-estimator forward it correctly\n    clf = WeightedMetaClassifier(\n        estimator=ConsumingClassifier().set_fit_request(sample_weight=True)\n    )\n    clf.fit(X, y, sample_weight=my_weights)\n    check_recorded_metadata(\n        clf.estimator_, method=\"fit\", parent=\"fit\", sample_weight=my_weights\n    )\n\n    # And requesting it with an alias\n    clf = WeightedMetaClassifier(\n        estimator=ConsumingClassifier().set_fit_request(\n            sample_weight=\"alternative_weight\"\n        )\n    )\n    clf.fit(X, y, alternative_weight=my_weights)\n    check_recorded_metadata(\n        clf.estimator_, method=\"fit\", parent=\"fit\", sample_weight=my_weights\n    )\n\n\n@config_context(enable_metadata_routing=True)\ndef test_nested_routing():\n    # check if metadata is routed in a nested routing situation.\n    pipeline = SimplePipeline(\n        [\n            MetaTransformer(\n                transformer=ConsumingTransformer()\n                .set_fit_request(metadata=True, sample_weigh"}, {"start_line": 76000, "end_line": 78000, "belongs_to": {"file_name": "test_pipeline.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "ght, prop] are passed but are not explicitly set as requested\"\n        f\" or not requested for SimpleEstimator.{method}\"\n    )\n    with pytest.raises(ValueError, match=re.escape(error_message)):\n        try:\n            # passing X, y positional as the first two arguments\n            getattr(pipeline, method)(X, y, sample_weight=sample_weight, prop=prop)\n        except TypeError:\n            # not all methods accept y (like `predict`), so here we only\n            # pass X as a positional arg.\n            getattr(pipeline, method)(X, sample_weight=sample_weight, prop=prop)\n\n\n@pytest.mark.parametrize(\n    \"method\", [\"decision_function\", \"transform\", \"inverse_transform\"]\n)\ndef test_routing_passed_metadata_not_supported(method):\n    \"\"\"Test that the right error message is raised when metadata is passed while\n    not supported when `enable_metadata_routing=False`.\"\"\"\n\n    pipe = Pipeline([(\"estimator\", SimpleEstimator())])\n\n    with pytest.raises(\n        ValueError, match=\"is only supported if enable_metadata_routing=True\"\n    ):\n        getattr(pipe, method)([[1]], sample_weight=[1], prop=\"a\")\n\n\n@config_context(enable_metadata_routing=True)\ndef test_pipeline_with_estimator_with_len():\n    \"\"\"Test that pipeline works with estimators that have a `__len__` method.\"\"\"\n    pipe = Pipeline(\n        [(\"trs\", RandomTreesEmbedding()), (\"estimator\", RandomForestClassifier())]\n    )\n    pipe.fit([[1]], [1])\n    pipe.predict([[1]])\n\n\n@pytest.mark.parametrize(\"last_step\", [None, \"passthrough\"])\n@config_context(enable_metadata_routing=True)\ndef test_pipeline_with_no_last_step(last_step):\n    \"\"\"Test that the pipeline works when there is not last step.\n\n    It should just ignore and pass through the data on transform.\n    \"\"\"\n    pipe = Pipeline([(\"trs\", FunctionTransformer()), (\"estimator\", last_step)])\n    assert pipe.fit([[1]], [1]).transform([[1], [2], [3]]) == [[1], [2], [3]]\n\n\n@config_context(enable_metadata_routing=True)\ndef test_feature_union_metadata_routing_error():\n    \"\"\""}, {"start_line": 12000, "end_line": 14000, "belongs_to": {"file_name": "test_metadata_routing.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "t=False)\n                .set_transform_request(sample_weight=True, metadata=False)\n            ),\n            WeightedMetaRegressor(\n                estimator=ConsumingRegressor()\n                .set_fit_request(sample_weight=\"inner_weights\", metadata=False)\n                .set_predict_request(sample_weight=False)\n            ).set_fit_request(sample_weight=\"outer_weights\"),\n        ]\n    )\n    w1, w2, w3 = [1], [2], [3]\n    pipeline.fit(\n        X, y, metadata=my_groups, sample_weight=w1, outer_weights=w2, inner_weights=w3\n    )\n    check_recorded_metadata(\n        pipeline.steps_[0].transformer_,\n        method=\"fit\",\n        parent=\"fit\",\n        metadata=my_groups,\n    )\n    check_recorded_metadata(\n        pipeline.steps_[0].transformer_,\n        method=\"transform\",\n        parent=\"fit\",\n        sample_weight=w1,\n    )\n    check_recorded_metadata(\n        pipeline.steps_[1], method=\"fit\", parent=\"fit\", sample_weight=w2\n    )\n    check_recorded_metadata(\n        pipeline.steps_[1].estimator_, method=\"fit\", parent=\"fit\", sample_weight=w3\n    )\n\n    pipeline.predict(X, sample_weight=w3)\n    check_recorded_metadata(\n        pipeline.steps_[0].transformer_,\n        method=\"transform\",\n        parent=\"fit\",\n        sample_weight=w3,\n    )\n\n\n@config_context(enable_metadata_routing=True)\ndef test_nested_routing_conflict():\n    # check if an error is raised if there's a conflict between keys\n    pipeline = SimplePipeline(\n        [\n            MetaTransformer(\n                transformer=ConsumingTransformer()\n                .set_fit_request(metadata=True, sample_weight=False)\n                .set_transform_request(sample_weight=True)\n            ),\n            WeightedMetaRegressor(\n                estimator=ConsumingRegressor().set_fit_request(sample_weight=True)\n            ).set_fit_request(sample_weight=\"outer_weights\"),\n        ]\n    )\n    w1, w2 = [1], [2]\n    with pytest.raises(\n        ValueError,\n        match=(\n            re.escape(\n                \"In W"}, {"start_line": 91000, "end_line": 93000, "belongs_to": {"file_name": "test_column_transformer.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/compose/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "           .set_transform_request(sample_weight=True, metadata=True),\n                [0],\n            )\n        ]\n    )\n\n    if method == \"transform\":\n        trs.fit(X, y, sample_weight=sample_weight, metadata=metadata)\n        trs.transform(X, sample_weight=sample_weight, metadata=metadata)\n    else:\n        getattr(trs, method)(X, y, sample_weight=sample_weight, metadata=metadata)\n\n    assert len(registry)\n    for _trs in registry:\n        check_recorded_metadata(\n            obj=_trs,\n            method=method,\n            parent=method,\n            sample_weight=sample_weight,\n            metadata=metadata,\n        )\n\n\n@config_context(enable_metadata_routing=True)\ndef test_metadata_routing_no_fit_transform():\n    \"\"\"Test metadata routing when the sub-estimator doesn't implement\n    ``fit_transform``.\"\"\"\n\n    class NoFitTransform(BaseEstimator):\n        def fit(self, X, y=None, sample_weight=None, metadata=None):\n            assert sample_weight\n            assert metadata\n            return self\n\n        def transform(self, X, sample_weight=None, metadata=None):\n            assert sample_weight\n            assert metadata\n            return X\n\n    X = np.array([[0, 1, 2], [2, 4, 6]]).T\n    y = [1, 2, 3]\n    sample_weight, metadata = [1], \"a\"\n    trs = ColumnTransformer(\n        [\n            (\n                \"trans\",\n                NoFitTransform()\n                .set_fit_request(sample_weight=True, metadata=True)\n                .set_transform_request(sample_weight=True, metadata=True),\n                [0],\n            )\n        ]\n    )\n\n    trs.fit(X, y, sample_weight=sample_weight, metadata=metadata)\n    trs.fit_transform(X, y, sample_weight=sample_weight, metadata=metadata)\n\n\n@pytest.mark.parametrize(\"method\", [\"transform\", \"fit_transform\", \"fit\"])\n@config_context(enable_metadata_routing=True)\ndef test_metadata_routing_error_for_column_transformer(method):\n    \"\"\"Test that the right error is raised when metadata is not requested.\"\"\"\n    X = np.array([[0"}, {"start_line": 11000, "end_line": 13000, "belongs_to": {"file_name": "test_metadata_routing.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "ta will make the meta-estimator forward it correctly\n    clf = WeightedMetaClassifier(\n        estimator=ConsumingClassifier().set_fit_request(sample_weight=True)\n    )\n    clf.fit(X, y, sample_weight=my_weights)\n    check_recorded_metadata(\n        clf.estimator_, method=\"fit\", parent=\"fit\", sample_weight=my_weights\n    )\n\n    # And requesting it with an alias\n    clf = WeightedMetaClassifier(\n        estimator=ConsumingClassifier().set_fit_request(\n            sample_weight=\"alternative_weight\"\n        )\n    )\n    clf.fit(X, y, alternative_weight=my_weights)\n    check_recorded_metadata(\n        clf.estimator_, method=\"fit\", parent=\"fit\", sample_weight=my_weights\n    )\n\n\n@config_context(enable_metadata_routing=True)\ndef test_nested_routing():\n    # check if metadata is routed in a nested routing situation.\n    pipeline = SimplePipeline(\n        [\n            MetaTransformer(\n                transformer=ConsumingTransformer()\n                .set_fit_request(metadata=True, sample_weight=False)\n                .set_transform_request(sample_weight=True, metadata=False)\n            ),\n            WeightedMetaRegressor(\n                estimator=ConsumingRegressor()\n                .set_fit_request(sample_weight=\"inner_weights\", metadata=False)\n                .set_predict_request(sample_weight=False)\n            ).set_fit_request(sample_weight=\"outer_weights\"),\n        ]\n    )\n    w1, w2, w3 = [1], [2], [3]\n    pipeline.fit(\n        X, y, metadata=my_groups, sample_weight=w1, outer_weights=w2, inner_weights=w3\n    )\n    check_recorded_metadata(\n        pipeline.steps_[0].transformer_,\n        method=\"fit\",\n        parent=\"fit\",\n        metadata=my_groups,\n    )\n    check_recorded_metadata(\n        pipeline.steps_[0].transformer_,\n        method=\"transform\",\n        parent=\"fit\",\n        sample_weight=w1,\n    )\n    check_recorded_metadata(\n        pipeline.steps_[1], method=\"fit\", parent=\"fit\", sample_weight=w2\n    )\n    check_recorded_metadata(\n        pipeline.steps_["}, {"start_line": 14000, "end_line": 16000, "belongs_to": {"file_name": "test_metadata_routing.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "eightedMetaRegressor, there is a conflict on sample_weight between\"\n                \" what is requested for this estimator and what is requested by its\"\n                \" children. You can resolve this conflict by using an alias for the\"\n                \" child estimators' requested metadata.\"\n            )\n        ),\n    ):\n        pipeline.fit(X, y, metadata=my_groups, sample_weight=w1, outer_weights=w2)\n\n\n@config_context(enable_metadata_routing=True)\ndef test_invalid_metadata():\n    # check that passing wrong metadata raises an error\n    trs = MetaTransformer(\n        transformer=ConsumingTransformer().set_transform_request(sample_weight=True)\n    )\n    with pytest.raises(\n        TypeError,\n        match=(re.escape(\"transform got unexpected argument(s) {'other_param'}\")),\n    ):\n        trs.fit(X, y).transform(X, other_param=my_weights)\n\n    # passing a metadata which is not requested by any estimator should also raise\n    trs = MetaTransformer(\n        transformer=ConsumingTransformer().set_transform_request(sample_weight=False)\n    )\n    with pytest.raises(\n        TypeError,\n        match=(re.escape(\"transform got unexpected argument(s) {'sample_weight'}\")),\n    ):\n        trs.fit(X, y).transform(X, sample_weight=my_weights)\n\n\n@config_context(enable_metadata_routing=True)\ndef test_get_metadata_routing():\n    class TestDefaultsBadMethodName(_MetadataRequester):\n        __metadata_request__fit = {\n            \"sample_weight\": None,\n            \"my_param\": None,\n        }\n        __metadata_request__score = {\n            \"sample_weight\": None,\n            \"my_param\": True,\n            \"my_other_param\": None,\n        }\n        # this will raise an error since we don't understand \"other_method\" as a method\n        __metadata_request__other_method = {\"my_param\": True}\n\n    class TestDefaults(_MetadataRequester):\n        __metadata_request__fit = {\n            \"sample_weight\": None,\n            \"my_other_param\": None,\n        }\n        __metadata_request__score = {\n"}, {"start_line": 90000, "end_line": 92000, "belongs_to": {"file_name": "test_column_transformer.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/compose/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "ror message is raised when metadata is passed while\n    not supported when `enable_metadata_routing=False`.\"\"\"\n\n    X = np.array([[0, 1, 2], [2, 4, 6]]).T\n    y = [1, 2, 3]\n    trs = ColumnTransformer([(\"trans\", Trans(), [0])]).fit(X, y)\n\n    with pytest.raises(\n        ValueError, match=\"is only supported if enable_metadata_routing=True\"\n    ):\n        getattr(trs, method)([[1]], sample_weight=[1], prop=\"a\")\n\n\n@pytest.mark.parametrize(\"method\", [\"transform\", \"fit_transform\", \"fit\"])\n@config_context(enable_metadata_routing=True)\ndef test_metadata_routing_for_column_transformer(method):\n    \"\"\"Test that metadata is routed correctly for column transformer.\"\"\"\n    X = np.array([[0, 1, 2], [2, 4, 6]]).T\n    y = [1, 2, 3]\n    registry = _Registry()\n    sample_weight, metadata = [1], \"a\"\n    trs = ColumnTransformer(\n        [\n            (\n                \"trans\",\n                ConsumingTransformer(registry=registry)\n                .set_fit_request(sample_weight=True, metadata=True)\n                .set_transform_request(sample_weight=True, metadata=True),\n                [0],\n            )\n        ]\n    )\n\n    if method == \"transform\":\n        trs.fit(X, y, sample_weight=sample_weight, metadata=metadata)\n        trs.transform(X, sample_weight=sample_weight, metadata=metadata)\n    else:\n        getattr(trs, method)(X, y, sample_weight=sample_weight, metadata=metadata)\n\n    assert len(registry)\n    for _trs in registry:\n        check_recorded_metadata(\n            obj=_trs,\n            method=method,\n            parent=method,\n            sample_weight=sample_weight,\n            metadata=metadata,\n        )\n\n\n@config_context(enable_metadata_routing=True)\ndef test_metadata_routing_no_fit_transform():\n    \"\"\"Test metadata routing when the sub-estimator doesn't implement\n    ``fit_transform``.\"\"\"\n\n    class NoFitTransform(BaseEstimator):\n        def fit(self, X, y=None, sample_weight=None, metadata=None):\n            assert sample_weight\n            assert metadata\n       "}, {"start_line": 14000, "end_line": 16000, "belongs_to": {"file_name": "plot_metadata_routing.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/examples/miscellaneous", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "mator\n            .add(\n                estimator=self.estimator,\n                method_mapping=MethodMapping()\n                .add(caller=\"fit\", callee=\"fit\")\n                .add(caller=\"predict\", callee=\"predict\")\n                .add(caller=\"score\", callee=\"score\"),\n            )\n        )\n        return router\n\n    # Since `sample_weight` is used and consumed here, it should be defined as\n    # an explicit argument in the method's signature. All other metadata which\n    # are only routed, will be passed as `**fit_params`:\n    def fit(self, X, y, sample_weight, **fit_params):\n        if self.estimator is None:\n            raise ValueError(\"estimator cannot be None!\")\n\n        check_metadata(self, sample_weight=sample_weight)\n\n        # We add `sample_weight` to the `fit_params` dictionary.\n        if sample_weight is not None:\n            fit_params[\"sample_weight\"] = sample_weight\n\n        request_router = get_routing_for_object(self)\n        request_router.validate_metadata(params=fit_params, method=\"fit\")\n        routed_params = request_router.route_params(params=fit_params, caller=\"fit\")\n        self.estimator_ = clone(self.estimator).fit(X, y, **routed_params.estimator.fit)\n        self.classes_ = self.estimator_.classes_\n        return self\n\n    def predict(self, X, **predict_params):\n        check_is_fitted(self)\n        # As in `fit`, we get a copy of the object's MetadataRouter,\n        request_router = get_routing_for_object(self)\n        # we validate the given metadata,\n        request_router.validate_metadata(params=predict_params, method=\"predict\")\n        # and then prepare the input to the underlying ``predict`` method.\n        routed_params = request_router.route_params(\n            params=predict_params, caller=\"predict\"\n        )\n        return self.estimator_.predict(X, **routed_params.estimator.predict)\n\n\n# %%\n# The key parts where the above meta-estimator differs from our previous\n# meta-estimator is accepting ``sample_weight`` explicitly"}], "retrieved_count": 10, "cost_time": 0.3975534439086914}
{"question": "Why does DummyTransformer's fit_counter mechanism enable detection of redundant fit invocations in scikit-learn's pipeline cloning and composition workflows?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"start_line": 11000, "end_line": 13000, "belongs_to": {"file_name": "test_target.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/compose/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": " how many time fit was called.\"\"\"\n\n    def __init__(self, fit_counter=0):\n        self.fit_counter = fit_counter\n\n    def fit(self, X, y=None):\n        self.fit_counter += 1\n        return self\n\n    def transform(self, X):\n        return X\n\n    def inverse_transform(self, X):\n        return X\n\n\n@pytest.mark.parametrize(\"check_inverse\", [False, True])\ndef test_transform_target_regressor_count_fit(check_inverse):\n    # regression test for gh-issue #11618\n    # check that we only call a single time fit for the transformer\n    X, y = friedman\n    ttr = TransformedTargetRegressor(\n        transformer=DummyTransformer(), check_inverse=check_inverse\n    )\n    ttr.fit(X, y)\n    assert ttr.transformer_.fit_counter == 1\n\n\nclass DummyRegressorWithExtraFitParams(DummyRegressor):\n    def fit(self, X, y, sample_weight=None, check_input=True):\n        # on the test below we force this to false, we make sure this is\n        # actually passed to the regressor\n        assert not check_input\n        return super().fit(X, y, sample_weight)\n\n\ndef test_transform_target_regressor_pass_fit_parameters():\n    X, y = friedman\n    regr = TransformedTargetRegressor(\n        regressor=DummyRegressorWithExtraFitParams(), transformer=DummyTransformer()\n    )\n\n    regr.fit(X, y, check_input=False)\n    assert regr.transformer_.fit_counter == 1\n\n\ndef test_transform_target_regressor_route_pipeline():\n    X, y = friedman\n\n    regr = TransformedTargetRegressor(\n        regressor=DummyRegressorWithExtraFitParams(), transformer=DummyTransformer()\n    )\n    estimators = [(\"normalize\", StandardScaler()), (\"est\", regr)]\n\n    pip = Pipeline(estimators)\n    pip.fit(X, y, **{\"est__check_input\": False})\n\n    assert regr.transformer_.fit_counter == 1\n\n\nclass DummyRegressorWithExtraPredictParams(DummyRegressor):\n    def predict(self, X, check_input=True):\n        # In the test below we make sure that the check input parameter is\n        # passed as false\n        self.predict_called = True\n        assert not check_"}, {"start_line": 4000, "end_line": 6000, "belongs_to": {"file_name": "test_pipeline.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "_predict(self, X, y, should_succeed=False):\n        self.fit(X, y, should_succeed=should_succeed)\n        return self.predict(X)\n\n    def score(self, X, y=None, sample_weight=None):\n        if sample_weight is not None:\n            X = X * sample_weight\n        return np.sum(X)\n\n\nclass DummyTransf(Transf):\n    \"\"\"Transformer which store the column means\"\"\"\n\n    def fit(self, X, y):\n        self.means_ = np.mean(X, axis=0)\n        # store timestamp to figure out whether the result of 'fit' has been\n        # cached or not\n        self.timestamp_ = time.time()\n        return self\n\n\nclass DummyEstimatorParams(BaseEstimator):\n    \"\"\"Mock classifier that takes params on predict\"\"\"\n\n    def __sklearn_is_fitted__(self):\n        return True\n\n    def fit(self, X, y):\n        return self\n\n    def predict(self, X, got_attribute=False):\n        self.got_attribute = got_attribute\n        return self\n\n    def predict_proba(self, X, got_attribute=False):\n        self.got_attribute = got_attribute\n        return self\n\n    def predict_log_proba(self, X, got_attribute=False):\n        self.got_attribute = got_attribute\n        return self\n\n\ndef test_pipeline_invalid_parameters():\n    # Test the various init parameters of the pipeline in fit\n    # method\n    pipeline = Pipeline([(1, 1)])\n    with pytest.raises(TypeError):\n        pipeline.fit([[1]], [1])\n\n    # Check that we can't fit pipelines with objects without fit\n    # method\n    msg = (\n        \"Last step of Pipeline should implement fit \"\n        \"or be the string 'passthrough'\"\n        \".*NoFit.*\"\n    )\n    pipeline = Pipeline([(\"clf\", NoFit())])\n    with pytest.raises(TypeError, match=msg):\n        pipeline.fit([[1]], [1])\n\n    # Smoke test with only an estimator\n    clf = NoTrans()\n    pipe = Pipeline([(\"svc\", clf)])\n    assert pipe.get_params(deep=True) == dict(\n        svc__a=None, svc__b=None, svc=clf, **pipe.get_params(deep=False)\n    )\n\n    # Check that params are set\n    pipe.set_params(svc__a=0.1)\n    assert clf.a == "}, {"start_line": 3000, "end_line": 5000, "belongs_to": {"file_name": "test_pipeline.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "TransfFitParams(Transf):\n    def fit(self, X, y=None, **fit_params):\n        self.fit_params = fit_params\n        return self\n\n\nclass Mult(TransformerMixin, BaseEstimator):\n    def __init__(self, mult=1):\n        self.mult = mult\n\n    def __sklearn_is_fitted__(self):\n        return True\n\n    def fit(self, X, y=None):\n        return self\n\n    def transform(self, X):\n        return np.asarray(X) * self.mult\n\n    def inverse_transform(self, X):\n        return np.asarray(X) / self.mult\n\n    def predict(self, X):\n        return (np.asarray(X) * self.mult).sum(axis=1)\n\n    predict_proba = predict_log_proba = decision_function = predict\n\n    def score(self, X, y=None):\n        return np.sum(X)\n\n\nclass FitParamT(BaseEstimator):\n    \"\"\"Mock classifier\"\"\"\n\n    def __init__(self):\n        self.successful = False\n\n    def fit(self, X, y, should_succeed=False):\n        self.successful = should_succeed\n        self.fitted_ = True\n\n    def predict(self, X):\n        return self.successful\n\n    def fit_predict(self, X, y, should_succeed=False):\n        self.fit(X, y, should_succeed=should_succeed)\n        return self.predict(X)\n\n    def score(self, X, y=None, sample_weight=None):\n        if sample_weight is not None:\n            X = X * sample_weight\n        return np.sum(X)\n\n\nclass DummyTransf(Transf):\n    \"\"\"Transformer which store the column means\"\"\"\n\n    def fit(self, X, y):\n        self.means_ = np.mean(X, axis=0)\n        # store timestamp to figure out whether the result of 'fit' has been\n        # cached or not\n        self.timestamp_ = time.time()\n        return self\n\n\nclass DummyEstimatorParams(BaseEstimator):\n    \"\"\"Mock classifier that takes params on predict\"\"\"\n\n    def __sklearn_is_fitted__(self):\n        return True\n\n    def fit(self, X, y):\n        return self\n\n    def predict(self, X, got_attribute=False):\n        self.got_attribute = got_attribute\n        return self\n\n    def predict_proba(self, X, got_attribute=False):\n        self.got_attribute = got_attribute\n   "}, {"start_line": 13000, "end_line": 15000, "belongs_to": {"file_name": "metadata_routing_common.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "  record_metadata_not_default(\n            self, sample_weight=sample_weight, metadata=metadata\n        )\n        self.fitted_ = True\n        return self\n\n    def transform(self, X, sample_weight=\"default\", metadata=\"default\"):\n        record_metadata_not_default(\n            self, sample_weight=sample_weight, metadata=metadata\n        )\n        return X + 1\n\n    def fit_transform(self, X, y, sample_weight=\"default\", metadata=\"default\"):\n        # implementing ``fit_transform`` is necessary since\n        # ``TransformerMixin.fit_transform`` doesn't route any metadata to\n        # ``transform``, while here we want ``transform`` to receive\n        # ``sample_weight`` and ``metadata``.\n        record_metadata_not_default(\n            self, sample_weight=sample_weight, metadata=metadata\n        )\n        return self.fit(X, y, sample_weight=sample_weight, metadata=metadata).transform(\n            X, sample_weight=sample_weight, metadata=metadata\n        )\n\n    def inverse_transform(self, X, sample_weight=None, metadata=None):\n        record_metadata_not_default(\n            self, sample_weight=sample_weight, metadata=metadata\n        )\n        return X - 1\n\n\nclass ConsumingNoFitTransformTransformer(BaseEstimator):\n    \"\"\"A metadata consuming transformer that doesn't inherit from\n    TransformerMixin, and thus doesn't implement `fit_transform`. Note that\n    TransformerMixin's `fit_transform` doesn't route metadata to `transform`.\"\"\"\n\n    def __init__(self, registry=None):\n        self.registry = registry\n\n    def fit(self, X, y=None, sample_weight=None, metadata=None):\n        if self.registry is not None:\n            self.registry.append(self)\n\n        record_metadata(self, sample_weight=sample_weight, metadata=metadata)\n\n        return self\n\n    def transform(self, X, sample_weight=None, metadata=None):\n        record_metadata(self, sample_weight=sample_weight, metadata=metadata)\n        return X\n\n\nclass ConsumingScorer(_Scorer):\n    def __init__(self, registry=None):\n"}, {"start_line": 10000, "end_line": 12000, "belongs_to": {"file_name": "test_target.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/compose/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "\n\nclass DummyCheckerListRegressor(DummyRegressor):\n    def fit(self, X, y, sample_weight=None):\n        assert isinstance(X, list)\n        return super().fit(X, y, sample_weight)\n\n    def predict(self, X):\n        assert isinstance(X, list)\n        return super().predict(X)\n\n\ndef test_transform_target_regressor_ensure_y_array():\n    # check that the target ``y`` passed to the transformer will always be a\n    # numpy array. Similarly, if ``X`` is passed as a list, we check that the\n    # predictor receive as it is.\n    X, y = friedman\n    tt = TransformedTargetRegressor(\n        transformer=DummyCheckerArrayTransformer(),\n        regressor=DummyCheckerListRegressor(),\n        check_inverse=False,\n    )\n    tt.fit(X.tolist(), y.tolist())\n    tt.predict(X.tolist())\n    with pytest.raises(AssertionError):\n        tt.fit(X, y.tolist())\n    with pytest.raises(AssertionError):\n        tt.predict(X)\n\n\nclass DummyTransformer(TransformerMixin, BaseEstimator):\n    \"\"\"Dummy transformer which count how many time fit was called.\"\"\"\n\n    def __init__(self, fit_counter=0):\n        self.fit_counter = fit_counter\n\n    def fit(self, X, y=None):\n        self.fit_counter += 1\n        return self\n\n    def transform(self, X):\n        return X\n\n    def inverse_transform(self, X):\n        return X\n\n\n@pytest.mark.parametrize(\"check_inverse\", [False, True])\ndef test_transform_target_regressor_count_fit(check_inverse):\n    # regression test for gh-issue #11618\n    # check that we only call a single time fit for the transformer\n    X, y = friedman\n    ttr = TransformedTargetRegressor(\n        transformer=DummyTransformer(), check_inverse=check_inverse\n    )\n    ttr.fit(X, y)\n    assert ttr.transformer_.fit_counter == 1\n\n\nclass DummyRegressorWithExtraFitParams(DummyRegressor):\n    def fit(self, X, y, sample_weight=None, check_input=True):\n        # on the test below we force this to false, we make sure this is\n        # actually passed to the regressor\n        assert not check_input\n        retu"}, {"start_line": 1000, "end_line": 3000, "belongs_to": {"file_name": "_mocking.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/utils", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "ingWrapper(array)\n\n    def __len__(self):\n        return len(self.array)\n\n    def __array__(self, dtype=None):\n        # Pandas data frames also are array-like: we want to make sure that\n        # input validation in cross-validation does not try to call that\n        # method.\n        return self.array\n\n    def __eq__(self, other):\n        return MockDataFrame(self.array == other.array)\n\n    def __ne__(self, other):\n        return not self == other\n\n    def take(self, indices, axis=0):\n        return MockDataFrame(self.array.take(indices, axis=axis))\n\n\nclass CheckingClassifier(ClassifierMixin, BaseEstimator):\n    \"\"\"Dummy classifier to test pipelining and meta-estimators.\n\n    Checks some property of `X` and `y`in fit / predict.\n    This allows testing whether pipelines / cross-validation or metaestimators\n    changed the input.\n\n    Can also be used to check if `fit_params` are passed correctly, and\n    to force a certain score to be returned.\n\n    Parameters\n    ----------\n    check_y, check_X : callable, default=None\n        The callable used to validate `X` and `y`. These callable should return\n        a bool where `False` will trigger an `AssertionError`. If `None`, the\n        data is not validated. Default is `None`.\n\n    check_y_params, check_X_params : dict, default=None\n        The optional parameters to pass to `check_X` and `check_y`. If `None`,\n        then no parameters are passed in.\n\n    methods_to_check : \"all\" or list of str, default=\"all\"\n        The methods in which the checks should be applied. By default,\n        all checks will be done on all methods (`fit`, `predict`,\n        `predict_proba`, `decision_function` and `score`).\n\n    foo_param : int, default=0\n        A `foo` param. When `foo > 1`, the output of :meth:`score` will be 1\n        otherwise it is 0.\n\n    expected_sample_weight : bool, default=False\n        Whether to check if a valid `sample_weight` was passed to `fit`.\n\n    expected_fit_params : list of str, default=None\n        A "}, {"start_line": 2000, "end_line": 4000, "belongs_to": {"file_name": "test_pipeline.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "e\n# side-effects between tests.\niris = load_iris()\niris.data.flags.writeable = False\niris.target.flags.writeable = False\n\n\nJUNK_FOOD_DOCS = (\n    \"the pizza pizza beer copyright\",\n    \"the pizza burger beer copyright\",\n    \"the the pizza beer beer copyright\",\n    \"the burger beer beer copyright\",\n    \"the coke burger coke copyright\",\n    \"the coke burger burger\",\n)\n\n\nclass NoFit(BaseEstimator):\n    \"\"\"Small class to test parameter dispatching.\"\"\"\n\n    def __init__(self, a=None, b=None):\n        self.a = a\n        self.b = b\n\n\nclass NoTrans(NoFit):\n    def fit(self, X, y=None):\n        return self\n\n    def get_params(self, deep=False):\n        return {\"a\": self.a, \"b\": self.b}\n\n    def set_params(self, **params):\n        self.a = params[\"a\"]\n        return self\n\n\nclass NoInvTransf(TransformerMixin, NoTrans):\n    def transform(self, X):\n        return X\n\n\nclass Transf(NoInvTransf):\n    def transform(self, X):\n        return X\n\n    def inverse_transform(self, X):\n        return X\n\n\nclass TransfFitParams(Transf):\n    def fit(self, X, y=None, **fit_params):\n        self.fit_params = fit_params\n        return self\n\n\nclass Mult(TransformerMixin, BaseEstimator):\n    def __init__(self, mult=1):\n        self.mult = mult\n\n    def __sklearn_is_fitted__(self):\n        return True\n\n    def fit(self, X, y=None):\n        return self\n\n    def transform(self, X):\n        return np.asarray(X) * self.mult\n\n    def inverse_transform(self, X):\n        return np.asarray(X) / self.mult\n\n    def predict(self, X):\n        return (np.asarray(X) * self.mult).sum(axis=1)\n\n    predict_proba = predict_log_proba = decision_function = predict\n\n    def score(self, X, y=None):\n        return np.sum(X)\n\n\nclass FitParamT(BaseEstimator):\n    \"\"\"Mock classifier\"\"\"\n\n    def __init__(self):\n        self.successful = False\n\n    def fit(self, X, y, should_succeed=False):\n        self.successful = should_succeed\n        self.fitted_ = True\n\n    def predict(self, X):\n        return self.successful\n\n    def fit"}, {"start_line": 70000, "end_line": 72000, "belongs_to": {"file_name": "estimator_checks.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/utils", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "(category=FutureWarning)\ndef check_transformers_unfitted(name, transformer):\n    X, y = _regression_dataset()\n\n    transformer = clone(transformer)\n    with raises(\n        (AttributeError, ValueError),\n        err_msg=(\n            \"The unfitted \"\n            f\"transformer {name} does not raise an error when \"\n            \"transform is called. Perhaps use \"\n            \"check_is_fitted in transform.\"\n        ),\n    ):\n        transformer.transform(X)\n\n\n@ignore_warnings(category=FutureWarning)\ndef check_transformers_unfitted_stateless(name, transformer):\n    \"\"\"Check that using transform without prior fitting\n    doesn't raise a NotFittedError for stateless transformers.\n    \"\"\"\n    rng = np.random.RandomState(0)\n    X = rng.uniform(size=(20, 5))\n    X = _enforce_estimator_tags_X(transformer, X)\n\n    transformer = clone(transformer)\n    X_trans = transformer.transform(X)\n\n    assert X_trans.shape[0] == X.shape[0]\n\n\ndef _check_transformer(name, transformer_orig, X, y):\n    n_samples, n_features = np.asarray(X).shape\n    transformer = clone(transformer_orig)\n    set_random_state(transformer)\n\n    # fit\n\n    if name in CROSS_DECOMPOSITION:\n        y_ = np.c_[np.asarray(y), np.asarray(y)]\n        y_[::2, 1] *= 2\n        if isinstance(X, _NotAnArray):\n            y_ = _NotAnArray(y_)\n    else:\n        y_ = y\n\n    transformer.fit(X, y_)\n    # fit_transform method should work on non fitted estimator\n    transformer_clone = clone(transformer)\n    X_pred = transformer_clone.fit_transform(X, y=y_)\n\n    if isinstance(X_pred, tuple):\n        for x_pred in X_pred:\n            assert x_pred.shape[0] == n_samples\n    else:\n        # check for consistent n_samples\n        assert X_pred.shape[0] == n_samples\n\n    if hasattr(transformer, \"transform\"):\n        if name in CROSS_DECOMPOSITION:\n            X_pred2 = transformer.transform(X, y_)\n            X_pred3 = transformer.fit_transform(X, y=y_)\n        else:\n            X_pred2 = transformer.transform(X)\n            X_pred3 = trans"}, {"start_line": 5000, "end_line": 7000, "belongs_to": {"file_name": "test_validation.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/model_selection/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "lf.param\n\n    def _is_training_data(self, X):\n        return X is self.X_subset\n\n\nclass MockEstimatorWithSingleFitCallAllowed(MockEstimatorWithParameter):\n    \"\"\"Dummy classifier that disallows repeated calls of fit method\"\"\"\n\n    def fit(self, X_subset, y_subset):\n        assert not hasattr(self, \"fit_called_\"), \"fit is called the second time\"\n        self.fit_called_ = True\n        return super().fit(X_subset, y_subset)\n\n    def predict(self, X):\n        raise NotImplementedError\n\n\nclass MockClassifier(ClassifierMixin, BaseEstimator):\n    \"\"\"Dummy classifier to test the cross-validation\"\"\"\n\n    def __init__(self, a=0, allow_nd=False):\n        self.a = a\n        self.allow_nd = allow_nd\n\n    def fit(\n        self,\n        X,\n        Y=None,\n        sample_weight=None,\n        class_prior=None,\n        sparse_sample_weight=None,\n        sparse_param=None,\n        dummy_int=None,\n        dummy_str=None,\n        dummy_obj=None,\n        callback=None,\n    ):\n        \"\"\"The dummy arguments are to test that this fit function can\n        accept non-array arguments through cross-validation, such as:\n            - int\n            - str (this is actually array-like)\n            - object\n            - function\n        \"\"\"\n        self.dummy_int = dummy_int\n        self.dummy_str = dummy_str\n        self.dummy_obj = dummy_obj\n        if callback is not None:\n            callback(self)\n\n        if self.allow_nd:\n            X = X.reshape(len(X), -1)\n        if X.ndim >= 3 and not self.allow_nd:\n            raise ValueError(\"X cannot be d\")\n        if sample_weight is not None:\n            assert sample_weight.shape[0] == X.shape[0], (\n                \"MockClassifier extra fit_param \"\n                \"sample_weight.shape[0] is {0}, should be {1}\".format(\n                    sample_weight.shape[0], X.shape[0]\n                )\n            )\n        if class_prior is not None:\n            assert class_prior.shape[0] == len(np.unique(y)), (\n                \"MockClassifier extra fit"}, {"start_line": 4000, "end_line": 6000, "belongs_to": {"file_name": "test_frozen.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/frozen/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "ich are not \"\n            \"routed to any object.\"\n        ),\n    ):\n        frozen.predict(X, metadata=\"test\")\n\n    frozen[\"consumesmetadata\"].set_predict_request(metadata=None)\n    with pytest.raises(UnsetMetadataPassedError):\n        frozen.predict(X, metadata=\"test\")\n\n\ndef test_composite_fit(classification_dataset):\n    \"\"\"Test that calling fit_transform and fit_predict doesn't call fit.\"\"\"\n\n    class Estimator(BaseEstimator):\n        def fit(self, X, y):\n            try:\n                self._fit_counter += 1\n            except AttributeError:\n                self._fit_counter = 1\n            return self\n\n        def fit_transform(self, X, y=None):\n            # only here to test that it doesn't get called\n            ...  # pragma: no cover\n\n        def fit_predict(self, X, y=None):\n            # only here to test that it doesn't get called\n            ...  # pragma: no cover\n\n    X, y = classification_dataset\n    est = Estimator().fit(X, y)\n    frozen = FrozenEstimator(est)\n\n    with pytest.raises(AttributeError):\n        frozen.fit_predict(X, y)\n    with pytest.raises(AttributeError):\n        frozen.fit_transform(X, y)\n\n    assert frozen._fit_counter == 1\n\n\ndef test_clone_frozen(regression_dataset):\n    \"\"\"Test that cloning a frozen estimator keeps the frozen state.\"\"\"\n    X, y = regression_dataset\n    estimator = LinearRegression().fit(X, y)\n    frozen = FrozenEstimator(estimator)\n    cloned = clone(frozen)\n    assert cloned.estimator is estimator\n\n\ndef test_check_is_fitted(regression_dataset):\n    \"\"\"Test that check_is_fitted works on frozen estimators.\"\"\"\n    X, y = regression_dataset\n\n    estimator = LinearRegression()\n    frozen = FrozenEstimator(estimator)\n    with pytest.raises(NotFittedError):\n        check_is_fitted(frozen)\n\n    estimator = LinearRegression().fit(X, y)\n    frozen = FrozenEstimator(estimator)\n    check_is_fitted(frozen)\n\n\ndef test_frozen_tags():\n    \"\"\"Test that frozen estimators have the same tags as the original estimator\n    except"}], "retrieved_count": 10, "cost_time": 0.39600276947021484}
{"question": "Where does the InfinityType class control the flow of comparison operations to ensure that its ordering semantics are preserved across all comparison chains, and what data transformation occurs when the __neg__ method is invoked to produce a NegativeInfinityType instance?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"start_line": 5000, "end_line": 7000, "belongs_to": {"file_name": "isotonic.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "dtype=y.dtype)\n    else:\n        # TODO: remove this branch when Scipy 1.12 is the minimum supported version\n        # Also remove _inplace_contiguous_isotonic_regression.\n        order = np.s_[:] if increasing else np.s_[::-1]\n        y = np.array(y[order], dtype=y.dtype)\n        sample_weight = _check_sample_weight(sample_weight, y, dtype=y.dtype, copy=True)\n        sample_weight = np.ascontiguousarray(sample_weight[order])\n        _inplace_contiguous_isotonic_regression(y, sample_weight)\n        y = y[order]\n\n    if y_min is not None or y_max is not None:\n        # Older versions of np.clip don't accept None as a bound, so use np.inf\n        if y_min is None:\n            y_min = -np.inf\n        if y_max is None:\n            y_max = np.inf\n        np.clip(y, y_min, y_max, y)\n    return y\n\n\nclass IsotonicRegression(RegressorMixin, TransformerMixin, BaseEstimator):\n    \"\"\"Isotonic regression model.\n\n    Read more in the :ref:`User Guide <isotonic>`.\n\n    .. versionadded:: 0.13\n\n    Parameters\n    ----------\n    y_min : float, default=None\n        Lower bound on the lowest predicted value (the minimum value may\n        still be higher). If not set, defaults to -inf.\n\n    y_max : float, default=None\n        Upper bound on the highest predicted value (the maximum may still be\n        lower). If not set, defaults to +inf.\n\n    increasing : bool or 'auto', default=True\n        Determines whether the predictions should be constrained to increase\n        or decrease with `X`. 'auto' will decide based on the Spearman\n        correlation estimate's sign.\n\n    out_of_bounds : {'nan', 'clip', 'raise'}, default='nan'\n        Handles how `X` values outside of the training domain are handled\n        during prediction.\n\n        - 'nan', predictions will be NaN.\n        - 'clip', predictions will be set to the value corresponding to\n          the nearest train interval endpoint.\n        - 'raise', a `ValueError` is raised.\n\n    Attributes\n    ----------\n    X_min_ : float\n        M"}, {"start_line": 47000, "end_line": 49000, "belongs_to": {"file_name": "test_impute.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/impute/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "= SimpleImputer(strategy=strategy)\n    X_trans = imputer.fit_transform(X)\n\n    assert_array_equal(X_trans, X_true)\n\n\n@pytest.mark.parametrize(\n    \"order, idx_order\",\n    [(\"ascending\", [3, 4, 2, 0, 1]), (\"descending\", [1, 0, 2, 4, 3])],\n)\ndef test_imputation_order(order, idx_order):\n    # regression test for #15393\n    rng = np.random.RandomState(42)\n    X = rng.rand(100, 5)\n    X[:50, 1] = np.nan\n    X[:30, 0] = np.nan\n    X[:20, 2] = np.nan\n    X[:10, 4] = np.nan\n\n    with pytest.warns(ConvergenceWarning):\n        trs = IterativeImputer(max_iter=1, imputation_order=order, random_state=0).fit(\n            X\n        )\n        idx = [x.feat_idx for x in trs.imputation_sequence_]\n        assert idx == idx_order\n\n\n@pytest.mark.parametrize(\"missing_value\", [-1, np.nan])\ndef test_simple_imputation_inverse_transform(missing_value):\n    # Test inverse_transform feature for np.nan\n    X_1 = np.array(\n        [\n            [9, missing_value, 3, -1],\n            [4, -1, 5, 4],\n            [6, 7, missing_value, -1],\n            [8, 9, 0, missing_value],\n        ]\n    )\n\n    X_2 = np.array(\n        [\n            [5, 4, 2, 1],\n            [2, 1, missing_value, 3],\n            [9, missing_value, 7, 1],\n            [6, 4, 2, missing_value],\n        ]\n    )\n\n    X_3 = np.array(\n        [\n            [1, missing_value, 5, 9],\n            [missing_value, 4, missing_value, missing_value],\n            [2, missing_value, 7, missing_value],\n            [missing_value, 3, missing_value, 8],\n        ]\n    )\n\n    X_4 = np.array(\n        [\n            [1, 1, 1, 3],\n            [missing_value, 2, missing_value, 1],\n            [2, 3, 3, 4],\n            [missing_value, 4, missing_value, 2],\n        ]\n    )\n\n    imputer = SimpleImputer(\n        missing_values=missing_value, strategy=\"mean\", add_indicator=True\n    )\n\n    X_1_trans = imputer.fit_transform(X_1)\n    X_1_inv_trans = imputer.inverse_transform(X_1_trans)\n\n    X_2_trans = imputer.transform(X_2)  # test on new data\n    X_2_inv_trans = "}, {"start_line": 3000, "end_line": 5000, "belongs_to": {"file_name": "_aliases.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/externals/array_api_compat/torch", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "t least one array or dtype must be provided\")\n\n    elif num == 1:\n        x = arrays_and_dtypes[0]\n        if isinstance(x, torch.dtype):\n            return x\n        return x.dtype\n\n    if num == 2:\n        x, y = arrays_and_dtypes\n        return _result_type(x, y)\n\n    else:\n        # sort scalars so that they are treated last\n        scalars, others = [], []\n        for x in arrays_and_dtypes:\n            if isinstance(x, _py_scalars):\n                scalars.append(x)\n            else:\n                others.append(x)\n        if not others:\n            raise ValueError(\"At least one array or dtype must be provided\")\n\n        # combine left-to-right\n        return _reduce(_result_type, others + scalars)\n\n\ndef _result_type(\n    x: Array | DType | bool | int | float | complex,\n    y: Array | DType | bool | int | float | complex,\n) -> DType:\n    if not (isinstance(x, _py_scalars) or isinstance(y, _py_scalars)):\n        xdt = x if isinstance(x, torch.dtype) else x.dtype\n        ydt = y if isinstance(y, torch.dtype) else y.dtype\n\n        try:\n            return _promotion_table[xdt, ydt]\n        except KeyError:\n            pass\n\n    # This doesn't result_type(dtype, dtype) for non-array API dtypes\n    # because torch.result_type only accepts tensors. This does however, allow\n    # cross-kind promotion.\n    x = torch.tensor([], dtype=x) if isinstance(x, torch.dtype) else x\n    y = torch.tensor([], dtype=y) if isinstance(y, torch.dtype) else y\n    return torch.result_type(x, y)\n\n\ndef can_cast(from_: Union[DType, Array], to: DType, /) -> bool:\n    if not isinstance(from_, torch.dtype):\n        from_ = from_.dtype\n    return torch.can_cast(from_, to)\n\n# Basic renames\nbitwise_invert = torch.bitwise_not\nnewaxis = None\n# torch.conj sets the conjugation bit, which breaks conversion to other\n# libraries. See https://github.com/data-apis/array-api-compat/issues/173\nconj = torch.conj_physical\n\n# Two-arg elementwise functions\n# These require a wrapper to do the correct type prom"}, {"start_line": 41000, "end_line": 43000, "belongs_to": {"file_name": "_nmf.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/decomposition", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "sent for API consistency by convention.\n\n        **params : kwargs\n            Parameters (keyword arguments) and values passed to\n            the fit_transform instance.\n\n        Returns\n        -------\n        self : object\n            Returns the instance itself.\n        \"\"\"\n        # param validation is done in fit_transform\n\n        self.fit_transform(X, **params)\n        return self\n\n    def inverse_transform(self, X):\n        \"\"\"Transform data back to its original space.\n\n        .. versionadded:: 0.18\n\n        Parameters\n        ----------\n        X : {ndarray, sparse matrix} of shape (n_samples, n_components)\n            Transformed data matrix.\n\n        Returns\n        -------\n        X_original : ndarray of shape (n_samples, n_features)\n            Returns a data matrix of the original shape.\n        \"\"\"\n\n        check_is_fitted(self)\n        return X @ self.components_\n\n    @property\n    def _n_features_out(self):\n        \"\"\"Number of transformed output features.\"\"\"\n        return self.components_.shape[0]\n\n    def __sklearn_tags__(self):\n        tags = super().__sklearn_tags__()\n        tags.input_tags.positive_only = True\n        tags.input_tags.sparse = True\n        tags.transformer_tags.preserves_dtype = [\"float64\", \"float32\"]\n        return tags\n\n\nclass NMF(_BaseNMF):\n    \"\"\"Non-Negative Matrix Factorization (NMF).\n\n    Find two non-negative matrices, i.e. matrices with all non-negative elements, (W, H)\n    whose product approximates the non-negative matrix X. This factorization can be used\n    for example for dimensionality reduction, source separation or topic extraction.\n\n    The objective function is:\n\n    .. math::\n\n        L(W, H) &= 0.5 * ||X - WH||_{loss}^2\n\n                &+ alpha\\\\_W * l1\\\\_ratio * n\\\\_features * ||vec(W)||_1\n\n                &+ alpha\\\\_H * l1\\\\_ratio * n\\\\_samples * ||vec(H)||_1\n\n                &+ 0.5 * alpha\\\\_W * (1 - l1\\\\_ratio) * n\\\\_features * ||W||_{Fro}^2\n\n                &+ 0.5 * alpha\\\\_H * (1 - l1\\\\_ratio) * n"}, {"start_line": 18000, "end_line": 19644, "belongs_to": {"file_name": "_aliases.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/externals/array_api_compat/common", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "abs(x, **kwargs))[...]\n        # sign(0) = 0 but the above formula would give nan\n        out[x == 0j] = 0j\n    else:\n        out = xp.sign(x, **kwargs)\n    # CuPy sign() does not propagate nans. See\n    # https://github.com/data-apis/array-api-compat/issues/136\n    if _is_cupy_namespace(xp) and isdtype(x.dtype, \"real floating\", xp=xp):\n        out[xp.isnan(x)] = xp.nan\n    return out[()]\n\n\ndef finfo(type_: DType | Array, /, xp: Namespace) -> Any:\n    # It is surprisingly difficult to recognize a dtype apart from an array.\n    # np.int64 is not the same as np.asarray(1).dtype!\n    try:\n        return xp.finfo(type_)\n    except (ValueError, TypeError):\n        return xp.finfo(type_.dtype)\n\n\ndef iinfo(type_: DType | Array, /, xp: Namespace) -> Any:\n    try:\n        return xp.iinfo(type_)\n    except (ValueError, TypeError):\n        return xp.iinfo(type_.dtype)\n\n\n__all__ = [\n    \"arange\",\n    \"empty\",\n    \"empty_like\",\n    \"eye\",\n    \"full\",\n    \"full_like\",\n    \"linspace\",\n    \"ones\",\n    \"ones_like\",\n    \"zeros\",\n    \"zeros_like\",\n    \"UniqueAllResult\",\n    \"UniqueCountsResult\",\n    \"UniqueInverseResult\",\n    \"unique_all\",\n    \"unique_counts\",\n    \"unique_inverse\",\n    \"unique_values\",\n    \"std\",\n    \"var\",\n    \"cumulative_sum\",\n    \"cumulative_prod\",\n    \"clip\",\n    \"permute_dims\",\n    \"reshape\",\n    \"argsort\",\n    \"sort\",\n    \"nonzero\",\n    \"ceil\",\n    \"floor\",\n    \"trunc\",\n    \"matmul\",\n    \"matrix_transpose\",\n    \"tensordot\",\n    \"vecdot\",\n    \"isdtype\",\n    \"unstack\",\n    \"sign\",\n    \"finfo\",\n    \"iinfo\",\n]\n_all_ignore = [\"inspect\", \"array_namespace\", \"NamedTuple\"]\n\n\ndef __dir__() -> list[str]:\n    return __all__\n"}, {"start_line": 101000, "end_line": 103000, "belongs_to": {"file_name": "_data.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/preprocessing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": " mapping to\n                    # infinity. Clip such that the inverse transform will be\n                    # consistent\n                    clip_min = stats.norm.ppf(BOUNDS_THRESHOLD - np.spacing(1))\n                    clip_max = stats.norm.ppf(1 - (BOUNDS_THRESHOLD - np.spacing(1)))\n                    X_col = np.clip(X_col, clip_min, clip_max)\n                # else output distribution is uniform and the ppf is the\n                # identity function so we let X_col unchanged\n\n        return X_col\n\n    def _check_inputs(self, X, in_fit, accept_sparse_negative=False, copy=False):\n        \"\"\"Check inputs before fit and transform.\"\"\"\n        X = validate_data(\n            self,\n            X,\n            reset=in_fit,\n            accept_sparse=\"csc\",\n            copy=copy,\n            dtype=FLOAT_DTYPES,\n            # only set force_writeable for the validation at transform time because\n            # it's the only place where QuantileTransformer performs inplace operations.\n            force_writeable=True if not in_fit else None,\n            ensure_all_finite=\"allow-nan\",\n        )\n        # we only accept positive sparse matrix when ignore_implicit_zeros is\n        # false and that we call fit or transform.\n        with np.errstate(invalid=\"ignore\"):  # hide NaN comparison warnings\n            if (\n                not accept_sparse_negative\n                and not self.ignore_implicit_zeros\n                and (sparse.issparse(X) and np.any(X.data < 0))\n            ):\n                raise ValueError(\n                    \"QuantileTransformer only accepts non-negative sparse matrices.\"\n                )\n\n        return X\n\n    def _transform(self, X, inverse=False):\n        \"\"\"Forward and inverse transform.\n\n        Parameters\n        ----------\n        X : ndarray of shape (n_samples, n_features)\n            The data used to scale along the features axis.\n\n        inverse : bool, default=False\n            If False, apply forward transform. If True, apply\n        "}, {"start_line": 47000, "end_line": 49000, "belongs_to": {"file_name": "validation.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/utils", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "f the input is not in the list.\n\n    order : {'F', 'C'}, default=None\n        Whether an array will be forced to be fortran or c-style. If\n        `None`, then the input data's order is preserved when possible.\n\n    copy : bool, default=False\n        Whether a forced copy will be triggered. If copy=False, a copy might\n        be triggered by a conversion.\n\n    force_writeable : bool, default=False\n        Whether to force the output array to be writeable. If True, the returned array\n        is guaranteed to be writeable, which may require a copy. Otherwise the\n        writeability of the input array is preserved.\n\n        .. versionadded:: 1.6\n\n    force_all_finite : bool or 'allow-nan', default=True\n        Whether to raise an error on np.inf, np.nan, pd.NA in array. This parameter\n        does not influence whether y can have np.inf, np.nan, pd.NA values.\n        The possibilities are:\n\n        - True: Force all values of X to be finite.\n        - False: accepts np.inf, np.nan, pd.NA in X.\n        - 'allow-nan': accepts only np.nan or pd.NA values in X. Values cannot\n          be infinite.\n\n        .. versionadded:: 0.20\n           ``force_all_finite`` accepts the string ``'allow-nan'``.\n\n        .. versionchanged:: 0.23\n           Accepts `pd.NA` and converts it into `np.nan`\n\n        .. deprecated:: 1.6\n           `force_all_finite` was renamed to `ensure_all_finite` and will be removed\n           in 1.8.\n\n    ensure_all_finite : bool or 'allow-nan', default=True\n        Whether to raise an error on np.inf, np.nan, pd.NA in array. This parameter\n        does not influence whether y can have np.inf, np.nan, pd.NA values.\n        The possibilities are:\n\n        - True: Force all values of X to be finite.\n        - False: accepts np.inf, np.nan, pd.NA in X.\n        - 'allow-nan': accepts only np.nan or pd.NA values in X. Values cannot\n          be infinite.\n\n        .. versionadded:: 1.6\n           `force_all_finite` was renamed to `ensure_all_finite`.\n\n    ensure_"}, {"start_line": 12000, "end_line": 14000, "belongs_to": {"file_name": "test_isotonic.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "ir.fit(x, y)\n    all_predictions_finite = np.all(np.isfinite(ir.predict(x)))\n    assert all_predictions_finite\n\n\ndef test_isotonic_ymin_ymax():\n    # Test from @NelleV's issue:\n    # https://github.com/scikit-learn/scikit-learn/issues/6921\n    x = np.array(\n        [\n            1.263,\n            1.318,\n            -0.572,\n            0.307,\n            -0.707,\n            -0.176,\n            -1.599,\n            1.059,\n            1.396,\n            1.906,\n            0.210,\n            0.028,\n            -0.081,\n            0.444,\n            0.018,\n            -0.377,\n            -0.896,\n            -0.377,\n            -1.327,\n            0.180,\n        ]\n    )\n    y = isotonic_regression(x, y_min=0.0, y_max=0.1)\n\n    assert np.all(y >= 0)\n    assert np.all(y <= 0.1)\n\n    # Also test decreasing case since the logic there is different\n    y = isotonic_regression(x, y_min=0.0, y_max=0.1, increasing=False)\n\n    assert np.all(y >= 0)\n    assert np.all(y <= 0.1)\n\n    # Finally, test with only one bound\n    y = isotonic_regression(x, y_min=0.0, increasing=False)\n\n    assert np.all(y >= 0)\n\n\ndef test_isotonic_zero_weight_loop():\n    # Test from @ogrisel's issue:\n    # https://github.com/scikit-learn/scikit-learn/issues/4297\n\n    # Get deterministic RNG with seed\n    rng = np.random.RandomState(42)\n\n    # Create regression and samples\n    regression = IsotonicRegression()\n    n_samples = 50\n    x = np.linspace(-3, 3, n_samples)\n    y = x + rng.uniform(size=n_samples)\n\n    # Get some random weights and zero out\n    w = rng.uniform(size=n_samples)\n    w[5:8] = 0\n    regression.fit(x, y, sample_weight=w)\n\n    # This will hang in failure case.\n    regression.fit(x, y, sample_weight=w)\n\n\ndef test_fast_predict():\n    # test that the faster prediction change doesn't\n    # affect out-of-sample predictions:\n    # https://github.com/scikit-learn/scikit-learn/pull/6206\n    rng = np.random.RandomState(123)\n    n_samples = 10**3\n    # X values over the -10,10 range\n    X_train = 20.0"}, {"start_line": 72000, "end_line": 74000, "belongs_to": {"file_name": "test_encoders.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/preprocessing/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "equal(X_inverse, expected_inverse)\n\n\ndef test_ordinal_encoder_infrequent_three_levels_user_cats():\n    \"\"\"Test that the order of the categories provided by a user is respected.\n\n    In this case 'c' is encoded as the first category and 'b' is encoded\n    as the second one.\n    \"\"\"\n\n    X_train = np.array(\n        [[\"a\"] * 5 + [\"b\"] * 20 + [\"c\"] * 10 + [\"d\"] * 3], dtype=object\n    ).T\n    ordinal = OrdinalEncoder(\n        categories=[[\"c\", \"d\", \"b\", \"a\"]],\n        max_categories=3,\n        handle_unknown=\"use_encoded_value\",\n        unknown_value=-1,\n    ).fit(X_train)\n    assert_array_equal(ordinal.categories_, [[\"c\", \"d\", \"b\", \"a\"]])\n    assert_array_equal(ordinal.infrequent_categories_, [[\"d\", \"a\"]])\n\n    X_test = [[\"a\"], [\"b\"], [\"c\"], [\"d\"], [\"z\"]]\n    expected_trans = [[2], [1], [0], [2], [-1]]\n\n    X_trans = ordinal.transform(X_test)\n    assert_allclose(X_trans, expected_trans)\n\n    X_inverse = ordinal.inverse_transform(X_trans)\n    expected_inverse = [\n        [\"infrequent_sklearn\"],\n        [\"b\"],\n        [\"c\"],\n        [\"infrequent_sklearn\"],\n        [None],\n    ]\n    assert_array_equal(X_inverse, expected_inverse)\n\n\ndef test_ordinal_encoder_infrequent_mixed():\n    \"\"\"Test when feature 0 has infrequent categories and feature 1 does not.\"\"\"\n\n    X = np.column_stack(([0, 1, 3, 3, 3, 3, 2, 0, 3], [0, 0, 0, 0, 1, 1, 1, 1, 1]))\n\n    ordinal = OrdinalEncoder(max_categories=3).fit(X)\n\n    assert_array_equal(ordinal.infrequent_categories_[0], [1, 2])\n    assert ordinal.infrequent_categories_[1] is None\n\n    X_test = [[3, 0], [1, 1]]\n    expected_trans = [[1, 0], [2, 1]]\n\n    X_trans = ordinal.transform(X_test)\n    assert_allclose(X_trans, expected_trans)\n\n    X_inverse = ordinal.inverse_transform(X_trans)\n    expected_inverse = np.array([[3, 0], [\"infrequent_sklearn\", 1]], dtype=object)\n    assert_array_equal(X_inverse, expected_inverse)\n\n\ndef test_ordinal_encoder_infrequent_multiple_categories_dtypes():\n    \"\"\"Test infrequent categories with a pandas DataFrame with"}, {"start_line": 5000, "end_line": 7000, "belongs_to": {"file_name": "_function_transformer.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/preprocessing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "]])\n    >>> transformer.transform(X)\n    array([[0.       , 0.6931],\n           [1.0986, 1.3862]])\n    \"\"\"\n\n    _parameter_constraints: dict = {\n        \"func\": [callable, None],\n        \"inverse_func\": [callable, None],\n        \"validate\": [\"boolean\"],\n        \"accept_sparse\": [\"boolean\"],\n        \"check_inverse\": [\"boolean\"],\n        \"feature_names_out\": [callable, StrOptions({\"one-to-one\"}), None],\n        \"kw_args\": [dict, None],\n        \"inv_kw_args\": [dict, None],\n    }\n\n    def __init__(\n        self,\n        func=None,\n        inverse_func=None,\n        *,\n        validate=False,\n        accept_sparse=False,\n        check_inverse=True,\n        feature_names_out=None,\n        kw_args=None,\n        inv_kw_args=None,\n    ):\n        self.func = func\n        self.inverse_func = inverse_func\n        self.validate = validate\n        self.accept_sparse = accept_sparse\n        self.check_inverse = check_inverse\n        self.feature_names_out = feature_names_out\n        self.kw_args = kw_args\n        self.inv_kw_args = inv_kw_args\n\n    def _check_inverse_transform(self, X):\n        \"\"\"Check that func and inverse_func are the inverse.\"\"\"\n        idx_selected = slice(None, None, max(1, X.shape[0] // 100))\n        X_round_trip = self.inverse_transform(self.transform(X[idx_selected]))\n\n        if hasattr(X, \"dtype\"):\n            dtypes = [X.dtype]\n        elif hasattr(X, \"dtypes\"):\n            # Dataframes can have multiple dtypes\n            dtypes = X.dtypes\n\n        # Not all dtypes are numpy dtypes, they can be pandas dtypes as well\n        if not all(\n            isinstance(d, np.dtype) and np.issubdtype(d, np.number) for d in dtypes\n        ):\n            raise ValueError(\n                \"'check_inverse' is only supported when all the elements in `X` is\"\n                \" numerical.\"\n            )\n\n        if not _allclose_dense_sparse(X[idx_selected], X_round_trip):\n            warnings.warn(\n                (\n                    \"The provided functions are not st"}], "retrieved_count": 10, "cost_time": 0.38907909393310547}
{"question": "Where does the control flow in test_affinities determine which affinity computation pathway is executed based on the kernel type, and what data transformations occur at each decision point before labels are generated?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"start_line": 1000, "end_line": 3000, "belongs_to": {"file_name": "test_label_propagation.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/semi_supervised/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "knn\", \"n_neighbors\": 2}),\n    (\n        label_propagation.LabelSpreading,\n        {\"kernel\": lambda x, y: rbf_kernel(x, y, gamma=20)},\n    ),\n]\n\n\n@pytest.mark.parametrize(\"Estimator, parameters\", ESTIMATORS)\ndef test_fit_transduction(global_dtype, Estimator, parameters):\n    samples = np.asarray([[1.0, 0.0], [0.0, 2.0], [1.0, 3.0]], dtype=global_dtype)\n    labels = [0, 1, -1]\n    clf = Estimator(**parameters).fit(samples, labels)\n    assert clf.transduction_[2] == 1\n\n\n@pytest.mark.parametrize(\"Estimator, parameters\", ESTIMATORS)\ndef test_distribution(global_dtype, Estimator, parameters):\n    if parameters[\"kernel\"] == \"knn\":\n        pytest.skip(\n            \"Unstable test for this configuration: changes in k-NN ordering break it.\"\n        )\n    samples = np.asarray([[1.0, 0.0], [0.0, 1.0], [1.0, 1.0]], dtype=global_dtype)\n    labels = [0, 1, -1]\n    clf = Estimator(**parameters).fit(samples, labels)\n    assert_allclose(clf.label_distributions_[2], [0.5, 0.5], atol=1e-2)\n\n\n@pytest.mark.parametrize(\"Estimator, parameters\", ESTIMATORS)\ndef test_predict(global_dtype, Estimator, parameters):\n    samples = np.asarray([[1.0, 0.0], [0.0, 2.0], [1.0, 3.0]], dtype=global_dtype)\n    labels = [0, 1, -1]\n    clf = Estimator(**parameters).fit(samples, labels)\n    assert_array_equal(clf.predict([[0.5, 2.5]]), np.array([1]))\n\n\n@pytest.mark.parametrize(\"Estimator, parameters\", ESTIMATORS)\ndef test_predict_proba(global_dtype, Estimator, parameters):\n    samples = np.asarray([[1.0, 0.0], [0.0, 1.0], [1.0, 2.5]], dtype=global_dtype)\n    labels = [0, 1, -1]\n    clf = Estimator(**parameters).fit(samples, labels)\n    assert_allclose(clf.predict_proba([[1.0, 1.0]]), np.array([[0.5, 0.5]]))\n\n\n@pytest.mark.parametrize(\"alpha\", [0.1, 0.3, 0.5, 0.7, 0.9])\n@pytest.mark.parametrize(\"Estimator, parameters\", ESTIMATORS)\ndef test_label_spreading_closed_form(global_dtype, Estimator, parameters, alpha):\n    n_classes = 2\n    X, y = make_classification(n_classes=n_classes, n_samples=200, random_state="}, {"start_line": 3000, "end_line": 5000, "belongs_to": {"file_name": "test_spectral.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/cluster/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "ted\",\n            assign_labels=assign_labels,\n        )\n        .fit(S)\n        .labels_\n    )\n    assert adjusted_rand_score(y, labels) == 1\n\n\ndef test_precomputed_nearest_neighbors_filtering(global_random_seed):\n    # Test precomputed graph filtering when containing too many neighbors\n    X, y = make_blobs(\n        n_samples=250,\n        random_state=global_random_seed,\n        centers=[[1, 1, 1], [-1, -1, -1]],\n        cluster_std=0.01,\n    )\n\n    n_neighbors = 2\n    results = []\n    for additional_neighbors in [0, 10]:\n        nn = NearestNeighbors(n_neighbors=n_neighbors + additional_neighbors).fit(X)\n        graph = nn.kneighbors_graph(X, mode=\"distance\")\n        labels = (\n            SpectralClustering(\n                random_state=global_random_seed,\n                n_clusters=2,\n                affinity=\"precomputed_nearest_neighbors\",\n                n_neighbors=n_neighbors,\n            )\n            .fit(graph)\n            .labels_\n        )\n        results.append(labels)\n\n    assert_array_equal(results[0], results[1])\n\n\ndef test_affinities(global_random_seed):\n    # Note: in the following, random_state has been selected to have\n    # a dataset that yields a stable eigen decomposition both when built\n    # on OSX and Linux\n    X, y = make_blobs(\n        n_samples=20, random_state=0, centers=[[1, 1], [-1, -1]], cluster_std=0.01\n    )\n    # nearest neighbors affinity\n    sp = SpectralClustering(n_clusters=2, affinity=\"nearest_neighbors\", random_state=0)\n    with pytest.warns(UserWarning, match=\"not fully connected\"):\n        sp.fit(X)\n    assert adjusted_rand_score(y, sp.labels_) == 1\n\n    sp = SpectralClustering(n_clusters=2, gamma=2, random_state=global_random_seed)\n    labels = sp.fit(X).labels_\n    assert adjusted_rand_score(y, labels) == 1\n\n    X = check_random_state(10).rand(10, 5) * 10\n\n    kernels_available = kernel_metrics()\n    for kern in kernels_available:\n        # Additive chi^2 gives a negative similarity matrix which\n        # doesn't make"}, {"start_line": 0, "end_line": 2000, "belongs_to": {"file_name": "test_label_propagation.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/semi_supervised/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "\"\"\"test the label propagation module\"\"\"\n\nimport warnings\n\nimport numpy as np\nimport pytest\nfrom scipy.sparse import issparse\n\nfrom sklearn.datasets import make_classification\nfrom sklearn.exceptions import ConvergenceWarning\nfrom sklearn.metrics.pairwise import rbf_kernel\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import NearestNeighbors\nfrom sklearn.semi_supervised import _label_propagation as label_propagation\nfrom sklearn.utils._testing import (\n    _convert_container,\n    assert_allclose,\n    assert_array_equal,\n)\n\nCONSTRUCTOR_TYPES = (\"array\", \"sparse_csr\", \"sparse_csc\")\n\nESTIMATORS = [\n    (label_propagation.LabelPropagation, {\"kernel\": \"rbf\"}),\n    (label_propagation.LabelPropagation, {\"kernel\": \"knn\", \"n_neighbors\": 2}),\n    (\n        label_propagation.LabelPropagation,\n        {\"kernel\": lambda x, y: rbf_kernel(x, y, gamma=20)},\n    ),\n    (label_propagation.LabelSpreading, {\"kernel\": \"rbf\"}),\n    (label_propagation.LabelSpreading, {\"kernel\": \"knn\", \"n_neighbors\": 2}),\n    (\n        label_propagation.LabelSpreading,\n        {\"kernel\": lambda x, y: rbf_kernel(x, y, gamma=20)},\n    ),\n]\n\n\n@pytest.mark.parametrize(\"Estimator, parameters\", ESTIMATORS)\ndef test_fit_transduction(global_dtype, Estimator, parameters):\n    samples = np.asarray([[1.0, 0.0], [0.0, 2.0], [1.0, 3.0]], dtype=global_dtype)\n    labels = [0, 1, -1]\n    clf = Estimator(**parameters).fit(samples, labels)\n    assert clf.transduction_[2] == 1\n\n\n@pytest.mark.parametrize(\"Estimator, parameters\", ESTIMATORS)\ndef test_distribution(global_dtype, Estimator, parameters):\n    if parameters[\"kernel\"] == \"knn\":\n        pytest.skip(\n            \"Unstable test for this configuration: changes in k-NN ordering break it.\"\n        )\n    samples = np.asarray([[1.0, 0.0], [0.0, 1.0], [1.0, 1.0]], dtype=global_dtype)\n    labels = [0, 1, -1]\n    clf = Estimator(**parameters).fit(samples, labels)\n    assert_allclose(clf.label_distributions_[2], [0.5, 0.5], atol=1e-2)\n\n\n@pytest.mark."}, {"start_line": 4000, "end_line": 6000, "belongs_to": {"file_name": "test_spectral.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/cluster/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "\n    assert_array_equal(results[0], results[1])\n\n\ndef test_affinities(global_random_seed):\n    # Note: in the following, random_state has been selected to have\n    # a dataset that yields a stable eigen decomposition both when built\n    # on OSX and Linux\n    X, y = make_blobs(\n        n_samples=20, random_state=0, centers=[[1, 1], [-1, -1]], cluster_std=0.01\n    )\n    # nearest neighbors affinity\n    sp = SpectralClustering(n_clusters=2, affinity=\"nearest_neighbors\", random_state=0)\n    with pytest.warns(UserWarning, match=\"not fully connected\"):\n        sp.fit(X)\n    assert adjusted_rand_score(y, sp.labels_) == 1\n\n    sp = SpectralClustering(n_clusters=2, gamma=2, random_state=global_random_seed)\n    labels = sp.fit(X).labels_\n    assert adjusted_rand_score(y, labels) == 1\n\n    X = check_random_state(10).rand(10, 5) * 10\n\n    kernels_available = kernel_metrics()\n    for kern in kernels_available:\n        # Additive chi^2 gives a negative similarity matrix which\n        # doesn't make sense for spectral clustering\n        if kern != \"additive_chi2\":\n            sp = SpectralClustering(n_clusters=2, affinity=kern, random_state=0)\n            labels = sp.fit(X).labels_\n            assert (X.shape[0],) == labels.shape\n\n    sp = SpectralClustering(n_clusters=2, affinity=lambda x, y: 1, random_state=0)\n    labels = sp.fit(X).labels_\n    assert (X.shape[0],) == labels.shape\n\n    def histogram(x, y, **kwargs):\n        # Histogram kernel implemented as a callable.\n        assert kwargs == {}  # no kernel_params that we didn't ask for\n        return np.minimum(x, y).sum()\n\n    sp = SpectralClustering(n_clusters=2, affinity=histogram, random_state=0)\n    labels = sp.fit(X).labels_\n    assert (X.shape[0],) == labels.shape\n\n\ndef test_cluster_qr(global_random_seed):\n    # cluster_qr by itself should not be used for clustering generic data\n    # other than the rows of the eigenvectors within spectral clustering,\n    # but cluster_qr must still preserve the labels for different d"}, {"start_line": 5000, "end_line": 7000, "belongs_to": {"file_name": "test_spectral_embedding.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/manifold/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "ple + 1, 0] = 1\n    affinity.flat[:: 2 * n_sample + 1] = 0\n    affinity = 0.5 * (affinity + affinity.T)\n\n    true_label = np.zeros(shape=2 * n_sample)\n    true_label[0:n_sample] = 1\n\n    se_precomp = SpectralEmbedding(\n        n_components=1,\n        affinity=\"precomputed\",\n        random_state=np.random.RandomState(seed),\n        eigen_solver=eigen_solver,\n    )\n\n    embedded_coordinate = se_precomp.fit_transform(affinity.astype(dtype))\n    # thresholding on the first components using 0.\n    label_ = np.array(embedded_coordinate.ravel() < 0, dtype=np.int64)\n    assert normalized_mutual_info_score(true_label, label_) == pytest.approx(1.0)\n\n\n@pytest.mark.parametrize(\"sparse_container\", [None, *CSR_CONTAINERS])\n@pytest.mark.parametrize(\n    \"eigen_solver\",\n    [\n        \"arpack\",\n        \"lobpcg\",\n        pytest.param(\"amg\", marks=skip_if_no_pyamg),\n    ],\n)\n@pytest.mark.parametrize(\"dtype\", (np.float32, np.float64))\ndef test_spectral_embedding_precomputed_affinity(\n    sparse_container, eigen_solver, dtype, seed=36\n):\n    # Test spectral embedding with precomputed kernel\n    gamma = 1.0\n    X = S if sparse_container is None else sparse_container(S)\n\n    se_precomp = SpectralEmbedding(\n        n_components=2,\n        affinity=\"precomputed\",\n        random_state=np.random.RandomState(seed),\n        eigen_solver=eigen_solver,\n    )\n    se_rbf = SpectralEmbedding(\n        n_components=2,\n        affinity=\"rbf\",\n        gamma=gamma,\n        random_state=np.random.RandomState(seed),\n        eigen_solver=eigen_solver,\n    )\n    embed_precomp = se_precomp.fit_transform(rbf_kernel(X.astype(dtype), gamma=gamma))\n    embed_rbf = se_rbf.fit_transform(X.astype(dtype))\n    assert_array_almost_equal(se_precomp.affinity_matrix_, se_rbf.affinity_matrix_)\n    _assert_equal_with_sign_flipping(embed_precomp, embed_rbf, 0.05)\n\n\ndef test_precomputed_nearest_neighbors_filtering():\n    # Test precomputed graph filtering when containing too many neighbors\n    n_neighbors = 2\n    results = []"}, {"start_line": 5000, "end_line": 7000, "belongs_to": {"file_name": "test_spectral.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/cluster/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": " sense for spectral clustering\n        if kern != \"additive_chi2\":\n            sp = SpectralClustering(n_clusters=2, affinity=kern, random_state=0)\n            labels = sp.fit(X).labels_\n            assert (X.shape[0],) == labels.shape\n\n    sp = SpectralClustering(n_clusters=2, affinity=lambda x, y: 1, random_state=0)\n    labels = sp.fit(X).labels_\n    assert (X.shape[0],) == labels.shape\n\n    def histogram(x, y, **kwargs):\n        # Histogram kernel implemented as a callable.\n        assert kwargs == {}  # no kernel_params that we didn't ask for\n        return np.minimum(x, y).sum()\n\n    sp = SpectralClustering(n_clusters=2, affinity=histogram, random_state=0)\n    labels = sp.fit(X).labels_\n    assert (X.shape[0],) == labels.shape\n\n\ndef test_cluster_qr(global_random_seed):\n    # cluster_qr by itself should not be used for clustering generic data\n    # other than the rows of the eigenvectors within spectral clustering,\n    # but cluster_qr must still preserve the labels for different dtypes\n    # of the generic fixed input even if the labels may be meaningless.\n    random_state = np.random.RandomState(seed=global_random_seed)\n    n_samples, n_components = 10, 5\n    data = random_state.randn(n_samples, n_components)\n    labels_float64 = cluster_qr(data.astype(np.float64))\n    # Each sample is assigned a cluster identifier\n    assert labels_float64.shape == (n_samples,)\n    # All components should be covered by the assignment\n    assert np.array_equal(np.unique(labels_float64), np.arange(n_components))\n    # Single precision data should yield the same cluster assignments\n    labels_float32 = cluster_qr(data.astype(np.float32))\n    assert np.array_equal(labels_float64, labels_float32)\n\n\ndef test_cluster_qr_permutation_invariance(global_random_seed):\n    # cluster_qr must be invariant to sample permutation.\n    random_state = np.random.RandomState(seed=global_random_seed)\n    n_samples, n_components = 100, 5\n    data = random_state.randn(n_samples, n_components)\n    per"}, {"start_line": 4000, "end_line": 6000, "belongs_to": {"file_name": "test_label_propagation.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/semi_supervised/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "= (Y[:, (-1,)] == 0).nonzero()[0]\n\n    clf = label_propagation.LabelPropagation(max_iter=100, tol=1e-10, gamma=0.1)\n    clf.fit(X, y)\n    # adopting notation from Zhu et al 2002\n    T_bar = clf._build_graph()\n    Tuu = T_bar[tuple(np.meshgrid(unlabelled_idx, unlabelled_idx, indexing=\"ij\"))]\n    Tul = T_bar[tuple(np.meshgrid(unlabelled_idx, labelled_idx, indexing=\"ij\"))]\n    Y = Y[:, :-1]\n    Y_l = Y[labelled_idx, :]\n    Y_u = np.dot(np.dot(np.linalg.inv(np.eye(Tuu.shape[0]) - Tuu), Tul), Y_l)\n\n    expected = Y.copy()\n    expected[unlabelled_idx, :] = Y_u\n    expected /= expected.sum(axis=1)[:, np.newaxis]\n\n    assert_allclose(expected, clf.label_distributions_, atol=1e-4)\n\n\n@pytest.mark.parametrize(\"accepted_sparse_type\", [\"sparse_csr\", \"sparse_csc\"])\n@pytest.mark.parametrize(\"index_dtype\", [np.int32, np.int64])\n@pytest.mark.parametrize(\"dtype\", [np.float32, np.float64])\n@pytest.mark.parametrize(\"Estimator, parameters\", ESTIMATORS)\ndef test_sparse_input_types(\n    accepted_sparse_type, index_dtype, dtype, Estimator, parameters\n):\n    # This is non-regression test for #17085\n    X = _convert_container([[1.0, 0.0], [0.0, 2.0], [1.0, 3.0]], accepted_sparse_type)\n    X.data = X.data.astype(dtype, copy=False)\n    X.indices = X.indices.astype(index_dtype, copy=False)\n    X.indptr = X.indptr.astype(index_dtype, copy=False)\n    labels = [0, 1, -1]\n    clf = Estimator(**parameters).fit(X, labels)\n    assert_array_equal(clf.predict([[0.5, 2.5]]), np.array([1]))\n\n\n@pytest.mark.parametrize(\"constructor_type\", CONSTRUCTOR_TYPES)\ndef test_convergence_speed(constructor_type):\n    # This is a non-regression test for #5774\n    X = _convert_container([[1.0, 0.0], [0.0, 1.0], [1.0, 2.5]], constructor_type)\n    y = np.array([0, 1, -1])\n    mdl = label_propagation.LabelSpreading(kernel=\"rbf\", max_iter=5000)\n    mdl.fit(X, y)\n\n    # this should converge quickly:\n    assert mdl.n_iter_ < 10\n    assert_array_equal(mdl.predict(X), [0, 1, 1])\n\n\ndef test_convergence_warning():\n    # This is a"}, {"start_line": 6000, "end_line": 8000, "belongs_to": {"file_name": "test_spectral_embedding.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/manifold/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": " eigen_solver, dtype, seed=36\n):\n    # Test spectral embedding with precomputed kernel\n    gamma = 1.0\n    X = S if sparse_container is None else sparse_container(S)\n\n    se_precomp = SpectralEmbedding(\n        n_components=2,\n        affinity=\"precomputed\",\n        random_state=np.random.RandomState(seed),\n        eigen_solver=eigen_solver,\n    )\n    se_rbf = SpectralEmbedding(\n        n_components=2,\n        affinity=\"rbf\",\n        gamma=gamma,\n        random_state=np.random.RandomState(seed),\n        eigen_solver=eigen_solver,\n    )\n    embed_precomp = se_precomp.fit_transform(rbf_kernel(X.astype(dtype), gamma=gamma))\n    embed_rbf = se_rbf.fit_transform(X.astype(dtype))\n    assert_array_almost_equal(se_precomp.affinity_matrix_, se_rbf.affinity_matrix_)\n    _assert_equal_with_sign_flipping(embed_precomp, embed_rbf, 0.05)\n\n\ndef test_precomputed_nearest_neighbors_filtering():\n    # Test precomputed graph filtering when containing too many neighbors\n    n_neighbors = 2\n    results = []\n    for additional_neighbors in [0, 10]:\n        nn = NearestNeighbors(n_neighbors=n_neighbors + additional_neighbors).fit(S)\n        graph = nn.kneighbors_graph(S, mode=\"connectivity\")\n        embedding = (\n            SpectralEmbedding(\n                random_state=0,\n                n_components=2,\n                affinity=\"precomputed_nearest_neighbors\",\n                n_neighbors=n_neighbors,\n            )\n            .fit(graph)\n            .embedding_\n        )\n        results.append(embedding)\n\n    assert_array_equal(results[0], results[1])\n\n\n@pytest.mark.parametrize(\"sparse_container\", [None, *CSR_CONTAINERS])\ndef test_spectral_embedding_callable_affinity(sparse_container, seed=36):\n    # Test spectral embedding with callable affinity\n    gamma = 0.9\n    kern = rbf_kernel(S, gamma=gamma)\n    X = S if sparse_container is None else sparse_container(S)\n\n    se_callable = SpectralEmbedding(\n        n_components=2,\n        affinity=(lambda x: rbf_kernel(x, gamma=gamma)),\n        "}, {"start_line": 3000, "end_line": 5000, "belongs_to": {"file_name": "test_label_propagation.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/semi_supervised/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "0)\n    X = X.astype(global_dtype, copy=False)\n    y[::3] = -1\n\n    gamma = 0.1\n    clf = label_propagation.LabelSpreading(gamma=gamma).fit(X, y)\n    # adopting notation from Zhou et al (2004):\n    S = clf._build_graph()\n    Y = np.zeros((len(y), n_classes + 1), dtype=X.dtype)\n    Y[np.arange(len(y)), y] = 1\n    Y = Y[:, :-1]\n\n    expected = np.dot(np.linalg.inv(np.eye(len(S), dtype=S.dtype) - alpha * S), Y)\n    expected /= expected.sum(axis=1)[:, np.newaxis]\n\n    clf = label_propagation.LabelSpreading(\n        max_iter=100, alpha=alpha, tol=1e-10, gamma=gamma\n    )\n    clf.fit(X, y)\n\n    assert_allclose(expected, clf.label_distributions_)\n\n\ndef test_label_propagation_closed_form(global_dtype):\n    n_classes = 2\n    X, y = make_classification(n_classes=n_classes, n_samples=200, random_state=0)\n    X = X.astype(global_dtype, copy=False)\n    y[::3] = -1\n    Y = np.zeros((len(y), n_classes + 1))\n    Y[np.arange(len(y)), y] = 1\n    unlabelled_idx = Y[:, (-1,)].nonzero()[0]\n    labelled_idx = (Y[:, (-1,)] == 0).nonzero()[0]\n\n    clf = label_propagation.LabelPropagation(max_iter=100, tol=1e-10, gamma=0.1)\n    clf.fit(X, y)\n    # adopting notation from Zhu et al 2002\n    T_bar = clf._build_graph()\n    Tuu = T_bar[tuple(np.meshgrid(unlabelled_idx, unlabelled_idx, indexing=\"ij\"))]\n    Tul = T_bar[tuple(np.meshgrid(unlabelled_idx, labelled_idx, indexing=\"ij\"))]\n    Y = Y[:, :-1]\n    Y_l = Y[labelled_idx, :]\n    Y_u = np.dot(np.dot(np.linalg.inv(np.eye(Tuu.shape[0]) - Tuu), Tul), Y_l)\n\n    expected = Y.copy()\n    expected[unlabelled_idx, :] = Y_u\n    expected /= expected.sum(axis=1)[:, np.newaxis]\n\n    assert_allclose(expected, clf.label_distributions_, atol=1e-4)\n\n\n@pytest.mark.parametrize(\"accepted_sparse_type\", [\"sparse_csr\", \"sparse_csc\"])\n@pytest.mark.parametrize(\"index_dtype\", [np.int32, np.int64])\n@pytest.mark.parametrize(\"dtype\", [np.float32, np.float64])\n@pytest.mark.parametrize(\"Estimator, parameters\", ESTIMATORS)\ndef test_sparse_input_types(\n    accepted_sparse_type,"}, {"start_line": 7000, "end_line": 8801, "belongs_to": {"file_name": "test_label_propagation.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/semi_supervised/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "el_propagation.LabelSpreading, label_propagation.LabelPropagation],\n)\ndef test_label_propagation_non_zero_normalizer(LabelPropagationCls):\n    # check that we don't divide by zero in case of null normalizer\n    # non-regression test for\n    # https://github.com/scikit-learn/scikit-learn/pull/15946\n    # https://github.com/scikit-learn/scikit-learn/issues/9292\n    X = np.array([[100.0, 100.0], [100.0, 100.0], [0.0, 0.0], [0.0, 0.0]])\n    y = np.array([0, 1, -1, -1])\n    mdl = LabelPropagationCls(kernel=\"knn\", max_iter=100, n_neighbors=1)\n    with warnings.catch_warnings():\n        warnings.simplefilter(\"error\", RuntimeWarning)\n        mdl.fit(X, y)\n\n\ndef test_predict_sparse_callable_kernel(global_dtype):\n    # This is a non-regression test for #15866\n\n    # Custom sparse kernel (top-K RBF)\n    def topk_rbf(X, Y=None, n_neighbors=10, gamma=1e-5):\n        nn = NearestNeighbors(n_neighbors=10, metric=\"euclidean\", n_jobs=2)\n        nn.fit(X)\n        W = -1 * nn.kneighbors_graph(Y, mode=\"distance\").power(2) * gamma\n        np.exp(W.data, out=W.data)\n        assert issparse(W)\n        return W.T\n\n    n_classes = 4\n    n_samples = 500\n    n_test = 10\n    X, y = make_classification(\n        n_classes=n_classes,\n        n_samples=n_samples,\n        n_features=20,\n        n_informative=20,\n        n_redundant=0,\n        n_repeated=0,\n        random_state=0,\n    )\n    X = X.astype(global_dtype)\n\n    X_train, X_test, y_train, y_test = train_test_split(\n        X, y, test_size=n_test, random_state=0\n    )\n\n    model = label_propagation.LabelSpreading(kernel=topk_rbf)\n    model.fit(X_train, y_train)\n    assert model.score(X_test, y_test) >= 0.9\n\n    model = label_propagation.LabelPropagation(kernel=topk_rbf)\n    model.fit(X_train, y_train)\n    assert model.score(X_test, y_test) >= 0.9\n"}], "retrieved_count": 10, "cost_time": 0.38211536407470703}
{"question": "Where does the permutation loop control the data transformation flow between y_true and y_score, and what specific inverse mapping mechanism ensures that the metric computation remains invariant across all class label permutations?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"start_line": 59000, "end_line": 61000, "belongs_to": {"file_name": "test_common.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/metrics/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "             continue\n\n            metric = ALL_METRICS[name]\n\n            score_labels = metric(y_true, y_pred, labels=labels, average=None)\n            score = metric(y_true, y_pred, average=None)\n            assert_array_equal(score_labels, score[inverse_labels])\n\n\n@pytest.mark.parametrize(\n    \"name\", sorted(MULTILABELS_METRICS - {\"unnormalized_multilabel_confusion_matrix\"})\n)\ndef test_multilabel_label_permutations_invariance(name):\n    random_state = check_random_state(0)\n    n_samples, n_classes = 20, 4\n\n    y_true = random_state.randint(0, 2, size=(n_samples, n_classes))\n    y_score = random_state.randint(0, 2, size=(n_samples, n_classes))\n\n    metric = ALL_METRICS[name]\n    score = metric(y_true, y_score)\n\n    for perm in permutations(range(n_classes), n_classes):\n        y_score_perm = y_score[:, perm]\n        y_true_perm = y_true[:, perm]\n\n        current_score = metric(y_true_perm, y_score_perm)\n        assert_almost_equal(score, current_score)\n\n\n@pytest.mark.parametrize(\n    \"name\", sorted(THRESHOLDED_MULTILABEL_METRICS | MULTIOUTPUT_METRICS)\n)\ndef test_thresholded_multilabel_multioutput_permutations_invariance(name):\n    random_state = check_random_state(0)\n    n_samples, n_classes = 20, 4\n    y_true = random_state.randint(0, 2, size=(n_samples, n_classes))\n    y_score = random_state.uniform(size=y_true.shape)\n\n    # Some metrics (e.g. log_loss) require y_score to be probabilities (sum to 1)\n    y_score /= y_score.sum(axis=1, keepdims=True)\n\n    # Makes sure all samples have at least one label. This works around errors\n    # when running metrics where average=\"sample\"\n    y_true[y_true.sum(1) == 4, 0] = 0\n    y_true[y_true.sum(1) == 0, 0] = 1\n\n    metric = ALL_METRICS[name]\n    score = metric(y_true, y_score)\n\n    for perm in permutations(range(n_classes), n_classes):\n        y_score_perm = y_score[:, perm]\n        y_true_perm = y_true[:, perm]\n\n        current_score = metric(y_true_perm, y_score_perm)\n        if metric == mean_absolute_percentage_error"}, {"start_line": 60000, "end_line": 62000, "belongs_to": {"file_name": "test_common.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/metrics/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "  \"name\", sorted(THRESHOLDED_MULTILABEL_METRICS | MULTIOUTPUT_METRICS)\n)\ndef test_thresholded_multilabel_multioutput_permutations_invariance(name):\n    random_state = check_random_state(0)\n    n_samples, n_classes = 20, 4\n    y_true = random_state.randint(0, 2, size=(n_samples, n_classes))\n    y_score = random_state.uniform(size=y_true.shape)\n\n    # Some metrics (e.g. log_loss) require y_score to be probabilities (sum to 1)\n    y_score /= y_score.sum(axis=1, keepdims=True)\n\n    # Makes sure all samples have at least one label. This works around errors\n    # when running metrics where average=\"sample\"\n    y_true[y_true.sum(1) == 4, 0] = 0\n    y_true[y_true.sum(1) == 0, 0] = 1\n\n    metric = ALL_METRICS[name]\n    score = metric(y_true, y_score)\n\n    for perm in permutations(range(n_classes), n_classes):\n        y_score_perm = y_score[:, perm]\n        y_true_perm = y_true[:, perm]\n\n        current_score = metric(y_true_perm, y_score_perm)\n        if metric == mean_absolute_percentage_error:\n            assert np.isfinite(current_score)\n            assert current_score > 1e6\n            # Here we are not comparing the values in case of MAPE because\n            # whenever y_true value is exactly zero, the MAPE value doesn't\n            # signify anything. Thus, in this case we are just expecting\n            # very large finite value.\n        else:\n            assert_almost_equal(score, current_score)\n\n\n@pytest.mark.parametrize(\n    \"name\", sorted(set(THRESHOLDED_METRICS) - METRIC_UNDEFINED_BINARY_MULTICLASS)\n)\ndef test_thresholded_metric_permutation_invariance(name):\n    n_samples, n_classes = 100, 3\n    random_state = check_random_state(0)\n\n    y_score = random_state.rand(n_samples, n_classes)\n    temp = np.exp(-y_score)\n    y_score = temp / temp.sum(axis=-1).reshape(-1, 1)\n    y_true = random_state.randint(0, n_classes, size=n_samples)\n\n    metric = ALL_METRICS[name]\n    score = metric(y_true, y_score)\n    for perm in permutations(range(n_classes), n_classes):\n        i"}, {"start_line": 61000, "end_line": 63000, "belongs_to": {"file_name": "test_common.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/metrics/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": ":\n            assert np.isfinite(current_score)\n            assert current_score > 1e6\n            # Here we are not comparing the values in case of MAPE because\n            # whenever y_true value is exactly zero, the MAPE value doesn't\n            # signify anything. Thus, in this case we are just expecting\n            # very large finite value.\n        else:\n            assert_almost_equal(score, current_score)\n\n\n@pytest.mark.parametrize(\n    \"name\", sorted(set(THRESHOLDED_METRICS) - METRIC_UNDEFINED_BINARY_MULTICLASS)\n)\ndef test_thresholded_metric_permutation_invariance(name):\n    n_samples, n_classes = 100, 3\n    random_state = check_random_state(0)\n\n    y_score = random_state.rand(n_samples, n_classes)\n    temp = np.exp(-y_score)\n    y_score = temp / temp.sum(axis=-1).reshape(-1, 1)\n    y_true = random_state.randint(0, n_classes, size=n_samples)\n\n    metric = ALL_METRICS[name]\n    score = metric(y_true, y_score)\n    for perm in permutations(range(n_classes), n_classes):\n        inverse_perm = np.zeros(n_classes, dtype=int)\n        inverse_perm[list(perm)] = np.arange(n_classes)\n        y_score_perm = y_score[:, inverse_perm]\n        y_true_perm = np.take(perm, y_true)\n\n        current_score = metric(y_true_perm, y_score_perm)\n        assert_almost_equal(score, current_score)\n\n\n@pytest.mark.parametrize(\"metric_name\", CLASSIFICATION_METRICS)\ndef test_metrics_consistent_type_error(metric_name):\n    # check that an understable message is raised when the type between y_true\n    # and y_pred mismatch\n    rng = np.random.RandomState(42)\n    y1 = np.array([\"spam\"] * 3 + [\"eggs\"] * 2, dtype=object)\n    y2 = rng.randint(0, 2, size=y1.size)\n\n    err_msg = \"Labels in y_true and y_pred should be of the same type.\"\n    with pytest.raises(TypeError, match=err_msg):\n        CLASSIFICATION_METRICS[metric_name](y1, y2)\n\n\n@pytest.mark.parametrize(\n    \"metric, y_pred_threshold\",\n    [\n        (average_precision_score, True),\n        (brier_score_loss, True),\n        (f1_score, F"}, {"start_line": 4000, "end_line": 6000, "belongs_to": {"file_name": "test_common.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/metrics/cluster/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": " pytest.approx(1.0)\n\n    lower_bound_1 = [0, 0, 0, 0, 0, 0]\n    lower_bound_2 = [0, 1, 2, 3, 4, 5]\n    score = np.array(\n        [metric(lower_bound_1, lower_bound_2), metric(lower_bound_2, lower_bound_1)]\n    )\n    assert not (score < 0).any()\n\n\n@pytest.mark.parametrize(\"metric_name\", chain(SUPERVISED_METRICS, UNSUPERVISED_METRICS))\ndef test_permute_labels(metric_name):\n    # All clustering metrics do not change score due to permutations of labels\n    # that is when 0 and 1 exchanged.\n    y_label = np.array([0, 0, 0, 1, 1, 0, 1])\n    y_pred = np.array([1, 0, 1, 0, 1, 1, 0])\n    if metric_name in SUPERVISED_METRICS:\n        metric = SUPERVISED_METRICS[metric_name]\n        score_1 = metric(y_pred, y_label)\n        assert_allclose(score_1, metric(1 - y_pred, y_label))\n        assert_allclose(score_1, metric(1 - y_pred, 1 - y_label))\n        assert_allclose(score_1, metric(y_pred, 1 - y_label))\n    else:\n        metric = UNSUPERVISED_METRICS[metric_name]\n        X = np.random.randint(10, size=(7, 10))\n        score_1 = metric(X, y_pred)\n        assert_allclose(score_1, metric(X, 1 - y_pred))\n\n\n@pytest.mark.parametrize(\"metric_name\", chain(SUPERVISED_METRICS, UNSUPERVISED_METRICS))\n# For all clustering metrics Input parameters can be both\n# in the form of arrays lists, positive, negative or string\ndef test_format_invariance(metric_name):\n    y_true = [0, 0, 0, 0, 1, 1, 1, 1]\n    y_pred = [0, 1, 2, 3, 4, 5, 6, 7]\n\n    def generate_formats(y):\n        y = np.array(y)\n        yield y, \"array of ints\"\n        yield y.tolist(), \"list of ints\"\n        yield [str(x) + \"-a\" for x in y.tolist()], \"list of strs\"\n        yield (\n            np.array([str(x) + \"-a\" for x in y.tolist()], dtype=object),\n            \"array of strs\",\n        )\n        yield y - 1, \"including negative ints\"\n        yield y + 1, \"strictly positive ints\"\n\n    if metric_name in SUPERVISED_METRICS:\n        metric = SUPERVISED_METRICS[metric_name]\n        score_1 = metric(y_true, y_pred)\n        y_true_gen ="}, {"start_line": 38000, "end_line": 40000, "belongs_to": {"file_name": "test_common.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/metrics/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "ed = random_state.uniform(0, 2, size=(20, 5))\n\n    metric = ALL_METRICS[name]\n    error = metric(y_true, y_pred)\n\n    for _ in range(3):\n        perm = random_state.permutation(y_true.shape[1])\n        assert_allclose(\n            metric(y_true[:, perm], y_pred[:, perm]),\n            error,\n            err_msg=\"%s is not dimension shuffling invariant\" % (name),\n        )\n\n\n@pytest.mark.filterwarnings(\"ignore::sklearn.exceptions.UndefinedMetricWarning\")\n@pytest.mark.parametrize(\"coo_container\", COO_CONTAINERS)\ndef test_multilabel_representation_invariance(coo_container):\n    # Generate some data\n    n_classes = 4\n    n_samples = 50\n\n    _, y1 = make_multilabel_classification(\n        n_features=1,\n        n_classes=n_classes,\n        random_state=0,\n        n_samples=n_samples,\n        allow_unlabeled=True,\n    )\n    _, y2 = make_multilabel_classification(\n        n_features=1,\n        n_classes=n_classes,\n        random_state=1,\n        n_samples=n_samples,\n        allow_unlabeled=True,\n    )\n\n    # To make sure at least one empty label is present\n    y1 = np.vstack([y1, [[0] * n_classes]])\n    y2 = np.vstack([y2, [[0] * n_classes]])\n\n    y1_sparse_indicator = coo_container(y1)\n    y2_sparse_indicator = coo_container(y2)\n\n    y1_list_array_indicator = list(y1)\n    y2_list_array_indicator = list(y2)\n\n    y1_list_list_indicator = [list(a) for a in y1_list_array_indicator]\n    y2_list_list_indicator = [list(a) for a in y2_list_array_indicator]\n\n    for name in MULTILABELS_METRICS:\n        metric = ALL_METRICS[name]\n\n        # XXX cruel hack to work with partial functions\n        if isinstance(metric, partial):\n            metric.__module__ = \"tmp\"\n            metric.__name__ = name\n\n        measure = metric(y1, y2)\n\n        # Check representation invariance\n        assert_allclose(\n            metric(y1_sparse_indicator, y2_sparse_indicator),\n            measure,\n            err_msg=(\n                \"%s failed representation invariance between \"\n                \"dense"}, {"start_line": 58000, "end_line": 60000, "belongs_to": {"file_name": "test_common.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/metrics/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "def test_multioutput_sample_weight_invariance(name):\n    random_state = check_random_state(0)\n    y_true = random_state.uniform(0, 2, size=(20, 5))\n    y_pred = random_state.uniform(0, 2, size=(20, 5))\n\n    metric = ALL_METRICS[name]\n    check_sample_weight_invariance(name, metric, y_true, y_pred)\n\n\ndef test_no_averaging_labels():\n    # test labels argument when not using averaging\n    # in multi-class and multi-label cases\n    y_true_multilabel = np.array([[1, 1, 0, 0], [1, 1, 0, 0]])\n    y_pred_multilabel = np.array([[0, 0, 1, 1], [0, 1, 1, 0]])\n    y_true_multiclass = np.array([0, 1, 2])\n    y_pred_multiclass = np.array([0, 2, 3])\n    labels = np.array([3, 0, 1, 2])\n    _, inverse_labels = np.unique(labels, return_inverse=True)\n\n    for name in METRICS_WITH_AVERAGING:\n        for y_true, y_pred in [\n            [y_true_multiclass, y_pred_multiclass],\n            [y_true_multilabel, y_pred_multilabel],\n        ]:\n            if name not in MULTILABELS_METRICS and y_pred.ndim > 1:\n                continue\n\n            metric = ALL_METRICS[name]\n\n            score_labels = metric(y_true, y_pred, labels=labels, average=None)\n            score = metric(y_true, y_pred, average=None)\n            assert_array_equal(score_labels, score[inverse_labels])\n\n\n@pytest.mark.parametrize(\n    \"name\", sorted(MULTILABELS_METRICS - {\"unnormalized_multilabel_confusion_matrix\"})\n)\ndef test_multilabel_label_permutations_invariance(name):\n    random_state = check_random_state(0)\n    n_samples, n_classes = 20, 4\n\n    y_true = random_state.randint(0, 2, size=(n_samples, n_classes))\n    y_score = random_state.randint(0, 2, size=(n_samples, n_classes))\n\n    metric = ALL_METRICS[name]\n    score = metric(y_true, y_score)\n\n    for perm in permutations(range(n_classes), n_classes):\n        y_score_perm = y_score[:, perm]\n        y_true_perm = y_true[:, perm]\n\n        current_score = metric(y_true_perm, y_score_perm)\n        assert_almost_equal(score, current_score)\n\n\n@pytest.mark.parametrize(\n  "}, {"start_line": 62000, "end_line": 64000, "belongs_to": {"file_name": "test_common.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/metrics/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "nverse_perm = np.zeros(n_classes, dtype=int)\n        inverse_perm[list(perm)] = np.arange(n_classes)\n        y_score_perm = y_score[:, inverse_perm]\n        y_true_perm = np.take(perm, y_true)\n\n        current_score = metric(y_true_perm, y_score_perm)\n        assert_almost_equal(score, current_score)\n\n\n@pytest.mark.parametrize(\"metric_name\", CLASSIFICATION_METRICS)\ndef test_metrics_consistent_type_error(metric_name):\n    # check that an understable message is raised when the type between y_true\n    # and y_pred mismatch\n    rng = np.random.RandomState(42)\n    y1 = np.array([\"spam\"] * 3 + [\"eggs\"] * 2, dtype=object)\n    y2 = rng.randint(0, 2, size=y1.size)\n\n    err_msg = \"Labels in y_true and y_pred should be of the same type.\"\n    with pytest.raises(TypeError, match=err_msg):\n        CLASSIFICATION_METRICS[metric_name](y1, y2)\n\n\n@pytest.mark.parametrize(\n    \"metric, y_pred_threshold\",\n    [\n        (average_precision_score, True),\n        (brier_score_loss, True),\n        (f1_score, False),\n        (partial(fbeta_score, beta=1), False),\n        (jaccard_score, False),\n        (precision_recall_curve, True),\n        (precision_score, False),\n        (recall_score, False),\n        (roc_curve, True),\n    ],\n)\n@pytest.mark.parametrize(\"dtype_y_str\", [str, object])\ndef test_metrics_pos_label_error_str(metric, y_pred_threshold, dtype_y_str):\n    # check that the error message if `pos_label` is not specified and the\n    # targets is made of strings.\n    rng = np.random.RandomState(42)\n    y1 = np.array([\"spam\"] * 3 + [\"eggs\"] * 2, dtype=dtype_y_str)\n    y2 = rng.randint(0, 2, size=y1.size)\n\n    if not y_pred_threshold:\n        y2 = np.array([\"spam\", \"eggs\"], dtype=dtype_y_str)[y2]\n\n    err_msg_pos_label_None = (\n        \"y_true takes value in {'eggs', 'spam'} and pos_label is not \"\n        \"specified: either make y_true take value in {0, 1} or {-1, 1} or \"\n        \"pass pos_label explicit\"\n    )\n    err_msg_pos_label_1 = (\n        r\"pos_label=1 is not a valid label. It sh"}, {"start_line": 64000, "end_line": 66000, "belongs_to": {"file_name": "_validation.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/model_selection", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "array(permutation_scores)\n    pvalue = (np.sum(permutation_scores >= score) + 1.0) / (n_permutations + 1)\n    return score, permutation_scores, pvalue\n\n\ndef _permutation_test_score(\n    estimator, X, y, cv, scorer, split_params, fit_params, score_params\n):\n    \"\"\"Auxiliary function for permutation_test_score\"\"\"\n    # Adjust length of sample weights\n    fit_params = fit_params if fit_params is not None else {}\n    score_params = score_params if score_params is not None else {}\n\n    avg_score = []\n    for train, test in cv.split(X, y, **split_params):\n        X_train, y_train = _safe_split(estimator, X, y, train)\n        X_test, y_test = _safe_split(estimator, X, y, test, train)\n        fit_params_train = _check_method_params(X, params=fit_params, indices=train)\n        score_params_test = _check_method_params(X, params=score_params, indices=test)\n        estimator.fit(X_train, y_train, **fit_params_train)\n        avg_score.append(scorer(estimator, X_test, y_test, **score_params_test))\n    return np.mean(avg_score)\n\n\ndef _shuffle(y, groups, random_state):\n    \"\"\"Return a shuffled copy of y eventually shuffle among same groups.\"\"\"\n    if groups is None:\n        indices = random_state.permutation(len(y))\n    else:\n        indices = np.arange(len(groups))\n        for group in np.unique(groups):\n            this_mask = groups == group\n            indices[this_mask] = random_state.permutation(indices[this_mask])\n    return _safe_indexing(y, indices)\n\n\n@validate_params(\n    {\n        \"estimator\": [HasMethods([\"fit\"])],\n        \"X\": [\"array-like\", \"sparse matrix\"],\n        \"y\": [\"array-like\", None],\n        \"groups\": [\"array-like\", None],\n        \"train_sizes\": [\"array-like\"],\n        \"cv\": [\"cv_object\"],\n        \"scoring\": [StrOptions(set(get_scorer_names())), callable, None],\n        \"exploit_incremental_learning\": [\"boolean\"],\n        \"n_jobs\": [Integral, None],\n        \"pre_dispatch\": [Integral, str],\n        \"verbose\": [\"verbose\"],\n        \"shuffle\": [\"boolean\"],\n      "}, {"start_line": 63000, "end_line": 65000, "belongs_to": {"file_name": "_validation.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/model_selection", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "timator = Bunch(fit=params)\n        routed_params.splitter = Bunch(split={\"groups\": groups})\n        routed_params.scorer = Bunch(score={})\n\n    # We clone the estimator to make sure that all the folds are\n    # independent, and that it is pickle-able.\n    score = _permutation_test_score(\n        clone(estimator),\n        X,\n        y,\n        cv,\n        scorer,\n        split_params=routed_params.splitter.split,\n        fit_params=routed_params.estimator.fit,\n        score_params=routed_params.scorer.score,\n    )\n    permutation_scores = Parallel(n_jobs=n_jobs, verbose=verbose)(\n        delayed(_permutation_test_score)(\n            clone(estimator),\n            X,\n            _shuffle(y, groups, random_state),\n            cv,\n            scorer,\n            split_params=routed_params.splitter.split,\n            fit_params=routed_params.estimator.fit,\n            score_params=routed_params.scorer.score,\n        )\n        for _ in range(n_permutations)\n    )\n    permutation_scores = np.array(permutation_scores)\n    pvalue = (np.sum(permutation_scores >= score) + 1.0) / (n_permutations + 1)\n    return score, permutation_scores, pvalue\n\n\ndef _permutation_test_score(\n    estimator, X, y, cv, scorer, split_params, fit_params, score_params\n):\n    \"\"\"Auxiliary function for permutation_test_score\"\"\"\n    # Adjust length of sample weights\n    fit_params = fit_params if fit_params is not None else {}\n    score_params = score_params if score_params is not None else {}\n\n    avg_score = []\n    for train, test in cv.split(X, y, **split_params):\n        X_train, y_train = _safe_split(estimator, X, y, train)\n        X_test, y_test = _safe_split(estimator, X, y, test, train)\n        fit_params_train = _check_method_params(X, params=fit_params, indices=train)\n        score_params_test = _check_method_params(X, params=score_params, indices=test)\n        estimator.fit(X_train, y_train, **fit_params_train)\n        avg_score.append(scorer(estimator, X_test, y_test, **score_params_test))\n "}, {"start_line": 5000, "end_line": 6999, "belongs_to": {"file_name": "_base.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/metrics", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "            Scores corresponding to the probability estimates\n                of a sample belonging to the designated positive class label\n\n    y_true : array-like of shape (n_samples,)\n        True multiclass labels.\n\n    y_score : array-like of shape (n_samples, n_classes)\n        Target scores corresponding to probability estimates of a sample\n        belonging to a particular class.\n\n    average : {'macro', 'weighted'}, default='macro'\n        Determines the type of averaging performed on the pairwise binary\n        metric scores:\n        ``'macro'``:\n            Calculate metrics for each label, and find their unweighted\n            mean. This does not take label imbalance into account. Classes\n            are assumed to be uniformly distributed.\n        ``'weighted'``:\n            Calculate metrics for each label, taking into account the\n            prevalence of the classes.\n\n    Returns\n    -------\n    score : float\n        Average of the pairwise binary metric scores.\n    \"\"\"\n    check_consistent_length(y_true, y_score)\n\n    y_true_unique = np.unique(y_true)\n    n_classes = y_true_unique.shape[0]\n    n_pairs = n_classes * (n_classes - 1) // 2\n    pair_scores = np.empty(n_pairs)\n\n    is_weighted = average == \"weighted\"\n    prevalence = np.empty(n_pairs) if is_weighted else None\n\n    # Compute scores treating a as positive class and b as negative class,\n    # then b as positive class and a as negative class\n    for ix, (a, b) in enumerate(combinations(y_true_unique, 2)):\n        a_mask = y_true == a\n        b_mask = y_true == b\n        ab_mask = np.logical_or(a_mask, b_mask)\n\n        if is_weighted:\n            prevalence[ix] = np.average(ab_mask)\n\n        a_true = a_mask[ab_mask]\n        b_true = b_mask[ab_mask]\n\n        a_true_score = binary_metric(a_true, y_score[ab_mask, a])\n        b_true_score = binary_metric(b_true, y_score[ab_mask, b])\n        pair_scores[ix] = (a_true_score + b_true_score) / 2\n\n    return np.average(pair_scores, weights=prevalence)\n"}], "retrieved_count": 10, "cost_time": 0.37233924865722656}
{"question": "Where does the solver selection logic in _BaseRidge.fit() determine which lower-level helper functions to invoke based on the combination of sparse data, intercept fitting, and solver parameters?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"start_line": 28000, "end_line": 30000, "belongs_to": {"file_name": "_ridge.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/linear_model", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "orts fitting intercept directly\n        return \"sag\"\n\n    if not is_sparse:\n        return \"cholesky\"\n\n    return \"sparse_cg\"\n\n\nclass _BaseRidge(LinearModel, metaclass=ABCMeta):\n    _parameter_constraints: dict = {\n        \"alpha\": [Interval(Real, 0, None, closed=\"left\"), np.ndarray],\n        \"fit_intercept\": [\"boolean\"],\n        \"copy_X\": [\"boolean\"],\n        \"max_iter\": [Interval(Integral, 1, None, closed=\"left\"), None],\n        \"tol\": [Interval(Real, 0, None, closed=\"left\")],\n        \"solver\": [\n            StrOptions(\n                {\"auto\", \"svd\", \"cholesky\", \"lsqr\", \"sparse_cg\", \"sag\", \"saga\", \"lbfgs\"}\n            )\n        ],\n        \"positive\": [\"boolean\"],\n        \"random_state\": [\"random_state\"],\n    }\n\n    @abstractmethod\n    def __init__(\n        self,\n        alpha=1.0,\n        *,\n        fit_intercept=True,\n        copy_X=True,\n        max_iter=None,\n        tol=1e-4,\n        solver=\"auto\",\n        positive=False,\n        random_state=None,\n    ):\n        self.alpha = alpha\n        self.fit_intercept = fit_intercept\n        self.copy_X = copy_X\n        self.max_iter = max_iter\n        self.tol = tol\n        self.solver = solver\n        self.positive = positive\n        self.random_state = random_state\n\n    def fit(self, X, y, sample_weight=None):\n        xp, is_array_api_compliant = get_namespace(X, y, sample_weight)\n\n        if self.solver == \"lbfgs\" and not self.positive:\n            raise ValueError(\n                \"'lbfgs' solver can be used only when positive=True. \"\n                \"Please use another solver.\"\n            )\n\n        if self.positive:\n            if self.solver not in [\"auto\", \"lbfgs\"]:\n                raise ValueError(\n                    f\"solver='{self.solver}' does not support positive fitting. Please\"\n                    \" set the solver to 'auto' or 'lbfgs', or set `positive=False`\"\n                )\n            else:\n                solver = self.solver\n        elif sparse.issparse(X) and self.fit_intercept:\n            if"}, {"start_line": 30000, "end_line": 32000, "belongs_to": {"file_name": "_ridge.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/linear_model", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": " self.solver not in [\"auto\", \"lbfgs\", \"lsqr\", \"sag\", \"sparse_cg\"]:\n                raise ValueError(\n                    \"solver='{}' does not support fitting the intercept \"\n                    \"on sparse data. Please set the solver to 'auto' or \"\n                    \"'lsqr', 'sparse_cg', 'sag', 'lbfgs' \"\n                    \"or set `fit_intercept=False`\".format(self.solver)\n                )\n            if self.solver in [\"lsqr\", \"lbfgs\"]:\n                solver = self.solver\n            elif self.solver == \"sag\" and self.max_iter is None and self.tol > 1e-4:\n                warnings.warn(\n                    '\"sag\" solver requires many iterations to fit '\n                    \"an intercept with sparse inputs. Either set the \"\n                    'solver to \"auto\" or \"sparse_cg\", or set a low '\n                    '\"tol\" and a high \"max_iter\" (especially if inputs are '\n                    \"not standardized).\"\n                )\n                solver = \"sag\"\n            else:\n                solver = \"sparse_cg\"\n        else:\n            solver = self.solver\n\n        if sample_weight is not None:\n            sample_weight = _check_sample_weight(sample_weight, X, dtype=X.dtype)\n\n        # when X is sparse we only remove offset from y\n        X, y, X_offset, y_offset, X_scale, _ = _preprocess_data(\n            X,\n            y,\n            fit_intercept=self.fit_intercept,\n            copy=self.copy_X,\n            sample_weight=sample_weight,\n            rescale_with_sw=False,\n        )\n\n        if solver == \"sag\" and sparse.issparse(X) and self.fit_intercept:\n            self.coef_, self.n_iter_, self.intercept_, self.solver_ = _ridge_regression(\n                X,\n                y,\n                alpha=self.alpha,\n                sample_weight=sample_weight,\n                max_iter=self.max_iter,\n                tol=self.tol,\n                solver=\"sag\",\n                positive=self.positive,\n                random_state=self.random_state,\n                retu"}, {"start_line": 26000, "end_line": 28000, "belongs_to": {"file_name": "_ridge.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/linear_model", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "        X_offset=X_offset,\n            X_scale=X_scale,\n            sample_weight_sqrt=sample_weight_sqrt if has_sw else None,\n        )\n\n    if solver == \"svd\":\n        if X_is_sparse:\n            raise TypeError(\"SVD solver does not support sparse inputs currently\")\n        coef = _solve_svd(X, y, alpha, xp)\n\n    if n_targets == 1:\n        coef = _ravel(coef)\n\n    coef = xp.asarray(coef)\n\n    if return_n_iter and return_intercept:\n        res = coef, n_iter, intercept\n    elif return_intercept:\n        res = coef, intercept\n    elif return_n_iter:\n        res = coef, n_iter\n    else:\n        res = coef\n\n    return (*res, solver) if return_solver else res\n\n\ndef resolve_solver(solver, positive, return_intercept, is_sparse, xp):\n    if solver != \"auto\":\n        return solver\n\n    is_numpy_namespace = _is_numpy_namespace(xp)\n\n    auto_solver_np = resolve_solver_for_numpy(positive, return_intercept, is_sparse)\n    if is_numpy_namespace:\n        return auto_solver_np\n\n    if positive:\n        raise ValueError(\n            \"The solvers that support positive fitting do not support \"\n            f\"Array API dispatch to namespace {xp.__name__}. Please \"\n            \"either disable Array API dispatch, or use a numpy-like \"\n            \"namespace, or set `positive=False`.\"\n        )\n\n    # At the moment, Array API dispatch only supports the \"svd\" solver.\n    solver = \"svd\"\n    if solver != auto_solver_np:\n        warnings.warn(\n            f\"Using Array API dispatch to namespace {xp.__name__} with \"\n            f\"`solver='auto'` will result in using the solver '{solver}'. \"\n            \"The results may differ from those when using a Numpy array, \"\n            f\"because in that case the preferred solver would be {auto_solver_np}. \"\n            f\"Set `solver='{solver}'` to suppress this warning.\"\n        )\n\n    return solver\n\n\ndef resolve_solver_for_numpy(positive, return_intercept, is_sparse):\n    if positive:\n        return \"lbfgs\"\n\n    if return_intercept:\n        # sag supp"}, {"start_line": 25000, "end_line": 27000, "belongs_to": {"file_name": "_ridge.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/linear_model", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": " {\n                \"coef\": np.zeros((n_features + int(return_intercept), 1), dtype=X.dtype)\n            }\n            coef_, n_iter_, _ = sag_solver(\n                X,\n                target.ravel(),\n                sample_weight,\n                \"squared\",\n                alpha_i,\n                0,\n                max_iter,\n                tol,\n                verbose,\n                random_state,\n                False,\n                max_squared_sum,\n                init,\n                is_saga=solver == \"saga\",\n            )\n            if return_intercept:\n                coef[i] = coef_[:-1]\n                intercept[i] = coef_[-1]\n            else:\n                coef[i] = coef_\n            n_iter[i] = n_iter_\n\n        if intercept.shape[0] == 1:\n            intercept = intercept[0]\n\n    elif solver == \"lbfgs\":\n        coef = _solve_lbfgs(\n            X,\n            y,\n            alpha,\n            positive=positive,\n            tol=tol,\n            max_iter=max_iter,\n            X_offset=X_offset,\n            X_scale=X_scale,\n            sample_weight_sqrt=sample_weight_sqrt if has_sw else None,\n        )\n\n    if solver == \"svd\":\n        if X_is_sparse:\n            raise TypeError(\"SVD solver does not support sparse inputs currently\")\n        coef = _solve_svd(X, y, alpha, xp)\n\n    if n_targets == 1:\n        coef = _ravel(coef)\n\n    coef = xp.asarray(coef)\n\n    if return_n_iter and return_intercept:\n        res = coef, n_iter, intercept\n    elif return_intercept:\n        res = coef, intercept\n    elif return_n_iter:\n        res = coef, n_iter\n    else:\n        res = coef\n\n    return (*res, solver) if return_solver else res\n\n\ndef resolve_solver(solver, positive, return_intercept, is_sparse, xp):\n    if solver != \"auto\":\n        return solver\n\n    is_numpy_namespace = _is_numpy_namespace(xp)\n\n    auto_solver_np = resolve_solver_for_numpy(positive, return_intercept, is_sparse)\n    if is_numpy_namespace:\n        return auto_solver_np\n\n    if positive:\n    "}, {"start_line": 27000, "end_line": 29000, "belongs_to": {"file_name": "_ridge.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/linear_model", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "    raise ValueError(\n            \"The solvers that support positive fitting do not support \"\n            f\"Array API dispatch to namespace {xp.__name__}. Please \"\n            \"either disable Array API dispatch, or use a numpy-like \"\n            \"namespace, or set `positive=False`.\"\n        )\n\n    # At the moment, Array API dispatch only supports the \"svd\" solver.\n    solver = \"svd\"\n    if solver != auto_solver_np:\n        warnings.warn(\n            f\"Using Array API dispatch to namespace {xp.__name__} with \"\n            f\"`solver='auto'` will result in using the solver '{solver}'. \"\n            \"The results may differ from those when using a Numpy array, \"\n            f\"because in that case the preferred solver would be {auto_solver_np}. \"\n            f\"Set `solver='{solver}'` to suppress this warning.\"\n        )\n\n    return solver\n\n\ndef resolve_solver_for_numpy(positive, return_intercept, is_sparse):\n    if positive:\n        return \"lbfgs\"\n\n    if return_intercept:\n        # sag supports fitting intercept directly\n        return \"sag\"\n\n    if not is_sparse:\n        return \"cholesky\"\n\n    return \"sparse_cg\"\n\n\nclass _BaseRidge(LinearModel, metaclass=ABCMeta):\n    _parameter_constraints: dict = {\n        \"alpha\": [Interval(Real, 0, None, closed=\"left\"), np.ndarray],\n        \"fit_intercept\": [\"boolean\"],\n        \"copy_X\": [\"boolean\"],\n        \"max_iter\": [Interval(Integral, 1, None, closed=\"left\"), None],\n        \"tol\": [Interval(Real, 0, None, closed=\"left\")],\n        \"solver\": [\n            StrOptions(\n                {\"auto\", \"svd\", \"cholesky\", \"lsqr\", \"sparse_cg\", \"sag\", \"saga\", \"lbfgs\"}\n            )\n        ],\n        \"positive\": [\"boolean\"],\n        \"random_state\": [\"random_state\"],\n    }\n\n    @abstractmethod\n    def __init__(\n        self,\n        alpha=1.0,\n        *,\n        fit_intercept=True,\n        copy_X=True,\n        max_iter=None,\n        tol=1e-4,\n        solver=\"auto\",\n        positive=False,\n        random_state=None,\n    ):\n        self.alpha = al"}, {"start_line": 31000, "end_line": 33000, "belongs_to": {"file_name": "_ridge.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/linear_model", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "        solver = \"sparse_cg\"\n        else:\n            solver = self.solver\n\n        if sample_weight is not None:\n            sample_weight = _check_sample_weight(sample_weight, X, dtype=X.dtype)\n\n        # when X is sparse we only remove offset from y\n        X, y, X_offset, y_offset, X_scale, _ = _preprocess_data(\n            X,\n            y,\n            fit_intercept=self.fit_intercept,\n            copy=self.copy_X,\n            sample_weight=sample_weight,\n            rescale_with_sw=False,\n        )\n\n        if solver == \"sag\" and sparse.issparse(X) and self.fit_intercept:\n            self.coef_, self.n_iter_, self.intercept_, self.solver_ = _ridge_regression(\n                X,\n                y,\n                alpha=self.alpha,\n                sample_weight=sample_weight,\n                max_iter=self.max_iter,\n                tol=self.tol,\n                solver=\"sag\",\n                positive=self.positive,\n                random_state=self.random_state,\n                return_n_iter=True,\n                return_intercept=True,\n                return_solver=True,\n                check_input=False,\n            )\n            # add the offset which was subtracted by _preprocess_data\n            self.intercept_ += y_offset\n\n        else:\n            if sparse.issparse(X) and self.fit_intercept:\n                # required to fit intercept with sparse_cg and lbfgs solver\n                params = {\"X_offset\": X_offset, \"X_scale\": X_scale}\n            else:\n                # for dense matrices or when intercept is set to 0\n                params = {}\n\n            self.coef_, self.n_iter_, self.solver_ = _ridge_regression(\n                X,\n                y,\n                alpha=self.alpha,\n                sample_weight=sample_weight,\n                max_iter=self.max_iter,\n                tol=self.tol,\n                solver=solver,\n                positive=self.positive,\n                random_state=self.random_state,\n                return_n_iter=True,\n     "}, {"start_line": 22000, "end_line": 24000, "belongs_to": {"file_name": "_ridge.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/linear_model", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "   % (n_samples, n_samples_)\n        )\n\n    if has_sw:\n        sample_weight = _check_sample_weight(sample_weight, X, dtype=X.dtype)\n\n        if solver not in [\"sag\", \"saga\"]:\n            # SAG supports sample_weight directly. For other solvers,\n            # we implement sample_weight via a simple rescaling.\n            X, y, sample_weight_sqrt = _rescale_data(X, y, sample_weight)\n\n    # Some callers of this method might pass alpha as single\n    # element array which already has been validated.\n    if alpha is not None and not isinstance(alpha, type(xp.asarray([0.0]))):\n        alpha = check_scalar(\n            alpha,\n            \"alpha\",\n            target_type=numbers.Real,\n            min_val=0.0,\n            include_boundaries=\"left\",\n        )\n\n    # There should be either 1 or n_targets penalties\n    alpha = _ravel(xp.asarray(alpha, device=device_, dtype=X.dtype), xp=xp)\n    if alpha.shape[0] not in [1, n_targets]:\n        raise ValueError(\n            \"Number of targets and number of penalties do not correspond: %d != %d\"\n            % (alpha.shape[0], n_targets)\n        )\n\n    if alpha.shape[0] == 1 and n_targets > 1:\n        alpha = xp.full(\n            shape=(n_targets,), fill_value=alpha[0], dtype=alpha.dtype, device=device_\n        )\n\n    n_iter = None\n    if solver == \"sparse_cg\":\n        coef = _solve_sparse_cg(\n            X,\n            y,\n            alpha,\n            max_iter=max_iter,\n            tol=tol,\n            verbose=verbose,\n            X_offset=X_offset,\n            X_scale=X_scale,\n            sample_weight_sqrt=sample_weight_sqrt if has_sw else None,\n        )\n\n    elif solver == \"lsqr\":\n        coef, n_iter = _solve_lsqr(\n            X,\n            y,\n            alpha=alpha,\n            fit_intercept=fit_intercept,\n            max_iter=max_iter,\n            tol=tol,\n            X_offset=X_offset,\n            X_scale=X_scale,\n            sample_weight_sqrt=sample_weight_sqrt if has_sw else None,\n        )\n\n    elif solver == \"choles"}, {"start_line": 23000, "end_line": 25000, "belongs_to": {"file_name": "_ridge.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/linear_model", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "ber of penalties do not correspond: %d != %d\"\n            % (alpha.shape[0], n_targets)\n        )\n\n    if alpha.shape[0] == 1 and n_targets > 1:\n        alpha = xp.full(\n            shape=(n_targets,), fill_value=alpha[0], dtype=alpha.dtype, device=device_\n        )\n\n    n_iter = None\n    if solver == \"sparse_cg\":\n        coef = _solve_sparse_cg(\n            X,\n            y,\n            alpha,\n            max_iter=max_iter,\n            tol=tol,\n            verbose=verbose,\n            X_offset=X_offset,\n            X_scale=X_scale,\n            sample_weight_sqrt=sample_weight_sqrt if has_sw else None,\n        )\n\n    elif solver == \"lsqr\":\n        coef, n_iter = _solve_lsqr(\n            X,\n            y,\n            alpha=alpha,\n            fit_intercept=fit_intercept,\n            max_iter=max_iter,\n            tol=tol,\n            X_offset=X_offset,\n            X_scale=X_scale,\n            sample_weight_sqrt=sample_weight_sqrt if has_sw else None,\n        )\n\n    elif solver == \"cholesky\":\n        if n_features > n_samples:\n            K = safe_sparse_dot(X, X.T, dense_output=True)\n            try:\n                dual_coef = _solve_cholesky_kernel(K, y, alpha)\n\n                coef = safe_sparse_dot(X.T, dual_coef, dense_output=True).T\n            except linalg.LinAlgError:\n                # use SVD solver if matrix is singular\n                solver = \"svd\"\n        else:\n            try:\n                coef = _solve_cholesky(X, y, alpha)\n            except linalg.LinAlgError:\n                # use SVD solver if matrix is singular\n                solver = \"svd\"\n\n    elif solver in [\"sag\", \"saga\"]:\n        # precompute max_squared_sum for all targets\n        max_squared_sum = row_norms(X, squared=True).max()\n\n        coef = np.empty((y.shape[1], n_features), dtype=X.dtype)\n        n_iter = np.empty(y.shape[1], dtype=np.int32)\n        intercept = np.zeros((y.shape[1],), dtype=X.dtype)\n        for i, (alpha_i, target) in enumerate(zip(alpha, y.T)):\n            init ="}, {"start_line": 20000, "end_line": 22000, "belongs_to": {"file_name": "_ridge.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/linear_model", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "    fit_intercept=False,\n):\n    xp, is_array_api_compliant, device_ = get_namespace_and_device(\n        X, y, sample_weight, X_scale, X_offset\n    )\n    is_numpy_namespace = _is_numpy_namespace(xp)\n    X_is_sparse = sparse.issparse(X)\n\n    has_sw = sample_weight is not None\n\n    solver = resolve_solver(solver, positive, return_intercept, X_is_sparse, xp)\n\n    if is_numpy_namespace and not X_is_sparse:\n        X = np.asarray(X)\n\n    if not is_numpy_namespace and solver != \"svd\":\n        raise ValueError(\n            f\"Array API dispatch to namespace {xp.__name__} only supports \"\n            f\"solver 'svd'. Got '{solver}'.\"\n        )\n\n    if positive and solver != \"lbfgs\":\n        raise ValueError(\n            \"When positive=True, only 'lbfgs' solver can be used. \"\n            f\"Please change solver {solver} to 'lbfgs' \"\n            \"or set positive=False.\"\n        )\n\n    if solver == \"lbfgs\" and not positive:\n        raise ValueError(\n            \"'lbfgs' solver can be used only when positive=True. \"\n            \"Please use another solver.\"\n        )\n\n    if return_intercept and solver != \"sag\":\n        raise ValueError(\n            \"In Ridge, only 'sag' solver can directly fit the \"\n            \"intercept. Please change solver to 'sag' or set \"\n            \"return_intercept=False.\"\n        )\n\n    if check_input:\n        _dtype = [xp.float64, xp.float32]\n        _accept_sparse = _get_valid_accept_sparse(X_is_sparse, solver)\n        X = check_array(X, accept_sparse=_accept_sparse, dtype=_dtype, order=\"C\")\n        y = check_array(y, dtype=X.dtype, ensure_2d=False, order=None)\n    check_consistent_length(X, y)\n\n    n_samples, n_features = X.shape\n\n    if y.ndim > 2:\n        raise ValueError(\"Target y has the wrong shape %s\" % str(y.shape))\n\n    if y.ndim == 1:\n        y = xp.reshape(y, (-1, 1))\n\n    n_samples_, n_targets = y.shape\n\n    if n_samples != n_samples_:\n        raise ValueError(\n            \"Number of samples in X and y does not correspond: %d != %d\"\n         "}, {"start_line": 3000, "end_line": 5000, "belongs_to": {"file_name": "_ridge.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/linear_model", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "  return X1.rmatvec(X1.matvec(x)) + curr_alpha * x\n\n            return _mv\n\n    for i in range(y.shape[1]):\n        y_column = y[:, i]\n\n        mv = create_mv(alpha[i])\n        if n_features > n_samples:\n            # kernel ridge\n            # w = X.T * inv(X X^t + alpha*Id) y\n            C = sp_linalg.LinearOperator(\n                (n_samples, n_samples), matvec=mv, dtype=X.dtype\n            )\n            coef, info = _sparse_linalg_cg(C, y_column, rtol=tol)\n            coefs[i] = X1.rmatvec(coef)\n        else:\n            # linear ridge\n            # w = inv(X^t X + alpha*Id) * X.T y\n            y_column = X1.rmatvec(y_column)\n            C = sp_linalg.LinearOperator(\n                (n_features, n_features), matvec=mv, dtype=X.dtype\n            )\n            coefs[i], info = _sparse_linalg_cg(C, y_column, maxiter=max_iter, rtol=tol)\n\n        if info < 0:\n            raise ValueError(\"Failed with error code %d\" % info)\n\n        if max_iter is None and info > 0 and verbose:\n            warnings.warn(\n                \"sparse_cg did not converge after %d iterations.\" % info,\n                ConvergenceWarning,\n            )\n\n    return coefs\n\n\ndef _solve_lsqr(\n    X,\n    y,\n    *,\n    alpha,\n    fit_intercept=True,\n    max_iter=None,\n    tol=1e-4,\n    X_offset=None,\n    X_scale=None,\n    sample_weight_sqrt=None,\n):\n    \"\"\"Solve Ridge regression via LSQR.\n\n    We expect that y is always mean centered.\n    If X is dense, we expect it to be mean centered such that we can solve\n        ||y - Xw||_2^2 + alpha * ||w||_2^2\n\n    If X is sparse, we expect X_offset to be given such that we can solve\n        ||y - (X - X_offset)w||_2^2 + alpha * ||w||_2^2\n\n    With sample weights S=diag(sample_weight), this becomes\n        ||sqrt(S) (y - (X - X_offset) w)||_2^2 + alpha * ||w||_2^2\n    and we expect y and X to already be rescaled, i.e. sqrt(S) @ y, sqrt(S) @ X. In\n    this case, X_offset is the sample_weight weighted mean of X before scaling by\n    sqrt(S). The objective then "}], "retrieved_count": 10, "cost_time": 0.3682727813720703}
{"question": "Where in the codebase are the lower-level helper functions that _SetOutputMixin delegates to in order to wrap the tuple output returned by EstimatorReturnTuple's transform method?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"start_line": 9000, "end_line": 11000, "belongs_to": {"file_name": "_set_output.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/utils", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "lt\" or not _auto_wrap_is_configured(estimator):\n        return data_to_wrap\n\n    dense_config = output_config[\"dense\"]\n    if issparse(data_to_wrap):\n        raise ValueError(\n            \"The transformer outputs a scipy sparse matrix. \"\n            \"Try to set the transformer output to a dense array or disable \"\n            f\"{dense_config.capitalize()} output with set_output(transform='default').\"\n        )\n\n    adapter = ADAPTERS_MANAGER.adapters[dense_config]\n    return adapter.create_container(\n        data_to_wrap,\n        original_input,\n        columns=estimator.get_feature_names_out,\n    )\n\n\ndef _wrap_method_output(f, method):\n    \"\"\"Wrapper used by `_SetOutputMixin` to automatically wrap methods.\"\"\"\n\n    @wraps(f)\n    def wrapped(self, X, *args, **kwargs):\n        data_to_wrap = f(self, X, *args, **kwargs)\n        if isinstance(data_to_wrap, tuple):\n            # only wrap the first output for cross decomposition\n            return_tuple = (\n                _wrap_data_with_container(method, data_to_wrap[0], X, self),\n                *data_to_wrap[1:],\n            )\n            # Support for namedtuples `_make` is a documented API for namedtuples:\n            # https://docs.python.org/3/library/collections.html#collections.somenamedtuple._make\n            if hasattr(type(data_to_wrap), \"_make\"):\n                return type(data_to_wrap)._make(return_tuple)\n            return return_tuple\n\n        return _wrap_data_with_container(method, data_to_wrap, X, self)\n\n    return wrapped\n\n\ndef _auto_wrap_is_configured(estimator):\n    \"\"\"Return True if estimator is configured for auto-wrapping the transform method.\n\n    `_SetOutputMixin` sets `_sklearn_auto_wrap_output_keys` to `set()` if auto wrapping\n    is manually disabled.\n    \"\"\"\n    auto_wrap_output_keys = getattr(estimator, \"_sklearn_auto_wrap_output_keys\", set())\n    return (\n        hasattr(estimator, \"get_feature_names_out\")\n        and \"transform\" in auto_wrap_output_keys\n    )\n\n\nclass _SetOutputMixin:\n  "}, {"start_line": 10000, "end_line": 12000, "belongs_to": {"file_name": "_set_output.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/utils", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "ntainer(method, data_to_wrap[0], X, self),\n                *data_to_wrap[1:],\n            )\n            # Support for namedtuples `_make` is a documented API for namedtuples:\n            # https://docs.python.org/3/library/collections.html#collections.somenamedtuple._make\n            if hasattr(type(data_to_wrap), \"_make\"):\n                return type(data_to_wrap)._make(return_tuple)\n            return return_tuple\n\n        return _wrap_data_with_container(method, data_to_wrap, X, self)\n\n    return wrapped\n\n\ndef _auto_wrap_is_configured(estimator):\n    \"\"\"Return True if estimator is configured for auto-wrapping the transform method.\n\n    `_SetOutputMixin` sets `_sklearn_auto_wrap_output_keys` to `set()` if auto wrapping\n    is manually disabled.\n    \"\"\"\n    auto_wrap_output_keys = getattr(estimator, \"_sklearn_auto_wrap_output_keys\", set())\n    return (\n        hasattr(estimator, \"get_feature_names_out\")\n        and \"transform\" in auto_wrap_output_keys\n    )\n\n\nclass _SetOutputMixin:\n    \"\"\"Mixin that dynamically wraps methods to return container based on config.\n\n    Currently `_SetOutputMixin` wraps `transform` and `fit_transform` and configures\n    it based on `set_output` of the global configuration.\n\n    `set_output` is only defined if `get_feature_names_out` is defined and\n    `auto_wrap_output_keys` is the default value.\n    \"\"\"\n\n    def __init_subclass__(cls, auto_wrap_output_keys=(\"transform\",), **kwargs):\n        super().__init_subclass__(**kwargs)\n\n        # Dynamically wraps `transform` and `fit_transform` and configure it's\n        # output based on `set_output`.\n        if not (\n            isinstance(auto_wrap_output_keys, tuple) or auto_wrap_output_keys is None\n        ):\n            raise ValueError(\"auto_wrap_output_keys must be None or a tuple of keys.\")\n\n        if auto_wrap_output_keys is None:\n            cls._sklearn_auto_wrap_output_keys = set()\n            return\n\n        # Mapping from method to key in configurations\n        method_to_key = "}, {"start_line": 8000, "end_line": 10000, "belongs_to": {"file_name": "_set_output.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/utils", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "orted_outputs)}, got {dense_config}\"\n        )\n\n    return {\"dense\": dense_config}\n\n\ndef _wrap_data_with_container(method, data_to_wrap, original_input, estimator):\n    \"\"\"Wrap output with container based on an estimator's or global config.\n\n    Parameters\n    ----------\n    method : {\"transform\"}\n        Estimator's method to get container output for.\n\n    data_to_wrap : {ndarray, dataframe}\n        Data to wrap with container.\n\n    original_input : {ndarray, dataframe}\n        Original input of function.\n\n    estimator : estimator instance\n        Estimator with to get the output configuration from.\n\n    Returns\n    -------\n    output : {ndarray, dataframe}\n        If the output config is \"default\" or the estimator is not configured\n        for wrapping return `data_to_wrap` unchanged.\n        If the output config is \"pandas\", return `data_to_wrap` as a pandas\n        DataFrame.\n    \"\"\"\n    output_config = _get_output_config(method, estimator)\n\n    if output_config[\"dense\"] == \"default\" or not _auto_wrap_is_configured(estimator):\n        return data_to_wrap\n\n    dense_config = output_config[\"dense\"]\n    if issparse(data_to_wrap):\n        raise ValueError(\n            \"The transformer outputs a scipy sparse matrix. \"\n            \"Try to set the transformer output to a dense array or disable \"\n            f\"{dense_config.capitalize()} output with set_output(transform='default').\"\n        )\n\n    adapter = ADAPTERS_MANAGER.adapters[dense_config]\n    return adapter.create_container(\n        data_to_wrap,\n        original_input,\n        columns=estimator.get_feature_names_out,\n    )\n\n\ndef _wrap_method_output(f, method):\n    \"\"\"Wrapper used by `_SetOutputMixin` to automatically wrap methods.\"\"\"\n\n    @wraps(f)\n    def wrapped(self, X, *args, **kwargs):\n        data_to_wrap = f(self, X, *args, **kwargs)\n        if isinstance(data_to_wrap, tuple):\n            # only wrap the first output for cross decomposition\n            return_tuple = (\n                _wrap_data_with_co"}, {"start_line": 14000, "end_line": 16000, "belongs_to": {"file_name": "_column_transformer.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/compose", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "      \"\"\"\n        Internal list of transformer only containing the name and\n        transformers, dropping the columns.\n\n        DO NOT USE: This is for the implementation of get_params via\n        BaseComposition._get_params which expects lists of tuples of len 2.\n\n        To iterate through the transformers, use ``self._iter`` instead.\n        \"\"\"\n        try:\n            return [(name, trans) for name, trans, _ in self.transformers]\n        except (TypeError, ValueError):\n            return self.transformers\n\n    @_transformers.setter\n    def _transformers(self, value):\n        \"\"\"DO NOT USE: This is for the implementation of set_params via\n        BaseComposition._get_params which gives lists of tuples of len 2.\n        \"\"\"\n        try:\n            self.transformers = [\n                (name, trans, col)\n                for ((name, trans), (_, _, col)) in zip(value, self.transformers)\n            ]\n        except (TypeError, ValueError):\n            self.transformers = value\n\n    def set_output(self, *, transform=None):\n        \"\"\"Set the output container when `\"transform\"` and `\"fit_transform\"` are called.\n\n        Calling `set_output` will set the output of all estimators in `transformers`\n        and `transformers_`.\n\n        Parameters\n        ----------\n        transform : {\"default\", \"pandas\", \"polars\"}, default=None\n            Configure output of `transform` and `fit_transform`.\n\n            - `\"default\"`: Default output format of a transformer\n            - `\"pandas\"`: DataFrame output\n            - `\"polars\"`: Polars output\n            - `None`: Transform configuration is unchanged\n\n            .. versionadded:: 1.4\n                `\"polars\"` option was added.\n\n        Returns\n        -------\n        self : estimator instance\n            Estimator instance.\n        \"\"\"\n        super().set_output(transform=transform)\n\n        transformers = (\n            trans\n            for _, trans, _ in chain(\n                self.transformers, getattr(self, \"transf"}, {"start_line": 12000, "end_line": 14000, "belongs_to": {"file_name": "_set_output.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/utils", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "{\n            \"transform\": \"transform\",\n            \"fit_transform\": \"transform\",\n        }\n        cls._sklearn_auto_wrap_output_keys = set()\n\n        for method, key in method_to_key.items():\n            if not hasattr(cls, method) or key not in auto_wrap_output_keys:\n                continue\n            cls._sklearn_auto_wrap_output_keys.add(key)\n\n            # Only wrap methods defined by cls itself\n            if method not in cls.__dict__:\n                continue\n            wrapped_method = _wrap_method_output(getattr(cls, method), key)\n            setattr(cls, method, wrapped_method)\n\n    @available_if(_auto_wrap_is_configured)\n    def set_output(self, *, transform=None):\n        \"\"\"Set output container.\n\n        See :ref:`sphx_glr_auto_examples_miscellaneous_plot_set_output.py`\n        for an example on how to use the API.\n\n        Parameters\n        ----------\n        transform : {\"default\", \"pandas\", \"polars\"}, default=None\n            Configure output of `transform` and `fit_transform`.\n\n            - `\"default\"`: Default output format of a transformer\n            - `\"pandas\"`: DataFrame output\n            - `\"polars\"`: Polars output\n            - `None`: Transform configuration is unchanged\n\n            .. versionadded:: 1.4\n                `\"polars\"` option was added.\n\n        Returns\n        -------\n        self : estimator instance\n            Estimator instance.\n        \"\"\"\n        if transform is None:\n            return self\n\n        if not hasattr(self, \"_sklearn_output_config\"):\n            self._sklearn_output_config = {}\n\n        self._sklearn_output_config[\"transform\"] = transform\n        return self\n\n\ndef _safe_set_output(estimator, *, transform=None):\n    \"\"\"Safely call estimator.set_output and error if it not available.\n\n    This is used by meta-estimators to set the output for child estimators.\n\n    Parameters\n    ----------\n    estimator : estimator instance\n        Estimator instance.\n\n    transform : {\"default\", \"pandas\", \"polars\"}, d"}, {"start_line": 10000, "end_line": 12000, "belongs_to": {"file_name": "test_set_output.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/utils/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "d\n        config = _get_output_config(\"transform\")\n        assert config[\"dense\"] == transform_output\n\n        est = EstimatorNoSetOutputWithTransform()\n        config = _get_output_config(\"transform\", est)\n        assert config[\"dense\"] == transform_output\n\n        est = EstimatorWithSetOutput()\n        # If estimator has not config, use global config\n        config = _get_output_config(\"transform\", est)\n        assert config[\"dense\"] == transform_output\n\n        # If estimator has a config, use local config\n        est.set_output(transform=\"default\")\n        config = _get_output_config(\"transform\", est)\n        assert config[\"dense\"] == \"default\"\n\n    est.set_output(transform=transform_output)\n    config = _get_output_config(\"transform\", est)\n    assert config[\"dense\"] == transform_output\n\n\nclass EstimatorWithSetOutputNoAutoWrap(_SetOutputMixin, auto_wrap_output_keys=None):\n    def transform(self, X, y=None):\n        return X\n\n\ndef test_get_output_auto_wrap_false():\n    \"\"\"Check that auto_wrap_output_keys=None does not wrap.\"\"\"\n    est = EstimatorWithSetOutputNoAutoWrap()\n    assert not hasattr(est, \"set_output\")\n\n    X = np.asarray([[1, 0, 3], [0, 0, 1]])\n    assert X is est.transform(X)\n\n\ndef test_auto_wrap_output_keys_errors_with_incorrect_input():\n    msg = \"auto_wrap_output_keys must be None or a tuple of keys.\"\n    with pytest.raises(ValueError, match=msg):\n\n        class BadEstimator(_SetOutputMixin, auto_wrap_output_keys=\"bad_parameter\"):\n            pass\n\n\nclass AnotherMixin:\n    def __init_subclass__(cls, custom_parameter, **kwargs):\n        super().__init_subclass__(**kwargs)\n        cls.custom_parameter = custom_parameter\n\n\ndef test_set_output_mixin_custom_mixin():\n    \"\"\"Check that multiple init_subclasses passes parameters up.\"\"\"\n\n    class BothMixinEstimator(_SetOutputMixin, AnotherMixin, custom_parameter=123):\n        def transform(self, X, y=None):\n            return X\n\n        def get_feature_names_out(self, input_features=None):\n            retu"}, {"start_line": 11000, "end_line": 13000, "belongs_to": {"file_name": "_set_output.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/utils", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "  \"\"\"Mixin that dynamically wraps methods to return container based on config.\n\n    Currently `_SetOutputMixin` wraps `transform` and `fit_transform` and configures\n    it based on `set_output` of the global configuration.\n\n    `set_output` is only defined if `get_feature_names_out` is defined and\n    `auto_wrap_output_keys` is the default value.\n    \"\"\"\n\n    def __init_subclass__(cls, auto_wrap_output_keys=(\"transform\",), **kwargs):\n        super().__init_subclass__(**kwargs)\n\n        # Dynamically wraps `transform` and `fit_transform` and configure it's\n        # output based on `set_output`.\n        if not (\n            isinstance(auto_wrap_output_keys, tuple) or auto_wrap_output_keys is None\n        ):\n            raise ValueError(\"auto_wrap_output_keys must be None or a tuple of keys.\")\n\n        if auto_wrap_output_keys is None:\n            cls._sklearn_auto_wrap_output_keys = set()\n            return\n\n        # Mapping from method to key in configurations\n        method_to_key = {\n            \"transform\": \"transform\",\n            \"fit_transform\": \"transform\",\n        }\n        cls._sklearn_auto_wrap_output_keys = set()\n\n        for method, key in method_to_key.items():\n            if not hasattr(cls, method) or key not in auto_wrap_output_keys:\n                continue\n            cls._sklearn_auto_wrap_output_keys.add(key)\n\n            # Only wrap methods defined by cls itself\n            if method not in cls.__dict__:\n                continue\n            wrapped_method = _wrap_method_output(getattr(cls, method), key)\n            setattr(cls, method, wrapped_method)\n\n    @available_if(_auto_wrap_is_configured)\n    def set_output(self, *, transform=None):\n        \"\"\"Set output container.\n\n        See :ref:`sphx_glr_auto_examples_miscellaneous_plot_set_output.py`\n        for an example on how to use the API.\n\n        Parameters\n        ----------\n        transform : {\"default\", \"pandas\", \"polars\"}, default=None\n            Configure output of `transform` and `f"}, {"start_line": 13000, "end_line": 15000, "belongs_to": {"file_name": "test_set_output.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/utils/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "(self.n_features_in_)], dtype=object)\n\n\ndef test_set_output_pandas_keep_index():\n    \"\"\"Check that set_output does not override index.\n\n    Non-regression test for gh-25730.\n    \"\"\"\n    pd = pytest.importorskip(\"pandas\")\n\n    X = pd.DataFrame([[1, 2, 3], [4, 5, 6]], index=[0, 1])\n    est = EstimatorWithSetOutputIndex().set_output(transform=\"pandas\")\n    est.fit(X)\n\n    X_trans = est.transform(X)\n    assert_array_equal(X_trans.index, [\"s0\", \"s1\"])\n\n\nclass EstimatorReturnTuple(_SetOutputMixin):\n    def __init__(self, OutputTuple):\n        self.OutputTuple = OutputTuple\n\n    def transform(self, X, y=None):\n        return self.OutputTuple(X, 2 * X)\n\n\ndef test_set_output_named_tuple_out():\n    \"\"\"Check that namedtuples are kept by default.\"\"\"\n    Output = namedtuple(\"Output\", \"X, Y\")\n    X = np.asarray([[1, 2, 3]])\n    est = EstimatorReturnTuple(OutputTuple=Output)\n    X_trans = est.transform(X)\n\n    assert isinstance(X_trans, Output)\n    assert_array_equal(X_trans.X, X)\n    assert_array_equal(X_trans.Y, 2 * X)\n\n\nclass EstimatorWithListInput(_SetOutputMixin):\n    def fit(self, X, y=None):\n        assert isinstance(X, list)\n        self.n_features_in_ = len(X[0])\n        return self\n\n    def transform(self, X, y=None):\n        return X\n\n    def get_feature_names_out(self, input_features=None):\n        return np.asarray([f\"X{i}\" for i in range(self.n_features_in_)], dtype=object)\n\n\n@pytest.mark.parametrize(\"dataframe_lib\", [\"pandas\", \"polars\"])\ndef test_set_output_list_input(dataframe_lib):\n    \"\"\"Check set_output for list input.\n\n    Non-regression test for #27037.\n    \"\"\"\n    lib = pytest.importorskip(dataframe_lib)\n\n    X = [[0, 1, 2, 3], [4, 5, 6, 7]]\n    est = EstimatorWithListInput()\n    est.set_output(transform=dataframe_lib)\n\n    X_out = est.fit(X).transform(X)\n    assert isinstance(X_out, lib.DataFrame)\n    assert_array_equal(X_out.columns, [\"X0\", \"X1\", \"X2\", \"X3\"])\n\n\n@pytest.mark.parametrize(\"name\", sorted(ADAPTERS_MANAGER.adapters))\ndef test_adapter_class_has_in"}, {"start_line": 7000, "end_line": 9000, "belongs_to": {"file_name": "test_set_output.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/utils/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "ng set_output for transform.\n    est = EstimatorWithoutSetOutputAndWithoutTransform()\n    _safe_set_output(est, transform=\"pandas\")\n\n    # Estimator with transform but without set_output will raise\n    est = EstimatorNoSetOutputWithTransform()\n    with pytest.raises(ValueError, match=\"Unable to configure output\"):\n        _safe_set_output(est, transform=\"pandas\")\n\n    est = EstimatorWithSetOutput().fit(np.asarray([[1, 2, 3]]))\n    _safe_set_output(est, transform=\"pandas\")\n    config = _get_output_config(\"transform\", est)\n    assert config[\"dense\"] == \"pandas\"\n\n    _safe_set_output(est, transform=\"default\")\n    config = _get_output_config(\"transform\", est)\n    assert config[\"dense\"] == \"default\"\n\n    # transform is None is a no-op, so the config remains \"default\"\n    _safe_set_output(est, transform=None)\n    config = _get_output_config(\"transform\", est)\n    assert config[\"dense\"] == \"default\"\n\n\nclass EstimatorNoSetOutputWithTransformNoFeatureNamesOut(_SetOutputMixin):\n    def transform(self, X, y=None):\n        return X  # pragma: no cover\n\n\ndef test_set_output_mixin():\n    \"\"\"Estimator without get_feature_names_out does not define `set_output`.\"\"\"\n    est = EstimatorNoSetOutputWithTransformNoFeatureNamesOut()\n    assert not hasattr(est, \"set_output\")\n\n\ndef test__safe_set_output_error():\n    \"\"\"Check transform with invalid config.\"\"\"\n    X = np.asarray([[1, 0, 3], [0, 0, 1]])\n\n    est = EstimatorWithSetOutput()\n    _safe_set_output(est, transform=\"bad\")\n\n    msg = \"output config must be in\"\n    with pytest.raises(ValueError, match=msg):\n        est.transform(X)\n\n\n@pytest.mark.parametrize(\"dataframe_lib\", [\"pandas\", \"polars\"])\ndef test_set_output_method(dataframe_lib):\n    \"\"\"Check that the output is a dataframe.\"\"\"\n    lib = pytest.importorskip(dataframe_lib)\n\n    X = np.asarray([[1, 0, 3], [0, 0, 1]])\n    est = EstimatorWithSetOutput().fit(X)\n\n    # transform=None is a no-op\n    est2 = est.set_output(transform=None)\n    assert est2 is est\n    X_trans_np = est2.trans"}, {"start_line": 6000, "end_line": 8000, "belongs_to": {"file_name": "test_set_output.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/utils/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "a_with_container.\"\"\"\n    X = np.asarray([[1, 0, 3], [0, 0, 1]])\n    X_csr = csr_container(X)\n    match = \"The transformer outputs a scipy sparse matrix.\"\n    with config_context(transform_output=\"pandas\"):\n        with pytest.raises(ValueError, match=match):\n            _wrap_data_with_container(\"transform\", X_csr, X, StandardScaler())\n\n\nclass EstimatorWithoutSetOutputAndWithoutTransform:\n    pass\n\n\nclass EstimatorNoSetOutputWithTransform:\n    def transform(self, X, y=None):\n        return X  # pragma: no cover\n\n\nclass EstimatorWithSetOutput(_SetOutputMixin):\n    def fit(self, X, y=None):\n        self.n_features_in_ = X.shape[1]\n        return self\n\n    def transform(self, X, y=None):\n        return X\n\n    def get_feature_names_out(self, input_features=None):\n        return np.asarray([f\"X{i}\" for i in range(self.n_features_in_)], dtype=object)\n\n\ndef test__safe_set_output():\n    \"\"\"Check _safe_set_output works as expected.\"\"\"\n\n    # Estimator without transform will not raise when setting set_output for transform.\n    est = EstimatorWithoutSetOutputAndWithoutTransform()\n    _safe_set_output(est, transform=\"pandas\")\n\n    # Estimator with transform but without set_output will raise\n    est = EstimatorNoSetOutputWithTransform()\n    with pytest.raises(ValueError, match=\"Unable to configure output\"):\n        _safe_set_output(est, transform=\"pandas\")\n\n    est = EstimatorWithSetOutput().fit(np.asarray([[1, 2, 3]]))\n    _safe_set_output(est, transform=\"pandas\")\n    config = _get_output_config(\"transform\", est)\n    assert config[\"dense\"] == \"pandas\"\n\n    _safe_set_output(est, transform=\"default\")\n    config = _get_output_config(\"transform\", est)\n    assert config[\"dense\"] == \"default\"\n\n    # transform is None is a no-op, so the config remains \"default\"\n    _safe_set_output(est, transform=None)\n    config = _get_output_config(\"transform\", est)\n    assert config[\"dense\"] == \"default\"\n\n\nclass EstimatorNoSetOutputWithTransformNoFeatureNamesOut(_SetOutputMixin):\n    def transform("}], "retrieved_count": 10, "cost_time": 0.3706982135772705}
{"question": "Where does the control flow in _NotAnArray.__array_function__ determine whether a TypeError is raised versus a boolean value returned, and what is the data dependency between the func parameter's __name__ attribute and the exception handling path?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"start_line": 30000, "end_line": 31586, "belongs_to": {"file_name": "_helpers.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/externals/array_api_compat/common", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": " res\n\n    if not hasattr(x, \"__array_namespace__\"):\n        return False\n\n    # Unknown Array API compatible object. Note that this test may have dire consequences\n    # in terms of performance, e.g. for a lazy object that eagerly computes the graph\n    # on __bool__ (dask is one such example, which however is special-cased above).\n\n    # Select a single point of the array\n    s = size(cast(\"HasShape[Collection[SupportsIndex | None]]\", x))\n    if s is None:\n        return True\n    xp = array_namespace(x)\n    if s > 1:\n        x = xp.reshape(x, (-1,))[0]\n    # Cast to dtype=bool and deal with size 0 arrays\n    x = xp.any(x)\n\n    try:\n        bool(x)\n        return False\n    # The Array API standard dictactes that __bool__ should raise TypeError if the\n    # output cannot be defined.\n    # Here we allow for it to raise arbitrary exceptions, e.g. like Dask does.\n    except Exception:\n        return True\n\n\n__all__ = [\n    \"array_namespace\",\n    \"device\",\n    \"get_namespace\",\n    \"is_array_api_obj\",\n    \"is_array_api_strict_namespace\",\n    \"is_cupy_array\",\n    \"is_cupy_namespace\",\n    \"is_dask_array\",\n    \"is_dask_namespace\",\n    \"is_jax_array\",\n    \"is_jax_namespace\",\n    \"is_numpy_array\",\n    \"is_numpy_namespace\",\n    \"is_torch_array\",\n    \"is_torch_namespace\",\n    \"is_ndonnx_array\",\n    \"is_ndonnx_namespace\",\n    \"is_pydata_sparse_array\",\n    \"is_pydata_sparse_namespace\",\n    \"is_writeable_array\",\n    \"is_lazy_array\",\n    \"size\",\n    \"to_device\",\n]\n\n_all_ignore = ['lru_cache', 'sys', 'math', 'inspect', 'warnings']\n\ndef __dir__() -> list[str]:\n    return __all__\n"}, {"start_line": 29000, "end_line": 31000, "belongs_to": {"file_name": "_helpers.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/externals/array_api_compat/common", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": " has the right dtype and size.\n\n    Note\n    ----\n    This function errs on the side of caution for array types that may or may not be\n    lazy, e.g. JAX arrays, by always returning True for them.\n    \"\"\"\n    # **JAX note:** while it is possible to determine if you're inside or outside\n    # jax.jit by testing the subclass of a jax.Array object, as well as testing bool()\n    # as we do below for unknown arrays, this is not recommended by JAX best practices.\n\n    # **Dask note:** Dask eagerly computes the graph on __bool__, __float__, and so on.\n    # This behaviour, while impossible to change without breaking backwards\n    # compatibility, is highly detrimental to performance as the whole graph will end\n    # up being computed multiple times.\n\n    # Note: skipping reclassification of JAX zero gradient arrays, as one will\n    # exclusively get them once they leave a jax.grad JIT context.\n    cls = cast(Hashable, type(x))\n    res = _is_lazy_cls(cls)\n    if res is not None:\n        return res\n\n    if not hasattr(x, \"__array_namespace__\"):\n        return False\n\n    # Unknown Array API compatible object. Note that this test may have dire consequences\n    # in terms of performance, e.g. for a lazy object that eagerly computes the graph\n    # on __bool__ (dask is one such example, which however is special-cased above).\n\n    # Select a single point of the array\n    s = size(cast(\"HasShape[Collection[SupportsIndex | None]]\", x))\n    if s is None:\n        return True\n    xp = array_namespace(x)\n    if s > 1:\n        x = xp.reshape(x, (-1,))[0]\n    # Cast to dtype=bool and deal with size 0 arrays\n    x = xp.any(x)\n\n    try:\n        bool(x)\n        return False\n    # The Array API standard dictactes that __bool__ should raise TypeError if the\n    # output cannot be defined.\n    # Here we allow for it to raise arbitrary exceptions, e.g. like Dask does.\n    except Exception:\n        return True\n\n\n__all__ = [\n    \"array_namespace\",\n    \"device\",\n    \"get_namespace\",\n    \"is_array_"}, {"start_line": 27000, "end_line": 29000, "belongs_to": {"file_name": "_helpers.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/externals/array_api_compat/common", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": ")\n    # dask.array.Array.shape can contain NaN\n    return None if math.isnan(out) else out\n\n\n@lru_cache(100)\ndef _is_writeable_cls(cls: type) -> bool | None:\n    if (\n        _issubclass_fast(cls, \"numpy\", \"generic\")\n        or _issubclass_fast(cls, \"jax\", \"Array\")\n        or _issubclass_fast(cls, \"sparse\", \"SparseArray\")\n    ):\n        return False\n    if _is_array_api_cls(cls):\n        return True\n    return None\n\n\ndef is_writeable_array(x: object) -> bool:\n    \"\"\"\n    Return False if ``x.__setitem__`` is expected to raise; True otherwise.\n    Return False if `x` is not an array API compatible object.\n\n    Warning\n    -------\n    As there is no standard way to check if an array is writeable without actually\n    writing to it, this function blindly returns True for all unknown array types.\n    \"\"\"\n    cls = cast(Hashable, type(x))\n    if _issubclass_fast(cls, \"numpy\", \"ndarray\"):\n        return cast(\"npt.NDArray\", x).flags.writeable\n    res = _is_writeable_cls(cls)\n    if res is not None:\n        return res\n    return hasattr(x, '__array_namespace__')\n\n\n@lru_cache(100)\ndef _is_lazy_cls(cls: type) -> bool | None:\n    if (\n        _issubclass_fast(cls, \"numpy\", \"ndarray\")\n        or _issubclass_fast(cls, \"numpy\", \"generic\")\n        or _issubclass_fast(cls, \"cupy\", \"ndarray\")\n        or _issubclass_fast(cls, \"torch\", \"Tensor\")\n        or _issubclass_fast(cls, \"sparse\", \"SparseArray\")\n    ):\n        return False\n    if (\n        _issubclass_fast(cls, \"jax\", \"Array\")\n        or _issubclass_fast(cls, \"dask.array\", \"Array\")\n        or _issubclass_fast(cls, \"ndonnx\", \"Array\")\n    ):\n        return True\n    return  None\n\n\ndef is_lazy_array(x: object) -> bool:\n    \"\"\"Return True if x is potentially a future or it may be otherwise impossible or\n    expensive to eagerly read its contents, regardless of their size, e.g. by\n    calling ``bool(x)`` or ``float(x)``.\n\n    Return False otherwise; e.g. ``bool(x)`` etc. is guaranteed to succeed and to be\n    cheap as long as the array"}, {"start_line": 2000, "end_line": 4000, "belongs_to": {"file_name": "_helpers.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/externals/array_api_compat/common", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "s://github.com/google/jax/issues/20620.\n    \"\"\"\n    # Fast exit\n    try:\n        dtype = x.dtype  # type: ignore[attr-defined]\n    except AttributeError:\n        return False\n    cls = cast(Hashable, type(dtype))\n    if not _issubclass_fast(cls, \"numpy.dtypes\", \"VoidDType\"):\n        return False\n\n    if \"jax\" not in sys.modules:\n        return False\n\n    import jax\n    # jax.float0 is a np.dtype([('float0', 'V')])\n    return dtype == jax.float0\n\n\ndef is_numpy_array(x: object) -> TypeGuard[npt.NDArray[Any]]:\n    \"\"\"\n    Return True if `x` is a NumPy array.\n\n    This function does not import NumPy if it has not already been imported\n    and is therefore cheap to use.\n\n    This also returns True for `ndarray` subclasses and NumPy scalar objects.\n\n    See Also\n    --------\n\n    array_namespace\n    is_array_api_obj\n    is_cupy_array\n    is_torch_array\n    is_ndonnx_array\n    is_dask_array\n    is_jax_array\n    is_pydata_sparse_array\n    \"\"\"\n    # TODO: Should we reject ndarray subclasses?\n    cls = cast(Hashable, type(x))\n    return (\n        _issubclass_fast(cls, \"numpy\", \"ndarray\") \n        or _issubclass_fast(cls, \"numpy\", \"generic\")\n    ) and not _is_jax_zero_gradient_array(x)\n\n\ndef is_cupy_array(x: object) -> bool:\n    \"\"\"\n    Return True if `x` is a CuPy array.\n\n    This function does not import CuPy if it has not already been imported\n    and is therefore cheap to use.\n\n    This also returns True for `cupy.ndarray` subclasses and CuPy scalar objects.\n\n    See Also\n    --------\n\n    array_namespace\n    is_array_api_obj\n    is_numpy_array\n    is_torch_array\n    is_ndonnx_array\n    is_dask_array\n    is_jax_array\n    is_pydata_sparse_array\n    \"\"\"\n    cls = cast(Hashable, type(x))\n    return _issubclass_fast(cls, \"cupy\", \"ndarray\")\n\n\ndef is_torch_array(x: object) -> TypeIs[torch.Tensor]:\n    \"\"\"\n    Return True if `x` is a PyTorch tensor.\n\n    This function does not import PyTorch if it has not already been imported\n    and is therefore cheap to use.\n\n    See Also\n    "}, {"start_line": 28000, "end_line": 30000, "belongs_to": {"file_name": "_helpers.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/externals/array_api_compat/common", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "one:\n        return res\n    return hasattr(x, '__array_namespace__')\n\n\n@lru_cache(100)\ndef _is_lazy_cls(cls: type) -> bool | None:\n    if (\n        _issubclass_fast(cls, \"numpy\", \"ndarray\")\n        or _issubclass_fast(cls, \"numpy\", \"generic\")\n        or _issubclass_fast(cls, \"cupy\", \"ndarray\")\n        or _issubclass_fast(cls, \"torch\", \"Tensor\")\n        or _issubclass_fast(cls, \"sparse\", \"SparseArray\")\n    ):\n        return False\n    if (\n        _issubclass_fast(cls, \"jax\", \"Array\")\n        or _issubclass_fast(cls, \"dask.array\", \"Array\")\n        or _issubclass_fast(cls, \"ndonnx\", \"Array\")\n    ):\n        return True\n    return  None\n\n\ndef is_lazy_array(x: object) -> bool:\n    \"\"\"Return True if x is potentially a future or it may be otherwise impossible or\n    expensive to eagerly read its contents, regardless of their size, e.g. by\n    calling ``bool(x)`` or ``float(x)``.\n\n    Return False otherwise; e.g. ``bool(x)`` etc. is guaranteed to succeed and to be\n    cheap as long as the array has the right dtype and size.\n\n    Note\n    ----\n    This function errs on the side of caution for array types that may or may not be\n    lazy, e.g. JAX arrays, by always returning True for them.\n    \"\"\"\n    # **JAX note:** while it is possible to determine if you're inside or outside\n    # jax.jit by testing the subclass of a jax.Array object, as well as testing bool()\n    # as we do below for unknown arrays, this is not recommended by JAX best practices.\n\n    # **Dask note:** Dask eagerly computes the graph on __bool__, __float__, and so on.\n    # This behaviour, while impossible to change without breaking backwards\n    # compatibility, is highly detrimental to performance as the whole graph will end\n    # up being computed multiple times.\n\n    # Note: skipping reclassification of JAX zero gradient arrays, as one will\n    # exclusively get them once they leave a jax.grad JIT context.\n    cls = cast(Hashable, type(x))\n    res = _is_lazy_cls(cls)\n    if res is not None:\n        return"}, {"start_line": 1000, "end_line": 3000, "belongs_to": {"file_name": "_helpers.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/externals/array_api_compat/common", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "SizeT = TypeVar(\"_SizeT\", bound = int | None)\n\n    _ZeroGradientArray: TypeAlias = npt.NDArray[np.void]\n    _CupyArray: TypeAlias = Any  # cupy has no py.typed\n\n    _ArrayApiObj: TypeAlias = (\n        npt.NDArray[Any]\n        | da.Array\n        | jax.Array\n        | ndx.Array\n        | sparse.SparseArray\n        | torch.Tensor\n        | SupportsArrayNamespace[Any]\n        | _CupyArray\n    )\n\n_API_VERSIONS_OLD: Final = frozenset({\"2021.12\", \"2022.12\", \"2023.12\"})\n_API_VERSIONS: Final = _API_VERSIONS_OLD | frozenset({\"2024.12\"})\n\n\n@lru_cache(100)\ndef _issubclass_fast(cls: type, modname: str, clsname: str) -> bool:\n    try:\n        mod = sys.modules[modname]\n    except KeyError:\n        return False\n    parent_cls = getattr(mod, clsname)\n    return issubclass(cls, parent_cls)\n\n\ndef _is_jax_zero_gradient_array(x: object) -> TypeGuard[_ZeroGradientArray]:\n    \"\"\"Return True if `x` is a zero-gradient array.\n\n    These arrays are a design quirk of Jax that may one day be removed.\n    See https://github.com/google/jax/issues/20620.\n    \"\"\"\n    # Fast exit\n    try:\n        dtype = x.dtype  # type: ignore[attr-defined]\n    except AttributeError:\n        return False\n    cls = cast(Hashable, type(dtype))\n    if not _issubclass_fast(cls, \"numpy.dtypes\", \"VoidDType\"):\n        return False\n\n    if \"jax\" not in sys.modules:\n        return False\n\n    import jax\n    # jax.float0 is a np.dtype([('float0', 'V')])\n    return dtype == jax.float0\n\n\ndef is_numpy_array(x: object) -> TypeGuard[npt.NDArray[Any]]:\n    \"\"\"\n    Return True if `x` is a NumPy array.\n\n    This function does not import NumPy if it has not already been imported\n    and is therefore cheap to use.\n\n    This also returns True for `ndarray` subclasses and NumPy scalar objects.\n\n    See Also\n    --------\n\n    array_namespace\n    is_array_api_obj\n    is_cupy_array\n    is_torch_array\n    is_ndonnx_array\n    is_dask_array\n    is_jax_array\n    is_pydata_sparse_array\n    \"\"\"\n    # TODO: Should we reject ndarray subclasses?\n  "}, {"start_line": 10000, "end_line": 12000, "belongs_to": {"file_name": "_lazy.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/externals/array_api_extra/_lib", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": " else s for s in shape),\n                dtype=dtype,\n                meta=metas[0],\n            )\n            for i, (shape, dtype) in enumerate(zip(shapes, dtypes, strict=True))\n        )\n\n    elif is_jax_namespace(xp) and _is_jax_jit_enabled(xp):\n        # Delay calling func with jax.pure_callback, which will forward to func eager\n        # JAX arrays. Do not use jax.pure_callback when running outside of the JIT,\n        # as it does not support raising exceptions:\n        # https://github.com/jax-ml/jax/issues/26102\n        import jax\n\n        if any(None in shape for shape in shapes):\n            msg = \"Output shape must be fully known when running inside jax.jit\"\n            raise ValueError(msg)\n\n        # Shield kwargs from being coerced into JAX arrays.\n        # jax.pure_callback calls jax.jit under the hood, but without the chance of\n        # passing static_argnames / static_argnums.\n        wrapped = _lazy_apply_wrapper(\n            partial(func, **kwargs), as_numpy, multi_output, xp\n        )\n\n        # suppress unused-ignore to run mypy in -e lint as well as -e dev\n        out = cast(  # type: ignore[bad-cast,unused-ignore]\n            tuple[Array, ...],\n            jax.pure_callback(\n                wrapped,\n                tuple(\n                    jax.ShapeDtypeStruct(shape, dtype)  # pyright: ignore[reportUnknownArgumentType]\n                    for shape, dtype in zip(shapes, dtypes, strict=True)\n                ),\n                *args,\n            ),\n        )\n\n    else:\n        # Eager backends, including non-jitted JAX\n        wrapped = _lazy_apply_wrapper(func, as_numpy, multi_output, xp)\n        out = wrapped(*args, **kwargs)\n\n    return out if multi_output else out[0]\n\n\ndef _is_jax_jit_enabled(xp: ModuleType) -> bool:  # numpydoc ignore=PR01,RT01\n    \"\"\"Return True if this function is being called inside ``jax.jit``.\"\"\"\n    import jax  # pylint: disable=import-outside-toplevel\n\n    x = xp.asarray(False)\n    try:\n        return bool(x)\n   "}, {"start_line": 0, "end_line": 2000, "belongs_to": {"file_name": "_funcs.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/externals/array_api_extra/_lib", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "\"\"\"Array-agnostic implementations for the public API.\"\"\"\n\nimport math\nimport warnings\nfrom collections.abc import Callable, Sequence\nfrom types import ModuleType, NoneType\nfrom typing import cast, overload\n\nfrom ._at import at\nfrom ._utils import _compat, _helpers\nfrom ._utils._compat import (\n    array_namespace,\n    is_dask_namespace,\n    is_jax_array,\n    is_jax_namespace,\n)\nfrom ._utils._helpers import asarrays, eager_shape, meta_namespace, ndindex\nfrom ._utils._typing import Array\n\n__all__ = [\n    \"apply_where\",\n    \"atleast_nd\",\n    \"broadcast_shapes\",\n    \"cov\",\n    \"create_diagonal\",\n    \"expand_dims\",\n    \"kron\",\n    \"nunique\",\n    \"pad\",\n    \"setdiff1d\",\n    \"sinc\",\n]\n\n\n@overload\ndef apply_where(  # type: ignore[explicit-any,decorated-any] # numpydoc ignore=GL08\n    cond: Array,\n    args: Array | tuple[Array, ...],\n    f1: Callable[..., Array],\n    f2: Callable[..., Array],\n    /,\n    *,\n    xp: ModuleType | None = None,\n) -> Array: ...\n\n\n@overload\ndef apply_where(  # type: ignore[explicit-any,decorated-any] # numpydoc ignore=GL08\n    cond: Array,\n    args: Array | tuple[Array, ...],\n    f1: Callable[..., Array],\n    /,\n    *,\n    fill_value: Array | complex,\n    xp: ModuleType | None = None,\n) -> Array: ...\n\n\ndef apply_where(  # type: ignore[explicit-any] # numpydoc ignore=PR01,PR02\n    cond: Array,\n    args: Array | tuple[Array, ...],\n    f1: Callable[..., Array],\n    f2: Callable[..., Array] | None = None,\n    /,\n    *,\n    fill_value: Array | complex | None = None,\n    xp: ModuleType | None = None,\n) -> Array:\n    \"\"\"\n    Run one of two elementwise functions depending on a condition.\n\n    Equivalent to ``f1(*args) if cond else fill_value`` performed elementwise\n    when `fill_value` is defined, otherwise to ``f1(*args) if cond else f2(*args)``.\n\n    Parameters\n    ----------\n    cond : array\n        The condition, expressed as a boolean array.\n    args : Array or tuple of Arrays\n        Argument(s) to `f1` (and `f2`). Must be broadcastable with `cond`."}, {"start_line": 3000, "end_line": 5000, "belongs_to": {"file_name": "_helpers.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/externals/array_api_compat/common", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "  cls = cast(Hashable, type(x))\n    return (\n        _issubclass_fast(cls, \"numpy\", \"ndarray\") \n        or _issubclass_fast(cls, \"numpy\", \"generic\")\n    ) and not _is_jax_zero_gradient_array(x)\n\n\ndef is_cupy_array(x: object) -> bool:\n    \"\"\"\n    Return True if `x` is a CuPy array.\n\n    This function does not import CuPy if it has not already been imported\n    and is therefore cheap to use.\n\n    This also returns True for `cupy.ndarray` subclasses and CuPy scalar objects.\n\n    See Also\n    --------\n\n    array_namespace\n    is_array_api_obj\n    is_numpy_array\n    is_torch_array\n    is_ndonnx_array\n    is_dask_array\n    is_jax_array\n    is_pydata_sparse_array\n    \"\"\"\n    cls = cast(Hashable, type(x))\n    return _issubclass_fast(cls, \"cupy\", \"ndarray\")\n\n\ndef is_torch_array(x: object) -> TypeIs[torch.Tensor]:\n    \"\"\"\n    Return True if `x` is a PyTorch tensor.\n\n    This function does not import PyTorch if it has not already been imported\n    and is therefore cheap to use.\n\n    See Also\n    --------\n\n    array_namespace\n    is_array_api_obj\n    is_numpy_array\n    is_cupy_array\n    is_dask_array\n    is_jax_array\n    is_pydata_sparse_array\n    \"\"\"\n    cls = cast(Hashable, type(x))\n    return _issubclass_fast(cls, \"torch\", \"Tensor\")\n\n\ndef is_ndonnx_array(x: object) -> TypeIs[ndx.Array]:\n    \"\"\"\n    Return True if `x` is a ndonnx Array.\n\n    This function does not import ndonnx if it has not already been imported\n    and is therefore cheap to use.\n\n    See Also\n    --------\n\n    array_namespace\n    is_array_api_obj\n    is_numpy_array\n    is_cupy_array\n    is_ndonnx_array\n    is_dask_array\n    is_jax_array\n    is_pydata_sparse_array\n    \"\"\"\n    cls = cast(Hashable, type(x))\n    return _issubclass_fast(cls, \"ndonnx\", \"Array\")\n\n\ndef is_dask_array(x: object) -> TypeIs[da.Array]:\n    \"\"\"\n    Return True if `x` is a dask.array Array.\n\n    This function does not import dask if it has not already been imported\n    and is therefore cheap to use.\n\n    See Also\n    --------\n\n    array_n"}, {"start_line": 4000, "end_line": 6000, "belongs_to": {"file_name": "_helpers.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/externals/array_api_compat/common", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "--------\n\n    array_namespace\n    is_array_api_obj\n    is_numpy_array\n    is_cupy_array\n    is_dask_array\n    is_jax_array\n    is_pydata_sparse_array\n    \"\"\"\n    cls = cast(Hashable, type(x))\n    return _issubclass_fast(cls, \"torch\", \"Tensor\")\n\n\ndef is_ndonnx_array(x: object) -> TypeIs[ndx.Array]:\n    \"\"\"\n    Return True if `x` is a ndonnx Array.\n\n    This function does not import ndonnx if it has not already been imported\n    and is therefore cheap to use.\n\n    See Also\n    --------\n\n    array_namespace\n    is_array_api_obj\n    is_numpy_array\n    is_cupy_array\n    is_ndonnx_array\n    is_dask_array\n    is_jax_array\n    is_pydata_sparse_array\n    \"\"\"\n    cls = cast(Hashable, type(x))\n    return _issubclass_fast(cls, \"ndonnx\", \"Array\")\n\n\ndef is_dask_array(x: object) -> TypeIs[da.Array]:\n    \"\"\"\n    Return True if `x` is a dask.array Array.\n\n    This function does not import dask if it has not already been imported\n    and is therefore cheap to use.\n\n    See Also\n    --------\n\n    array_namespace\n    is_array_api_obj\n    is_numpy_array\n    is_cupy_array\n    is_torch_array\n    is_ndonnx_array\n    is_jax_array\n    is_pydata_sparse_array\n    \"\"\"\n    cls = cast(Hashable, type(x))\n    return _issubclass_fast(cls, \"dask.array\", \"Array\")\n\n\ndef is_jax_array(x: object) -> TypeIs[jax.Array]:\n    \"\"\"\n    Return True if `x` is a JAX array.\n\n    This function does not import JAX if it has not already been imported\n    and is therefore cheap to use.\n\n\n    See Also\n    --------\n\n    array_namespace\n    is_array_api_obj\n    is_numpy_array\n    is_cupy_array\n    is_torch_array\n    is_ndonnx_array\n    is_dask_array\n    is_pydata_sparse_array\n    \"\"\"\n    cls = cast(Hashable, type(x))\n    return _issubclass_fast(cls, \"jax\", \"Array\") or _is_jax_zero_gradient_array(x)\n\n\ndef is_pydata_sparse_array(x: object) -> TypeIs[sparse.SparseArray]:\n    \"\"\"\n    Return True if `x` is an array from the `sparse` package.\n\n    This function does not import `sparse` if it has not already been imported\n    an"}], "retrieved_count": 10, "cost_time": 0.365314245223999}
{"question": "Why does the test_minibatch_nmf_transform function require the fresh_restarts parameter to be set to True to guarantee equivalence between fit_transform and transform outputs, and what underlying algorithmic behavior would be violated if this constraint were removed?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"start_line": 7000, "end_line": 9000, "belongs_to": {"file_name": "test_nmf.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/decomposition/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "\n    t = m.transform(A)\n    assert_allclose(ft, t, atol=1e-1)\n\n\ndef test_minibatch_nmf_transform():\n    # Test that fit_transform is equivalent to fit.transform for MiniBatchNMF\n    # Only guaranteed with fresh restarts\n    rng = np.random.mtrand.RandomState(42)\n    A = np.abs(rng.randn(6, 5))\n    m = MiniBatchNMF(\n        n_components=3,\n        random_state=0,\n        tol=1e-3,\n        fresh_restarts=True,\n    )\n    ft = m.fit_transform(A)\n    t = m.transform(A)\n    assert_allclose(ft, t)\n\n\n@pytest.mark.parametrize(\n    [\"Estimator\", \"solver\"],\n    [[NMF, {\"solver\": \"cd\"}], [NMF, {\"solver\": \"mu\"}], [MiniBatchNMF, {}]],\n)\ndef test_nmf_transform_custom_init(Estimator, solver):\n    # Smoke test that checks if NMF.transform works with custom initialization\n    random_state = np.random.RandomState(0)\n    A = np.abs(random_state.randn(6, 5))\n    n_components = 4\n    avg = np.sqrt(A.mean() / n_components)\n    H_init = np.abs(avg * random_state.randn(n_components, 5))\n    W_init = np.abs(avg * random_state.randn(6, n_components))\n\n    m = Estimator(\n        n_components=n_components, init=\"custom\", random_state=0, tol=1e-3, **solver\n    )\n    m.fit_transform(A, W=W_init, H=H_init)\n    m.transform(A)\n\n\n@pytest.mark.parametrize(\"solver\", (\"cd\", \"mu\"))\ndef test_nmf_inverse_transform(solver):\n    # Test that NMF.inverse_transform returns close values\n    random_state = np.random.RandomState(0)\n    A = np.abs(random_state.randn(6, 4))\n    m = NMF(\n        solver=solver,\n        n_components=4,\n        init=\"random\",\n        random_state=0,\n        max_iter=1000,\n    )\n    ft = m.fit_transform(A)\n    A_new = m.inverse_transform(ft)\n    assert_array_almost_equal(A, A_new, decimal=2)\n\n\ndef test_mbnmf_inverse_transform():\n    # Test that MiniBatchNMF.transform followed by MiniBatchNMF.inverse_transform\n    # is close to the identity\n    rng = np.random.RandomState(0)\n    A = np.abs(rng.randn(6, 4))\n    nmf = MiniBatchNMF(\n        random_state=rng,\n        max_iter=500,\n        ini"}, {"start_line": 6000, "end_line": 8000, "belongs_to": {"file_name": "test_nmf.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/decomposition/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "    max_iter=max_iter,\n        random_state=0,\n    )\n    transf = model.fit_transform(X)\n    X_calc = np.dot(transf, model.components_)\n\n    assert model.reconstruction_err_ < 0.1\n    assert_allclose(X, X_calc)\n\n    mbmodel = MiniBatchNMF(\n        n_components=n_components,\n        beta_loss=beta_loss,\n        batch_size=batch_size,\n        random_state=0,\n        max_iter=max_iter,\n    )\n    transf = mbmodel.fit_transform(X)\n    X_calc = np.dot(transf, mbmodel.components_)\n\n    assert mbmodel.reconstruction_err_ < 0.1\n    assert_allclose(X, X_calc, atol=1)\n\n\n@pytest.mark.parametrize(\"solver\", [\"cd\", \"mu\"])\ndef test_nmf_transform(solver):\n    # Test that fit_transform is equivalent to fit.transform for NMF\n    # Test that NMF.transform returns close values\n    rng = np.random.mtrand.RandomState(42)\n    A = np.abs(rng.randn(6, 5))\n    m = NMF(\n        solver=solver,\n        n_components=3,\n        init=\"random\",\n        random_state=0,\n        tol=1e-6,\n    )\n    ft = m.fit_transform(A)\n    t = m.transform(A)\n    assert_allclose(ft, t, atol=1e-1)\n\n\ndef test_minibatch_nmf_transform():\n    # Test that fit_transform is equivalent to fit.transform for MiniBatchNMF\n    # Only guaranteed with fresh restarts\n    rng = np.random.mtrand.RandomState(42)\n    A = np.abs(rng.randn(6, 5))\n    m = MiniBatchNMF(\n        n_components=3,\n        random_state=0,\n        tol=1e-3,\n        fresh_restarts=True,\n    )\n    ft = m.fit_transform(A)\n    t = m.transform(A)\n    assert_allclose(ft, t)\n\n\n@pytest.mark.parametrize(\n    [\"Estimator\", \"solver\"],\n    [[NMF, {\"solver\": \"cd\"}], [NMF, {\"solver\": \"mu\"}], [MiniBatchNMF, {}]],\n)\ndef test_nmf_transform_custom_init(Estimator, solver):\n    # Smoke test that checks if NMF.transform works with custom initialization\n    random_state = np.random.RandomState(0)\n    A = np.abs(random_state.randn(6, 5))\n    n_components = 4\n    avg = np.sqrt(A.mean() / n_components)\n    H_init = np.abs(avg * random_state.randn(n_components, 5))\n    W_init = np.abs(avg"}, {"start_line": 26000, "end_line": 28000, "belongs_to": {"file_name": "test_nmf.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/decomposition/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": " don't have the same\n    # dtype as X.\n    rng = np.random.RandomState(0)\n    X = rng.random_sample((20, 15))\n    H = rng.random_sample((15, 15)).astype(np.float32)\n    W = rng.random_sample((20, 15))\n\n    with pytest.raises(TypeError, match=\"should have the same dtype as X\"):\n        Estimator(init=\"custom\").fit(X, H=H, W=W)\n\n    with pytest.raises(TypeError, match=\"should have the same dtype as X\"):\n        non_negative_factorization(X, H=H, update_H=False)\n\n\n@pytest.mark.parametrize(\"beta_loss\", [-0.5, 0, 0.5, 1, 1.5, 2, 2.5])\ndef test_nmf_minibatchnmf_equivalence(beta_loss):\n    # Test that MiniBatchNMF is equivalent to NMF when batch_size = n_samples and\n    # forget_factor 0.0 (stopping criterion put aside)\n    rng = np.random.mtrand.RandomState(42)\n    X = np.abs(rng.randn(48, 5))\n\n    nmf = NMF(\n        n_components=5,\n        beta_loss=beta_loss,\n        solver=\"mu\",\n        random_state=0,\n        tol=0,\n    )\n    mbnmf = MiniBatchNMF(\n        n_components=5,\n        beta_loss=beta_loss,\n        random_state=0,\n        tol=0,\n        max_no_improvement=None,\n        batch_size=X.shape[0],\n        forget_factor=0.0,\n    )\n    W = nmf.fit_transform(X)\n    mbW = mbnmf.fit_transform(X)\n    assert_allclose(W, mbW)\n\n\ndef test_minibatch_nmf_partial_fit():\n    # Check fit / partial_fit equivalence. Applicable only with fresh restarts.\n    rng = np.random.mtrand.RandomState(42)\n    X = np.abs(rng.randn(100, 5))\n\n    n_components = 5\n    batch_size = 10\n    max_iter = 2\n\n    mbnmf1 = MiniBatchNMF(\n        n_components=n_components,\n        init=\"custom\",\n        random_state=0,\n        max_iter=max_iter,\n        batch_size=batch_size,\n        tol=0,\n        max_no_improvement=None,\n        fresh_restarts=False,\n    )\n    mbnmf2 = MiniBatchNMF(n_components=n_components, init=\"custom\", random_state=0)\n\n    # Force the same init of H (W is recomputed anyway) to be able to compare results.\n    W, H = nmf._initialize_nmf(\n        X, n_components=n_components, init=\"rando"}, {"start_line": 27000, "end_line": 29000, "belongs_to": {"file_name": "test_nmf.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/decomposition/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "s=beta_loss,\n        random_state=0,\n        tol=0,\n        max_no_improvement=None,\n        batch_size=X.shape[0],\n        forget_factor=0.0,\n    )\n    W = nmf.fit_transform(X)\n    mbW = mbnmf.fit_transform(X)\n    assert_allclose(W, mbW)\n\n\ndef test_minibatch_nmf_partial_fit():\n    # Check fit / partial_fit equivalence. Applicable only with fresh restarts.\n    rng = np.random.mtrand.RandomState(42)\n    X = np.abs(rng.randn(100, 5))\n\n    n_components = 5\n    batch_size = 10\n    max_iter = 2\n\n    mbnmf1 = MiniBatchNMF(\n        n_components=n_components,\n        init=\"custom\",\n        random_state=0,\n        max_iter=max_iter,\n        batch_size=batch_size,\n        tol=0,\n        max_no_improvement=None,\n        fresh_restarts=False,\n    )\n    mbnmf2 = MiniBatchNMF(n_components=n_components, init=\"custom\", random_state=0)\n\n    # Force the same init of H (W is recomputed anyway) to be able to compare results.\n    W, H = nmf._initialize_nmf(\n        X, n_components=n_components, init=\"random\", random_state=0\n    )\n\n    mbnmf1.fit(X, W=W, H=H)\n    for i in range(max_iter):\n        for j in range(batch_size):\n            mbnmf2.partial_fit(X[j : j + batch_size], W=W[:batch_size], H=H)\n\n    assert mbnmf1.n_steps_ == mbnmf2.n_steps_\n    assert_allclose(mbnmf1.components_, mbnmf2.components_)\n\n\ndef test_feature_names_out():\n    \"\"\"Check feature names out for NMF.\"\"\"\n    random_state = np.random.RandomState(0)\n    X = np.abs(random_state.randn(10, 4))\n    nmf = NMF(n_components=3).fit(X)\n\n    names = nmf.get_feature_names_out()\n    assert_array_equal([f\"nmf{i}\" for i in range(3)], names)\n\n\ndef test_minibatch_nmf_verbose():\n    # Check verbose mode of MiniBatchNMF for better coverage.\n    A = np.random.RandomState(0).random_sample((100, 10))\n    nmf = MiniBatchNMF(tol=1e-2, random_state=0, verbose=1)\n    old_stdout = sys.stdout\n    sys.stdout = StringIO()\n    try:\n        nmf.fit(A)\n    finally:\n        sys.stdout = old_stdout\n\n\n@pytest.mark.parametrize(\"Estimator\", [NMF, MiniB"}, {"start_line": 5000, "end_line": 7000, "belongs_to": {"file_name": "test_nmf.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/decomposition/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "timator(\n        5,\n        init=\"nndsvdar\",\n        random_state=0,\n        max_iter=600,\n        **solver,\n    )\n    X = np.abs(rng.randn(6, 5))\n    assert pnmf.fit(X).reconstruction_err_ < 0.1\n\n\ndef test_nmf_true_reconstruction():\n    # Test that the fit is not too far away from an exact solution\n    # (by construction)\n    n_samples = 15\n    n_features = 10\n    n_components = 5\n    beta_loss = 1\n    batch_size = 3\n    max_iter = 1000\n\n    rng = np.random.mtrand.RandomState(42)\n    W_true = np.zeros([n_samples, n_components])\n    W_array = np.abs(rng.randn(n_samples))\n    for j in range(n_components):\n        W_true[j % n_samples, j] = W_array[j % n_samples]\n    H_true = np.zeros([n_components, n_features])\n    H_array = np.abs(rng.randn(n_components))\n    for j in range(n_features):\n        H_true[j % n_components, j] = H_array[j % n_components]\n    X = np.dot(W_true, H_true)\n\n    model = NMF(\n        n_components=n_components,\n        solver=\"mu\",\n        beta_loss=beta_loss,\n        max_iter=max_iter,\n        random_state=0,\n    )\n    transf = model.fit_transform(X)\n    X_calc = np.dot(transf, model.components_)\n\n    assert model.reconstruction_err_ < 0.1\n    assert_allclose(X, X_calc)\n\n    mbmodel = MiniBatchNMF(\n        n_components=n_components,\n        beta_loss=beta_loss,\n        batch_size=batch_size,\n        random_state=0,\n        max_iter=max_iter,\n    )\n    transf = mbmodel.fit_transform(X)\n    X_calc = np.dot(transf, mbmodel.components_)\n\n    assert mbmodel.reconstruction_err_ < 0.1\n    assert_allclose(X, X_calc, atol=1)\n\n\n@pytest.mark.parametrize(\"solver\", [\"cd\", \"mu\"])\ndef test_nmf_transform(solver):\n    # Test that fit_transform is equivalent to fit.transform for NMF\n    # Test that NMF.transform returns close values\n    rng = np.random.mtrand.RandomState(42)\n    A = np.abs(rng.randn(6, 5))\n    m = NMF(\n        solver=solver,\n        n_components=3,\n        init=\"random\",\n        random_state=0,\n        tol=1e-6,\n    )\n    ft = m.fit_transform(A)"}, {"start_line": 25000, "end_line": 27000, "belongs_to": {"file_name": "test_nmf.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/decomposition/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "  alpha_W=1.0,\n        alpha_H=1.0,\n        tol=1e-2,\n        random_state=0,\n        **solver,\n    )\n\n    assert nmf.fit(X).transform(X).dtype == dtype_out\n    assert nmf.fit_transform(X).dtype == dtype_out\n    assert nmf.components_.dtype == dtype_out\n\n\n@pytest.mark.parametrize(\n    [\"Estimator\", \"solver\"],\n    [[NMF, {\"solver\": \"cd\"}], [NMF, {\"solver\": \"mu\"}], [MiniBatchNMF, {}]],\n)\ndef test_nmf_float32_float64_consistency(Estimator, solver):\n    # Check that the result of NMF is the same between float32 and float64\n    X = np.random.RandomState(0).randn(50, 7)\n    np.abs(X, out=X)\n    nmf32 = Estimator(random_state=0, tol=1e-3, **solver)\n    W32 = nmf32.fit_transform(X.astype(np.float32))\n    nmf64 = Estimator(random_state=0, tol=1e-3, **solver)\n    W64 = nmf64.fit_transform(X)\n\n    assert_allclose(W32, W64, atol=1e-5)\n\n\n@pytest.mark.parametrize(\"Estimator\", [NMF, MiniBatchNMF])\ndef test_nmf_custom_init_dtype_error(Estimator):\n    # Check that an error is raise if custom H and/or W don't have the same\n    # dtype as X.\n    rng = np.random.RandomState(0)\n    X = rng.random_sample((20, 15))\n    H = rng.random_sample((15, 15)).astype(np.float32)\n    W = rng.random_sample((20, 15))\n\n    with pytest.raises(TypeError, match=\"should have the same dtype as X\"):\n        Estimator(init=\"custom\").fit(X, H=H, W=W)\n\n    with pytest.raises(TypeError, match=\"should have the same dtype as X\"):\n        non_negative_factorization(X, H=H, update_H=False)\n\n\n@pytest.mark.parametrize(\"beta_loss\", [-0.5, 0, 0.5, 1, 1.5, 2, 2.5])\ndef test_nmf_minibatchnmf_equivalence(beta_loss):\n    # Test that MiniBatchNMF is equivalent to NMF when batch_size = n_samples and\n    # forget_factor 0.0 (stopping criterion put aside)\n    rng = np.random.mtrand.RandomState(42)\n    X = np.abs(rng.randn(48, 5))\n\n    nmf = NMF(\n        n_components=5,\n        beta_loss=beta_loss,\n        solver=\"mu\",\n        random_state=0,\n        tol=0,\n    )\n    mbnmf = MiniBatchNMF(\n        n_components=5,\n        beta_los"}, {"start_line": 77000, "end_line": 79000, "belongs_to": {"file_name": "_nmf.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/decomposition", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "ta_loss <= 0 and X contains zeros, \"\n                \"the solver may diverge. Please add small values \"\n                \"to X, or use a positive beta_loss.\"\n            )\n\n        n_samples = X.shape[0]\n\n        # initialize or check W and H\n        W, H = self._check_w_h(X, W, H, update_H)\n        H_buffer = H.copy()\n\n        # Initialize auxiliary matrices\n        self._components_numerator = H.copy()\n        self._components_denominator = np.ones(H.shape, dtype=H.dtype)\n\n        # Attributes to monitor the convergence\n        self._ewa_cost = None\n        self._ewa_cost_min = None\n        self._no_improvement = 0\n\n        batches = gen_batches(n_samples, self._batch_size)\n        batches = itertools.cycle(batches)\n        n_steps_per_iter = int(np.ceil(n_samples / self._batch_size))\n        n_steps = self.max_iter * n_steps_per_iter\n\n        for i, batch in zip(range(n_steps), batches):\n            batch_cost = self._minibatch_step(X[batch], W[batch], H, update_H)\n\n            if update_H and self._minibatch_convergence(\n                X[batch], batch_cost, H, H_buffer, n_samples, i, n_steps\n            ):\n                break\n\n            H_buffer[:] = H\n\n        if self.fresh_restarts:\n            W = self._solve_W(X, H, self._transform_max_iter)\n\n        n_steps = i + 1\n        n_iter = int(np.ceil(n_steps / n_steps_per_iter))\n\n        if n_iter == self.max_iter and self.tol > 0:\n            warnings.warn(\n                (\n                    f\"Maximum number of iterations {self.max_iter} reached. \"\n                    \"Increase it to improve convergence.\"\n                ),\n                ConvergenceWarning,\n            )\n\n        return W, H, n_iter, n_steps\n\n    def transform(self, X):\n        \"\"\"Transform the data X according to the fitted MiniBatchNMF model.\n\n        Parameters\n        ----------\n        X : {array-like, sparse matrix} of shape (n_samples, n_features)\n            Data matrix to be transformed by the model.\n\n        Returns\n        ---"}, {"start_line": 9000, "end_line": 11000, "belongs_to": {"file_name": "test_nmf.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/decomposition/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "t=\"nndsvdar\",\n        fresh_restarts=True,\n    )\n    ft = nmf.fit_transform(A)\n    A_new = nmf.inverse_transform(ft)\n    assert_allclose(A, A_new, rtol=1e-3, atol=1e-2)\n\n\n@pytest.mark.parametrize(\"Estimator\", [NMF, MiniBatchNMF])\ndef test_n_components_greater_n_features(Estimator):\n    # Smoke test for the case of more components than features.\n    rng = np.random.mtrand.RandomState(42)\n    A = np.abs(rng.randn(30, 10))\n    Estimator(n_components=15, random_state=0, tol=1e-2).fit(A)\n\n\n@pytest.mark.parametrize(\n    [\"Estimator\", \"solver\"],\n    [[NMF, {\"solver\": \"cd\"}], [NMF, {\"solver\": \"mu\"}], [MiniBatchNMF, {}]],\n)\n@pytest.mark.parametrize(\"sparse_container\", CSC_CONTAINERS + CSR_CONTAINERS)\n@pytest.mark.parametrize(\"alpha_W\", (0.0, 1.0))\n@pytest.mark.parametrize(\"alpha_H\", (0.0, 1.0, \"same\"))\ndef test_nmf_sparse_input(Estimator, solver, sparse_container, alpha_W, alpha_H):\n    # Test that sparse matrices are accepted as input\n    rng = np.random.mtrand.RandomState(42)\n    A = np.abs(rng.randn(10, 10))\n    A[:, 2 * np.arange(5)] = 0\n    A_sparse = sparse_container(A)\n\n    est1 = Estimator(\n        n_components=5,\n        init=\"random\",\n        alpha_W=alpha_W,\n        alpha_H=alpha_H,\n        random_state=0,\n        tol=0,\n        max_iter=100,\n        **solver,\n    )\n    est2 = clone(est1)\n\n    W1 = est1.fit_transform(A)\n    W2 = est2.fit_transform(A_sparse)\n    H1 = est1.components_\n    H2 = est2.components_\n\n    assert_allclose(W1, W2)\n    assert_allclose(H1, H2)\n\n\n@pytest.mark.parametrize(\n    [\"Estimator\", \"solver\"],\n    [[NMF, {\"solver\": \"cd\"}], [NMF, {\"solver\": \"mu\"}], [MiniBatchNMF, {}]],\n)\n@pytest.mark.parametrize(\"csc_container\", CSC_CONTAINERS)\ndef test_nmf_sparse_transform(Estimator, solver, csc_container):\n    # Test that transform works on sparse data.  Issue #2124\n    rng = np.random.mtrand.RandomState(42)\n    A = np.abs(rng.randn(3, 2))\n    A[1, 1] = 0\n    A = csc_container(A)\n\n    model = Estimator(random_state=0, n_components=2, max_iter=400, **sol"}, {"start_line": 66000, "end_line": 68000, "belongs_to": {"file_name": "_nmf.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/decomposition", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": " 1], [2, 1], [3, 1.2], [4, 1], [5, 0.8], [6, 1]])\n    >>> from sklearn.decomposition import MiniBatchNMF\n    >>> model = MiniBatchNMF(n_components=2, init='random', random_state=0)\n    >>> W = model.fit_transform(X)\n    >>> H = model.components_\n    \"\"\"\n\n    _parameter_constraints: dict = {\n        **_BaseNMF._parameter_constraints,\n        \"max_no_improvement\": [Interval(Integral, 1, None, closed=\"left\"), None],\n        \"batch_size\": [Interval(Integral, 1, None, closed=\"left\")],\n        \"forget_factor\": [Interval(Real, 0, 1, closed=\"both\")],\n        \"fresh_restarts\": [\"boolean\"],\n        \"fresh_restarts_max_iter\": [Interval(Integral, 1, None, closed=\"left\")],\n        \"transform_max_iter\": [Interval(Integral, 1, None, closed=\"left\"), None],\n    }\n\n    def __init__(\n        self,\n        n_components=\"auto\",\n        *,\n        init=None,\n        batch_size=1024,\n        beta_loss=\"frobenius\",\n        tol=1e-4,\n        max_no_improvement=10,\n        max_iter=200,\n        alpha_W=0.0,\n        alpha_H=\"same\",\n        l1_ratio=0.0,\n        forget_factor=0.7,\n        fresh_restarts=False,\n        fresh_restarts_max_iter=30,\n        transform_max_iter=None,\n        random_state=None,\n        verbose=0,\n    ):\n        super().__init__(\n            n_components=n_components,\n            init=init,\n            beta_loss=beta_loss,\n            tol=tol,\n            max_iter=max_iter,\n            random_state=random_state,\n            alpha_W=alpha_W,\n            alpha_H=alpha_H,\n            l1_ratio=l1_ratio,\n            verbose=verbose,\n        )\n\n        self.max_no_improvement = max_no_improvement\n        self.batch_size = batch_size\n        self.forget_factor = forget_factor\n        self.fresh_restarts = fresh_restarts\n        self.fresh_restarts_max_iter = fresh_restarts_max_iter\n        self.transform_max_iter = transform_max_iter\n\n    def _check_params(self, X):\n        super()._check_params(X)\n\n        # batch_size\n        self._batch_size = min(self.batch_size, X.shape"}, {"start_line": 8000, "end_line": 10000, "belongs_to": {"file_name": "test_nmf.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/decomposition/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": " * random_state.randn(6, n_components))\n\n    m = Estimator(\n        n_components=n_components, init=\"custom\", random_state=0, tol=1e-3, **solver\n    )\n    m.fit_transform(A, W=W_init, H=H_init)\n    m.transform(A)\n\n\n@pytest.mark.parametrize(\"solver\", (\"cd\", \"mu\"))\ndef test_nmf_inverse_transform(solver):\n    # Test that NMF.inverse_transform returns close values\n    random_state = np.random.RandomState(0)\n    A = np.abs(random_state.randn(6, 4))\n    m = NMF(\n        solver=solver,\n        n_components=4,\n        init=\"random\",\n        random_state=0,\n        max_iter=1000,\n    )\n    ft = m.fit_transform(A)\n    A_new = m.inverse_transform(ft)\n    assert_array_almost_equal(A, A_new, decimal=2)\n\n\ndef test_mbnmf_inverse_transform():\n    # Test that MiniBatchNMF.transform followed by MiniBatchNMF.inverse_transform\n    # is close to the identity\n    rng = np.random.RandomState(0)\n    A = np.abs(rng.randn(6, 4))\n    nmf = MiniBatchNMF(\n        random_state=rng,\n        max_iter=500,\n        init=\"nndsvdar\",\n        fresh_restarts=True,\n    )\n    ft = nmf.fit_transform(A)\n    A_new = nmf.inverse_transform(ft)\n    assert_allclose(A, A_new, rtol=1e-3, atol=1e-2)\n\n\n@pytest.mark.parametrize(\"Estimator\", [NMF, MiniBatchNMF])\ndef test_n_components_greater_n_features(Estimator):\n    # Smoke test for the case of more components than features.\n    rng = np.random.mtrand.RandomState(42)\n    A = np.abs(rng.randn(30, 10))\n    Estimator(n_components=15, random_state=0, tol=1e-2).fit(A)\n\n\n@pytest.mark.parametrize(\n    [\"Estimator\", \"solver\"],\n    [[NMF, {\"solver\": \"cd\"}], [NMF, {\"solver\": \"mu\"}], [MiniBatchNMF, {}]],\n)\n@pytest.mark.parametrize(\"sparse_container\", CSC_CONTAINERS + CSR_CONTAINERS)\n@pytest.mark.parametrize(\"alpha_W\", (0.0, 1.0))\n@pytest.mark.parametrize(\"alpha_H\", (0.0, 1.0, \"same\"))\ndef test_nmf_sparse_input(Estimator, solver, sparse_container, alpha_W, alpha_H):\n    # Test that sparse matrices are accepted as input\n    rng = np.random.mtrand.RandomState(42)\n    A = np.abs(r"}], "retrieved_count": 10, "cost_time": 0.36452198028564453}
{"question": "Where does the `set_params` method in `_BaseHeterogeneousEnsemble` delegate parameter setting to its parent class, and what is the control flow path that determines whether individual estimators are modified, replaced, or dropped based on the 'drop' sentinel value?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"start_line": 7000, "end_line": 9000, "belongs_to": {"file_name": "_base.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/ensemble", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "self.estimators))\n\n    @abstractmethod\n    def __init__(self, estimators):\n        self.estimators = estimators\n\n    def _validate_estimators(self):\n        if len(self.estimators) == 0 or not all(\n            isinstance(item, (tuple, list)) and isinstance(item[0], str)\n            for item in self.estimators\n        ):\n            raise ValueError(\n                \"Invalid 'estimators' attribute, 'estimators' should be a \"\n                \"non-empty list of (string, estimator) tuples.\"\n            )\n        names, estimators = zip(*self.estimators)\n        # defined by MetaEstimatorMixin\n        self._validate_names(names)\n\n        has_estimator = any(est != \"drop\" for est in estimators)\n        if not has_estimator:\n            raise ValueError(\n                \"All estimators are dropped. At least one is required \"\n                \"to be an estimator.\"\n            )\n\n        is_estimator_type = is_classifier if is_classifier(self) else is_regressor\n\n        for est in estimators:\n            if est != \"drop\" and not is_estimator_type(est):\n                raise ValueError(\n                    \"The estimator {} should be a {}.\".format(\n                        est.__class__.__name__, is_estimator_type.__name__[3:]\n                    )\n                )\n\n        return names, estimators\n\n    def set_params(self, **params):\n        \"\"\"\n        Set the parameters of an estimator from the ensemble.\n\n        Valid parameter keys can be listed with `get_params()`. Note that you\n        can directly set the parameters of the estimators contained in\n        `estimators`.\n\n        Parameters\n        ----------\n        **params : keyword arguments\n            Specific parameters using e.g.\n            `set_params(parameter_name=new_value)`. In addition, to setting the\n            parameters of the estimator, the individual estimator of the\n            estimators can also be set, or can be removed by setting them to\n            'drop'.\n\n        Returns\n        -------\n      "}, {"start_line": 8000, "end_line": 10000, "belongs_to": {"file_name": "_base.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/ensemble", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "          if est != \"drop\" and not is_estimator_type(est):\n                raise ValueError(\n                    \"The estimator {} should be a {}.\".format(\n                        est.__class__.__name__, is_estimator_type.__name__[3:]\n                    )\n                )\n\n        return names, estimators\n\n    def set_params(self, **params):\n        \"\"\"\n        Set the parameters of an estimator from the ensemble.\n\n        Valid parameter keys can be listed with `get_params()`. Note that you\n        can directly set the parameters of the estimators contained in\n        `estimators`.\n\n        Parameters\n        ----------\n        **params : keyword arguments\n            Specific parameters using e.g.\n            `set_params(parameter_name=new_value)`. In addition, to setting the\n            parameters of the estimator, the individual estimator of the\n            estimators can also be set, or can be removed by setting them to\n            'drop'.\n\n        Returns\n        -------\n        self : object\n            Estimator instance.\n        \"\"\"\n        super()._set_params(\"estimators\", **params)\n        return self\n\n    def get_params(self, deep=True):\n        \"\"\"\n        Get the parameters of an estimator from the ensemble.\n\n        Returns the parameters given in the constructor as well as the\n        estimators contained within the `estimators` parameter.\n\n        Parameters\n        ----------\n        deep : bool, default=True\n            Setting it to True gets the various estimators and the parameters\n            of the estimators as well.\n\n        Returns\n        -------\n        params : dict\n            Parameter and estimator names mapped to their values or parameter\n            names mapped to their values.\n        \"\"\"\n        return super()._get_params(\"estimators\", deep=deep)\n\n    def __sklearn_tags__(self):\n        tags = super().__sklearn_tags__()\n        try:\n            tags.input_tags.allow_nan = all(\n                get_tags(est[1]).input_tags.allow_"}, {"start_line": 3000, "end_line": 5000, "belongs_to": {"file_name": "test_common.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/ensemble/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "rams() does not add a new attribute\n    estimator_new_params = clone(estimator)\n    svm_estimator = SVC() if is_classifier(estimator) else SVR()\n    estimator_new_params.set_params(svm=svm_estimator).fit(X, y)\n    assert not hasattr(estimator_new_params, \"svm\")\n    assert (\n        estimator_new_params.named_estimators.lr.get_params()\n        == estimator.named_estimators.lr.get_params()\n    )\n    assert (\n        estimator_new_params.named_estimators.rf.get_params()\n        == estimator.named_estimators.rf.get_params()\n    )\n\n    # check the behavior when setting an dropping an estimator\n    estimator_dropped = clone(estimator)\n    estimator_dropped.set_params(svm=\"drop\")\n    estimator_dropped.fit(X, y)\n    assert len(estimator_dropped.named_estimators) == 3\n    assert estimator_dropped.named_estimators.svm == \"drop\"\n    assert len(estimator_dropped.named_estimators_) == 3\n    assert sorted(list(estimator_dropped.named_estimators_.keys())) == sorted(\n        [\"lr\", \"svm\", \"rf\"]\n    )\n    for sub_est in estimator_dropped.named_estimators_:\n        # check that the correspondence is correct\n        assert not isinstance(sub_est, type(estimator.named_estimators.svm))\n\n    # check that we can set the parameters of the underlying classifier\n    estimator.set_params(svm__C=10.0)\n    estimator.set_params(rf__max_depth=5)\n    assert (\n        estimator.get_params()[\"svm__C\"]\n        == estimator.get_params()[\"svm\"].get_params()[\"C\"]\n    )\n    assert (\n        estimator.get_params()[\"rf__max_depth\"]\n        == estimator.get_params()[\"rf\"].get_params()[\"max_depth\"]\n    )\n\n\n@pytest.mark.parametrize(\n    \"Ensemble\",\n    [VotingClassifier, StackingRegressor, VotingRegressor],\n)\ndef test_ensemble_heterogeneous_estimators_type(Ensemble):\n    # check that ensemble will fail during validation if the underlying\n    # estimators are not of the same type (i.e. classifier or regressor)\n    # StackingClassifier can have an underlying regresor so it's not checked\n    if issubclass(Ensemb"}, {"start_line": 9000, "end_line": 10604, "belongs_to": {"file_name": "_base.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/ensemble", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "  self : object\n            Estimator instance.\n        \"\"\"\n        super()._set_params(\"estimators\", **params)\n        return self\n\n    def get_params(self, deep=True):\n        \"\"\"\n        Get the parameters of an estimator from the ensemble.\n\n        Returns the parameters given in the constructor as well as the\n        estimators contained within the `estimators` parameter.\n\n        Parameters\n        ----------\n        deep : bool, default=True\n            Setting it to True gets the various estimators and the parameters\n            of the estimators as well.\n\n        Returns\n        -------\n        params : dict\n            Parameter and estimator names mapped to their values or parameter\n            names mapped to their values.\n        \"\"\"\n        return super()._get_params(\"estimators\", deep=deep)\n\n    def __sklearn_tags__(self):\n        tags = super().__sklearn_tags__()\n        try:\n            tags.input_tags.allow_nan = all(\n                get_tags(est[1]).input_tags.allow_nan if est[1] != \"drop\" else True\n                for est in self.estimators\n            )\n            tags.input_tags.sparse = all(\n                get_tags(est[1]).input_tags.sparse if est[1] != \"drop\" else True\n                for est in self.estimators\n            )\n        except Exception:\n            # If `estimators` does not comply with our API (list of tuples) then it will\n            # fail. In this case, we assume that `allow_nan` and `sparse` are False but\n            # the parameter validation will raise an error during `fit`.\n            pass  # pragma: no cover\n        return tags\n"}, {"start_line": 1000, "end_line": 3000, "belongs_to": {"file_name": "metaestimators.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/utils", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "ors is not a list of\n            # (name, estimator) and ignore ValueError when the list is not\n            # formatted correctly. This is to prevent errors when calling\n            # `set_params`. `BaseEstimator.set_params` calls `get_params` which\n            # can error for invalid values for `estimators`.\n            return out\n\n        for name, estimator in estimators:\n            if hasattr(estimator, \"get_params\"):\n                for key, value in estimator.get_params(deep=True).items():\n                    out[\"%s__%s\" % (name, key)] = value\n        return out\n\n    def _set_params(self, attr, **params):\n        # Ensure strict ordering of parameter setting:\n        # 1. All steps\n        if attr in params:\n            setattr(self, attr, params.pop(attr))\n        # 2. Replace items with estimators in params\n        items = getattr(self, attr)\n        if isinstance(items, list) and items:\n            # Get item names used to identify valid names in params\n            # `zip` raises a TypeError when `items` does not contains\n            # elements of length 2\n            with suppress(TypeError):\n                item_names, _ = zip(*items)\n                for name in list(params.keys()):\n                    if \"__\" not in name and name in item_names:\n                        self._replace_estimator(attr, name, params.pop(name))\n\n        # 3. Step parameters and other initialisation arguments\n        super().set_params(**params)\n        return self\n\n    def _replace_estimator(self, attr, name, new_val):\n        # assumes `name` is a valid estimator name\n        new_estimators = list(getattr(self, attr))\n        for i, (estimator_name, _) in enumerate(new_estimators):\n            if estimator_name == name:\n                new_estimators[i] = (name, new_val)\n                break\n        setattr(self, attr, new_estimators)\n\n    def _validate_names(self, names):\n        if len(set(names)) != len(names):\n            raise ValueError(\"Names provided are not unique:"}, {"start_line": 6000, "end_line": 8000, "belongs_to": {"file_name": "_base.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/ensemble", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": ", [0] + starts.tolist()\n\n\nclass _BaseHeterogeneousEnsemble(\n    MetaEstimatorMixin, _BaseComposition, metaclass=ABCMeta\n):\n    \"\"\"Base class for heterogeneous ensemble of learners.\n\n    Parameters\n    ----------\n    estimators : list of (str, estimator) tuples\n        The ensemble of estimators to use in the ensemble. Each element of the\n        list is defined as a tuple of string (i.e. name of the estimator) and\n        an estimator instance. An estimator can be set to `'drop'` using\n        `set_params`.\n\n    Attributes\n    ----------\n    estimators_ : list of estimators\n        The elements of the estimators parameter, having been fitted on the\n        training data. If an estimator has been set to `'drop'`, it will not\n        appear in `estimators_`.\n    \"\"\"\n\n    @property\n    def named_estimators(self):\n        \"\"\"Dictionary to access any fitted sub-estimators by name.\n\n        Returns\n        -------\n        :class:`~sklearn.utils.Bunch`\n        \"\"\"\n        return Bunch(**dict(self.estimators))\n\n    @abstractmethod\n    def __init__(self, estimators):\n        self.estimators = estimators\n\n    def _validate_estimators(self):\n        if len(self.estimators) == 0 or not all(\n            isinstance(item, (tuple, list)) and isinstance(item[0], str)\n            for item in self.estimators\n        ):\n            raise ValueError(\n                \"Invalid 'estimators' attribute, 'estimators' should be a \"\n                \"non-empty list of (string, estimator) tuples.\"\n            )\n        names, estimators = zip(*self.estimators)\n        # defined by MetaEstimatorMixin\n        self._validate_names(names)\n\n        has_estimator = any(est != \"drop\" for est in estimators)\n        if not has_estimator:\n            raise ValueError(\n                \"All estimators are dropped. At least one is required \"\n                \"to be an estimator.\"\n            )\n\n        is_estimator_type = is_classifier if is_classifier(self) else is_regressor\n\n        for est in estimators:\n  "}, {"start_line": 2000, "end_line": 4000, "belongs_to": {"file_name": "test_common.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/ensemble/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "rf\", RandomForestRegressor(n_estimators=5, max_depth=3)),\n                ]\n            ),\n        ),\n    ],\n    ids=[\n        \"stacking-classifier\",\n        \"voting-classifier\",\n        \"stacking-regressor\",\n        \"voting-regressor\",\n    ],\n)\ndef test_ensemble_heterogeneous_estimators_behavior(X, y, estimator):\n    # check that the behavior of `estimators`, `estimators_`,\n    # `named_estimators`, `named_estimators_` is consistent across all\n    # ensemble classes and when using `set_params()`.\n\n    # before fit\n    assert \"svm\" in estimator.named_estimators\n    assert estimator.named_estimators.svm is estimator.estimators[1][1]\n    assert estimator.named_estimators.svm is estimator.named_estimators[\"svm\"]\n\n    # check fitted attributes\n    estimator.fit(X, y)\n    assert len(estimator.named_estimators) == 3\n    assert len(estimator.named_estimators_) == 3\n    assert sorted(list(estimator.named_estimators_.keys())) == sorted(\n        [\"lr\", \"svm\", \"rf\"]\n    )\n\n    # check that set_params() does not add a new attribute\n    estimator_new_params = clone(estimator)\n    svm_estimator = SVC() if is_classifier(estimator) else SVR()\n    estimator_new_params.set_params(svm=svm_estimator).fit(X, y)\n    assert not hasattr(estimator_new_params, \"svm\")\n    assert (\n        estimator_new_params.named_estimators.lr.get_params()\n        == estimator.named_estimators.lr.get_params()\n    )\n    assert (\n        estimator_new_params.named_estimators.rf.get_params()\n        == estimator.named_estimators.rf.get_params()\n    )\n\n    # check the behavior when setting an dropping an estimator\n    estimator_dropped = clone(estimator)\n    estimator_dropped.set_params(svm=\"drop\")\n    estimator_dropped.fit(X, y)\n    assert len(estimator_dropped.named_estimators) == 3\n    assert estimator_dropped.named_estimators.svm == \"drop\"\n    assert len(estimator_dropped.named_estimators_) == 3\n    assert sorted(list(estimator_dropped.named_estimators_.keys())) == sorted(\n        [\"lr\", \"svm\", \"rf\"]\n    )\n"}, {"start_line": 2000, "end_line": 4000, "belongs_to": {"file_name": "metaestimators.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/utils", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "aises a TypeError when `items` does not contains\n            # elements of length 2\n            with suppress(TypeError):\n                item_names, _ = zip(*items)\n                for name in list(params.keys()):\n                    if \"__\" not in name and name in item_names:\n                        self._replace_estimator(attr, name, params.pop(name))\n\n        # 3. Step parameters and other initialisation arguments\n        super().set_params(**params)\n        return self\n\n    def _replace_estimator(self, attr, name, new_val):\n        # assumes `name` is a valid estimator name\n        new_estimators = list(getattr(self, attr))\n        for i, (estimator_name, _) in enumerate(new_estimators):\n            if estimator_name == name:\n                new_estimators[i] = (name, new_val)\n                break\n        setattr(self, attr, new_estimators)\n\n    def _validate_names(self, names):\n        if len(set(names)) != len(names):\n            raise ValueError(\"Names provided are not unique: {0!r}\".format(list(names)))\n        invalid_names = set(names).intersection(self.get_params(deep=False))\n        if invalid_names:\n            raise ValueError(\n                \"Estimator names conflict with constructor arguments: {0!r}\".format(\n                    sorted(invalid_names)\n                )\n            )\n        invalid_names = [name for name in names if \"__\" in name]\n        if invalid_names:\n            raise ValueError(\n                \"Estimator names must not contain __: got {0!r}\".format(invalid_names)\n            )\n\n\ndef _safe_split(estimator, X, y, indices, train_indices=None):\n    \"\"\"Create subset of dataset and properly handle kernels.\n\n    Slice X, y according to indices for cross-validation, but take care of\n    precomputed kernel-matrices or pairwise affinities / distances.\n\n    If ``estimator._pairwise is True``, X needs to be square and\n    we slice rows and columns. If ``train_indices`` is not None,\n    we slice rows using ``indices`` (assumed the test se"}, {"start_line": 5000, "end_line": 7000, "belongs_to": {"file_name": "_base.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/ensemble", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "set_random_states(estimator, random_state)\n\n        if append:\n            self.estimators_.append(estimator)\n\n        return estimator\n\n    def __len__(self):\n        \"\"\"Return the number of estimators in the ensemble.\"\"\"\n        return len(self.estimators_)\n\n    def __getitem__(self, index):\n        \"\"\"Return the index'th estimator in the ensemble.\"\"\"\n        return self.estimators_[index]\n\n    def __iter__(self):\n        \"\"\"Return iterator over estimators in the ensemble.\"\"\"\n        return iter(self.estimators_)\n\n\ndef _partition_estimators(n_estimators, n_jobs):\n    \"\"\"Private function used to partition estimators between jobs.\"\"\"\n    # Compute the number of jobs\n    n_jobs = min(effective_n_jobs(n_jobs), n_estimators)\n\n    # Partition estimators between jobs\n    n_estimators_per_job = np.full(n_jobs, n_estimators // n_jobs, dtype=int)\n    n_estimators_per_job[: n_estimators % n_jobs] += 1\n    starts = np.cumsum(n_estimators_per_job)\n\n    return n_jobs, n_estimators_per_job.tolist(), [0] + starts.tolist()\n\n\nclass _BaseHeterogeneousEnsemble(\n    MetaEstimatorMixin, _BaseComposition, metaclass=ABCMeta\n):\n    \"\"\"Base class for heterogeneous ensemble of learners.\n\n    Parameters\n    ----------\n    estimators : list of (str, estimator) tuples\n        The ensemble of estimators to use in the ensemble. Each element of the\n        list is defined as a tuple of string (i.e. name of the estimator) and\n        an estimator instance. An estimator can be set to `'drop'` using\n        `set_params`.\n\n    Attributes\n    ----------\n    estimators_ : list of estimators\n        The elements of the estimators parameter, having been fitted on the\n        training data. If an estimator has been set to `'drop'`, it will not\n        appear in `estimators_`.\n    \"\"\"\n\n    @property\n    def named_estimators(self):\n        \"\"\"Dictionary to access any fitted sub-estimators by name.\n\n        Returns\n        -------\n        :class:`~sklearn.utils.Bunch`\n        \"\"\"\n        return Bunch(**dict("}, {"start_line": 24000, "end_line": 26000, "belongs_to": {"file_name": "_stacking.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/ensemble", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": " if not is_classifier(self.final_estimator_):\n            raise ValueError(\n                \"'final_estimator' parameter should be a classifier. Got {}\".format(\n                    self.final_estimator_\n                )\n            )\n\n    def _validate_estimators(self):\n        \"\"\"Overload the method of `_BaseHeterogeneousEnsemble` to be more\n        lenient towards the type of `estimators`.\n\n        Regressors can be accepted for some cases such as ordinal regression.\n        \"\"\"\n        if len(self.estimators) == 0:\n            raise ValueError(\n                \"Invalid 'estimators' attribute, 'estimators' should be a \"\n                \"non-empty list of (string, estimator) tuples.\"\n            )\n        names, estimators = zip(*self.estimators)\n        self._validate_names(names)\n\n        has_estimator = any(est != \"drop\" for est in estimators)\n        if not has_estimator:\n            raise ValueError(\n                \"All estimators are dropped. At least one is required \"\n                \"to be an estimator.\"\n            )\n\n        return names, estimators\n\n    def fit(self, X, y, **fit_params):\n        \"\"\"Fit the estimators.\n\n        Parameters\n        ----------\n        X : {array-like, sparse matrix} of shape (n_samples, n_features)\n            Training vectors, where `n_samples` is the number of samples and\n            `n_features` is the number of features.\n\n        y : array-like of shape (n_samples,)\n            Target values. Note that `y` will be internally encoded in\n            numerically increasing order or lexicographic order. If the order\n            matter (e.g. for ordinal regression), one should numerically encode\n            the target `y` before calling :term:`fit`.\n\n        **fit_params : dict\n            Parameters to pass to the underlying estimators.\n\n            .. versionadded:: 1.6\n\n                Only available if `enable_metadata_routing=True`, which can be\n                set by using ``sklearn.set_config(enable_metadata_routing="}], "retrieved_count": 10, "cost_time": 0.3549671173095703}
{"question": "Where in the CountVectorizer class initialization is the token_pattern parameter processed and how does its assignment relate to the subsequent tokenizer parameter validation logic?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"start_line": 10000, "end_line": 12000, "belongs_to": {"file_name": "test_text.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/feature_extraction/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "\n\n\ndef test_countvectorizer_custom_vocabulary_gap_index():\n    vocab = {\"pizza\": 1, \"beer\": 2}\n    with pytest.raises(ValueError, match=\"doesn't contain index\"):\n        vect = CountVectorizer(vocabulary=vocab)\n        vect.fit([\"pasta_verdura\"])\n\n\ndef test_countvectorizer_stop_words():\n    cv = CountVectorizer()\n    cv.set_params(stop_words=\"english\")\n    assert cv.get_stop_words() == ENGLISH_STOP_WORDS\n    cv.set_params(stop_words=\"_bad_str_stop_\")\n    with pytest.raises(ValueError):\n        cv.get_stop_words()\n    cv.set_params(stop_words=\"_bad_unicode_stop_\")\n    with pytest.raises(ValueError):\n        cv.get_stop_words()\n    stoplist = [\"some\", \"other\", \"words\"]\n    cv.set_params(stop_words=stoplist)\n    assert cv.get_stop_words() == set(stoplist)\n\n\ndef test_countvectorizer_empty_vocabulary():\n    with pytest.raises(ValueError, match=\"empty vocabulary\"):\n        vect = CountVectorizer(vocabulary=[])\n        vect.fit([\"foo\"])\n\n    with pytest.raises(ValueError, match=\"empty vocabulary\"):\n        v = CountVectorizer(max_df=1.0, stop_words=\"english\")\n        # fit on stopwords only\n        v.fit([\"to be or not to be\", \"and me too\", \"and so do you\"])\n\n\ndef test_fit_countvectorizer_twice():\n    cv = CountVectorizer()\n    X1 = cv.fit_transform(ALL_FOOD_DOCS[:5])\n    X2 = cv.fit_transform(ALL_FOOD_DOCS[5:])\n    assert X1.shape[1] != X2.shape[1]\n\n\ndef test_countvectorizer_custom_token_pattern():\n    \"\"\"Check `get_feature_names_out()` when a custom token pattern is passed.\n    Non-regression test for:\n    https://github.com/scikit-learn/scikit-learn/issues/12971\n    \"\"\"\n    corpus = [\n        \"This is the 1st document in my corpus.\",\n        \"This document is the 2nd sample.\",\n        \"And this is the 3rd one.\",\n        \"Is this the 4th document?\",\n    ]\n    token_pattern = r\"[0-9]{1,3}(?:st|nd|rd|th)\\s\\b(\\w{2,})\\b\"\n    vectorizer = CountVectorizer(token_pattern=token_pattern)\n    vectorizer.fit_transform(corpus)\n    expected = [\"document\", \"one\", \"sample\"]\n    feature_"}, {"start_line": 67000, "end_line": 69000, "belongs_to": {"file_name": "text.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/feature_extraction", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "_pattern then the\n        captured group content, not the entire match, becomes the token.\n        At most one capturing group is permitted.\n\n    ngram_range : tuple (min_n, max_n), default=(1, 1)\n        The lower and upper boundary of the range of n-values for different\n        n-grams to be extracted. All values of n such that min_n <= n <= max_n\n        will be used. For example an ``ngram_range`` of ``(1, 1)`` means only\n        unigrams, ``(1, 2)`` means unigrams and bigrams, and ``(2, 2)`` means\n        only bigrams.\n        Only applies if ``analyzer`` is not callable.\n\n    max_df : float or int, default=1.0\n        When building the vocabulary ignore terms that have a document\n        frequency strictly higher than the given threshold (corpus-specific\n        stop words).\n        If float in range [0.0, 1.0], the parameter represents a proportion of\n        documents, integer absolute counts.\n        This parameter is ignored if vocabulary is not None.\n\n    min_df : float or int, default=1\n        When building the vocabulary ignore terms that have a document\n        frequency strictly lower than the given threshold. This value is also\n        called cut-off in the literature.\n        If float in range of [0.0, 1.0], the parameter represents a proportion\n        of documents, integer absolute counts.\n        This parameter is ignored if vocabulary is not None.\n\n    max_features : int, default=None\n        If not None, build a vocabulary that only consider the top\n        `max_features` ordered by term frequency across the corpus.\n        Otherwise, all features are used.\n\n        This parameter is ignored if vocabulary is not None.\n\n    vocabulary : Mapping or iterable, default=None\n        Either a Mapping (e.g., a dict) where keys are terms and values are\n        indices in the feature matrix, or an iterable over terms. If not\n        given, a vocabulary is determined from the input documents.\n\n    binary : bool, default=False\n        If True, all non-zer"}, {"start_line": 11000, "end_line": 13000, "belongs_to": {"file_name": "test_text.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/feature_extraction/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "ary\"):\n        v = CountVectorizer(max_df=1.0, stop_words=\"english\")\n        # fit on stopwords only\n        v.fit([\"to be or not to be\", \"and me too\", \"and so do you\"])\n\n\ndef test_fit_countvectorizer_twice():\n    cv = CountVectorizer()\n    X1 = cv.fit_transform(ALL_FOOD_DOCS[:5])\n    X2 = cv.fit_transform(ALL_FOOD_DOCS[5:])\n    assert X1.shape[1] != X2.shape[1]\n\n\ndef test_countvectorizer_custom_token_pattern():\n    \"\"\"Check `get_feature_names_out()` when a custom token pattern is passed.\n    Non-regression test for:\n    https://github.com/scikit-learn/scikit-learn/issues/12971\n    \"\"\"\n    corpus = [\n        \"This is the 1st document in my corpus.\",\n        \"This document is the 2nd sample.\",\n        \"And this is the 3rd one.\",\n        \"Is this the 4th document?\",\n    ]\n    token_pattern = r\"[0-9]{1,3}(?:st|nd|rd|th)\\s\\b(\\w{2,})\\b\"\n    vectorizer = CountVectorizer(token_pattern=token_pattern)\n    vectorizer.fit_transform(corpus)\n    expected = [\"document\", \"one\", \"sample\"]\n    feature_names_out = vectorizer.get_feature_names_out()\n    assert_array_equal(feature_names_out, expected)\n\n\ndef test_countvectorizer_custom_token_pattern_with_several_group():\n    \"\"\"Check that we raise an error if token pattern capture several groups.\n    Non-regression test for:\n    https://github.com/scikit-learn/scikit-learn/issues/12971\n    \"\"\"\n    corpus = [\n        \"This is the 1st document in my corpus.\",\n        \"This document is the 2nd sample.\",\n        \"And this is the 3rd one.\",\n        \"Is this the 4th document?\",\n    ]\n\n    token_pattern = r\"([0-9]{1,3}(?:st|nd|rd|th))\\s\\b(\\w{2,})\\b\"\n    err_msg = \"More than 1 capturing group in token pattern\"\n    vectorizer = CountVectorizer(token_pattern=token_pattern)\n    with pytest.raises(ValueError, match=err_msg):\n        vectorizer.fit(corpus)\n\n\ndef test_countvectorizer_uppercase_in_vocab():\n    # Check that the check for uppercase in the provided vocabulary is only done at fit\n    # time and not at transform time (#21251)\n    vocabular"}, {"start_line": 65000, "end_line": 67000, "belongs_to": {"file_name": "text.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/feature_extraction", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "r`` is not callable.\n\n    tokenizer : callable, default=None\n        Override the string tokenization step while preserving the\n        preprocessing and n-grams generation steps.\n        Only applies if ``analyzer == 'word'``.\n\n    analyzer : {'word', 'char', 'char_wb'} or callable, default='word'\n        Whether the feature should be made of word or character n-grams.\n        Option 'char_wb' creates character n-grams only from text inside\n        word boundaries; n-grams at the edges of words are padded with space.\n\n        If a callable is passed it is used to extract the sequence of features\n        out of the raw, unprocessed input.\n\n        .. versionchanged:: 0.21\n            Since v0.21, if ``input`` is ``'filename'`` or ``'file'``, the data\n            is first read from the file and then passed to the given callable\n            analyzer.\n\n    stop_words : {'english'}, list, default=None\n        If a string, it is passed to _check_stop_list and the appropriate stop\n        list is returned. 'english' is currently the only supported string\n        value.\n        There are several known issues with 'english' and you should\n        consider an alternative (see :ref:`stop_words`).\n\n        If a list, that list is assumed to contain stop words, all of which\n        will be removed from the resulting tokens.\n        Only applies if ``analyzer == 'word'``.\n\n        If None, no stop words will be used. In this case, setting `max_df`\n        to a higher value, such as in the range (0.7, 1.0), can automatically detect\n        and filter stop words based on intra corpus document frequency of terms.\n\n    token_pattern : str, default=r\"(?u)\\\\b\\\\w\\\\w+\\\\b\"\n        Regular expression denoting what constitutes a \"token\", only used\n        if ``analyzer == 'word'``. The default regexp selects tokens of 2\n        or more alphanumeric characters (punctuation is completely ignored\n        and always treated as a token separator).\n\n        If there is a capturing group in token"}, {"start_line": 34000, "end_line": 36000, "belongs_to": {"file_name": "test_text.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/feature_extraction/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "      assert_allclose_dense_sparse(\n            copy.fit_transform(JUNK_FOOD_DOCS),\n            orig.fit_transform(JUNK_FOOD_DOCS),\n        )\n\n\n@pytest.mark.parametrize(\n    \"factory\",\n    [\n        CountVectorizer.build_analyzer,\n        CountVectorizer.build_preprocessor,\n        CountVectorizer.build_tokenizer,\n    ],\n)\ndef test_pickling_built_processors(factory):\n    \"\"\"Tokenizers cannot be pickled\n    https://github.com/scikit-learn/scikit-learn/issues/12833\n    \"\"\"\n    vec = CountVectorizer()\n    function = factory(vec)\n    text = \"J'ai mang du kangourou  ce midi, c'tait pas trs bon.\"\n    roundtripped_function = pickle.loads(pickle.dumps(function))\n    expected = function(text)\n    result = roundtripped_function(text)\n    assert result == expected\n\n\ndef test_countvectorizer_vocab_sets_when_pickling():\n    # ensure that vocabulary of type set is coerced to a list to\n    # preserve iteration ordering after deserialization\n    rng = np.random.RandomState(0)\n    vocab_words = np.array(\n        [\n            \"beer\",\n            \"burger\",\n            \"celeri\",\n            \"coke\",\n            \"pizza\",\n            \"salad\",\n            \"sparkling\",\n            \"tomato\",\n            \"water\",\n        ]\n    )\n    for x in range(0, 100):\n        vocab_set = set(rng.choice(vocab_words, size=5, replace=False))\n        cv = CountVectorizer(vocabulary=vocab_set)\n        unpickled_cv = pickle.loads(pickle.dumps(cv))\n        cv.fit(ALL_FOOD_DOCS)\n        unpickled_cv.fit(ALL_FOOD_DOCS)\n        assert_array_equal(\n            cv.get_feature_names_out(), unpickled_cv.get_feature_names_out()\n        )\n\n\ndef test_countvectorizer_vocab_dicts_when_pickling():\n    rng = np.random.RandomState(0)\n    vocab_words = np.array(\n        [\n            \"beer\",\n            \"burger\",\n            \"celeri\",\n            \"coke\",\n            \"pizza\",\n            \"salad\",\n            \"sparkling\",\n            \"tomato\",\n            \"water\",\n        ]\n    )\n    for x in range(0, 100):\n        vocab_dic"}, {"start_line": 35000, "end_line": 37000, "belongs_to": {"file_name": "text.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/feature_extraction", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "d from the resulting tokens.\n        Only applies if ``analyzer == 'word'``.\n\n        If None, no stop words will be used. In this case, setting `max_df`\n        to a higher value, such as in the range (0.7, 1.0), can automatically detect\n        and filter stop words based on intra corpus document frequency of terms.\n\n    token_pattern : str or None, default=r\"(?u)\\\\b\\\\w\\\\w+\\\\b\"\n        Regular expression denoting what constitutes a \"token\", only used\n        if ``analyzer == 'word'``. The default regexp select tokens of 2\n        or more alphanumeric characters (punctuation is completely ignored\n        and always treated as a token separator).\n\n        If there is a capturing group in token_pattern then the\n        captured group content, not the entire match, becomes the token.\n        At most one capturing group is permitted.\n\n    ngram_range : tuple (min_n, max_n), default=(1, 1)\n        The lower and upper boundary of the range of n-values for different\n        word n-grams or char n-grams to be extracted. All values of n such\n        such that min_n <= n <= max_n will be used. For example an\n        ``ngram_range`` of ``(1, 1)`` means only unigrams, ``(1, 2)`` means\n        unigrams and bigrams, and ``(2, 2)`` means only bigrams.\n        Only applies if ``analyzer`` is not callable.\n\n    analyzer : {'word', 'char', 'char_wb'} or callable, default='word'\n        Whether the feature should be made of word n-gram or character\n        n-grams.\n        Option 'char_wb' creates character n-grams only from text inside\n        word boundaries; n-grams at the edges of words are padded with space.\n\n        If a callable is passed it is used to extract the sequence of features\n        out of the raw, unprocessed input.\n\n        .. versionchanged:: 0.21\n\n        Since v0.21, if ``input`` is ``filename`` or ``file``, the data is\n        first read from the file and then passed to the given callable\n        analyzer.\n\n    max_df : float in range [0.0, 1.0] or int, default"}, {"start_line": 21000, "end_line": 23000, "belongs_to": {"file_name": "text.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/feature_extraction", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "\n    strip_accents : {'ascii', 'unicode'} or callable, default=None\n        Remove accents and perform other character normalization\n        during the preprocessing step.\n        'ascii' is a fast method that only works on characters that have\n        a direct ASCII mapping.\n        'unicode' is a slightly slower method that works on any character.\n        None (default) means no character normalization is performed.\n\n        Both 'ascii' and 'unicode' use NFKD normalization from\n        :func:`unicodedata.normalize`.\n\n    lowercase : bool, default=True\n        Convert all characters to lowercase before tokenizing.\n\n    preprocessor : callable, default=None\n        Override the preprocessing (string transformation) stage while\n        preserving the tokenizing and n-grams generation steps.\n        Only applies if ``analyzer`` is not callable.\n\n    tokenizer : callable, default=None\n        Override the string tokenization step while preserving the\n        preprocessing and n-grams generation steps.\n        Only applies if ``analyzer == 'word'``.\n\n    stop_words : {'english'}, list, default=None\n        If 'english', a built-in stop word list for English is used.\n        There are several known issues with 'english' and you should\n        consider an alternative (see :ref:`stop_words`).\n\n        If a list, that list is assumed to contain stop words, all of which\n        will be removed from the resulting tokens.\n        Only applies if ``analyzer == 'word'``.\n\n    token_pattern : str or None, default=r\"(?u)\\\\b\\\\w\\\\w+\\\\b\"\n        Regular expression denoting what constitutes a \"token\", only used\n        if ``analyzer == 'word'``. The default regexp selects tokens of 2\n        or more alphanumeric characters (punctuation is completely ignored\n        and always treated as a token separator).\n\n        If there is a capturing group in token_pattern then the\n        captured group content, not the entire match, becomes the token.\n        At most one capturing group is per"}, {"start_line": 48000, "end_line": 50000, "belongs_to": {"file_name": "test_text.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/feature_extraction/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "   \"'token_pattern'\",\n            \"'tokenizer'\",\n            \"is not None\",\n        ),\n        (\n            None,\n            None,\n            lambda s: s.upper(),\n            (1, 1),\n            r\"\\w+\",\n            lambda s: s.upper(),\n            \"'preprocessor'\",\n            \"'analyzer'\",\n            \"is callable\",\n        ),\n        (\n            None,\n            None,\n            None,\n            (1, 2),\n            None,\n            lambda s: s.upper(),\n            \"'ngram_range'\",\n            \"'analyzer'\",\n            \"is callable\",\n        ),\n        (\n            None,\n            None,\n            None,\n            (1, 1),\n            r\"\\w+\",\n            \"char\",\n            \"'token_pattern'\",\n            \"'analyzer'\",\n            \"!= 'word'\",\n        ),\n    ],\n)\ndef test_unused_parameters_warn(\n    Vectorizer,\n    stop_words,\n    tokenizer,\n    preprocessor,\n    ngram_range,\n    token_pattern,\n    analyzer,\n    unused_name,\n    ovrd_name,\n    ovrd_msg,\n):\n    train_data = JUNK_FOOD_DOCS\n    # setting parameter and checking for corresponding warning messages\n    vect = Vectorizer()\n    vect.set_params(\n        stop_words=stop_words,\n        tokenizer=tokenizer,\n        preprocessor=preprocessor,\n        ngram_range=ngram_range,\n        token_pattern=token_pattern,\n        analyzer=analyzer,\n    )\n    msg = \"The parameter %s will not be used since %s %s\" % (\n        unused_name,\n        ovrd_name,\n        ovrd_msg,\n    )\n    with pytest.warns(UserWarning, match=msg):\n        vect.fit(train_data)\n\n\n@pytest.mark.parametrize(\n    \"Vectorizer, X\",\n    (\n        (HashingVectorizer, [{\"foo\": 1, \"bar\": 2}, {\"foo\": 3, \"baz\": 1}]),\n        (CountVectorizer, JUNK_FOOD_DOCS),\n    ),\n)\ndef test_n_features_in(Vectorizer, X):\n    # For vectorizers, n_features_in_ does not make sense\n    vectorizer = Vectorizer()\n    assert not hasattr(vectorizer, \"n_features_in_\")\n    vectorizer.fit(X)\n    assert not hasattr(vectorizer, \"n_features_in_\")\n\n\ndef test_tie_breaking_sample"}, {"start_line": 66000, "end_line": 68000, "belongs_to": {"file_name": "text.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/feature_extraction", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "st is returned. 'english' is currently the only supported string\n        value.\n        There are several known issues with 'english' and you should\n        consider an alternative (see :ref:`stop_words`).\n\n        If a list, that list is assumed to contain stop words, all of which\n        will be removed from the resulting tokens.\n        Only applies if ``analyzer == 'word'``.\n\n        If None, no stop words will be used. In this case, setting `max_df`\n        to a higher value, such as in the range (0.7, 1.0), can automatically detect\n        and filter stop words based on intra corpus document frequency of terms.\n\n    token_pattern : str, default=r\"(?u)\\\\b\\\\w\\\\w+\\\\b\"\n        Regular expression denoting what constitutes a \"token\", only used\n        if ``analyzer == 'word'``. The default regexp selects tokens of 2\n        or more alphanumeric characters (punctuation is completely ignored\n        and always treated as a token separator).\n\n        If there is a capturing group in token_pattern then the\n        captured group content, not the entire match, becomes the token.\n        At most one capturing group is permitted.\n\n    ngram_range : tuple (min_n, max_n), default=(1, 1)\n        The lower and upper boundary of the range of n-values for different\n        n-grams to be extracted. All values of n such that min_n <= n <= max_n\n        will be used. For example an ``ngram_range`` of ``(1, 1)`` means only\n        unigrams, ``(1, 2)`` means unigrams and bigrams, and ``(2, 2)`` means\n        only bigrams.\n        Only applies if ``analyzer`` is not callable.\n\n    max_df : float or int, default=1.0\n        When building the vocabulary ignore terms that have a document\n        frequency strictly higher than the given threshold (corpus-specific\n        stop words).\n        If float in range [0.0, 1.0], the parameter represents a proportion of\n        documents, integer absolute counts.\n        This parameter is ignored if vocabulary is not None.\n\n    min_df : float or i"}, {"start_line": 49000, "end_line": 51000, "belongs_to": {"file_name": "test_text.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/feature_extraction/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": " JUNK_FOOD_DOCS\n    # setting parameter and checking for corresponding warning messages\n    vect = Vectorizer()\n    vect.set_params(\n        stop_words=stop_words,\n        tokenizer=tokenizer,\n        preprocessor=preprocessor,\n        ngram_range=ngram_range,\n        token_pattern=token_pattern,\n        analyzer=analyzer,\n    )\n    msg = \"The parameter %s will not be used since %s %s\" % (\n        unused_name,\n        ovrd_name,\n        ovrd_msg,\n    )\n    with pytest.warns(UserWarning, match=msg):\n        vect.fit(train_data)\n\n\n@pytest.mark.parametrize(\n    \"Vectorizer, X\",\n    (\n        (HashingVectorizer, [{\"foo\": 1, \"bar\": 2}, {\"foo\": 3, \"baz\": 1}]),\n        (CountVectorizer, JUNK_FOOD_DOCS),\n    ),\n)\ndef test_n_features_in(Vectorizer, X):\n    # For vectorizers, n_features_in_ does not make sense\n    vectorizer = Vectorizer()\n    assert not hasattr(vectorizer, \"n_features_in_\")\n    vectorizer.fit(X)\n    assert not hasattr(vectorizer, \"n_features_in_\")\n\n\ndef test_tie_breaking_sample_order_invariance():\n    # Checks the sample order invariance when setting max_features\n    # non-regression test for #17939\n    vec = CountVectorizer(max_features=1)\n    vocab1 = vec.fit([\"hello\", \"world\"]).vocabulary_\n    vocab2 = vec.fit([\"world\", \"hello\"]).vocabulary_\n    assert vocab1 == vocab2\n\n\ndef test_nonnegative_hashing_vectorizer_result_indices():\n    # add test for pr 19035\n    hashing = HashingVectorizer(n_features=1000000, ngram_range=(2, 3))\n    indices = hashing.transform([\"22pcs efuture\"]).indices\n    assert indices[0] >= 0\n\n\n@pytest.mark.parametrize(\n    \"Estimator\", [CountVectorizer, TfidfVectorizer, TfidfTransformer, HashingVectorizer]\n)\ndef test_vectorizers_do_not_have_set_output(Estimator):\n    \"\"\"Check that vectorizers do not define set_output.\"\"\"\n    est = Estimator()\n    assert not hasattr(est, \"set_output\")\n\n\n@pytest.mark.parametrize(\"csr_container\", CSR_CONTAINERS)\ndef test_tfidf_transformer_copy(csr_container):\n    \"\"\"Check the behaviour of TfidfTransformer."}], "retrieved_count": 10, "cost_time": 0.34074902534484863}
{"question": "Where in the codebase do functions conditionally invoke the _CVObjects constraint validation logic, and how does the constraint's is_satisfied_by method propagate validation results through the parameter validation framework?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"start_line": 13000, "end_line": 15000, "belongs_to": {"file_name": "test_param_validation.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/utils/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "     (MissingValues(), np.nan),\n        (MissingValues(), \"missing\"),\n        (HasMethods(\"fit\"), _Estimator(a=0)),\n        (\"cv_object\", 5),\n    ],\n)\ndef test_is_satisfied_by(constraint_declaration, value):\n    \"\"\"Sanity check for the is_satisfied_by method\"\"\"\n    constraint = make_constraint(constraint_declaration)\n    assert constraint.is_satisfied_by(value)\n\n\n@pytest.mark.parametrize(\n    \"constraint_declaration, expected_constraint_class\",\n    [\n        (Interval(Real, 0, 1, closed=\"both\"), Interval),\n        (StrOptions({\"option1\", \"option2\"}), StrOptions),\n        (Options(Real, {0.42, 1.23}), Options),\n        (\"array-like\", _ArrayLikes),\n        (\"sparse matrix\", _SparseMatrices),\n        (\"random_state\", _RandomStates),\n        (None, _NoneConstraint),\n        (callable, _Callables),\n        (int, _InstancesOf),\n        (\"boolean\", _Booleans),\n        (\"verbose\", _VerboseHelper),\n        (MissingValues(numeric_only=True), MissingValues),\n        (HasMethods(\"fit\"), HasMethods),\n        (\"cv_object\", _CVObjects),\n        (\"nan\", _NanConstraint),\n        (np.nan, _NanConstraint),\n    ],\n)\ndef test_make_constraint(constraint_declaration, expected_constraint_class):\n    \"\"\"Check that make_constraint dispatches to the appropriate constraint class\"\"\"\n    constraint = make_constraint(constraint_declaration)\n    assert constraint.__class__ is expected_constraint_class\n\n\ndef test_make_constraint_unknown():\n    \"\"\"Check that an informative error is raised when an unknown constraint is passed\"\"\"\n    with pytest.raises(ValueError, match=\"Unknown constraint\"):\n        make_constraint(\"not a valid constraint\")\n\n\ndef test_validate_params():\n    \"\"\"Check that validate_params works no matter how the arguments are passed\"\"\"\n    with pytest.raises(\n        InvalidParameterError, match=\"The 'a' parameter of _func must be\"\n    ):\n        _func(\"wrong\", c=1)\n\n    with pytest.raises(\n        InvalidParameterError, match=\"The 'b' parameter of _func must be\"\n    ):\n        _func(*"}, {"start_line": 14000, "end_line": 16000, "belongs_to": {"file_name": "test_param_validation.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/utils/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "),\n        (\"cv_object\", _CVObjects),\n        (\"nan\", _NanConstraint),\n        (np.nan, _NanConstraint),\n    ],\n)\ndef test_make_constraint(constraint_declaration, expected_constraint_class):\n    \"\"\"Check that make_constraint dispatches to the appropriate constraint class\"\"\"\n    constraint = make_constraint(constraint_declaration)\n    assert constraint.__class__ is expected_constraint_class\n\n\ndef test_make_constraint_unknown():\n    \"\"\"Check that an informative error is raised when an unknown constraint is passed\"\"\"\n    with pytest.raises(ValueError, match=\"Unknown constraint\"):\n        make_constraint(\"not a valid constraint\")\n\n\ndef test_validate_params():\n    \"\"\"Check that validate_params works no matter how the arguments are passed\"\"\"\n    with pytest.raises(\n        InvalidParameterError, match=\"The 'a' parameter of _func must be\"\n    ):\n        _func(\"wrong\", c=1)\n\n    with pytest.raises(\n        InvalidParameterError, match=\"The 'b' parameter of _func must be\"\n    ):\n        _func(*[1, \"wrong\"], c=1)\n\n    with pytest.raises(\n        InvalidParameterError, match=\"The 'c' parameter of _func must be\"\n    ):\n        _func(1, **{\"c\": \"wrong\"})\n\n    with pytest.raises(\n        InvalidParameterError, match=\"The 'd' parameter of _func must be\"\n    ):\n        _func(1, c=1, d=\"wrong\")\n\n    # check in the presence of extra positional and keyword args\n    with pytest.raises(\n        InvalidParameterError, match=\"The 'b' parameter of _func must be\"\n    ):\n        _func(0, *[\"wrong\", 2, 3], c=4, **{\"e\": 5})\n\n    with pytest.raises(\n        InvalidParameterError, match=\"The 'c' parameter of _func must be\"\n    ):\n        _func(0, *[1, 2, 3], c=\"four\", **{\"e\": 5})\n\n\ndef test_validate_params_missing_params():\n    \"\"\"Check that no error is raised when there are parameters without\n    constraints\n    \"\"\"\n\n    @validate_params({\"a\": [int]}, prefer_skip_nested_validation=True)\n    def func(a, b):\n        pass\n\n    func(1, 2)\n\n\ndef test_decorate_validated_function():\n    \"\"\"Check that "}, {"start_line": 19000, "end_line": 21000, "belongs_to": {"file_name": "test_param_validation.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/utils/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "t the validate_params decorator properly sets the parameter constraints\n    as attribute of the decorated function/method.\n    \"\"\"\n    assert hasattr(_func, \"_skl_parameter_constraints\")\n    assert hasattr(_Class()._method, \"_skl_parameter_constraints\")\n\n\ndef test_boolean_constraint_deprecated_int():\n    \"\"\"Check that validate_params raise a deprecation message but still passes\n    validation when using an int for a parameter accepting a boolean.\n    \"\"\"\n\n    @validate_params({\"param\": [\"boolean\"]}, prefer_skip_nested_validation=True)\n    def f(param):\n        pass\n\n    # True/False and np.bool_(True/False) are valid params\n    f(True)\n    f(np.bool_(False))\n\n\ndef test_no_validation():\n    \"\"\"Check that validation can be skipped for a parameter.\"\"\"\n\n    @validate_params(\n        {\"param1\": [int, None], \"param2\": \"no_validation\"},\n        prefer_skip_nested_validation=True,\n    )\n    def f(param1=None, param2=None):\n        pass\n\n    # param1 is validated\n    with pytest.raises(InvalidParameterError, match=\"The 'param1' parameter\"):\n        f(param1=\"wrong\")\n\n    # param2 is not validated: any type is valid.\n    class SomeType:\n        pass\n\n    f(param2=SomeType)\n    f(param2=SomeType())\n\n\ndef test_pandas_na_constraint_with_pd_na():\n    \"\"\"Add a specific test for checking support for `pandas.NA`.\"\"\"\n    pd = pytest.importorskip(\"pandas\")\n\n    na_constraint = _PandasNAConstraint()\n    assert na_constraint.is_satisfied_by(pd.NA)\n    assert not na_constraint.is_satisfied_by(np.array([1, 2, 3]))\n\n\ndef test_iterable_not_string():\n    \"\"\"Check that a string does not satisfy the _IterableNotString constraint.\"\"\"\n    constraint = _IterablesNotString()\n    assert constraint.is_satisfied_by([1, 2, 3])\n    assert constraint.is_satisfied_by(range(10))\n    assert not constraint.is_satisfied_by(\"some string\")\n\n\ndef test_cv_objects():\n    \"\"\"Check that the _CVObjects constraint accepts all current ways\n    to pass cv objects.\"\"\"\n    constraint = _CVObjects()\n    assert constraint."}, {"start_line": 21000, "end_line": 23000, "belongs_to": {"file_name": "test_param_validation.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/utils/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "is_satisfied_by(5)\n    assert constraint.is_satisfied_by(LeaveOneOut())\n    assert constraint.is_satisfied_by([([1, 2], [3, 4]), ([3, 4], [1, 2])])\n    assert constraint.is_satisfied_by(None)\n    assert not constraint.is_satisfied_by(\"not a CV object\")\n\n\ndef test_third_party_estimator():\n    \"\"\"Check that the validation from a scikit-learn estimator inherited by a third\n    party estimator does not impose a match between the dict of constraints and the\n    parameters of the estimator.\n    \"\"\"\n\n    class ThirdPartyEstimator(_Estimator):\n        def __init__(self, b):\n            self.b = b\n            super().__init__(a=0)\n\n        def fit(self, X=None, y=None):\n            super().fit(X, y)\n\n    # does not raise, even though \"b\" is not in the constraints dict and \"a\" is not\n    # a parameter of the estimator.\n    ThirdPartyEstimator(b=0).fit()\n\n\ndef test_interval_real_not_int():\n    \"\"\"Check for the type RealNotInt in the Interval constraint.\"\"\"\n    constraint = Interval(RealNotInt, 0, 1, closed=\"both\")\n    assert constraint.is_satisfied_by(1.0)\n    assert not constraint.is_satisfied_by(1)\n\n\ndef test_real_not_int():\n    \"\"\"Check for the RealNotInt type.\"\"\"\n    assert isinstance(1.0, RealNotInt)\n    assert not isinstance(1, RealNotInt)\n    assert isinstance(np.float64(1), RealNotInt)\n    assert not isinstance(np.int64(1), RealNotInt)\n\n\ndef test_skip_param_validation():\n    \"\"\"Check that param validation can be skipped using config_context.\"\"\"\n\n    @validate_params({\"a\": [int]}, prefer_skip_nested_validation=True)\n    def f(a):\n        pass\n\n    with pytest.raises(InvalidParameterError, match=\"The 'a' parameter\"):\n        f(a=\"1\")\n\n    # does not raise\n    with config_context(skip_parameter_validation=True):\n        f(a=\"1\")\n\n\n@pytest.mark.parametrize(\"prefer_skip_nested_validation\", [True, False])\ndef test_skip_nested_validation(prefer_skip_nested_validation):\n    \"\"\"Check that nested validation can be skipped.\"\"\"\n\n    @validate_params({\"a\": [int]}, prefer_skip_neste"}, {"start_line": 20000, "end_line": 22000, "belongs_to": {"file_name": "test_param_validation.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/utils/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "arameterError, match=\"The 'param1' parameter\"):\n        f(param1=\"wrong\")\n\n    # param2 is not validated: any type is valid.\n    class SomeType:\n        pass\n\n    f(param2=SomeType)\n    f(param2=SomeType())\n\n\ndef test_pandas_na_constraint_with_pd_na():\n    \"\"\"Add a specific test for checking support for `pandas.NA`.\"\"\"\n    pd = pytest.importorskip(\"pandas\")\n\n    na_constraint = _PandasNAConstraint()\n    assert na_constraint.is_satisfied_by(pd.NA)\n    assert not na_constraint.is_satisfied_by(np.array([1, 2, 3]))\n\n\ndef test_iterable_not_string():\n    \"\"\"Check that a string does not satisfy the _IterableNotString constraint.\"\"\"\n    constraint = _IterablesNotString()\n    assert constraint.is_satisfied_by([1, 2, 3])\n    assert constraint.is_satisfied_by(range(10))\n    assert not constraint.is_satisfied_by(\"some string\")\n\n\ndef test_cv_objects():\n    \"\"\"Check that the _CVObjects constraint accepts all current ways\n    to pass cv objects.\"\"\"\n    constraint = _CVObjects()\n    assert constraint.is_satisfied_by(5)\n    assert constraint.is_satisfied_by(LeaveOneOut())\n    assert constraint.is_satisfied_by([([1, 2], [3, 4]), ([3, 4], [1, 2])])\n    assert constraint.is_satisfied_by(None)\n    assert not constraint.is_satisfied_by(\"not a CV object\")\n\n\ndef test_third_party_estimator():\n    \"\"\"Check that the validation from a scikit-learn estimator inherited by a third\n    party estimator does not impose a match between the dict of constraints and the\n    parameters of the estimator.\n    \"\"\"\n\n    class ThirdPartyEstimator(_Estimator):\n        def __init__(self, b):\n            self.b = b\n            super().__init__(a=0)\n\n        def fit(self, X=None, y=None):\n            super().fit(X, y)\n\n    # does not raise, even though \"b\" is not in the constraints dict and \"a\" is not\n    # a parameter of the estimator.\n    ThirdPartyEstimator(b=0).fit()\n\n\ndef test_interval_real_not_int():\n    \"\"\"Check for the type RealNotInt in the Interval constraint.\"\"\"\n    constraint = Interval(RealNotInt, 0,"}, {"start_line": 5000, "end_line": 7000, "belongs_to": {"file_name": "_param_validation.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/utils", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "straint, str) and constraint == \"cv_object\":\n        return _CVObjects()\n    if isinstance(constraint, Hidden):\n        constraint = make_constraint(constraint.constraint)\n        constraint.hidden = True\n        return constraint\n    if (isinstance(constraint, str) and constraint == \"nan\") or (\n        isinstance(constraint, float) and np.isnan(constraint)\n    ):\n        return _NanConstraint()\n    raise ValueError(f\"Unknown constraint type: {constraint}\")\n\n\ndef validate_params(parameter_constraints, *, prefer_skip_nested_validation):\n    \"\"\"Decorator to validate types and values of functions and methods.\n\n    Parameters\n    ----------\n    parameter_constraints : dict\n        A dictionary `param_name: list of constraints`. See the docstring of\n        `validate_parameter_constraints` for a description of the accepted constraints.\n\n        Note that the *args and **kwargs parameters are not validated and must not be\n        present in the parameter_constraints dictionary.\n\n    prefer_skip_nested_validation : bool\n        If True, the validation of parameters of inner estimators or functions\n        called by the decorated function will be skipped.\n\n        This is useful to avoid validating many times the parameters passed by the\n        user from the public facing API. It's also useful to avoid validating\n        parameters that we pass internally to inner functions that are guaranteed to\n        be valid by the test suite.\n\n        It should be set to True for most functions, except for those that receive\n        non-validated objects as parameters or that are just wrappers around classes\n        because they only perform a partial validation.\n\n    Returns\n    -------\n    decorated_function : function or method\n        The decorated function.\n    \"\"\"\n\n    def decorator(func):\n        # The dict of parameter constraints is set as an attribute of the function\n        # to make it possible to dynamically introspect the constraints for\n        # automatic testing.\n   "}, {"start_line": 12000, "end_line": 14000, "belongs_to": {"file_name": "test_param_validation.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/utils/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "e\",\n    [\n        (Interval(Real, 0, 1, closed=\"both\"), 0.42),\n        (Interval(Integral, 0, None, closed=\"neither\"), 42),\n        (StrOptions({\"a\", \"b\", \"c\"}), \"b\"),\n        (Options(type, {np.float32, np.float64}), np.float64),\n        (callable, lambda x: x + 1),\n        (None, None),\n        (\"array-like\", [[1, 2], [3, 4]]),\n        (\"array-like\", np.array([[1, 2], [3, 4]])),\n        (\"sparse matrix\", csr_matrix([[1, 2], [3, 4]])),\n        *[\n            (\"sparse matrix\", container([[1, 2], [3, 4]]))\n            for container in CSR_CONTAINERS\n        ],\n        (\"random_state\", 0),\n        (\"random_state\", np.random.RandomState(0)),\n        (\"random_state\", None),\n        (_Class, _Class()),\n        (int, 1),\n        (Real, 0.5),\n        (\"boolean\", False),\n        (\"verbose\", 1),\n        (\"nan\", np.nan),\n        (MissingValues(), -1),\n        (MissingValues(), -1.0),\n        (MissingValues(), 2**1028),\n        (MissingValues(), None),\n        (MissingValues(), float(\"nan\")),\n        (MissingValues(), np.nan),\n        (MissingValues(), \"missing\"),\n        (HasMethods(\"fit\"), _Estimator(a=0)),\n        (\"cv_object\", 5),\n    ],\n)\ndef test_is_satisfied_by(constraint_declaration, value):\n    \"\"\"Sanity check for the is_satisfied_by method\"\"\"\n    constraint = make_constraint(constraint_declaration)\n    assert constraint.is_satisfied_by(value)\n\n\n@pytest.mark.parametrize(\n    \"constraint_declaration, expected_constraint_class\",\n    [\n        (Interval(Real, 0, 1, closed=\"both\"), Interval),\n        (StrOptions({\"option1\", \"option2\"}), StrOptions),\n        (Options(Real, {0.42, 1.23}), Options),\n        (\"array-like\", _ArrayLikes),\n        (\"sparse matrix\", _SparseMatrices),\n        (\"random_state\", _RandomStates),\n        (None, _NoneConstraint),\n        (callable, _Callables),\n        (int, _InstancesOf),\n        (\"boolean\", _Booleans),\n        (\"verbose\", _VerboseHelper),\n        (MissingValues(numeric_only=True), MissingValues),\n        (HasMethods(\"fit\"), HasMethods"}, {"start_line": 11000, "end_line": 13000, "belongs_to": {"file_name": "test_param_validation.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/utils/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "cesOf(list),\n        _NoneConstraint(),\n        _RandomStates(),\n        _SparseMatrices(),\n        _Booleans(),\n        _VerboseHelper(),\n        MissingValues(),\n        MissingValues(numeric_only=True),\n        StrOptions({\"a\", \"b\", \"c\"}),\n        Options(Integral, {1, 2, 3}),\n        Interval(Integral, None, None, closed=\"neither\"),\n        Interval(Integral, 0, 10, closed=\"neither\"),\n        Interval(Integral, 0, None, closed=\"neither\"),\n        Interval(Integral, None, 0, closed=\"neither\"),\n        Interval(Real, 0, 1, closed=\"neither\"),\n        Interval(Real, 0, None, closed=\"both\"),\n        Interval(Real, None, 0, closed=\"right\"),\n        HasMethods(\"fit\"),\n        _IterablesNotString(),\n        _CVObjects(),\n    ],\n)\ndef test_generate_valid_param(constraint):\n    \"\"\"Check that the value generated does satisfy the constraint.\"\"\"\n    value = generate_valid_param(constraint)\n    assert constraint.is_satisfied_by(value)\n\n\n@pytest.mark.parametrize(\n    \"constraint_declaration, value\",\n    [\n        (Interval(Real, 0, 1, closed=\"both\"), 0.42),\n        (Interval(Integral, 0, None, closed=\"neither\"), 42),\n        (StrOptions({\"a\", \"b\", \"c\"}), \"b\"),\n        (Options(type, {np.float32, np.float64}), np.float64),\n        (callable, lambda x: x + 1),\n        (None, None),\n        (\"array-like\", [[1, 2], [3, 4]]),\n        (\"array-like\", np.array([[1, 2], [3, 4]])),\n        (\"sparse matrix\", csr_matrix([[1, 2], [3, 4]])),\n        *[\n            (\"sparse matrix\", container([[1, 2], [3, 4]]))\n            for container in CSR_CONTAINERS\n        ],\n        (\"random_state\", 0),\n        (\"random_state\", np.random.RandomState(0)),\n        (\"random_state\", None),\n        (_Class, _Class()),\n        (int, 1),\n        (Real, 0.5),\n        (\"boolean\", False),\n        (\"verbose\", 1),\n        (\"nan\", np.nan),\n        (MissingValues(), -1),\n        (MissingValues(), -1.0),\n        (MissingValues(), 2**1028),\n        (MissingValues(), None),\n        (MissingValues(), float(\"nan\")),\n   "}, {"start_line": 2000, "end_line": 4000, "belongs_to": {"file_name": "_param_validation.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/utils", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "nstraint not meant to be exposed to the user\n\n    params : dict\n        A dictionary `param_name: param_value`. The parameters to validate against the\n        constraints.\n\n    caller_name : str\n        The name of the estimator or function or method that called this function.\n    \"\"\"\n    for param_name, param_val in params.items():\n        # We allow parameters to not have a constraint so that third party estimators\n        # can inherit from sklearn estimators without having to necessarily use the\n        # validation tools.\n        if param_name not in parameter_constraints:\n            continue\n\n        constraints = parameter_constraints[param_name]\n\n        if constraints == \"no_validation\":\n            continue\n\n        constraints = [make_constraint(constraint) for constraint in constraints]\n\n        for constraint in constraints:\n            if constraint.is_satisfied_by(param_val):\n                # this constraint is satisfied, no need to check further.\n                break\n        else:\n            # No constraint is satisfied, raise with an informative message.\n\n            # Ignore constraints that we don't want to expose in the error message,\n            # i.e. options that are for internal purpose or not officially supported.\n            constraints = [\n                constraint for constraint in constraints if not constraint.hidden\n            ]\n\n            if len(constraints) == 1:\n                constraints_str = f\"{constraints[0]}\"\n            else:\n                constraints_str = (\n                    f\"{', '.join([str(c) for c in constraints[:-1]])} or\"\n                    f\" {constraints[-1]}\"\n                )\n\n            raise InvalidParameterError(\n                f\"The {param_name!r} parameter of {caller_name} must be\"\n                f\" {constraints_str}. Got {param_val!r} instead.\"\n            )\n\n\ndef make_constraint(constraint):\n    \"\"\"Convert the constraint into the appropriate Constraint object.\n\n    Parameters\n    ----------\n "}, {"start_line": 8000, "end_line": 10000, "belongs_to": {"file_name": "_param_validation.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/utils", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "            try:\n                with config_context(\n                    skip_parameter_validation=(\n                        prefer_skip_nested_validation or global_skip_validation\n                    )\n                ):\n                    return func(*args, **kwargs)\n            except InvalidParameterError as e:\n                # When the function is just a wrapper around an estimator, we allow\n                # the function to delegate validation to the estimator, but we replace\n                # the name of the estimator by the name of the function in the error\n                # message to avoid confusion.\n                msg = re.sub(\n                    r\"parameter of \\w+ must be\",\n                    f\"parameter of {func.__qualname__} must be\",\n                    str(e),\n                )\n                raise InvalidParameterError(msg) from e\n\n        return wrapper\n\n    return decorator\n\n\nclass RealNotInt(Real):\n    \"\"\"A type that represents reals that are not instances of int.\n\n    Behaves like float, but also works with values extracted from numpy arrays.\n    isintance(1, RealNotInt) -> False\n    isinstance(1.0, RealNotInt) -> True\n    \"\"\"\n\n\nRealNotInt.register(float)\n\n\ndef _type_name(t):\n    \"\"\"Convert type into human readable string.\"\"\"\n    module = t.__module__\n    qualname = t.__qualname__\n    if module == \"builtins\":\n        return qualname\n    elif t == Real:\n        return \"float\"\n    elif t == Integral:\n        return \"int\"\n    return f\"{module}.{qualname}\"\n\n\nclass _Constraint(ABC):\n    \"\"\"Base class for the constraint objects.\"\"\"\n\n    def __init__(self):\n        self.hidden = False\n\n    @abstractmethod\n    def is_satisfied_by(self, val):\n        \"\"\"Whether or not a value satisfies the constraint.\n\n        Parameters\n        ----------\n        val : object\n            The value to check.\n\n        Returns\n        -------\n        is_satisfied : bool\n            Whether or not the constraint is satisfied by this value.\n        \"\"\"\n\n    @abstractm"}], "retrieved_count": 10, "cost_time": 0.34234189987182617}
{"question": "Where in the codebase are the constraint validation classes that invoke InvalidParameterError, and how does the error propagation chain from _Constraint subclasses back to the parameter validation entry points?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"start_line": 2000, "end_line": 4000, "belongs_to": {"file_name": "_param_validation.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/utils", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "nstraint not meant to be exposed to the user\n\n    params : dict\n        A dictionary `param_name: param_value`. The parameters to validate against the\n        constraints.\n\n    caller_name : str\n        The name of the estimator or function or method that called this function.\n    \"\"\"\n    for param_name, param_val in params.items():\n        # We allow parameters to not have a constraint so that third party estimators\n        # can inherit from sklearn estimators without having to necessarily use the\n        # validation tools.\n        if param_name not in parameter_constraints:\n            continue\n\n        constraints = parameter_constraints[param_name]\n\n        if constraints == \"no_validation\":\n            continue\n\n        constraints = [make_constraint(constraint) for constraint in constraints]\n\n        for constraint in constraints:\n            if constraint.is_satisfied_by(param_val):\n                # this constraint is satisfied, no need to check further.\n                break\n        else:\n            # No constraint is satisfied, raise with an informative message.\n\n            # Ignore constraints that we don't want to expose in the error message,\n            # i.e. options that are for internal purpose or not officially supported.\n            constraints = [\n                constraint for constraint in constraints if not constraint.hidden\n            ]\n\n            if len(constraints) == 1:\n                constraints_str = f\"{constraints[0]}\"\n            else:\n                constraints_str = (\n                    f\"{', '.join([str(c) for c in constraints[:-1]])} or\"\n                    f\" {constraints[-1]}\"\n                )\n\n            raise InvalidParameterError(\n                f\"The {param_name!r} parameter of {caller_name} must be\"\n                f\" {constraints_str}. Got {param_val!r} instead.\"\n            )\n\n\ndef make_constraint(constraint):\n    \"\"\"Convert the constraint into the appropriate Constraint object.\n\n    Parameters\n    ----------\n "}, {"start_line": 14000, "end_line": 16000, "belongs_to": {"file_name": "test_param_validation.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/utils/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "),\n        (\"cv_object\", _CVObjects),\n        (\"nan\", _NanConstraint),\n        (np.nan, _NanConstraint),\n    ],\n)\ndef test_make_constraint(constraint_declaration, expected_constraint_class):\n    \"\"\"Check that make_constraint dispatches to the appropriate constraint class\"\"\"\n    constraint = make_constraint(constraint_declaration)\n    assert constraint.__class__ is expected_constraint_class\n\n\ndef test_make_constraint_unknown():\n    \"\"\"Check that an informative error is raised when an unknown constraint is passed\"\"\"\n    with pytest.raises(ValueError, match=\"Unknown constraint\"):\n        make_constraint(\"not a valid constraint\")\n\n\ndef test_validate_params():\n    \"\"\"Check that validate_params works no matter how the arguments are passed\"\"\"\n    with pytest.raises(\n        InvalidParameterError, match=\"The 'a' parameter of _func must be\"\n    ):\n        _func(\"wrong\", c=1)\n\n    with pytest.raises(\n        InvalidParameterError, match=\"The 'b' parameter of _func must be\"\n    ):\n        _func(*[1, \"wrong\"], c=1)\n\n    with pytest.raises(\n        InvalidParameterError, match=\"The 'c' parameter of _func must be\"\n    ):\n        _func(1, **{\"c\": \"wrong\"})\n\n    with pytest.raises(\n        InvalidParameterError, match=\"The 'd' parameter of _func must be\"\n    ):\n        _func(1, c=1, d=\"wrong\")\n\n    # check in the presence of extra positional and keyword args\n    with pytest.raises(\n        InvalidParameterError, match=\"The 'b' parameter of _func must be\"\n    ):\n        _func(0, *[\"wrong\", 2, 3], c=4, **{\"e\": 5})\n\n    with pytest.raises(\n        InvalidParameterError, match=\"The 'c' parameter of _func must be\"\n    ):\n        _func(0, *[1, 2, 3], c=\"four\", **{\"e\": 5})\n\n\ndef test_validate_params_missing_params():\n    \"\"\"Check that no error is raised when there are parameters without\n    constraints\n    \"\"\"\n\n    @validate_params({\"a\": [int]}, prefer_skip_nested_validation=True)\n    def func(a, b):\n        pass\n\n    func(1, 2)\n\n\ndef test_decorate_validated_function():\n    \"\"\"Check that "}, {"start_line": 4000, "end_line": 6000, "belongs_to": {"file_name": "test_public_functions.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "# value for this type.\n        constraints = [make_constraint(constraint) for constraint in constraints]\n\n        for constraint in constraints:\n            try:\n                bad_value = generate_invalid_param_val(constraint)\n            except NotImplementedError:\n                continue\n\n            err_msg = (\n                f\"{func_name} does not raise an informative error message when the \"\n                f\"parameter {param_name} does not have a valid value.\\n\"\n                \"Constraints should be disjoint. For instance \"\n                \"[StrOptions({'a_string'}), str] is not a acceptable set of \"\n                \"constraint because generating an invalid string for the first \"\n                \"constraint will always produce a valid string for the second \"\n                \"constraint.\"\n            )\n\n            with pytest.raises(InvalidParameterError, match=match):\n                func(**{**valid_required_params, param_name: bad_value})\n                pytest.fail(err_msg)\n\n\nPARAM_VALIDATION_FUNCTION_LIST = [\n    \"sklearn.calibration.calibration_curve\",\n    \"sklearn.cluster.cluster_optics_dbscan\",\n    \"sklearn.cluster.compute_optics_graph\",\n    \"sklearn.cluster.estimate_bandwidth\",\n    \"sklearn.cluster.kmeans_plusplus\",\n    \"sklearn.cluster.cluster_optics_xi\",\n    \"sklearn.cluster.ward_tree\",\n    \"sklearn.covariance.empirical_covariance\",\n    \"sklearn.covariance.ledoit_wolf_shrinkage\",\n    \"sklearn.covariance.log_likelihood\",\n    \"sklearn.covariance.shrunk_covariance\",\n    \"sklearn.datasets.clear_data_home\",\n    \"sklearn.datasets.dump_svmlight_file\",\n    \"sklearn.datasets.fetch_20newsgroups\",\n    \"sklearn.datasets.fetch_20newsgroups_vectorized\",\n    \"sklearn.datasets.fetch_california_housing\",\n    \"sklearn.datasets.fetch_covtype\",\n    \"sklearn.datasets.fetch_kddcup99\",\n    \"sklearn.datasets.fetch_lfw_pairs\",\n    \"sklearn.datasets.fetch_lfw_people\",\n    \"sklearn.datasets.fetch_olivetti_faces\",\n    \"sklearn.datasets.fetch_rcv1\",\n    \"sklearn.datasets.fe"}, {"start_line": 3000, "end_line": 5000, "belongs_to": {"file_name": "test_public_functions.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "_name} of {func_name} can't have a\"\n                \" mix of intervals of Integral and Real types. Use the type\"\n                \" RealNotInt instead of Real.\"\n            )\n\n        match = (\n            rf\"The '{param_name}' parameter of {func_name} must be .* Got .* instead.\"\n        )\n\n        err_msg = (\n            f\"{func_name} does not raise an informative error message when the \"\n            f\"parameter {param_name} does not have a valid type. If any Python type \"\n            \"is valid, the constraint should be 'no_validation'.\"\n        )\n\n        # First, check that the error is raised if param doesn't match any valid type.\n        with pytest.raises(InvalidParameterError, match=match):\n            func(**{**valid_required_params, param_name: param_with_bad_type})\n            pytest.fail(err_msg)\n\n        # Then, for constraints that are more than a type constraint, check that the\n        # error is raised if param does match a valid type but does not match any valid\n        # value for this type.\n        constraints = [make_constraint(constraint) for constraint in constraints]\n\n        for constraint in constraints:\n            try:\n                bad_value = generate_invalid_param_val(constraint)\n            except NotImplementedError:\n                continue\n\n            err_msg = (\n                f\"{func_name} does not raise an informative error message when the \"\n                f\"parameter {param_name} does not have a valid value.\\n\"\n                \"Constraints should be disjoint. For instance \"\n                \"[StrOptions({'a_string'}), str] is not a acceptable set of \"\n                \"constraint because generating an invalid string for the first \"\n                \"constraint will always produce a valid string for the second \"\n                \"constraint.\"\n            )\n\n            with pytest.raises(InvalidParameterError, match=match):\n                func(**{**valid_required_params, param_name: bad_value})\n                pytest.fail(err_ms"}, {"start_line": 13000, "end_line": 15000, "belongs_to": {"file_name": "test_param_validation.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/utils/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "     (MissingValues(), np.nan),\n        (MissingValues(), \"missing\"),\n        (HasMethods(\"fit\"), _Estimator(a=0)),\n        (\"cv_object\", 5),\n    ],\n)\ndef test_is_satisfied_by(constraint_declaration, value):\n    \"\"\"Sanity check for the is_satisfied_by method\"\"\"\n    constraint = make_constraint(constraint_declaration)\n    assert constraint.is_satisfied_by(value)\n\n\n@pytest.mark.parametrize(\n    \"constraint_declaration, expected_constraint_class\",\n    [\n        (Interval(Real, 0, 1, closed=\"both\"), Interval),\n        (StrOptions({\"option1\", \"option2\"}), StrOptions),\n        (Options(Real, {0.42, 1.23}), Options),\n        (\"array-like\", _ArrayLikes),\n        (\"sparse matrix\", _SparseMatrices),\n        (\"random_state\", _RandomStates),\n        (None, _NoneConstraint),\n        (callable, _Callables),\n        (int, _InstancesOf),\n        (\"boolean\", _Booleans),\n        (\"verbose\", _VerboseHelper),\n        (MissingValues(numeric_only=True), MissingValues),\n        (HasMethods(\"fit\"), HasMethods),\n        (\"cv_object\", _CVObjects),\n        (\"nan\", _NanConstraint),\n        (np.nan, _NanConstraint),\n    ],\n)\ndef test_make_constraint(constraint_declaration, expected_constraint_class):\n    \"\"\"Check that make_constraint dispatches to the appropriate constraint class\"\"\"\n    constraint = make_constraint(constraint_declaration)\n    assert constraint.__class__ is expected_constraint_class\n\n\ndef test_make_constraint_unknown():\n    \"\"\"Check that an informative error is raised when an unknown constraint is passed\"\"\"\n    with pytest.raises(ValueError, match=\"Unknown constraint\"):\n        make_constraint(\"not a valid constraint\")\n\n\ndef test_validate_params():\n    \"\"\"Check that validate_params works no matter how the arguments are passed\"\"\"\n    with pytest.raises(\n        InvalidParameterError, match=\"The 'a' parameter of _func must be\"\n    ):\n        _func(\"wrong\", c=1)\n\n    with pytest.raises(\n        InvalidParameterError, match=\"The 'b' parameter of _func must be\"\n    ):\n        _func(*"}, {"start_line": 3000, "end_line": 5000, "belongs_to": {"file_name": "_param_validation.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/utils", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "\n        else:\n            # No constraint is satisfied, raise with an informative message.\n\n            # Ignore constraints that we don't want to expose in the error message,\n            # i.e. options that are for internal purpose or not officially supported.\n            constraints = [\n                constraint for constraint in constraints if not constraint.hidden\n            ]\n\n            if len(constraints) == 1:\n                constraints_str = f\"{constraints[0]}\"\n            else:\n                constraints_str = (\n                    f\"{', '.join([str(c) for c in constraints[:-1]])} or\"\n                    f\" {constraints[-1]}\"\n                )\n\n            raise InvalidParameterError(\n                f\"The {param_name!r} parameter of {caller_name} must be\"\n                f\" {constraints_str}. Got {param_val!r} instead.\"\n            )\n\n\ndef make_constraint(constraint):\n    \"\"\"Convert the constraint into the appropriate Constraint object.\n\n    Parameters\n    ----------\n    constraint : object\n        The constraint to convert.\n\n    Returns\n    -------\n    constraint : instance of _Constraint\n        The converted constraint.\n    \"\"\"\n    if isinstance(constraint, str) and constraint == \"array-like\":\n        return _ArrayLikes()\n    if isinstance(constraint, str) and constraint == \"sparse matrix\":\n        return _SparseMatrices()\n    if isinstance(constraint, str) and constraint == \"random_state\":\n        return _RandomStates()\n    if constraint is callable:\n        return _Callables()\n    if constraint is None:\n        return _NoneConstraint()\n    if isinstance(constraint, type):\n        return _InstancesOf(constraint)\n    if isinstance(\n        constraint, (Interval, StrOptions, Options, HasMethods, MissingValues)\n    ):\n        return constraint\n    if isinstance(constraint, str) and constraint == \"boolean\":\n        return _Booleans()\n    if isinstance(constraint, str) and constraint == \"verbose\":\n        return _VerboseHelper()\n    if isinstance(con"}, {"start_line": 8000, "end_line": 10000, "belongs_to": {"file_name": "_param_validation.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/utils", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "            try:\n                with config_context(\n                    skip_parameter_validation=(\n                        prefer_skip_nested_validation or global_skip_validation\n                    )\n                ):\n                    return func(*args, **kwargs)\n            except InvalidParameterError as e:\n                # When the function is just a wrapper around an estimator, we allow\n                # the function to delegate validation to the estimator, but we replace\n                # the name of the estimator by the name of the function in the error\n                # message to avoid confusion.\n                msg = re.sub(\n                    r\"parameter of \\w+ must be\",\n                    f\"parameter of {func.__qualname__} must be\",\n                    str(e),\n                )\n                raise InvalidParameterError(msg) from e\n\n        return wrapper\n\n    return decorator\n\n\nclass RealNotInt(Real):\n    \"\"\"A type that represents reals that are not instances of int.\n\n    Behaves like float, but also works with values extracted from numpy arrays.\n    isintance(1, RealNotInt) -> False\n    isinstance(1.0, RealNotInt) -> True\n    \"\"\"\n\n\nRealNotInt.register(float)\n\n\ndef _type_name(t):\n    \"\"\"Convert type into human readable string.\"\"\"\n    module = t.__module__\n    qualname = t.__qualname__\n    if module == \"builtins\":\n        return qualname\n    elif t == Real:\n        return \"float\"\n    elif t == Integral:\n        return \"int\"\n    return f\"{module}.{qualname}\"\n\n\nclass _Constraint(ABC):\n    \"\"\"Base class for the constraint objects.\"\"\"\n\n    def __init__(self):\n        self.hidden = False\n\n    @abstractmethod\n    def is_satisfied_by(self, val):\n        \"\"\"Whether or not a value satisfies the constraint.\n\n        Parameters\n        ----------\n        val : object\n            The value to check.\n\n        Returns\n        -------\n        is_satisfied : bool\n            Whether or not the constraint is satisfied by this value.\n        \"\"\"\n\n    @abstractm"}, {"start_line": 2000, "end_line": 4000, "belongs_to": {"file_name": "test_public_functions.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "       f\" {func_name}.\\nConsider the unexpected parameters {unexpected_params} and\"\n            f\" expected but missing parameters {missing_params}\\n\"\n        )\n        assert set(validation_params) == set(func_params), err_msg\n\n    # this object does not have a valid type for sure for all params\n    param_with_bad_type = type(\"BadType\", (), {})()\n\n    for param_name in func_params:\n        constraints = parameter_constraints[param_name]\n\n        if constraints == \"no_validation\":\n            # This parameter is not validated\n            continue\n\n        # Mixing an interval of reals and an interval of integers must be avoided.\n        if any(\n            isinstance(constraint, Interval) and constraint.type == Integral\n            for constraint in constraints\n        ) and any(\n            isinstance(constraint, Interval) and constraint.type == Real\n            for constraint in constraints\n        ):\n            raise ValueError(\n                f\"The constraint for parameter {param_name} of {func_name} can't have a\"\n                \" mix of intervals of Integral and Real types. Use the type\"\n                \" RealNotInt instead of Real.\"\n            )\n\n        match = (\n            rf\"The '{param_name}' parameter of {func_name} must be .* Got .* instead.\"\n        )\n\n        err_msg = (\n            f\"{func_name} does not raise an informative error message when the \"\n            f\"parameter {param_name} does not have a valid type. If any Python type \"\n            \"is valid, the constraint should be 'no_validation'.\"\n        )\n\n        # First, check that the error is raised if param doesn't match any valid type.\n        with pytest.raises(InvalidParameterError, match=match):\n            func(**{**valid_required_params, param_name: param_with_bad_type})\n            pytest.fail(err_msg)\n\n        # Then, for constraints that are more than a type constraint, check that the\n        # error is raised if param does match a valid type but does not match any valid\n        "}, {"start_line": 0, "end_line": 2000, "belongs_to": {"file_name": "_param_validation.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/utils", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "# Authors: The scikit-learn developers\n# SPDX-License-Identifier: BSD-3-Clause\n\nimport functools\nimport math\nimport operator\nimport re\nfrom abc import ABC, abstractmethod\nfrom collections.abc import Iterable\nfrom inspect import signature\nfrom numbers import Integral, Real\n\nimport numpy as np\nfrom scipy.sparse import csr_matrix, issparse\n\nfrom sklearn._config import config_context, get_config\nfrom sklearn.utils.validation import _is_arraylike_not_scalar\n\n\nclass InvalidParameterError(ValueError, TypeError):\n    \"\"\"Custom exception to be raised when the parameter of a class/method/function\n    does not have a valid type or value.\n    \"\"\"\n\n    # Inherits from ValueError and TypeError to keep backward compatibility.\n\n\ndef validate_parameter_constraints(parameter_constraints, params, caller_name):\n    \"\"\"Validate types and values of given parameters.\n\n    Parameters\n    ----------\n    parameter_constraints : dict or {\"no_validation\"}\n        If \"no_validation\", validation is skipped for this parameter.\n\n        If a dict, it must be a dictionary `param_name: list of constraints`.\n        A parameter is valid if it satisfies one of the constraints from the list.\n        Constraints can be:\n        - an Interval object, representing a continuous or discrete range of numbers\n        - the string \"array-like\"\n        - the string \"sparse matrix\"\n        - the string \"random_state\"\n        - callable\n        - None, meaning that None is a valid value for the parameter\n        - any type, meaning that any instance of this type is valid\n        - an Options object, representing a set of elements of a given type\n        - a StrOptions object, representing a set of strings\n        - the string \"boolean\"\n        - the string \"verbose\"\n        - the string \"cv_object\"\n        - the string \"nan\"\n        - a MissingValues object representing markers for missing values\n        - a HasMethods object, representing method(s) an object must have\n        - a Hidden object, representing a co"}, {"start_line": 17000, "end_line": 19000, "belongs_to": {"file_name": "test_param_validation.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/utils/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "ethod must be\",\n        ):\n            _Class()._deprecated_method(\"wrong\")\n\n\ndef test_validate_params_estimator():\n    \"\"\"Check that validate_params works with Estimator instances\"\"\"\n    # no validation in init\n    est = _Estimator(\"wrong\")\n\n    with pytest.raises(\n        InvalidParameterError, match=\"The 'a' parameter of _Estimator must be\"\n    ):\n        est.fit()\n\n\ndef test_stroptions_deprecated_subset():\n    \"\"\"Check that the deprecated parameter must be a subset of options.\"\"\"\n    with pytest.raises(ValueError, match=\"deprecated options must be a subset\"):\n        StrOptions({\"a\", \"b\", \"c\"}, deprecated={\"a\", \"d\"})\n\n\ndef test_hidden_constraint():\n    \"\"\"Check that internal constraints are not exposed in the error message.\"\"\"\n\n    @validate_params(\n        {\"param\": [Hidden(list), dict]}, prefer_skip_nested_validation=True\n    )\n    def f(param):\n        pass\n\n    # list and dict are valid params\n    f({\"a\": 1, \"b\": 2, \"c\": 3})\n    f([1, 2, 3])\n\n    with pytest.raises(\n        InvalidParameterError, match=\"The 'param' parameter\"\n    ) as exc_info:\n        f(param=\"bad\")\n\n    # the list option is not exposed in the error message\n    err_msg = str(exc_info.value)\n    assert \"an instance of 'dict'\" in err_msg\n    assert \"an instance of 'list'\" not in err_msg\n\n\ndef test_hidden_stroptions():\n    \"\"\"Check that we can have 2 StrOptions constraints, one being hidden.\"\"\"\n\n    @validate_params(\n        {\"param\": [StrOptions({\"auto\"}), Hidden(StrOptions({\"warn\"}))]},\n        prefer_skip_nested_validation=True,\n    )\n    def f(param):\n        pass\n\n    # \"auto\" and \"warn\" are valid params\n    f(\"auto\")\n    f(\"warn\")\n\n    with pytest.raises(\n        InvalidParameterError, match=\"The 'param' parameter\"\n    ) as exc_info:\n        f(param=\"bad\")\n\n    # the \"warn\" option is not exposed in the error message\n    err_msg = str(exc_info.value)\n    assert \"auto\" in err_msg\n    assert \"warn\" not in err_msg\n\n\ndef test_validate_params_set_param_constraints_attribute():\n    \"\"\"Check tha"}], "retrieved_count": 10, "cost_time": 0.34656453132629395}
{"question": "Where in the scikit-learn repository are the manifold learning classes and dimensionality reduction algorithms imported and utilized within the plot_embedding function's execution context?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"start_line": 0, "end_line": 658, "belongs_to": {"file_name": "__init__.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/manifold", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "\"\"\"Data embedding techniques.\"\"\"\n\n# Authors: The scikit-learn developers\n# SPDX-License-Identifier: BSD-3-Clause\n\nfrom sklearn.manifold._isomap import Isomap\nfrom sklearn.manifold._locally_linear import (\n    LocallyLinearEmbedding,\n    locally_linear_embedding,\n)\nfrom sklearn.manifold._mds import MDS, smacof\nfrom sklearn.manifold._spectral_embedding import SpectralEmbedding, spectral_embedding\nfrom sklearn.manifold._t_sne import TSNE, trustworthiness\n\n__all__ = [\n    \"MDS\",\n    \"TSNE\",\n    \"Isomap\",\n    \"LocallyLinearEmbedding\",\n    \"SpectralEmbedding\",\n    \"locally_linear_embedding\",\n    \"smacof\",\n    \"spectral_embedding\",\n    \"trustworthiness\",\n]\n"}, {"start_line": 3000, "end_line": 5000, "belongs_to": {"file_name": "plot_lle_digits.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/examples/manifold", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "rn.discriminant_analysis.LinearDiscriminantAnalysis` and\n#   the :class:`~sklearn.neighbors.NeighborhoodComponentsAnalysis`, are supervised\n#   dimensionality reduction method, i.e. they make use of the provided labels,\n#   contrary to other methods.\n# * the :class:`~sklearn.manifold.TSNE` is initialized with the embedding that is\n#   generated by PCA in this example. It ensures global stability  of the embedding,\n#   i.e., the embedding does not depend on random initialization.\nfrom sklearn.decomposition import TruncatedSVD\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.ensemble import RandomTreesEmbedding\nfrom sklearn.manifold import (\n    MDS,\n    TSNE,\n    Isomap,\n    LocallyLinearEmbedding,\n    SpectralEmbedding,\n)\nfrom sklearn.neighbors import NeighborhoodComponentsAnalysis\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.random_projection import SparseRandomProjection\n\nembeddings = {\n    \"Random projection embedding\": SparseRandomProjection(\n        n_components=2, random_state=42\n    ),\n    \"Truncated SVD embedding\": TruncatedSVD(n_components=2),\n    \"Linear Discriminant Analysis embedding\": LinearDiscriminantAnalysis(\n        n_components=2\n    ),\n    \"Isomap embedding\": Isomap(n_neighbors=n_neighbors, n_components=2),\n    \"Standard LLE embedding\": LocallyLinearEmbedding(\n        n_neighbors=n_neighbors, n_components=2, method=\"standard\"\n    ),\n    \"Modified LLE embedding\": LocallyLinearEmbedding(\n        n_neighbors=n_neighbors, n_components=2, method=\"modified\"\n    ),\n    \"Hessian LLE embedding\": LocallyLinearEmbedding(\n        n_neighbors=n_neighbors, n_components=2, method=\"hessian\"\n    ),\n    \"LTSA LLE embedding\": LocallyLinearEmbedding(\n        n_neighbors=n_neighbors, n_components=2, method=\"ltsa\"\n    ),\n    \"MDS embedding\": MDS(n_components=2, n_init=1, max_iter=120, eps=1e-6),\n    \"Random Trees embedding\": make_pipeline(\n        RandomTreesEmbedding(n_estimators=200, max_depth=5, random_state=0),\n        Tr"}, {"start_line": 0, "end_line": 2000, "belongs_to": {"file_name": "plot_lle_digits.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/examples/manifold", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "\"\"\"\n=============================================================================\nManifold learning on handwritten digits: Locally Linear Embedding, Isomap...\n=============================================================================\n\nWe illustrate various embedding techniques on the digits dataset.\n\n\"\"\"\n\n# Authors: The scikit-learn developers\n# SPDX-License-Identifier: BSD-3-Clause\n\n# %%\n# Load digits dataset\n# -------------------\n# We will load the digits dataset and only use six first of the ten available classes.\nfrom sklearn.datasets import load_digits\n\ndigits = load_digits(n_class=6)\nX, y = digits.data, digits.target\nn_samples, n_features = X.shape\nn_neighbors = 30\n\n# %%\n# We can plot the first hundred digits from this data set.\nimport matplotlib.pyplot as plt\n\nfig, axs = plt.subplots(nrows=10, ncols=10, figsize=(6, 6))\nfor idx, ax in enumerate(axs.ravel()):\n    ax.imshow(X[idx].reshape((8, 8)), cmap=plt.cm.binary)\n    ax.axis(\"off\")\n_ = fig.suptitle(\"A selection from the 64-dimensional digits dataset\", fontsize=16)\n\n# %%\n# Helper function to plot embedding\n# ---------------------------------\n# Below, we will use different techniques to embed the digits dataset. We will plot\n# the projection of the original data onto each embedding. It will allow us to\n# check whether or digits are grouped together in the embedding space, or\n# scattered across it.\nimport numpy as np\nfrom matplotlib import offsetbox\n\nfrom sklearn.preprocessing import MinMaxScaler\n\n\ndef plot_embedding(X, title):\n    _, ax = plt.subplots()\n    X = MinMaxScaler().fit_transform(X)\n\n    for digit in digits.target_names:\n        ax.scatter(\n            *X[y == digit].T,\n            marker=f\"${digit}$\",\n            s=60,\n            color=plt.cm.Dark2(digit),\n            alpha=0.425,\n            zorder=2,\n        )\n    shown_images = np.array([[1.0, 1.0]])  # just something big\n    for i in range(X.shape[0]):\n        # plot every digit on the embedding\n        # show an annotation box for a group o"}, {"start_line": 2000, "end_line": 4000, "belongs_to": {"file_name": "plot_lle_digits.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/examples/manifold", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "f digits\n        dist = np.sum((X[i] - shown_images) ** 2, 1)\n        if np.min(dist) < 4e-3:\n            # don't show points that are too close\n            continue\n        shown_images = np.concatenate([shown_images, [X[i]]], axis=0)\n        imagebox = offsetbox.AnnotationBbox(\n            offsetbox.OffsetImage(digits.images[i], cmap=plt.cm.gray_r), X[i]\n        )\n        imagebox.set(zorder=1)\n        ax.add_artist(imagebox)\n\n    ax.set_title(title)\n    ax.axis(\"off\")\n\n\n# %%\n# Embedding techniques comparison\n# -------------------------------\n#\n# Below, we compare different techniques. However, there are a couple of things\n# to note:\n#\n# * the :class:`~sklearn.ensemble.RandomTreesEmbedding` is not\n#   technically a manifold embedding method, as it learn a high-dimensional\n#   representation on which we apply a dimensionality reduction method.\n#   However, it is often useful to cast a dataset into a representation in\n#   which the classes are linearly-separable.\n# * the :class:`~sklearn.discriminant_analysis.LinearDiscriminantAnalysis` and\n#   the :class:`~sklearn.neighbors.NeighborhoodComponentsAnalysis`, are supervised\n#   dimensionality reduction method, i.e. they make use of the provided labels,\n#   contrary to other methods.\n# * the :class:`~sklearn.manifold.TSNE` is initialized with the embedding that is\n#   generated by PCA in this example. It ensures global stability  of the embedding,\n#   i.e., the embedding does not depend on random initialization.\nfrom sklearn.decomposition import TruncatedSVD\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.ensemble import RandomTreesEmbedding\nfrom sklearn.manifold import (\n    MDS,\n    TSNE,\n    Isomap,\n    LocallyLinearEmbedding,\n    SpectralEmbedding,\n)\nfrom sklearn.neighbors import NeighborhoodComponentsAnalysis\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.random_projection import SparseRandomProjection\n\nembeddings = {\n    \"Random projection embedding\": SparseRandomProject"}, {"start_line": 3000, "end_line": 5000, "belongs_to": {"file_name": "plot_manifold_sphere.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/examples/manifold", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": ")\n    plt.title(\"%s (%.2g sec)\" % (labels[i], t1 - t0))\n    ax.xaxis.set_major_formatter(NullFormatter())\n    ax.yaxis.set_major_formatter(NullFormatter())\n    plt.axis(\"tight\")\n\n# Perform Isomap Manifold learning.\nt0 = time()\ntrans_data = (\n    manifold.Isomap(n_neighbors=n_neighbors, n_components=2)\n    .fit_transform(sphere_data)\n    .T\n)\nt1 = time()\nprint(\"%s: %.2g sec\" % (\"ISO\", t1 - t0))\n\nax = fig.add_subplot(257)\nplt.scatter(trans_data[0], trans_data[1], c=colors, cmap=plt.cm.rainbow)\nplt.title(\"%s (%.2g sec)\" % (\"Isomap\", t1 - t0))\nax.xaxis.set_major_formatter(NullFormatter())\nax.yaxis.set_major_formatter(NullFormatter())\nplt.axis(\"tight\")\n\n# Perform Multi-dimensional scaling.\nt0 = time()\nmds = manifold.MDS(2, max_iter=100, n_init=1, random_state=42)\ntrans_data = mds.fit_transform(sphere_data).T\nt1 = time()\nprint(\"MDS: %.2g sec\" % (t1 - t0))\n\nax = fig.add_subplot(258)\nplt.scatter(trans_data[0], trans_data[1], c=colors, cmap=plt.cm.rainbow)\nplt.title(\"MDS (%.2g sec)\" % (t1 - t0))\nax.xaxis.set_major_formatter(NullFormatter())\nax.yaxis.set_major_formatter(NullFormatter())\nplt.axis(\"tight\")\n\n# Perform Spectral Embedding.\nt0 = time()\nse = manifold.SpectralEmbedding(\n    n_components=2, n_neighbors=n_neighbors, random_state=42\n)\ntrans_data = se.fit_transform(sphere_data).T\nt1 = time()\nprint(\"Spectral Embedding: %.2g sec\" % (t1 - t0))\n\nax = fig.add_subplot(259)\nplt.scatter(trans_data[0], trans_data[1], c=colors, cmap=plt.cm.rainbow)\nplt.title(\"Spectral Embedding (%.2g sec)\" % (t1 - t0))\nax.xaxis.set_major_formatter(NullFormatter())\nax.yaxis.set_major_formatter(NullFormatter())\nplt.axis(\"tight\")\n\n# Perform t-distributed stochastic neighbor embedding.\nt0 = time()\ntsne = manifold.TSNE(n_components=2, random_state=0)\ntrans_data = tsne.fit_transform(sphere_data).T\nt1 = time()\nprint(\"t-SNE: %.2g sec\" % (t1 - t0))\n\nax = fig.add_subplot(2, 5, 10)\nplt.scatter(trans_data[0], trans_data[1], c=colors, cmap=plt.cm.rainbow)\nplt.title(\"t-SNE (%.2g sec)\" % (t1 - t0))\nax.xaxis.set_"}, {"start_line": 5000, "end_line": 6272, "belongs_to": {"file_name": "plot_lle_digits.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/examples/manifold", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "uncatedSVD(n_components=2),\n    ),\n    \"Spectral embedding\": SpectralEmbedding(\n        n_components=2, random_state=0, eigen_solver=\"arpack\"\n    ),\n    \"t-SNE embedding\": TSNE(\n        n_components=2,\n        max_iter=500,\n        n_iter_without_progress=150,\n        n_jobs=2,\n        random_state=0,\n    ),\n    \"NCA embedding\": NeighborhoodComponentsAnalysis(\n        n_components=2, init=\"pca\", random_state=0\n    ),\n}\n\n# %%\n# Once we declared all the methods of interest, we can run and perform the projection\n# of the original data. We will store the projected data as well as the computational\n# time needed to perform each projection.\nfrom time import time\n\nprojections, timing = {}, {}\nfor name, transformer in embeddings.items():\n    if name.startswith(\"Linear Discriminant Analysis\"):\n        data = X.copy()\n        data.flat[:: X.shape[1] + 1] += 0.01  # Make X invertible\n    else:\n        data = X\n\n    print(f\"Computing {name}...\")\n    start_time = time()\n    projections[name] = transformer.fit_transform(data, y)\n    timing[name] = time() - start_time\n\n# %%\n# Finally, we can plot the resulting projection given by each method.\nfor name in timing:\n    title = f\"{name} (time {timing[name]:.3f}s)\"\n    plot_embedding(projections[name], title)\n\nplt.show()\n"}, {"start_line": 5000, "end_line": 6770, "belongs_to": {"file_name": "plot_compare_methods.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/examples/manifold", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "ling (MDS) seeks a low-dimensional representation\n# of the data in which the distances respect well the distances in the\n# original high-dimensional space.\n# Read more in the :ref:`User Guide <multidimensional_scaling>`.\n\nmd_scaling = manifold.MDS(\n    n_components=n_components,\n    max_iter=50,\n    n_init=1,\n    random_state=0,\n    normalized_stress=False,\n)\nS_scaling = md_scaling.fit_transform(S_points)\n\nplot_2d(S_scaling, S_color, \"Multidimensional scaling\")\n\n# %%\n# Spectral embedding for non-linear dimensionality reduction\n# ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n#\n# This implementation uses Laplacian Eigenmaps, which finds a low dimensional\n# representation of the data using a spectral decomposition of the graph Laplacian.\n# Read more in the :ref:`User Guide <spectral_embedding>`.\n\nspectral = manifold.SpectralEmbedding(\n    n_components=n_components, n_neighbors=n_neighbors, random_state=42\n)\nS_spectral = spectral.fit_transform(S_points)\n\nplot_2d(S_spectral, S_color, \"Spectral Embedding\")\n\n# %%\n# T-distributed Stochastic Neighbor Embedding\n# ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n#\n# It converts similarities between data points to joint probabilities and\n# tries to minimize the Kullback-Leibler divergence between the joint probabilities\n# of the low-dimensional embedding and the high-dimensional data. t-SNE has a cost\n# function that is not convex, i.e. with different initializations we can get\n# different results. Read more in the :ref:`User Guide <t_sne>`.\n\nt_sne = manifold.TSNE(\n    n_components=n_components,\n    perplexity=30,\n    init=\"random\",\n    max_iter=250,\n    random_state=0,\n)\nS_t_sne = t_sne.fit_transform(S_points)\n\nplot_2d(S_t_sne, S_color, \"T-distributed Stochastic  \\n Neighbor Embedding\")\n\n# %%\n"}, {"start_line": 4000, "end_line": 6000, "belongs_to": {"file_name": "plot_compare_methods.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/examples/manifold", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "lt.subplots(\n    nrows=2, ncols=2, figsize=(7, 7), facecolor=\"white\", constrained_layout=True\n)\nfig.suptitle(\"Locally Linear Embeddings\", size=16)\n\nlle_methods = [\n    (\"Standard locally linear embedding\", S_standard),\n    (\"Local tangent space alignment\", S_ltsa),\n    (\"Hessian eigenmap\", S_hessian),\n    (\"Modified locally linear embedding\", S_mod),\n]\nfor ax, method in zip(axs.flat, lle_methods):\n    name, points = method\n    add_2d_scatter(ax, points, S_color, name)\n\nplt.show()\n\n# %%\n# Isomap Embedding\n# ^^^^^^^^^^^^^^^^\n#\n# Non-linear dimensionality reduction through Isometric Mapping.\n# Isomap seeks a lower-dimensional embedding which maintains geodesic\n# distances between all points. Read more in the :ref:`User Guide <isomap>`.\n\nisomap = manifold.Isomap(n_neighbors=n_neighbors, n_components=n_components, p=1)\nS_isomap = isomap.fit_transform(S_points)\n\nplot_2d(S_isomap, S_color, \"Isomap Embedding\")\n\n# %%\n# Multidimensional scaling\n# ^^^^^^^^^^^^^^^^^^^^^^^^\n#\n# Multidimensional scaling (MDS) seeks a low-dimensional representation\n# of the data in which the distances respect well the distances in the\n# original high-dimensional space.\n# Read more in the :ref:`User Guide <multidimensional_scaling>`.\n\nmd_scaling = manifold.MDS(\n    n_components=n_components,\n    max_iter=50,\n    n_init=1,\n    random_state=0,\n    normalized_stress=False,\n)\nS_scaling = md_scaling.fit_transform(S_points)\n\nplot_2d(S_scaling, S_color, \"Multidimensional scaling\")\n\n# %%\n# Spectral embedding for non-linear dimensionality reduction\n# ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n#\n# This implementation uses Laplacian Eigenmaps, which finds a low dimensional\n# representation of the data using a spectral decomposition of the graph Laplacian.\n# Read more in the :ref:`User Guide <spectral_embedding>`.\n\nspectral = manifold.SpectralEmbedding(\n    n_components=n_components, n_neighbors=n_neighbors, random_state=42\n)\nS_spectral = spectral.fit_transform(S_points)\n\nplot_2d(S_spectral, S_"}, {"start_line": 1000, "end_line": 3000, "belongs_to": {"file_name": "plot_compare_methods.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/examples/manifold", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "b.pyplot as plt\n\n# unused but required import for doing 3d projections with matplotlib < 3.2\nimport mpl_toolkits.mplot3d  # noqa: F401\nfrom matplotlib import ticker\n\nfrom sklearn import datasets, manifold\n\nn_samples = 1500\nS_points, S_color = datasets.make_s_curve(n_samples, random_state=0)\n\n# %%\n# Let's look at the original data. Also define some helping\n# functions, which we will use further on.\n\n\ndef plot_3d(points, points_color, title):\n    x, y, z = points.T\n\n    fig, ax = plt.subplots(\n        figsize=(6, 6),\n        facecolor=\"white\",\n        tight_layout=True,\n        subplot_kw={\"projection\": \"3d\"},\n    )\n    fig.suptitle(title, size=16)\n    col = ax.scatter(x, y, z, c=points_color, s=50, alpha=0.8)\n    ax.view_init(azim=-60, elev=9)\n    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n    ax.zaxis.set_major_locator(ticker.MultipleLocator(1))\n\n    fig.colorbar(col, ax=ax, orientation=\"horizontal\", shrink=0.6, aspect=60, pad=0.01)\n    plt.show()\n\n\ndef plot_2d(points, points_color, title):\n    fig, ax = plt.subplots(figsize=(3, 3), facecolor=\"white\", constrained_layout=True)\n    fig.suptitle(title, size=16)\n    add_2d_scatter(ax, points, points_color)\n    plt.show()\n\n\ndef add_2d_scatter(ax, points, points_color, title=None):\n    x, y = points.T\n    ax.scatter(x, y, c=points_color, s=50, alpha=0.8)\n    ax.set_title(title)\n    ax.xaxis.set_major_formatter(ticker.NullFormatter())\n    ax.yaxis.set_major_formatter(ticker.NullFormatter())\n\n\nplot_3d(S_points, S_color, \"Original S-curve samples\")\n\n# %%\n# Define algorithms for the manifold learning\n# -------------------------------------------\n#\n# Manifold learning is an approach to non-linear dimensionality reduction.\n# Algorithms for this task are based on the idea that the dimensionality of\n# many data sets is only artificially high.\n#\n# Read more in the :ref:`User Guide <manifold>`.\n\nn_neighbors = 12  # neighborhood which is used to recover the locally"}, {"start_line": 2000, "end_line": 4000, "belongs_to": {"file_name": "plot_compare_methods.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/examples/manifold", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "t=60, pad=0.01)\n    plt.show()\n\n\ndef plot_2d(points, points_color, title):\n    fig, ax = plt.subplots(figsize=(3, 3), facecolor=\"white\", constrained_layout=True)\n    fig.suptitle(title, size=16)\n    add_2d_scatter(ax, points, points_color)\n    plt.show()\n\n\ndef add_2d_scatter(ax, points, points_color, title=None):\n    x, y = points.T\n    ax.scatter(x, y, c=points_color, s=50, alpha=0.8)\n    ax.set_title(title)\n    ax.xaxis.set_major_formatter(ticker.NullFormatter())\n    ax.yaxis.set_major_formatter(ticker.NullFormatter())\n\n\nplot_3d(S_points, S_color, \"Original S-curve samples\")\n\n# %%\n# Define algorithms for the manifold learning\n# -------------------------------------------\n#\n# Manifold learning is an approach to non-linear dimensionality reduction.\n# Algorithms for this task are based on the idea that the dimensionality of\n# many data sets is only artificially high.\n#\n# Read more in the :ref:`User Guide <manifold>`.\n\nn_neighbors = 12  # neighborhood which is used to recover the locally linear structure\nn_components = 2  # number of coordinates for the manifold\n\n# %%\n# Locally Linear Embeddings\n# ^^^^^^^^^^^^^^^^^^^^^^^^^\n#\n# Locally linear embedding (LLE) can be thought of as a series of local\n# Principal Component Analyses which are globally compared to find the\n# best non-linear embedding.\n# Read more in the :ref:`User Guide <locally_linear_embedding>`.\n\nparams = {\n    \"n_neighbors\": n_neighbors,\n    \"n_components\": n_components,\n    \"eigen_solver\": \"auto\",\n    \"random_state\": 0,\n}\n\nlle_standard = manifold.LocallyLinearEmbedding(method=\"standard\", **params)\nS_standard = lle_standard.fit_transform(S_points)\n\nlle_ltsa = manifold.LocallyLinearEmbedding(method=\"ltsa\", **params)\nS_ltsa = lle_ltsa.fit_transform(S_points)\n\nlle_hessian = manifold.LocallyLinearEmbedding(method=\"hessian\", **params)\nS_hessian = lle_hessian.fit_transform(S_points)\n\nlle_mod = manifold.LocallyLinearEmbedding(method=\"modified\", **params)\nS_mod = lle_mod.fit_transform(S_points)\n\n# %%\nfig, axs = p"}], "retrieved_count": 10, "cost_time": 0.34453845024108887}
{"question": "Where in the codebase are the probability calibration mechanisms that enable SVC and NuSVC to produce consistent probability estimates through predict_proba and predict_log_proba methods?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"start_line": 6000, "end_line": 8000, "belongs_to": {"file_name": "plot_calibration_curve.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/examples/calibration", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "should however, make the predicted probabilities more\n# accurate and thus more useful for making allocation decisions under\n# uncertainty.\n# Further, ROC AUC, should not change at all because calibration is a\n# monotonic transformation. Indeed, no rank metrics are affected by\n# calibration.\n#\n# Linear support vector classifier\n# ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n# Next, we will compare:\n#\n# * :class:`~sklearn.linear_model.LogisticRegression` (baseline)\n# * Uncalibrated :class:`~sklearn.svm.LinearSVC`. Since SVC does not output\n#   probabilities by default, we naively scale the output of the\n#   :term:`decision_function` into [0, 1] by applying min-max scaling.\n# * :class:`~sklearn.svm.LinearSVC` with isotonic and sigmoid\n#   calibration (see :ref:`User Guide <calibration>`)\n\nimport numpy as np\n\nfrom sklearn.svm import LinearSVC\n\n\nclass NaivelyCalibratedLinearSVC(LinearSVC):\n    \"\"\"LinearSVC with `predict_proba` method that naively scales\n    `decision_function` output for binary classification.\"\"\"\n\n    def fit(self, X, y):\n        super().fit(X, y)\n        df = self.decision_function(X)\n        self.df_min_ = df.min()\n        self.df_max_ = df.max()\n\n    def predict_proba(self, X):\n        \"\"\"Min-max scale output of `decision_function` to [0, 1].\"\"\"\n        df = self.decision_function(X)\n        calibrated_df = (df - self.df_min_) / (self.df_max_ - self.df_min_)\n        proba_pos_class = np.clip(calibrated_df, 0, 1)\n        proba_neg_class = 1 - proba_pos_class\n        proba = np.c_[proba_neg_class, proba_pos_class]\n        return proba\n\n\n# %%\n\nlr = LogisticRegression(C=1.0)\nsvc = NaivelyCalibratedLinearSVC(max_iter=10_000)\nsvc_isotonic = CalibratedClassifierCV(svc, cv=2, method=\"isotonic\")\nsvc_sigmoid = CalibratedClassifierCV(svc, cv=2, method=\"sigmoid\")\n\nclf_list = [\n    (lr, \"Logistic\"),\n    (svc, \"SVC\"),\n    (svc_isotonic, \"SVC + Isotonic\"),\n    (svc_sigmoid, \"SVC + Sigmoid\"),\n]\n\n# %%\nfig = plt.figure(figsize=(10, 10))\ngs = GridSpec(4, 2)\n\nax_calibration_curve = "}, {"start_line": 7000, "end_line": 9000, "belongs_to": {"file_name": "plot_calibration_curve.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/examples/calibration", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "ication.\"\"\"\n\n    def fit(self, X, y):\n        super().fit(X, y)\n        df = self.decision_function(X)\n        self.df_min_ = df.min()\n        self.df_max_ = df.max()\n\n    def predict_proba(self, X):\n        \"\"\"Min-max scale output of `decision_function` to [0, 1].\"\"\"\n        df = self.decision_function(X)\n        calibrated_df = (df - self.df_min_) / (self.df_max_ - self.df_min_)\n        proba_pos_class = np.clip(calibrated_df, 0, 1)\n        proba_neg_class = 1 - proba_pos_class\n        proba = np.c_[proba_neg_class, proba_pos_class]\n        return proba\n\n\n# %%\n\nlr = LogisticRegression(C=1.0)\nsvc = NaivelyCalibratedLinearSVC(max_iter=10_000)\nsvc_isotonic = CalibratedClassifierCV(svc, cv=2, method=\"isotonic\")\nsvc_sigmoid = CalibratedClassifierCV(svc, cv=2, method=\"sigmoid\")\n\nclf_list = [\n    (lr, \"Logistic\"),\n    (svc, \"SVC\"),\n    (svc_isotonic, \"SVC + Isotonic\"),\n    (svc_sigmoid, \"SVC + Sigmoid\"),\n]\n\n# %%\nfig = plt.figure(figsize=(10, 10))\ngs = GridSpec(4, 2)\n\nax_calibration_curve = fig.add_subplot(gs[:2, :2])\ncalibration_displays = {}\nfor i, (clf, name) in enumerate(clf_list):\n    clf.fit(X_train, y_train)\n    display = CalibrationDisplay.from_estimator(\n        clf,\n        X_test,\n        y_test,\n        n_bins=10,\n        name=name,\n        ax=ax_calibration_curve,\n        color=colors(i),\n    )\n    calibration_displays[name] = display\n\nax_calibration_curve.grid()\nax_calibration_curve.set_title(\"Calibration plots (SVC)\")\n\n# Add histogram\ngrid_positions = [(2, 0), (2, 1), (3, 0), (3, 1)]\nfor i, (_, name) in enumerate(clf_list):\n    row, col = grid_positions[i]\n    ax = fig.add_subplot(gs[row, col])\n\n    ax.hist(\n        calibration_displays[name].y_prob,\n        range=(0, 1),\n        bins=10,\n        label=name,\n        color=colors(i),\n    )\n    ax.set(title=name, xlabel=\"Mean predicted probability\", ylabel=\"Count\")\n\nplt.tight_layout()\nplt.show()\n\n# %%\n# :class:`~sklearn.svm.LinearSVC` shows the opposite\n# behavior to :class:`~sklearn.naive_bayes.GaussianNB`; "}, {"start_line": 28000, "end_line": 30000, "belongs_to": {"file_name": "_base.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/svm", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "when\n    # probabilities are not available depending on a setting, introduce two\n    # estimators.\n    def _check_proba(self):\n        if not self.probability:\n            raise AttributeError(\n                \"predict_proba is not available when probability=False\"\n            )\n        if self._impl not in (\"c_svc\", \"nu_svc\"):\n            raise AttributeError(\"predict_proba only implemented for SVC and NuSVC\")\n        return True\n\n    @available_if(_check_proba)\n    def predict_proba(self, X):\n        \"\"\"Compute probabilities of possible outcomes for samples in X.\n\n        The model needs to have probability information computed at training\n        time: fit with attribute `probability` set to True.\n\n        Parameters\n        ----------\n        X : array-like of shape (n_samples, n_features)\n            For kernel=\"precomputed\", the expected shape of X is\n            (n_samples_test, n_samples_train).\n\n        Returns\n        -------\n        T : ndarray of shape (n_samples, n_classes)\n            Returns the probability of the sample for each class in\n            the model. The columns correspond to the classes in sorted\n            order, as they appear in the attribute :term:`classes_`.\n\n        Notes\n        -----\n        The probability model is created using cross validation, so\n        the results can be slightly different than those obtained by\n        predict. Also, it will produce meaningless results on very small\n        datasets.\n        \"\"\"\n        X = self._validate_for_predict(X)\n        if self.probA_.size == 0 or self.probB_.size == 0:\n            raise NotFittedError(\n                \"predict_proba is not available when fitted with probability=False\"\n            )\n        pred_proba = (\n            self._sparse_predict_proba if self._sparse else self._dense_predict_proba\n        )\n        return pred_proba(X)\n\n    @available_if(_check_proba)\n    def predict_log_proba(self, X):\n        \"\"\"Compute log probabilities of possible outcomes for samples i"}, {"start_line": 42000, "end_line": 44000, "belongs_to": {"file_name": "_classes.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/svm", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "hape (n_SV,)\n        Indices of support vectors.\n\n    support_vectors_ : ndarray of shape (n_SV, n_features)\n        Support vectors.\n\n    n_support_ : ndarray of shape (n_classes,), dtype=int32\n        Number of support vectors for each class.\n\n    fit_status_ : int\n        0 if correctly fitted, 1 if the algorithm did not converge.\n\n    probA_ : ndarray of shape (n_classes * (n_classes - 1) / 2,)\n\n    probB_ : ndarray of shape (n_classes * (n_classes - 1) / 2,)\n        If `probability=True`, it corresponds to the parameters learned in\n        Platt scaling to produce probability estimates from decision values.\n        If `probability=False`, it's an empty array. Platt scaling uses the\n        logistic function\n        ``1 / (1 + exp(decision_value * probA_ + probB_))``\n        where ``probA_`` and ``probB_`` are learned from the dataset [2]_. For\n        more information on the multiclass case and training procedure see\n        section 8 of [1]_.\n\n    shape_fit_ : tuple of int of shape (n_dimensions_of_X,)\n        Array dimensions of training vector ``X``.\n\n    See Also\n    --------\n    SVC : Support Vector Machine for classification using libsvm.\n\n    LinearSVC : Scalable linear Support Vector Machine for classification using\n        liblinear.\n\n    References\n    ----------\n    .. [1] `LIBSVM: A Library for Support Vector Machines\n        <http://www.csie.ntu.edu.tw/~cjlin/papers/libsvm.pdf>`_\n\n    .. [2] `Platt, John (1999). \"Probabilistic Outputs for Support Vector\n        Machines and Comparisons to Regularized Likelihood Methods\"\n        <https://citeseerx.ist.psu.edu/doc_view/pid/42e5ed832d4310ce4378c44d05570439df28a393>`_\n\n    Examples\n    --------\n    >>> import numpy as np\n    >>> X = np.array([[-1, -1], [-2, -1], [1, 1], [2, 1]])\n    >>> y = np.array([1, 1, 2, 2])\n    >>> from sklearn.pipeline import make_pipeline\n    >>> from sklearn.preprocessing import StandardScaler\n    >>> from sklearn.svm import NuSVC\n    >>> clf = make_pipeline(StandardScaler(), "}, {"start_line": 12000, "end_line": 14000, "belongs_to": {"file_name": "test_svm.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/svm/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "ision_function([[2.0, 2.0]]) + clf.offset_,\n    )\n\n\ndef test_tweak_params():\n    # Make sure some tweaking of parameters works.\n    # We change clf.dual_coef_ at run time and expect .predict() to change\n    # accordingly. Notice that this is not trivial since it involves a lot\n    # of C/Python copying in the libsvm bindings.\n    # The success of this test ensures that the mapping between libsvm and\n    # the python classifier is complete.\n    clf = svm.SVC(kernel=\"linear\", C=1.0)\n    clf.fit(X, Y)\n    assert_array_equal(clf.dual_coef_, [[-0.25, 0.25]])\n    assert_array_equal(clf.predict([[-0.1, -0.1]]), [1])\n    clf._dual_coef_ = np.array([[0.0, 1.0]])\n    assert_array_equal(clf.predict([[-0.1, -0.1]]), [2])\n\n\ndef test_probability(global_random_seed):\n    # Predict probabilities using SVC\n    # This uses cross validation, so we use a slightly bigger testing set.\n    iris = get_iris_dataset(global_random_seed)\n\n    for clf in (\n        svm.SVC(probability=True, random_state=global_random_seed, C=1.0),\n        svm.NuSVC(probability=True, random_state=global_random_seed),\n    ):\n        clf.fit(iris.data, iris.target)\n\n        prob_predict = clf.predict_proba(iris.data)\n        assert_array_almost_equal(np.sum(prob_predict, 1), np.ones(iris.data.shape[0]))\n        assert np.mean(np.argmax(prob_predict, 1) == clf.predict(iris.data)) > 0.9\n\n        assert_almost_equal(\n            clf.predict_proba(iris.data), np.exp(clf.predict_log_proba(iris.data)), 8\n        )\n\n\ndef test_decision_function(global_random_seed):\n    iris = get_iris_dataset(global_random_seed)\n    # Test decision_function\n    # Sanity check, test that decision_function implemented in python\n    # returns the same as the one in libsvm\n    # multi class:\n    clf = svm.SVC(kernel=\"linear\", C=0.1, decision_function_shape=\"ovo\").fit(\n        iris.data, iris.target\n    )\n\n    dec = np.dot(iris.data, clf.coef_.T) + clf.intercept_\n\n    assert_array_almost_equal(dec, clf.decision_function(iris.data))\n\n    # binar"}, {"start_line": 32000, "end_line": 34000, "belongs_to": {"file_name": "_base.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/svm", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "e.libsvm_sparse_predict_proba(\n            X.data,\n            X.indices,\n            X.indptr,\n            self.support_vectors_.data,\n            self.support_vectors_.indices,\n            self.support_vectors_.indptr,\n            self._dual_coef_.data,\n            self._intercept_,\n            LIBSVM_IMPL.index(self._impl),\n            kernel_type,\n            self.degree,\n            self._gamma,\n            self.coef0,\n            self.tol,\n            self.C,\n            getattr(self, \"class_weight_\", np.empty(0)),\n            self.nu,\n            self.epsilon,\n            self.shrinking,\n            self.probability,\n            self._n_support,\n            self._probA,\n            self._probB,\n        )\n\n    def _get_coef(self):\n        if self.dual_coef_.shape[0] == 1:\n            # binary classifier\n            coef = safe_sparse_dot(self.dual_coef_, self.support_vectors_)\n        else:\n            # 1vs1 classifier\n            coef = _one_vs_one_coef(\n                self.dual_coef_, self._n_support, self.support_vectors_\n            )\n            if sp.issparse(coef[0]):\n                coef = sp.vstack(coef).tocsr()\n            else:\n                coef = np.vstack(coef)\n\n        return coef\n\n    @property\n    def probA_(self):\n        \"\"\"Parameter learned in Platt scaling when `probability=True`.\n\n        Returns\n        -------\n        ndarray of shape  (n_classes * (n_classes - 1) / 2)\n        \"\"\"\n        return self._probA\n\n    @property\n    def probB_(self):\n        \"\"\"Parameter learned in Platt scaling when `probability=True`.\n\n        Returns\n        -------\n        ndarray of shape  (n_classes * (n_classes - 1) / 2)\n        \"\"\"\n        return self._probB\n\n    def __sklearn_tags__(self):\n        tags = super().__sklearn_tags__()\n        tags.input_tags.sparse = self.kernel != \"precomputed\"\n        return tags\n\n\ndef _get_liblinear_solver_type(multi_class, penalty, loss, dual):\n    \"\"\"Find the liblinear magic number for the solver.\n\n    This numbe"}, {"start_line": 31000, "end_line": 33000, "belongs_to": {"file_name": "_base.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/svm", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "redict_proba(X))\n\n    def _dense_predict_proba(self, X):\n        X = self._compute_kernel(X)\n\n        kernel = self.kernel\n        if callable(kernel):\n            kernel = \"precomputed\"\n\n        svm_type = LIBSVM_IMPL.index(self._impl)\n        pprob = libsvm.predict_proba(\n            X,\n            self.support_,\n            self.support_vectors_,\n            self._n_support,\n            self._dual_coef_,\n            self._intercept_,\n            self._probA,\n            self._probB,\n            svm_type=svm_type,\n            kernel=kernel,\n            degree=self.degree,\n            cache_size=self.cache_size,\n            coef0=self.coef0,\n            gamma=self._gamma,\n        )\n\n        return pprob\n\n    def _sparse_predict_proba(self, X):\n        X.data = np.asarray(X.data, dtype=np.float64, order=\"C\")\n\n        kernel = self.kernel\n        if callable(kernel):\n            kernel = \"precomputed\"\n\n        kernel_type = self._sparse_kernels.index(kernel)\n\n        return libsvm_sparse.libsvm_sparse_predict_proba(\n            X.data,\n            X.indices,\n            X.indptr,\n            self.support_vectors_.data,\n            self.support_vectors_.indices,\n            self.support_vectors_.indptr,\n            self._dual_coef_.data,\n            self._intercept_,\n            LIBSVM_IMPL.index(self._impl),\n            kernel_type,\n            self.degree,\n            self._gamma,\n            self.coef0,\n            self.tol,\n            self.C,\n            getattr(self, \"class_weight_\", np.empty(0)),\n            self.nu,\n            self.epsilon,\n            self.shrinking,\n            self.probability,\n            self._n_support,\n            self._probA,\n            self._probB,\n        )\n\n    def _get_coef(self):\n        if self.dual_coef_.shape[0] == 1:\n            # binary classifier\n            coef = safe_sparse_dot(self.dual_coef_, self.support_vectors_)\n        else:\n            # 1vs1 classifier\n            coef = _one_vs_one_coef(\n                self.du"}, {"start_line": 1000, "end_line": 3000, "belongs_to": {"file_name": "calibration.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": ",\n    validate_params,\n)\nfrom sklearn.utils._plotting import (\n    _BinaryClassifierCurveDisplayMixin,\n    _validate_style_kwargs,\n)\nfrom sklearn.utils._response import _get_response_values, _process_predict_proba\nfrom sklearn.utils.extmath import softmax\nfrom sklearn.utils.metadata_routing import (\n    MetadataRouter,\n    MethodMapping,\n    _routing_enabled,\n    process_routing,\n)\nfrom sklearn.utils.multiclass import check_classification_targets\nfrom sklearn.utils.parallel import Parallel, delayed\nfrom sklearn.utils.validation import (\n    _check_method_params,\n    _check_pos_label_consistency,\n    _check_response_method,\n    _check_sample_weight,\n    _num_samples,\n    check_array,\n    check_consistent_length,\n    check_is_fitted,\n)\n\n\nclass CalibratedClassifierCV(ClassifierMixin, MetaEstimatorMixin, BaseEstimator):\n    \"\"\"Calibrate probabilities using isotonic, sigmoid, or temperature scaling.\n\n    This class uses cross-validation to both estimate the parameters of a\n    classifier and subsequently calibrate a classifier. With\n    `ensemble=True`, for each cv split it\n    fits a copy of the base estimator to the training subset, and calibrates it\n    using the testing subset. For prediction, predicted probabilities are\n    averaged across these individual calibrated classifiers. When\n    `ensemble=False`, cross-validation is used to obtain unbiased predictions,\n    via :func:`~sklearn.model_selection.cross_val_predict`, which are then\n    used for calibration. For prediction, the base estimator, trained using all\n    the data, is used. This is the prediction method implemented when\n    `probabilities=True` for :class:`~sklearn.svm.SVC` and :class:`~sklearn.svm.NuSVC`\n    estimators (see :ref:`User Guide <scores_probabilities>` for details).\n\n    Already fitted classifiers can be calibrated by wrapping the model in a\n    :class:`~sklearn.frozen.FrozenEstimator`. In this case all provided\n    data is used for calibration. The user has to take care manually that data\n"}, {"start_line": 40000, "end_line": 42000, "belongs_to": {"file_name": "test_svm.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/svm/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "d):\n    iris = get_iris_dataset(global_random_seed)\n\n    # Method must be (un)available before or after fit, switched by\n    # `probability` param\n\n    G = svm.SVC(probability=True)\n    assert hasattr(G, \"predict_proba\")\n    G.fit(iris.data, iris.target)\n    assert hasattr(G, \"predict_proba\")\n\n    G = svm.SVC(probability=False)\n    assert not hasattr(G, \"predict_proba\")\n    G.fit(iris.data, iris.target)\n    assert not hasattr(G, \"predict_proba\")\n\n    # Switching to `probability=True` after fitting should make\n    # predict_proba available, but calling it must not work:\n    G.probability = True\n    assert hasattr(G, \"predict_proba\")\n    msg = \"predict_proba is not available when fitted with probability=False\"\n\n    with pytest.raises(NotFittedError, match=msg):\n        G.predict_proba(iris.data)\n\n\ndef test_decision_function_shape_two_class(global_random_seed):\n    for n_classes in [2, 3]:\n        X, y = make_blobs(centers=n_classes, random_state=global_random_seed)\n        for estimator in [svm.SVC, svm.NuSVC]:\n            clf = OneVsRestClassifier(estimator(decision_function_shape=\"ovr\")).fit(\n                X, y\n            )\n            assert len(clf.predict(X)) == len(y)\n\n\ndef test_ovr_decision_function():\n    # One point from each quadrant represents one class\n    X_train = np.array([[1, 1], [-1, 1], [-1, -1], [1, -1]])\n    y_train = [0, 1, 2, 3]\n\n    # First point is closer to the decision boundaries than the second point\n    base_points = np.array([[5, 5], [10, 10]])\n\n    # For all the quadrants (classes)\n    X_test = np.vstack(\n        (\n            base_points * [1, 1],  # Q1\n            base_points * [-1, 1],  # Q2\n            base_points * [-1, -1],  # Q3\n            base_points * [1, -1],  # Q4\n        )\n    )\n\n    y_test = [0] * 2 + [1] * 2 + [2] * 2 + [3] * 2\n\n    clf = svm.SVC(kernel=\"linear\", decision_function_shape=\"ovr\")\n    clf.fit(X_train, y_train)\n\n    y_pred = clf.predict(X_test)\n\n    # Test if the prediction is the same as y\n    assert_array_e"}, {"start_line": 13000, "end_line": 15000, "belongs_to": {"file_name": "test_svm.py", "upper_path": "/data2/raymone/swebench-repos/scikit-learn/sklearn/svm/tests", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "om_seed, C=1.0),\n        svm.NuSVC(probability=True, random_state=global_random_seed),\n    ):\n        clf.fit(iris.data, iris.target)\n\n        prob_predict = clf.predict_proba(iris.data)\n        assert_array_almost_equal(np.sum(prob_predict, 1), np.ones(iris.data.shape[0]))\n        assert np.mean(np.argmax(prob_predict, 1) == clf.predict(iris.data)) > 0.9\n\n        assert_almost_equal(\n            clf.predict_proba(iris.data), np.exp(clf.predict_log_proba(iris.data)), 8\n        )\n\n\ndef test_decision_function(global_random_seed):\n    iris = get_iris_dataset(global_random_seed)\n    # Test decision_function\n    # Sanity check, test that decision_function implemented in python\n    # returns the same as the one in libsvm\n    # multi class:\n    clf = svm.SVC(kernel=\"linear\", C=0.1, decision_function_shape=\"ovo\").fit(\n        iris.data, iris.target\n    )\n\n    dec = np.dot(iris.data, clf.coef_.T) + clf.intercept_\n\n    assert_array_almost_equal(dec, clf.decision_function(iris.data))\n\n    # binary:\n    clf.fit(X, Y)\n    dec = np.dot(X, clf.coef_.T) + clf.intercept_\n    prediction = clf.predict(X)\n    assert_array_almost_equal(dec.ravel(), clf.decision_function(X))\n    assert_array_almost_equal(\n        prediction, clf.classes_[(clf.decision_function(X) > 0).astype(int)]\n    )\n    expected = np.array([-1.0, -0.66, -1.0, 0.66, 1.0, 1.0])\n    assert_array_almost_equal(clf.decision_function(X), expected, 2)\n\n    # kernel binary:\n    clf = svm.SVC(kernel=\"rbf\", gamma=1, decision_function_shape=\"ovo\")\n    clf.fit(X, Y)\n\n    rbfs = rbf_kernel(X, clf.support_vectors_, gamma=clf.gamma)\n    dec = np.dot(rbfs, clf.dual_coef_.T) + clf.intercept_\n    assert_array_almost_equal(dec.ravel(), clf.decision_function(X))\n\n\n@pytest.mark.parametrize(\"SVM\", (svm.SVC, svm.NuSVC))\ndef test_decision_function_shape(SVM, global_random_seed):\n    # check that decision_function_shape='ovr' or 'ovo' gives\n    # correct shape and is consistent with predict\n    iris = get_iris_dataset(global_random_seed)\n\n   "}], "retrieved_count": 10, "cost_time": 0.4305233955383301}
