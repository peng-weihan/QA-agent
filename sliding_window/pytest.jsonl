{"question": "What is the interaction mechanism between Pytest's FixtureManager class and the FixtureRequest class to establish the relationship between fixture dependencies and fixture execution?", "answer": null, "relative_code_list": null, "ground_truth": "The interaction mechanism between FixtureManager and FixtureRequest establishes a dependency resolution and execution system: 1) FixtureManager serves as the central registry that stores all fixture definitions in _arg2fixturedefs mapping fixture names to FixtureDef objects, 2) FixtureManager provides getfixtureinfo() method that analyzes test functions and creates FuncFixtureInfo objects containing fixture dependency information, 3) FixtureRequest acts as the execution context that provides access to fixture information and manages fixture resolution during test execution, 4) FixtureRequest maintains _arg2fixturedefs and _fixture_defs attributes that map fixture names to their definitions and resolved instances, 5) The dependency resolution process involves FixtureRequest calling _get_active_fixturedef() to find and execute the appropriate FixtureDef for each requested fixture, 6) FixtureRequest creates SubRequest instances for each fixture execution, passing scope, parameters, and context information, 7) FixtureManager's parsefactories() method during collection discovers and registers all fixture definitions, 8) FixtureRequest's getfixturevalue() method provides dynamic fixture access during test execution, 9) The interaction ensures proper fixture scoping through _check_scope() validation, 10) Fixture caching is coordinated between FixtureManager's registry and FixtureRequest's execution context, 11) Dependency ordering is handled through the fixture closure calculation in FixtureManager, 12) The relationship enables both static (collection-time) and dynamic (execution-time) fixture resolution.", "score": null, "retrieved_content": [{"start_line": 13000, "end_line": 15000, "belongs_to": {"file_name": "fixtures.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "        working_set = set(self.initialnames)\n        while working_set:\n            argname = working_set.pop()\n            # Argname may be something not included in the original names_closure,\n            # in which case we ignore it. This currently happens with pseudo\n            # FixtureDefs which wrap 'get_direct_param_fixture_func(request)'.\n            # So they introduce the new dependency 'request' which might have\n            # been missing in the original tree (closure).\n            if argname not in closure and argname in self.names_closure:\n                closure.add(argname)\n                if argname in self.name2fixturedefs:\n                    working_set.update(self.name2fixturedefs[argname][-1].argnames)\n\n        self.names_closure[:] = sorted(closure, key=self.names_closure.index)\n\n\nclass FixtureRequest(abc.ABC):\n    \"\"\"The type of the ``request`` fixture.\n\n    A request object gives access to the requesting test context and has a\n    ``param`` attribute in case the fixture is parametrized.\n    \"\"\"\n\n    def __init__(\n        self,\n        pyfuncitem: Function,\n        fixturename: str | None,\n        arg2fixturedefs: dict[str, Sequence[FixtureDef[Any]]],\n        fixture_defs: dict[str, FixtureDef[Any]],\n        *,\n        _ispytest: bool = False,\n    ) -> None:\n        check_ispytest(_ispytest)\n        #: Fixture for which this request is being performed.\n        self.fixturename: Final = fixturename\n        self._pyfuncitem: Final = pyfuncitem\n        # The FixtureDefs for each fixture name requested by this item.\n        # Starts from the statically-known fixturedefs resolved during\n        # collection. Dynamically requested fixtures (using\n        # `request.getfixturevalue(\"foo\")`) are added dynamically.\n        self._arg2fixturedefs: Final = arg2fixturedefs\n        # The evaluated argnames so far, mapping to the FixtureDef they resolved\n        # to.\n        self._fixture_defs: Final = fixture_defs\n        # Notes on the type of `param`:\n"}, {"start_line": 12000, "end_line": 14000, "belongs_to": {"file_name": "fixtures.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "c dependencies (`request.getfixturevalue` calls).\n    names_closure: list[str]\n    # A map from a fixture name in the transitive closure to the FixtureDefs\n    # matching the name which are applicable to this function.\n    # There may be multiple overriding fixtures with the same name. The\n    # sequence is ordered from furthest to closes to the function.\n    name2fixturedefs: dict[str, Sequence[FixtureDef[Any]]]\n\n    def prune_dependency_tree(self) -> None:\n        \"\"\"Recompute names_closure from initialnames and name2fixturedefs.\n\n        Can only reduce names_closure, which means that the new closure will\n        always be a subset of the old one. The order is preserved.\n\n        This method is needed because direct parametrization may shadow some\n        of the fixtures that were included in the originally built dependency\n        tree. In this way the dependency tree can get pruned, and the closure\n        of argnames may get reduced.\n        \"\"\"\n        closure: set[str] = set()\n        working_set = set(self.initialnames)\n        while working_set:\n            argname = working_set.pop()\n            # Argname may be something not included in the original names_closure,\n            # in which case we ignore it. This currently happens with pseudo\n            # FixtureDefs which wrap 'get_direct_param_fixture_func(request)'.\n            # So they introduce the new dependency 'request' which might have\n            # been missing in the original tree (closure).\n            if argname not in closure and argname in self.names_closure:\n                closure.add(argname)\n                if argname in self.name2fixturedefs:\n                    working_set.update(self.name2fixturedefs[argname][-1].argnames)\n\n        self.names_closure[:] = sorted(closure, key=self.names_closure.index)\n\n\nclass FixtureRequest(abc.ABC):\n    \"\"\"The type of the ``request`` fixture.\n\n    A request object gives access to the requesting test context and has a\n    ``param`` attribute in case t"}, {"start_line": 26000, "end_line": 28000, "belongs_to": {"file_name": "fixtures.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "d for test:\\n\"\n                f\"    {funcitem.nodeid}\\n\\n\"\n                f\"Requested fixture '{fixturedef.argname}' defined in:\\n\"\n                f\"{location}\\n\\n\"\n                f\"Requested here:\\n\"\n                f\"{source_path_str}:{source_lineno}\"\n            )\n            fail(msg, pytrace=False)\n\n    def _get_fixturestack(self) -> list[FixtureDef[Any]]:\n        values = [request._fixturedef for request in self._iter_chain()]\n        values.reverse()\n        return values\n\n\n@final\nclass TopRequest(FixtureRequest):\n    \"\"\"The type of the ``request`` fixture in a test function.\"\"\"\n\n    def __init__(self, pyfuncitem: Function, *, _ispytest: bool = False) -> None:\n        super().__init__(\n            fixturename=None,\n            pyfuncitem=pyfuncitem,\n            arg2fixturedefs=pyfuncitem._fixtureinfo.name2fixturedefs.copy(),\n            fixture_defs={},\n            _ispytest=_ispytest,\n        )\n\n    @property\n    def _scope(self) -> Scope:\n        return Scope.Function\n\n    def _check_scope(\n        self,\n        requested_fixturedef: FixtureDef[object] | PseudoFixtureDef[object],\n        requested_scope: Scope,\n    ) -> None:\n        # TopRequest always has function scope so always valid.\n        pass\n\n    @property\n    def node(self):\n        return self._pyfuncitem\n\n    def __repr__(self) -> str:\n        return f\"<FixtureRequest for {self.node!r}>\"\n\n    def _fillfixtures(self) -> None:\n        item = self._pyfuncitem\n        for argname in item.fixturenames:\n            if argname not in item.funcargs:\n                item.funcargs[argname] = self.getfixturevalue(argname)\n\n    def addfinalizer(self, finalizer: Callable[[], object]) -> None:\n        self.node.addfinalizer(finalizer)\n\n\n@final\nclass SubRequest(FixtureRequest):\n    \"\"\"The type of the ``request`` fixture in a fixture function requested\n    (transitively) by a test function.\"\"\"\n\n    def __init__(\n        self,\n        request: FixtureRequest,\n        scope: Scope,\n        param: Any,\n      "}, {"start_line": 27000, "end_line": 29000, "belongs_to": {"file_name": "fixtures.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": " def _check_scope(\n        self,\n        requested_fixturedef: FixtureDef[object] | PseudoFixtureDef[object],\n        requested_scope: Scope,\n    ) -> None:\n        # TopRequest always has function scope so always valid.\n        pass\n\n    @property\n    def node(self):\n        return self._pyfuncitem\n\n    def __repr__(self) -> str:\n        return f\"<FixtureRequest for {self.node!r}>\"\n\n    def _fillfixtures(self) -> None:\n        item = self._pyfuncitem\n        for argname in item.fixturenames:\n            if argname not in item.funcargs:\n                item.funcargs[argname] = self.getfixturevalue(argname)\n\n    def addfinalizer(self, finalizer: Callable[[], object]) -> None:\n        self.node.addfinalizer(finalizer)\n\n\n@final\nclass SubRequest(FixtureRequest):\n    \"\"\"The type of the ``request`` fixture in a fixture function requested\n    (transitively) by a test function.\"\"\"\n\n    def __init__(\n        self,\n        request: FixtureRequest,\n        scope: Scope,\n        param: Any,\n        param_index: int,\n        fixturedef: FixtureDef[object],\n        *,\n        _ispytest: bool = False,\n    ) -> None:\n        super().__init__(\n            pyfuncitem=request._pyfuncitem,\n            fixturename=fixturedef.argname,\n            fixture_defs=request._fixture_defs,\n            arg2fixturedefs=request._arg2fixturedefs,\n            _ispytest=_ispytest,\n        )\n        self._parent_request: Final[FixtureRequest] = request\n        self._scope_field: Final = scope\n        self._fixturedef: Final[FixtureDef[object]] = fixturedef\n        if param is not NOTSET:\n            self.param = param\n        self.param_index: Final = param_index\n\n    def __repr__(self) -> str:\n        return f\"<SubRequest {self.fixturename!r} for {self._pyfuncitem!r}>\"\n\n    @property\n    def _scope(self) -> Scope:\n        return self._scope_field\n\n    @property\n    def node(self):\n        scope = self._scope\n        if scope is Scope.Function:\n            # This might also be a non-function Item despi"}, {"start_line": 0, "end_line": 321, "belongs_to": {"file_name": "test_getfixturevalue_dynamic.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing/example_scripts/fixtures", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "# mypy: allow-untyped-defs\nfrom __future__ import annotations\n\nimport pytest\n\n\n@pytest.fixture\ndef dynamic():\n    pass\n\n\n@pytest.fixture\ndef a(request):\n    request.getfixturevalue(\"dynamic\")\n\n\n@pytest.fixture\ndef b(a):\n    pass\n\n\ndef test(b, request):\n    assert request.fixturenames == [\"b\", \"request\", \"a\", \"dynamic\"]\n"}, {"start_line": 59000, "end_line": 61000, "belongs_to": {"file_name": "fixtures.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "ture name (argname) to all of the FixtureDefs in the test\n        # suite/plugins defined with this name. Populated by parsefactories().\n        # TODO: The order of the FixtureDefs list of each arg is significant,\n        #       explain.\n        self._arg2fixturedefs: Final[dict[str, list[FixtureDef[Any]]]] = {}\n        self._holderobjseen: Final[set[object]] = set()\n        # A mapping from a nodeid to a list of autouse fixtures it defines.\n        self._nodeid_autousenames: Final[dict[str, list[str]]] = {\n            \"\": self.config.getini(\"usefixtures\"),\n        }\n        session.config.pluginmanager.register(self, \"funcmanage\")\n\n    def getfixtureinfo(\n        self,\n        node: nodes.Item,\n        func: Callable[..., object] | None,\n        cls: type | None,\n    ) -> FuncFixtureInfo:\n        \"\"\"Calculate the :class:`FuncFixtureInfo` for an item.\n\n        If ``func`` is None, or if the item sets an attribute\n        ``nofuncargs = True``, then ``func`` is not examined at all.\n\n        :param node:\n            The item requesting the fixtures.\n        :param func:\n            The item's function.\n        :param cls:\n            If the function is a method, the method's class.\n        \"\"\"\n        if func is not None and not getattr(node, \"nofuncargs\", False):\n            argnames = getfuncargnames(func, name=node.name, cls=cls)\n        else:\n            argnames = ()\n        usefixturesnames = self._getusefixturesnames(node)\n        autousenames = self._getautousenames(node)\n        initialnames = deduplicate_names(autousenames, usefixturesnames, argnames)\n\n        direct_parametrize_args = _get_direct_parametrize_args(node)\n\n        names_closure, arg2fixturedefs = self.getfixtureclosure(\n            parentnode=node,\n            initialnames=initialnames,\n            ignore_args=direct_parametrize_args,\n        )\n\n        return FuncFixtureInfo(argnames, initialnames, names_closure, arg2fixturedefs)\n\n    def pytest_plugin_registered(self, plugin: _PluggyPlugin"}, {"start_line": 44000, "end_line": 46000, "belongs_to": {"file_name": "fixtures.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "t=request)\n        for parent_fixture in requested_fixtures_that_should_finalize_us:\n            parent_fixture.addfinalizer(finalizer)\n\n        ihook = request.node.ihook\n        try:\n            # Setup the fixture, run the code in it, and cache the value\n            # in self.cached_result.\n            result: FixtureValue = ihook.pytest_fixture_setup(\n                fixturedef=self, request=request\n            )\n        finally:\n            # Schedule our finalizer, even if the setup failed.\n            request.node.addfinalizer(finalizer)\n\n        return result\n\n    def cache_key(self, request: SubRequest) -> object:\n        return getattr(request, \"param\", None)\n\n    def __repr__(self) -> str:\n        return f\"<FixtureDef argname={self.argname!r} scope={self.scope!r} baseid={self.baseid!r}>\"\n\n\ndef resolve_fixture_function(\n    fixturedef: FixtureDef[FixtureValue], request: FixtureRequest\n) -> _FixtureFunc[FixtureValue]:\n    \"\"\"Get the actual callable that can be called to obtain the fixture\n    value.\"\"\"\n    fixturefunc = fixturedef.func\n    # The fixture function needs to be bound to the actual\n    # request.instance so that code working with \"fixturedef\" behaves\n    # as expected.\n    instance = request.instance\n    if instance is not None:\n        # Handle the case where fixture is defined not in a test class, but some other class\n        # (for example a plugin class with a fixture), see #2270.\n        if hasattr(fixturefunc, \"__self__\") and not isinstance(\n            instance,\n            fixturefunc.__self__.__class__,\n        ):\n            return fixturefunc\n        fixturefunc = getimfunc(fixturedef.func)\n        if fixturefunc != fixturedef.func:\n            fixturefunc = fixturefunc.__get__(instance)\n    return fixturefunc\n\n\ndef pytest_fixture_setup(\n    fixturedef: FixtureDef[FixtureValue], request: SubRequest\n) -> FixtureValue:\n    \"\"\"Execution of fixture setup.\"\"\"\n    kwargs = {}\n    for argname in fixturedef.argnames:\n        kwargs[argname] ="}, {"start_line": 16000, "end_line": 18000, "belongs_to": {"file_name": "fixtures.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "_fixturedef: FixtureDef[object] | PseudoFixtureDef[object],\n        requested_scope: Scope,\n    ) -> None:\n        raise NotImplementedError()\n\n    @property\n    def fixturenames(self) -> list[str]:\n        \"\"\"Names of all active fixtures in this request.\"\"\"\n        result = list(self._pyfuncitem.fixturenames)\n        result.extend(set(self._fixture_defs).difference(result))\n        return result\n\n    @property\n    @abc.abstractmethod\n    def node(self):\n        \"\"\"Underlying collection node (depends on current request scope).\"\"\"\n        raise NotImplementedError()\n\n    @property\n    def config(self) -> Config:\n        \"\"\"The pytest config object associated with this request.\"\"\"\n        return self._pyfuncitem.config\n\n    @property\n    def function(self):\n        \"\"\"Test function object if the request has a per-function scope.\"\"\"\n        if self.scope != \"function\":\n            raise AttributeError(\n                f\"function not available in {self.scope}-scoped context\"\n            )\n        return self._pyfuncitem.obj\n\n    @property\n    def cls(self):\n        \"\"\"Class (can be None) where the test function was collected.\"\"\"\n        if self.scope not in (\"class\", \"function\"):\n            raise AttributeError(f\"cls not available in {self.scope}-scoped context\")\n        clscol = self._pyfuncitem.getparent(_pytest.python.Class)\n        if clscol:\n            return clscol.obj\n\n    @property\n    def instance(self):\n        \"\"\"Instance (can be None) on which test function was collected.\"\"\"\n        if self.scope != \"function\":\n            return None\n        return getattr(self._pyfuncitem, \"instance\", None)\n\n    @property\n    def module(self):\n        \"\"\"Python module object where the test function was collected.\"\"\"\n        if self.scope not in (\"function\", \"class\", \"module\"):\n            raise AttributeError(f\"module not available in {self.scope}-scoped context\")\n        mod = self._pyfuncitem.getparent(_pytest.python.Module)\n        assert mod is not None\n        retur"}, {"start_line": 21000, "end_line": 23000, "belongs_to": {"file_name": "fixtures.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "est.\n        \"\"\"\n        current = self\n        while isinstance(current, SubRequest):\n            yield current\n            current = current._parent_request\n\n    def _get_active_fixturedef(\n        self, argname: str\n    ) -> FixtureDef[object] | PseudoFixtureDef[object]:\n        if argname == \"request\":\n            cached_result = (self, [0], None)\n            return PseudoFixtureDef(cached_result, Scope.Function)\n\n        # If we already finished computing a fixture by this name in this item,\n        # return it.\n        fixturedef = self._fixture_defs.get(argname)\n        if fixturedef is not None:\n            self._check_scope(fixturedef, fixturedef._scope)\n            return fixturedef\n\n        # Find the appropriate fixturedef.\n        fixturedefs = self._arg2fixturedefs.get(argname, None)\n        if fixturedefs is None:\n            # We arrive here because of a dynamic call to\n            # getfixturevalue(argname) which was naturally\n            # not known at parsing/collection time.\n            fixturedefs = self._fixturemanager.getfixturedefs(argname, self._pyfuncitem)\n            if fixturedefs is not None:\n                self._arg2fixturedefs[argname] = fixturedefs\n        # No fixtures defined with this name.\n        if fixturedefs is None:\n            raise FixtureLookupError(argname, self)\n        # The are no fixtures with this name applicable for the function.\n        if not fixturedefs:\n            raise FixtureLookupError(argname, self)\n\n        # A fixture may override another fixture with the same name, e.g. a\n        # fixture in a module can override a fixture in a conftest, a fixture in\n        # a class can override a fixture in the module, and so on.\n        # An overriding fixture can request its own name (possibly indirectly);\n        # in this case it gets the value of the fixture it overrides, one level\n        # up.\n        # Check how many `argname`s deep we are, and take the next one.\n        # `fixturedefs` is sorted from furthe"}, {"start_line": 25000, "end_line": 27000, "belongs_to": {"file_name": "fixtures.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "= fixturedef.params is not None\n        fixtures_not_supported = getattr(funcitem, \"nofuncargs\", False)\n        if has_params and fixtures_not_supported:\n            msg = (\n                f\"{funcitem.name} does not support fixtures, maybe unittest.TestCase subclass?\\n\"\n                f\"Node id: {funcitem.nodeid}\\n\"\n                f\"Function type: {type(funcitem).__name__}\"\n            )\n            fail(msg, pytrace=False)\n        if has_params:\n            frame = inspect.stack()[3]\n            frameinfo = inspect.getframeinfo(frame[0])\n            source_path = absolutepath(frameinfo.filename)\n            source_lineno = frameinfo.lineno\n            try:\n                source_path_str = str(source_path.relative_to(funcitem.config.rootpath))\n            except ValueError:\n                source_path_str = str(source_path)\n            location = getlocation(fixturedef.func, funcitem.config.rootpath)\n            msg = (\n                \"The requested fixture has no parameter defined for test:\\n\"\n                f\"    {funcitem.nodeid}\\n\\n\"\n                f\"Requested fixture '{fixturedef.argname}' defined in:\\n\"\n                f\"{location}\\n\\n\"\n                f\"Requested here:\\n\"\n                f\"{source_path_str}:{source_lineno}\"\n            )\n            fail(msg, pytrace=False)\n\n    def _get_fixturestack(self) -> list[FixtureDef[Any]]:\n        values = [request._fixturedef for request in self._iter_chain()]\n        values.reverse()\n        return values\n\n\n@final\nclass TopRequest(FixtureRequest):\n    \"\"\"The type of the ``request`` fixture in a test function.\"\"\"\n\n    def __init__(self, pyfuncitem: Function, *, _ispytest: bool = False) -> None:\n        super().__init__(\n            fixturename=None,\n            pyfuncitem=pyfuncitem,\n            arg2fixturedefs=pyfuncitem._fixtureinfo.name2fixturedefs.copy(),\n            fixture_defs={},\n            _ispytest=_ispytest,\n        )\n\n    @property\n    def _scope(self) -> Scope:\n        return Scope.Function\n\n   "}], "retrieved_count": 10, "cost_time": 1.0008163452148438}
{"question": "What is the role of the Session class in pytest?", "answer": null, "relative_code_list": null, "ground_truth": "The Session class serves as the root of the collection tree and the main orchestrator of the pytest test execution process. Its key roles include: 1) Root collector that initiates test collection from the initial paths given as command line arguments, 2) Manages the overall test session state including testsfailed and testscollected counters, 3) Coordinates the collection phase through perform_collect() method which discovers and organizes test items, 4) Maintains the collection tree hierarchy with items list containing all discovered test items, 5) Handles session-level control flow with shouldstop and shouldfail flags for early termination, 6) Integrates with fixture management through _fixturemanager and setup state through _setupstate, 7) Provides session-scoped configuration access and plugin management, 8) Manages collection caching and duplicate handling for efficient test discovery, 9) Coordinates with the test runner through pytest_runtestloop hook, 10) Handles session-level hooks like pytest_sessionstart and pytest_sessionfinish, 11) Maintains exit status and error handling for the entire test session, 12) Serves as the entry point for the main test execution protocol.", "score": null, "retrieved_content": [{"start_line": 18000, "end_line": 20000, "belongs_to": {"file_name": "main.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "= frozenset()\n        self._initialpaths_with_parents: frozenset[Path] = frozenset()\n        self._notfound: list[tuple[str, Sequence[nodes.Collector]]] = []\n        self._initial_parts: list[CollectionArgument] = []\n        self._collection_cache: dict[nodes.Collector, CollectReport] = {}\n        self.items: list[nodes.Item] = []\n\n        self._bestrelpathcache: dict[Path, str] = _bestrelpath_cache(config.rootpath)\n\n        self.config.pluginmanager.register(self, name=\"session\")\n\n    @classmethod\n    def from_config(cls, config: Config) -> Session:\n        session: Session = cls._create(config=config)\n        return session\n\n    def __repr__(self) -> str:\n        return (\n            f\"<{self.__class__.__name__} {self.name} \"\n            f\"exitstatus=%r \"\n            f\"testsfailed={self.testsfailed} \"\n            f\"testscollected={self.testscollected}>\"\n        ) % getattr(self, \"exitstatus\", \"<UNSET>\")\n\n    @property\n    def shouldstop(self) -> bool | str:\n        return self._shouldstop\n\n    @shouldstop.setter\n    def shouldstop(self, value: bool | str) -> None:\n        # The runner checks shouldfail and assumes that if it is set we are\n        # definitely stopping, so prevent unsetting it.\n        if value is False and self._shouldstop:\n            warnings.warn(\n                PytestWarning(\n                    \"session.shouldstop cannot be unset after it has been set; ignoring.\"\n                ),\n                stacklevel=2,\n            )\n            return\n        self._shouldstop = value\n\n    @property\n    def shouldfail(self) -> bool | str:\n        return self._shouldfail\n\n    @shouldfail.setter\n    def shouldfail(self, value: bool | str) -> None:\n        # The runner checks shouldfail and assumes that if it is set we are\n        # definitely stopping, so prevent unsetting it.\n        if value is False and self._shouldfail:\n            warnings.warn(\n                PytestWarning(\n                    \"session.shouldfail cannot be unset after it has bee"}, {"start_line": 17000, "end_line": 19000, "belongs_to": {"file_name": "main.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "le_path=path, parent=self)\n                yield from cols\n\n\n@final\nclass Session(nodes.Collector):\n    \"\"\"The root of the collection tree.\n\n    ``Session`` collects the initial paths given as arguments to pytest.\n    \"\"\"\n\n    Interrupted = Interrupted\n    Failed = Failed\n    # Set on the session by runner.pytest_sessionstart.\n    _setupstate: SetupState\n    # Set on the session by fixtures.pytest_sessionstart.\n    _fixturemanager: FixtureManager\n    exitstatus: int | ExitCode\n\n    def __init__(self, config: Config) -> None:\n        super().__init__(\n            name=\"\",\n            path=config.rootpath,\n            fspath=None,\n            parent=None,\n            config=config,\n            session=self,\n            nodeid=\"\",\n        )\n        self.testsfailed = 0\n        self.testscollected = 0\n        self._shouldstop: bool | str = False\n        self._shouldfail: bool | str = False\n        self.trace = config.trace.root.get(\"collection\")\n        self._initialpaths: frozenset[Path] = frozenset()\n        self._initialpaths_with_parents: frozenset[Path] = frozenset()\n        self._notfound: list[tuple[str, Sequence[nodes.Collector]]] = []\n        self._initial_parts: list[CollectionArgument] = []\n        self._collection_cache: dict[nodes.Collector, CollectReport] = {}\n        self.items: list[nodes.Item] = []\n\n        self._bestrelpathcache: dict[Path, str] = _bestrelpath_cache(config.rootpath)\n\n        self.config.pluginmanager.register(self, name=\"session\")\n\n    @classmethod\n    def from_config(cls, config: Config) -> Session:\n        session: Session = cls._create(config=config)\n        return session\n\n    def __repr__(self) -> str:\n        return (\n            f\"<{self.__class__.__name__} {self.name} \"\n            f\"exitstatus=%r \"\n            f\"testsfailed={self.testsfailed} \"\n            f\"testscollected={self.testscollected}>\"\n        ) % getattr(self, \"exitstatus\", \"<UNSET>\")\n\n    @property\n    def shouldstop(self) -> bool | str:\n        return self._shoul"}, {"start_line": 19000, "end_line": 21000, "belongs_to": {"file_name": "main.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "dstop\n\n    @shouldstop.setter\n    def shouldstop(self, value: bool | str) -> None:\n        # The runner checks shouldfail and assumes that if it is set we are\n        # definitely stopping, so prevent unsetting it.\n        if value is False and self._shouldstop:\n            warnings.warn(\n                PytestWarning(\n                    \"session.shouldstop cannot be unset after it has been set; ignoring.\"\n                ),\n                stacklevel=2,\n            )\n            return\n        self._shouldstop = value\n\n    @property\n    def shouldfail(self) -> bool | str:\n        return self._shouldfail\n\n    @shouldfail.setter\n    def shouldfail(self, value: bool | str) -> None:\n        # The runner checks shouldfail and assumes that if it is set we are\n        # definitely stopping, so prevent unsetting it.\n        if value is False and self._shouldfail:\n            warnings.warn(\n                PytestWarning(\n                    \"session.shouldfail cannot be unset after it has been set; ignoring.\"\n                ),\n                stacklevel=2,\n            )\n            return\n        self._shouldfail = value\n\n    @property\n    def startpath(self) -> Path:\n        \"\"\"The path from which pytest was invoked.\n\n        .. versionadded:: 7.0.0\n        \"\"\"\n        return self.config.invocation_params.dir\n\n    def _node_location_to_relpath(self, node_path: Path) -> str:\n        # bestrelpath is a quite slow function.\n        return self._bestrelpathcache[node_path]\n\n    @hookimpl(tryfirst=True)\n    def pytest_collectstart(self) -> None:\n        if self.shouldfail:\n            raise self.Failed(self.shouldfail)\n        if self.shouldstop:\n            raise self.Interrupted(self.shouldstop)\n\n    @hookimpl(tryfirst=True)\n    def pytest_runtest_logreport(self, report: TestReport | CollectReport) -> None:\n        if report.failed and not hasattr(report, \"wasxfail\"):\n            self.testsfailed += 1\n            maxfail = self.config.getvalue(\"maxfail\")\n            if maxf"}, {"start_line": 5000, "end_line": 7000, "belongs_to": {"file_name": "test_session.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "c.listoutcomes()\n        assert (len(passed), len(skipped), len(failed)) == (0, 0, 1)\n        entries = failed[0].longrepr.reprtraceback.reprentries  # type: ignore[union-attr]\n        assert len(entries) == 1\n        repr_locals = entries[0].reprlocals\n        assert repr_locals.lines\n        assert len(repr_locals.lines) == 1\n        assert repr_locals.lines[0].startswith(\n            \"x          = <[NotImplementedError() raised in repr()] ObjWithErrorInRepr\"\n        )\n\n    def test_skip_file_by_conftest(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            conftest=\"\"\"\n            import pytest\n            def pytest_collect_file():\n                pytest.skip(\"intentional\")\n        \"\"\",\n            test_file=\"\"\"\n            def test_one(): pass\n        \"\"\",\n        )\n        try:\n            reprec = pytester.inline_run(pytester.path)\n        except pytest.skip.Exception:  # pragma: no cover\n            pytest.fail(\"wrong skipped caught\")\n        reports = reprec.getreports(\"pytest_collectreport\")\n        # Session, Dir\n        assert len(reports) == 2\n        assert reports[1].skipped\n\n\nclass TestNewSession(SessionTests):\n    def test_order_of_execution(self, pytester: Pytester) -> None:\n        reprec = pytester.inline_runsource(\n            \"\"\"\n            values = []\n            def test_1():\n                values.append(1)\n            def test_2():\n                values.append(2)\n            def test_3():\n                assert values == [1,2]\n            class Testmygroup(object):\n                reslist = values\n                def test_1(self):\n                    self.reslist.append(1)\n                def test_2(self):\n                    self.reslist.append(2)\n                def test_3(self):\n                    self.reslist.append(3)\n                def test_4(self):\n                    assert self.reslist == [1,2,1,2,3]\n        \"\"\"\n        )\n        passed, skipped, failed = reprec.countoutcomes()\n        assert failed == ski"}, {"start_line": 15000, "end_line": 17000, "belongs_to": {"file_name": "pytester.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "during initialization.\n\n    It is particularly useful for testing plugins. It is similar to the :fixture:`tmp_path`\n    fixture but provides methods which aid in testing pytest itself.\n    \"\"\"\n    return Pytester(request, tmp_path_factory, monkeypatch, _ispytest=True)\n\n\n@fixture\ndef _sys_snapshot() -> Generator[None]:\n    snappaths = SysPathsSnapshot()\n    snapmods = SysModulesSnapshot()\n    yield\n    snapmods.restore()\n    snappaths.restore()\n\n\n@fixture\ndef _config_for_test() -> Generator[Config]:\n    from _pytest.config import get_config\n\n    config = get_config()\n    yield config\n    config._ensure_unconfigure()  # cleanup, e.g. capman closing tmpfiles.\n\n\n# Regex to match the session duration string in the summary: \"74.34s\".\nrex_session_duration = re.compile(r\"\\d+\\.\\d\\ds\")\n# Regex to match all the counts and phrases in the summary line: \"34 passed, 111 skipped\".\nrex_outcome = re.compile(r\"(\\d+) (\\w+)\")\n\n\n@final\nclass RunResult:\n    \"\"\"The result of running a command from :class:`~pytest.Pytester`.\"\"\"\n\n    def __init__(\n        self,\n        ret: int | ExitCode,\n        outlines: list[str],\n        errlines: list[str],\n        duration: float,\n    ) -> None:\n        try:\n            self.ret: int | ExitCode = ExitCode(ret)\n            \"\"\"The return value.\"\"\"\n        except ValueError:\n            self.ret = ret\n        self.outlines = outlines\n        \"\"\"List of lines captured from stdout.\"\"\"\n        self.errlines = errlines\n        \"\"\"List of lines captured from stderr.\"\"\"\n        self.stdout = LineMatcher(outlines)\n        \"\"\":class:`~pytest.LineMatcher` of stdout.\n\n        Use e.g. :func:`str(stdout) <pytest.LineMatcher.__str__()>` to reconstruct stdout, or the commonly used\n        :func:`stdout.fnmatch_lines() <pytest.LineMatcher.fnmatch_lines()>` method.\n        \"\"\"\n        self.stderr = LineMatcher(errlines)\n        \"\"\":class:`~pytest.LineMatcher` of stderr.\"\"\"\n        self.duration = duration\n        \"\"\"Duration in seconds.\"\"\"\n\n    def __repr__(self) -> st"}, {"start_line": 0, "end_line": 2000, "belongs_to": {"file_name": "test_session.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "# mypy: allow-untyped-defs\nfrom __future__ import annotations\n\nfrom _pytest.config import ExitCode\nfrom _pytest.monkeypatch import MonkeyPatch\nfrom _pytest.pytester import Pytester\nimport pytest\n\n\nclass SessionTests:\n    def test_basic_testitem_events(self, pytester: Pytester) -> None:\n        tfile = pytester.makepyfile(\n            \"\"\"\n            def test_one():\n                pass\n            def test_one_one():\n                assert 0\n            def test_other():\n                raise ValueError(23)\n            class TestClass(object):\n                def test_two(self, someargs):\n                    pass\n        \"\"\"\n        )\n        reprec = pytester.inline_run(tfile)\n        passed, skipped, failed = reprec.listoutcomes()\n        assert len(skipped) == 0\n        assert len(passed) == 1\n        assert len(failed) == 3\n\n        def end(x):\n            return x.nodeid.split(\"::\")[-1]\n\n        assert end(failed[0]) == \"test_one_one\"\n        assert end(failed[1]) == \"test_other\"\n        itemstarted = reprec.getcalls(\"pytest_itemcollected\")\n        assert len(itemstarted) == 4\n        # XXX check for failing funcarg setup\n        # colreports = reprec.getcalls(\"pytest_collectreport\")\n        # assert len(colreports) == 4\n        # assert colreports[1].report.failed\n\n    def test_nested_import_error(self, pytester: Pytester) -> None:\n        tfile = pytester.makepyfile(\n            \"\"\"\n            import import_fails\n            def test_this():\n                assert import_fails.a == 1\n        \"\"\",\n            import_fails=\"\"\"\n            import does_not_work\n            a = 1\n        \"\"\",\n        )\n        reprec = pytester.inline_run(tfile)\n        values = reprec.getfailedcollections()\n        assert len(values) == 1\n        out = str(values[0].longrepr)\n        assert out.find(\"does_not_work\") != -1\n\n    def test_raises_output(self, pytester: Pytester) -> None:\n        reprec = pytester.inline_runsource(\n            \"\"\"\n            import pytest\n          "}, {"start_line": 9000, "end_line": 11000, "belongs_to": {"file_name": "main.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "             exitstatus = excinfo.value.returncode\n                if initstate < 2:\n                    sys.stderr.write(f\"{excinfo.typename}: {excinfo.value.msg}\\n\")\n            config.hook.pytest_keyboard_interrupt(excinfo=excinfo)\n            session.exitstatus = exitstatus\n        except BaseException:\n            session.exitstatus = ExitCode.INTERNAL_ERROR\n            excinfo = _pytest._code.ExceptionInfo.from_current()\n            try:\n                config.notify_exception(excinfo, config.option)\n            except exit.Exception as exc:\n                if exc.returncode is not None:\n                    session.exitstatus = exc.returncode\n                sys.stderr.write(f\"{type(exc).__name__}: {exc}\\n\")\n            else:\n                if isinstance(excinfo.value, SystemExit):\n                    sys.stderr.write(\"mainloop: caught unexpected SystemExit!\\n\")\n\n    finally:\n        # Explicitly break reference cycle.\n        excinfo = None  # type: ignore\n        os.chdir(session.startpath)\n        if initstate >= 2:\n            try:\n                config.hook.pytest_sessionfinish(\n                    session=session, exitstatus=session.exitstatus\n                )\n            except exit.Exception as exc:\n                if exc.returncode is not None:\n                    session.exitstatus = exc.returncode\n                sys.stderr.write(f\"{type(exc).__name__}: {exc}\\n\")\n        config._ensure_unconfigure()\n    return session.exitstatus\n\n\ndef pytest_cmdline_main(config: Config) -> int | ExitCode:\n    return wrap_session(config, _main)\n\n\ndef _main(config: Config, session: Session) -> int | ExitCode | None:\n    \"\"\"Default command line protocol for initialization, session,\n    running tests and reporting.\"\"\"\n    config.hook.pytest_collection(session=session)\n    config.hook.pytest_runtestloop(session=session)\n\n    if session.testsfailed:\n        return ExitCode.TESTS_FAILED\n    elif session.testscollected == 0:\n        return ExitCode.NO_TESTS_COLLECTED\n   "}, {"start_line": 14000, "end_line": 15460, "belongs_to": {"file_name": "test_session.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "s_sticky(pytester: Pytester) -> None:\n    \"\"\"Test that session.shouldfail cannot be reset to False after being set.\n\n    Issue #11706.\n    \"\"\"\n    pytester.makeconftest(\n        \"\"\"\n        def pytest_sessionfinish(session):\n            assert session.shouldfail\n            session.shouldfail = False\n            assert session.shouldfail\n        \"\"\"\n    )\n    pytester.makepyfile(\n        \"\"\"\n        import pytest\n\n        def test_foo():\n            pytest.fail(\"This is a failing test\")\n\n        def test_bar(): pass\n        \"\"\"\n    )\n\n    result = pytester.runpytest(\"--maxfail=1\", \"-Wall\")\n\n    result.assert_outcomes(failed=1, warnings=1)\n    result.stdout.fnmatch_lines(\"*session.shouldfail cannot be unset*\")\n\n\ndef test_shouldstop_is_sticky(pytester: Pytester) -> None:\n    \"\"\"Test that session.shouldstop cannot be reset to False after being set.\n\n    Issue #11706.\n    \"\"\"\n    pytester.makeconftest(\n        \"\"\"\n        def pytest_sessionfinish(session):\n            assert session.shouldstop\n            session.shouldstop = False\n            assert session.shouldstop\n        \"\"\"\n    )\n    pytester.makepyfile(\n        \"\"\"\n        import pytest\n\n        def test_foo():\n            pytest.fail(\"This is a failing test\")\n\n        def test_bar(): pass\n        \"\"\"\n    )\n\n    result = pytester.runpytest(\"--stepwise\", \"-Wall\")\n\n    result.assert_outcomes(failed=1, warnings=1)\n    result.stdout.fnmatch_lines(\"*session.shouldstop cannot be unset*\")\n"}, {"start_line": 0, "end_line": 2000, "belongs_to": {"file_name": "test_main.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "# mypy: allow-untyped-defs\nfrom __future__ import annotations\n\nimport argparse\nimport os\nfrom pathlib import Path\nimport re\n\nfrom _pytest.config import ExitCode\nfrom _pytest.config import UsageError\nfrom _pytest.main import CollectionArgument\nfrom _pytest.main import resolve_collection_argument\nfrom _pytest.main import validate_basetemp\nfrom _pytest.pytester import Pytester\nimport pytest\n\n\n@pytest.mark.parametrize(\n    \"ret_exc\",\n    (\n        pytest.param((None, ValueError)),\n        pytest.param((42, SystemExit)),\n        pytest.param((False, SystemExit)),\n    ),\n)\ndef test_wrap_session_notify_exception(ret_exc, pytester: Pytester) -> None:\n    returncode, exc = ret_exc\n    c1 = pytester.makeconftest(\n        f\"\"\"\n        import pytest\n\n        def pytest_sessionstart():\n            raise {exc.__name__}(\"boom\")\n\n        def pytest_internalerror(excrepr, excinfo):\n            returncode = {returncode!r}\n            if returncode is not False:\n                pytest.exit(\"exiting after %s...\" % excinfo.typename, returncode={returncode!r})\n    \"\"\"\n    )\n    result = pytester.runpytest()\n    if returncode:\n        assert result.ret == returncode\n    else:\n        assert result.ret == ExitCode.INTERNAL_ERROR\n    assert result.stdout.lines[0] == \"INTERNALERROR> Traceback (most recent call last):\"\n\n    end_lines = result.stdout.lines[-3:]\n\n    if exc == SystemExit:\n        assert end_lines == [\n            f'INTERNALERROR>   File \"{c1}\", line 4, in pytest_sessionstart',\n            'INTERNALERROR>     raise SystemExit(\"boom\")',\n            \"INTERNALERROR> SystemExit: boom\",\n        ]\n    else:\n        assert end_lines == [\n            f'INTERNALERROR>   File \"{c1}\", line 4, in pytest_sessionstart',\n            'INTERNALERROR>     raise ValueError(\"boom\")',\n            \"INTERNALERROR> ValueError: boom\",\n        ]\n    if returncode is False:\n        assert result.stderr.lines == [\"mainloop: caught unexpected SystemExit!\"]\n    else:\n        assert result.stderr.lines == [f\""}, {"start_line": 16000, "end_line": 18000, "belongs_to": {"file_name": "main.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "m_parent(parent=parent, path=path)\n\n    def collect(self) -> Iterable[nodes.Item | nodes.Collector]:\n        config = self.config\n        col: nodes.Collector | None\n        cols: Sequence[nodes.Collector]\n        ihook = self.ihook\n        for direntry in scandir(self.path):\n            if direntry.is_dir():\n                path = Path(direntry.path)\n                if not self.session.isinitpath(path, with_parents=True):\n                    if ihook.pytest_ignore_collect(collection_path=path, config=config):\n                        continue\n                col = ihook.pytest_collect_directory(path=path, parent=self)\n                if col is not None:\n                    yield col\n\n            elif direntry.is_file():\n                path = Path(direntry.path)\n                if not self.session.isinitpath(path):\n                    if ihook.pytest_ignore_collect(collection_path=path, config=config):\n                        continue\n                cols = ihook.pytest_collect_file(file_path=path, parent=self)\n                yield from cols\n\n\n@final\nclass Session(nodes.Collector):\n    \"\"\"The root of the collection tree.\n\n    ``Session`` collects the initial paths given as arguments to pytest.\n    \"\"\"\n\n    Interrupted = Interrupted\n    Failed = Failed\n    # Set on the session by runner.pytest_sessionstart.\n    _setupstate: SetupState\n    # Set on the session by fixtures.pytest_sessionstart.\n    _fixturemanager: FixtureManager\n    exitstatus: int | ExitCode\n\n    def __init__(self, config: Config) -> None:\n        super().__init__(\n            name=\"\",\n            path=config.rootpath,\n            fspath=None,\n            parent=None,\n            config=config,\n            session=self,\n            nodeid=\"\",\n        )\n        self.testsfailed = 0\n        self.testscollected = 0\n        self._shouldstop: bool | str = False\n        self._shouldfail: bool | str = False\n        self.trace = config.trace.root.get(\"collection\")\n        self._initialpaths: frozenset[Path] "}], "retrieved_count": 10, "cost_time": 1.0172765254974365}
{"question": "What is the purpose of the AssertionRewritingHook?", "answer": null, "relative_code_list": null, "ground_truth": "The AssertionRewritingHook serves as a PEP302/PEP451 import hook that rewrites assert statements in test modules to provide detailed introspection information when assertions fail. Its main purposes are: 1) Intercepts module imports and rewrites assert statements in test files before they are compiled to bytecode, 2) Transforms plain assert statements into detailed if-else blocks that provide intermediate values and explanations when assertions fail, 3) Caches rewritten modules as .pyc files with special pytest tags to avoid re-rewriting, 4) Only rewrites test modules (as defined by python_files config) and plugin modules, not production code, 5) Provides detailed assertion failure messages showing the actual values being compared, 6) Enables the use of plain assert statements instead of unittest-style assertion methods, 7) Supports the pytest_assertion_pass hook for custom behavior when assertions pass, 8) Handles concurrent pytest processes safely through atomic file operations, 9) Can be disabled for specific modules using PYTEST_DONT_REWRITE in docstrings, 10) Integrates with pytest's configuration system to determine which files to rewrite.", "score": null, "retrieved_content": [{"start_line": 2000, "end_line": 4000, "belongs_to": {"file_name": "__init__.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest/assertion", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "lanation when an assertion fails.\"\n        ),\n    )\n\n\ndef register_assert_rewrite(*names: str) -> None:\n    \"\"\"Register one or more module names to be rewritten on import.\n\n    This function will make sure that this module or all modules inside\n    the package will get their assert statements rewritten.\n    Thus you should make sure to call this before the module is\n    actually imported, usually in your __init__.py if you are a plugin\n    using a package.\n\n    :param names: The module names to register.\n    \"\"\"\n    for name in names:\n        if not isinstance(name, str):\n            msg = \"expected module names as *args, got {0} instead\"  # type: ignore[unreachable]\n            raise TypeError(msg.format(repr(names)))\n    rewrite_hook: RewriteHook\n    for hook in sys.meta_path:\n        if isinstance(hook, rewrite.AssertionRewritingHook):\n            rewrite_hook = hook\n            break\n    else:\n        rewrite_hook = DummyRewriteHook()\n    rewrite_hook.mark_rewrite(*names)\n\n\nclass RewriteHook(Protocol):\n    def mark_rewrite(self, *names: str) -> None: ...\n\n\nclass DummyRewriteHook:\n    \"\"\"A no-op import hook for when rewriting is disabled.\"\"\"\n\n    def mark_rewrite(self, *names: str) -> None:\n        pass\n\n\nclass AssertionState:\n    \"\"\"State for the assertion plugin.\"\"\"\n\n    def __init__(self, config: Config, mode) -> None:\n        self.mode = mode\n        self.trace = config.trace.root.get(\"assertion\")\n        self.hook: rewrite.AssertionRewritingHook | None = None\n\n\ndef install_importhook(config: Config) -> rewrite.AssertionRewritingHook:\n    \"\"\"Try to install the rewrite hook, raise SystemError if it fails.\"\"\"\n    config.stash[assertstate_key] = AssertionState(config, \"rewrite\")\n    config.stash[assertstate_key].hook = hook = rewrite.AssertionRewritingHook(config)\n    sys.meta_path.insert(0, hook)\n    config.stash[assertstate_key].trace(\"installed rewrite import hook\")\n\n    def undo() -> None:\n        hook = config.stash[assertstate_key].hook\n        if hook is "}, {"start_line": 22000, "end_line": 24000, "belongs_to": {"file_name": "rewrite.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest/assertion", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "r(ast.NodeVisitor):\n    \"\"\"Assertion rewriting implementation.\n\n    The main entrypoint is to call .run() with an ast.Module instance,\n    this will then find all the assert statements and rewrite them to\n    provide intermediate values and a detailed assertion error.  See\n    http://pybites.blogspot.be/2011/07/behind-scenes-of-pytests-new-assertion.html\n    for an overview of how this works.\n\n    The entry point here is .run() which will iterate over all the\n    statements in an ast.Module and for each ast.Assert statement it\n    finds call .visit() with it.  Then .visit_Assert() takes over and\n    is responsible for creating new ast statements to replace the\n    original assert statement: it rewrites the test of an assertion\n    to provide intermediate values and replace it with an if statement\n    which raises an assertion error with a detailed explanation in\n    case the expression is false and calls pytest_assertion_pass hook\n    if expression is true.\n\n    For this .visit_Assert() uses the visitor pattern to visit all the\n    AST nodes of the ast.Assert.test field, each visit call returning\n    an AST node and the corresponding explanation string.  During this\n    state is kept in several instance attributes:\n\n    :statements: All the AST statements which will replace the assert\n       statement.\n\n    :variables: This is populated by .variable() with each variable\n       used by the statements so that they can all be set to None at\n       the end of the statements.\n\n    :variable_counter: Counter to create new unique variables needed\n       by statements.  Variables are created using .variable() and\n       have the form of \"@py_assert0\".\n\n    :expl_stmts: The AST statements which will be executed to get\n       data from the assertion.  This is the code which will construct\n       the detailed assertion message that is used in the AssertionError\n       or for the pytest_assertion_pass hook.\n\n    :explanation_specifiers: A dict filled by .explanation_param()\n   "}, {"start_line": 21000, "end_line": 23000, "belongs_to": {"file_name": "rewrite.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest/assertion", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "  seen_lines.add(lineno)\n            # a non-nested comma separates the expression from the message\n            elif depth == 0 and tp == tokenize.OP and source == \",\":\n                # one line assert with message\n                if lineno in seen_lines and len(lines) == 1:\n                    offset_in_trimmed = offset + len(lines[-1]) - len(line)\n                    lines[-1] = lines[-1][:offset_in_trimmed]\n                # multi-line assert with message\n                elif lineno in seen_lines:\n                    lines[-1] = lines[-1][:offset]\n                # multi line assert with escaped newline before message\n                else:\n                    lines.append(line[:offset])\n                _write_and_reset()\n            elif tp in {tokenize.NEWLINE, tokenize.ENDMARKER}:\n                _write_and_reset()\n            elif lines and lineno not in seen_lines:\n                lines.append(line)\n                seen_lines.add(lineno)\n\n    return ret\n\n\nclass AssertionRewriter(ast.NodeVisitor):\n    \"\"\"Assertion rewriting implementation.\n\n    The main entrypoint is to call .run() with an ast.Module instance,\n    this will then find all the assert statements and rewrite them to\n    provide intermediate values and a detailed assertion error.  See\n    http://pybites.blogspot.be/2011/07/behind-scenes-of-pytests-new-assertion.html\n    for an overview of how this works.\n\n    The entry point here is .run() which will iterate over all the\n    statements in an ast.Module and for each ast.Assert statement it\n    finds call .visit() with it.  Then .visit_Assert() takes over and\n    is responsible for creating new ast statements to replace the\n    original assert statement: it rewrites the test of an assertion\n    to provide intermediate values and replace it with an if statement\n    which raises an assertion error with a detailed explanation in\n    case the expression is false and calls pytest_assertion_pass hook\n    if expression is true.\n\n    For this .visit_Assert("}, {"start_line": 58000, "end_line": 60000, "belongs_to": {"file_name": "test_assertrewrite.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "fig)\n    spec = hook.find_spec(\"test_foo\")\n    assert spec is not None\n    module = importlib.util.module_from_spec(spec)\n    hook.exec_module(module)\n    assert len(write_pyc_called) == 1\n\n\nclass TestEarlyRewriteBailout:\n    @pytest.fixture\n    def hook(\n        self, pytestconfig, monkeypatch, pytester: Pytester\n    ) -> Generator[AssertionRewritingHook]:\n        \"\"\"Returns a patched AssertionRewritingHook instance so we can configure its initial paths and track\n        if PathFinder.find_spec has been called.\n        \"\"\"\n        import importlib.machinery\n\n        self.find_spec_calls: list[str] = []\n        self.initial_paths: set[Path] = set()\n\n        class StubSession:\n            _initialpaths = self.initial_paths\n\n            def isinitpath(self, p):\n                return p in self._initialpaths\n\n        def spy_find_spec(name, path):\n            self.find_spec_calls.append(name)\n            return importlib.machinery.PathFinder.find_spec(name, path)\n\n        hook = AssertionRewritingHook(pytestconfig)\n        # use default patterns, otherwise we inherit pytest's testing config\n        with mock.patch.object(hook, \"fnpats\", [\"test_*.py\", \"*_test.py\"]):\n            monkeypatch.setattr(hook, \"_find_spec\", spy_find_spec)\n            hook.set_session(StubSession())  # type: ignore[arg-type]\n            pytester.syspathinsert()\n            yield hook\n\n    def test_basic(self, pytester: Pytester, hook: AssertionRewritingHook) -> None:\n        \"\"\"\n        Ensure we avoid calling PathFinder.find_spec when we know for sure a certain\n        module will not be rewritten to optimize assertion rewriting (#3918).\n        \"\"\"\n        pytester.makeconftest(\n            \"\"\"\n            import pytest\n            @pytest.fixture\n            def fix(): return 1\n        \"\"\"\n        )\n        pytester.makepyfile(test_foo=\"def test_foo(): pass\")\n        pytester.makepyfile(bar=\"def bar(): pass\")\n        foobar_path = pytester.makepyfile(foobar=\"def foobar(): pass\")\n        self"}, {"start_line": 3000, "end_line": 5000, "belongs_to": {"file_name": "__init__.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest/assertion", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "ewriteHook(Protocol):\n    def mark_rewrite(self, *names: str) -> None: ...\n\n\nclass DummyRewriteHook:\n    \"\"\"A no-op import hook for when rewriting is disabled.\"\"\"\n\n    def mark_rewrite(self, *names: str) -> None:\n        pass\n\n\nclass AssertionState:\n    \"\"\"State for the assertion plugin.\"\"\"\n\n    def __init__(self, config: Config, mode) -> None:\n        self.mode = mode\n        self.trace = config.trace.root.get(\"assertion\")\n        self.hook: rewrite.AssertionRewritingHook | None = None\n\n\ndef install_importhook(config: Config) -> rewrite.AssertionRewritingHook:\n    \"\"\"Try to install the rewrite hook, raise SystemError if it fails.\"\"\"\n    config.stash[assertstate_key] = AssertionState(config, \"rewrite\")\n    config.stash[assertstate_key].hook = hook = rewrite.AssertionRewritingHook(config)\n    sys.meta_path.insert(0, hook)\n    config.stash[assertstate_key].trace(\"installed rewrite import hook\")\n\n    def undo() -> None:\n        hook = config.stash[assertstate_key].hook\n        if hook is not None and hook in sys.meta_path:\n            sys.meta_path.remove(hook)\n\n    config.add_cleanup(undo)\n    return hook\n\n\ndef pytest_collection(session: Session) -> None:\n    # This hook is only called when test modules are collected\n    # so for example not in the managing process of pytest-xdist\n    # (which does not collect test modules).\n    assertstate = session.config.stash.get(assertstate_key, None)\n    if assertstate:\n        if assertstate.hook is not None:\n            assertstate.hook.set_session(session)\n\n\n@hookimpl(wrapper=True, tryfirst=True)\ndef pytest_runtest_protocol(item: Item) -> Generator[None, object, object]:\n    \"\"\"Setup the pytest_assertrepr_compare and pytest_assertion_pass hooks.\n\n    The rewrite module will use util._reprcompare if it exists to use custom\n    reporting via the pytest_assertrepr_compare hook.  This sets up this custom\n    comparison for the test.\n    \"\"\"\n    ihook = item.ihook\n\n    def callbinrepr(op, left: object, right: object) -> str | None"}, {"start_line": 59000, "end_line": 61000, "belongs_to": {"file_name": "test_assertrewrite.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "RewritingHook(pytestconfig)\n        # use default patterns, otherwise we inherit pytest's testing config\n        with mock.patch.object(hook, \"fnpats\", [\"test_*.py\", \"*_test.py\"]):\n            monkeypatch.setattr(hook, \"_find_spec\", spy_find_spec)\n            hook.set_session(StubSession())  # type: ignore[arg-type]\n            pytester.syspathinsert()\n            yield hook\n\n    def test_basic(self, pytester: Pytester, hook: AssertionRewritingHook) -> None:\n        \"\"\"\n        Ensure we avoid calling PathFinder.find_spec when we know for sure a certain\n        module will not be rewritten to optimize assertion rewriting (#3918).\n        \"\"\"\n        pytester.makeconftest(\n            \"\"\"\n            import pytest\n            @pytest.fixture\n            def fix(): return 1\n        \"\"\"\n        )\n        pytester.makepyfile(test_foo=\"def test_foo(): pass\")\n        pytester.makepyfile(bar=\"def bar(): pass\")\n        foobar_path = pytester.makepyfile(foobar=\"def foobar(): pass\")\n        self.initial_paths.add(foobar_path)\n\n        # conftest files should always be rewritten\n        assert hook.find_spec(\"conftest\") is not None\n        assert self.find_spec_calls == [\"conftest\"]\n\n        # files matching \"python_files\" mask should always be rewritten\n        assert hook.find_spec(\"test_foo\") is not None\n        assert self.find_spec_calls == [\"conftest\", \"test_foo\"]\n\n        # file does not match \"python_files\": early bailout\n        assert hook.find_spec(\"bar\") is None\n        assert self.find_spec_calls == [\"conftest\", \"test_foo\"]\n\n        # file is an initial path (passed on the command-line): should be rewritten\n        assert hook.find_spec(\"foobar\") is not None\n        assert self.find_spec_calls == [\"conftest\", \"test_foo\", \"foobar\"]\n\n    def test_pattern_contains_subdirectories(\n        self, pytester: Pytester, hook: AssertionRewritingHook\n    ) -> None:\n        \"\"\"If one of the python_files patterns contain subdirectories (\"tests/**.py\") we can't bailout early\n   "}, {"start_line": 57000, "end_line": 59000, "belongs_to": {"file_name": "test_assertrewrite.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": " writing pyc files: if an import happens to be triggered when writing the pyc\n    file, this would cause another call to the hook, which would trigger another pyc writing, which could\n    trigger another import, and so on. (#3506)\"\"\"\n    from _pytest.assertion import rewrite as rewritemod\n\n    pytester.syspathinsert()\n    pytester.makepyfile(test_foo=\"def test_foo(): pass\")\n    pytester.makepyfile(test_bar=\"def test_bar(): pass\")\n\n    original_write_pyc = rewritemod._write_pyc\n\n    write_pyc_called = []\n\n    def spy_write_pyc(*args, **kwargs):\n        # make a note that we have called _write_pyc\n        write_pyc_called.append(True)\n        # try to import a module at this point: we should not try to rewrite this module\n        assert hook.find_spec(\"test_bar\") is None\n        return original_write_pyc(*args, **kwargs)\n\n    monkeypatch.setattr(rewritemod, \"_write_pyc\", spy_write_pyc)\n    monkeypatch.setattr(sys, \"dont_write_bytecode\", False)\n\n    hook = AssertionRewritingHook(pytestconfig)\n    spec = hook.find_spec(\"test_foo\")\n    assert spec is not None\n    module = importlib.util.module_from_spec(spec)\n    hook.exec_module(module)\n    assert len(write_pyc_called) == 1\n\n\nclass TestEarlyRewriteBailout:\n    @pytest.fixture\n    def hook(\n        self, pytestconfig, monkeypatch, pytester: Pytester\n    ) -> Generator[AssertionRewritingHook]:\n        \"\"\"Returns a patched AssertionRewritingHook instance so we can configure its initial paths and track\n        if PathFinder.find_spec has been called.\n        \"\"\"\n        import importlib.machinery\n\n        self.find_spec_calls: list[str] = []\n        self.initial_paths: set[Path] = set()\n\n        class StubSession:\n            _initialpaths = self.initial_paths\n\n            def isinitpath(self, p):\n                return p in self._initialpaths\n\n        def spy_find_spec(name, path):\n            self.find_spec_calls.append(name)\n            return importlib.machinery.PathFinder.find_spec(name, path)\n\n        hook = Assertion"}, {"start_line": 43000, "end_line": 45000, "belongs_to": {"file_name": "__init__.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest/config", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "rootdir or None,\n            invocation_dir=self.invocation_params.dir,\n        )\n        self._rootpath = rootpath\n        self._inipath = inipath\n        self.inicfg = inicfg\n        self._parser.extra_info[\"rootdir\"] = str(self.rootpath)\n        self._parser.extra_info[\"inifile\"] = str(self.inipath)\n        self._parser.addini(\"addopts\", \"Extra command line options\", \"args\")\n        self._parser.addini(\"minversion\", \"Minimally required pytest version\")\n        self._parser.addini(\n            \"pythonpath\", type=\"paths\", help=\"Add paths to sys.path\", default=[]\n        )\n        self._parser.addini(\n            \"required_plugins\",\n            \"Plugins that must be present for pytest to run\",\n            type=\"args\",\n            default=[],\n        )\n        self._override_ini = ns.override_ini or ()\n\n    def _consider_importhook(self, args: Sequence[str]) -> None:\n        \"\"\"Install the PEP 302 import hook if using assertion rewriting.\n\n        Needs to parse the --assert=<mode> option from the commandline\n        and find all the installed plugins to mark them for rewriting\n        by the importhook.\n        \"\"\"\n        ns, unknown_args = self._parser.parse_known_and_unknown_args(args)\n        mode = getattr(ns, \"assertmode\", \"plain\")\n\n        disable_autoload = getattr(ns, \"disable_plugin_autoload\", False) or bool(\n            os.environ.get(\"PYTEST_DISABLE_PLUGIN_AUTOLOAD\")\n        )\n        if mode == \"rewrite\":\n            import _pytest.assertion\n\n            try:\n                hook = _pytest.assertion.install_importhook(self)\n            except SystemError:\n                mode = \"plain\"\n            else:\n                self._mark_plugins_for_rewrite(hook, disable_autoload)\n        self._warn_about_missing_assertion(mode)\n\n    def _mark_plugins_for_rewrite(\n        self, hook: AssertionRewritingHook, disable_autoload: bool\n    ) -> None:\n        \"\"\"Given an importhook, mark for rewrite any top-level\n        modules or packages in the distribution package"}, {"start_line": 35000, "end_line": 37000, "belongs_to": {"file_name": "test_assertrewrite.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "      pytester.makeconftest(\n            \"\"\"\n            import pytest\n            pytest.register_assert_rewrite(\"_pytest\")\n        \"\"\"\n        )\n        # needs to be a subprocess because pytester explicitly disables this warning\n        result = pytester.runpytest_subprocess()\n        result.stdout.fnmatch_lines([\"*Module already imported*; _pytest\"])\n\n    def test_rewrite_warning_ignore(self, pytester: Pytester) -> None:\n        pytester.makeconftest(\n            \"\"\"\n            import pytest\n            pytest.register_assert_rewrite(\"_pytest\")\n        \"\"\"\n        )\n        # needs to be a subprocess because pytester explicitly disables this warning\n        result = pytester.runpytest_subprocess(\n            \"-W\",\n            \"ignore:Module already imported so cannot be rewritten; _pytest:pytest.PytestAssertRewriteWarning\",\n        )\n        # Previously, when the message pattern used to contain an extra `:`, an error was raised.\n        assert not result.stderr.str().strip()\n        result.stdout.no_fnmatch_line(\"*Module already imported*; _pytest\")\n\n    def test_rewrite_module_imported_from_conftest(self, pytester: Pytester) -> None:\n        pytester.makeconftest(\n            \"\"\"\n            import test_rewrite_module_imported\n        \"\"\"\n        )\n        pytester.makepyfile(\n            test_rewrite_module_imported=\"\"\"\n            def test_rewritten():\n                assert \"@py_builtins\" in globals()\n        \"\"\"\n        )\n        assert pytester.runpytest_subprocess().ret == 0\n\n    def test_remember_rewritten_modules(\n        self, pytestconfig, pytester: Pytester, monkeypatch\n    ) -> None:\n        \"\"\"`AssertionRewriteHook` should remember rewritten modules so it\n        doesn't give false positives (#2005).\"\"\"\n        monkeypatch.syspath_prepend(pytester.path)\n        pytester.makepyfile(test_remember_rewritten_modules=\"\")\n        warnings = []\n        hook = AssertionRewritingHook(pytestconfig)\n        monkeypatch.setattr(\n            hook, \"_warn_alre"}, {"start_line": 15000, "end_line": 17000, "belongs_to": {"file_name": "rewrite.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest/assertion", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "tion as e:\n            trace(f\"_read_pyc({source}): marshal.load error {e}\")\n            return None\n        if not isinstance(co, types.CodeType):\n            trace(f\"_read_pyc({source}): not a code object\")\n            return None\n        return co\n\n\ndef rewrite_asserts(\n    mod: ast.Module,\n    source: bytes,\n    module_path: str | None = None,\n    config: Config | None = None,\n) -> None:\n    \"\"\"Rewrite the assert statements in mod.\"\"\"\n    AssertionRewriter(module_path, config, source).run(mod)\n\n\ndef _saferepr(obj: object) -> str:\n    r\"\"\"Get a safe repr of an object for assertion error messages.\n\n    The assertion formatting (util.format_explanation()) requires\n    newlines to be escaped since they are a special character for it.\n    Normally assertion.util.format_explanation() does this but for a\n    custom repr it is possible to contain one of the special escape\n    sequences, especially '\\n{' and '\\n}' are likely to be present in\n    JSON reprs.\n    \"\"\"\n    if isinstance(obj, types.MethodType):\n        # for bound methods, skip redundant <bound method ...> information\n        return obj.__name__\n\n    maxsize = _get_maxsize_for_saferepr(util._config)\n    if not maxsize:\n        return saferepr_unlimited(obj).replace(\"\\n\", \"\\\\n\")\n    return saferepr(obj, maxsize=maxsize).replace(\"\\n\", \"\\\\n\")\n\n\ndef _get_maxsize_for_saferepr(config: Config | None) -> int | None:\n    \"\"\"Get `maxsize` configuration for saferepr based on the given config object.\"\"\"\n    if config is None:\n        verbosity = 0\n    else:\n        verbosity = config.get_verbosity(Config.VERBOSITY_ASSERTIONS)\n    if verbosity >= 2:\n        return None\n    if verbosity >= 1:\n        return DEFAULT_REPR_MAX_SIZE * 10\n    return DEFAULT_REPR_MAX_SIZE\n\n\ndef _format_assertmsg(obj: object) -> str:\n    r\"\"\"Format the custom assertion message given.\n\n    For strings this simply replaces newlines with '\\n~' so that\n    util.format_explanation() will preserve them instead of escaping\n    newlines.  For other objec"}], "retrieved_count": 10, "cost_time": 1.0262410640716553}
{"question": "What are the core components of Pytest's test runner?", "answer": null, "relative_code_list": null, "ground_truth": "Pytest's test runner consists of several core components: 1) Session class - the root of the collection tree that manages test collection and execution state, 2) Config class - handles configuration, plugin management, and command-line options, 3) PytestPluginManager - manages plugin registration and hook invocation, 4) Test execution protocol with three phases: setup, call, and teardown, 5) Runner module that implements the runtestprotocol function for executing individual test items, 6) Hook system using pluggy for extensibility, 7) Essential plugins including main, runner, fixtures, and mark plugins that provide core functionality.", "score": null, "retrieved_content": [{"start_line": 0, "end_line": 2000, "belongs_to": {"file_name": "main.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "\"\"\"Core implementation of the testing process: init, session, runtest loop.\"\"\"\n\nfrom __future__ import annotations\n\nimport argparse\nfrom collections.abc import Callable\nfrom collections.abc import Iterable\nfrom collections.abc import Iterator\nfrom collections.abc import Sequence\nfrom collections.abc import Set as AbstractSet\nimport dataclasses\nimport fnmatch\nimport functools\nimport importlib\nimport importlib.util\nimport os\nfrom pathlib import Path\nimport sys\nfrom typing import final\nfrom typing import Literal\nfrom typing import overload\nfrom typing import TYPE_CHECKING\nimport warnings\n\nimport pluggy\n\nfrom _pytest import nodes\nimport _pytest._code\nfrom _pytest.config import Config\nfrom _pytest.config import directory_arg\nfrom _pytest.config import ExitCode\nfrom _pytest.config import hookimpl\nfrom _pytest.config import PytestPluginManager\nfrom _pytest.config import UsageError\nfrom _pytest.config.argparsing import Parser\nfrom _pytest.config.compat import PathAwareHookProxy\nfrom _pytest.outcomes import exit\nfrom _pytest.pathlib import absolutepath\nfrom _pytest.pathlib import bestrelpath\nfrom _pytest.pathlib import fnmatch_ex\nfrom _pytest.pathlib import safe_exists\nfrom _pytest.pathlib import scandir\nfrom _pytest.reports import CollectReport\nfrom _pytest.reports import TestReport\nfrom _pytest.runner import collect_one_node\nfrom _pytest.runner import SetupState\nfrom _pytest.warning_types import PytestWarning\n\n\nif TYPE_CHECKING:\n    from typing_extensions import Self\n\n    from _pytest.fixtures import FixtureManager\n\n\ndef pytest_addoption(parser: Parser) -> None:\n    group = parser.getgroup(\"general\", \"Running and selection options\")\n    group._addoption(  # private to use reserved lower-case short option\n        \"-x\",\n        \"--exitfirst\",\n        action=\"store_const\",\n        dest=\"maxfail\",\n        const=1,\n        help=\"Exit instantly on first error or failed test\",\n    )\n    group.addoption(\n        \"--maxfail\",\n        metavar=\"num\",\n        action=\"store\",\n        t"}, {"start_line": 0, "end_line": 2000, "belongs_to": {"file_name": "__init__.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "# PYTHON_ARGCOMPLETE_OK\n\"\"\"pytest: unit and functional testing with Python.\"\"\"\n\nfrom __future__ import annotations\n\nfrom _pytest import __version__\nfrom _pytest import version_tuple\nfrom _pytest._code import ExceptionInfo\nfrom _pytest.assertion import register_assert_rewrite\nfrom _pytest.cacheprovider import Cache\nfrom _pytest.capture import CaptureFixture\nfrom _pytest.config import cmdline\nfrom _pytest.config import Config\nfrom _pytest.config import console_main\nfrom _pytest.config import ExitCode\nfrom _pytest.config import hookimpl\nfrom _pytest.config import hookspec\nfrom _pytest.config import main\nfrom _pytest.config import PytestPluginManager\nfrom _pytest.config import UsageError\nfrom _pytest.config.argparsing import OptionGroup\nfrom _pytest.config.argparsing import Parser\nfrom _pytest.debugging import pytestPDB as __pytestPDB\nfrom _pytest.doctest import DoctestItem\nfrom _pytest.fixtures import fixture\nfrom _pytest.fixtures import FixtureDef\nfrom _pytest.fixtures import FixtureLookupError\nfrom _pytest.fixtures import FixtureRequest\nfrom _pytest.fixtures import yield_fixture\nfrom _pytest.freeze_support import freeze_includes\nfrom _pytest.legacypath import TempdirFactory\nfrom _pytest.legacypath import Testdir\nfrom _pytest.logging import LogCaptureFixture\nfrom _pytest.main import Dir\nfrom _pytest.main import Session\nfrom _pytest.mark import HIDDEN_PARAM\nfrom _pytest.mark import Mark\nfrom _pytest.mark import MARK_GEN as mark\nfrom _pytest.mark import MarkDecorator\nfrom _pytest.mark import MarkGenerator\nfrom _pytest.mark import param\nfrom _pytest.monkeypatch import MonkeyPatch\nfrom _pytest.nodes import Collector\nfrom _pytest.nodes import Directory\nfrom _pytest.nodes import File\nfrom _pytest.nodes import Item\nfrom _pytest.outcomes import exit\nfrom _pytest.outcomes import fail\nfrom _pytest.outcomes import importorskip\nfrom _pytest.outcomes import skip\nfrom _pytest.outcomes import xfail\nfrom _pytest.pytester import HookRecorder\nfrom _pytest.pytester import LineMatcher\nfr"}, {"start_line": 2000, "end_line": 4000, "belongs_to": {"file_name": "__init__.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "om _pytest.pytester import Pytester\nfrom _pytest.pytester import RecordedHookCall\nfrom _pytest.pytester import RunResult\nfrom _pytest.python import Class\nfrom _pytest.python import Function\nfrom _pytest.python import Metafunc\nfrom _pytest.python import Module\nfrom _pytest.python import Package\nfrom _pytest.python_api import approx\nfrom _pytest.raises import raises\nfrom _pytest.raises import RaisesExc\nfrom _pytest.raises import RaisesGroup\nfrom _pytest.recwarn import deprecated_call\nfrom _pytest.recwarn import WarningsRecorder\nfrom _pytest.recwarn import warns\nfrom _pytest.reports import CollectReport\nfrom _pytest.reports import TestReport\nfrom _pytest.runner import CallInfo\nfrom _pytest.stash import Stash\nfrom _pytest.stash import StashKey\nfrom _pytest.terminal import TerminalReporter\nfrom _pytest.terminal import TestShortLogReport\nfrom _pytest.tmpdir import TempPathFactory\nfrom _pytest.warning_types import PytestAssertRewriteWarning\nfrom _pytest.warning_types import PytestCacheWarning\nfrom _pytest.warning_types import PytestCollectionWarning\nfrom _pytest.warning_types import PytestConfigWarning\nfrom _pytest.warning_types import PytestDeprecationWarning\nfrom _pytest.warning_types import PytestExperimentalApiWarning\nfrom _pytest.warning_types import PytestFDWarning\nfrom _pytest.warning_types import PytestRemovedIn9Warning\nfrom _pytest.warning_types import PytestReturnNotNoneWarning\nfrom _pytest.warning_types import PytestUnhandledThreadExceptionWarning\nfrom _pytest.warning_types import PytestUnknownMarkWarning\nfrom _pytest.warning_types import PytestUnraisableExceptionWarning\nfrom _pytest.warning_types import PytestWarning\n\n\nset_trace = __pytestPDB.set_trace\n\n\n__all__ = [\n    \"HIDDEN_PARAM\",\n    \"Cache\",\n    \"CallInfo\",\n    \"CaptureFixture\",\n    \"Class\",\n    \"CollectReport\",\n    \"Collector\",\n    \"Config\",\n    \"Dir\",\n    \"Directory\",\n    \"DoctestItem\",\n    \"ExceptionInfo\",\n    \"ExitCode\",\n    \"File\",\n    \"FixtureDef\",\n    \"FixtureLookupError\",\n    \"FixtureRequest\",\n  "}, {"start_line": 1000, "end_line": 3000, "belongs_to": {"file_name": "__init__.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "upError\nfrom _pytest.fixtures import FixtureRequest\nfrom _pytest.fixtures import yield_fixture\nfrom _pytest.freeze_support import freeze_includes\nfrom _pytest.legacypath import TempdirFactory\nfrom _pytest.legacypath import Testdir\nfrom _pytest.logging import LogCaptureFixture\nfrom _pytest.main import Dir\nfrom _pytest.main import Session\nfrom _pytest.mark import HIDDEN_PARAM\nfrom _pytest.mark import Mark\nfrom _pytest.mark import MARK_GEN as mark\nfrom _pytest.mark import MarkDecorator\nfrom _pytest.mark import MarkGenerator\nfrom _pytest.mark import param\nfrom _pytest.monkeypatch import MonkeyPatch\nfrom _pytest.nodes import Collector\nfrom _pytest.nodes import Directory\nfrom _pytest.nodes import File\nfrom _pytest.nodes import Item\nfrom _pytest.outcomes import exit\nfrom _pytest.outcomes import fail\nfrom _pytest.outcomes import importorskip\nfrom _pytest.outcomes import skip\nfrom _pytest.outcomes import xfail\nfrom _pytest.pytester import HookRecorder\nfrom _pytest.pytester import LineMatcher\nfrom _pytest.pytester import Pytester\nfrom _pytest.pytester import RecordedHookCall\nfrom _pytest.pytester import RunResult\nfrom _pytest.python import Class\nfrom _pytest.python import Function\nfrom _pytest.python import Metafunc\nfrom _pytest.python import Module\nfrom _pytest.python import Package\nfrom _pytest.python_api import approx\nfrom _pytest.raises import raises\nfrom _pytest.raises import RaisesExc\nfrom _pytest.raises import RaisesGroup\nfrom _pytest.recwarn import deprecated_call\nfrom _pytest.recwarn import WarningsRecorder\nfrom _pytest.recwarn import warns\nfrom _pytest.reports import CollectReport\nfrom _pytest.reports import TestReport\nfrom _pytest.runner import CallInfo\nfrom _pytest.stash import Stash\nfrom _pytest.stash import StashKey\nfrom _pytest.terminal import TerminalReporter\nfrom _pytest.terminal import TestShortLogReport\nfrom _pytest.tmpdir import TempPathFactory\nfrom _pytest.warning_types import PytestAssertRewriteWarning\nfrom _pytest.warning_types import PytestCacheWarning"}, {"start_line": 15000, "end_line": 17000, "belongs_to": {"file_name": "pytester.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "during initialization.\n\n    It is particularly useful for testing plugins. It is similar to the :fixture:`tmp_path`\n    fixture but provides methods which aid in testing pytest itself.\n    \"\"\"\n    return Pytester(request, tmp_path_factory, monkeypatch, _ispytest=True)\n\n\n@fixture\ndef _sys_snapshot() -> Generator[None]:\n    snappaths = SysPathsSnapshot()\n    snapmods = SysModulesSnapshot()\n    yield\n    snapmods.restore()\n    snappaths.restore()\n\n\n@fixture\ndef _config_for_test() -> Generator[Config]:\n    from _pytest.config import get_config\n\n    config = get_config()\n    yield config\n    config._ensure_unconfigure()  # cleanup, e.g. capman closing tmpfiles.\n\n\n# Regex to match the session duration string in the summary: \"74.34s\".\nrex_session_duration = re.compile(r\"\\d+\\.\\d\\ds\")\n# Regex to match all the counts and phrases in the summary line: \"34 passed, 111 skipped\".\nrex_outcome = re.compile(r\"(\\d+) (\\w+)\")\n\n\n@final\nclass RunResult:\n    \"\"\"The result of running a command from :class:`~pytest.Pytester`.\"\"\"\n\n    def __init__(\n        self,\n        ret: int | ExitCode,\n        outlines: list[str],\n        errlines: list[str],\n        duration: float,\n    ) -> None:\n        try:\n            self.ret: int | ExitCode = ExitCode(ret)\n            \"\"\"The return value.\"\"\"\n        except ValueError:\n            self.ret = ret\n        self.outlines = outlines\n        \"\"\"List of lines captured from stdout.\"\"\"\n        self.errlines = errlines\n        \"\"\"List of lines captured from stderr.\"\"\"\n        self.stdout = LineMatcher(outlines)\n        \"\"\":class:`~pytest.LineMatcher` of stdout.\n\n        Use e.g. :func:`str(stdout) <pytest.LineMatcher.__str__()>` to reconstruct stdout, or the commonly used\n        :func:`stdout.fnmatch_lines() <pytest.LineMatcher.fnmatch_lines()>` method.\n        \"\"\"\n        self.stderr = LineMatcher(errlines)\n        \"\"\":class:`~pytest.LineMatcher` of stderr.\"\"\"\n        self.duration = duration\n        \"\"\"Duration in seconds.\"\"\"\n\n    def __repr__(self) -> st"}, {"start_line": 10000, "end_line": 12000, "belongs_to": {"file_name": "main.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "ion.startpath)\n        if initstate >= 2:\n            try:\n                config.hook.pytest_sessionfinish(\n                    session=session, exitstatus=session.exitstatus\n                )\n            except exit.Exception as exc:\n                if exc.returncode is not None:\n                    session.exitstatus = exc.returncode\n                sys.stderr.write(f\"{type(exc).__name__}: {exc}\\n\")\n        config._ensure_unconfigure()\n    return session.exitstatus\n\n\ndef pytest_cmdline_main(config: Config) -> int | ExitCode:\n    return wrap_session(config, _main)\n\n\ndef _main(config: Config, session: Session) -> int | ExitCode | None:\n    \"\"\"Default command line protocol for initialization, session,\n    running tests and reporting.\"\"\"\n    config.hook.pytest_collection(session=session)\n    config.hook.pytest_runtestloop(session=session)\n\n    if session.testsfailed:\n        return ExitCode.TESTS_FAILED\n    elif session.testscollected == 0:\n        return ExitCode.NO_TESTS_COLLECTED\n    return None\n\n\ndef pytest_collection(session: Session) -> None:\n    session.perform_collect()\n\n\ndef pytest_runtestloop(session: Session) -> bool:\n    if session.testsfailed and not session.config.option.continue_on_collection_errors:\n        raise session.Interrupted(\n            f\"{session.testsfailed} error{'s' if session.testsfailed != 1 else ''} during collection\"\n        )\n\n    if session.config.option.collectonly:\n        return True\n\n    for i, item in enumerate(session.items):\n        nextitem = session.items[i + 1] if i + 1 < len(session.items) else None\n        item.config.hook.pytest_runtest_protocol(item=item, nextitem=nextitem)\n        if session.shouldfail:\n            raise session.Failed(session.shouldfail)\n        if session.shouldstop:\n            raise session.Interrupted(session.shouldstop)\n    return True\n\n\ndef _in_venv(path: Path) -> bool:\n    \"\"\"Attempt to detect if ``path`` is the root of a Virtual Environment by\n    checking for the existence of the pyvenv.cfg "}, {"start_line": 34000, "end_line": 36000, "belongs_to": {"file_name": "pytester.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "containing the test method) must\n        provide a ``.getrunner()`` method which should return a runner which\n        can run the test protocol for a single item, e.g.\n        ``_pytest.runner.runtestprotocol``.\n        \"\"\"\n        # used from runner functional tests\n        item = self.getitem(source)\n        # the test class where we are called from wants to provide the runner\n        testclassinstance = self._request.instance\n        runner = testclassinstance.getrunner()\n        return runner(item)\n\n    def inline_runsource(self, source: str, *cmdlineargs) -> HookRecorder:\n        \"\"\"Run a test module in process using ``pytest.main()``.\n\n        This run writes \"source\" into a temporary file and runs\n        ``pytest.main()`` on it, returning a :py:class:`HookRecorder` instance\n        for the result.\n\n        :param source: The source code of the test module.\n        :param cmdlineargs: Any extra command line arguments to use.\n        \"\"\"\n        p = self.makepyfile(source)\n        values = [*list(cmdlineargs), p]\n        return self.inline_run(*values)\n\n    def inline_genitems(self, *args) -> tuple[list[Item], HookRecorder]:\n        \"\"\"Run ``pytest.main(['--collect-only'])`` in-process.\n\n        Runs the :py:func:`pytest.main` function to run all of pytest inside\n        the test process itself like :py:meth:`inline_run`, but returns a\n        tuple of the collected items and a :py:class:`HookRecorder` instance.\n        \"\"\"\n        rec = self.inline_run(\"--collect-only\", *args)\n        items = [x.item for x in rec.getcalls(\"pytest_itemcollected\")]\n        return items, rec\n\n    def inline_run(\n        self,\n        *args: str | os.PathLike[str],\n        plugins=(),\n        no_reraise_ctrlc: bool = False,\n    ) -> HookRecorder:\n        \"\"\"Run ``pytest.main()`` in-process, returning a HookRecorder.\n\n        Runs the :py:func:`pytest.main` function to run all of pytest inside\n        the test process itself.  This means it can return a\n        :py:class:`HookReco"}, {"start_line": 4000, "end_line": 5373, "belongs_to": {"file_name": "__init__.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "  \"Function\",\n    \"HookRecorder\",\n    \"Item\",\n    \"LineMatcher\",\n    \"LogCaptureFixture\",\n    \"Mark\",\n    \"MarkDecorator\",\n    \"MarkGenerator\",\n    \"Metafunc\",\n    \"Module\",\n    \"MonkeyPatch\",\n    \"OptionGroup\",\n    \"Package\",\n    \"Parser\",\n    \"PytestAssertRewriteWarning\",\n    \"PytestCacheWarning\",\n    \"PytestCollectionWarning\",\n    \"PytestConfigWarning\",\n    \"PytestDeprecationWarning\",\n    \"PytestExperimentalApiWarning\",\n    \"PytestFDWarning\",\n    \"PytestPluginManager\",\n    \"PytestRemovedIn9Warning\",\n    \"PytestReturnNotNoneWarning\",\n    \"PytestUnhandledThreadExceptionWarning\",\n    \"PytestUnknownMarkWarning\",\n    \"PytestUnraisableExceptionWarning\",\n    \"PytestWarning\",\n    \"Pytester\",\n    \"RaisesExc\",\n    \"RaisesGroup\",\n    \"RecordedHookCall\",\n    \"RunResult\",\n    \"Session\",\n    \"Stash\",\n    \"StashKey\",\n    \"TempPathFactory\",\n    \"TempdirFactory\",\n    \"TerminalReporter\",\n    \"TestReport\",\n    \"TestShortLogReport\",\n    \"Testdir\",\n    \"UsageError\",\n    \"WarningsRecorder\",\n    \"__version__\",\n    \"approx\",\n    \"cmdline\",\n    \"console_main\",\n    \"deprecated_call\",\n    \"exit\",\n    \"fail\",\n    \"fixture\",\n    \"freeze_includes\",\n    \"hookimpl\",\n    \"hookspec\",\n    \"importorskip\",\n    \"main\",\n    \"mark\",\n    \"param\",\n    \"raises\",\n    \"register_assert_rewrite\",\n    \"set_trace\",\n    \"skip\",\n    \"version_tuple\",\n    \"warns\",\n    \"xfail\",\n    \"yield_fixture\",\n]\n"}, {"start_line": 0, "end_line": 2000, "belongs_to": {"file_name": "python.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "# mypy: allow-untyped-defs\n\"\"\"Python test discovery, setup and run of test functions.\"\"\"\n\nfrom __future__ import annotations\n\nimport abc\nfrom collections import Counter\nfrom collections import defaultdict\nfrom collections.abc import Callable\nfrom collections.abc import Generator\nfrom collections.abc import Iterable\nfrom collections.abc import Iterator\nfrom collections.abc import Mapping\nfrom collections.abc import Sequence\nimport dataclasses\nimport enum\nimport fnmatch\nfrom functools import partial\nimport inspect\nimport itertools\nimport os\nfrom pathlib import Path\nimport re\nimport types\nfrom typing import Any\nfrom typing import final\nfrom typing import Literal\nfrom typing import NoReturn\nfrom typing import TYPE_CHECKING\nimport warnings\n\nimport _pytest\nfrom _pytest import fixtures\nfrom _pytest import nodes\nfrom _pytest._code import filter_traceback\nfrom _pytest._code import getfslineno\nfrom _pytest._code.code import ExceptionInfo\nfrom _pytest._code.code import TerminalRepr\nfrom _pytest._code.code import Traceback\nfrom _pytest._io.saferepr import saferepr\nfrom _pytest.compat import ascii_escaped\nfrom _pytest.compat import get_default_arg_names\nfrom _pytest.compat import get_real_func\nfrom _pytest.compat import getimfunc\nfrom _pytest.compat import is_async_function\nfrom _pytest.compat import LEGACY_PATH\nfrom _pytest.compat import NOTSET\nfrom _pytest.compat import safe_getattr\nfrom _pytest.compat import safe_isclass\nfrom _pytest.config import Config\nfrom _pytest.config import hookimpl\nfrom _pytest.config.argparsing import Parser\nfrom _pytest.deprecated import check_ispytest\nfrom _pytest.fixtures import FixtureDef\nfrom _pytest.fixtures import FixtureRequest\nfrom _pytest.fixtures import FuncFixtureInfo\nfrom _pytest.fixtures import get_scope_node\nfrom _pytest.main import Session\nfrom _pytest.mark import ParameterSet\nfrom _pytest.mark.structures import _HiddenParam\nfrom _pytest.mark.structures import get_unpacked_marks\nfrom _pytest.mark.structures import HIDDEN_PARAM\nfrom _p"}, {"start_line": 1000, "end_line": 3000, "belongs_to": {"file_name": "python.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "code.code import Traceback\nfrom _pytest._io.saferepr import saferepr\nfrom _pytest.compat import ascii_escaped\nfrom _pytest.compat import get_default_arg_names\nfrom _pytest.compat import get_real_func\nfrom _pytest.compat import getimfunc\nfrom _pytest.compat import is_async_function\nfrom _pytest.compat import LEGACY_PATH\nfrom _pytest.compat import NOTSET\nfrom _pytest.compat import safe_getattr\nfrom _pytest.compat import safe_isclass\nfrom _pytest.config import Config\nfrom _pytest.config import hookimpl\nfrom _pytest.config.argparsing import Parser\nfrom _pytest.deprecated import check_ispytest\nfrom _pytest.fixtures import FixtureDef\nfrom _pytest.fixtures import FixtureRequest\nfrom _pytest.fixtures import FuncFixtureInfo\nfrom _pytest.fixtures import get_scope_node\nfrom _pytest.main import Session\nfrom _pytest.mark import ParameterSet\nfrom _pytest.mark.structures import _HiddenParam\nfrom _pytest.mark.structures import get_unpacked_marks\nfrom _pytest.mark.structures import HIDDEN_PARAM\nfrom _pytest.mark.structures import Mark\nfrom _pytest.mark.structures import MarkDecorator\nfrom _pytest.mark.structures import normalize_mark_list\nfrom _pytest.outcomes import fail\nfrom _pytest.outcomes import skip\nfrom _pytest.pathlib import fnmatch_ex\nfrom _pytest.pathlib import import_path\nfrom _pytest.pathlib import ImportPathMismatchError\nfrom _pytest.pathlib import scandir\nfrom _pytest.scope import _ScopeName\nfrom _pytest.scope import Scope\nfrom _pytest.stash import StashKey\nfrom _pytest.warning_types import PytestCollectionWarning\nfrom _pytest.warning_types import PytestReturnNotNoneWarning\n\n\nif TYPE_CHECKING:\n    from typing_extensions import Self\n\n\ndef pytest_addoption(parser: Parser) -> None:\n    parser.addini(\n        \"python_files\",\n        type=\"args\",\n        # NOTE: default is also used in AssertionRewritingHook.\n        default=[\"test_*.py\", \"*_test.py\"],\n        help=\"Glob-style file patterns for Python test module discovery\",\n    )\n    parser.addini(\n        \"python_classes\""}], "retrieved_count": 10, "cost_time": 1.0565783977508545}
{"question": "What is the structure of Pytest's configuration system?", "answer": null, "relative_code_list": null, "ground_truth": "Pytest's configuration system consists of several components: 1) Config class - the main configuration object that holds all settings and provides access to plugin manager and hooks, 2) Multiple configuration file formats supported: pytest.ini (highest precedence), pyproject.toml with [tool.pytest.ini_options] section, tox.ini with [pytest] section, and setup.cfg with [tool:pytest] section, 3) Command-line argument parsing through the Parser class, 4) Configuration file discovery that determines rootdir and configfile based on command line arguments and file existence, 5) Plugin manager integration for registering configuration options from plugins, 6) Environment variable support (PYTEST_ADDOPTS), 7) Configuration inheritance and override mechanisms, 8) Stash object for plugins to store configuration data, 9) InvocationParams class to hold parameters passed during pytest.main() calls, 10) Configuration validation and error handling for invalid settings.", "score": null, "retrieved_content": [{"start_line": 36000, "end_line": 38000, "belongs_to": {"file_name": "__init__.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest/config", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": " and hook invocation.\n\n        :type: PytestPluginManager\n        \"\"\"\n\n        self.stash = Stash()\n        \"\"\"A place where plugins can store information on the config for their\n        own use.\n\n        :type: Stash\n        \"\"\"\n        # Deprecated alias. Was never public. Can be removed in a few releases.\n        self._store = self.stash\n\n        self.trace = self.pluginmanager.trace.root.get(\"config\")\n        self.hook: pluggy.HookRelay = PathAwareHookProxy(self.pluginmanager.hook)  # type: ignore[assignment]\n        self._inicache: dict[str, Any] = {}\n        self._override_ini: Sequence[str] = ()\n        self._opt2dest: dict[str, str] = {}\n        self._cleanup_stack = contextlib.ExitStack()\n        self.pluginmanager.register(self, \"pytestconfig\")\n        self._configured = False\n        self.hook.pytest_addoption.call_historic(\n            kwargs=dict(parser=self._parser, pluginmanager=self.pluginmanager)\n        )\n        self.args_source = Config.ArgsSource.ARGS\n        self.args: list[str] = []\n\n    @property\n    def rootpath(self) -> pathlib.Path:\n        \"\"\"The path to the :ref:`rootdir <rootdir>`.\n\n        :type: pathlib.Path\n\n        .. versionadded:: 6.1\n        \"\"\"\n        return self._rootpath\n\n    @property\n    def inipath(self) -> pathlib.Path | None:\n        \"\"\"The path to the :ref:`configfile <configfiles>`.\n\n        .. versionadded:: 6.1\n        \"\"\"\n        return self._inipath\n\n    def add_cleanup(self, func: Callable[[], None]) -> None:\n        \"\"\"Add a function to be called when the config object gets out of\n        use (usually coinciding with pytest_unconfigure).\n        \"\"\"\n        self._cleanup_stack.callback(func)\n\n    def _do_configure(self) -> None:\n        assert not self._configured\n        self._configured = True\n        self.hook.pytest_configure.call_historic(kwargs=dict(config=self))\n\n    def _ensure_unconfigure(self) -> None:\n        try:\n            if self._configured:\n                self._configured = False\n               "}, {"start_line": 33000, "end_line": 35000, "belongs_to": {"file_name": "__init__.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest/config", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "e_files)\n\n\n@final\nclass Config:\n    \"\"\"Access to configuration values, pluginmanager and plugin hooks.\n\n    :param PytestPluginManager pluginmanager:\n        A pytest PluginManager.\n\n    :param InvocationParams invocation_params:\n        Object containing parameters regarding the :func:`pytest.main`\n        invocation.\n    \"\"\"\n\n    @final\n    @dataclasses.dataclass(frozen=True)\n    class InvocationParams:\n        \"\"\"Holds parameters passed during :func:`pytest.main`.\n\n        The object attributes are read-only.\n\n        .. versionadded:: 5.1\n\n        .. note::\n\n            Note that the environment variable ``PYTEST_ADDOPTS`` and the ``addopts``\n            ini option are handled by pytest, not being included in the ``args`` attribute.\n\n            Plugins accessing ``InvocationParams`` must be aware of that.\n        \"\"\"\n\n        args: tuple[str, ...]\n        \"\"\"The command-line arguments as passed to :func:`pytest.main`.\"\"\"\n        plugins: Sequence[str | _PluggyPlugin] | None\n        \"\"\"Extra plugins, might be `None`.\"\"\"\n        dir: pathlib.Path\n        \"\"\"The directory from which :func:`pytest.main` was invoked. :type: pathlib.Path\"\"\"\n\n        def __init__(\n            self,\n            *,\n            args: Iterable[str],\n            plugins: Sequence[str | _PluggyPlugin] | None,\n            dir: pathlib.Path,\n        ) -> None:\n            object.__setattr__(self, \"args\", tuple(args))\n            object.__setattr__(self, \"plugins\", plugins)\n            object.__setattr__(self, \"dir\", dir)\n\n    class ArgsSource(enum.Enum):\n        \"\"\"Indicates the source of the test arguments.\n\n        .. versionadded:: 7.2\n        \"\"\"\n\n        #: Command line arguments.\n        ARGS = enum.auto()\n        #: Invocation directory.\n        INVOCATION_DIR = enum.auto()\n        INCOVATION_DIR = INVOCATION_DIR  # backwards compatibility alias\n        #: 'testpaths' configuration value.\n        TESTPATHS = enum.auto()\n\n    # Set by cacheprovider plugin.\n    cache: Cache\n\n    def __in"}, {"start_line": 0, "end_line": 2000, "belongs_to": {"file_name": "test_config.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "# mypy: allow-untyped-defs\nfrom __future__ import annotations\n\nfrom collections.abc import Sequence\nimport dataclasses\nimport importlib.metadata\nimport os\nfrom pathlib import Path\nimport platform\nimport re\nimport sys\nimport textwrap\nfrom typing import Any\n\nimport _pytest._code\nfrom _pytest.config import _get_plugin_specs_as_list\nfrom _pytest.config import _iter_rewritable_modules\nfrom _pytest.config import _strtobool\nfrom _pytest.config import Config\nfrom _pytest.config import ConftestImportFailure\nfrom _pytest.config import ExitCode\nfrom _pytest.config import parse_warning_filter\nfrom _pytest.config.argparsing import get_ini_default_for_type\nfrom _pytest.config.argparsing import Parser\nfrom _pytest.config.exceptions import UsageError\nfrom _pytest.config.findpaths import determine_setup\nfrom _pytest.config.findpaths import get_common_ancestor\nfrom _pytest.config.findpaths import locate_config\nfrom _pytest.monkeypatch import MonkeyPatch\nfrom _pytest.pathlib import absolutepath\nfrom _pytest.pytester import Pytester\nimport pytest\n\n\nclass TestParseIni:\n    @pytest.mark.parametrize(\n        \"section, filename\", [(\"pytest\", \"pytest.ini\"), (\"tool:pytest\", \"setup.cfg\")]\n    )\n    def test_getcfg_and_config(\n        self,\n        pytester: Pytester,\n        tmp_path: Path,\n        section: str,\n        filename: str,\n        monkeypatch: MonkeyPatch,\n    ) -> None:\n        sub = tmp_path / \"sub\"\n        sub.mkdir()\n        monkeypatch.chdir(sub)\n        (tmp_path / filename).write_text(\n            textwrap.dedent(\n                f\"\"\"\\\n                [{section}]\n                name = value\n                \"\"\"\n            ),\n            encoding=\"utf-8\",\n        )\n        _, _, cfg = locate_config(Path.cwd(), [sub])\n        assert cfg[\"name\"] == \"value\"\n        config = pytester.parseconfigure(str(sub))\n        assert config.inicfg[\"name\"] == \"value\"\n\n    def test_setupcfg_uses_toolpytest_with_pytest(self, pytester: Pytester) -> None:\n        p1 = pytester.makepyfile(\"def "}, {"start_line": 12000, "end_line": 14000, "belongs_to": {"file_name": "__init__.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest/config", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "his includes the directory's own conftest modules as well\n        # as those of its parent directories.\n        self._dirpath2confmods: dict[pathlib.Path, list[types.ModuleType]] = {}\n        # Cutoff directory above which conftests are no longer discovered.\n        self._confcutdir: pathlib.Path | None = None\n        # If set, conftest loading is skipped.\n        self._noconftest = False\n\n        # _getconftestmodules()'s call to _get_directory() causes a stat\n        # storm when it's called potentially thousands of times in a test\n        # session (#9478), often with the same path, so cache it.\n        self._get_directory = lru_cache(256)(_get_directory)\n\n        # plugins that were explicitly skipped with pytest.skip\n        # list of (module name, skip reason)\n        # previously we would issue a warning when a plugin was skipped, but\n        # since we refactored warnings as first citizens of Config, they are\n        # just stored here to be used later.\n        self.skipped_plugins: list[tuple[str, str]] = []\n\n        self.add_hookspecs(_pytest.hookspec)\n        self.register(self)\n        if os.environ.get(\"PYTEST_DEBUG\"):\n            err: IO[str] = sys.stderr\n            encoding: str = getattr(err, \"encoding\", \"utf8\")\n            try:\n                err = open(\n                    os.dup(err.fileno()),\n                    mode=err.mode,\n                    buffering=1,\n                    encoding=encoding,\n                )\n            except Exception:\n                pass\n            self.trace.root.setwriter(err.write)\n            self.enable_tracing()\n\n        # Config._consider_importhook will set a real object if required.\n        self.rewrite_hook: RewriteHook = DummyRewriteHook()\n        # Used to know when we are importing conftests after the pytest_configure stage.\n        self._configured = False\n\n    def parse_hookimpl_opts(\n        self, plugin: _PluggyPlugin, name: str\n    ) -> HookimplOpts | None:\n        \"\"\":meta private:\"\"\"\n        # py"}, {"start_line": 38000, "end_line": 40000, "belongs_to": {"file_name": "test_config.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "   option_dict = {\"inifilename\": inifilename, \"capture\": \"no\"}\n\n        cwd = tmp_path.joinpath(\"a/b\")\n        cwd.mkdir(parents=True)\n        p2 = cwd.joinpath(\"pytest.ini\")\n        p2.touch()\n        p2.write_text(\n            textwrap.dedent(\n                \"\"\"\\\n                [pytest]\n                name = wrong-value\n                should_not_be_set = true\n                \"\"\"\n            ),\n            encoding=\"utf-8\",\n        )\n        with MonkeyPatch.context() as mp:\n            mp.chdir(cwd)\n            config = Config.fromdictargs(option_dict, ())\n            inipath = absolutepath(inifilename)\n\n        assert config.args == [str(cwd)]\n        assert config.option.inifilename == inifilename\n        assert config.option.capture == \"no\"\n\n        # this indicates this is the file used for getting configuration values\n        assert config.inipath == inipath\n        assert config.inicfg.get(\"name\") == \"value\"\n        assert config.inicfg.get(\"should_not_be_set\") is None\n\n\ndef test_options_on_small_file_do_not_blow_up(pytester: Pytester) -> None:\n    def runfiletest(opts: Sequence[str]) -> None:\n        reprec = pytester.inline_run(*opts)\n        passed, skipped, failed = reprec.countoutcomes()\n        assert failed == 2\n        assert skipped == passed == 0\n\n    path = str(\n        pytester.makepyfile(\n            \"\"\"\n        def test_f1(): assert 0\n        def test_f2(): assert 0\n    \"\"\"\n        )\n    )\n\n    runfiletest([path])\n    runfiletest([\"-l\", path])\n    runfiletest([\"-s\", path])\n    runfiletest([\"--tb=no\", path])\n    runfiletest([\"--tb=short\", path])\n    runfiletest([\"--tb=long\", path])\n    runfiletest([\"--fulltrace\", path])\n    runfiletest([\"--traceconfig\", path])\n    runfiletest([\"-v\", path])\n    runfiletest([\"-v\", \"-v\", path])\n\n\ndef test_preparse_ordering_with_setuptools(\n    pytester: Pytester, monkeypatch: MonkeyPatch\n) -> None:\n    monkeypatch.delenv(\"PYTEST_DISABLE_PLUGIN_AUTOLOAD\", raising=False)\n\n    class EntryPoint:\n        name = \"myt"}, {"start_line": 37000, "end_line": 39000, "belongs_to": {"file_name": "__init__.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest/config", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "args: list[str] = []\n\n    @property\n    def rootpath(self) -> pathlib.Path:\n        \"\"\"The path to the :ref:`rootdir <rootdir>`.\n\n        :type: pathlib.Path\n\n        .. versionadded:: 6.1\n        \"\"\"\n        return self._rootpath\n\n    @property\n    def inipath(self) -> pathlib.Path | None:\n        \"\"\"The path to the :ref:`configfile <configfiles>`.\n\n        .. versionadded:: 6.1\n        \"\"\"\n        return self._inipath\n\n    def add_cleanup(self, func: Callable[[], None]) -> None:\n        \"\"\"Add a function to be called when the config object gets out of\n        use (usually coinciding with pytest_unconfigure).\n        \"\"\"\n        self._cleanup_stack.callback(func)\n\n    def _do_configure(self) -> None:\n        assert not self._configured\n        self._configured = True\n        self.hook.pytest_configure.call_historic(kwargs=dict(config=self))\n\n    def _ensure_unconfigure(self) -> None:\n        try:\n            if self._configured:\n                self._configured = False\n                try:\n                    self.hook.pytest_unconfigure(config=self)\n                finally:\n                    self.hook.pytest_configure._call_history = []\n        finally:\n            try:\n                self._cleanup_stack.close()\n            finally:\n                self._cleanup_stack = contextlib.ExitStack()\n\n    def get_terminal_writer(self) -> TerminalWriter:\n        terminalreporter: TerminalReporter | None = self.pluginmanager.get_plugin(\n            \"terminalreporter\"\n        )\n        assert terminalreporter is not None\n        return terminalreporter._tw\n\n    def pytest_cmdline_parse(\n        self, pluginmanager: PytestPluginManager, args: list[str]\n    ) -> Config:\n        try:\n            self.parse(args)\n        except UsageError:\n            # Handle --version and --help here in a minimal fashion.\n            # This gets done via helpconfig normally, but its\n            # pytest_cmdline_main is not called in case of errors.\n            if getattr(self.option, \"versi"}, {"start_line": 0, "end_line": 2000, "belongs_to": {"file_name": "test_conftest.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "# mypy: allow-untyped-defs\nfrom __future__ import annotations\n\nfrom collections.abc import Generator\nfrom collections.abc import Sequence\nimport os\nfrom pathlib import Path\nimport textwrap\nfrom typing import cast\n\nfrom _pytest.config import ExitCode\nfrom _pytest.config import PytestPluginManager\nfrom _pytest.monkeypatch import MonkeyPatch\nfrom _pytest.pathlib import symlink_or_skip\nfrom _pytest.pytester import Pytester\nfrom _pytest.tmpdir import TempPathFactory\nimport pytest\n\n\ndef ConftestWithSetinitial(path) -> PytestPluginManager:\n    conftest = PytestPluginManager()\n    conftest_setinitial(conftest, [path])\n    return conftest\n\n\ndef conftest_setinitial(\n    conftest: PytestPluginManager,\n    args: Sequence[str | Path],\n    confcutdir: Path | None = None,\n) -> None:\n    conftest._set_initial_conftests(\n        args=args,\n        pyargs=False,\n        noconftest=False,\n        rootpath=Path(args[0]),\n        confcutdir=confcutdir,\n        invocation_dir=Path.cwd(),\n        importmode=\"prepend\",\n        consider_namespace_packages=False,\n    )\n\n\n@pytest.mark.usefixtures(\"_sys_snapshot\")\nclass TestConftestValueAccessGlobal:\n    @pytest.fixture(scope=\"module\", params=[\"global\", \"inpackage\"])\n    def basedir(self, request, tmp_path_factory: TempPathFactory) -> Generator[Path]:\n        tmp_path = tmp_path_factory.mktemp(\"basedir\", numbered=True)\n        tmp_path.joinpath(\"adir/b\").mkdir(parents=True)\n        tmp_path.joinpath(\"adir/conftest.py\").write_text(\n            \"a=1 ; Directory = 3\", encoding=\"utf-8\"\n        )\n        tmp_path.joinpath(\"adir/b/conftest.py\").write_text(\n            \"b=2 ; a = 1.5\", encoding=\"utf-8\"\n        )\n        if request.param == \"inpackage\":\n            tmp_path.joinpath(\"adir/__init__.py\").touch()\n            tmp_path.joinpath(\"adir/b/__init__.py\").touch()\n\n        yield tmp_path\n\n    def test_basic_init(self, basedir: Path) -> None:\n        conftest = PytestPluginManager()\n        p = basedir / \"adir\"\n        conftest._loadconftestmodule"}, {"start_line": 1000, "end_line": 3000, "belongs_to": {"file_name": "test_config.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "est.pytester import Pytester\nimport pytest\n\n\nclass TestParseIni:\n    @pytest.mark.parametrize(\n        \"section, filename\", [(\"pytest\", \"pytest.ini\"), (\"tool:pytest\", \"setup.cfg\")]\n    )\n    def test_getcfg_and_config(\n        self,\n        pytester: Pytester,\n        tmp_path: Path,\n        section: str,\n        filename: str,\n        monkeypatch: MonkeyPatch,\n    ) -> None:\n        sub = tmp_path / \"sub\"\n        sub.mkdir()\n        monkeypatch.chdir(sub)\n        (tmp_path / filename).write_text(\n            textwrap.dedent(\n                f\"\"\"\\\n                [{section}]\n                name = value\n                \"\"\"\n            ),\n            encoding=\"utf-8\",\n        )\n        _, _, cfg = locate_config(Path.cwd(), [sub])\n        assert cfg[\"name\"] == \"value\"\n        config = pytester.parseconfigure(str(sub))\n        assert config.inicfg[\"name\"] == \"value\"\n\n    def test_setupcfg_uses_toolpytest_with_pytest(self, pytester: Pytester) -> None:\n        p1 = pytester.makepyfile(\"def test(): pass\")\n        pytester.makefile(\n            \".cfg\",\n            setup=f\"\"\"\n                [tool:pytest]\n                testpaths={p1.name}\n                [pytest]\n                testpaths=ignored\n        \"\"\",\n        )\n        result = pytester.runpytest()\n        result.stdout.fnmatch_lines([\"configfile: setup.cfg\", \"* 1 passed in *\"])\n        assert result.ret == 0\n\n    def test_append_parse_args(\n        self, pytester: Pytester, tmp_path: Path, monkeypatch: MonkeyPatch\n    ) -> None:\n        monkeypatch.setenv(\"PYTEST_ADDOPTS\", '--color no -rs --tb=\"short\"')\n        tmp_path.joinpath(\"pytest.ini\").write_text(\n            textwrap.dedent(\n                \"\"\"\\\n                [pytest]\n                addopts = --verbose\n                \"\"\"\n            ),\n            encoding=\"utf-8\",\n        )\n        config = pytester.parseconfig(tmp_path)\n        assert config.option.color == \"no\"\n        assert config.option.reportchars == \"s\"\n        assert config.option.tbstyle == "}, {"start_line": 0, "end_line": 2000, "belongs_to": {"file_name": "findpaths.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest/config", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "from __future__ import annotations\n\nfrom collections.abc import Iterable\nfrom collections.abc import Sequence\nimport os\nfrom pathlib import Path\nimport sys\nfrom typing import TYPE_CHECKING\n\nimport iniconfig\n\nfrom .exceptions import UsageError\nfrom _pytest.outcomes import fail\nfrom _pytest.pathlib import absolutepath\nfrom _pytest.pathlib import commonpath\nfrom _pytest.pathlib import safe_exists\n\n\nif TYPE_CHECKING:\n    from typing import Union\n\n    from typing_extensions import TypeAlias\n\n    # Even though TOML supports richer data types, all values are converted to str/list[str] during\n    # parsing to maintain compatibility with the rest of the configuration system.\n    ConfigDict: TypeAlias = dict[str, Union[str, list[str]]]\n\n\ndef _parse_ini_config(path: Path) -> iniconfig.IniConfig:\n    \"\"\"Parse the given generic '.ini' file using legacy IniConfig parser, returning\n    the parsed object.\n\n    Raise UsageError if the file cannot be parsed.\n    \"\"\"\n    try:\n        return iniconfig.IniConfig(str(path))\n    except iniconfig.ParseError as exc:\n        raise UsageError(str(exc)) from exc\n\n\ndef load_config_dict_from_file(\n    filepath: Path,\n) -> ConfigDict | None:\n    \"\"\"Load pytest configuration from the given file path, if supported.\n\n    Return None if the file does not contain valid pytest configuration.\n    \"\"\"\n    # Configuration from ini files are obtained from the [pytest] section, if present.\n    if filepath.suffix == \".ini\":\n        iniconfig = _parse_ini_config(filepath)\n\n        if \"pytest\" in iniconfig:\n            return dict(iniconfig[\"pytest\"].items())\n        else:\n            # \"pytest.ini\" files are always the source of configuration, even if empty.\n            if filepath.name == \"pytest.ini\":\n                return {}\n\n    # '.cfg' files are considered if they contain a \"[tool:pytest]\" section.\n    elif filepath.suffix == \".cfg\":\n        iniconfig = _parse_ini_config(filepath)\n\n        if \"tool:pytest\" in iniconfig.sections:\n            return dict"}, {"start_line": 37000, "end_line": 39000, "belongs_to": {"file_name": "test_config.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": " config.option.foo == \"bar\"\n        assert config.option.capture == \"no\"\n        assert config.args == args\n\n    def test_invocation_params_args(self, _sys_snapshot) -> None:\n        \"\"\"Show that fromdictargs can handle args in their \"orig\" format\"\"\"\n        option_dict: dict[str, object] = {}\n        args = [\"-vvvv\", \"-s\", \"a\", \"b\"]\n\n        config = Config.fromdictargs(option_dict, args)\n        assert config.args == [\"a\", \"b\"]\n        assert config.invocation_params.args == tuple(args)\n        assert config.option.verbose == 4\n        assert config.option.capture == \"no\"\n\n    def test_inifilename(self, tmp_path: Path) -> None:\n        d1 = tmp_path.joinpath(\"foo\")\n        d1.mkdir()\n        p1 = d1.joinpath(\"bar.ini\")\n        p1.touch()\n        p1.write_text(\n            textwrap.dedent(\n                \"\"\"\\\n                [pytest]\n                name = value\n                \"\"\"\n            ),\n            encoding=\"utf-8\",\n        )\n\n        inifilename = \"../../foo/bar.ini\"\n        option_dict = {\"inifilename\": inifilename, \"capture\": \"no\"}\n\n        cwd = tmp_path.joinpath(\"a/b\")\n        cwd.mkdir(parents=True)\n        p2 = cwd.joinpath(\"pytest.ini\")\n        p2.touch()\n        p2.write_text(\n            textwrap.dedent(\n                \"\"\"\\\n                [pytest]\n                name = wrong-value\n                should_not_be_set = true\n                \"\"\"\n            ),\n            encoding=\"utf-8\",\n        )\n        with MonkeyPatch.context() as mp:\n            mp.chdir(cwd)\n            config = Config.fromdictargs(option_dict, ())\n            inipath = absolutepath(inifilename)\n\n        assert config.args == [str(cwd)]\n        assert config.option.inifilename == inifilename\n        assert config.option.capture == \"no\"\n\n        # this indicates this is the file used for getting configuration values\n        assert config.inipath == inipath\n        assert config.inicfg.get(\"name\") == \"value\"\n        assert config.inicfg.get(\"should_not_be_set\") is None\n\n\nde"}], "retrieved_count": 10, "cost_time": 1.060288906097412}
{"question": "What is the difference between direct and indirect parametrization in pytest?", "answer": null, "relative_code_list": null, "ground_truth": "Direct and indirect parametrization in pytest differ in how parameter values are handled: 1) Direct parametrization (default) - parameter values are passed directly to the test function as arguments during test execution, 2) Indirect parametrization (indirect=True) - parameter values are passed to fixture functions via request.param, allowing the fixture to process or transform the values before providing them to the test, 3) Direct parametrization happens at collection time and creates separate test instances for each parameter value, 4) Indirect parametrization allows expensive setup operations to be performed in fixtures at test execution time rather than collection time, 5) Direct parametrization is simpler and more straightforward for basic parameter passing, 6) Indirect parametrization enables more complex parameter processing, validation, or resource setup in fixtures, 7) Indirect parametrization can be applied selectively to specific arguments using a list of argument names, 8) Direct parametrization creates test IDs based on the parameter values themselves, 9) Indirect parametrization can use fixture-defined IDs and scoping, 10) Direct parametrization is more efficient for simple parameter passing, while indirect is better for complex setup scenarios.", "score": null, "retrieved_content": [{"start_line": 57000, "end_line": 59000, "belongs_to": {"file_name": "metafunc.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing/python", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "ct=['echo'])\n            def test_1(animal, echo):\n                assert animal in ('dog', 'cat')\n                assert echo in (1, 2, 3)\n\n            @pytest.mark.parametrize('animal, echo', [('fish', 3)], indirect=['echo'])\n            def test_2(animal, echo):\n                assert animal == 'fish'\n                assert echo in (1, 2, 3)\n        \"\"\"\n        )\n        result = pytester.runpytest()\n        result.stdout.fnmatch_lines([\"* 3 passed *\"])\n\n    def test_parametrize_auto_scope_override_fixture(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n\n            @pytest.fixture(scope='session', autouse=True)\n            def animal():\n                return 'fox'\n\n            @pytest.mark.parametrize('animal', [\"dog\", \"cat\"])\n            def test_1(animal):\n                assert animal in ('dog', 'cat')\n        \"\"\"\n        )\n        result = pytester.runpytest()\n        result.stdout.fnmatch_lines([\"* 2 passed *\"])\n\n    def test_parametrize_all_indirects(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n\n            @pytest.fixture()\n            def animal(request):\n                return request.param\n\n            @pytest.fixture(scope='session')\n            def echo(request):\n                return request.param\n\n            @pytest.mark.parametrize('animal, echo', [(\"dog\", 1), (\"cat\", 2)], indirect=True)\n            def test_1(animal, echo):\n                assert animal in ('dog', 'cat')\n                assert echo in (1, 2, 3)\n\n            @pytest.mark.parametrize('animal, echo', [(\"fish\", 3)], indirect=True)\n            def test_2(animal, echo):\n                assert animal == 'fish'\n                assert echo in (1, 2, 3)\n        \"\"\"\n        )\n        result = pytester.runpytest()\n        result.stdout.fnmatch_lines([\"* 3 passed *\"])\n\n    def test_parametrize_some_arguments_auto_scope(\n        self, pytester: Pytester, monkeypatch\n    ) -"}, {"start_line": 43000, "end_line": 45000, "belongs_to": {"file_name": "metafunc.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing/python", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": ":\n        p = pytester.makepyfile(\n            \"\"\"\n            def pytest_generate_tests(metafunc):\n                assert \"arg1\" in metafunc.fixturenames\n                metafunc.parametrize(\"arg1\", [1], indirect=True)\n\n            import pytest\n            @pytest.fixture\n            def arg1(request):\n                return request.param\n\n            @pytest.fixture\n            def arg2(request, arg1):\n                return 10 * arg1\n\n            def test_func(arg2):\n                assert arg2 == 10\n        \"\"\"\n        )\n        result = pytester.runpytest(\"-v\", p)\n        result.stdout.fnmatch_lines([\"*test_func*1*PASS*\", \"*1 passed*\"])\n\n    def test_parametrize_with_ids(self, pytester: Pytester) -> None:\n        pytester.makeini(\n            \"\"\"\n            [pytest]\n            console_output_style=classic\n        \"\"\"\n        )\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n            def pytest_generate_tests(metafunc):\n                metafunc.parametrize((\"a\", \"b\"), [(1,1), (1,2)],\n                                     ids=[\"basic\", \"advanced\"])\n\n            def test_function(a, b):\n                assert a == b\n        \"\"\"\n        )\n        result = pytester.runpytest(\"-v\")\n        assert result.ret == 1\n        result.stdout.fnmatch_lines_random(\n            [\"*test_function*basic*PASSED\", \"*test_function*advanced*FAILED\"]\n        )\n\n    def test_parametrize_without_ids(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n            def pytest_generate_tests(metafunc):\n                metafunc.parametrize((\"a\", \"b\"),\n                                     [(1,object()), (1.3,object())])\n\n            def test_function(a, b):\n                assert 1\n        \"\"\"\n        )\n        result = pytester.runpytest(\"-v\")\n        result.stdout.fnmatch_lines(\n            \"\"\"\n            *test_function*1-b0*\n            *test_function*1.3-b1*\n        \"\"\"\n        )\n\n    def test_parametrize_wi"}, {"start_line": 56000, "end_line": 58000, "belongs_to": {"file_name": "metafunc.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing/python", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "\"\"\"\n\n    def test_parametrize_auto_scope(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n\n            @pytest.fixture(scope='session', autouse=True)\n            def fixture():\n                return 1\n\n            @pytest.mark.parametrize('animal', [\"dog\", \"cat\"])\n            def test_1(animal):\n                assert animal in ('dog', 'cat')\n\n            @pytest.mark.parametrize('animal', ['fish'])\n            def test_2(animal):\n                assert animal == 'fish'\n\n        \"\"\"\n        )\n        result = pytester.runpytest()\n        result.stdout.fnmatch_lines([\"* 3 passed *\"])\n\n    def test_parametrize_auto_scope_indirect(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n\n            @pytest.fixture(scope='session')\n            def echo(request):\n                return request.param\n\n            @pytest.mark.parametrize('animal, echo', [(\"dog\", 1), (\"cat\", 2)], indirect=['echo'])\n            def test_1(animal, echo):\n                assert animal in ('dog', 'cat')\n                assert echo in (1, 2, 3)\n\n            @pytest.mark.parametrize('animal, echo', [('fish', 3)], indirect=['echo'])\n            def test_2(animal, echo):\n                assert animal == 'fish'\n                assert echo in (1, 2, 3)\n        \"\"\"\n        )\n        result = pytester.runpytest()\n        result.stdout.fnmatch_lines([\"* 3 passed *\"])\n\n    def test_parametrize_auto_scope_override_fixture(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n\n            @pytest.fixture(scope='session', autouse=True)\n            def animal():\n                return 'fox'\n\n            @pytest.mark.parametrize('animal', [\"dog\", \"cat\"])\n            def test_1(animal):\n                assert animal in ('dog', 'cat')\n        \"\"\"\n        )\n        result = pytester.runpytest()\n        result.stdout.fnmatch_lines([\"* 2 passed *\"])\n\n    d"}, {"start_line": 17000, "end_line": 19000, "belongs_to": {"file_name": "collect.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing/python", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "             return request.param\n\n            @pytest.mark.parametrize('value',\n                                     ['overridden'])\n            def test_overridden_via_param(value):\n                assert value == 'overridden'\n        \"\"\"\n        )\n        rec = pytester.inline_run()\n        rec.assertoutcome(passed=1)\n\n    def test_parametrize_overrides_indirect_dependency_fixture(\n        self, pytester: Pytester\n    ) -> None:\n        \"\"\"Test parametrization when parameter overrides a fixture that a test indirectly depends on\"\"\"\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n\n            fix3_instantiated = False\n\n            @pytest.fixture\n            def fix1(fix2):\n               return fix2 + '1'\n\n            @pytest.fixture\n            def fix2(fix3):\n               return fix3 + '2'\n\n            @pytest.fixture\n            def fix3():\n               global fix3_instantiated\n               fix3_instantiated = True\n               return '3'\n\n            @pytest.mark.parametrize('fix2', ['2'])\n            def test_it(fix1):\n               assert fix1 == '21'\n               assert not fix3_instantiated\n        \"\"\"\n        )\n        rec = pytester.inline_run()\n        rec.assertoutcome(passed=1)\n\n    def test_parametrize_with_mark(self, pytester: Pytester) -> None:\n        items = pytester.getitems(\n            \"\"\"\n            import pytest\n            @pytest.mark.foo\n            @pytest.mark.parametrize('arg', [\n                1,\n                pytest.param(2, marks=[pytest.mark.baz, pytest.mark.bar])\n            ])\n            def test_function(arg):\n                pass\n        \"\"\"\n        )\n        keywords = [item.keywords for item in items]\n        assert (\n            \"foo\" in keywords[0]\n            and \"bar\" not in keywords[0]\n            and \"baz\" not in keywords[0]\n        )\n        assert \"foo\" in keywords[1] and \"bar\" in keywords[1] and \"baz\" in keywords[1]\n\n    def test_parametrize_with_empty_string_arguments(self, pyt"}, {"start_line": 26000, "end_line": 28000, "belongs_to": {"file_name": "metafunc.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing/python", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "` is a direct parameter, its pseudo-fixture would\n        # be registered.\n        assert list(metafunc._arg2fixturedefs.keys()) == [\"y\"]\n\n    def test_parametrize_indirect_list_all(self) -> None:\n        \"\"\"#714\"\"\"\n\n        def func(x, y):\n            pass\n\n        metafunc = self.Metafunc(func)\n        metafunc.parametrize(\"x, y\", [(\"a\", \"b\")], indirect=[\"x\", \"y\"])\n        assert metafunc._calls[0].params == dict(x=\"a\", y=\"b\")\n        assert list(metafunc._arg2fixturedefs.keys()) == []\n\n    def test_parametrize_indirect_list_empty(self) -> None:\n        \"\"\"#714\"\"\"\n\n        def func(x, y):\n            pass\n\n        metafunc = self.Metafunc(func)\n        metafunc.parametrize(\"x, y\", [(\"a\", \"b\")], indirect=[])\n        assert metafunc._calls[0].params == dict(x=\"a\", y=\"b\")\n        assert list(metafunc._arg2fixturedefs.keys()) == [\"x\", \"y\"]\n\n    def test_parametrize_indirect_wrong_type(self) -> None:\n        def func(x, y):\n            pass\n\n        metafunc = self.Metafunc(func)\n        with pytest.raises(\n            fail.Exception,\n            match=\"In func: expected Sequence or boolean for indirect, got dict\",\n        ):\n            metafunc.parametrize(\"x, y\", [(\"a\", \"b\")], indirect={})  # type: ignore[arg-type]\n\n    def test_parametrize_indirect_list_functional(self, pytester: Pytester) -> None:\n        \"\"\"\n        #714\n        Test parametrization with 'indirect' parameter applied on\n        particular arguments. As y is direct, its value should\n        be used directly rather than being passed to the fixture y.\n\n        :param pytester: the instance of Pytester class, a temporary\n        test directory.\n        \"\"\"\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n            @pytest.fixture(scope='function')\n            def x(request):\n                return request.param * 3\n            @pytest.fixture(scope='function')\n            def y(request):\n                return request.param * 2\n            @pytest.mark.parametrize('x, y', [('a'"}, {"start_line": 33000, "end_line": 35000, "belongs_to": {"file_name": "metafunc.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing/python", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "simple*2-2*\", \"*2 passed*\"]\n        )\n\n    def test_parametrize_onearg(self) -> None:\n        metafunc = self.Metafunc(lambda x: None)\n        metafunc.parametrize(\"x\", [1, 2])\n        assert len(metafunc._calls) == 2\n        assert metafunc._calls[0].params == dict(x=1)\n        assert metafunc._calls[0].id == \"1\"\n        assert metafunc._calls[1].params == dict(x=2)\n        assert metafunc._calls[1].id == \"2\"\n\n    def test_parametrize_onearg_indirect(self) -> None:\n        metafunc = self.Metafunc(lambda x: None)\n        metafunc.parametrize(\"x\", [1, 2], indirect=True)\n        assert metafunc._calls[0].params == dict(x=1)\n        assert metafunc._calls[0].id == \"1\"\n        assert metafunc._calls[1].params == dict(x=2)\n        assert metafunc._calls[1].id == \"2\"\n\n    def test_parametrize_twoargs(self) -> None:\n        metafunc = self.Metafunc(lambda x, y: None)\n        metafunc.parametrize((\"x\", \"y\"), [(1, 2), (3, 4)])\n        assert len(metafunc._calls) == 2\n        assert metafunc._calls[0].params == dict(x=1, y=2)\n        assert metafunc._calls[0].id == \"1-2\"\n        assert metafunc._calls[1].params == dict(x=3, y=4)\n        assert metafunc._calls[1].id == \"3-4\"\n\n    def test_high_scoped_parametrize_reordering(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n\n            @pytest.mark.parametrize(\"arg2\", [3, 4])\n            @pytest.mark.parametrize(\"arg1\", [0, 1, 2], scope='module')\n            def test1(arg1, arg2):\n                pass\n\n            def test2():\n                pass\n\n            @pytest.mark.parametrize(\"arg1\", [0, 1, 2], scope='module')\n            def test3(arg1):\n                pass\n        \"\"\"\n        )\n        result = pytester.runpytest(\"--collect-only\")\n        result.stdout.re_match_lines(\n            [\n                r\"    <Function test1\\[0-3\\]>\",\n                r\"    <Function test3\\[0\\]>\",\n                r\"    <Function test1\\[0-4\\]>\",\n                r\"    <Function test3\\["}, {"start_line": 14000, "end_line": 16000, "belongs_to": {"file_name": "fixtures.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing/python", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "st\n\n            @pytest.fixture(params=[1, 2])\n            def foo(request):\n                return request.param\n            \"\"\"\n        )\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n\n            @pytest.fixture\n            def foo(foo):\n                return foo * 2\n\n            def test_spam(foo):\n                assert foo in (2, 4)\n            \"\"\"\n        )\n        result = pytester.runpytest()\n        result.stdout.fnmatch_lines([\"*2 passed*\"])\n\n    def test_override_parametrize_fixture_and_indirect(\n        self, pytester: Pytester\n    ) -> None:\n        \"\"\"Override a fixture at a lower level, reusing the higher-level fixture that\n        is parametrized, while also using indirect parametrization.\n        \"\"\"\n        pytester.makeconftest(\n            \"\"\"\n            import pytest\n\n            @pytest.fixture(params=[1, 2])\n            def foo(request):\n                return request.param\n            \"\"\"\n        )\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n\n            @pytest.fixture\n            def foo(foo):\n                return foo * 2\n\n            @pytest.fixture\n            def bar(request):\n                return request.param * 100\n\n            @pytest.mark.parametrize(\"bar\", [42], indirect=True)\n            def test_spam(bar, foo):\n                assert bar == 4200\n                assert foo in (2, 4)\n            \"\"\"\n        )\n        result = pytester.runpytest()\n        result.stdout.fnmatch_lines([\"*2 passed*\"])\n\n    def test_override_top_level_fixture_reusing_super_fixture_parametrization(\n        self, pytester: Pytester\n    ) -> None:\n        \"\"\"Same as the above test, but with another level of overwriting.\"\"\"\n        pytester.makeconftest(\n            \"\"\"\n            import pytest\n\n            @pytest.fixture(params=['unused', 'unused'])\n            def foo(request):\n                return request.param\n            \"\"\"\n        )\n        pytester.makepyfile(\n            \"\"\"\n            "}, {"start_line": 42000, "end_line": 44000, "belongs_to": {"file_name": "metafunc.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing/python", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "     result.stdout.fnmatch_lines(\n            [\"*(1, 4)*\", \"*(1, 5)*\", \"*(2, 4)*\", \"*(2, 5)*\", \"*4 failed*\"]\n        )\n\n    def test_parametrize_and_inner_getfixturevalue(self, pytester: Pytester) -> None:\n        p = pytester.makepyfile(\n            \"\"\"\n            def pytest_generate_tests(metafunc):\n                metafunc.parametrize(\"arg1\", [1], indirect=True)\n                metafunc.parametrize(\"arg2\", [10], indirect=True)\n\n            import pytest\n            @pytest.fixture\n            def arg1(request):\n                x = request.getfixturevalue(\"arg2\")\n                return x + request.param\n\n            @pytest.fixture\n            def arg2(request):\n                return request.param\n\n            def test_func1(arg1, arg2):\n                assert arg1 == 11\n        \"\"\"\n        )\n        result = pytester.runpytest(\"-v\", p)\n        result.stdout.fnmatch_lines([\"*test_func1*1*PASS*\", \"*1 passed*\"])\n\n    def test_parametrize_on_setup_arg(self, pytester: Pytester) -> None:\n        p = pytester.makepyfile(\n            \"\"\"\n            def pytest_generate_tests(metafunc):\n                assert \"arg1\" in metafunc.fixturenames\n                metafunc.parametrize(\"arg1\", [1], indirect=True)\n\n            import pytest\n            @pytest.fixture\n            def arg1(request):\n                return request.param\n\n            @pytest.fixture\n            def arg2(request, arg1):\n                return 10 * arg1\n\n            def test_func(arg2):\n                assert arg2 == 10\n        \"\"\"\n        )\n        result = pytester.runpytest(\"-v\", p)\n        result.stdout.fnmatch_lines([\"*test_func*1*PASS*\", \"*1 passed*\"])\n\n    def test_parametrize_with_ids(self, pytester: Pytester) -> None:\n        pytester.makeini(\n            \"\"\"\n            [pytest]\n            console_output_style=classic\n        \"\"\"\n        )\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n            def pytest_generate_tests(metafunc):\n                metafunc.parametr"}, {"start_line": 16000, "end_line": 18000, "belongs_to": {"file_name": "collect.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing/python", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "'overridden'])\n            def test_overridden_via_param(value):\n                assert value == 'overridden'\n\n            @pytest.mark.parametrize('somevalue', ['overridden'])\n            def test_not_overridden(value, somevalue):\n                assert value == 'value'\n                assert somevalue == 'overridden'\n\n            @pytest.mark.parametrize('other,value', [('foo', 'overridden')])\n            def test_overridden_via_multiparam(other, value):\n                assert other == 'foo'\n                assert value == 'overridden'\n        \"\"\"\n        )\n        rec = pytester.inline_run()\n        rec.assertoutcome(passed=3)\n\n    def test_parametrize_overrides_parametrized_fixture(\n        self, pytester: Pytester\n    ) -> None:\n        \"\"\"Test parametrization when parameter overrides existing parametrized fixture with same name.\"\"\"\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n\n            @pytest.fixture(params=[1, 2])\n            def value(request):\n                return request.param\n\n            @pytest.mark.parametrize('value',\n                                     ['overridden'])\n            def test_overridden_via_param(value):\n                assert value == 'overridden'\n        \"\"\"\n        )\n        rec = pytester.inline_run()\n        rec.assertoutcome(passed=1)\n\n    def test_parametrize_overrides_indirect_dependency_fixture(\n        self, pytester: Pytester\n    ) -> None:\n        \"\"\"Test parametrization when parameter overrides a fixture that a test indirectly depends on\"\"\"\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n\n            fix3_instantiated = False\n\n            @pytest.fixture\n            def fix1(fix2):\n               return fix2 + '1'\n\n            @pytest.fixture\n            def fix2(fix3):\n               return fix3 + '2'\n\n            @pytest.fixture\n            def fix3():\n               global fix3_instantiated\n               fix3_instantiated = True\n               return '3'\n\n          "}, {"start_line": 32000, "end_line": 34000, "belongs_to": {"file_name": "metafunc.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing/python", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "   \"\"\"\n            import pytest\n\n            @pytest.mark.parametrize('x, y', [('a', 'b')])\n            def test_simple(x, y=1):\n                assert len(x) == 1\n        \"\"\"\n        )\n        result = pytester.runpytest(\"--collect-only\")\n        result.stdout.fnmatch_lines(\n            [\"*already takes an argument 'y' with a default value\"]\n        )\n\n    def test_parametrize_functional(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n            def pytest_generate_tests(metafunc):\n                metafunc.parametrize('x', [1,2], indirect=True)\n                metafunc.parametrize('y', [2])\n            @pytest.fixture\n            def x(request):\n                return request.param * 10\n\n            def test_simple(x,y):\n                assert x in (10,20)\n                assert y == 2\n        \"\"\"\n        )\n        result = pytester.runpytest(\"-v\")\n        result.stdout.fnmatch_lines(\n            [\"*test_simple*1-2*\", \"*test_simple*2-2*\", \"*2 passed*\"]\n        )\n\n    def test_parametrize_onearg(self) -> None:\n        metafunc = self.Metafunc(lambda x: None)\n        metafunc.parametrize(\"x\", [1, 2])\n        assert len(metafunc._calls) == 2\n        assert metafunc._calls[0].params == dict(x=1)\n        assert metafunc._calls[0].id == \"1\"\n        assert metafunc._calls[1].params == dict(x=2)\n        assert metafunc._calls[1].id == \"2\"\n\n    def test_parametrize_onearg_indirect(self) -> None:\n        metafunc = self.Metafunc(lambda x: None)\n        metafunc.parametrize(\"x\", [1, 2], indirect=True)\n        assert metafunc._calls[0].params == dict(x=1)\n        assert metafunc._calls[0].id == \"1\"\n        assert metafunc._calls[1].params == dict(x=2)\n        assert metafunc._calls[1].id == \"2\"\n\n    def test_parametrize_twoargs(self) -> None:\n        metafunc = self.Metafunc(lambda x, y: None)\n        metafunc.parametrize((\"x\", \"y\"), [(1, 2), (3, 4)])\n        assert len(metafunc._calls) == 2\n        assert metafunc._c"}], "retrieved_count": 10, "cost_time": 1.057190179824829}
{"question": "What is the purpose of the FixtureDef class?", "answer": null, "relative_code_list": null, "ground_truth": "The FixtureDef class serves as a container for fixture definitions and manages the lifecycle of fixtures in pytest. Its main purposes include: 1) Encapsulating all metadata about a fixture including its function, scope, parameters, and IDs, 2) Managing fixture visibility through baseid which determines which nodes can access the fixture, 3) Handling fixture parametrization with params and ids attributes for multiple fixture instances, 4) Storing cached results to avoid re-executing fixtures within their scope, 5) Managing fixture dependencies through argnames which lists the fixtures this fixture requires, 6) Providing scope management with _scope attribute that determines fixture lifecycle, 7) Handling fixture finalization through _finalizers list for cleanup operations, 8) Supporting fixture execution through execute() method that runs the fixture function, 9) Managing fixture caching through cache_key() method for efficient reuse, 10) Providing fixture lookup and resolution in the fixture manager system, 11) Supporting autouse fixtures through _autouse flag for automatic activation, 12) Enabling fixture override mechanisms where fixtures can override others with the same name.", "score": null, "retrieved_content": [{"start_line": 37000, "end_line": 39000, "belongs_to": {"file_name": "fixtures.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "l(\n            f\"Expected {scope_callable} to return a 'str' while defining fixture '{fixture_name}', but it returned:\\n\"\n            f\"{result!r}\",\n            pytrace=False,\n        )\n    return result\n\n\n@final\nclass FixtureDef(Generic[FixtureValue]):\n    \"\"\"A container for a fixture definition.\n\n    Note: At this time, only explicitly documented fields and methods are\n    considered public stable API.\n    \"\"\"\n\n    def __init__(\n        self,\n        config: Config,\n        baseid: str | None,\n        argname: str,\n        func: _FixtureFunc[FixtureValue],\n        scope: Scope | _ScopeName | Callable[[str, Config], _ScopeName] | None,\n        params: Sequence[object] | None,\n        ids: tuple[object | None, ...] | Callable[[Any], object | None] | None = None,\n        *,\n        _ispytest: bool = False,\n        # only used in a deprecationwarning msg, can be removed in pytest9\n        _autouse: bool = False,\n    ) -> None:\n        check_ispytest(_ispytest)\n        # The \"base\" node ID for the fixture.\n        #\n        # This is a node ID prefix. A fixture is only available to a node (e.g.\n        # a `Function` item) if the fixture's baseid is a nodeid of a parent of\n        # node.\n        #\n        # For a fixture found in a Collector's object (e.g. a `Module`s module,\n        # a `Class`'s class), the baseid is the Collector's nodeid.\n        #\n        # For a fixture found in a conftest plugin, the baseid is the conftest's\n        # directory path relative to the rootdir.\n        #\n        # For other plugins, the baseid is the empty string (always matches).\n        self.baseid: Final = baseid or \"\"\n        # Whether the fixture was found from a node or a conftest in the\n        # collection tree. Will be false for fixtures defined in non-conftest\n        # plugins.\n        self.has_location: Final = baseid is not None\n        # The fixture factory function.\n        self.func: Final = func\n        # The name by which the fixture may be requested.\n        self"}, {"start_line": 38000, "end_line": 40000, "belongs_to": {"file_name": "fixtures.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "D for the fixture.\n        #\n        # This is a node ID prefix. A fixture is only available to a node (e.g.\n        # a `Function` item) if the fixture's baseid is a nodeid of a parent of\n        # node.\n        #\n        # For a fixture found in a Collector's object (e.g. a `Module`s module,\n        # a `Class`'s class), the baseid is the Collector's nodeid.\n        #\n        # For a fixture found in a conftest plugin, the baseid is the conftest's\n        # directory path relative to the rootdir.\n        #\n        # For other plugins, the baseid is the empty string (always matches).\n        self.baseid: Final = baseid or \"\"\n        # Whether the fixture was found from a node or a conftest in the\n        # collection tree. Will be false for fixtures defined in non-conftest\n        # plugins.\n        self.has_location: Final = baseid is not None\n        # The fixture factory function.\n        self.func: Final = func\n        # The name by which the fixture may be requested.\n        self.argname: Final = argname\n        if scope is None:\n            scope = Scope.Function\n        elif callable(scope):\n            scope = _eval_scope_callable(scope, argname, config)\n        if isinstance(scope, str):\n            scope = Scope.from_user(\n                scope, descr=f\"Fixture '{func.__name__}'\", where=baseid\n            )\n        self._scope: Final = scope\n        # If the fixture is directly parametrized, the parameter values.\n        self.params: Final = params\n        # If the fixture is directly parametrized, a tuple of explicit IDs to\n        # assign to the parameter values, or a callable to generate an ID given\n        # a parameter value.\n        self.ids: Final = ids\n        # The names requested by the fixtures.\n        self.argnames: Final = getfuncargnames(func, name=argname)\n        # If the fixture was executed, the current value of the fixture.\n        # Can change if the fixture is executed with different parameters.\n        self.cached_result: _FixtureC"}, {"start_line": 71000, "end_line": 73000, "belongs_to": {"file_name": "fixtures.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": " = obj_ub._fixture_function_marker\n                if marker.name:\n                    fixture_name = marker.name\n                else:\n                    fixture_name = name\n\n                # OK we know it is a fixture -- now safe to look up on the _instance_.\n                try:\n                    obj = getattr(holderobj, name)\n                # if the fixture is named in the decorator we cannot find it in the module\n                except AttributeError:\n                    obj = obj_ub\n\n                func = obj._get_wrapped_function()\n\n                self._register_fixture(\n                    name=fixture_name,\n                    nodeid=nodeid,\n                    func=func,\n                    scope=marker.scope,\n                    params=marker.params,\n                    ids=marker.ids,\n                    autouse=marker.autouse,\n                )\n\n    def getfixturedefs(\n        self, argname: str, node: nodes.Node\n    ) -> Sequence[FixtureDef[Any]] | None:\n        \"\"\"Get FixtureDefs for a fixture name which are applicable\n        to a given node.\n\n        Returns None if there are no fixtures at all defined with the given\n        name. (This is different from the case in which there are fixtures\n        with the given name, but none applicable to the node. In this case,\n        an empty result is returned).\n\n        :param argname: Name of the fixture to search for.\n        :param node: The requesting Node.\n        \"\"\"\n        try:\n            fixturedefs = self._arg2fixturedefs[argname]\n        except KeyError:\n            return None\n        return tuple(self._matchfactories(fixturedefs, node))\n\n    def _matchfactories(\n        self, fixturedefs: Iterable[FixtureDef[Any]], node: nodes.Node\n    ) -> Iterator[FixtureDef[Any]]:\n        parentnodeids = {n.nodeid for n in node.iter_parents()}\n        for fixturedef in fixturedefs:\n            if fixturedef.baseid in parentnodeids:\n                yield fixturedef\n\n\ndef show_fixtures_per_test(config: "}, {"start_line": 48000, "end_line": 50000, "belongs_to": {"file_name": "fixtures.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "> FixtureFunctionDefinition:\n        if inspect.isclass(function):\n            raise ValueError(\"class fixtures not supported (maybe in the future)\")\n\n        if isinstance(function, FixtureFunctionDefinition):\n            raise ValueError(\n                f\"@pytest.fixture is being applied more than once to the same function {function.__name__!r}\"\n            )\n\n        if hasattr(function, \"pytestmark\"):\n            warnings.warn(MARKED_FIXTURE, stacklevel=2)\n\n        fixture_definition = FixtureFunctionDefinition(\n            function=function, fixture_function_marker=self, _ispytest=True\n        )\n\n        name = self.name or function.__name__\n        if name == \"request\":\n            location = getlocation(function)\n            fail(\n                f\"'request' is a reserved word for fixtures, use another name:\\n  {location}\",\n                pytrace=False,\n            )\n\n        return fixture_definition\n\n\n# TODO: paramspec/return type annotation tracking and storing\nclass FixtureFunctionDefinition:\n    def __init__(\n        self,\n        *,\n        function: Callable[..., Any],\n        fixture_function_marker: FixtureFunctionMarker,\n        instance: object | None = None,\n        _ispytest: bool = False,\n    ) -> None:\n        check_ispytest(_ispytest)\n        self.name = fixture_function_marker.name or function.__name__\n        # In order to show the function that this fixture contains in messages.\n        # Set the __name__ to be same as the function __name__ or the given fixture name.\n        self.__name__ = self.name\n        self._fixture_function_marker = fixture_function_marker\n        if instance is not None:\n            self._fixture_function = cast(\n                Callable[..., Any], function.__get__(instance)\n            )\n        else:\n            self._fixture_function = function\n        functools.update_wrapper(self, function)\n\n    def __repr__(self) -> str:\n        return f\"<pytest_fixture({self._fixture_function})>\"\n\n    def __get__(self, inst"}, {"start_line": 52000, "end_line": 54000, "belongs_to": {"file_name": "fixtures.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "tionMarker | FixtureFunctionDefinition:\n    \"\"\"Decorator to mark a fixture factory function.\n\n    This decorator can be used, with or without parameters, to define a\n    fixture function.\n\n    The name of the fixture function can later be referenced to cause its\n    invocation ahead of running tests: test modules or classes can use the\n    ``pytest.mark.usefixtures(fixturename)`` marker.\n\n    Test functions can directly use fixture names as input arguments in which\n    case the fixture instance returned from the fixture function will be\n    injected.\n\n    Fixtures can provide their values to test functions using ``return`` or\n    ``yield`` statements. When using ``yield`` the code block after the\n    ``yield`` statement is executed as teardown code regardless of the test\n    outcome, and must yield exactly once.\n\n    :param scope:\n        The scope for which this fixture is shared; one of ``\"function\"``\n        (default), ``\"class\"``, ``\"module\"``, ``\"package\"`` or ``\"session\"``.\n\n        This parameter may also be a callable which receives ``(fixture_name, config)``\n        as parameters, and must return a ``str`` with one of the values mentioned above.\n\n        See :ref:`dynamic scope` in the docs for more information.\n\n    :param params:\n        An optional list of parameters which will cause multiple invocations\n        of the fixture function and all of the tests using it. The current\n        parameter is available in ``request.param``.\n\n    :param autouse:\n        If True, the fixture func is activated for all tests that can see it.\n        If False (the default), an explicit reference is needed to activate\n        the fixture.\n\n    :param ids:\n        Sequence of ids each corresponding to the params so that they are\n        part of the test id. If no ids are provided they will be generated\n        automatically from the params.\n\n    :param name:\n        The name of the fixture. This defaults to the name of the decorated\n        function. If a fixture is used "}, {"start_line": 49000, "end_line": 51000, "belongs_to": {"file_name": "fixtures.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "eFunctionDefinition:\n    def __init__(\n        self,\n        *,\n        function: Callable[..., Any],\n        fixture_function_marker: FixtureFunctionMarker,\n        instance: object | None = None,\n        _ispytest: bool = False,\n    ) -> None:\n        check_ispytest(_ispytest)\n        self.name = fixture_function_marker.name or function.__name__\n        # In order to show the function that this fixture contains in messages.\n        # Set the __name__ to be same as the function __name__ or the given fixture name.\n        self.__name__ = self.name\n        self._fixture_function_marker = fixture_function_marker\n        if instance is not None:\n            self._fixture_function = cast(\n                Callable[..., Any], function.__get__(instance)\n            )\n        else:\n            self._fixture_function = function\n        functools.update_wrapper(self, function)\n\n    def __repr__(self) -> str:\n        return f\"<pytest_fixture({self._fixture_function})>\"\n\n    def __get__(self, instance, owner=None):\n        \"\"\"Behave like a method if the function it was applied to was a method.\"\"\"\n        return FixtureFunctionDefinition(\n            function=self._fixture_function,\n            fixture_function_marker=self._fixture_function_marker,\n            instance=instance,\n            _ispytest=True,\n        )\n\n    def __call__(self, *args: Any, **kwds: Any) -> Any:\n        message = (\n            f'Fixture \"{self.name}\" called directly. Fixtures are not meant to be called directly,\\n'\n            \"but are created automatically when test functions request them as parameters.\\n\"\n            \"See https://docs.pytest.org/en/stable/explanation/fixtures.html for more information about fixtures, and\\n\"\n            \"https://docs.pytest.org/en/stable/deprecations.html#calling-fixtures-directly\"\n        )\n        fail(message, pytrace=False)\n\n    def _get_wrapped_function(self) -> Callable[..., Any]:\n        return self._fixture_function\n\n\n@overload\ndef fixture(\n    fixture_functio"}, {"start_line": 67000, "end_line": 69000, "belongs_to": {"file_name": "fixtures.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": " _ScopeName | Callable[[str, Config], _ScopeName] = \"function\",\n        params: Sequence[object] | None = None,\n        ids: tuple[object | None, ...] | Callable[[Any], object | None] | None = None,\n        autouse: bool = False,\n    ) -> None:\n        \"\"\"Register a fixture\n\n        :param name:\n            The fixture's name.\n        :param func:\n            The fixture's implementation function.\n        :param nodeid:\n            The visibility of the fixture. The fixture will be available to the\n            node with this nodeid and its children in the collection tree.\n            None means that the fixture is visible to the entire collection tree,\n            e.g. a fixture defined for general use in a plugin.\n        :param scope:\n            The fixture's scope.\n        :param params:\n            The fixture's parametrization params.\n        :param ids:\n            The fixture's IDs.\n        :param autouse:\n            Whether this is an autouse fixture.\n        \"\"\"\n        fixture_def = FixtureDef(\n            config=self.config,\n            baseid=nodeid,\n            argname=name,\n            func=func,\n            scope=scope,\n            params=params,\n            ids=ids,\n            _ispytest=True,\n            _autouse=autouse,\n        )\n\n        faclist = self._arg2fixturedefs.setdefault(name, [])\n        if fixture_def.has_location:\n            faclist.append(fixture_def)\n        else:\n            # fixturedefs with no location are at the front\n            # so this inserts the current fixturedef after the\n            # existing fixturedefs from external plugins but\n            # before the fixturedefs provided in conftests.\n            i = len([f for f in faclist if not f.has_location])\n            faclist.insert(i, fixture_def)\n        if autouse:\n            self._nodeid_autousenames.setdefault(nodeid or \"\", []).append(name)\n\n    @overload\n    def parsefactories(\n        self,\n        node_or_obj: nodes.Node,\n    ) -> None:\n        raise NotImpleme"}, {"start_line": 39000, "end_line": 41000, "belongs_to": {"file_name": "fixtures.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": ".argname: Final = argname\n        if scope is None:\n            scope = Scope.Function\n        elif callable(scope):\n            scope = _eval_scope_callable(scope, argname, config)\n        if isinstance(scope, str):\n            scope = Scope.from_user(\n                scope, descr=f\"Fixture '{func.__name__}'\", where=baseid\n            )\n        self._scope: Final = scope\n        # If the fixture is directly parametrized, the parameter values.\n        self.params: Final = params\n        # If the fixture is directly parametrized, a tuple of explicit IDs to\n        # assign to the parameter values, or a callable to generate an ID given\n        # a parameter value.\n        self.ids: Final = ids\n        # The names requested by the fixtures.\n        self.argnames: Final = getfuncargnames(func, name=argname)\n        # If the fixture was executed, the current value of the fixture.\n        # Can change if the fixture is executed with different parameters.\n        self.cached_result: _FixtureCachedResult[FixtureValue] | None = None\n        self._finalizers: Final[list[Callable[[], object]]] = []\n\n        # only used to emit a deprecationwarning, can be removed in pytest9\n        self._autouse = _autouse\n\n    @property\n    def scope(self) -> _ScopeName:\n        \"\"\"Scope string, one of \"function\", \"class\", \"module\", \"package\", \"session\".\"\"\"\n        return self._scope.value\n\n    def addfinalizer(self, finalizer: Callable[[], object]) -> None:\n        self._finalizers.append(finalizer)\n\n    def finish(self, request: SubRequest) -> None:\n        exceptions: list[BaseException] = []\n        while self._finalizers:\n            fin = self._finalizers.pop()\n            try:\n                fin()\n            except BaseException as e:\n                exceptions.append(e)\n        node = request.node\n        node.ihook.pytest_fixture_post_finalizer(fixturedef=self, request=request)\n        # Even if finalization fails, we invalidate the cached fixture\n        # value and remove all fin"}, {"start_line": 72000, "end_line": 74000, "belongs_to": {"file_name": "fixtures.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "\"Get FixtureDefs for a fixture name which are applicable\n        to a given node.\n\n        Returns None if there are no fixtures at all defined with the given\n        name. (This is different from the case in which there are fixtures\n        with the given name, but none applicable to the node. In this case,\n        an empty result is returned).\n\n        :param argname: Name of the fixture to search for.\n        :param node: The requesting Node.\n        \"\"\"\n        try:\n            fixturedefs = self._arg2fixturedefs[argname]\n        except KeyError:\n            return None\n        return tuple(self._matchfactories(fixturedefs, node))\n\n    def _matchfactories(\n        self, fixturedefs: Iterable[FixtureDef[Any]], node: nodes.Node\n    ) -> Iterator[FixtureDef[Any]]:\n        parentnodeids = {n.nodeid for n in node.iter_parents()}\n        for fixturedef in fixturedefs:\n            if fixturedef.baseid in parentnodeids:\n                yield fixturedef\n\n\ndef show_fixtures_per_test(config: Config) -> int | ExitCode:\n    from _pytest.main import wrap_session\n\n    return wrap_session(config, _show_fixtures_per_test)\n\n\n_PYTEST_DIR = Path(_pytest.__file__).parent\n\n\ndef _pretty_fixture_path(invocation_dir: Path, func) -> str:\n    loc = Path(getlocation(func, invocation_dir))\n    prefix = Path(\"...\", \"_pytest\")\n    try:\n        return str(prefix / loc.relative_to(_PYTEST_DIR))\n    except ValueError:\n        return bestrelpath(invocation_dir, loc)\n\n\ndef _show_fixtures_per_test(config: Config, session: Session) -> None:\n    import _pytest.config\n\n    session.perform_collect()\n    invocation_dir = config.invocation_params.dir\n    tw = _pytest.config.create_terminal_writer(config)\n    verbose = config.get_verbosity()\n\n    def get_best_relpath(func) -> str:\n        loc = getlocation(func, invocation_dir)\n        return bestrelpath(invocation_dir, Path(loc))\n\n    def write_fixture(fixture_def: FixtureDef[object]) -> None:\n        argname = fixture_def.argname\n        if verbose <= 0"}, {"start_line": 40000, "end_line": 42000, "belongs_to": {"file_name": "fixtures.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "achedResult[FixtureValue] | None = None\n        self._finalizers: Final[list[Callable[[], object]]] = []\n\n        # only used to emit a deprecationwarning, can be removed in pytest9\n        self._autouse = _autouse\n\n    @property\n    def scope(self) -> _ScopeName:\n        \"\"\"Scope string, one of \"function\", \"class\", \"module\", \"package\", \"session\".\"\"\"\n        return self._scope.value\n\n    def addfinalizer(self, finalizer: Callable[[], object]) -> None:\n        self._finalizers.append(finalizer)\n\n    def finish(self, request: SubRequest) -> None:\n        exceptions: list[BaseException] = []\n        while self._finalizers:\n            fin = self._finalizers.pop()\n            try:\n                fin()\n            except BaseException as e:\n                exceptions.append(e)\n        node = request.node\n        node.ihook.pytest_fixture_post_finalizer(fixturedef=self, request=request)\n        # Even if finalization fails, we invalidate the cached fixture\n        # value and remove all finalizers because they may be bound methods\n        # which will keep instances alive.\n        self.cached_result = None\n        self._finalizers.clear()\n        if len(exceptions) == 1:\n            raise exceptions[0]\n        elif len(exceptions) > 1:\n            msg = f'errors while tearing down fixture \"{self.argname}\" of {node}'\n            raise BaseExceptionGroup(msg, exceptions[::-1])\n\n    def execute(self, request: SubRequest) -> FixtureValue:\n        \"\"\"Return the value of this fixture, executing it if not cached.\"\"\"\n        # Ensure that the dependent fixtures requested by this fixture are loaded.\n        # This needs to be done before checking if we have a cached value, since\n        # if a dependent fixture has their cache invalidated, e.g. due to\n        # parametrization, they finalize themselves and fixtures depending on it\n        # (which will likely include this fixture) setting `self.cached_result = None`.\n        # See #4871\n        requested_fixtures_that_should_fina"}], "retrieved_count": 10, "cost_time": 1.0630638599395752}
{"question": "What error handling mechanisms does Pytest use for test failures?", "answer": null, "relative_code_list": null, "ground_truth": "Pytest uses several error handling mechanisms for test failures: 1) TestReport class - captures test outcomes (passed, failed, skipped) with detailed exception information, 2) CallInfo class - wraps function calls with exception handling and timing information, 3) ExceptionInfo class - provides detailed exception representation with traceback information, 4) Three-phase test execution (setup, call, teardown) with separate error handling for each phase, 5) sys.last_type, sys.last_value, sys.last_traceback storage for postmortem debugging, 6) Interactive exception handling with pytest_exception_interact hook, 7) Different outcome types: passed, failed, skipped, error (for setup/teardown failures), 8) Longrepr mechanism for detailed failure reporting, 9) Exception chaining support for complex error scenarios, 10) Error categorization (E for errors, F for failures) in test summaries, 11) Maxfail mechanism to stop after N failures, 12) PDB integration for debugging on failures.", "score": null, "retrieved_content": [{"start_line": 2000, "end_line": 4000, "belongs_to": {"file_name": "test_session.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "  def test_raises_doesnt():\n                pytest.raises(ValueError, int, \"3\")\n        \"\"\"\n        )\n        passed, skipped, failed = reprec.listoutcomes()\n        assert len(failed) == 1\n        out = failed[0].longrepr.reprcrash.message  # type: ignore[union-attr]\n        assert \"DID NOT RAISE\" in out\n\n    def test_syntax_error_module(self, pytester: Pytester) -> None:\n        reprec = pytester.inline_runsource(\"this is really not python\")\n        values = reprec.getfailedcollections()\n        assert len(values) == 1\n        out = str(values[0].longrepr)\n        assert out.find(\"not python\") != -1\n\n    def test_exit_first_problem(self, pytester: Pytester) -> None:\n        reprec = pytester.inline_runsource(\n            \"\"\"\n            def test_one(): assert 0\n            def test_two(): assert 0\n        \"\"\",\n            \"--exitfirst\",\n        )\n        passed, skipped, failed = reprec.countoutcomes()\n        assert failed == 1\n        assert passed == skipped == 0\n\n    def test_maxfail(self, pytester: Pytester) -> None:\n        reprec = pytester.inline_runsource(\n            \"\"\"\n            def test_one(): assert 0\n            def test_two(): assert 0\n            def test_three(): assert 0\n        \"\"\",\n            \"--maxfail=2\",\n        )\n        passed, skipped, failed = reprec.countoutcomes()\n        assert failed == 2\n        assert passed == skipped == 0\n\n    def test_broken_repr(self, pytester: Pytester) -> None:\n        p = pytester.makepyfile(\n            \"\"\"\n            import pytest\n\n            class reprexc(BaseException):\n                def __str__(self):\n                    return \"Ha Ha fooled you, I'm a broken repr().\"\n\n            class BrokenRepr1(object):\n                foo=0\n                def __repr__(self):\n                    raise reprexc\n\n            class TestBrokenClass(object):\n                def test_explicit_bad_repr(self):\n                    t = BrokenRepr1()\n                    with pytest.raises(BaseException, match=\"broken r"}, {"start_line": 3000, "end_line": 5000, "belongs_to": {"file_name": "test_session.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "fail(self, pytester: Pytester) -> None:\n        reprec = pytester.inline_runsource(\n            \"\"\"\n            def test_one(): assert 0\n            def test_two(): assert 0\n            def test_three(): assert 0\n        \"\"\",\n            \"--maxfail=2\",\n        )\n        passed, skipped, failed = reprec.countoutcomes()\n        assert failed == 2\n        assert passed == skipped == 0\n\n    def test_broken_repr(self, pytester: Pytester) -> None:\n        p = pytester.makepyfile(\n            \"\"\"\n            import pytest\n\n            class reprexc(BaseException):\n                def __str__(self):\n                    return \"Ha Ha fooled you, I'm a broken repr().\"\n\n            class BrokenRepr1(object):\n                foo=0\n                def __repr__(self):\n                    raise reprexc\n\n            class TestBrokenClass(object):\n                def test_explicit_bad_repr(self):\n                    t = BrokenRepr1()\n                    with pytest.raises(BaseException, match=\"broken repr\"):\n                        repr(t)\n\n                def test_implicit_bad_repr1(self):\n                    t = BrokenRepr1()\n                    assert t.foo == 1\n\n        \"\"\"\n        )\n        reprec = pytester.inline_run(p)\n        passed, skipped, failed = reprec.listoutcomes()\n        assert (len(passed), len(skipped), len(failed)) == (1, 0, 1)\n        out = failed[0].longrepr.reprcrash.message  # type: ignore[union-attr]\n        assert out.find(\"<[reprexc() raised in repr()] BrokenRepr1\") != -1\n\n    def test_broken_repr_with_showlocals_verbose(self, pytester: Pytester) -> None:\n        p = pytester.makepyfile(\n            \"\"\"\n            class ObjWithErrorInRepr:\n                def __repr__(self):\n                    raise NotImplementedError\n\n            def test_repr_error():\n                x = ObjWithErrorInRepr()\n                assert x == \"value\"\n        \"\"\"\n        )\n        reprec = pytester.inline_run(\"--showlocals\", \"-vv\", p)\n        passed, skipped, failed = repre"}, {"start_line": 14000, "end_line": 16000, "belongs_to": {"file_name": "test_runner.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "epr_failure(self, excinfo):\n                    assert 0\n        \"\"\"\n        )\n        reports = pytester.runitem(\n            \"\"\"\n            def setup_function(func):\n                raise ValueError(42)\n            def test_func():\n                pass\n        \"\"\"\n        )\n        assert len(reports) == 2\n        rep = reports[0]\n        print(rep)\n        assert not rep.skipped\n        assert not rep.passed\n        assert rep.failed\n        # assert rep.outcome.when == \"setup\"\n        # assert rep.outcome.where.lineno == 3\n        # assert rep.outcome.where.path.basename == \"test_func.py\"\n        # assert isinstance(rep.failed.failurerepr, PythonFailureRepr)\n\n    def test_systemexit_does_not_bail_out(self, pytester: Pytester) -> None:\n        try:\n            reports = pytester.runitem(\n                \"\"\"\n                def test_func():\n                    raise SystemExit(42)\n            \"\"\"\n            )\n        except SystemExit:\n            assert False, \"runner did not catch SystemExit\"\n        rep = reports[1]\n        assert rep.failed\n        assert rep.when == \"call\"\n\n    def test_exit_propagates(self, pytester: Pytester) -> None:\n        try:\n            pytester.runitem(\n                \"\"\"\n                import pytest\n                def test_func():\n                    raise pytest.exit.Exception()\n            \"\"\"\n            )\n        except pytest.exit.Exception:\n            pass\n        else:\n            assert False, \"did not raise\"\n\n\nclass TestExecutionNonForked(BaseFunctionalTests):\n    def getrunner(self):\n        def f(item):\n            return runner.runtestprotocol(item, log=False)\n\n        return f\n\n    def test_keyboardinterrupt_propagates(self, pytester: Pytester) -> None:\n        try:\n            pytester.runitem(\n                \"\"\"\n                def test_func():\n                    raise KeyboardInterrupt(\"fake\")\n            \"\"\"\n            )\n        except KeyboardInterrupt:\n            pass\n        else:\n            assert Fal"}, {"start_line": 50000, "end_line": 52000, "belongs_to": {"file_name": "test_terminal.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "rting*\", \"*No module named *xyz*\", \"*1 error*\"]\n        )\n\n    def test_maxfailures(self, pytester: Pytester, option) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            def test_1():\n                assert 0\n            def test_2():\n                assert 0\n            def test_3():\n                assert 0\n        \"\"\"\n        )\n        result = pytester.runpytest(\"--maxfail=2\", *option.args)\n        result.stdout.fnmatch_lines(\n            [\n                \"*def test_1():*\",\n                \"*def test_2():*\",\n                \"*! stopping after 2 failures !*\",\n                \"*2 failed*\",\n            ]\n        )\n\n    def test_maxfailures_with_interrupted(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            def test(request):\n                request.session.shouldstop = \"session_interrupted\"\n                assert 0\n        \"\"\"\n        )\n        result = pytester.runpytest(\"--maxfail=1\", \"-ra\")\n        result.stdout.fnmatch_lines(\n            [\n                \"*= short test summary info =*\",\n                \"FAILED *\",\n                \"*! stopping after 1 failures !*\",\n                \"*! session_interrupted !*\",\n                \"*= 1 failed in*\",\n            ]\n        )\n\n    def test_tb_option(self, pytester: Pytester, option) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n            def g():\n                raise IndexError\n            def test_func():\n                print(6*7)\n                g()  # --calling--\n        \"\"\"\n        )\n        for tbopt in [\"long\", \"short\", \"no\"]:\n            print(f\"testing --tb={tbopt}...\")\n            result = pytester.runpytest(\"-rN\", f\"--tb={tbopt}\")\n            s = result.stdout.str()\n            if tbopt == \"long\":\n                assert \"print(6*7)\" in s\n            else:\n                assert \"print(6*7)\" not in s\n            if tbopt != \"no\":\n                assert \"--calling--\" in s\n                assert \"IndexError\" in s\n       "}, {"start_line": 49000, "end_line": 51000, "belongs_to": {"file_name": "test_terminal.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": " 42\n        def test_opt(arg):\n            x = 0\n            assert x\n    \"\"\"\n    )\n    result = pytester.runpytest(\"--tb=short\")\n    s = result.stdout.str()\n    assert \"arg = 42\" not in s\n    assert \"x = 0\" not in s\n    result.stdout.fnmatch_lines([f\"*{p.name}:8*\", \"    assert x\", \"E   assert*\"])\n    result = pytester.runpytest()\n    s = result.stdout.str()\n    assert \"x = 0\" in s\n    assert \"assert x\" in s\n\n\ndef test_traceconfig(pytester: Pytester) -> None:\n    result = pytester.runpytest(\"--traceconfig\")\n    result.stdout.fnmatch_lines([\"*active plugins*\"])\n    assert result.ret == ExitCode.NO_TESTS_COLLECTED\n\n\nclass TestGenericReporting:\n    \"\"\"Test class which can be subclassed with a different option provider to\n    run e.g. distributed tests.\"\"\"\n\n    def test_collect_fail(self, pytester: Pytester, option) -> None:\n        pytester.makepyfile(\"import xyz\\n\")\n        result = pytester.runpytest(*option.args)\n        result.stdout.fnmatch_lines(\n            [\"ImportError while importing*\", \"*No module named *xyz*\", \"*1 error*\"]\n        )\n\n    def test_maxfailures(self, pytester: Pytester, option) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            def test_1():\n                assert 0\n            def test_2():\n                assert 0\n            def test_3():\n                assert 0\n        \"\"\"\n        )\n        result = pytester.runpytest(\"--maxfail=2\", *option.args)\n        result.stdout.fnmatch_lines(\n            [\n                \"*def test_1():*\",\n                \"*def test_2():*\",\n                \"*! stopping after 2 failures !*\",\n                \"*2 failed*\",\n            ]\n        )\n\n    def test_maxfailures_with_interrupted(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            def test(request):\n                request.session.shouldstop = \"session_interrupted\"\n                assert 0\n        \"\"\"\n        )\n        result = pytester.runpytest(\"--maxfail=1\", \"-ra\")\n        result.stdout.fnmatch_lines("}, {"start_line": 20000, "end_line": 22000, "belongs_to": {"file_name": "test_runner.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": " test_pytest_fail() -> None:\n    with pytest.raises(pytest.fail.Exception) as excinfo:\n        pytest.fail(\"hello\")\n    s = excinfo.exconly(tryshort=True)\n    assert s.startswith(\"Failed\")\n\n\ndef test_pytest_exit_msg(pytester: Pytester) -> None:\n    pytester.makeconftest(\n        \"\"\"\n    import pytest\n\n    def pytest_configure(config):\n        pytest.exit('oh noes')\n    \"\"\"\n    )\n    result = pytester.runpytest()\n    result.stderr.fnmatch_lines([\"Exit: oh noes\"])\n\n\ndef _strip_resource_warnings(lines):\n    # Assert no output on stderr, except for unreliable ResourceWarnings.\n    # (https://github.com/pytest-dev/pytest/issues/5088)\n    return [\n        x\n        for x in lines\n        if not x.startswith((\"Exception ignored in:\", \"ResourceWarning\"))\n    ]\n\n\ndef test_pytest_exit_returncode(pytester: Pytester) -> None:\n    pytester.makepyfile(\n        \"\"\"\\\n        import pytest\n        def test_foo():\n            pytest.exit(\"some exit msg\", 99)\n    \"\"\"\n    )\n    result = pytester.runpytest()\n    result.stdout.fnmatch_lines([\"*! *Exit: some exit msg !*\"])\n\n    assert _strip_resource_warnings(result.stderr.lines) == []\n    assert result.ret == 99\n\n    # It prints to stderr also in case of exit during pytest_sessionstart.\n    pytester.makeconftest(\n        \"\"\"\\\n        import pytest\n\n        def pytest_sessionstart():\n            pytest.exit(\"during_sessionstart\", 98)\n        \"\"\"\n    )\n    result = pytester.runpytest()\n    result.stdout.fnmatch_lines([\"*! *Exit: during_sessionstart !*\"])\n    assert _strip_resource_warnings(result.stderr.lines) == [\n        \"Exit: during_sessionstart\"\n    ]\n    assert result.ret == 98\n\n\ndef test_pytest_fail_notrace_runtest(pytester: Pytester) -> None:\n    \"\"\"Test pytest.fail(..., pytrace=False) does not show tracebacks during test run.\"\"\"\n    pytester.makepyfile(\n        \"\"\"\n        import pytest\n        def test_hello():\n            pytest.fail(\"hello\", pytrace=False)\n        def teardown_function(function):\n            pytest.fail(\"world\""}, {"start_line": 19000, "end_line": 21000, "belongs_to": {"file_name": "test_runner.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "     def test_hello1(self, mylist):\n                assert mylist == ['class', 'module'], mylist\n                raise ValueError()\n            def test_hello2(self, mylist):\n                assert mylist == ['class', 'module'], mylist\n        def pytest_runtest_teardown(item):\n            del item.function.mylist\n    \"\"\"\n    )\n    result = pytester.runpytest(p1)\n    result.stdout.fnmatch_lines([\"*2 passed*\"])\n\n\ndef test_outcomeexception_exceptionattributes() -> None:\n    outcome = outcomes.OutcomeException(\"test\")\n    assert outcome.args[0] == outcome.msg\n\n\ndef test_outcomeexception_passes_except_Exception() -> None:\n    with pytest.raises(outcomes.OutcomeException):\n        try:\n            raise outcomes.OutcomeException(\"test\")\n        except Exception as e:\n            raise NotImplementedError from e\n\n\ndef test_pytest_exit() -> None:\n    with pytest.raises(pytest.exit.Exception) as excinfo:\n        pytest.exit(\"hello\")\n    assert excinfo.errisinstance(pytest.exit.Exception)\n\n\ndef test_pytest_fail() -> None:\n    with pytest.raises(pytest.fail.Exception) as excinfo:\n        pytest.fail(\"hello\")\n    s = excinfo.exconly(tryshort=True)\n    assert s.startswith(\"Failed\")\n\n\ndef test_pytest_exit_msg(pytester: Pytester) -> None:\n    pytester.makeconftest(\n        \"\"\"\n    import pytest\n\n    def pytest_configure(config):\n        pytest.exit('oh noes')\n    \"\"\"\n    )\n    result = pytester.runpytest()\n    result.stderr.fnmatch_lines([\"Exit: oh noes\"])\n\n\ndef _strip_resource_warnings(lines):\n    # Assert no output on stderr, except for unreliable ResourceWarnings.\n    # (https://github.com/pytest-dev/pytest/issues/5088)\n    return [\n        x\n        for x in lines\n        if not x.startswith((\"Exception ignored in:\", \"ResourceWarning\"))\n    ]\n\n\ndef test_pytest_exit_returncode(pytester: Pytester) -> None:\n    pytester.makepyfile(\n        \"\"\"\\\n        import pytest\n        def test_foo():\n            pytest.exit(\"some exit msg\", 99)\n    \"\"\"\n    )\n    result = pytester.runpytest"}, {"start_line": 50000, "end_line": 52000, "belongs_to": {"file_name": "test_config.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "n err\n\n    class A:\n        def pytest_internalerror(self):\n            return True\n\n    config.pluginmanager.register(A())\n    config.notify_exception(excinfo, config.option)\n    _, err = capfd.readouterr()\n    assert not err\n\n    config = pytester.parseconfig(\"-p\", \"no:terminal\")\n    with pytest.raises(ValueError) as excinfo:\n        raise ValueError(1)\n    config.notify_exception(excinfo, config.option)\n    _, err = capfd.readouterr()\n    assert \"ValueError\" in err\n\n\ndef test_no_terminal_discovery_error(pytester: Pytester) -> None:\n    pytester.makepyfile(\"raise TypeError('oops!')\")\n    result = pytester.runpytest(\"-p\", \"no:terminal\", \"--collect-only\")\n    assert result.ret == ExitCode.INTERRUPTED\n\n\ndef test_load_initial_conftest_last_ordering(_config_for_test):\n    pm = _config_for_test.pluginmanager\n\n    class My:\n        def pytest_load_initial_conftests(self):\n            pass\n\n    m = My()\n    pm.register(m)\n    hc = pm.hook.pytest_load_initial_conftests\n    hookimpls = [\n        (\n            hookimpl.function.__module__,\n            \"wrapper\" if (hookimpl.wrapper or hookimpl.hookwrapper) else \"nonwrapper\",\n        )\n        for hookimpl in hc.get_hookimpls()\n    ]\n    assert hookimpls == [\n        (\"_pytest.config\", \"nonwrapper\"),\n        (m.__module__, \"nonwrapper\"),\n        (\"_pytest.legacypath\", \"nonwrapper\"),\n        (\"_pytest.capture\", \"wrapper\"),\n        (\"_pytest.warnings\", \"wrapper\"),\n    ]\n\n\ndef test_get_plugin_specs_as_list() -> None:\n    def exp_match(val: object) -> str:\n        return (\n            f\"Plugins may be specified as a sequence or a ','-separated string \"\n            f\"of plugin names. Got: {re.escape(repr(val))}\"\n        )\n\n    with pytest.raises(pytest.UsageError, match=exp_match({\"foo\"})):\n        _get_plugin_specs_as_list({\"foo\"})  # type: ignore[arg-type]\n    with pytest.raises(pytest.UsageError, match=exp_match({})):\n        _get_plugin_specs_as_list(dict())  # type: ignore[arg-type]\n\n    assert _get_plugin_specs_as_list(None)"}, {"start_line": 32000, "end_line": 34000, "belongs_to": {"file_name": "test_runner.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": " def test_fix(foo):\n            assert False\n    \"\"\"\n    )\n    result = pytester.runpytest(\"-vv\")\n    result.stdout.no_fnmatch_line(\"*INTERNALERROR*\")\n    result.stdout.fnmatch_lines([\"*test_fix*\", \"*fixture*'missing'*not found*\"])\n\n\ndef test_store_except_info_on_error() -> None:\n    \"\"\"Test that upon test failure, the exception info is stored on\n    sys.last_traceback and friends.\"\"\"\n\n    # Simulate item that might raise a specific exception, depending on `raise_error` class var\n    class ItemMightRaise:\n        nodeid = \"item_that_raises\"\n        raise_error = True\n\n        def runtest(self):\n            if self.raise_error:\n                raise IndexError(\"TEST\")\n\n    try:\n        runner.pytest_runtest_call(ItemMightRaise())  # type: ignore[arg-type]\n    except IndexError:\n        pass\n    # Check that exception info is stored on sys\n    assert sys.last_type is IndexError\n    assert isinstance(sys.last_value, IndexError)\n    if sys.version_info >= (3, 12, 0):\n        assert isinstance(sys.last_exc, IndexError)  # type:ignore[attr-defined]\n\n    assert sys.last_value.args[0] == \"TEST\"\n    assert sys.last_traceback\n\n    # The next run should clear the exception info stored by the previous run\n    ItemMightRaise.raise_error = False\n    runner.pytest_runtest_call(ItemMightRaise())  # type: ignore[arg-type]\n    assert not hasattr(sys, \"last_type\")\n    assert not hasattr(sys, \"last_value\")\n    if sys.version_info >= (3, 12, 0):\n        assert not hasattr(sys, \"last_exc\")\n    assert not hasattr(sys, \"last_traceback\")\n\n\ndef test_current_test_env_var(pytester: Pytester, monkeypatch: MonkeyPatch) -> None:\n    pytest_current_test_vars: list[tuple[str, str]] = []\n    monkeypatch.setattr(\n        sys, \"pytest_current_test_vars\", pytest_current_test_vars, raising=False\n    )\n    pytester.makepyfile(\n        \"\"\"\n        import pytest\n        import sys\n        import os\n\n        @pytest.fixture\n        def fix():\n            sys.pytest_current_test_vars.append(('setup', os.envi"}, {"start_line": 1000, "end_line": 3000, "belongs_to": {"file_name": "acceptance_test.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": ".makepyfile(conftest=\"raise SyntaxError\\n\")\n        result = pytester.runpytest()\n        result.stderr.fnmatch_lines([\"*raise SyntaxError*\"])\n        assert result.ret != 0\n\n    def test_early_hook_error_issue38_1(self, pytester: Pytester) -> None:\n        pytester.makeconftest(\n            \"\"\"\n            def pytest_sessionstart():\n                0 / 0\n        \"\"\"\n        )\n        result = pytester.runpytest(pytester.path)\n        assert result.ret != 0\n        # tracestyle is native by default for hook failures\n        result.stdout.fnmatch_lines(\n            [\"*INTERNALERROR*File*conftest.py*line 2*\", \"*0 / 0*\"]\n        )\n        result = pytester.runpytest(pytester.path, \"--fulltrace\")\n        assert result.ret != 0\n        # tracestyle is native by default for hook failures\n        result.stdout.fnmatch_lines(\n            [\"*INTERNALERROR*def pytest_sessionstart():*\", \"*INTERNALERROR*0 / 0*\"]\n        )\n\n    def test_early_hook_configure_error_issue38(self, pytester: Pytester) -> None:\n        pytester.makeconftest(\n            \"\"\"\n            def pytest_configure():\n                0 / 0\n        \"\"\"\n        )\n        result = pytester.runpytest(pytester.path)\n        assert result.ret != 0\n        # here we get it on stderr\n        result.stderr.fnmatch_lines(\n            [\"*INTERNALERROR*File*conftest.py*line 2*\", \"*0 / 0*\"]\n        )\n\n    def test_file_not_found(self, pytester: Pytester) -> None:\n        result = pytester.runpytest(\"asd\")\n        assert result.ret != 0\n        result.stderr.fnmatch_lines([\"ERROR: file or directory not found: asd\"])\n\n    def test_file_not_found_unconfigure_issue143(self, pytester: Pytester) -> None:\n        pytester.makeconftest(\n            \"\"\"\n            def pytest_configure():\n                print(\"---configure\")\n            def pytest_unconfigure():\n                print(\"---unconfigure\")\n        \"\"\"\n        )\n        result = pytester.runpytest(\"-s\", \"asd\")\n        assert result.ret == ExitCode.USAGE_ERROR\n        re"}], "retrieved_count": 10, "cost_time": 1.081204891204834}
{"question": "What is the interaction mechanism between Pytest's Session class and the Collector class to establish the relationship between test collection and test execution?", "answer": null, "relative_code_list": null, "ground_truth": "The interaction mechanism between Pytest's Session class and Collector class establishes a hierarchical relationship for test collection and execution: 1) Session class serves as the root collector that inherits from nodes.Collector and initiates the collection process through perform_collect() method, 2) Session coordinates the collection phase by calling pytest_collection hook which triggers the collection protocol, 3) Collection follows a recursive pattern where Session collects initial paths and delegates to appropriate Collector instances (File, Module, Class, etc.), 4) Each Collector implements the collect() method to discover and yield child nodes (Items or other Collectors), 5) Session maintains the collection tree hierarchy with items list containing all discovered test items, 6) Collection reports are generated through pytest_collectreport hook to track collection progress and failures, 7) Session manages collection state including testsfailed and testscollected counters, 8) After collection, Session triggers pytest_collection_modifyitems hook for post-collection processing, 9) Session then coordinates test execution through pytest_runtestloop hook, 10) The collection-execution relationship is established through the items list that Session maintains, 11) Session provides control flow mechanisms (shouldstop, shouldfail) that affect both collection and execution phases, 12) Collection caching and duplicate handling ensure efficient test discovery and execution coordination.", "score": null, "retrieved_content": [{"start_line": 17000, "end_line": 19000, "belongs_to": {"file_name": "main.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "le_path=path, parent=self)\n                yield from cols\n\n\n@final\nclass Session(nodes.Collector):\n    \"\"\"The root of the collection tree.\n\n    ``Session`` collects the initial paths given as arguments to pytest.\n    \"\"\"\n\n    Interrupted = Interrupted\n    Failed = Failed\n    # Set on the session by runner.pytest_sessionstart.\n    _setupstate: SetupState\n    # Set on the session by fixtures.pytest_sessionstart.\n    _fixturemanager: FixtureManager\n    exitstatus: int | ExitCode\n\n    def __init__(self, config: Config) -> None:\n        super().__init__(\n            name=\"\",\n            path=config.rootpath,\n            fspath=None,\n            parent=None,\n            config=config,\n            session=self,\n            nodeid=\"\",\n        )\n        self.testsfailed = 0\n        self.testscollected = 0\n        self._shouldstop: bool | str = False\n        self._shouldfail: bool | str = False\n        self.trace = config.trace.root.get(\"collection\")\n        self._initialpaths: frozenset[Path] = frozenset()\n        self._initialpaths_with_parents: frozenset[Path] = frozenset()\n        self._notfound: list[tuple[str, Sequence[nodes.Collector]]] = []\n        self._initial_parts: list[CollectionArgument] = []\n        self._collection_cache: dict[nodes.Collector, CollectReport] = {}\n        self.items: list[nodes.Item] = []\n\n        self._bestrelpathcache: dict[Path, str] = _bestrelpath_cache(config.rootpath)\n\n        self.config.pluginmanager.register(self, name=\"session\")\n\n    @classmethod\n    def from_config(cls, config: Config) -> Session:\n        session: Session = cls._create(config=config)\n        return session\n\n    def __repr__(self) -> str:\n        return (\n            f\"<{self.__class__.__name__} {self.name} \"\n            f\"exitstatus=%r \"\n            f\"testsfailed={self.testsfailed} \"\n            f\"testscollected={self.testscollected}>\"\n        ) % getattr(self, \"exitstatus\", \"<UNSET>\")\n\n    @property\n    def shouldstop(self) -> bool | str:\n        return self._shoul"}, {"start_line": 18000, "end_line": 20000, "belongs_to": {"file_name": "main.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "= frozenset()\n        self._initialpaths_with_parents: frozenset[Path] = frozenset()\n        self._notfound: list[tuple[str, Sequence[nodes.Collector]]] = []\n        self._initial_parts: list[CollectionArgument] = []\n        self._collection_cache: dict[nodes.Collector, CollectReport] = {}\n        self.items: list[nodes.Item] = []\n\n        self._bestrelpathcache: dict[Path, str] = _bestrelpath_cache(config.rootpath)\n\n        self.config.pluginmanager.register(self, name=\"session\")\n\n    @classmethod\n    def from_config(cls, config: Config) -> Session:\n        session: Session = cls._create(config=config)\n        return session\n\n    def __repr__(self) -> str:\n        return (\n            f\"<{self.__class__.__name__} {self.name} \"\n            f\"exitstatus=%r \"\n            f\"testsfailed={self.testsfailed} \"\n            f\"testscollected={self.testscollected}>\"\n        ) % getattr(self, \"exitstatus\", \"<UNSET>\")\n\n    @property\n    def shouldstop(self) -> bool | str:\n        return self._shouldstop\n\n    @shouldstop.setter\n    def shouldstop(self, value: bool | str) -> None:\n        # The runner checks shouldfail and assumes that if it is set we are\n        # definitely stopping, so prevent unsetting it.\n        if value is False and self._shouldstop:\n            warnings.warn(\n                PytestWarning(\n                    \"session.shouldstop cannot be unset after it has been set; ignoring.\"\n                ),\n                stacklevel=2,\n            )\n            return\n        self._shouldstop = value\n\n    @property\n    def shouldfail(self) -> bool | str:\n        return self._shouldfail\n\n    @shouldfail.setter\n    def shouldfail(self, value: bool | str) -> None:\n        # The runner checks shouldfail and assumes that if it is set we are\n        # definitely stopping, so prevent unsetting it.\n        if value is False and self._shouldfail:\n            warnings.warn(\n                PytestWarning(\n                    \"session.shouldfail cannot be unset after it has bee"}, {"start_line": 16000, "end_line": 18000, "belongs_to": {"file_name": "main.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "m_parent(parent=parent, path=path)\n\n    def collect(self) -> Iterable[nodes.Item | nodes.Collector]:\n        config = self.config\n        col: nodes.Collector | None\n        cols: Sequence[nodes.Collector]\n        ihook = self.ihook\n        for direntry in scandir(self.path):\n            if direntry.is_dir():\n                path = Path(direntry.path)\n                if not self.session.isinitpath(path, with_parents=True):\n                    if ihook.pytest_ignore_collect(collection_path=path, config=config):\n                        continue\n                col = ihook.pytest_collect_directory(path=path, parent=self)\n                if col is not None:\n                    yield col\n\n            elif direntry.is_file():\n                path = Path(direntry.path)\n                if not self.session.isinitpath(path):\n                    if ihook.pytest_ignore_collect(collection_path=path, config=config):\n                        continue\n                cols = ihook.pytest_collect_file(file_path=path, parent=self)\n                yield from cols\n\n\n@final\nclass Session(nodes.Collector):\n    \"\"\"The root of the collection tree.\n\n    ``Session`` collects the initial paths given as arguments to pytest.\n    \"\"\"\n\n    Interrupted = Interrupted\n    Failed = Failed\n    # Set on the session by runner.pytest_sessionstart.\n    _setupstate: SetupState\n    # Set on the session by fixtures.pytest_sessionstart.\n    _fixturemanager: FixtureManager\n    exitstatus: int | ExitCode\n\n    def __init__(self, config: Config) -> None:\n        super().__init__(\n            name=\"\",\n            path=config.rootpath,\n            fspath=None,\n            parent=None,\n            config=config,\n            session=self,\n            nodeid=\"\",\n        )\n        self.testsfailed = 0\n        self.testscollected = 0\n        self._shouldstop: bool | str = False\n        self._shouldfail: bool | str = False\n        self.trace = config.trace.root.get(\"collection\")\n        self._initialpaths: frozenset[Path] "}, {"start_line": 18000, "end_line": 20000, "belongs_to": {"file_name": "test_collection.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "sub2.joinpath(conf2.name))\n        p = pytester.makepyfile(\"def test_x(): pass\")\n        shutil.copy(p, sub1.joinpath(p.name))\n        shutil.copy(p, sub2.joinpath(p.name))\n        result = pytester.runpytest(\"--co\")\n        result.stdout.fnmatch_lines([\"*MyModule1*\", \"*MyModule2*\", \"*test_x*\"])\n\n\nclass TestSession:\n    def test_collect_topdir(self, pytester: Pytester) -> None:\n        p = pytester.makepyfile(\"def test_func(): pass\")\n        id = \"::\".join([p.name, \"test_func\"])\n        # XXX migrate to collectonly? (see below)\n        config = pytester.parseconfig(id)\n        topdir = pytester.path\n        rcol = Session.from_config(config)\n        assert topdir == rcol.path\n        # rootid = rcol.nodeid\n        # root2 = rcol.perform_collect([rcol.nodeid], genitems=False)[0]\n        # assert root2 == rcol, rootid\n        colitems = rcol.perform_collect([rcol.nodeid], genitems=False)\n        assert len(colitems) == 1\n        assert colitems[0].path == topdir\n\n    def get_reported_items(self, hookrec: HookRecorder) -> list[Item]:\n        \"\"\"Return pytest.Item instances reported by the pytest_collectreport hook\"\"\"\n        calls = hookrec.getcalls(\"pytest_collectreport\")\n        return [\n            x\n            for call in calls\n            for x in call.report.result\n            if isinstance(x, pytest.Item)\n        ]\n\n    def test_collect_protocol_single_function(self, pytester: Pytester) -> None:\n        p = pytester.makepyfile(\"def test_func(): pass\")\n        id = \"::\".join([p.name, \"test_func\"])\n        items, hookrec = pytester.inline_genitems(id)\n        (item,) = items\n        assert item.name == \"test_func\"\n        newid = item.nodeid\n        assert newid == id\n        pprint.pprint(hookrec.calls)\n        topdir = pytester.path  # noqa: F841\n        hookrec.assert_contains(\n            [\n                (\"pytest_collectstart\", \"collector.path == topdir\"),\n                (\"pytest_make_collect_report\", \"collector.path == topdir\"),\n                (\"pytest_c"}, {"start_line": 6000, "end_line": 8000, "belongs_to": {"file_name": "test_session.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "rec.getreports(\"pytest_collectreport\")\n        # Session, Dir\n        assert len(reports) == 2\n        assert reports[1].skipped\n\n\nclass TestNewSession(SessionTests):\n    def test_order_of_execution(self, pytester: Pytester) -> None:\n        reprec = pytester.inline_runsource(\n            \"\"\"\n            values = []\n            def test_1():\n                values.append(1)\n            def test_2():\n                values.append(2)\n            def test_3():\n                assert values == [1,2]\n            class Testmygroup(object):\n                reslist = values\n                def test_1(self):\n                    self.reslist.append(1)\n                def test_2(self):\n                    self.reslist.append(2)\n                def test_3(self):\n                    self.reslist.append(3)\n                def test_4(self):\n                    assert self.reslist == [1,2,1,2,3]\n        \"\"\"\n        )\n        passed, skipped, failed = reprec.countoutcomes()\n        assert failed == skipped == 0\n        assert passed == 7\n\n    def test_collect_only_with_various_situations(self, pytester: Pytester) -> None:\n        p = pytester.makepyfile(\n            test_one=\"\"\"\n                def test_one():\n                    raise ValueError()\n\n                class TestX(object):\n                    def test_method_one(self):\n                        pass\n\n                class TestY(TestX):\n                    pass\n            \"\"\",\n            test_three=\"xxxdsadsadsadsa\",\n            __init__=\"\",\n        )\n        reprec = pytester.inline_run(\"--collect-only\", p.parent)\n\n        itemstarted = reprec.getcalls(\"pytest_itemcollected\")\n        assert len(itemstarted) == 3\n        assert not reprec.getreports(\"pytest_runtest_logreport\")\n        started = reprec.getcalls(\"pytest_collectstart\")\n        finished = reprec.getreports(\"pytest_collectreport\")\n        assert len(started) == len(finished)\n        assert len(started) == 6\n        colfail = [x for x in finished if x.failed]\n"}, {"start_line": 17000, "end_line": 19000, "belongs_to": {"file_name": "test_collection.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "        result.stdout.fnmatch_lines([\"*MyModule*\", \"*test_x*\"])\n\n    def test_pytest_collect_file_from_sister_dir(self, pytester: Pytester) -> None:\n        sub1 = pytester.mkpydir(\"sub1\")\n        sub2 = pytester.mkpydir(\"sub2\")\n        conf1 = pytester.makeconftest(\n            \"\"\"\n            import pytest\n            class MyModule1(pytest.Module):\n                pass\n            def pytest_collect_file(file_path, parent):\n                if file_path.suffix == \".py\":\n                    return MyModule1.from_parent(path=file_path, parent=parent)\n        \"\"\"\n        )\n        conf1.replace(sub1.joinpath(conf1.name))\n        conf2 = pytester.makeconftest(\n            \"\"\"\n            import pytest\n            class MyModule2(pytest.Module):\n                pass\n            def pytest_collect_file(file_path, parent):\n                if file_path.suffix == \".py\":\n                    return MyModule2.from_parent(path=file_path, parent=parent)\n        \"\"\"\n        )\n        conf2.replace(sub2.joinpath(conf2.name))\n        p = pytester.makepyfile(\"def test_x(): pass\")\n        shutil.copy(p, sub1.joinpath(p.name))\n        shutil.copy(p, sub2.joinpath(p.name))\n        result = pytester.runpytest(\"--co\")\n        result.stdout.fnmatch_lines([\"*MyModule1*\", \"*MyModule2*\", \"*test_x*\"])\n\n\nclass TestSession:\n    def test_collect_topdir(self, pytester: Pytester) -> None:\n        p = pytester.makepyfile(\"def test_func(): pass\")\n        id = \"::\".join([p.name, \"test_func\"])\n        # XXX migrate to collectonly? (see below)\n        config = pytester.parseconfig(id)\n        topdir = pytester.path\n        rcol = Session.from_config(config)\n        assert topdir == rcol.path\n        # rootid = rcol.nodeid\n        # root2 = rcol.perform_collect([rcol.nodeid], genitems=False)[0]\n        # assert root2 == rcol, rootid\n        colitems = rcol.perform_collect([rcol.nodeid], genitems=False)\n        assert len(colitems) == 1\n        assert colitems[0].path == topdir\n\n    def get_reported_ite"}, {"start_line": 33000, "end_line": 35000, "belongs_to": {"file_name": "pytester.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "onfigure(path)\n        session = Session.from_config(config)\n        x = bestrelpath(session.path, path)\n        config.hook.pytest_sessionstart(session=session)\n        res = session.perform_collect([x], genitems=False)[0]\n        config.hook.pytest_sessionfinish(session=session, exitstatus=ExitCode.OK)\n        return res\n\n    def genitems(self, colitems: Sequence[Item | Collector]) -> list[Item]:\n        \"\"\"Generate all test items from a collection node.\n\n        This recurses into the collection node and returns a list of all the\n        test items contained within.\n\n        :param colitems:\n            The collection nodes.\n        :returns:\n            The collected items.\n        \"\"\"\n        session = colitems[0].session\n        result: list[Item] = []\n        for colitem in colitems:\n            result.extend(session.genitems(colitem))\n        return result\n\n    def runitem(self, source: str) -> Any:\n        \"\"\"Run the \"test_func\" Item.\n\n        The calling test instance (class containing the test method) must\n        provide a ``.getrunner()`` method which should return a runner which\n        can run the test protocol for a single item, e.g.\n        ``_pytest.runner.runtestprotocol``.\n        \"\"\"\n        # used from runner functional tests\n        item = self.getitem(source)\n        # the test class where we are called from wants to provide the runner\n        testclassinstance = self._request.instance\n        runner = testclassinstance.getrunner()\n        return runner(item)\n\n    def inline_runsource(self, source: str, *cmdlineargs) -> HookRecorder:\n        \"\"\"Run a test module in process using ``pytest.main()``.\n\n        This run writes \"source\" into a temporary file and runs\n        ``pytest.main()`` on it, returning a :py:class:`HookRecorder` instance\n        for the result.\n\n        :param source: The source code of the test module.\n        :param cmdlineargs: Any extra command line arguments to use.\n        \"\"\"\n        p = self.makepyfile(source)\n      "}, {"start_line": 27000, "end_line": 29000, "belongs_to": {"file_name": "main.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "pluginmanager.check_pending()\n            hook.pytest_collection_modifyitems(\n                session=self, config=self.config, items=items\n            )\n        finally:\n            self._notfound = []\n            self._initial_parts = []\n            self._collection_cache = {}\n            hook.pytest_collection_finish(session=self)\n\n        if genitems:\n            self.testscollected = len(items)\n\n        return items\n\n    def _collect_one_node(\n        self,\n        node: nodes.Collector,\n        handle_dupes: bool = True,\n    ) -> tuple[CollectReport, bool]:\n        if node in self._collection_cache and handle_dupes:\n            rep = self._collection_cache[node]\n            return rep, True\n        else:\n            rep = collect_one_node(node)\n            self._collection_cache[node] = rep\n            return rep, False\n\n    def collect(self) -> Iterator[nodes.Item | nodes.Collector]:\n        # This is a cache for the root directories of the initial paths.\n        # We can't use collection_cache for Session because of its special\n        # role as the bootstrapping collector.\n        path_cache: dict[Path, Sequence[nodes.Collector]] = {}\n\n        pm = self.config.pluginmanager\n\n        for collection_argument in self._initial_parts:\n            self.trace(\"processing argument\", collection_argument)\n            self.trace.root.indent += 1\n\n            argpath = collection_argument.path\n            names = collection_argument.parts\n            module_name = collection_argument.module_name\n\n            # resolve_collection_argument() ensures this.\n            if argpath.is_dir():\n                assert not names, f\"invalid arg {(argpath, names)!r}\"\n\n            paths = [argpath]\n            # Add relevant parents of the path, from the root, e.g.\n            #   /a/b/c.py -> [/, /a, /a/b, /a/b/c.py]\n            if module_name is None:\n                # Paths outside of the confcutdir should not be considered.\n                for path in argpath.parents:\n          "}, {"start_line": 13000, "end_line": 15000, "belongs_to": {"file_name": "runner.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "e_packages=collector.config.getini(\n                    \"consider_namespace_packages\"\n                ),\n            )\n\n        return list(collector.collect())\n\n    call = CallInfo.from_call(\n        collect, \"collect\", reraise=(KeyboardInterrupt, SystemExit)\n    )\n    longrepr: None | tuple[str, int, str] | str | TerminalRepr = None\n    if not call.excinfo:\n        outcome: Literal[\"passed\", \"skipped\", \"failed\"] = \"passed\"\n    else:\n        skip_exceptions = [Skipped]\n        unittest = sys.modules.get(\"unittest\")\n        if unittest is not None:\n            skip_exceptions.append(unittest.SkipTest)\n        if isinstance(call.excinfo.value, tuple(skip_exceptions)):\n            outcome = \"skipped\"\n            r_ = collector._repr_failure_py(call.excinfo, \"line\")\n            assert isinstance(r_, ExceptionChainRepr), repr(r_)\n            r = r_.reprcrash\n            assert r\n            longrepr = (str(r.path), r.lineno, r.message)\n        else:\n            outcome = \"failed\"\n            errorinfo = collector.repr_failure(call.excinfo)\n            if not hasattr(errorinfo, \"toterminal\"):\n                assert isinstance(errorinfo, str)\n                errorinfo = CollectErrorRepr(errorinfo)\n            longrepr = errorinfo\n    result = call.result if not call.excinfo else None\n    rep = CollectReport(collector.nodeid, outcome, longrepr, result)\n    rep.call = call  # type: ignore # see collect_one_node\n    return rep\n\n\nclass SetupState:\n    \"\"\"Shared state for setting up/tearing down test items or collectors\n    in a session.\n\n    Suppose we have a collection tree as follows:\n\n    <Session session>\n        <Module mod1>\n            <Function item1>\n        <Module mod2>\n            <Function item2>\n\n    The SetupState maintains a stack. The stack starts out empty:\n\n        []\n\n    During the setup phase of item1, setup(item1) is called. What it does\n    is:\n\n        push session to stack, run session.setup()\n        push mod1 to stack, run mod1.setup()\n        push"}, {"start_line": 24000, "end_line": 26000, "belongs_to": {"file_name": "main.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "| nodes.Collector]: ...\n\n    def perform_collect(\n        self, args: Sequence[str] | None = None, genitems: bool = True\n    ) -> Sequence[nodes.Item | nodes.Collector]:\n        \"\"\"Perform the collection phase for this session.\n\n        This is called by the default :hook:`pytest_collection` hook\n        implementation; see the documentation of this hook for more details.\n        For testing purposes, it may also be called directly on a fresh\n        ``Session``.\n\n        This function normally recursively expands any collectors collected\n        from the session to their items, and only items are returned. For\n        testing purposes, this may be suppressed by passing ``genitems=False``,\n        in which case the return value contains these collectors unexpanded,\n        and ``session.items`` is empty.\n        \"\"\"\n        if args is None:\n            args = self.config.args\n\n        self.trace(\"perform_collect\", self, args)\n        self.trace.root.indent += 1\n\n        hook = self.config.hook\n\n        self._notfound = []\n        self._initial_parts = []\n        self._collection_cache = {}\n        self.items = []\n        items: Sequence[nodes.Item | nodes.Collector] = self.items\n        consider_namespace_packages: bool = self.config.getini(\n            \"consider_namespace_packages\"\n        )\n        try:\n            initialpaths: list[Path] = []\n            initialpaths_with_parents: list[Path] = []\n            for arg in args:\n                collection_argument = resolve_collection_argument(\n                    self.config.invocation_params.dir,\n                    arg,\n                    as_pypath=self.config.option.pyargs,\n                    consider_namespace_packages=consider_namespace_packages,\n                )\n                self._initial_parts.append(collection_argument)\n                initialpaths.append(collection_argument.path)\n                initialpaths_with_parents.append(collection_argument.path)\n                initialpaths_with_parents.exten"}], "retrieved_count": 10, "cost_time": 1.0676348209381104}
{"question": "Why does Pytest use a fixture system with dependency injection instead of traditional setup/teardown methods?", "answer": null, "relative_code_list": null, "ground_truth": "Pytest uses a fixture system with dependency injection instead of traditional setup/teardown methods for several key architectural and practical reasons: 1) Dependency injection provides explicit, declarative dependencies where test functions clearly declare what resources they need through function parameters, making test requirements transparent and self-documenting, 2) Fixture system enables automatic dependency resolution where pytest automatically determines the order of fixture execution based on dependencies, eliminating the need for manual setup ordering, 3) Fixture scoping system (function, class, module, package, session) provides fine-grained control over resource lifecycle, allowing expensive resources to be shared across multiple tests when appropriate, 4) Fixture caching within scope prevents redundant setup/teardown operations, improving performance by reusing fixture instances across tests in the same scope, 5) Fixture system supports parametrization where the same fixture can be used with different parameters, enabling comprehensive testing scenarios, 6) Automatic cleanup through yield statements ensures proper resource cleanup regardless of test outcome, preventing resource leaks, 7) Fixture system integrates seamlessly with pytest's plugin architecture, allowing fixtures to be defined in plugins and shared across projects, 8) Dependency injection makes tests more modular and reusable, as fixtures can be easily shared between different test modules and projects, 9) Fixture system provides better error isolation where fixture failures are clearly attributed to specific fixtures rather than generic setup/teardown methods, 10) The system supports both autouse fixtures for automatic setup and explicit fixtures for on-demand resource creation, providing flexibility for different testing scenarios, 11) Fixture system enables better test organization where related setup logic is grouped with the resources it creates, 12) The dependency injection approach makes tests more testable themselves, as fixtures can be easily mocked or replaced for testing purposes.", "score": null, "retrieved_content": [{"start_line": 47000, "end_line": 49000, "belongs_to": {"file_name": "fixtures.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing/python", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "ope=\"module\", params=f())\n\n            @dec\n            def arg(request):\n                return request.param\n            @dec\n            def arg2(request):\n                return request.param\n\n            def test_1(arg):\n                values.append(arg)\n            def test_2(arg2):\n                values.append(arg2*10)\n        \"\"\"\n        )\n        reprec = pytester.inline_run(\"-v\")\n        reprec.assertoutcome(passed=4)\n        values = reprec.getcalls(\"pytest_runtest_call\")[0].item.module.values\n        assert values == [1, 2, 10, 20]\n\n    def test_setup_functions_as_fixtures(self, pytester: Pytester) -> None:\n        \"\"\"Ensure setup_* methods obey fixture scope rules (#517, #3094).\"\"\"\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n\n            DB_INITIALIZED = None\n\n            @pytest.fixture(scope=\"session\", autouse=True)\n            def db():\n                global DB_INITIALIZED\n                DB_INITIALIZED = True\n                yield\n                DB_INITIALIZED = False\n\n            def setup_module():\n                assert DB_INITIALIZED\n\n            def teardown_module():\n                assert DB_INITIALIZED\n\n            class TestClass(object):\n\n                def setup_method(self, method):\n                    assert DB_INITIALIZED\n\n                def teardown_method(self, method):\n                    assert DB_INITIALIZED\n\n                def test_printer_1(self):\n                    pass\n\n                def test_printer_2(self):\n                    pass\n        \"\"\"\n        )\n        result = pytester.runpytest()\n        result.stdout.fnmatch_lines([\"* 2 passed in *\"])\n\n    def test_parameterized_fixture_caching(self, pytester: Pytester) -> None:\n        \"\"\"Regression test for #12600.\"\"\"\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n            from itertools import count\n\n            CACHE_MISSES = count(0)\n\n            def pytest_generate_tests(metafunc):\n                if \"my_fixtur"}, {"start_line": 48000, "end_line": 50000, "belongs_to": {"file_name": "fixtures.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing/python", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "        DB_INITIALIZED = False\n\n            def setup_module():\n                assert DB_INITIALIZED\n\n            def teardown_module():\n                assert DB_INITIALIZED\n\n            class TestClass(object):\n\n                def setup_method(self, method):\n                    assert DB_INITIALIZED\n\n                def teardown_method(self, method):\n                    assert DB_INITIALIZED\n\n                def test_printer_1(self):\n                    pass\n\n                def test_printer_2(self):\n                    pass\n        \"\"\"\n        )\n        result = pytester.runpytest()\n        result.stdout.fnmatch_lines([\"* 2 passed in *\"])\n\n    def test_parameterized_fixture_caching(self, pytester: Pytester) -> None:\n        \"\"\"Regression test for #12600.\"\"\"\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n            from itertools import count\n\n            CACHE_MISSES = count(0)\n\n            def pytest_generate_tests(metafunc):\n                if \"my_fixture\" in metafunc.fixturenames:\n                    # Use unique objects for parametrization (as opposed to small strings\n                    # and small integers which are singletons).\n                    metafunc.parametrize(\"my_fixture\", [[1], [2]], indirect=True)\n\n            @pytest.fixture(scope='session')\n            def my_fixture(request):\n                next(CACHE_MISSES)\n\n            def test1(my_fixture):\n                pass\n\n            def test2(my_fixture):\n                pass\n\n            def teardown_module():\n                assert next(CACHE_MISSES) == 2\n            \"\"\"\n        )\n        result = pytester.runpytest()\n        result.stdout.no_fnmatch_line(\"* ERROR at teardown *\")\n\n    def test_unwrapping_pytest_fixture(self, pytester: Pytester) -> None:\n        \"\"\"Ensure the unwrap method on `FixtureFunctionDefinition` correctly wraps and unwraps methods and functions\"\"\"\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n            import inspect\n"}, {"start_line": 32000, "end_line": 34000, "belongs_to": {"file_name": "fixtures.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing/python", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "value_dynamic.py\")\n        result = pytester.runpytest()\n        result.stdout.fnmatch_lines([\"*1 passed*\"])\n\n    def test_setupdecorator_and_xunit(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n            values = []\n            @pytest.fixture(scope='module', autouse=True)\n            def setup_module():\n                values.append(\"module\")\n            @pytest.fixture(autouse=True)\n            def setup_function():\n                values.append(\"function\")\n\n            def test_func():\n                pass\n\n            class TestClass(object):\n                @pytest.fixture(scope=\"class\", autouse=True)\n                def setup_class(self):\n                    values.append(\"class\")\n                @pytest.fixture(autouse=True)\n                def setup_method(self):\n                    values.append(\"method\")\n                def test_method(self):\n                    pass\n            def test_all():\n                assert values == [\"module\", \"function\", \"class\",\n                             \"function\", \"method\", \"function\"]\n        \"\"\"\n        )\n        reprec = pytester.inline_run(\"-v\")\n        reprec.assertoutcome(passed=3)\n\n    def test_fixtures_sub_subdir_normalize_sep(self, pytester: Pytester) -> None:\n        # this tests that normalization of nodeids takes place\n        b = pytester.path.joinpath(\"tests\", \"unit\")\n        b.mkdir(parents=True)\n        b.joinpath(\"conftest.py\").write_text(\n            textwrap.dedent(\n                \"\"\"\\\n                import pytest\n                @pytest.fixture\n                def arg1():\n                    pass\n                \"\"\"\n            ),\n            encoding=\"utf-8\",\n        )\n        p = b.joinpath(\"test_module.py\")\n        p.write_text(\"def test_func(arg1): pass\", encoding=\"utf-8\")\n        result = pytester.runpytest(p, \"--fixtures\")\n        assert result.ret == 0\n        result.stdout.fnmatch_lines(\n            \"\"\"\n            *fixtures define"}, {"start_line": 42000, "end_line": 44000, "belongs_to": {"file_name": "fixtures.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing/python", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "stdout.fnmatch_lines([\"*4 passed*\"])\n\n    def test_funcarg_parametrized_and_used_twice(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n            values = []\n            @pytest.fixture(params=[1,2])\n            def arg1(request):\n                values.append(1)\n                return request.param\n\n            @pytest.fixture()\n            def arg2(arg1):\n                return arg1 + 1\n\n            def test_add(arg1, arg2):\n                assert arg2 == arg1 + 1\n                assert len(values) == arg1\n        \"\"\"\n        )\n        result = pytester.runpytest()\n        result.stdout.fnmatch_lines([\"*2 passed*\"])\n\n    def test_factory_uses_unknown_funcarg_as_dependency_error(\n        self, pytester: Pytester\n    ) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n\n            @pytest.fixture()\n            def fail(missing):\n                return\n\n            @pytest.fixture()\n            def call_fail(fail):\n                return\n\n            def test_missing(call_fail):\n                pass\n            \"\"\"\n        )\n        result = pytester.runpytest()\n        result.stdout.fnmatch_lines(\n            \"\"\"\n            *pytest.fixture()*\n            *def call_fail(fail)*\n            *pytest.fixture()*\n            *def fail*\n            *fixture*'missing'*not found*\n        \"\"\"\n        )\n\n    def test_factory_setup_as_classes_fails(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n            class arg1(object):\n                def __init__(self, request):\n                    self.x = 1\n            arg1 = pytest.fixture()(arg1)\n\n        \"\"\"\n        )\n        reprec = pytester.inline_run()\n        values = reprec.getfailedcollections()\n        assert len(values) == 1\n\n    def test_usefixtures_marker(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n\n            val"}, {"start_line": 61000, "end_line": 63000, "belongs_to": {"file_name": "fixtures.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing/python", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "ue)\n                def setup2(self):\n                    self.values.append(1)\n                def test_setup2(self):\n                    assert self.values == [1]\n        \"\"\"\n        )\n        reprec = pytester.inline_run()\n        reprec.assertoutcome(passed=2)\n\n    def test_setup_at_classlevel(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n            class TestClass(object):\n                @pytest.fixture(autouse=True)\n                def permethod(self, request):\n                    request.instance.funcname = request.function.__name__\n                def test_method1(self):\n                    assert self.funcname == \"test_method1\"\n                def test_method2(self):\n                    assert self.funcname == \"test_method2\"\n        \"\"\"\n        )\n        reprec = pytester.inline_run(\"-s\")\n        reprec.assertoutcome(passed=2)\n\n    @pytest.mark.xfail(reason=\"'enabled' feature not implemented\")\n    def test_setup_enabled_functionnode(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n\n            def enabled(parentnode, markers):\n                return \"needsdb\" in markers\n\n            @pytest.fixture(params=[1,2])\n            def db(request):\n                return request.param\n\n            @pytest.fixture(enabled=enabled, autouse=True)\n            def createdb(db):\n                pass\n\n            def test_func1(request):\n                assert \"db\" not in request.fixturenames\n\n            @pytest.mark.needsdb\n            def test_func2(request):\n                assert \"db\" in request.fixturenames\n        \"\"\"\n        )\n        reprec = pytester.inline_run(\"-s\")\n        reprec.assertoutcome(passed=2)\n\n    def test_callables_nocode(self, pytester: Pytester) -> None:\n        \"\"\"An imported mock.call would break setup/factory discovery due to\n        it being callable and __code__ not being a code object.\"\"\"\n        pytester.makepyfile(\n      "}, {"start_line": 33000, "end_line": 35000, "belongs_to": {"file_name": "fixtures.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing/python", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "rt values == [\"module\", \"function\", \"class\",\n                             \"function\", \"method\", \"function\"]\n        \"\"\"\n        )\n        reprec = pytester.inline_run(\"-v\")\n        reprec.assertoutcome(passed=3)\n\n    def test_fixtures_sub_subdir_normalize_sep(self, pytester: Pytester) -> None:\n        # this tests that normalization of nodeids takes place\n        b = pytester.path.joinpath(\"tests\", \"unit\")\n        b.mkdir(parents=True)\n        b.joinpath(\"conftest.py\").write_text(\n            textwrap.dedent(\n                \"\"\"\\\n                import pytest\n                @pytest.fixture\n                def arg1():\n                    pass\n                \"\"\"\n            ),\n            encoding=\"utf-8\",\n        )\n        p = b.joinpath(\"test_module.py\")\n        p.write_text(\"def test_func(arg1): pass\", encoding=\"utf-8\")\n        result = pytester.runpytest(p, \"--fixtures\")\n        assert result.ret == 0\n        result.stdout.fnmatch_lines(\n            \"\"\"\n            *fixtures defined*conftest*\n            *arg1*\n        \"\"\"\n        )\n\n    def test_show_fixtures_color_yes(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\"def test_this(): assert 1\")\n        result = pytester.runpytest(\"--color=yes\", \"--fixtures\")\n        assert \"\\x1b[32mtmp_path\" in result.stdout.str()\n\n    def test_newstyle_with_request(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n            @pytest.fixture()\n            def arg(request):\n                pass\n            def test_1(arg):\n                pass\n        \"\"\"\n        )\n        reprec = pytester.inline_run()\n        reprec.assertoutcome(passed=1)\n\n    def test_setupcontext_no_param(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n            @pytest.fixture(params=[1,2])\n            def arg(request):\n                return request.param\n\n            @pytest.fixture(autouse=True)\n            def mysetup(requ"}, {"start_line": 120000, "end_line": 122000, "belongs_to": {"file_name": "fixtures.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing/python", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "t(\"setup\")\n                yield 1\n                print(\"teardown\")\n            def test_1(arg1):\n                print(\"test1\", arg1)\n            def test_2(arg1):\n                print(\"test2\", arg1)\n                assert 0\n        \"\"\"\n        )\n        result = pytester.runpytest(\"-s\")\n        result.stdout.fnmatch_lines(\n            \"\"\"\n            *setup*\n            *test1 1*\n            *teardown*\n            *setup*\n            *test2 1*\n            *teardown*\n        \"\"\"\n        )\n\n    def test_scoped(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n            @pytest.fixture(scope=\"module\")\n            def arg1():\n                print(\"setup\")\n                yield 1\n                print(\"teardown\")\n            def test_1(arg1):\n                print(\"test1\", arg1)\n            def test_2(arg1):\n                print(\"test2\", arg1)\n        \"\"\"\n        )\n        result = pytester.runpytest(\"-s\")\n        result.stdout.fnmatch_lines(\n            \"\"\"\n            *setup*\n            *test1 1*\n            *test2 1*\n            *teardown*\n        \"\"\"\n        )\n\n    def test_setup_exception(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n            @pytest.fixture(scope=\"module\")\n            def arg1():\n                pytest.fail(\"setup\")\n                yield 1\n            def test_1(arg1):\n                pass\n        \"\"\"\n        )\n        result = pytester.runpytest(\"-s\")\n        result.stdout.fnmatch_lines(\n            \"\"\"\n            *pytest.fail*setup*\n            *1 error*\n        \"\"\"\n        )\n\n    def test_teardown_exception(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n            @pytest.fixture(scope=\"module\")\n            def arg1():\n                yield 1\n                pytest.fail(\"teardown\")\n            def test_1(arg1):\n                pass\n        \"\"\"\n        )\n      "}, {"start_line": 31000, "end_line": 33000, "belongs_to": {"file_name": "fixtures.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing/python", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "sert req.path == modcol.path\n\n    def test_request_fixturenames(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n            from _pytest.pytester import get_public_names\n            @pytest.fixture()\n            def arg1():\n                pass\n            @pytest.fixture()\n            def farg(arg1):\n                pass\n            @pytest.fixture(autouse=True)\n            def sarg(tmp_path):\n                pass\n            def test_function(request, farg):\n                assert set(get_public_names(request.fixturenames)) == \\\n                       set([\"sarg\", \"arg1\", \"request\", \"farg\",\n                            \"tmp_path\", \"tmp_path_factory\"])\n        \"\"\"\n        )\n        reprec = pytester.inline_run()\n        reprec.assertoutcome(passed=1)\n\n    def test_request_fixturenames_dynamic_fixture(self, pytester: Pytester) -> None:\n        \"\"\"Regression test for #3057\"\"\"\n        pytester.copy_example(\"fixtures/test_getfixturevalue_dynamic.py\")\n        result = pytester.runpytest()\n        result.stdout.fnmatch_lines([\"*1 passed*\"])\n\n    def test_setupdecorator_and_xunit(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n            values = []\n            @pytest.fixture(scope='module', autouse=True)\n            def setup_module():\n                values.append(\"module\")\n            @pytest.fixture(autouse=True)\n            def setup_function():\n                values.append(\"function\")\n\n            def test_func():\n                pass\n\n            class TestClass(object):\n                @pytest.fixture(scope=\"class\", autouse=True)\n                def setup_class(self):\n                    values.append(\"class\")\n                @pytest.fixture(autouse=True)\n                def setup_method(self):\n                    values.append(\"method\")\n                def test_method(self):\n                    pass\n            def test_all():\n                asse"}, {"start_line": 1000, "end_line": 3000, "belongs_to": {"file_name": "test_setuponly.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "er.makepyfile(\n        '''\n        import pytest\n        @pytest.fixture\n        def arg_function():\n            \"\"\"function scoped fixture\"\"\"\n        @pytest.fixture(scope='session')\n        def arg_session():\n            \"\"\"session scoped fixture\"\"\"\n        def test_arg1(arg_session, arg_function):\n            pass\n    '''\n    )\n\n    result = pytester.runpytest(mode, p)\n    assert result.ret == 0\n\n    result.stdout.fnmatch_lines(\n        [\n            \"SETUP    S arg_session*\",\n            \"*SETUP    F arg_function*\",\n            \"*test_arg1 (fixtures used: arg_function, arg_session)*\",\n            \"*TEARDOWN F arg_function*\",\n            \"TEARDOWN S arg_session*\",\n        ]\n    )\n\n\ndef test_show_nested_fixtures(pytester: Pytester, mode) -> None:\n    pytester.makeconftest(\n        '''\n        import pytest\n        @pytest.fixture(scope='session')\n        def arg_same():\n            \"\"\"session scoped fixture\"\"\"\n        '''\n    )\n    p = pytester.makepyfile(\n        '''\n        import pytest\n        @pytest.fixture(scope='function')\n        def arg_same(arg_same):\n            \"\"\"function scoped fixture\"\"\"\n        def test_arg1(arg_same):\n            pass\n    '''\n    )\n\n    result = pytester.runpytest(mode, p)\n    assert result.ret == 0\n\n    result.stdout.fnmatch_lines(\n        [\n            \"SETUP    S arg_same*\",\n            \"*SETUP    F arg_same (fixtures used: arg_same)*\",\n            \"*test_arg1 (fixtures used: arg_same)*\",\n            \"*TEARDOWN F arg_same*\",\n            \"TEARDOWN S arg_same*\",\n        ]\n    )\n\n\ndef test_show_fixtures_with_autouse(pytester: Pytester, mode) -> None:\n    p = pytester.makepyfile(\n        '''\n        import pytest\n        @pytest.fixture\n        def arg_function():\n            \"\"\"function scoped fixture\"\"\"\n        @pytest.fixture(scope='session', autouse=True)\n        def arg_session():\n            \"\"\"session scoped fixture\"\"\"\n        def test_arg1(arg_function):\n            pass\n    '''\n    )\n\n    result = pytester.runpytest(mode,"}, {"start_line": 93000, "end_line": 95000, "belongs_to": {"file_name": "fixtures.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing/python", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "request.param\n                request.addfinalizer(lambda: values.append(\"fin:%s\" % param))\n                values.append(\"create:%s\" % param)\n                return request.param\n\n            values = []\n            def test_1(arg):\n                values.append(\"test1\")\n            def test_2(modarg):\n                values.append(\"test2\")\n            def test_3(arg, modarg):\n                values.append(\"test3\")\n            def test_4(modarg, arg):\n                values.append(\"test4\")\n        \"\"\"\n        )\n        reprec = pytester.inline_run(\"-v\")\n        reprec.assertoutcome(passed=12)\n        values = reprec.getcalls(\"pytest_runtest_call\")[0].item.module.values\n        expected = [\n            \"create:1\",\n            \"test1\",\n            \"fin:1\",\n            \"create:2\",\n            \"test1\",\n            \"fin:2\",\n            \"create:mod1\",\n            \"test2\",\n            \"create:1\",\n            \"test3\",\n            \"fin:1\",\n            \"create:2\",\n            \"test3\",\n            \"fin:2\",\n            \"create:1\",\n            \"test4\",\n            \"fin:1\",\n            \"create:2\",\n            \"test4\",\n            \"fin:2\",\n            \"fin:mod1\",\n            \"create:mod2\",\n            \"test2\",\n            \"create:1\",\n            \"test3\",\n            \"fin:1\",\n            \"create:2\",\n            \"test3\",\n            \"fin:2\",\n            \"create:1\",\n            \"test4\",\n            \"fin:1\",\n            \"create:2\",\n            \"test4\",\n            \"fin:2\",\n            \"fin:mod2\",\n        ]\n        import pprint\n\n        pprint.pprint(list(zip(values, expected)))\n        assert values == expected\n\n    def test_parametrized_fixture_teardown_order(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n            @pytest.fixture(params=[1,2], scope=\"class\")\n            def param1(request):\n                return request.param\n\n            values = []\n\n            class TestClass(object):\n                @classmethod\n   "}], "retrieved_count": 10, "cost_time": 1.0733070373535156}
{"question": "What dependencies exist between Pytest's plugin system and the core test runner?", "answer": null, "relative_code_list": null, "ground_truth": "The dependencies between Pytest's plugin system and core test runner create a tightly integrated architecture: 1) Core test runner depends on essential plugins (mark, main, runner, fixtures, helpconfig) that cannot be disabled and provide fundamental functionality, 2) Plugin system is built on pluggy library which provides the hook mechanism that enables all pytest functionality, 3) Core test runner delegates all major operations to plugins through hook calls (pytest_collection, pytest_runtestloop, pytest_runtest_protocol), 4) Configuration system depends on plugins to register command-line options and ini settings through pytest_addoption hook, 5) Test collection is entirely plugin-driven with built-in plugins (python, terminal, debugging) providing the collection logic, 6) Test execution relies on runner plugin to coordinate the three-phase test execution protocol, 7) Fixture system is implemented as a plugin that the core runner depends on for test setup and teardown, 8) Reporting and output formatting are handled by terminal and other reporting plugins, 9) Core runner provides the hook infrastructure but actual functionality comes from plugins, 10) Plugin discovery and loading happens before core runner initialization, establishing the execution environment, 11) Core runner's Config class integrates with PluginManager to coordinate plugin registration and hook invocation, 12) The dependency relationship ensures that the core runner is minimal while plugins provide all the actual testing functionality.", "score": null, "retrieved_content": [{"start_line": 13000, "end_line": 15000, "belongs_to": {"file_name": "test_pluginmanager.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "h_lines([\"*1 passed*\"])\n\n    def test_import_plugin_importname(\n        self, pytester: Pytester, pytestpm: PytestPluginManager\n    ) -> None:\n        pytest.raises(ImportError, pytestpm.import_plugin, \"qweqwex.y\")\n        pytest.raises(ImportError, pytestpm.import_plugin, \"pytest_qweqwx.y\")\n\n        pytester.syspathinsert()\n        pluginname = \"pytest_hello\"\n        pytester.makepyfile(**{pluginname: \"\"})\n        pytestpm.import_plugin(\"pytest_hello\")\n        len1 = len(pytestpm.get_plugins())\n        pytestpm.import_plugin(\"pytest_hello\")\n        len2 = len(pytestpm.get_plugins())\n        assert len1 == len2\n        plugin1 = pytestpm.get_plugin(\"pytest_hello\")\n        assert plugin1 is not None\n        assert plugin1.__name__.endswith(\"pytest_hello\")\n        plugin2 = pytestpm.get_plugin(\"pytest_hello\")\n        assert plugin2 is plugin1\n\n    def test_import_plugin_dotted_name(\n        self, pytester: Pytester, pytestpm: PytestPluginManager\n    ) -> None:\n        pytest.raises(ImportError, pytestpm.import_plugin, \"qweqwex.y\")\n        pytest.raises(ImportError, pytestpm.import_plugin, \"pytest_qweqwex.y\")\n\n        pytester.syspathinsert()\n        pytester.mkpydir(\"pkg\").joinpath(\"plug.py\").write_text(\"x=3\", encoding=\"utf-8\")\n        pluginname = \"pkg.plug\"\n        pytestpm.import_plugin(pluginname)\n        mod = pytestpm.get_plugin(\"pkg.plug\")\n        assert mod is not None\n        assert mod.x == 3\n\n    def test_consider_conftest_deps(\n        self,\n        pytester: Pytester,\n        pytestpm: PytestPluginManager,\n    ) -> None:\n        mod = import_path(\n            pytester.makepyfile(\"pytest_plugins='xyz'\"),\n            root=pytester.path,\n            consider_namespace_packages=False,\n        )\n        with pytest.raises(ImportError):\n            pytestpm.consider_conftest(mod, registration_name=\"unused\")\n\n\nclass TestPytestPluginManagerBootstrapping:\n    def test_preparse_args(self, pytestpm: PytestPluginManager) -> None:\n        pytest.raises(\n            Im"}, {"start_line": 0, "end_line": 2000, "belongs_to": {"file_name": "test_pluginmanager.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "# mypy: allow-untyped-defs\nfrom __future__ import annotations\n\nimport os\nimport shutil\nimport sys\nimport types\n\nfrom _pytest.config import Config\nfrom _pytest.config import ExitCode\nfrom _pytest.config import PytestPluginManager\nfrom _pytest.config.exceptions import UsageError\nfrom _pytest.main import Session\nfrom _pytest.monkeypatch import MonkeyPatch\nfrom _pytest.pathlib import import_path\nfrom _pytest.pytester import Pytester\nimport pytest\n\n\n@pytest.fixture\ndef pytestpm() -> PytestPluginManager:\n    return PytestPluginManager()\n\n\nclass TestPytestPluginInteractions:\n    def test_addhooks_conftestplugin(\n        self, pytester: Pytester, _config_for_test: Config\n    ) -> None:\n        pytester.makepyfile(\n            newhooks=\"\"\"\n            def pytest_myhook(xyz):\n                \"new hook\"\n        \"\"\"\n        )\n        conf = pytester.makeconftest(\n            \"\"\"\n            import newhooks\n            def pytest_addhooks(pluginmanager):\n                pluginmanager.add_hookspecs(newhooks)\n            def pytest_myhook(xyz):\n                return xyz + 1\n        \"\"\"\n        )\n        config = _config_for_test\n        pm = config.pluginmanager\n        pm.hook.pytest_addhooks.call_historic(\n            kwargs=dict(pluginmanager=config.pluginmanager)\n        )\n        config.pluginmanager._importconftest(\n            conf,\n            importmode=\"prepend\",\n            rootpath=pytester.path,\n            consider_namespace_packages=False,\n        )\n        # print(config.pluginmanager.get_plugins())\n        res = config.hook.pytest_myhook(xyz=10)\n        assert res == [11]\n\n    def test_addhooks_nohooks(self, pytester: Pytester) -> None:\n        pytester.makeconftest(\n            \"\"\"\n            import sys\n            def pytest_addhooks(pluginmanager):\n                pluginmanager.add_hookspecs(sys)\n        \"\"\"\n        )\n        res = pytester.runpytest()\n        assert res.ret != 0\n        res.stderr.fnmatch_lines([\"*did not find*sys*\"])\n\n    def test_do_option"}, {"start_line": 14000, "end_line": 16000, "belongs_to": {"file_name": "test_pluginmanager.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "tError, pytestpm.import_plugin, \"qweqwex.y\")\n        pytest.raises(ImportError, pytestpm.import_plugin, \"pytest_qweqwex.y\")\n\n        pytester.syspathinsert()\n        pytester.mkpydir(\"pkg\").joinpath(\"plug.py\").write_text(\"x=3\", encoding=\"utf-8\")\n        pluginname = \"pkg.plug\"\n        pytestpm.import_plugin(pluginname)\n        mod = pytestpm.get_plugin(\"pkg.plug\")\n        assert mod is not None\n        assert mod.x == 3\n\n    def test_consider_conftest_deps(\n        self,\n        pytester: Pytester,\n        pytestpm: PytestPluginManager,\n    ) -> None:\n        mod = import_path(\n            pytester.makepyfile(\"pytest_plugins='xyz'\"),\n            root=pytester.path,\n            consider_namespace_packages=False,\n        )\n        with pytest.raises(ImportError):\n            pytestpm.consider_conftest(mod, registration_name=\"unused\")\n\n\nclass TestPytestPluginManagerBootstrapping:\n    def test_preparse_args(self, pytestpm: PytestPluginManager) -> None:\n        pytest.raises(\n            ImportError, lambda: pytestpm.consider_preparse([\"xyz\", \"-p\", \"hello123\"])\n        )\n\n        # Handles -p without space (#3532).\n        with pytest.raises(ImportError) as excinfo:\n            pytestpm.consider_preparse([\"-phello123\"])\n        assert '\"hello123\"' in excinfo.value.args[0]\n        pytestpm.consider_preparse([\"-pno:hello123\"])\n\n        # Handles -p without following arg (when used without argparse).\n        pytestpm.consider_preparse([\"-p\"])\n\n        with pytest.raises(UsageError, match=\"^plugin main cannot be disabled$\"):\n            pytestpm.consider_preparse([\"-p\", \"no:main\"])\n\n    def test_plugin_prevent_register(self, pytestpm: PytestPluginManager) -> None:\n        pytestpm.consider_preparse([\"xyz\", \"-p\", \"no:abc\"])\n        l1 = pytestpm.get_plugins()\n        pytestpm.register(42, name=\"abc\")\n        l2 = pytestpm.get_plugins()\n        assert len(l2) == len(l1)\n        assert 42 not in l2\n\n    def test_plugin_prevent_register_unregistered_already_registered(\n        s"}, {"start_line": 25000, "end_line": 27000, "belongs_to": {"file_name": "__init__.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest/config", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "od, \"pytest_plugins\")\n            and self._configured\n            and not self._using_pyargs\n        ):\n            msg = (\n                \"Defining 'pytest_plugins' in a non-top-level conftest is no longer supported:\\n\"\n                \"It affects the entire test suite instead of just below the conftest as expected.\\n\"\n                \"  {}\\n\"\n                \"Please move it to a top level conftest file at the rootdir:\\n\"\n                \"  {}\\n\"\n                \"For more information, visit:\\n\"\n                \"  https://docs.pytest.org/en/stable/deprecations.html#pytest-plugins-in-non-top-level-conftest-files\"\n            )\n            fail(msg.format(conftestpath, self._confcutdir), pytrace=False)\n\n    #\n    # API for bootstrapping plugin loading\n    #\n    #\n\n    def consider_preparse(\n        self, args: Sequence[str], *, exclude_only: bool = False\n    ) -> None:\n        \"\"\":meta private:\"\"\"\n        i = 0\n        n = len(args)\n        while i < n:\n            opt = args[i]\n            i += 1\n            if isinstance(opt, str):\n                if opt == \"-p\":\n                    try:\n                        parg = args[i]\n                    except IndexError:\n                        return\n                    i += 1\n                elif opt.startswith(\"-p\"):\n                    parg = opt[2:]\n                else:\n                    continue\n                parg = parg.strip()\n                if exclude_only and not parg.startswith(\"no:\"):\n                    continue\n                self.consider_pluginarg(parg)\n\n    def consider_pluginarg(self, arg: str) -> None:\n        \"\"\":meta private:\"\"\"\n        if arg.startswith(\"no:\"):\n            name = arg[3:]\n            if name in essential_plugins:\n                raise UsageError(f\"plugin {name} cannot be disabled\")\n\n            # PR #4304: remove stepwise if cacheprovider is blocked.\n            if name == \"cacheprovider\":\n                self.set_blocked(\"stepwise\")\n                self.set_blocked(\"pytest_st"}, {"start_line": 39000, "end_line": 41000, "belongs_to": {"file_name": "acceptance_test.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "test()\n    assert r.ret == 0\n\n\ndef test_pytest_plugins_as_module(pytester: Pytester) -> None:\n    \"\"\"Do not raise an error if pytest_plugins attribute is a module (#3899)\"\"\"\n    pytester.makepyfile(\n        **{\n            \"__init__.py\": \"\",\n            \"pytest_plugins.py\": \"\",\n            \"conftest.py\": \"from . import pytest_plugins\",\n            \"test_foo.py\": \"def test(): pass\",\n        }\n    )\n    result = pytester.runpytest()\n    result.stdout.fnmatch_lines([\"* 1 passed in *\"])\n\n\ndef test_deferred_hook_checking(pytester: Pytester) -> None:\n    \"\"\"Check hooks as late as possible (#1821).\"\"\"\n    pytester.syspathinsert()\n    pytester.makepyfile(\n        **{\n            \"plugin.py\": \"\"\"\n        class Hooks(object):\n            def pytest_my_hook(self, config):\n                pass\n\n        def pytest_configure(config):\n            config.pluginmanager.add_hookspecs(Hooks)\n        \"\"\",\n            \"conftest.py\": \"\"\"\n            pytest_plugins = ['plugin']\n            def pytest_my_hook(config):\n                return 40\n        \"\"\",\n            \"test_foo.py\": \"\"\"\n            def test(request):\n                assert request.config.hook.pytest_my_hook(config=request.config) == [40]\n        \"\"\",\n        }\n    )\n    result = pytester.runpytest()\n    result.stdout.fnmatch_lines([\"* 1 passed *\"])\n\n\ndef test_fixture_values_leak(pytester: Pytester) -> None:\n    \"\"\"Ensure that fixture objects are properly destroyed by the garbage collector at the end of their expected\n    life-times (#2981).\n    \"\"\"\n    pytester.makepyfile(\n        \"\"\"\n        import dataclasses\n        import gc\n        import pytest\n        import weakref\n\n        @dataclasses.dataclass\n        class SomeObj:\n            name: str\n\n        fix_of_test1_ref = None\n        session_ref = None\n\n        @pytest.fixture(scope='session')\n        def session_fix():\n            global session_ref\n            obj = SomeObj(name='session-fixture')\n            session_ref = weakref.ref(obj)\n            return obj\n\n  "}, {"start_line": 4000, "end_line": 6000, "belongs_to": {"file_name": "acceptance_test.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "\")\n\n        pytester.makepyfile(mytestplugin1_module=\"\")\n        pytester.makepyfile(mytestplugin2_module=\"\")\n        pytester.makepyfile(mycov_module=\"\")\n        pytester.syspathinsert()\n\n        loaded = []\n\n        @dataclasses.dataclass\n        class DummyEntryPoint:\n            name: str\n            module: str\n            group: str = \"pytest11\"\n\n            def load(self):\n                __import__(self.module)\n                loaded.append(self.name)\n                return sys.modules[self.module]\n\n        entry_points = [\n            DummyEntryPoint(\"myplugin1\", \"mytestplugin1_module\"),\n            DummyEntryPoint(\"myplugin2\", \"mytestplugin2_module\"),\n            DummyEntryPoint(\"mycov\", \"mycov_module\"),\n        ]\n\n        @dataclasses.dataclass\n        class DummyDist:\n            entry_points: object\n            files: object = ()\n\n        def my_dists():\n            return (DummyDist(entry_points),)\n\n        monkeypatch.setattr(importlib.metadata, \"distributions\", my_dists)\n        params = (\"-p\", \"mycov\") if load_cov_early else ()\n        pytester.runpytest_inprocess(*params)\n        if load_cov_early:\n            assert loaded == [\"mycov\", \"myplugin1\", \"myplugin2\"]\n        else:\n            assert loaded == [\"myplugin1\", \"myplugin2\", \"mycov\"]\n\n    @pytest.mark.parametrize(\"import_mode\", [\"prepend\", \"append\", \"importlib\"])\n    def test_assertion_rewrite(self, pytester: Pytester, import_mode) -> None:\n        p = pytester.makepyfile(\n            \"\"\"\n            def test_this():\n                x = 0\n                assert x\n        \"\"\"\n        )\n        result = pytester.runpytest(p, f\"--import-mode={import_mode}\")\n        result.stdout.fnmatch_lines([\">       assert x\", \"E       assert 0\"])\n        assert result.ret == 1\n\n    def test_nested_import_error(self, pytester: Pytester) -> None:\n        p = pytester.makepyfile(\n            \"\"\"\n                import import_fails\n                def test_this():\n                    assert import_fails.a == 1\n "}, {"start_line": 16000, "end_line": 18000, "belongs_to": {"file_name": "__init__.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest/config", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "ict(\n                    plugin=plugin,\n                    plugin_name=plugin_name,\n                    manager=self,\n                )\n            )\n\n            if isinstance(plugin, types.ModuleType):\n                self.consider_module(plugin)\n        return plugin_name\n\n    def getplugin(self, name: str):\n        # Support deprecated naming because plugins (xdist e.g.) use it.\n        plugin: _PluggyPlugin | None = self.get_plugin(name)\n        return plugin\n\n    def hasplugin(self, name: str) -> bool:\n        \"\"\"Return whether a plugin with the given name is registered.\"\"\"\n        return bool(self.get_plugin(name))\n\n    def pytest_configure(self, config: Config) -> None:\n        \"\"\":meta private:\"\"\"\n        # XXX now that the pluginmanager exposes hookimpl(tryfirst...)\n        # we should remove tryfirst/trylast as markers.\n        config.addinivalue_line(\n            \"markers\",\n            \"tryfirst: mark a hook implementation function such that the \"\n            \"plugin machinery will try to call it first/as early as possible. \"\n            \"DEPRECATED, use @pytest.hookimpl(tryfirst=True) instead.\",\n        )\n        config.addinivalue_line(\n            \"markers\",\n            \"trylast: mark a hook implementation function such that the \"\n            \"plugin machinery will try to call it last/as late as possible. \"\n            \"DEPRECATED, use @pytest.hookimpl(trylast=True) instead.\",\n        )\n        self._configured = True\n\n    #\n    # Internal API for local conftest plugin handling.\n    #\n    def _set_initial_conftests(\n        self,\n        args: Sequence[str | pathlib.Path],\n        pyargs: bool,\n        noconftest: bool,\n        rootpath: pathlib.Path,\n        confcutdir: pathlib.Path | None,\n        invocation_dir: pathlib.Path,\n        importmode: ImportMode | str,\n        *,\n        consider_namespace_packages: bool,\n    ) -> None:\n        \"\"\"Load initial conftest files given a preparsed \"namespace\".\n\n        As conftest files may add their own com"}, {"start_line": 3000, "end_line": 5000, "belongs_to": {"file_name": "acceptance_test.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "sult.stderr.fnmatch_lines([\"ERROR: file or directory not found: asd\"])\n        result.stdout.fnmatch_lines([\"*---configure\", \"*---unconfigure\"])\n\n    def test_config_preparse_plugin_option(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            pytest_xyz=\"\"\"\n            def pytest_addoption(parser):\n                parser.addoption(\"--xyz\", dest=\"xyz\", action=\"store\")\n        \"\"\"\n        )\n        pytester.makepyfile(\n            test_one=\"\"\"\n            def test_option(pytestconfig):\n                assert pytestconfig.option.xyz == \"123\"\n        \"\"\"\n        )\n        result = pytester.runpytest(\"-p\", \"pytest_xyz\", \"--xyz=123\", syspathinsert=True)\n        assert result.ret == 0\n        result.stdout.fnmatch_lines([\"*1 passed*\"])\n\n    @pytest.mark.parametrize(\"load_cov_early\", [True, False])\n    def test_early_load_setuptools_name(\n        self, pytester: Pytester, monkeypatch, load_cov_early\n    ) -> None:\n        monkeypatch.delenv(\"PYTEST_DISABLE_PLUGIN_AUTOLOAD\")\n\n        pytester.makepyfile(mytestplugin1_module=\"\")\n        pytester.makepyfile(mytestplugin2_module=\"\")\n        pytester.makepyfile(mycov_module=\"\")\n        pytester.syspathinsert()\n\n        loaded = []\n\n        @dataclasses.dataclass\n        class DummyEntryPoint:\n            name: str\n            module: str\n            group: str = \"pytest11\"\n\n            def load(self):\n                __import__(self.module)\n                loaded.append(self.name)\n                return sys.modules[self.module]\n\n        entry_points = [\n            DummyEntryPoint(\"myplugin1\", \"mytestplugin1_module\"),\n            DummyEntryPoint(\"myplugin2\", \"mytestplugin2_module\"),\n            DummyEntryPoint(\"mycov\", \"mycov_module\"),\n        ]\n\n        @dataclasses.dataclass\n        class DummyDist:\n            entry_points: object\n            files: object = ()\n\n        def my_dists():\n            return (DummyDist(entry_points),)\n\n        monkeypatch.setattr(importlib.metadata, \"distributions\", my_dists"}, {"start_line": 8000, "end_line": 10000, "belongs_to": {"file_name": "test_assertion.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "h: pytest.MonkeyPatch,\n        disable_plugin_autoload: str,\n        explicit_specify: str,\n    ) -> None:\n        args = [\"mainwrapper.py\", \"-s\", f\"--assert={mode}\"]\n        if disable_plugin_autoload == \"env_var\":\n            monkeypatch.setenv(\"PYTEST_DISABLE_PLUGIN_AUTOLOAD\", \"1\")\n        elif disable_plugin_autoload == \"cli\":\n            monkeypatch.delenv(\"PYTEST_DISABLE_PLUGIN_AUTOLOAD\", raising=False)\n            args.append(\"--disable-plugin-autoload\")\n        else:\n            assert disable_plugin_autoload == \"\"\n            monkeypatch.delenv(\"PYTEST_DISABLE_PLUGIN_AUTOLOAD\", raising=False)\n\n        name = \"spamplugin\"\n\n        if explicit_specify == \"env_var\":\n            monkeypatch.setenv(\"PYTEST_PLUGINS\", name)\n        elif explicit_specify == \"cli\":\n            args.append(\"-p\")\n            args.append(name)\n        else:\n            assert explicit_specify == \"\"\n\n        # Make sure the hook is installed early enough so that plugins\n        # installed via distribution package are rewritten.\n        pytester.mkdir(\"hampkg\")\n        contents = {\n            \"hampkg/__init__.py\": \"\"\"\\\n                import pytest\n\n                @pytest.fixture\n                def check_first2():\n                    def check(values, value):\n                        assert values.pop(0) == value\n                    return check\n            \"\"\",\n            \"spamplugin.py\": \"\"\"\\\n            import pytest\n            from hampkg import check_first2\n\n            @pytest.fixture\n            def check_first():\n                def check(values, value):\n                    assert values.pop(0) == value\n                return check\n            \"\"\",\n            \"mainwrapper.py\": \"\"\"\\\n            import importlib.metadata\n            import pytest\n\n            class DummyEntryPoint(object):\n                name = 'spamplugin'\n                module_name = 'spam.py'\n                group = 'pytest11'\n\n                def load(self):\n                    import spamplugin\n       "}, {"start_line": 45000, "end_line": 47000, "belongs_to": {"file_name": "test_config.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "\n\n    has_loaded = config.pluginmanager.get_plugin(\"mytestplugin\") is not None\n    # it should load if it's enabled, or we haven't disabled autoloading\n    assert has_loaded == (bool(enable_plugin_method) or not disable_plugin_method)\n\n    # The reason for the discrepancy between 'has_loaded' and __loader__ being accessed\n    # appears to be the monkeypatching of importlib.metadata.distributions; where\n    # files being empty means that _mark_plugins_for_rewrite doesn't find the plugin.\n    # But enable_method==flag ends up in mark_rewrite being called and __loader__\n    # being accessed.\n    assert (\"__loader__\" in PseudoPlugin.attrs_used) == (\n        has_loaded\n        and not (enable_plugin_method in (\"env_var\", \"\") and not disable_plugin_method)\n    )\n\n    # __spec__ is accessed in AssertionRewritingHook.exec_module, which would be\n    # eventually called if we did a full pytest run; but it's only accessed with\n    # enable_plugin_method==\"env_var\" because that will early-load it.\n    # Except when autoloads aren't disabled, in which case PytestPluginManager.import_plugin\n    # bails out before importing it.. because it knows it'll be loaded later?\n    # The above seems a bit weird, but I *think* it's true.\n    if platform.python_implementation() != \"PyPy\":\n        assert (\"__spec__\" in PseudoPlugin.attrs_used) == bool(\n            enable_plugin_method == \"env_var\" and disable_plugin_method\n        )\n    # __spec__ is present when testing locally on pypy, but not in CI ????\n\n\ndef test_plugin_loading_order(pytester: Pytester) -> None:\n    \"\"\"Test order of plugin loading with `-p`.\"\"\"\n    p1 = pytester.makepyfile(\n        \"\"\"\n        def test_terminal_plugin(request):\n            import myplugin\n            assert myplugin.terminal_plugin == [False, True]\n        \"\"\",\n        myplugin=\"\"\"\n            terminal_plugin = []\n\n            def pytest_configure(config):\n                terminal_plugin.append(bool(config.pluginmanager.get_plugin(\"terminalreporter\")))\n\n  "}], "retrieved_count": 10, "cost_time": 1.0871801376342773}
{"question": "Why does Pytest implement assertion rewriting instead of using Python's built-in assert statements directly?", "answer": null, "relative_code_list": null, "ground_truth": "Pytest implements assertion rewriting instead of using Python's built-in assert statements directly to provide detailed introspection information when assertions fail. The key reasons include: 1) Built-in assert statements only provide basic AssertionError messages without showing intermediate values or detailed context, 2) Assertion rewriting transforms assert statements into detailed if-else blocks that capture and display intermediate values during assertion evaluation, 3) The rewriting process provides rich introspection showing the actual values being compared, function call results, and attribute access details, 4) Without rewriting, users would need to manually add debug prints or use unittest-style assertion methods to get detailed failure information, 5) Assertion rewriting enables the use of idiomatic Python assert statements while maintaining detailed debugging information, 6) The rewriting process caches transformed modules as .pyc files to avoid re-rewriting on subsequent runs, 7) Rewriting allows pytest to integrate with the pytest_assertion_pass hook for custom behavior when assertions pass, 8) The transformation provides better error messages that show the exact values being compared, making debugging much easier, 9) Assertion rewriting works transparently without requiring users to change their coding style or use special assertion libraries, 10) The rewriting process can be selectively disabled for specific modules using PYTEST_DONT_REWRITE in docstrings, 11) Rewriting enables pytest to provide consistent, detailed error reporting across all test scenarios, 12) The approach maintains backward compatibility while significantly improving the debugging experience for test failures.", "score": null, "retrieved_content": [{"start_line": 1000, "end_line": 3000, "belongs_to": {"file_name": "test_assertrewrite.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": " Config\nfrom _pytest.config import ExitCode\nfrom _pytest.pathlib import make_numbered_dir\nfrom _pytest.pytester import Pytester\nimport pytest\n\n\ndef rewrite(src: str) -> ast.Module:\n    tree = ast.parse(src)\n    rewrite_asserts(tree, src.encode())\n    return tree\n\n\ndef getmsg(\n    f, extra_ns: Mapping[str, object] | None = None, *, must_pass: bool = False\n) -> str | None:\n    \"\"\"Rewrite the assertions in f, run it, and get the failure message.\"\"\"\n    src = \"\\n\".join(_pytest._code.Code.from_function(f).source().lines)\n    mod = rewrite(src)\n    code = compile(mod, \"<test>\", \"exec\")\n    ns: dict[str, object] = {}\n    if extra_ns is not None:\n        ns.update(extra_ns)\n    exec(code, ns)\n    func = ns[f.__name__]\n    try:\n        func()  # type: ignore[operator]\n    except AssertionError:\n        if must_pass:\n            pytest.fail(\"shouldn't have raised\")\n        s = str(sys.exc_info()[1])\n        if not s.startswith(\"assert\"):\n            return \"AssertionError: \" + s\n        return s\n    else:\n        if not must_pass:\n            pytest.fail(\"function didn't raise at all\")\n        return None\n\n\nclass TestAssertionRewrite:\n    def test_place_initial_imports(self) -> None:\n        s = \"\"\"'Doc string'\\nother = stuff\"\"\"\n        m = rewrite(s)\n        assert isinstance(m.body[0], ast.Expr)\n        for imp in m.body[1:3]:\n            assert isinstance(imp, ast.Import)\n            assert imp.lineno == 2\n            assert imp.col_offset == 0\n        assert isinstance(m.body[3], ast.Assign)\n        s = \"\"\"from __future__ import division\\nother_stuff\"\"\"\n        m = rewrite(s)\n        assert isinstance(m.body[0], ast.ImportFrom)\n        for imp in m.body[1:3]:\n            assert isinstance(imp, ast.Import)\n            assert imp.lineno == 2\n            assert imp.col_offset == 0\n        assert isinstance(m.body[3], ast.Expr)\n        s = \"\"\"'doc string'\\nfrom __future__ import division\"\"\"\n        m = rewrite(s)\n        assert isinstance(m.body[0], ast.Expr)\n        assert i"}, {"start_line": 21000, "end_line": 23000, "belongs_to": {"file_name": "rewrite.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest/assertion", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "  seen_lines.add(lineno)\n            # a non-nested comma separates the expression from the message\n            elif depth == 0 and tp == tokenize.OP and source == \",\":\n                # one line assert with message\n                if lineno in seen_lines and len(lines) == 1:\n                    offset_in_trimmed = offset + len(lines[-1]) - len(line)\n                    lines[-1] = lines[-1][:offset_in_trimmed]\n                # multi-line assert with message\n                elif lineno in seen_lines:\n                    lines[-1] = lines[-1][:offset]\n                # multi line assert with escaped newline before message\n                else:\n                    lines.append(line[:offset])\n                _write_and_reset()\n            elif tp in {tokenize.NEWLINE, tokenize.ENDMARKER}:\n                _write_and_reset()\n            elif lines and lineno not in seen_lines:\n                lines.append(line)\n                seen_lines.add(lineno)\n\n    return ret\n\n\nclass AssertionRewriter(ast.NodeVisitor):\n    \"\"\"Assertion rewriting implementation.\n\n    The main entrypoint is to call .run() with an ast.Module instance,\n    this will then find all the assert statements and rewrite them to\n    provide intermediate values and a detailed assertion error.  See\n    http://pybites.blogspot.be/2011/07/behind-scenes-of-pytests-new-assertion.html\n    for an overview of how this works.\n\n    The entry point here is .run() which will iterate over all the\n    statements in an ast.Module and for each ast.Assert statement it\n    finds call .visit() with it.  Then .visit_Assert() takes over and\n    is responsible for creating new ast statements to replace the\n    original assert statement: it rewrites the test of an assertion\n    to provide intermediate values and replace it with an if statement\n    which raises an assertion error with a detailed explanation in\n    case the expression is false and calls pytest_assertion_pass hook\n    if expression is true.\n\n    For this .visit_Assert("}, {"start_line": 22000, "end_line": 24000, "belongs_to": {"file_name": "rewrite.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest/assertion", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "r(ast.NodeVisitor):\n    \"\"\"Assertion rewriting implementation.\n\n    The main entrypoint is to call .run() with an ast.Module instance,\n    this will then find all the assert statements and rewrite them to\n    provide intermediate values and a detailed assertion error.  See\n    http://pybites.blogspot.be/2011/07/behind-scenes-of-pytests-new-assertion.html\n    for an overview of how this works.\n\n    The entry point here is .run() which will iterate over all the\n    statements in an ast.Module and for each ast.Assert statement it\n    finds call .visit() with it.  Then .visit_Assert() takes over and\n    is responsible for creating new ast statements to replace the\n    original assert statement: it rewrites the test of an assertion\n    to provide intermediate values and replace it with an if statement\n    which raises an assertion error with a detailed explanation in\n    case the expression is false and calls pytest_assertion_pass hook\n    if expression is true.\n\n    For this .visit_Assert() uses the visitor pattern to visit all the\n    AST nodes of the ast.Assert.test field, each visit call returning\n    an AST node and the corresponding explanation string.  During this\n    state is kept in several instance attributes:\n\n    :statements: All the AST statements which will replace the assert\n       statement.\n\n    :variables: This is populated by .variable() with each variable\n       used by the statements so that they can all be set to None at\n       the end of the statements.\n\n    :variable_counter: Counter to create new unique variables needed\n       by statements.  Variables are created using .variable() and\n       have the form of \"@py_assert0\".\n\n    :expl_stmts: The AST statements which will be executed to get\n       data from the assertion.  This is the code which will construct\n       the detailed assertion message that is used in the AssertionError\n       or for the pytest_assertion_pass hook.\n\n    :explanation_specifiers: A dict filled by .explanation_param()\n   "}, {"start_line": 0, "end_line": 2000, "belongs_to": {"file_name": "test_assertrewrite.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "# mypy: allow-untyped-defs\nfrom __future__ import annotations\n\nimport ast\nfrom collections.abc import Generator\nfrom collections.abc import Mapping\nimport dis\nimport errno\nfrom functools import partial\nimport glob\nimport importlib\nimport inspect\nimport marshal\nimport os\nfrom pathlib import Path\nimport py_compile\nimport re\nimport stat\nimport sys\nimport textwrap\nfrom typing import cast\nfrom unittest import mock\nimport zipfile\n\nimport _pytest._code\nfrom _pytest._io.saferepr import DEFAULT_REPR_MAX_SIZE\nfrom _pytest.assertion import util\nfrom _pytest.assertion.rewrite import _get_assertion_exprs\nfrom _pytest.assertion.rewrite import _get_maxsize_for_saferepr\nfrom _pytest.assertion.rewrite import _saferepr\nfrom _pytest.assertion.rewrite import AssertionRewritingHook\nfrom _pytest.assertion.rewrite import get_cache_dir\nfrom _pytest.assertion.rewrite import PYC_TAIL\nfrom _pytest.assertion.rewrite import PYTEST_TAG\nfrom _pytest.assertion.rewrite import rewrite_asserts\nfrom _pytest.config import Config\nfrom _pytest.config import ExitCode\nfrom _pytest.pathlib import make_numbered_dir\nfrom _pytest.pytester import Pytester\nimport pytest\n\n\ndef rewrite(src: str) -> ast.Module:\n    tree = ast.parse(src)\n    rewrite_asserts(tree, src.encode())\n    return tree\n\n\ndef getmsg(\n    f, extra_ns: Mapping[str, object] | None = None, *, must_pass: bool = False\n) -> str | None:\n    \"\"\"Rewrite the assertions in f, run it, and get the failure message.\"\"\"\n    src = \"\\n\".join(_pytest._code.Code.from_function(f).source().lines)\n    mod = rewrite(src)\n    code = compile(mod, \"<test>\", \"exec\")\n    ns: dict[str, object] = {}\n    if extra_ns is not None:\n        ns.update(extra_ns)\n    exec(code, ns)\n    func = ns[f.__name__]\n    try:\n        func()  # type: ignore[operator]\n    except AssertionError:\n        if must_pass:\n            pytest.fail(\"shouldn't have raised\")\n        s = str(sys.exc_info()[1])\n        if not s.startswith(\"assert\"):\n            return \"AssertionError: \" + s\n        return s"}, {"start_line": 11000, "end_line": 13000, "belongs_to": {"file_name": "test_assertion.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": ":\n            result.assert_outcomes(failed=2)\n            result.stdout.fnmatch_lines([expected, expected])\n        else:\n            result.assert_outcomes(errors=2)\n            result.stdout.fnmatch_lines(\n                [\n                    \"E       fixture 'check_first' not found\",\n                    \"E       fixture 'check_first2' not found\",\n                ]\n            )\n\n    def test_rewrite_ast(self, pytester: Pytester) -> None:\n        pytester.mkdir(\"pkg\")\n        contents = {\n            \"pkg/__init__.py\": \"\"\"\n                import pytest\n                pytest.register_assert_rewrite('pkg.helper')\n            \"\"\",\n            \"pkg/helper.py\": \"\"\"\n                def tool():\n                    a, b = 2, 3\n                    assert a == b\n            \"\"\",\n            \"pkg/plugin.py\": \"\"\"\n                import pytest, pkg.helper\n                @pytest.fixture\n                def tool():\n                    return pkg.helper.tool\n            \"\"\",\n            \"pkg/other.py\": \"\"\"\n                values = [3, 2]\n                def tool():\n                    assert values.pop() == 3\n            \"\"\",\n            \"conftest.py\": \"\"\"\n                pytest_plugins = ['pkg.plugin']\n            \"\"\",\n            \"test_pkg.py\": \"\"\"\n                import pkg.other\n                def test_tool(tool):\n                    tool()\n                def test_other():\n                    pkg.other.tool()\n            \"\"\",\n        }\n        pytester.makepyfile(**contents)\n        result = pytester.runpytest_subprocess(\"--assert=rewrite\")\n        result.stdout.fnmatch_lines(\n            [\n                \">*assert a == b*\",\n                \"E*assert 2 == 3*\",\n                \">*assert values.pop() == 3*\",\n                \"E*AssertionError\",\n            ]\n        )\n\n    def test_register_assert_rewrite_checks_types(self) -> None:\n        with pytest.raises(TypeError):\n            pytest.register_assert_rewrite([\"pytest_tests_internal_non_existing\"])  # type: ignore\n   "}, {"start_line": 9000, "end_line": 11000, "belongs_to": {"file_name": "test_assertrewrite.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "     class T:\n                    def __{name}__(self,other):\n                        loc()\n                        return True\n\n                assert  5 {op} T()\n                assert  (5\n                         {op}\n                         T\n                         ())\n        \"\"\")\n\n        preserved(\"\"\"\n            def func(value):\n                loc(\"func\")\n                return value\n\n            class T:\n                def __iter__(self):\n                    loc(\"iter\")\n                    return iter([5])\n\n            assert  func(*T()) == 5\n        \"\"\")\n\n        preserved(\"\"\"\n            class T:\n                def __getattr__(self,name):\n                    loc()\n                    return name\n\n            assert  T().attr == \"attr\"\n        \"\"\")\n\n    def test_dont_rewrite(self) -> None:\n        s = \"\"\"'PYTEST_DONT_REWRITE'\\nassert 14\"\"\"\n        m = rewrite(s)\n        assert len(m.body) == 2\n        assert isinstance(m.body[1], ast.Assert)\n        assert m.body[1].msg is None\n\n    def test_dont_rewrite_plugin(self, pytester: Pytester) -> None:\n        contents = {\n            \"conftest.py\": \"pytest_plugins = 'plugin'; import plugin\",\n            \"plugin.py\": \"'PYTEST_DONT_REWRITE'\",\n            \"test_foo.py\": \"def test_foo(): pass\",\n        }\n        pytester.makepyfile(**contents)\n        result = pytester.runpytest_subprocess()\n        assert \"warning\" not in \"\".join(result.outlines)\n\n    def test_rewrites_plugin_as_a_package(self, pytester: Pytester) -> None:\n        pkgdir = pytester.mkpydir(\"plugin\")\n        pkgdir.joinpath(\"__init__.py\").write_text(\n            \"import pytest\\n\"\n            \"@pytest.fixture\\n\"\n            \"def special_asserter():\\n\"\n            \"    def special_assert(x, y):\\n\"\n            \"        assert x == y\\n\"\n            \"    return special_assert\\n\",\n            encoding=\"utf-8\",\n        )\n        pytester.makeconftest('pytest_plugins = [\"plugin\"]')\n        pytester.makepyfile(\"def test(special_asserter): special_asser"}, {"start_line": 3000, "end_line": 5000, "belongs_to": {"file_name": "test_assertion.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "st():\n                    def check(values, value):\n                        assert values.pop(0) == value\n                    return check\n            \"\"\",\n            \"foo/tests/test_foo.py\": \"\"\"\n                def test(check_first):\n                    check_first([10, 30], 30)\n            \"\"\",\n        }\n        pytester.makepyfile(**contents)\n        result = pytester.runpytest_subprocess(f\"--assert={mode}\")\n        if mode == \"plain\":\n            expected = \"E       AssertionError\"\n        elif mode == \"rewrite\":\n            expected = \"*assert 10 == 30*\"\n        else:\n            assert 0\n        result.stdout.fnmatch_lines([expected])\n\n    def test_rewrite_assertions_pytester_plugin(self, pytester: Pytester) -> None:\n        \"\"\"\n        Assertions in the pytester plugin must also benefit from assertion\n        rewriting (#1920).\n        \"\"\"\n        pytester.makepyfile(\n            \"\"\"\n            pytest_plugins = ['pytester']\n            def test_dummy_failure(pytester):  # how meta!\n                pytester.makepyfile('def test(): assert 0')\n                r = pytester.inline_run()\n                r.assertoutcome(passed=1)\n        \"\"\"\n        )\n        result = pytester.runpytest_subprocess()\n        result.stdout.fnmatch_lines(\n            [\n                \">       r.assertoutcome(passed=1)\",\n                \"E       AssertionError: ([[][]], [[][]], [[]<TestReport *>[]])*\",\n                \"E       assert {'failed': 1,... 'skipped': 0} == {'failed': 0,... 'skipped': 0}\",\n                \"E         Omitting 1 identical items, use -vv to show\",\n                \"E         Differing items:\",\n                \"E         Use -v to get more diff\",\n            ]\n        )\n        # XXX: unstable output.\n        result.stdout.fnmatch_lines_random(\n            [\n                \"E         {'failed': 1} != {'failed': 0}\",\n                \"E         {'passed': 0} != {'passed': 1}\",\n            ]\n        )\n\n    @pytest.mark.parametrize(\"mode\", [\"plain\", \"rewrite\"])\n   "}, {"start_line": 15000, "end_line": 17000, "belongs_to": {"file_name": "rewrite.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest/assertion", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "tion as e:\n            trace(f\"_read_pyc({source}): marshal.load error {e}\")\n            return None\n        if not isinstance(co, types.CodeType):\n            trace(f\"_read_pyc({source}): not a code object\")\n            return None\n        return co\n\n\ndef rewrite_asserts(\n    mod: ast.Module,\n    source: bytes,\n    module_path: str | None = None,\n    config: Config | None = None,\n) -> None:\n    \"\"\"Rewrite the assert statements in mod.\"\"\"\n    AssertionRewriter(module_path, config, source).run(mod)\n\n\ndef _saferepr(obj: object) -> str:\n    r\"\"\"Get a safe repr of an object for assertion error messages.\n\n    The assertion formatting (util.format_explanation()) requires\n    newlines to be escaped since they are a special character for it.\n    Normally assertion.util.format_explanation() does this but for a\n    custom repr it is possible to contain one of the special escape\n    sequences, especially '\\n{' and '\\n}' are likely to be present in\n    JSON reprs.\n    \"\"\"\n    if isinstance(obj, types.MethodType):\n        # for bound methods, skip redundant <bound method ...> information\n        return obj.__name__\n\n    maxsize = _get_maxsize_for_saferepr(util._config)\n    if not maxsize:\n        return saferepr_unlimited(obj).replace(\"\\n\", \"\\\\n\")\n    return saferepr(obj, maxsize=maxsize).replace(\"\\n\", \"\\\\n\")\n\n\ndef _get_maxsize_for_saferepr(config: Config | None) -> int | None:\n    \"\"\"Get `maxsize` configuration for saferepr based on the given config object.\"\"\"\n    if config is None:\n        verbosity = 0\n    else:\n        verbosity = config.get_verbosity(Config.VERBOSITY_ASSERTIONS)\n    if verbosity >= 2:\n        return None\n    if verbosity >= 1:\n        return DEFAULT_REPR_MAX_SIZE * 10\n    return DEFAULT_REPR_MAX_SIZE\n\n\ndef _format_assertmsg(obj: object) -> str:\n    r\"\"\"Format the custom assertion message given.\n\n    For strings this simply replaces newlines with '\\n~' so that\n    util.format_explanation() will preserve them instead of escaping\n    newlines.  For other objec"}, {"start_line": 0, "end_line": 2000, "belongs_to": {"file_name": "rewrite.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest/assertion", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "\"\"\"Rewrite assertion AST to produce nice error messages.\"\"\"\n\nfrom __future__ import annotations\n\nimport ast\nfrom collections import defaultdict\nfrom collections.abc import Callable\nfrom collections.abc import Iterable\nfrom collections.abc import Iterator\nfrom collections.abc import Sequence\nimport errno\nimport functools\nimport importlib.abc\nimport importlib.machinery\nimport importlib.util\nimport io\nimport itertools\nimport marshal\nimport os\nfrom pathlib import Path\nfrom pathlib import PurePath\nimport struct\nimport sys\nimport tokenize\nimport types\nfrom typing import IO\nfrom typing import TYPE_CHECKING\n\nfrom _pytest._io.saferepr import DEFAULT_REPR_MAX_SIZE\nfrom _pytest._io.saferepr import saferepr\nfrom _pytest._io.saferepr import saferepr_unlimited\nfrom _pytest._version import version\nfrom _pytest.assertion import util\nfrom _pytest.config import Config\nfrom _pytest.fixtures import FixtureFunctionDefinition\nfrom _pytest.main import Session\nfrom _pytest.pathlib import absolutepath\nfrom _pytest.pathlib import fnmatch_ex\nfrom _pytest.stash import StashKey\n\n\n# fmt: off\nfrom _pytest.assertion.util import format_explanation as _format_explanation  # noqa:F401, isort:skip\n# fmt:on\n\nif TYPE_CHECKING:\n    from _pytest.assertion import AssertionState\n\n\nclass Sentinel:\n    pass\n\n\nassertstate_key = StashKey[\"AssertionState\"]()\n\n# pytest caches rewritten pycs in pycache dirs\nPYTEST_TAG = f\"{sys.implementation.cache_tag}-pytest-{version}\"\nPYC_EXT = \".py\" + ((__debug__ and \"c\") or \"o\")\nPYC_TAIL = \".\" + PYTEST_TAG + PYC_EXT\n\n# Special marker that denotes we have just left a scope definition\n_SCOPE_END_MARKER = Sentinel()\n\n\nclass AssertionRewritingHook(importlib.abc.MetaPathFinder, importlib.abc.Loader):\n    \"\"\"PEP302/PEP451 import hook which rewrites asserts.\"\"\"\n\n    def __init__(self, config: Config) -> None:\n        self.config = config\n        try:\n            self.fnpats = config.getini(\"python_files\")\n        except ValueError:\n            self.fnpats = [\"test_*.py\", \"*_test.py\"]"}, {"start_line": 1000, "end_line": 3000, "belongs_to": {"file_name": "rewrite.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest/assertion", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "test.pathlib import fnmatch_ex\nfrom _pytest.stash import StashKey\n\n\n# fmt: off\nfrom _pytest.assertion.util import format_explanation as _format_explanation  # noqa:F401, isort:skip\n# fmt:on\n\nif TYPE_CHECKING:\n    from _pytest.assertion import AssertionState\n\n\nclass Sentinel:\n    pass\n\n\nassertstate_key = StashKey[\"AssertionState\"]()\n\n# pytest caches rewritten pycs in pycache dirs\nPYTEST_TAG = f\"{sys.implementation.cache_tag}-pytest-{version}\"\nPYC_EXT = \".py\" + ((__debug__ and \"c\") or \"o\")\nPYC_TAIL = \".\" + PYTEST_TAG + PYC_EXT\n\n# Special marker that denotes we have just left a scope definition\n_SCOPE_END_MARKER = Sentinel()\n\n\nclass AssertionRewritingHook(importlib.abc.MetaPathFinder, importlib.abc.Loader):\n    \"\"\"PEP302/PEP451 import hook which rewrites asserts.\"\"\"\n\n    def __init__(self, config: Config) -> None:\n        self.config = config\n        try:\n            self.fnpats = config.getini(\"python_files\")\n        except ValueError:\n            self.fnpats = [\"test_*.py\", \"*_test.py\"]\n        self.session: Session | None = None\n        self._rewritten_names: dict[str, Path] = {}\n        self._must_rewrite: set[str] = set()\n        # flag to guard against trying to rewrite a pyc file while we are already writing another pyc file,\n        # which might result in infinite recursion (#3506)\n        self._writing_pyc = False\n        self._basenames_to_check_rewrite = {\"conftest\"}\n        self._marked_for_rewrite_cache: dict[str, bool] = {}\n        self._session_paths_checked = False\n\n    def set_session(self, session: Session | None) -> None:\n        self.session = session\n        self._session_paths_checked = False\n\n    # Indirection so we can mock calls to find_spec originated from the hook during testing\n    _find_spec = importlib.machinery.PathFinder.find_spec\n\n    def find_spec(\n        self,\n        name: str,\n        path: Sequence[str | bytes] | None = None,\n        target: types.ModuleType | None = None,\n    ) -> importlib.machinery.ModuleSpec | None:\n        i"}], "retrieved_count": 10, "cost_time": 1.083369255065918}
{"question": "What is Pytest's approach to handling test isolation?", "answer": null, "relative_code_list": null, "ground_truth": "Pytest's approach to test isolation is based on fixture scoping and automatic cleanup: 1) Fixture scoping system with five levels: function (default), class, module, package, and session - each test gets its own instance based on scope, 2) Automatic fixture execution where each test receives fresh fixture instances to ensure clean state, 3) Fixture dependency injection that creates isolated objects for each test, 4) Teardown/cleanup mechanism using yield statements in fixtures for automatic resource cleanup, 5) Scope hierarchy where higher-scoped fixtures are created before lower-scoped ones, 6) Fixture caching within scope - only one instance per scope is maintained, 7) Automatic grouping of tests by fixture instances to minimize active fixtures, 8) Fixture finalization that ensures proper cleanup even when tests fail, 9) Dependency resolution that ensures fixtures are executed in correct order, 10) Autouse fixtures for automatic setup/teardown without explicit requests, 11) Fixture availability rules that prevent cross-contamination between different test scopes, 12) Deterministic fixture collection and execution order.", "score": null, "retrieved_content": [{"start_line": 20000, "end_line": 22000, "belongs_to": {"file_name": "pytester.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "\n        self.__saved = list(sys.path), list(sys.meta_path)\n\n    def restore(self) -> None:\n        sys.path[:], sys.meta_path[:] = self.__saved\n\n\n@final\nclass Pytester:\n    \"\"\"\n    Facilities to write tests/configuration files, execute pytest in isolation, and match\n    against expected output, perfect for black-box testing of pytest plugins.\n\n    It attempts to isolate the test run from external factors as much as possible, modifying\n    the current working directory to :attr:`path` and environment variables during initialization.\n    \"\"\"\n\n    __test__ = False\n\n    CLOSE_STDIN: Final = NOTSET\n\n    class TimeoutExpired(Exception):\n        pass\n\n    def __init__(\n        self,\n        request: FixtureRequest,\n        tmp_path_factory: TempPathFactory,\n        monkeypatch: MonkeyPatch,\n        *,\n        _ispytest: bool = False,\n    ) -> None:\n        check_ispytest(_ispytest)\n        self._request = request\n        self._mod_collections: WeakKeyDictionary[Collector, list[Item | Collector]] = (\n            WeakKeyDictionary()\n        )\n        if request.function:\n            name: str = request.function.__name__\n        else:\n            name = request.node.name\n        self._name = name\n        self._path: Path = tmp_path_factory.mktemp(name, numbered=True)\n        #: A list of plugins to use with :py:meth:`parseconfig` and\n        #: :py:meth:`runpytest`. Initially this is an empty list but plugins can\n        #: be added to the list.\n        #:\n        #: When running in subprocess mode, specify plugins by name (str) - adding\n        #: plugin objects directly is not supported.\n        self.plugins: list[str | _PluggyPlugin] = []\n        self._sys_path_snapshot = SysPathsSnapshot()\n        self._sys_modules_snapshot = self.__take_sys_modules_snapshot()\n        self._request.addfinalizer(self._finalize)\n        self._method = self._request.config.getoption(\"--runpytest\")\n        self._test_tmproot = tmp_path_factory.mktemp(f\"tmp-{name}\", numbered=True)\n\n        se"}, {"start_line": 7000, "end_line": 9000, "belongs_to": {"file_name": "integration.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing/python", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "\"\"\"\n        )\n        reprec = pytester.inline_run()\n        reprec.assertoutcome(passed=1)\n\n\nclass TestReRunTests:\n    def test_rerun(self, pytester: Pytester) -> None:\n        pytester.makeconftest(\n            \"\"\"\n            from _pytest.runner import runtestprotocol\n            def pytest_runtest_protocol(item, nextitem):\n                runtestprotocol(item, log=False, nextitem=nextitem)\n                runtestprotocol(item, log=True, nextitem=nextitem)\n        \"\"\"\n        )\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n            count = 0\n            req = None\n            @pytest.fixture\n            def fix(request):\n                global count, req\n                assert request != req\n                req = request\n                print(\"fix count %s\" % count)\n                count += 1\n            def test_fix(fix):\n                pass\n        \"\"\"\n        )\n        result = pytester.runpytest(\"-s\")\n        result.stdout.fnmatch_lines(\n            \"\"\"\n            *fix count 0*\n            *fix count 1*\n        \"\"\"\n        )\n        result.stdout.fnmatch_lines(\n            \"\"\"\n            *2 passed*\n        \"\"\"\n        )\n\n\ndef test_pytestconfig_is_session_scoped() -> None:\n    from _pytest.fixtures import pytestconfig\n\n    marker = getfixturemarker(pytestconfig)\n    assert marker is not None\n    assert marker.scope == \"session\"\n\n\nclass TestNoselikeTestAttribute:\n    def test_module_with_global_test(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            __test__ = False\n            def test_hello():\n                pass\n        \"\"\"\n        )\n        reprec = pytester.inline_run()\n        assert not reprec.getfailedcollections()\n        calls = reprec.getreports(\"pytest_runtest_logreport\")\n        assert not calls\n\n    def test_class_and_method(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            __test__ = True\n            def test_func():\n                "}, {"start_line": 30000, "end_line": 32000, "belongs_to": {"file_name": "test_assertrewrite.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "tr(init)!r}}}\n                \"\"\",\n            }\n        )\n        example.mkdir()\n\n        assert pytester.runpytest(\"-vv\").ret == ExitCode.OK\n\n    def test_readonly(self, pytester: Pytester) -> None:\n        sub = pytester.mkdir(\"testing\")\n        sub.joinpath(\"test_readonly.py\").write_bytes(\n            b\"\"\"\ndef test_rewritten():\n    assert \"@py_builtins\" in globals()\n            \"\"\",\n        )\n        old_mode = sub.stat().st_mode\n        sub.chmod(320)\n        try:\n            assert pytester.runpytest().ret == 0\n        finally:\n            sub.chmod(old_mode)\n\n    def test_dont_write_bytecode(self, pytester: Pytester, monkeypatch) -> None:\n        monkeypatch.delenv(\"PYTHONPYCACHEPREFIX\", raising=False)\n\n        pytester.makepyfile(\n            \"\"\"\n            import os\n            def test_no_bytecode():\n                assert \"__pycache__\" in __cached__\n                assert not os.path.exists(__cached__)\n                assert not os.path.exists(os.path.dirname(__cached__))\"\"\"\n        )\n        monkeypatch.setenv(\"PYTHONDONTWRITEBYTECODE\", \"1\")\n        assert pytester.runpytest_subprocess().ret == 0\n\n    def test_orphaned_pyc_file(self, pytester: Pytester, monkeypatch) -> None:\n        monkeypatch.delenv(\"PYTHONPYCACHEPREFIX\", raising=False)\n        monkeypatch.setattr(sys, \"pycache_prefix\", None, raising=False)\n\n        pytester.makepyfile(\n            \"\"\"\n            import orphan\n            def test_it():\n                assert orphan.value == 17\n            \"\"\"\n        )\n        pytester.makepyfile(\n            orphan=\"\"\"\n            value = 17\n            \"\"\"\n        )\n        py_compile.compile(\"orphan.py\")\n        os.remove(\"orphan.py\")\n\n        # Python 3 puts the .pyc files in a __pycache__ directory, and will\n        # not import from there without source.  It will import a .pyc from\n        # the source location though.\n        if not os.path.exists(\"orphan.pyc\"):\n            pycs = glob.glob(\"__pycache__/orphan.*.pyc\")\n            assert len("}, {"start_line": 10000, "end_line": 12000, "belongs_to": {"file_name": "test_assertrewrite.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": " is None\n\n    def test_dont_rewrite_plugin(self, pytester: Pytester) -> None:\n        contents = {\n            \"conftest.py\": \"pytest_plugins = 'plugin'; import plugin\",\n            \"plugin.py\": \"'PYTEST_DONT_REWRITE'\",\n            \"test_foo.py\": \"def test_foo(): pass\",\n        }\n        pytester.makepyfile(**contents)\n        result = pytester.runpytest_subprocess()\n        assert \"warning\" not in \"\".join(result.outlines)\n\n    def test_rewrites_plugin_as_a_package(self, pytester: Pytester) -> None:\n        pkgdir = pytester.mkpydir(\"plugin\")\n        pkgdir.joinpath(\"__init__.py\").write_text(\n            \"import pytest\\n\"\n            \"@pytest.fixture\\n\"\n            \"def special_asserter():\\n\"\n            \"    def special_assert(x, y):\\n\"\n            \"        assert x == y\\n\"\n            \"    return special_assert\\n\",\n            encoding=\"utf-8\",\n        )\n        pytester.makeconftest('pytest_plugins = [\"plugin\"]')\n        pytester.makepyfile(\"def test(special_asserter): special_asserter(1, 2)\\n\")\n        result = pytester.runpytest()\n        result.stdout.fnmatch_lines([\"*assert 1 == 2*\"])\n\n    def test_honors_pep_235(self, pytester: Pytester, monkeypatch) -> None:\n        # note: couldn't make it fail on macos with a single `sys.path` entry\n        # note: these modules are named `test_*` to trigger rewriting\n        pytester.makepyfile(test_y=\"x = 1\")\n        xdir = pytester.mkdir(\"x\")\n        pytester.mkpydir(str(xdir.joinpath(\"test_Y\")))\n        xdir.joinpath(\"test_Y\").joinpath(\"__init__.py\").write_text(\n            \"x = 2\", encoding=\"utf-8\"\n        )\n        pytester.makepyfile(\n            \"import test_y\\n\"\n            \"import test_Y\\n\"\n            \"def test():\\n\"\n            \"    assert test_y.x == 1\\n\"\n            \"    assert test_Y.x == 2\\n\"\n        )\n        monkeypatch.syspath_prepend(str(xdir))\n        pytester.runpytest().assert_outcomes(passed=1)\n\n    def test_name(self, request) -> None:\n        def f1() -> None:\n            assert False\n\n        as"}, {"start_line": 8000, "end_line": 10000, "belongs_to": {"file_name": "integration.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing/python", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "\"\"\"\n            *fix count 0*\n            *fix count 1*\n        \"\"\"\n        )\n        result.stdout.fnmatch_lines(\n            \"\"\"\n            *2 passed*\n        \"\"\"\n        )\n\n\ndef test_pytestconfig_is_session_scoped() -> None:\n    from _pytest.fixtures import pytestconfig\n\n    marker = getfixturemarker(pytestconfig)\n    assert marker is not None\n    assert marker.scope == \"session\"\n\n\nclass TestNoselikeTestAttribute:\n    def test_module_with_global_test(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            __test__ = False\n            def test_hello():\n                pass\n        \"\"\"\n        )\n        reprec = pytester.inline_run()\n        assert not reprec.getfailedcollections()\n        calls = reprec.getreports(\"pytest_runtest_logreport\")\n        assert not calls\n\n    def test_class_and_method(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            __test__ = True\n            def test_func():\n                pass\n            test_func.__test__ = False\n\n            class TestSome(object):\n                __test__ = False\n                def test_method(self):\n                    pass\n        \"\"\"\n        )\n        reprec = pytester.inline_run()\n        assert not reprec.getfailedcollections()\n        calls = reprec.getreports(\"pytest_runtest_logreport\")\n        assert not calls\n\n    def test_unittest_class(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            import unittest\n            class TC(unittest.TestCase):\n                def test_1(self):\n                    pass\n            class TC2(unittest.TestCase):\n                __test__ = False\n                def test_2(self):\n                    pass\n        \"\"\"\n        )\n        reprec = pytester.inline_run()\n        assert not reprec.getfailedcollections()\n        call = reprec.getcalls(\"pytest_collection_modifyitems\")[0]\n        assert len(call.items) == 1\n        assert call.items[0].cls.__name__"}, {"start_line": 15000, "end_line": 17000, "belongs_to": {"file_name": "pytester.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "during initialization.\n\n    It is particularly useful for testing plugins. It is similar to the :fixture:`tmp_path`\n    fixture but provides methods which aid in testing pytest itself.\n    \"\"\"\n    return Pytester(request, tmp_path_factory, monkeypatch, _ispytest=True)\n\n\n@fixture\ndef _sys_snapshot() -> Generator[None]:\n    snappaths = SysPathsSnapshot()\n    snapmods = SysModulesSnapshot()\n    yield\n    snapmods.restore()\n    snappaths.restore()\n\n\n@fixture\ndef _config_for_test() -> Generator[Config]:\n    from _pytest.config import get_config\n\n    config = get_config()\n    yield config\n    config._ensure_unconfigure()  # cleanup, e.g. capman closing tmpfiles.\n\n\n# Regex to match the session duration string in the summary: \"74.34s\".\nrex_session_duration = re.compile(r\"\\d+\\.\\d\\ds\")\n# Regex to match all the counts and phrases in the summary line: \"34 passed, 111 skipped\".\nrex_outcome = re.compile(r\"(\\d+) (\\w+)\")\n\n\n@final\nclass RunResult:\n    \"\"\"The result of running a command from :class:`~pytest.Pytester`.\"\"\"\n\n    def __init__(\n        self,\n        ret: int | ExitCode,\n        outlines: list[str],\n        errlines: list[str],\n        duration: float,\n    ) -> None:\n        try:\n            self.ret: int | ExitCode = ExitCode(ret)\n            \"\"\"The return value.\"\"\"\n        except ValueError:\n            self.ret = ret\n        self.outlines = outlines\n        \"\"\"List of lines captured from stdout.\"\"\"\n        self.errlines = errlines\n        \"\"\"List of lines captured from stderr.\"\"\"\n        self.stdout = LineMatcher(outlines)\n        \"\"\":class:`~pytest.LineMatcher` of stdout.\n\n        Use e.g. :func:`str(stdout) <pytest.LineMatcher.__str__()>` to reconstruct stdout, or the commonly used\n        :func:`stdout.fnmatch_lines() <pytest.LineMatcher.fnmatch_lines()>` method.\n        \"\"\"\n        self.stderr = LineMatcher(errlines)\n        \"\"\":class:`~pytest.LineMatcher` of stderr.\"\"\"\n        self.duration = duration\n        \"\"\"Duration in seconds.\"\"\"\n\n    def __repr__(self) -> st"}, {"start_line": 32000, "end_line": 34000, "belongs_to": {"file_name": "test_assertrewrite.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "pycs) == 1\n            os.rename(pycs[0], \"orphan.pyc\")\n\n        assert pytester.runpytest().ret == 0\n\n    def test_cached_pyc_includes_pytest_version(\n        self, pytester: Pytester, monkeypatch\n    ) -> None:\n        \"\"\"Avoid stale caches (#1671)\"\"\"\n        monkeypatch.delenv(\"PYTHONDONTWRITEBYTECODE\", raising=False)\n        monkeypatch.delenv(\"PYTHONPYCACHEPREFIX\", raising=False)\n        pytester.makepyfile(\n            test_foo=\"\"\"\n            def test_foo():\n                assert True\n            \"\"\"\n        )\n        result = pytester.runpytest_subprocess()\n        assert result.ret == 0\n        found_names = glob.glob(f\"__pycache__/*-pytest-{pytest.__version__}.pyc\")\n        assert found_names, \"pyc with expected tag not found in names: {}\".format(\n            glob.glob(\"__pycache__/*.pyc\")\n        )\n\n    @pytest.mark.skipif('\"__pypy__\" in sys.modules')\n    def test_pyc_vs_pyo(\n        self,\n        pytester: Pytester,\n        monkeypatch: pytest.MonkeyPatch,\n    ) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n            def test_optimized():\n                \"hello\"\n                assert test_optimized.__doc__ is None\"\"\"\n        )\n        p = make_numbered_dir(root=Path(pytester.path), prefix=\"runpytest-\")\n        tmp = f\"--basetemp={p}\"\n        with monkeypatch.context() as mp:\n            mp.setenv(\"PYTHONOPTIMIZE\", \"2\")\n            mp.delenv(\"PYTHONDONTWRITEBYTECODE\", raising=False)\n            mp.delenv(\"PYTHONPYCACHEPREFIX\", raising=False)\n            assert pytester.runpytest_subprocess(tmp).ret == 0\n            tagged = \"test_pyc_vs_pyo.\" + PYTEST_TAG\n            assert tagged + \".pyo\" in os.listdir(\"__pycache__\")\n        monkeypatch.delenv(\"PYTHONDONTWRITEBYTECODE\", raising=False)\n        monkeypatch.delenv(\"PYTHONPYCACHEPREFIX\", raising=False)\n        assert pytester.runpytest_subprocess(tmp).ret == 1\n        assert tagged + \".pyc\" in os.listdir(\"__pycache__\")\n\n    def test_package(self, pytester: Pytester) -> N"}, {"start_line": 33000, "end_line": 35000, "belongs_to": {"file_name": "test_assertrewrite.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "       pytester.makepyfile(\n            \"\"\"\n            import pytest\n            def test_optimized():\n                \"hello\"\n                assert test_optimized.__doc__ is None\"\"\"\n        )\n        p = make_numbered_dir(root=Path(pytester.path), prefix=\"runpytest-\")\n        tmp = f\"--basetemp={p}\"\n        with monkeypatch.context() as mp:\n            mp.setenv(\"PYTHONOPTIMIZE\", \"2\")\n            mp.delenv(\"PYTHONDONTWRITEBYTECODE\", raising=False)\n            mp.delenv(\"PYTHONPYCACHEPREFIX\", raising=False)\n            assert pytester.runpytest_subprocess(tmp).ret == 0\n            tagged = \"test_pyc_vs_pyo.\" + PYTEST_TAG\n            assert tagged + \".pyo\" in os.listdir(\"__pycache__\")\n        monkeypatch.delenv(\"PYTHONDONTWRITEBYTECODE\", raising=False)\n        monkeypatch.delenv(\"PYTHONPYCACHEPREFIX\", raising=False)\n        assert pytester.runpytest_subprocess(tmp).ret == 1\n        assert tagged + \".pyc\" in os.listdir(\"__pycache__\")\n\n    def test_package(self, pytester: Pytester) -> None:\n        pkg = pytester.path.joinpath(\"pkg\")\n        pkg.mkdir()\n        pkg.joinpath(\"__init__.py\")\n        pkg.joinpath(\"test_blah.py\").write_text(\n            \"\"\"\ndef test_rewritten():\n    assert \"@py_builtins\" in globals()\"\"\",\n            encoding=\"utf-8\",\n        )\n        assert pytester.runpytest().ret == 0\n\n    def test_translate_newlines(self, pytester: Pytester) -> None:\n        content = \"def test_rewritten():\\r\\n assert '@py_builtins' in globals()\"\n        b = content.encode(\"utf-8\")\n        pytester.path.joinpath(\"test_newlines.py\").write_bytes(b)\n        assert pytester.runpytest().ret == 0\n\n    def test_package_without__init__py(self, pytester: Pytester) -> None:\n        pkg = pytester.mkdir(\"a_package_without_init_py\")\n        pkg.joinpath(\"module.py\").touch()\n        pytester.makepyfile(\"import a_package_without_init_py.module\")\n        assert pytester.runpytest().ret == ExitCode.NO_TESTS_COLLECTED\n\n    def test_rewrite_warning(self, pytester: Pytester) -> None:\n  "}, {"start_line": 106000, "end_line": 108000, "belongs_to": {"file_name": "fixtures.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing/python", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": " hash(B) or True\n            \"\"\"\n        )\n        monkeypatch.setenv(\"PYTHONHASHSEED\", \"1\")\n        out1 = pytester.runpytest_subprocess(\"-v\")\n        monkeypatch.setenv(\"PYTHONHASHSEED\", \"2\")\n        out2 = pytester.runpytest_subprocess(\"-v\")\n        output1 = [\n            line\n            for line in out1.outlines\n            if line.startswith(\"test_deterministic_fixture_collection.py::test_foo\")\n        ]\n        output2 = [\n            line\n            for line in out2.outlines\n            if line.startswith(\"test_deterministic_fixture_collection.py::test_foo\")\n        ]\n        assert len(output1) == 12\n        assert output1 == output2\n\n\nclass TestRequestScopeAccess:\n    pytestmark = pytest.mark.parametrize(\n        (\"scope\", \"ok\", \"error\"),\n        [\n            [\"session\", \"\", \"path class function module\"],\n            [\"module\", \"module path\", \"cls function\"],\n            [\"class\", \"module path cls\", \"function\"],\n            [\"function\", \"module path cls function\", \"\"],\n        ],\n    )\n\n    def test_setup(self, pytester: Pytester, scope, ok, error) -> None:\n        pytester.makepyfile(\n            f\"\"\"\n            import pytest\n            @pytest.fixture(scope={scope!r}, autouse=True)\n            def myscoped(request):\n                for x in {ok.split()}:\n                    assert hasattr(request, x)\n                for x in {error.split()}:\n                    pytest.raises(AttributeError, lambda:\n                        getattr(request, x))\n                assert request.session\n                assert request.config\n            def test_func():\n                pass\n        \"\"\"\n        )\n        reprec = pytester.inline_run(\"-l\")\n        reprec.assertoutcome(passed=1)\n\n    def test_funcarg(self, pytester: Pytester, scope, ok, error) -> None:\n        pytester.makepyfile(\n            f\"\"\"\n            import pytest\n            @pytest.fixture(scope={scope!r})\n            def arg(request):\n                for x in {ok.split()!r}:\n                    as"}, {"start_line": 1000, "end_line": 3000, "belongs_to": {"file_name": "test_conftest.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "\"prepend\",\n        consider_namespace_packages=False,\n    )\n\n\n@pytest.mark.usefixtures(\"_sys_snapshot\")\nclass TestConftestValueAccessGlobal:\n    @pytest.fixture(scope=\"module\", params=[\"global\", \"inpackage\"])\n    def basedir(self, request, tmp_path_factory: TempPathFactory) -> Generator[Path]:\n        tmp_path = tmp_path_factory.mktemp(\"basedir\", numbered=True)\n        tmp_path.joinpath(\"adir/b\").mkdir(parents=True)\n        tmp_path.joinpath(\"adir/conftest.py\").write_text(\n            \"a=1 ; Directory = 3\", encoding=\"utf-8\"\n        )\n        tmp_path.joinpath(\"adir/b/conftest.py\").write_text(\n            \"b=2 ; a = 1.5\", encoding=\"utf-8\"\n        )\n        if request.param == \"inpackage\":\n            tmp_path.joinpath(\"adir/__init__.py\").touch()\n            tmp_path.joinpath(\"adir/b/__init__.py\").touch()\n\n        yield tmp_path\n\n    def test_basic_init(self, basedir: Path) -> None:\n        conftest = PytestPluginManager()\n        p = basedir / \"adir\"\n        conftest._loadconftestmodules(\n            p, importmode=\"prepend\", rootpath=basedir, consider_namespace_packages=False\n        )\n        assert conftest._rget_with_confmod(\"a\", p)[1] == 1\n\n    def test_immediate_initialization_and_incremental_are_the_same(\n        self, basedir: Path\n    ) -> None:\n        conftest = PytestPluginManager()\n        assert not len(conftest._dirpath2confmods)\n        conftest._loadconftestmodules(\n            basedir,\n            importmode=\"prepend\",\n            rootpath=basedir,\n            consider_namespace_packages=False,\n        )\n        snap1 = len(conftest._dirpath2confmods)\n        assert snap1 == 1\n        conftest._loadconftestmodules(\n            basedir / \"adir\",\n            importmode=\"prepend\",\n            rootpath=basedir,\n            consider_namespace_packages=False,\n        )\n        assert len(conftest._dirpath2confmods) == snap1 + 1\n        conftest._loadconftestmodules(\n            basedir / \"b\",\n            importmode=\"prepend\",\n            rootpath=basedir,\n"}], "retrieved_count": 10, "cost_time": 1.1096982955932617}
{"question": "Why does Pytest implement a collector-based test discovery system instead of simple file scanning?", "answer": null, "relative_code_list": null, "ground_truth": "Pytest implements a collector-based test discovery system instead of simple file scanning for several key architectural and functional reasons: 1) Collector-based system provides a hierarchical structure (Session -> Directory -> Package -> Module -> Class -> Function) that mirrors the actual test organization, 2) Each collector type (Session, Dir, Package, Module, Class) can implement custom collection logic through the collect() method, 3) The collector hierarchy enables sophisticated filtering and customization at each level through hooks like pytest_ignore_collect and pytest_collect_directory, 4) Collector-based system supports complex test discovery scenarios like custom directory collectors that can read manifest files or implement custom logic, 5) The hierarchical structure allows for proper scope management where higher-level collectors can influence lower-level ones, 6) Collector system enables plugin extensibility where plugins can provide custom collectors for specific file types or directory structures, 7) The collector hierarchy supports proper test organization where tests can be grouped by package, module, or class structure, 8) Collector-based system provides better error handling and reporting at each level of the discovery process, 9) The system enables incremental collection where only changed parts of the test tree need to be re-collected, 10) Collector hierarchy supports proper fixture scoping where fixtures can be defined at different levels (session, package, module, class), 11) The collector system enables sophisticated test filtering and deselection at multiple levels, 12) Collector-based approach provides better integration with pytest's plugin architecture and hook system for extensible test discovery.", "score": null, "retrieved_content": [{"start_line": 16000, "end_line": 18000, "belongs_to": {"file_name": "test_collection.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "ignore_glob[:] = []\n        \"\"\"\n        )\n        pytester.makepyfile(test_world=\"def test_hello(): pass\")\n        pytester.makepyfile(test_welt=\"def test_hallo(): pass\")\n        result = pytester.runpytest()\n        assert result.ret == ExitCode.NO_TESTS_COLLECTED\n        result.stdout.fnmatch_lines([\"*collected 0 items*\"])\n        result = pytester.runpytest(\"--XX\")\n        assert result.ret == 0\n        result.stdout.fnmatch_lines([\"*2 passed*\"])\n\n    def test_pytest_fs_collect_hooks_are_seen(self, pytester: Pytester) -> None:\n        pytester.makeconftest(\n            \"\"\"\n            import pytest\n            class MyModule(pytest.Module):\n                pass\n            def pytest_collect_file(file_path, parent):\n                if file_path.suffix == \".py\":\n                    return MyModule.from_parent(path=file_path, parent=parent)\n        \"\"\"\n        )\n        pytester.mkdir(\"sub\")\n        pytester.makepyfile(\"def test_x(): pass\")\n        result = pytester.runpytest(\"--co\")\n        result.stdout.fnmatch_lines([\"*MyModule*\", \"*test_x*\"])\n\n    def test_pytest_collect_file_from_sister_dir(self, pytester: Pytester) -> None:\n        sub1 = pytester.mkpydir(\"sub1\")\n        sub2 = pytester.mkpydir(\"sub2\")\n        conf1 = pytester.makeconftest(\n            \"\"\"\n            import pytest\n            class MyModule1(pytest.Module):\n                pass\n            def pytest_collect_file(file_path, parent):\n                if file_path.suffix == \".py\":\n                    return MyModule1.from_parent(path=file_path, parent=parent)\n        \"\"\"\n        )\n        conf1.replace(sub1.joinpath(conf1.name))\n        conf2 = pytester.makeconftest(\n            \"\"\"\n            import pytest\n            class MyModule2(pytest.Module):\n                pass\n            def pytest_collect_file(file_path, parent):\n                if file_path.suffix == \".py\":\n                    return MyModule2.from_parent(path=file_path, parent=parent)\n        \"\"\"\n        )\n        conf2.replace("}, {"start_line": 50000, "end_line": 52000, "belongs_to": {"file_name": "collect.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing/python", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "None:\n    \"\"\"\n    .\n     root\n         Test_root.py\n         __init__.py\n         sub1\n            Test_sub1.py\n            __init__.py\n         sub2\n             test\n                 test_sub2.py\n\n    \"\"\"\n    pytester.makeini(\n        \"\"\"\n        [pytest]\n        python_files=*.py\n    \"\"\"\n    )\n    root = pytester.mkpydir(\"root\")\n    sub1 = root.joinpath(\"sub1\")\n    sub1.mkdir()\n    sub1.joinpath(\"__init__.py\").touch()\n    sub2 = root.joinpath(\"sub2\")\n    sub2_test = sub2.joinpath(\"test\")\n    sub2_test.mkdir(parents=True)\n\n    root.joinpath(\"Test_root.py\").write_text(\"def test_1(): pass\", encoding=\"utf-8\")\n    sub1.joinpath(\"Test_sub1.py\").write_text(\"def test_2(): pass\", encoding=\"utf-8\")\n    sub2_test.joinpath(\"test_sub2.py\").write_text(\n        \"def test_3(): pass\", encoding=\"utf-8\"\n    )\n\n    # Execute from .\n    result = pytester.runpytest(\"-v\", \"-s\")\n    result.assert_outcomes(passed=3)\n\n\ndef test_collection_hierarchy(pytester: Pytester) -> None:\n    \"\"\"A general test checking that a filesystem hierarchy is collected as\n    expected in various scenarios.\n\n    top/\n     aaa\n        pkg\n           __init__.py\n           test_pkg.py\n        test_aaa.py\n     test_a.py\n     test_b\n        __init__.py\n        test_b.py\n     test_c.py\n     zzz\n         dir\n            test_dir.py\n         __init__.py\n         test_zzz.py\n    \"\"\"\n    pytester.makepyfile(\n        **{\n            \"top/aaa/test_aaa.py\": \"def test_it(): pass\",\n            \"top/aaa/pkg/__init__.py\": \"\",\n            \"top/aaa/pkg/test_pkg.py\": \"def test_it(): pass\",\n            \"top/test_a.py\": \"def test_it(): pass\",\n            \"top/test_b/__init__.py\": \"\",\n            \"top/test_b/test_b.py\": \"def test_it(): pass\",\n            \"top/test_c.py\": \"def test_it(): pass\",\n            \"top/zzz/__init__.py\": \"\",\n            \"top/zzz/test_zzz.py\": \"def test_it(): pass\",\n            \"top/zzz/dir/test_dir.py\": \"def test_it(): pass\",\n "}, {"start_line": 16000, "end_line": 18000, "belongs_to": {"file_name": "main.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "m_parent(parent=parent, path=path)\n\n    def collect(self) -> Iterable[nodes.Item | nodes.Collector]:\n        config = self.config\n        col: nodes.Collector | None\n        cols: Sequence[nodes.Collector]\n        ihook = self.ihook\n        for direntry in scandir(self.path):\n            if direntry.is_dir():\n                path = Path(direntry.path)\n                if not self.session.isinitpath(path, with_parents=True):\n                    if ihook.pytest_ignore_collect(collection_path=path, config=config):\n                        continue\n                col = ihook.pytest_collect_directory(path=path, parent=self)\n                if col is not None:\n                    yield col\n\n            elif direntry.is_file():\n                path = Path(direntry.path)\n                if not self.session.isinitpath(path):\n                    if ihook.pytest_ignore_collect(collection_path=path, config=config):\n                        continue\n                cols = ihook.pytest_collect_file(file_path=path, parent=self)\n                yield from cols\n\n\n@final\nclass Session(nodes.Collector):\n    \"\"\"The root of the collection tree.\n\n    ``Session`` collects the initial paths given as arguments to pytest.\n    \"\"\"\n\n    Interrupted = Interrupted\n    Failed = Failed\n    # Set on the session by runner.pytest_sessionstart.\n    _setupstate: SetupState\n    # Set on the session by fixtures.pytest_sessionstart.\n    _fixturemanager: FixtureManager\n    exitstatus: int | ExitCode\n\n    def __init__(self, config: Config) -> None:\n        super().__init__(\n            name=\"\",\n            path=config.rootpath,\n            fspath=None,\n            parent=None,\n            config=config,\n            session=self,\n            nodeid=\"\",\n        )\n        self.testsfailed = 0\n        self.testscollected = 0\n        self._shouldstop: bool | str = False\n        self._shouldfail: bool | str = False\n        self.trace = config.trace.root.get(\"collection\")\n        self._initialpaths: frozenset[Path] "}, {"start_line": 6000, "end_line": 8000, "belongs_to": {"file_name": "python.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "f pytest_collect_directory(\n    path: Path, parent: nodes.Collector\n) -> nodes.Collector | None:\n    pkginit = path / \"__init__.py\"\n    try:\n        has_pkginit = pkginit.is_file()\n    except PermissionError:\n        # See https://github.com/pytest-dev/pytest/issues/12120#issuecomment-2106349096.\n        return None\n    if has_pkginit:\n        return Package.from_parent(parent, path=path)\n    return None\n\n\ndef pytest_collect_file(file_path: Path, parent: nodes.Collector) -> Module | None:\n    if file_path.suffix == \".py\":\n        if not parent.session.isinitpath(file_path):\n            if not path_matches_patterns(\n                file_path, parent.config.getini(\"python_files\")\n            ):\n                return None\n        ihook = parent.session.gethookproxy(file_path)\n        module: Module = ihook.pytest_pycollect_makemodule(\n            module_path=file_path, parent=parent\n        )\n        return module\n    return None\n\n\ndef path_matches_patterns(path: Path, patterns: Iterable[str]) -> bool:\n    \"\"\"Return whether path matches any of the patterns in the list of globs given.\"\"\"\n    return any(fnmatch_ex(pattern, path) for pattern in patterns)\n\n\ndef pytest_pycollect_makemodule(module_path: Path, parent) -> Module:\n    return Module.from_parent(parent, path=module_path)\n\n\n@hookimpl(trylast=True)\ndef pytest_pycollect_makeitem(\n    collector: Module | Class, name: str, obj: object\n) -> None | nodes.Item | nodes.Collector | list[nodes.Item | nodes.Collector]:\n    assert isinstance(collector, (Class, Module)), type(collector)\n    # Nothing was collected elsewhere, let's do it here.\n    if safe_isclass(obj):\n        if collector.istestclass(obj, name):\n            return Class.from_parent(collector, name=name, obj=obj)\n    elif collector.istestfunction(obj, name):\n        # mock seems to store unbound methods (issue473), normalize it.\n        obj = getattr(obj, \"__func__\", obj)\n        # We need to try and unwrap the function if it's a functools.partial\n        # or"}, {"start_line": 9000, "end_line": 11000, "belongs_to": {"file_name": "test_collection.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "stpaths` directories\n        # are collected\n        items, reprec = pytester.inline_genitems(\"-v\")\n        assert [x.name for x in items] == [\"test_b\", \"test_c\"]\n\n        # check that explicitly passing directories in the command-line\n        # collects the tests\n        for dirname in (\"a\", \"b\", \"c\"):\n            items, reprec = pytester.inline_genitems(tmp_path.joinpath(dirname))\n            assert [x.name for x in items] == [f\"test_{dirname}\"]\n\n        # changing cwd to each subdirectory and running pytest without\n        # arguments collects the tests in that directory normally\n        for dirname in (\"a\", \"b\", \"c\"):\n            monkeypatch.chdir(pytester.path.joinpath(dirname))\n            items, reprec = pytester.inline_genitems()\n            assert [x.name for x in items] == [f\"test_{dirname}\"]\n\n    def test_missing_permissions_on_unselected_directory_doesnt_crash(\n        self, pytester: Pytester\n    ) -> None:\n        \"\"\"Regression test for #12120.\"\"\"\n        test = pytester.makepyfile(test=\"def test(): pass\")\n        bad = pytester.mkdir(\"bad\")\n        try:\n            bad.chmod(0)\n\n            result = pytester.runpytest(test)\n        finally:\n            bad.chmod(750)\n            bad.rmdir()\n\n        assert result.ret == ExitCode.OK\n        result.assert_outcomes(passed=1)\n\n\nclass TestCollectPluginHookRelay:\n    def test_pytest_collect_file(self, pytester: Pytester) -> None:\n        wascalled = []\n\n        class Plugin:\n            def pytest_collect_file(self, file_path: Path) -> None:\n                if not file_path.name.startswith(\".\"):\n                    # Ignore hidden files, e.g. .testmondata.\n                    wascalled.append(file_path)\n\n        pytester.makefile(\".abc\", \"xyz\")\n        pytest.main(pytester.path, plugins=[Plugin()])\n        assert len(wascalled) == 1\n        assert wascalled[0].suffix == \".abc\"\n\n\nclass TestPrunetraceback:\n    def test_custom_repr_failure(self, pytester: Pytester) -> None:\n        p = pytester.makepyfile(\n   "}, {"start_line": 0, "end_line": 1071, "belongs_to": {"file_name": "conftest.py", "upper_path": "/data2/raymone/swebench-repos/pytest/doc/en/example/customdirectory", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "# content of conftest.py\nfrom __future__ import annotations\n\nimport json\n\nimport pytest\n\n\nclass ManifestDirectory(pytest.Directory):\n    def collect(self):\n        # The standard pytest behavior is to loop over all `test_*.py` files and\n        # call `pytest_collect_file` on each file. This collector instead reads\n        # the `manifest.json` file and only calls `pytest_collect_file` for the\n        # files defined there.\n        manifest_path = self.path / \"manifest.json\"\n        manifest = json.loads(manifest_path.read_text(encoding=\"utf-8\"))\n        ihook = self.ihook\n        for file in manifest[\"files\"]:\n            yield from ihook.pytest_collect_file(\n                file_path=self.path / file, parent=self\n            )\n\n\n@pytest.hookimpl\ndef pytest_collect_directory(path, parent):\n    # Use our custom collector for directories containing a `manifest.json` file.\n    if path.joinpath(\"manifest.json\").is_file():\n        return ManifestDirectory.from_parent(parent=parent, path=path)\n    # Otherwise fallback to the standard behavior.\n    return None\n"}, {"start_line": 17000, "end_line": 19000, "belongs_to": {"file_name": "test_collection.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "        result.stdout.fnmatch_lines([\"*MyModule*\", \"*test_x*\"])\n\n    def test_pytest_collect_file_from_sister_dir(self, pytester: Pytester) -> None:\n        sub1 = pytester.mkpydir(\"sub1\")\n        sub2 = pytester.mkpydir(\"sub2\")\n        conf1 = pytester.makeconftest(\n            \"\"\"\n            import pytest\n            class MyModule1(pytest.Module):\n                pass\n            def pytest_collect_file(file_path, parent):\n                if file_path.suffix == \".py\":\n                    return MyModule1.from_parent(path=file_path, parent=parent)\n        \"\"\"\n        )\n        conf1.replace(sub1.joinpath(conf1.name))\n        conf2 = pytester.makeconftest(\n            \"\"\"\n            import pytest\n            class MyModule2(pytest.Module):\n                pass\n            def pytest_collect_file(file_path, parent):\n                if file_path.suffix == \".py\":\n                    return MyModule2.from_parent(path=file_path, parent=parent)\n        \"\"\"\n        )\n        conf2.replace(sub2.joinpath(conf2.name))\n        p = pytester.makepyfile(\"def test_x(): pass\")\n        shutil.copy(p, sub1.joinpath(p.name))\n        shutil.copy(p, sub2.joinpath(p.name))\n        result = pytester.runpytest(\"--co\")\n        result.stdout.fnmatch_lines([\"*MyModule1*\", \"*MyModule2*\", \"*test_x*\"])\n\n\nclass TestSession:\n    def test_collect_topdir(self, pytester: Pytester) -> None:\n        p = pytester.makepyfile(\"def test_func(): pass\")\n        id = \"::\".join([p.name, \"test_func\"])\n        # XXX migrate to collectonly? (see below)\n        config = pytester.parseconfig(id)\n        topdir = pytester.path\n        rcol = Session.from_config(config)\n        assert topdir == rcol.path\n        # rootid = rcol.nodeid\n        # root2 = rcol.perform_collect([rcol.nodeid], genitems=False)[0]\n        # assert root2 == rcol, rootid\n        colitems = rcol.perform_collect([rcol.nodeid], genitems=False)\n        assert len(colitems) == 1\n        assert colitems[0].path == topdir\n\n    def get_reported_ite"}, {"start_line": 47000, "end_line": 49000, "belongs_to": {"file_name": "collect.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing/python", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "icate directories.\n    \"\"\"\n    a = pytester.mkdir(\"a\")\n    fh = a.joinpath(\"test_a.py\")\n    fh.write_text(\n        textwrap.dedent(\n            \"\"\"\\\n            import pytest\n            def test_real():\n                pass\n            \"\"\"\n        ),\n        encoding=\"utf-8\",\n    )\n    result = pytester.runpytest(str(a), str(a))\n    result.stdout.fnmatch_lines([\"*collected 1 item*\"])\n\n\ndef test_keep_duplicates(pytester: Pytester) -> None:\n    \"\"\"Test for issue https://github.com/pytest-dev/pytest/issues/1609 (#1609)\n\n    Use --keep-duplicates to collect tests from duplicate directories.\n    \"\"\"\n    a = pytester.mkdir(\"a\")\n    fh = a.joinpath(\"test_a.py\")\n    fh.write_text(\n        textwrap.dedent(\n            \"\"\"\\\n            import pytest\n            def test_real():\n                pass\n            \"\"\"\n        ),\n        encoding=\"utf-8\",\n    )\n    result = pytester.runpytest(\"--keep-duplicates\", str(a), str(a))\n    result.stdout.fnmatch_lines([\"*collected 2 item*\"])\n\n\ndef test_package_collection_infinite_recursion(pytester: Pytester) -> None:\n    pytester.copy_example(\"collect/package_infinite_recursion\")\n    result = pytester.runpytest()\n    result.stdout.fnmatch_lines([\"*1 passed*\"])\n\n\ndef test_package_collection_init_given_as_argument(pytester: Pytester) -> None:\n    \"\"\"Regression test for #3749, #8976, #9263, #9313.\n\n    Specifying an __init__.py file directly should collect only the __init__.py\n    Module, not the entire package.\n    \"\"\"\n    p = pytester.copy_example(\"collect/package_init_given_as_arg\")\n    items, hookrecorder = pytester.inline_genitems(p / \"pkg\" / \"__init__.py\")\n    assert len(items) == 1\n    assert items[0].name == \"test_init\"\n\n\ndef test_package_with_modules(pytester: Pytester) -> None:\n    \"\"\"\n    .\n     root\n         __init__.py\n         sub1\n            __init__.py\n            sub1_1\n                __init__.py\n                test_in_sub1.py\n         sub2\n             test\n                 test_in_sub"}, {"start_line": 51000, "end_line": 53000, "belongs_to": {"file_name": "collect.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing/python", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "  \"\"\"A general test checking that a filesystem hierarchy is collected as\n    expected in various scenarios.\n\n    top/\n     aaa\n        pkg\n           __init__.py\n           test_pkg.py\n        test_aaa.py\n     test_a.py\n     test_b\n        __init__.py\n        test_b.py\n     test_c.py\n     zzz\n         dir\n            test_dir.py\n         __init__.py\n         test_zzz.py\n    \"\"\"\n    pytester.makepyfile(\n        **{\n            \"top/aaa/test_aaa.py\": \"def test_it(): pass\",\n            \"top/aaa/pkg/__init__.py\": \"\",\n            \"top/aaa/pkg/test_pkg.py\": \"def test_it(): pass\",\n            \"top/test_a.py\": \"def test_it(): pass\",\n            \"top/test_b/__init__.py\": \"\",\n            \"top/test_b/test_b.py\": \"def test_it(): pass\",\n            \"top/test_c.py\": \"def test_it(): pass\",\n            \"top/zzz/__init__.py\": \"\",\n            \"top/zzz/test_zzz.py\": \"def test_it(): pass\",\n            \"top/zzz/dir/test_dir.py\": \"def test_it(): pass\",\n        }\n    )\n\n    full = [\n        \"<Dir test_collection_hierarchy*>\",\n        \"  <Dir top>\",\n        \"    <Dir aaa>\",\n        \"      <Package pkg>\",\n        \"        <Module test_pkg.py>\",\n        \"          <Function test_it>\",\n        \"      <Module test_aaa.py>\",\n        \"        <Function test_it>\",\n        \"    <Module test_a.py>\",\n        \"      <Function test_it>\",\n        \"    <Package test_b>\",\n        \"      <Module test_b.py>\",\n        \"        <Function test_it>\",\n        \"    <Module test_c.py>\",\n        \"      <Function test_it>\",\n        \"    <Package zzz>\",\n        \"      <Dir dir>\",\n        \"        <Module test_dir.py>\",\n        \"          <Function test_it>\",\n        \"      <Module test_zzz.py>\",\n        \"        <Function test_it>\",\n    ]\n    result = pytester.runpytest(\"--collect-only\")\n    result.stdout.fnmatch_lines(full, consecutive=True)\n    result = pytester.runpytest(\"top\", \"--collect-only\")\n    result.stdout.fnmatch_lines(full, consecutive=True)\n    resul"}, {"start_line": 25000, "end_line": 27000, "belongs_to": {"file_name": "python.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "          parent=parent,\n            config=config,\n            session=session,\n            nodeid=nodeid,\n        )\n\n    def setup(self) -> None:\n        init_mod = importtestmodule(self.path / \"__init__.py\", self.config)\n\n        # Not using fixtures to call setup_module here because autouse fixtures\n        # from packages are not called automatically (#4085).\n        setup_module = _get_first_non_fixture_func(\n            init_mod, (\"setUpModule\", \"setup_module\")\n        )\n        if setup_module is not None:\n            _call_with_optional_argument(setup_module, init_mod)\n\n        teardown_module = _get_first_non_fixture_func(\n            init_mod, (\"tearDownModule\", \"teardown_module\")\n        )\n        if teardown_module is not None:\n            func = partial(_call_with_optional_argument, teardown_module, init_mod)\n            self.addfinalizer(func)\n\n    def collect(self) -> Iterable[nodes.Item | nodes.Collector]:\n        # Always collect __init__.py first.\n        def sort_key(entry: os.DirEntry[str]) -> object:\n            return (entry.name != \"__init__.py\", entry.name)\n\n        config = self.config\n        col: nodes.Collector | None\n        cols: Sequence[nodes.Collector]\n        ihook = self.ihook\n        for direntry in scandir(self.path, sort_key):\n            if direntry.is_dir():\n                path = Path(direntry.path)\n                if not self.session.isinitpath(path, with_parents=True):\n                    if ihook.pytest_ignore_collect(collection_path=path, config=config):\n                        continue\n                col = ihook.pytest_collect_directory(path=path, parent=self)\n                if col is not None:\n                    yield col\n\n            elif direntry.is_file():\n                path = Path(direntry.path)\n                if not self.session.isinitpath(path):\n                    if ihook.pytest_ignore_collect(collection_path=path, config=config):\n                        continue\n                cols = ihook.pytest_collec"}], "retrieved_count": 10, "cost_time": 1.1043038368225098}
{"question": "Why does Pytest implement parallel test execution for performance optimization?", "answer": null, "relative_code_list": null, "ground_truth": "Pytest implements parallel test execution for performance optimization to address the need for faster test execution in large test suites: 1) Parallel execution allows multiple tests to run simultaneously, reducing total test execution time by utilizing multiple CPU cores and processes, 2) Large test suites can take significant time to complete sequentially, making parallel execution essential for maintaining fast feedback cycles in development workflows, 3) Modern hardware with multiple CPU cores provides the capability to run tests in parallel, and pytest leverages this through plugins like pytest-xdist, 4) Parallel execution is particularly beneficial for I/O-bound tests that spend time waiting for external resources, allowing CPU-bound tests to run concurrently, 5) CI/CD pipelines benefit from faster test execution, reducing build times and improving developer productivity, 6) Parallel execution helps distribute the computational load across multiple processes, preventing single-process bottlenecks, 7) Test isolation is maintained through process-based parallelism rather than threading, avoiding issues with shared state and GIL limitations, 8) Parallel execution can be configured to match available system resources, optimizing performance for different environments, 9) Large test suites with thousands of tests can see dramatic performance improvements when executed in parallel, 10) Parallel execution supports different distribution strategies (load balancing, round-robin) to optimize resource utilization, 11) The pytest-xdist plugin provides sophisticated parallel execution capabilities including worker management and result collection, 12) Parallel execution enables better resource utilization in cloud and containerized environments where multiple cores are available.", "score": null, "retrieved_content": [{"start_line": 33000, "end_line": 35000, "belongs_to": {"file_name": "collect.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing/python", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "   This tests a performance optimization, not correctness, really,\n        although it tests PytestCollectionWarning is not raised, while\n        it would have been raised otherwise.\n        \"\"\"\n        pytester.makeini(\n            \"\"\"\n            [pytest]\n            python_classes=*\n            python_functions=*\n        \"\"\"\n        )\n        pytester.makepyfile(\n            \"\"\"\n            class TestEmpty:\n                pass\n            test_empty = TestEmpty()\n            def test_real():\n                pass\n        \"\"\"\n        )\n        items, rec = pytester.inline_genitems()\n        assert rec.ret == 0\n        assert len(items) == 1\n\n\ndef test_setup_only_available_in_subdir(pytester: Pytester) -> None:\n    sub1 = pytester.mkpydir(\"sub1\")\n    sub2 = pytester.mkpydir(\"sub2\")\n    sub1.joinpath(\"conftest.py\").write_text(\n        textwrap.dedent(\n            \"\"\"\\\n            import pytest\n            def pytest_runtest_setup(item):\n                assert item.path.stem == \"test_in_sub1\"\n            def pytest_runtest_call(item):\n                assert item.path.stem == \"test_in_sub1\"\n            def pytest_runtest_teardown(item):\n                assert item.path.stem == \"test_in_sub1\"\n            \"\"\"\n        ),\n        encoding=\"utf-8\",\n    )\n    sub2.joinpath(\"conftest.py\").write_text(\n        textwrap.dedent(\n            \"\"\"\\\n            import pytest\n            def pytest_runtest_setup(item):\n                assert item.path.stem == \"test_in_sub2\"\n            def pytest_runtest_call(item):\n                assert item.path.stem == \"test_in_sub2\"\n            def pytest_runtest_teardown(item):\n                assert item.path.stem == \"test_in_sub2\"\n            \"\"\"\n        ),\n        encoding=\"utf-8\",\n    )\n    sub1.joinpath(\"test_in_sub1.py\").write_text(\"def test_1(): pass\", encoding=\"utf-8\")\n    sub2.joinpath(\"test_in_sub2.py\").write_text(\"def test_2(): pass\", encoding=\"utf-8\")\n    result = pytester.runpytest(\"-v\", \"-s\")\n    result.assert_outcomes(passed=2)\n\n"}, {"start_line": 76000, "end_line": 78000, "belongs_to": {"file_name": "test_terminal.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "y::test_foobar\\[4\\] PASSED \\s+ \\[20/20\\]\",\n            ]\n        )\n\n    def test_verbose_times(self, many_tests_files, pytester: Pytester) -> None:\n        pytester.makeini(\n            \"\"\"\n            [pytest]\n            console_output_style = times\n        \"\"\"\n        )\n        output = pytester.runpytest(\"-v\")\n        output.stdout.re_match_lines(\n            [\n                r\"test_bar.py::test_bar\\[0\\] PASSED \\s+ \\d{1,3}[\\.[a-z\\ ]{1,2}\\d{0,3}\\w{1,2}$\",\n                r\"test_foo.py::test_foo\\[4\\] PASSED \\s+ \\d{1,3}[\\.[a-z\\ ]{1,2}\\d{0,3}\\w{1,2}$\",\n                r\"test_foobar.py::test_foobar\\[4\\] PASSED \\s+ \\d{1,3}[\\.[a-z\\ ]{1,2}\\d{0,3}\\w{1,2}$\",\n            ]\n        )\n\n    def test_xdist_normal(\n        self, many_tests_files, pytester: Pytester, monkeypatch\n    ) -> None:\n        pytest.importorskip(\"xdist\")\n        monkeypatch.delenv(\"PYTEST_DISABLE_PLUGIN_AUTOLOAD\", raising=False)\n        output = pytester.runpytest(\"-n2\")\n        output.stdout.re_match_lines([r\"\\.{20} \\s+ \\[100%\\]\"])\n\n    def test_xdist_normal_count(\n        self, many_tests_files, pytester: Pytester, monkeypatch\n    ) -> None:\n        pytest.importorskip(\"xdist\")\n        monkeypatch.delenv(\"PYTEST_DISABLE_PLUGIN_AUTOLOAD\", raising=False)\n        pytester.makeini(\n            \"\"\"\n            [pytest]\n            console_output_style = count\n        \"\"\"\n        )\n        output = pytester.runpytest(\"-n2\")\n        output.stdout.re_match_lines([r\"\\.{20} \\s+ \\[20/20\\]\"])\n\n    def test_xdist_verbose(\n        self, many_tests_files, pytester: Pytester, monkeypatch\n    ) -> None:\n        pytest.importorskip(\"xdist\")\n        monkeypatch.delenv(\"PYTEST_DISABLE_PLUGIN_AUTOLOAD\", raising=False)\n        output = pytester.runpytest(\"-n2\", \"-v\")\n        output.stdout.re_match_lines_random(\n            [\n                r\"\\[gw\\d\\] \\[\\s*\\d+%\\] PASSED test_bar.py::test_bar\\[1\\]\",\n                r\"\\[gw\\d\\] \\[\\s*\\d+%\\] PASSED test_foo.py::test_foo\\[1\\]\",\n                r\"\\[gw\\d\\] \\[\\s*\\d+%\\] PASSED test"}, {"start_line": 77000, "end_line": 79000, "belongs_to": {"file_name": "test_terminal.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "\\[100%\\]\"])\n\n    def test_xdist_normal_count(\n        self, many_tests_files, pytester: Pytester, monkeypatch\n    ) -> None:\n        pytest.importorskip(\"xdist\")\n        monkeypatch.delenv(\"PYTEST_DISABLE_PLUGIN_AUTOLOAD\", raising=False)\n        pytester.makeini(\n            \"\"\"\n            [pytest]\n            console_output_style = count\n        \"\"\"\n        )\n        output = pytester.runpytest(\"-n2\")\n        output.stdout.re_match_lines([r\"\\.{20} \\s+ \\[20/20\\]\"])\n\n    def test_xdist_verbose(\n        self, many_tests_files, pytester: Pytester, monkeypatch\n    ) -> None:\n        pytest.importorskip(\"xdist\")\n        monkeypatch.delenv(\"PYTEST_DISABLE_PLUGIN_AUTOLOAD\", raising=False)\n        output = pytester.runpytest(\"-n2\", \"-v\")\n        output.stdout.re_match_lines_random(\n            [\n                r\"\\[gw\\d\\] \\[\\s*\\d+%\\] PASSED test_bar.py::test_bar\\[1\\]\",\n                r\"\\[gw\\d\\] \\[\\s*\\d+%\\] PASSED test_foo.py::test_foo\\[1\\]\",\n                r\"\\[gw\\d\\] \\[\\s*\\d+%\\] PASSED test_foobar.py::test_foobar\\[1\\]\",\n            ]\n        )\n        output.stdout.fnmatch_lines_random(\n            [\n                line.translate(TRANS_FNMATCH)\n                for line in [\n                    \"test_bar.py::test_bar[0] \",\n                    \"test_foo.py::test_foo[0] \",\n                    \"test_foobar.py::test_foobar[0] \",\n                    \"[gw?] [  5%] PASSED test_*[?] \",\n                    \"[gw?] [ 10%] PASSED test_*[?] \",\n                    \"[gw?] [ 55%] PASSED test_*[?] \",\n                    \"[gw?] [ 60%] PASSED test_*[?] \",\n                    \"[gw?] [ 95%] PASSED test_*[?] \",\n                    \"[gw?] [100%] PASSED test_*[?] \",\n                ]\n            ]\n        )\n\n    def test_xdist_times(\n        self, many_tests_files, pytester: Pytester, monkeypatch\n    ) -> None:\n        pytest.importorskip(\"xdist\")\n        monkeypatch.delenv(\"PYTEST_DISABLE_PLUGIN_AUTOLOAD\", raising=False)\n        pytester.makeini(\n            \"\"\"\n            [pytest]\n          "}, {"start_line": 82000, "end_line": 84000, "belongs_to": {"file_name": "test_terminal.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "ytest(\"-rfE\")\n        output.stdout.re_match_lines(\n            [\n                r\"test_teardown_with_test_also_failing.py FE\\s+\\[100%\\]\",\n                \"FAILED test_teardown_with_test_also_failing.py::test_foo - assert 0\",\n                \"ERROR test_teardown_with_test_also_failing.py::test_foo - assert False\",\n            ]\n        )\n\n    def test_teardown_many(self, pytester: Pytester, many_files) -> None:\n        output = pytester.runpytest()\n        output.stdout.re_match_lines(\n            [r\"test_bar.py (\\.E){5}\\s+\\[ 25%\\]\", r\"test_foo.py (\\.E){15}\\s+\\[100%\\]\"]\n        )\n\n    def test_teardown_many_verbose(\n        self, pytester: Pytester, many_files, color_mapping\n    ) -> None:\n        result = pytester.runpytest(\"-v\")\n        result.stdout.fnmatch_lines(\n            color_mapping.format_for_fnmatch(\n                [\n                    \"test_bar.py::test_bar[0] PASSED  * [  5%]\",\n                    \"test_bar.py::test_bar[0] ERROR   * [  5%]\",\n                    \"test_bar.py::test_bar[4] PASSED  * [ 25%]\",\n                    \"test_foo.py::test_foo[14] PASSED * [100%]\",\n                    \"test_foo.py::test_foo[14] ERROR  * [100%]\",\n                    \"=* 20 passed, 20 errors in *\",\n                ]\n            )\n        )\n\n    def test_xdist_normal(self, many_files, pytester: Pytester, monkeypatch) -> None:\n        pytest.importorskip(\"xdist\")\n        monkeypatch.delenv(\"PYTEST_DISABLE_PLUGIN_AUTOLOAD\", raising=False)\n        output = pytester.runpytest(\"-n2\")\n        output.stdout.re_match_lines([r\"[\\.E]{40} \\s+ \\[100%\\]\"])\n\n\ndef test_skip_reasons_folding() -> None:\n    path = \"xyz\"\n    lineno = 3\n    message = \"justso\"\n    longrepr = (path, lineno, message)\n\n    class X:\n        pass\n\n    ev1 = cast(CollectReport, X())\n    ev1.when = \"execute\"\n    ev1.skipped = True  # type: ignore[misc]\n    ev1.longrepr = longrepr\n\n    ev2 = cast(CollectReport, X())\n    ev2.when = \"execute\"\n    ev2.longrepr = longrepr\n    ev2.skipped = True  # type: ignore[mis"}, {"start_line": 0, "end_line": 2000, "belongs_to": {"file_name": "conftest.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "# mypy: allow-untyped-defs\nfrom __future__ import annotations\n\nfrom collections.abc import Generator\nimport importlib.metadata\nimport re\nimport sys\n\nfrom packaging.version import Version\n\nfrom _pytest.monkeypatch import MonkeyPatch\nfrom _pytest.pytester import Pytester\nimport pytest\n\n\nif sys.gettrace():\n\n    @pytest.fixture(autouse=True)\n    def restore_tracing():\n        \"\"\"Restore tracing function (when run with Coverage.py).\n\n        https://bugs.python.org/issue37011\n        \"\"\"\n        orig_trace = sys.gettrace()\n        yield\n        if sys.gettrace() != orig_trace:\n            sys.settrace(orig_trace)\n\n\n@pytest.fixture(autouse=True)\ndef set_column_width(monkeypatch: pytest.MonkeyPatch) -> None:\n    \"\"\"\n    Force terminal width to 80: some tests check the formatting of --help, which is sensible\n    to terminal width.\n    \"\"\"\n    monkeypatch.setenv(\"COLUMNS\", \"80\")\n\n\n@pytest.fixture(autouse=True)\ndef reset_colors(monkeypatch: pytest.MonkeyPatch) -> None:\n    \"\"\"\n    Reset all color-related variables to prevent them from affecting internal pytest output\n    in tests that depend on it.\n    \"\"\"\n    monkeypatch.delenv(\"PY_COLORS\", raising=False)\n    monkeypatch.delenv(\"NO_COLOR\", raising=False)\n    monkeypatch.delenv(\"FORCE_COLOR\", raising=False)\n\n\n@pytest.hookimpl(wrapper=True, tryfirst=True)\ndef pytest_collection_modifyitems(items) -> Generator[None]:\n    \"\"\"Prefer faster tests.\n\n    Use a hook wrapper to do this in the beginning, so e.g. --ff still works\n    correctly.\n    \"\"\"\n    fast_items = []\n    slow_items = []\n    slowest_items = []\n    neutral_items = []\n\n    spawn_names = {\"spawn_pytest\", \"spawn\"}\n\n    for item in items:\n        try:\n            fixtures = item.fixturenames\n        except AttributeError:\n            # doctest at least\n            # (https://github.com/pytest-dev/pytest/issues/5070)\n            neutral_items.append(item)\n        else:\n            if \"pytester\" in fixtures:\n                co_names = item.function.__code__.co_names\n       "}, {"start_line": 33000, "end_line": 35000, "belongs_to": {"file_name": "acceptance_test.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "r.runpytest(testid, \"-rf\", \"--tb=short\")\n        result.stdout.fnmatch_lines(expected_lines)\n\n    def test_core_backward_compatibility(self) -> None:\n        \"\"\"Test backward compatibility for get_plugin_manager function. See #787.\"\"\"\n        import _pytest.config\n\n        assert (\n            type(_pytest.config.get_plugin_manager())\n            is _pytest.config.PytestPluginManager\n        )\n\n    def test_has_plugin(self, request) -> None:\n        \"\"\"Test hasplugin function of the plugin manager (#932).\"\"\"\n        assert request.config.pluginmanager.hasplugin(\"python\")\n\n\nclass TestDurations:\n    source = \"\"\"\n        from _pytest import timing\n        def test_something():\n            pass\n        def test_2():\n            timing.sleep(0.010)\n        def test_1():\n            timing.sleep(0.002)\n        def test_3():\n            timing.sleep(0.020)\n    \"\"\"\n\n    def test_calls(self, pytester: Pytester, mock_timing) -> None:\n        pytester.makepyfile(self.source)\n        result = pytester.runpytest_inprocess(\"--durations=10\")\n        assert result.ret == 0\n\n        result.stdout.fnmatch_lines_random(\n            [\"*durations*\", \"*call*test_3*\", \"*call*test_2*\"]\n        )\n\n        result.stdout.fnmatch_lines(\n            [\"(8 durations < 0.005s hidden.  Use -vv to show these durations.)\"]\n        )\n\n    def test_calls_show_2(self, pytester: Pytester, mock_timing) -> None:\n        pytester.makepyfile(self.source)\n        result = pytester.runpytest_inprocess(\"--durations=2\")\n        assert result.ret == 0\n\n        lines = result.stdout.get_lines_after(\"*slowest*durations*\")\n        assert \"4 passed\" in lines[2]\n\n    def test_calls_showall(self, pytester: Pytester, mock_timing) -> None:\n        pytester.makepyfile(self.source)\n        result = pytester.runpytest_inprocess(\"--durations=0\")\n        assert result.ret == 0\n        TestDurations.check_tests_in_output(result.stdout.lines, 2, 3)\n\n    def test_calls_showall_verbose(self, pytester: Pytester, mock_timing) -> No"}, {"start_line": 0, "end_line": 2000, "belongs_to": {"file_name": "main.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "\"\"\"Core implementation of the testing process: init, session, runtest loop.\"\"\"\n\nfrom __future__ import annotations\n\nimport argparse\nfrom collections.abc import Callable\nfrom collections.abc import Iterable\nfrom collections.abc import Iterator\nfrom collections.abc import Sequence\nfrom collections.abc import Set as AbstractSet\nimport dataclasses\nimport fnmatch\nimport functools\nimport importlib\nimport importlib.util\nimport os\nfrom pathlib import Path\nimport sys\nfrom typing import final\nfrom typing import Literal\nfrom typing import overload\nfrom typing import TYPE_CHECKING\nimport warnings\n\nimport pluggy\n\nfrom _pytest import nodes\nimport _pytest._code\nfrom _pytest.config import Config\nfrom _pytest.config import directory_arg\nfrom _pytest.config import ExitCode\nfrom _pytest.config import hookimpl\nfrom _pytest.config import PytestPluginManager\nfrom _pytest.config import UsageError\nfrom _pytest.config.argparsing import Parser\nfrom _pytest.config.compat import PathAwareHookProxy\nfrom _pytest.outcomes import exit\nfrom _pytest.pathlib import absolutepath\nfrom _pytest.pathlib import bestrelpath\nfrom _pytest.pathlib import fnmatch_ex\nfrom _pytest.pathlib import safe_exists\nfrom _pytest.pathlib import scandir\nfrom _pytest.reports import CollectReport\nfrom _pytest.reports import TestReport\nfrom _pytest.runner import collect_one_node\nfrom _pytest.runner import SetupState\nfrom _pytest.warning_types import PytestWarning\n\n\nif TYPE_CHECKING:\n    from typing_extensions import Self\n\n    from _pytest.fixtures import FixtureManager\n\n\ndef pytest_addoption(parser: Parser) -> None:\n    group = parser.getgroup(\"general\", \"Running and selection options\")\n    group._addoption(  # private to use reserved lower-case short option\n        \"-x\",\n        \"--exitfirst\",\n        action=\"store_const\",\n        dest=\"maxfail\",\n        const=1,\n        help=\"Exit instantly on first error or failed test\",\n    )\n    group.addoption(\n        \"--maxfail\",\n        metavar=\"num\",\n        action=\"store\",\n        t"}, {"start_line": 75000, "end_line": 77000, "belongs_to": {"file_name": "test_terminal.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "_style = times\n        \"\"\"\n        )\n        output = pytester.runpytest()\n        assert output.ret == ExitCode.NO_TESTS_COLLECTED\n\n    def test_verbose(self, many_tests_files, pytester: Pytester) -> None:\n        output = pytester.runpytest(\"-v\")\n        output.stdout.re_match_lines(\n            [\n                r\"test_bar.py::test_bar\\[0\\] PASSED \\s+ \\[  5%\\]\",\n                r\"test_foo.py::test_foo\\[4\\] PASSED \\s+ \\[ 75%\\]\",\n                r\"test_foobar.py::test_foobar\\[4\\] PASSED \\s+ \\[100%\\]\",\n            ]\n        )\n\n    def test_verbose_count(self, many_tests_files, pytester: Pytester) -> None:\n        pytester.makeini(\n            \"\"\"\n            [pytest]\n            console_output_style = count\n        \"\"\"\n        )\n        output = pytester.runpytest(\"-v\")\n        output.stdout.re_match_lines(\n            [\n                r\"test_bar.py::test_bar\\[0\\] PASSED \\s+ \\[ 1/20\\]\",\n                r\"test_foo.py::test_foo\\[4\\] PASSED \\s+ \\[15/20\\]\",\n                r\"test_foobar.py::test_foobar\\[4\\] PASSED \\s+ \\[20/20\\]\",\n            ]\n        )\n\n    def test_verbose_times(self, many_tests_files, pytester: Pytester) -> None:\n        pytester.makeini(\n            \"\"\"\n            [pytest]\n            console_output_style = times\n        \"\"\"\n        )\n        output = pytester.runpytest(\"-v\")\n        output.stdout.re_match_lines(\n            [\n                r\"test_bar.py::test_bar\\[0\\] PASSED \\s+ \\d{1,3}[\\.[a-z\\ ]{1,2}\\d{0,3}\\w{1,2}$\",\n                r\"test_foo.py::test_foo\\[4\\] PASSED \\s+ \\d{1,3}[\\.[a-z\\ ]{1,2}\\d{0,3}\\w{1,2}$\",\n                r\"test_foobar.py::test_foobar\\[4\\] PASSED \\s+ \\d{1,3}[\\.[a-z\\ ]{1,2}\\d{0,3}\\w{1,2}$\",\n            ]\n        )\n\n    def test_xdist_normal(\n        self, many_tests_files, pytester: Pytester, monkeypatch\n    ) -> None:\n        pytest.importorskip(\"xdist\")\n        monkeypatch.delenv(\"PYTEST_DISABLE_PLUGIN_AUTOLOAD\", raising=False)\n        output = pytester.runpytest(\"-n2\")\n        output.stdout.re_match_lines([r\"\\.{20} \\s+ "}, {"start_line": 49000, "end_line": 51000, "belongs_to": {"file_name": "collect.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing/python", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "2.py\n\n    \"\"\"\n    root = pytester.mkpydir(\"root\")\n    sub1 = root.joinpath(\"sub1\")\n    sub1_test = sub1.joinpath(\"sub1_1\")\n    sub1_test.mkdir(parents=True)\n    for d in (sub1, sub1_test):\n        d.joinpath(\"__init__.py\").touch()\n\n    sub2 = root.joinpath(\"sub2\")\n    sub2_test = sub2.joinpath(\"test\")\n    sub2_test.mkdir(parents=True)\n\n    sub1_test.joinpath(\"test_in_sub1.py\").write_text(\n        \"def test_1(): pass\", encoding=\"utf-8\"\n    )\n    sub2_test.joinpath(\"test_in_sub2.py\").write_text(\n        \"def test_2(): pass\", encoding=\"utf-8\"\n    )\n\n    # Execute from .\n    result = pytester.runpytest(\"-v\", \"-s\")\n    result.assert_outcomes(passed=2)\n\n    # Execute from . with one argument \"root\"\n    result = pytester.runpytest(\"-v\", \"-s\", \"root\")\n    result.assert_outcomes(passed=2)\n\n    # Chdir into package's root and execute with no args\n    os.chdir(root)\n    result = pytester.runpytest(\"-v\", \"-s\")\n    result.assert_outcomes(passed=2)\n\n\ndef test_package_ordering(pytester: Pytester) -> None:\n    \"\"\"\n    .\n     root\n         Test_root.py\n         __init__.py\n         sub1\n            Test_sub1.py\n            __init__.py\n         sub2\n             test\n                 test_sub2.py\n\n    \"\"\"\n    pytester.makeini(\n        \"\"\"\n        [pytest]\n        python_files=*.py\n    \"\"\"\n    )\n    root = pytester.mkpydir(\"root\")\n    sub1 = root.joinpath(\"sub1\")\n    sub1.mkdir()\n    sub1.joinpath(\"__init__.py\").touch()\n    sub2 = root.joinpath(\"sub2\")\n    sub2_test = sub2.joinpath(\"test\")\n    sub2_test.mkdir(parents=True)\n\n    root.joinpath(\"Test_root.py\").write_text(\"def test_1(): pass\", encoding=\"utf-8\")\n    sub1.joinpath(\"Test_sub1.py\").write_text(\"def test_2(): pass\", encoding=\"utf-8\")\n    sub2_test.joinpath(\"test_sub2.py\").write_text(\n        \"def test_3(): pass\", encoding=\"utf-8\"\n    )\n\n    # Execute from .\n    result = pytester.runpytest(\"-v\", \"-s\")\n    result.assert_outcomes(passed=3)\n\n\ndef test_collection_hierarchy(pytester: Pytester) -> None:\n  "}, {"start_line": 6000, "end_line": 8000, "belongs_to": {"file_name": "test_session.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "rec.getreports(\"pytest_collectreport\")\n        # Session, Dir\n        assert len(reports) == 2\n        assert reports[1].skipped\n\n\nclass TestNewSession(SessionTests):\n    def test_order_of_execution(self, pytester: Pytester) -> None:\n        reprec = pytester.inline_runsource(\n            \"\"\"\n            values = []\n            def test_1():\n                values.append(1)\n            def test_2():\n                values.append(2)\n            def test_3():\n                assert values == [1,2]\n            class Testmygroup(object):\n                reslist = values\n                def test_1(self):\n                    self.reslist.append(1)\n                def test_2(self):\n                    self.reslist.append(2)\n                def test_3(self):\n                    self.reslist.append(3)\n                def test_4(self):\n                    assert self.reslist == [1,2,1,2,3]\n        \"\"\"\n        )\n        passed, skipped, failed = reprec.countoutcomes()\n        assert failed == skipped == 0\n        assert passed == 7\n\n    def test_collect_only_with_various_situations(self, pytester: Pytester) -> None:\n        p = pytester.makepyfile(\n            test_one=\"\"\"\n                def test_one():\n                    raise ValueError()\n\n                class TestX(object):\n                    def test_method_one(self):\n                        pass\n\n                class TestY(TestX):\n                    pass\n            \"\"\",\n            test_three=\"xxxdsadsadsadsa\",\n            __init__=\"\",\n        )\n        reprec = pytester.inline_run(\"--collect-only\", p.parent)\n\n        itemstarted = reprec.getcalls(\"pytest_itemcollected\")\n        assert len(itemstarted) == 3\n        assert not reprec.getreports(\"pytest_runtest_logreport\")\n        started = reprec.getcalls(\"pytest_collectstart\")\n        finished = reprec.getreports(\"pytest_collectreport\")\n        assert len(started) == len(finished)\n        assert len(started) == 6\n        colfail = [x for x in finished if x.failed]\n"}], "retrieved_count": 10, "cost_time": 1.1007978916168213}
{"question": "Why does Pytest provide multiple assertion rewriting mechanisms for different test scenarios?", "answer": null, "relative_code_list": null, "ground_truth": "Pytest provides multiple assertion rewriting mechanisms for different test scenarios to accommodate various testing needs and environments: 1) Default assertion rewriting mode transforms assert statements to provide detailed introspection information when assertions fail, 2) Plain assertion mode (--assert=plain) disables rewriting entirely for compatibility with certain environments or when detailed introspection is not needed, 3) Selective rewriting through pytest.register_assert_rewrite() allows specific modules to be rewritten even if they're not test modules, 4) Automatic rewriting for test modules and plugin modules ensures that test code gets detailed assertion information, 5) PYTEST_DONT_REWRITE docstring marker allows individual modules to opt out of rewriting when needed, 6) Different rewriting strategies for different Python versions and environments ensure compatibility, 7) Caching mechanisms for rewritten modules to avoid repeated rewriting and improve performance, 8) Integration with pytest_assertion_pass hook for custom behavior when assertions pass, 9) Support for different encoding scenarios (UTF-8, Latin-1) in assertion rewriting, 10) Multi-line assertion support for complex test expressions, 11) Backward compatibility mechanisms to ensure existing test suites continue to work, 12) Environment-specific rewriting behavior for CI/CD pipelines and different deployment scenarios.", "score": null, "retrieved_content": [{"start_line": 3000, "end_line": 5000, "belongs_to": {"file_name": "test_assertion.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "st():\n                    def check(values, value):\n                        assert values.pop(0) == value\n                    return check\n            \"\"\",\n            \"foo/tests/test_foo.py\": \"\"\"\n                def test(check_first):\n                    check_first([10, 30], 30)\n            \"\"\",\n        }\n        pytester.makepyfile(**contents)\n        result = pytester.runpytest_subprocess(f\"--assert={mode}\")\n        if mode == \"plain\":\n            expected = \"E       AssertionError\"\n        elif mode == \"rewrite\":\n            expected = \"*assert 10 == 30*\"\n        else:\n            assert 0\n        result.stdout.fnmatch_lines([expected])\n\n    def test_rewrite_assertions_pytester_plugin(self, pytester: Pytester) -> None:\n        \"\"\"\n        Assertions in the pytester plugin must also benefit from assertion\n        rewriting (#1920).\n        \"\"\"\n        pytester.makepyfile(\n            \"\"\"\n            pytest_plugins = ['pytester']\n            def test_dummy_failure(pytester):  # how meta!\n                pytester.makepyfile('def test(): assert 0')\n                r = pytester.inline_run()\n                r.assertoutcome(passed=1)\n        \"\"\"\n        )\n        result = pytester.runpytest_subprocess()\n        result.stdout.fnmatch_lines(\n            [\n                \">       r.assertoutcome(passed=1)\",\n                \"E       AssertionError: ([[][]], [[][]], [[]<TestReport *>[]])*\",\n                \"E       assert {'failed': 1,... 'skipped': 0} == {'failed': 0,... 'skipped': 0}\",\n                \"E         Omitting 1 identical items, use -vv to show\",\n                \"E         Differing items:\",\n                \"E         Use -v to get more diff\",\n            ]\n        )\n        # XXX: unstable output.\n        result.stdout.fnmatch_lines_random(\n            [\n                \"E         {'failed': 1} != {'failed': 0}\",\n                \"E         {'passed': 0} != {'passed': 1}\",\n            ]\n        )\n\n    @pytest.mark.parametrize(\"mode\", [\"plain\", \"rewrite\"])\n   "}, {"start_line": 11000, "end_line": 13000, "belongs_to": {"file_name": "test_assertion.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": ":\n            result.assert_outcomes(failed=2)\n            result.stdout.fnmatch_lines([expected, expected])\n        else:\n            result.assert_outcomes(errors=2)\n            result.stdout.fnmatch_lines(\n                [\n                    \"E       fixture 'check_first' not found\",\n                    \"E       fixture 'check_first2' not found\",\n                ]\n            )\n\n    def test_rewrite_ast(self, pytester: Pytester) -> None:\n        pytester.mkdir(\"pkg\")\n        contents = {\n            \"pkg/__init__.py\": \"\"\"\n                import pytest\n                pytest.register_assert_rewrite('pkg.helper')\n            \"\"\",\n            \"pkg/helper.py\": \"\"\"\n                def tool():\n                    a, b = 2, 3\n                    assert a == b\n            \"\"\",\n            \"pkg/plugin.py\": \"\"\"\n                import pytest, pkg.helper\n                @pytest.fixture\n                def tool():\n                    return pkg.helper.tool\n            \"\"\",\n            \"pkg/other.py\": \"\"\"\n                values = [3, 2]\n                def tool():\n                    assert values.pop() == 3\n            \"\"\",\n            \"conftest.py\": \"\"\"\n                pytest_plugins = ['pkg.plugin']\n            \"\"\",\n            \"test_pkg.py\": \"\"\"\n                import pkg.other\n                def test_tool(tool):\n                    tool()\n                def test_other():\n                    pkg.other.tool()\n            \"\"\",\n        }\n        pytester.makepyfile(**contents)\n        result = pytester.runpytest_subprocess(\"--assert=rewrite\")\n        result.stdout.fnmatch_lines(\n            [\n                \">*assert a == b*\",\n                \"E*assert 2 == 3*\",\n                \">*assert values.pop() == 3*\",\n                \"E*AssertionError\",\n            ]\n        )\n\n    def test_register_assert_rewrite_checks_types(self) -> None:\n        with pytest.raises(TypeError):\n            pytest.register_assert_rewrite([\"pytest_tests_internal_non_existing\"])  # type: ignore\n   "}, {"start_line": 1000, "end_line": 3000, "belongs_to": {"file_name": "test_assertrewrite.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": " Config\nfrom _pytest.config import ExitCode\nfrom _pytest.pathlib import make_numbered_dir\nfrom _pytest.pytester import Pytester\nimport pytest\n\n\ndef rewrite(src: str) -> ast.Module:\n    tree = ast.parse(src)\n    rewrite_asserts(tree, src.encode())\n    return tree\n\n\ndef getmsg(\n    f, extra_ns: Mapping[str, object] | None = None, *, must_pass: bool = False\n) -> str | None:\n    \"\"\"Rewrite the assertions in f, run it, and get the failure message.\"\"\"\n    src = \"\\n\".join(_pytest._code.Code.from_function(f).source().lines)\n    mod = rewrite(src)\n    code = compile(mod, \"<test>\", \"exec\")\n    ns: dict[str, object] = {}\n    if extra_ns is not None:\n        ns.update(extra_ns)\n    exec(code, ns)\n    func = ns[f.__name__]\n    try:\n        func()  # type: ignore[operator]\n    except AssertionError:\n        if must_pass:\n            pytest.fail(\"shouldn't have raised\")\n        s = str(sys.exc_info()[1])\n        if not s.startswith(\"assert\"):\n            return \"AssertionError: \" + s\n        return s\n    else:\n        if not must_pass:\n            pytest.fail(\"function didn't raise at all\")\n        return None\n\n\nclass TestAssertionRewrite:\n    def test_place_initial_imports(self) -> None:\n        s = \"\"\"'Doc string'\\nother = stuff\"\"\"\n        m = rewrite(s)\n        assert isinstance(m.body[0], ast.Expr)\n        for imp in m.body[1:3]:\n            assert isinstance(imp, ast.Import)\n            assert imp.lineno == 2\n            assert imp.col_offset == 0\n        assert isinstance(m.body[3], ast.Assign)\n        s = \"\"\"from __future__ import division\\nother_stuff\"\"\"\n        m = rewrite(s)\n        assert isinstance(m.body[0], ast.ImportFrom)\n        for imp in m.body[1:3]:\n            assert isinstance(imp, ast.Import)\n            assert imp.lineno == 2\n            assert imp.col_offset == 0\n        assert isinstance(m.body[3], ast.Expr)\n        s = \"\"\"'doc string'\\nfrom __future__ import division\"\"\"\n        m = rewrite(s)\n        assert isinstance(m.body[0], ast.Expr)\n        assert i"}, {"start_line": 2000, "end_line": 4000, "belongs_to": {"file_name": "test_assertion.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "       config.get_verbosity(_Config.VERBOSITY_ASSERTIONS)\n            == TestMockConfig.SOME_OTHER_VERBOSITY_LEVEL\n        )\n\n    def test_get_unsupported_type_error(self):\n        config = mock_config(verbose=TestMockConfig.SOME_VERBOSITY_LEVEL)\n\n        with pytest.raises(KeyError):\n            config.get_verbosity(\"--- NOT A VERBOSITY LEVEL ---\")\n\n\nclass TestImportHookInstallation:\n    @pytest.mark.parametrize(\"initial_conftest\", [True, False])\n    @pytest.mark.parametrize(\"mode\", [\"plain\", \"rewrite\"])\n    def test_conftest_assertion_rewrite(\n        self, pytester: Pytester, initial_conftest, mode\n    ) -> None:\n        \"\"\"Test that conftest files are using assertion rewrite on import (#1619).\"\"\"\n        pytester.mkdir(\"foo\")\n        pytester.mkdir(\"foo/tests\")\n        conftest_path = \"conftest.py\" if initial_conftest else \"foo/conftest.py\"\n        contents = {\n            conftest_path: \"\"\"\n                import pytest\n                @pytest.fixture\n                def check_first():\n                    def check(values, value):\n                        assert values.pop(0) == value\n                    return check\n            \"\"\",\n            \"foo/tests/test_foo.py\": \"\"\"\n                def test(check_first):\n                    check_first([10, 30], 30)\n            \"\"\",\n        }\n        pytester.makepyfile(**contents)\n        result = pytester.runpytest_subprocess(f\"--assert={mode}\")\n        if mode == \"plain\":\n            expected = \"E       AssertionError\"\n        elif mode == \"rewrite\":\n            expected = \"*assert 10 == 30*\"\n        else:\n            assert 0\n        result.stdout.fnmatch_lines([expected])\n\n    def test_rewrite_assertions_pytester_plugin(self, pytester: Pytester) -> None:\n        \"\"\"\n        Assertions in the pytester plugin must also benefit from assertion\n        rewriting (#1920).\n        \"\"\"\n        pytester.makepyfile(\n            \"\"\"\n            pytest_plugins = ['pytester']\n            def test_dummy_failure(pytester):  # how "}, {"start_line": 12000, "end_line": 14000, "belongs_to": {"file_name": "test_assertion.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "er.py\": \"\"\"\n                values = [3, 2]\n                def tool():\n                    assert values.pop() == 3\n            \"\"\",\n            \"conftest.py\": \"\"\"\n                pytest_plugins = ['pkg.plugin']\n            \"\"\",\n            \"test_pkg.py\": \"\"\"\n                import pkg.other\n                def test_tool(tool):\n                    tool()\n                def test_other():\n                    pkg.other.tool()\n            \"\"\",\n        }\n        pytester.makepyfile(**contents)\n        result = pytester.runpytest_subprocess(\"--assert=rewrite\")\n        result.stdout.fnmatch_lines(\n            [\n                \">*assert a == b*\",\n                \"E*assert 2 == 3*\",\n                \">*assert values.pop() == 3*\",\n                \"E*AssertionError\",\n            ]\n        )\n\n    def test_register_assert_rewrite_checks_types(self) -> None:\n        with pytest.raises(TypeError):\n            pytest.register_assert_rewrite([\"pytest_tests_internal_non_existing\"])  # type: ignore\n        pytest.register_assert_rewrite(\n            \"pytest_tests_internal_non_existing\", \"pytest_tests_internal_non_existing2\"\n        )\n\n\nclass TestBinReprIntegration:\n    def test_pytest_assertrepr_compare_called(self, pytester: Pytester) -> None:\n        pytester.makeconftest(\n            \"\"\"\n            import pytest\n            values = []\n            def pytest_assertrepr_compare(op, left, right):\n                values.append((op, left, right))\n\n            @pytest.fixture\n            def list(request):\n                return values\n        \"\"\"\n        )\n        pytester.makepyfile(\n            \"\"\"\n            def test_hello():\n                assert 0 == 1\n            def test_check(list):\n                assert list == [(\"==\", 0, 1)]\n        \"\"\"\n        )\n        result = pytester.runpytest(\"-v\")\n        result.stdout.fnmatch_lines([\"*test_hello*FAIL*\", \"*test_check*PASS*\"])\n\n\ndef callop(op: str, left: Any, right: Any, verbose: int = 0) -> list[str] | None:\n    config = mock_con"}, {"start_line": 0, "end_line": 2000, "belongs_to": {"file_name": "test_assertrewrite.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "# mypy: allow-untyped-defs\nfrom __future__ import annotations\n\nimport ast\nfrom collections.abc import Generator\nfrom collections.abc import Mapping\nimport dis\nimport errno\nfrom functools import partial\nimport glob\nimport importlib\nimport inspect\nimport marshal\nimport os\nfrom pathlib import Path\nimport py_compile\nimport re\nimport stat\nimport sys\nimport textwrap\nfrom typing import cast\nfrom unittest import mock\nimport zipfile\n\nimport _pytest._code\nfrom _pytest._io.saferepr import DEFAULT_REPR_MAX_SIZE\nfrom _pytest.assertion import util\nfrom _pytest.assertion.rewrite import _get_assertion_exprs\nfrom _pytest.assertion.rewrite import _get_maxsize_for_saferepr\nfrom _pytest.assertion.rewrite import _saferepr\nfrom _pytest.assertion.rewrite import AssertionRewritingHook\nfrom _pytest.assertion.rewrite import get_cache_dir\nfrom _pytest.assertion.rewrite import PYC_TAIL\nfrom _pytest.assertion.rewrite import PYTEST_TAG\nfrom _pytest.assertion.rewrite import rewrite_asserts\nfrom _pytest.config import Config\nfrom _pytest.config import ExitCode\nfrom _pytest.pathlib import make_numbered_dir\nfrom _pytest.pytester import Pytester\nimport pytest\n\n\ndef rewrite(src: str) -> ast.Module:\n    tree = ast.parse(src)\n    rewrite_asserts(tree, src.encode())\n    return tree\n\n\ndef getmsg(\n    f, extra_ns: Mapping[str, object] | None = None, *, must_pass: bool = False\n) -> str | None:\n    \"\"\"Rewrite the assertions in f, run it, and get the failure message.\"\"\"\n    src = \"\\n\".join(_pytest._code.Code.from_function(f).source().lines)\n    mod = rewrite(src)\n    code = compile(mod, \"<test>\", \"exec\")\n    ns: dict[str, object] = {}\n    if extra_ns is not None:\n        ns.update(extra_ns)\n    exec(code, ns)\n    func = ns[f.__name__]\n    try:\n        func()  # type: ignore[operator]\n    except AssertionError:\n        if must_pass:\n            pytest.fail(\"shouldn't have raised\")\n        s = str(sys.exc_info()[1])\n        if not s.startswith(\"assert\"):\n            return \"AssertionError: \" + s\n        return s"}, {"start_line": 10000, "end_line": 12000, "belongs_to": {"file_name": "test_assertion.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "             return spamplugin\n\n            class DummyDistInfo(object):\n                version = '1.0'\n                files = ('spamplugin.py', 'hampkg/__init__.py')\n                entry_points = (DummyEntryPoint(),)\n                metadata = {'name': 'foo'}\n\n            def distributions():\n                return (DummyDistInfo(),)\n\n            importlib.metadata.distributions = distributions\n            pytest.main()\n            \"\"\",\n            \"test_foo.py\": \"\"\"\\\n            def test(check_first):\n                check_first([10, 30], 30)\n\n            def test2(check_first2):\n                check_first2([10, 30], 30)\n            \"\"\",\n        }\n        pytester.makepyfile(**contents)\n        result = pytester.run(sys.executable, *args)\n        if mode == \"plain\":\n            expected = \"E       AssertionError\"\n        elif mode == \"rewrite\":\n            expected = \"*assert 10 == 30*\"\n        else:\n            assert 0\n\n        if not disable_plugin_autoload or explicit_specify:\n            result.assert_outcomes(failed=2)\n            result.stdout.fnmatch_lines([expected, expected])\n        else:\n            result.assert_outcomes(errors=2)\n            result.stdout.fnmatch_lines(\n                [\n                    \"E       fixture 'check_first' not found\",\n                    \"E       fixture 'check_first2' not found\",\n                ]\n            )\n\n    def test_rewrite_ast(self, pytester: Pytester) -> None:\n        pytester.mkdir(\"pkg\")\n        contents = {\n            \"pkg/__init__.py\": \"\"\"\n                import pytest\n                pytest.register_assert_rewrite('pkg.helper')\n            \"\"\",\n            \"pkg/helper.py\": \"\"\"\n                def tool():\n                    a, b = 2, 3\n                    assert a == b\n            \"\"\",\n            \"pkg/plugin.py\": \"\"\"\n                import pytest, pkg.helper\n                @pytest.fixture\n                def tool():\n                    return pkg.helper.tool\n            \"\"\",\n            \"pkg/oth"}, {"start_line": 9000, "end_line": 11000, "belongs_to": {"file_name": "test_assertrewrite.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "     class T:\n                    def __{name}__(self,other):\n                        loc()\n                        return True\n\n                assert  5 {op} T()\n                assert  (5\n                         {op}\n                         T\n                         ())\n        \"\"\")\n\n        preserved(\"\"\"\n            def func(value):\n                loc(\"func\")\n                return value\n\n            class T:\n                def __iter__(self):\n                    loc(\"iter\")\n                    return iter([5])\n\n            assert  func(*T()) == 5\n        \"\"\")\n\n        preserved(\"\"\"\n            class T:\n                def __getattr__(self,name):\n                    loc()\n                    return name\n\n            assert  T().attr == \"attr\"\n        \"\"\")\n\n    def test_dont_rewrite(self) -> None:\n        s = \"\"\"'PYTEST_DONT_REWRITE'\\nassert 14\"\"\"\n        m = rewrite(s)\n        assert len(m.body) == 2\n        assert isinstance(m.body[1], ast.Assert)\n        assert m.body[1].msg is None\n\n    def test_dont_rewrite_plugin(self, pytester: Pytester) -> None:\n        contents = {\n            \"conftest.py\": \"pytest_plugins = 'plugin'; import plugin\",\n            \"plugin.py\": \"'PYTEST_DONT_REWRITE'\",\n            \"test_foo.py\": \"def test_foo(): pass\",\n        }\n        pytester.makepyfile(**contents)\n        result = pytester.runpytest_subprocess()\n        assert \"warning\" not in \"\".join(result.outlines)\n\n    def test_rewrites_plugin_as_a_package(self, pytester: Pytester) -> None:\n        pkgdir = pytester.mkpydir(\"plugin\")\n        pkgdir.joinpath(\"__init__.py\").write_text(\n            \"import pytest\\n\"\n            \"@pytest.fixture\\n\"\n            \"def special_asserter():\\n\"\n            \"    def special_assert(x, y):\\n\"\n            \"        assert x == y\\n\"\n            \"    return special_assert\\n\",\n            encoding=\"utf-8\",\n        )\n        pytester.makeconftest('pytest_plugins = [\"plugin\"]')\n        pytester.makepyfile(\"def test(special_asserter): special_asser"}, {"start_line": 34000, "end_line": 36000, "belongs_to": {"file_name": "test_assertrewrite.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "one:\n        pkg = pytester.path.joinpath(\"pkg\")\n        pkg.mkdir()\n        pkg.joinpath(\"__init__.py\")\n        pkg.joinpath(\"test_blah.py\").write_text(\n            \"\"\"\ndef test_rewritten():\n    assert \"@py_builtins\" in globals()\"\"\",\n            encoding=\"utf-8\",\n        )\n        assert pytester.runpytest().ret == 0\n\n    def test_translate_newlines(self, pytester: Pytester) -> None:\n        content = \"def test_rewritten():\\r\\n assert '@py_builtins' in globals()\"\n        b = content.encode(\"utf-8\")\n        pytester.path.joinpath(\"test_newlines.py\").write_bytes(b)\n        assert pytester.runpytest().ret == 0\n\n    def test_package_without__init__py(self, pytester: Pytester) -> None:\n        pkg = pytester.mkdir(\"a_package_without_init_py\")\n        pkg.joinpath(\"module.py\").touch()\n        pytester.makepyfile(\"import a_package_without_init_py.module\")\n        assert pytester.runpytest().ret == ExitCode.NO_TESTS_COLLECTED\n\n    def test_rewrite_warning(self, pytester: Pytester) -> None:\n        pytester.makeconftest(\n            \"\"\"\n            import pytest\n            pytest.register_assert_rewrite(\"_pytest\")\n        \"\"\"\n        )\n        # needs to be a subprocess because pytester explicitly disables this warning\n        result = pytester.runpytest_subprocess()\n        result.stdout.fnmatch_lines([\"*Module already imported*; _pytest\"])\n\n    def test_rewrite_warning_ignore(self, pytester: Pytester) -> None:\n        pytester.makeconftest(\n            \"\"\"\n            import pytest\n            pytest.register_assert_rewrite(\"_pytest\")\n        \"\"\"\n        )\n        # needs to be a subprocess because pytester explicitly disables this warning\n        result = pytester.runpytest_subprocess(\n            \"-W\",\n            \"ignore:Module already imported so cannot be rewritten; _pytest:pytest.PytestAssertRewriteWarning\",\n        )\n        # Previously, when the message pattern used to contain an extra `:`, an error was raised.\n        assert not result.stderr.str().strip()\n    "}, {"start_line": 5000, "end_line": 7000, "belongs_to": {"file_name": "test_assertion.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": " def test_pytest_plugins_rewrite(self, pytester: Pytester, mode) -> None:\n        contents = {\n            \"conftest.py\": \"\"\"\n                pytest_plugins = ['ham']\n            \"\"\",\n            \"ham.py\": \"\"\"\n                import pytest\n                @pytest.fixture\n                def check_first():\n                    def check(values, value):\n                        assert values.pop(0) == value\n                    return check\n            \"\"\",\n            \"test_foo.py\": \"\"\"\n                def test_foo(check_first):\n                    check_first([10, 30], 30)\n            \"\"\",\n        }\n        pytester.makepyfile(**contents)\n        result = pytester.runpytest_subprocess(f\"--assert={mode}\")\n        if mode == \"plain\":\n            expected = \"E       AssertionError\"\n        elif mode == \"rewrite\":\n            expected = \"*assert 10 == 30*\"\n        else:\n            assert 0\n        result.stdout.fnmatch_lines([expected])\n\n    @pytest.mark.parametrize(\"mode\", [\"str\", \"list\"])\n    def test_pytest_plugins_rewrite_module_names(\n        self, pytester: Pytester, mode\n    ) -> None:\n        \"\"\"Test that pluginmanager correct marks pytest_plugins variables\n        for assertion rewriting if they are defined as plain strings or\n        list of strings (#1888).\n        \"\"\"\n        plugins = '\"ham\"' if mode == \"str\" else '[\"ham\"]'\n        contents = {\n            \"conftest.py\": f\"\"\"\n                pytest_plugins = {plugins}\n            \"\"\",\n            \"ham.py\": \"\"\"\n                import pytest\n            \"\"\",\n            \"test_foo.py\": \"\"\"\n                def test_foo(pytestconfig):\n                    assert 'ham' in pytestconfig.pluginmanager.rewrite_hook._must_rewrite\n            \"\"\",\n        }\n        pytester.makepyfile(**contents)\n        result = pytester.runpytest_subprocess(\"--assert=rewrite\")\n        assert result.ret == 0\n\n    def test_pytest_plugins_rewrite_module_names_correctly(\n        self, pytester: Pytester\n    ) -> None:\n        \"\"\"Test that w"}], "retrieved_count": 10, "cost_time": 1.1108014583587646}
{"question": "Why does Pytest use a session-based test execution model instead of individual test isolation?", "answer": null, "relative_code_list": null, "ground_truth": "Pytest uses a session-based test execution model for three main reasons: 1) Performance - reuses expensive setup operations and cached fixtures across tests, reducing execution time for large test suites; 2) Fixture System - enables fixture sharing and dependency injection with different scopes (function, class, module, session), which is core to Pytest's design; 3) Plugin Architecture - allows plugins to maintain state and interact with the test lifecycle through session-level hooks and context management. The session model balances test isolation with efficiency, enabling Pytest's powerful features while maintaining good performance.", "score": null, "retrieved_content": [{"start_line": 20000, "end_line": 22000, "belongs_to": {"file_name": "pytester.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "\n        self.__saved = list(sys.path), list(sys.meta_path)\n\n    def restore(self) -> None:\n        sys.path[:], sys.meta_path[:] = self.__saved\n\n\n@final\nclass Pytester:\n    \"\"\"\n    Facilities to write tests/configuration files, execute pytest in isolation, and match\n    against expected output, perfect for black-box testing of pytest plugins.\n\n    It attempts to isolate the test run from external factors as much as possible, modifying\n    the current working directory to :attr:`path` and environment variables during initialization.\n    \"\"\"\n\n    __test__ = False\n\n    CLOSE_STDIN: Final = NOTSET\n\n    class TimeoutExpired(Exception):\n        pass\n\n    def __init__(\n        self,\n        request: FixtureRequest,\n        tmp_path_factory: TempPathFactory,\n        monkeypatch: MonkeyPatch,\n        *,\n        _ispytest: bool = False,\n    ) -> None:\n        check_ispytest(_ispytest)\n        self._request = request\n        self._mod_collections: WeakKeyDictionary[Collector, list[Item | Collector]] = (\n            WeakKeyDictionary()\n        )\n        if request.function:\n            name: str = request.function.__name__\n        else:\n            name = request.node.name\n        self._name = name\n        self._path: Path = tmp_path_factory.mktemp(name, numbered=True)\n        #: A list of plugins to use with :py:meth:`parseconfig` and\n        #: :py:meth:`runpytest`. Initially this is an empty list but plugins can\n        #: be added to the list.\n        #:\n        #: When running in subprocess mode, specify plugins by name (str) - adding\n        #: plugin objects directly is not supported.\n        self.plugins: list[str | _PluggyPlugin] = []\n        self._sys_path_snapshot = SysPathsSnapshot()\n        self._sys_modules_snapshot = self.__take_sys_modules_snapshot()\n        self._request.addfinalizer(self._finalize)\n        self._method = self._request.config.getoption(\"--runpytest\")\n        self._test_tmproot = tmp_path_factory.mktemp(f\"tmp-{name}\", numbered=True)\n\n        se"}, {"start_line": 7000, "end_line": 9000, "belongs_to": {"file_name": "integration.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing/python", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "\"\"\"\n        )\n        reprec = pytester.inline_run()\n        reprec.assertoutcome(passed=1)\n\n\nclass TestReRunTests:\n    def test_rerun(self, pytester: Pytester) -> None:\n        pytester.makeconftest(\n            \"\"\"\n            from _pytest.runner import runtestprotocol\n            def pytest_runtest_protocol(item, nextitem):\n                runtestprotocol(item, log=False, nextitem=nextitem)\n                runtestprotocol(item, log=True, nextitem=nextitem)\n        \"\"\"\n        )\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n            count = 0\n            req = None\n            @pytest.fixture\n            def fix(request):\n                global count, req\n                assert request != req\n                req = request\n                print(\"fix count %s\" % count)\n                count += 1\n            def test_fix(fix):\n                pass\n        \"\"\"\n        )\n        result = pytester.runpytest(\"-s\")\n        result.stdout.fnmatch_lines(\n            \"\"\"\n            *fix count 0*\n            *fix count 1*\n        \"\"\"\n        )\n        result.stdout.fnmatch_lines(\n            \"\"\"\n            *2 passed*\n        \"\"\"\n        )\n\n\ndef test_pytestconfig_is_session_scoped() -> None:\n    from _pytest.fixtures import pytestconfig\n\n    marker = getfixturemarker(pytestconfig)\n    assert marker is not None\n    assert marker.scope == \"session\"\n\n\nclass TestNoselikeTestAttribute:\n    def test_module_with_global_test(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            __test__ = False\n            def test_hello():\n                pass\n        \"\"\"\n        )\n        reprec = pytester.inline_run()\n        assert not reprec.getfailedcollections()\n        calls = reprec.getreports(\"pytest_runtest_logreport\")\n        assert not calls\n\n    def test_class_and_method(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            __test__ = True\n            def test_func():\n                "}, {"start_line": 6000, "end_line": 8000, "belongs_to": {"file_name": "test_session.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "rec.getreports(\"pytest_collectreport\")\n        # Session, Dir\n        assert len(reports) == 2\n        assert reports[1].skipped\n\n\nclass TestNewSession(SessionTests):\n    def test_order_of_execution(self, pytester: Pytester) -> None:\n        reprec = pytester.inline_runsource(\n            \"\"\"\n            values = []\n            def test_1():\n                values.append(1)\n            def test_2():\n                values.append(2)\n            def test_3():\n                assert values == [1,2]\n            class Testmygroup(object):\n                reslist = values\n                def test_1(self):\n                    self.reslist.append(1)\n                def test_2(self):\n                    self.reslist.append(2)\n                def test_3(self):\n                    self.reslist.append(3)\n                def test_4(self):\n                    assert self.reslist == [1,2,1,2,3]\n        \"\"\"\n        )\n        passed, skipped, failed = reprec.countoutcomes()\n        assert failed == skipped == 0\n        assert passed == 7\n\n    def test_collect_only_with_various_situations(self, pytester: Pytester) -> None:\n        p = pytester.makepyfile(\n            test_one=\"\"\"\n                def test_one():\n                    raise ValueError()\n\n                class TestX(object):\n                    def test_method_one(self):\n                        pass\n\n                class TestY(TestX):\n                    pass\n            \"\"\",\n            test_three=\"xxxdsadsadsadsa\",\n            __init__=\"\",\n        )\n        reprec = pytester.inline_run(\"--collect-only\", p.parent)\n\n        itemstarted = reprec.getcalls(\"pytest_itemcollected\")\n        assert len(itemstarted) == 3\n        assert not reprec.getreports(\"pytest_runtest_logreport\")\n        started = reprec.getcalls(\"pytest_collectstart\")\n        finished = reprec.getreports(\"pytest_collectreport\")\n        assert len(started) == len(finished)\n        assert len(started) == 6\n        colfail = [x for x in finished if x.failed]\n"}, {"start_line": 15000, "end_line": 17000, "belongs_to": {"file_name": "pytester.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "during initialization.\n\n    It is particularly useful for testing plugins. It is similar to the :fixture:`tmp_path`\n    fixture but provides methods which aid in testing pytest itself.\n    \"\"\"\n    return Pytester(request, tmp_path_factory, monkeypatch, _ispytest=True)\n\n\n@fixture\ndef _sys_snapshot() -> Generator[None]:\n    snappaths = SysPathsSnapshot()\n    snapmods = SysModulesSnapshot()\n    yield\n    snapmods.restore()\n    snappaths.restore()\n\n\n@fixture\ndef _config_for_test() -> Generator[Config]:\n    from _pytest.config import get_config\n\n    config = get_config()\n    yield config\n    config._ensure_unconfigure()  # cleanup, e.g. capman closing tmpfiles.\n\n\n# Regex to match the session duration string in the summary: \"74.34s\".\nrex_session_duration = re.compile(r\"\\d+\\.\\d\\ds\")\n# Regex to match all the counts and phrases in the summary line: \"34 passed, 111 skipped\".\nrex_outcome = re.compile(r\"(\\d+) (\\w+)\")\n\n\n@final\nclass RunResult:\n    \"\"\"The result of running a command from :class:`~pytest.Pytester`.\"\"\"\n\n    def __init__(\n        self,\n        ret: int | ExitCode,\n        outlines: list[str],\n        errlines: list[str],\n        duration: float,\n    ) -> None:\n        try:\n            self.ret: int | ExitCode = ExitCode(ret)\n            \"\"\"The return value.\"\"\"\n        except ValueError:\n            self.ret = ret\n        self.outlines = outlines\n        \"\"\"List of lines captured from stdout.\"\"\"\n        self.errlines = errlines\n        \"\"\"List of lines captured from stderr.\"\"\"\n        self.stdout = LineMatcher(outlines)\n        \"\"\":class:`~pytest.LineMatcher` of stdout.\n\n        Use e.g. :func:`str(stdout) <pytest.LineMatcher.__str__()>` to reconstruct stdout, or the commonly used\n        :func:`stdout.fnmatch_lines() <pytest.LineMatcher.fnmatch_lines()>` method.\n        \"\"\"\n        self.stderr = LineMatcher(errlines)\n        \"\"\":class:`~pytest.LineMatcher` of stderr.\"\"\"\n        self.duration = duration\n        \"\"\"Duration in seconds.\"\"\"\n\n    def __repr__(self) -> st"}, {"start_line": 76000, "end_line": 78000, "belongs_to": {"file_name": "fixtures.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing/python", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "eturn 1\n\n            def test_1(arg):\n                assert arg == 1\n            def test_2(arg):\n                assert arg == 1\n                assert len(values) == 1\n            class TestClass(object):\n                def test3(self, arg):\n                    assert arg == 1\n                    assert len(values) == 1\n        \"\"\"\n        )\n        reprec = pytester.inline_run()\n        reprec.assertoutcome(passed=3)\n\n    def test_scope_session_exc(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n            values = []\n            @pytest.fixture(scope=\"session\")\n            def fix():\n                values.append(1)\n                pytest.skip('skipping')\n\n            def test_1(fix):\n                pass\n            def test_2(fix):\n                pass\n            def test_last():\n                assert values == [1]\n        \"\"\"\n        )\n        reprec = pytester.inline_run()\n        reprec.assertoutcome(skipped=2, passed=1)\n\n    def test_scope_session_exc_two_fix(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n            values = []\n            m = []\n            @pytest.fixture(scope=\"session\")\n            def a():\n                values.append(1)\n                pytest.skip('skipping')\n            @pytest.fixture(scope=\"session\")\n            def b(a):\n                m.append(1)\n\n            def test_1(b):\n                pass\n            def test_2(b):\n                pass\n            def test_last():\n                assert values == [1]\n                assert m == []\n        \"\"\"\n        )\n        reprec = pytester.inline_run()\n        reprec.assertoutcome(skipped=2, passed=1)\n\n    def test_scope_exc(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            test_foo=\"\"\"\n                def test_foo(fix):\n                    pass\n            \"\"\",\n            test_bar=\"\"\"\n                def test_bar(fix):\n               "}, {"start_line": 8000, "end_line": 10000, "belongs_to": {"file_name": "integration.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing/python", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "\"\"\"\n            *fix count 0*\n            *fix count 1*\n        \"\"\"\n        )\n        result.stdout.fnmatch_lines(\n            \"\"\"\n            *2 passed*\n        \"\"\"\n        )\n\n\ndef test_pytestconfig_is_session_scoped() -> None:\n    from _pytest.fixtures import pytestconfig\n\n    marker = getfixturemarker(pytestconfig)\n    assert marker is not None\n    assert marker.scope == \"session\"\n\n\nclass TestNoselikeTestAttribute:\n    def test_module_with_global_test(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            __test__ = False\n            def test_hello():\n                pass\n        \"\"\"\n        )\n        reprec = pytester.inline_run()\n        assert not reprec.getfailedcollections()\n        calls = reprec.getreports(\"pytest_runtest_logreport\")\n        assert not calls\n\n    def test_class_and_method(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            __test__ = True\n            def test_func():\n                pass\n            test_func.__test__ = False\n\n            class TestSome(object):\n                __test__ = False\n                def test_method(self):\n                    pass\n        \"\"\"\n        )\n        reprec = pytester.inline_run()\n        assert not reprec.getfailedcollections()\n        calls = reprec.getreports(\"pytest_runtest_logreport\")\n        assert not calls\n\n    def test_unittest_class(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            import unittest\n            class TC(unittest.TestCase):\n                def test_1(self):\n                    pass\n            class TC2(unittest.TestCase):\n                __test__ = False\n                def test_2(self):\n                    pass\n        \"\"\"\n        )\n        reprec = pytester.inline_run()\n        assert not reprec.getfailedcollections()\n        call = reprec.getcalls(\"pytest_collection_modifyitems\")[0]\n        assert len(call.items) == 1\n        assert call.items[0].cls.__name__"}, {"start_line": 10000, "end_line": 12000, "belongs_to": {"file_name": "main.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "ion.startpath)\n        if initstate >= 2:\n            try:\n                config.hook.pytest_sessionfinish(\n                    session=session, exitstatus=session.exitstatus\n                )\n            except exit.Exception as exc:\n                if exc.returncode is not None:\n                    session.exitstatus = exc.returncode\n                sys.stderr.write(f\"{type(exc).__name__}: {exc}\\n\")\n        config._ensure_unconfigure()\n    return session.exitstatus\n\n\ndef pytest_cmdline_main(config: Config) -> int | ExitCode:\n    return wrap_session(config, _main)\n\n\ndef _main(config: Config, session: Session) -> int | ExitCode | None:\n    \"\"\"Default command line protocol for initialization, session,\n    running tests and reporting.\"\"\"\n    config.hook.pytest_collection(session=session)\n    config.hook.pytest_runtestloop(session=session)\n\n    if session.testsfailed:\n        return ExitCode.TESTS_FAILED\n    elif session.testscollected == 0:\n        return ExitCode.NO_TESTS_COLLECTED\n    return None\n\n\ndef pytest_collection(session: Session) -> None:\n    session.perform_collect()\n\n\ndef pytest_runtestloop(session: Session) -> bool:\n    if session.testsfailed and not session.config.option.continue_on_collection_errors:\n        raise session.Interrupted(\n            f\"{session.testsfailed} error{'s' if session.testsfailed != 1 else ''} during collection\"\n        )\n\n    if session.config.option.collectonly:\n        return True\n\n    for i, item in enumerate(session.items):\n        nextitem = session.items[i + 1] if i + 1 < len(session.items) else None\n        item.config.hook.pytest_runtest_protocol(item=item, nextitem=nextitem)\n        if session.shouldfail:\n            raise session.Failed(session.shouldfail)\n        if session.shouldstop:\n            raise session.Interrupted(session.shouldstop)\n    return True\n\n\ndef _in_venv(path: Path) -> bool:\n    \"\"\"Attempt to detect if ``path`` is the root of a Virtual Environment by\n    checking for the existence of the pyvenv.cfg "}, {"start_line": 0, "end_line": 2000, "belongs_to": {"file_name": "test_session.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "# mypy: allow-untyped-defs\nfrom __future__ import annotations\n\nfrom _pytest.config import ExitCode\nfrom _pytest.monkeypatch import MonkeyPatch\nfrom _pytest.pytester import Pytester\nimport pytest\n\n\nclass SessionTests:\n    def test_basic_testitem_events(self, pytester: Pytester) -> None:\n        tfile = pytester.makepyfile(\n            \"\"\"\n            def test_one():\n                pass\n            def test_one_one():\n                assert 0\n            def test_other():\n                raise ValueError(23)\n            class TestClass(object):\n                def test_two(self, someargs):\n                    pass\n        \"\"\"\n        )\n        reprec = pytester.inline_run(tfile)\n        passed, skipped, failed = reprec.listoutcomes()\n        assert len(skipped) == 0\n        assert len(passed) == 1\n        assert len(failed) == 3\n\n        def end(x):\n            return x.nodeid.split(\"::\")[-1]\n\n        assert end(failed[0]) == \"test_one_one\"\n        assert end(failed[1]) == \"test_other\"\n        itemstarted = reprec.getcalls(\"pytest_itemcollected\")\n        assert len(itemstarted) == 4\n        # XXX check for failing funcarg setup\n        # colreports = reprec.getcalls(\"pytest_collectreport\")\n        # assert len(colreports) == 4\n        # assert colreports[1].report.failed\n\n    def test_nested_import_error(self, pytester: Pytester) -> None:\n        tfile = pytester.makepyfile(\n            \"\"\"\n            import import_fails\n            def test_this():\n                assert import_fails.a == 1\n        \"\"\",\n            import_fails=\"\"\"\n            import does_not_work\n            a = 1\n        \"\"\",\n        )\n        reprec = pytester.inline_run(tfile)\n        values = reprec.getfailedcollections()\n        assert len(values) == 1\n        out = str(values[0].longrepr)\n        assert out.find(\"does_not_work\") != -1\n\n    def test_raises_output(self, pytester: Pytester) -> None:\n        reprec = pytester.inline_runsource(\n            \"\"\"\n            import pytest\n          "}, {"start_line": 11000, "end_line": 13000, "belongs_to": {"file_name": "test_session.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "]\",\n        \"--deselect=test_a.py::TestClass::test_c1\",\n    )\n    assert result.ret == 0\n    result.stdout.fnmatch_lines([\"*3 passed, 3 deselected*\"])\n    for line in result.stdout.lines:\n        assert not line.startswith((\"test_a.py::test_a2[1]\", \"test_a.py::test_a2[2]\"))\n\n\ndef test_sessionfinish_with_start(pytester: Pytester) -> None:\n    pytester.makeconftest(\n        \"\"\"\n        import os\n        values = []\n        def pytest_sessionstart():\n            values.append(os.getcwd())\n            os.chdir(\"..\")\n\n        def pytest_sessionfinish():\n            assert values[0] == os.getcwd()\n\n    \"\"\"\n    )\n    res = pytester.runpytest(\"--collect-only\")\n    assert res.ret == ExitCode.NO_TESTS_COLLECTED\n\n\ndef test_collection_args_do_not_duplicate_modules(pytester: Pytester) -> None:\n    \"\"\"Test that when multiple collection args are specified on the command line\n    for the same module, only a single Module collector is created.\n\n    Regression test for #723, #3358.\n    \"\"\"\n    pytester.makepyfile(\n        **{\n            \"d/test_it\": \"\"\"\n                def test_1(): pass\n                def test_2(): pass\n                \"\"\"\n        }\n    )\n\n    result = pytester.runpytest(\n        \"--collect-only\",\n        \"d/test_it.py::test_1\",\n        \"d/test_it.py::test_2\",\n    )\n    result.stdout.fnmatch_lines(\n        [\n            \"  <Dir d>\",\n            \"    <Module test_it.py>\",\n            \"      <Function test_1>\",\n            \"      <Function test_2>\",\n        ],\n        consecutive=True,\n    )\n\n    # Different, but related case.\n    result = pytester.runpytest(\n        \"--collect-only\",\n        \"--keep-duplicates\",\n        \"d\",\n        \"d\",\n    )\n    result.stdout.fnmatch_lines(\n        [\n            \"  <Dir d>\",\n            \"    <Module test_it.py>\",\n            \"      <Function test_1>\",\n            \"      <Function test_2>\",\n            \"      <Function test_1>\",\n            \"      <Function test_2>\",\n        ],\n        consecutive=True,\n    )\n\n\n@pytest.mark.parame"}, {"start_line": 77000, "end_line": 79000, "belongs_to": {"file_name": "fixtures.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing/python", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "sed=1)\n\n    def test_scope_session_exc_two_fix(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n            values = []\n            m = []\n            @pytest.fixture(scope=\"session\")\n            def a():\n                values.append(1)\n                pytest.skip('skipping')\n            @pytest.fixture(scope=\"session\")\n            def b(a):\n                m.append(1)\n\n            def test_1(b):\n                pass\n            def test_2(b):\n                pass\n            def test_last():\n                assert values == [1]\n                assert m == []\n        \"\"\"\n        )\n        reprec = pytester.inline_run()\n        reprec.assertoutcome(skipped=2, passed=1)\n\n    def test_scope_exc(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            test_foo=\"\"\"\n                def test_foo(fix):\n                    pass\n            \"\"\",\n            test_bar=\"\"\"\n                def test_bar(fix):\n                    pass\n            \"\"\",\n            conftest=\"\"\"\n                import pytest\n                reqs = []\n                @pytest.fixture(scope=\"session\")\n                def fix(request):\n                    reqs.append(1)\n                    pytest.skip()\n                @pytest.fixture\n                def req_list():\n                    return reqs\n            \"\"\",\n            test_real=\"\"\"\n                def test_last(req_list):\n                    assert req_list == [1]\n            \"\"\",\n        )\n        reprec = pytester.inline_run()\n        reprec.assertoutcome(skipped=2, passed=1)\n\n    def test_scope_module_uses_session(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n            values = []\n            @pytest.fixture(scope=\"module\")\n            def arg():\n                values.append(1)\n                return 1\n\n            def test_1(arg):\n                assert arg == 1\n            def test_2(arg):\n               "}], "retrieved_count": 10, "cost_time": 1.1018548011779785}
{"question": "Why does Pytest's fixture caching system impact memory usage and performance in large test suites?", "answer": null, "relative_code_list": null, "ground_truth": "Pytest's fixture caching system impacts memory usage and performance in large test suites due to several factors: 1) Fixture instances are cached in memory for the duration of their scope (function, class, module, package, session), leading to increased memory consumption as more fixtures are created, 2) Session-scoped fixtures remain in memory for the entire test session, potentially holding large objects or resources that consume significant memory, 3) Fixture dependency chains can create complex caching hierarchies where multiple fixtures are cached simultaneously, multiplying memory usage, 4) Parametrized fixtures create separate cached instances for each parameter value, exponentially increasing memory usage with parameter combinations, 5) Fixture finalization and cleanup operations add overhead as cached fixtures must be properly torn down when their scope ends, 6) Cache key generation and comparison overhead for determining cache hits/misses in large fixture dependency graphs, 7) Memory fragmentation from fixture objects that may have different lifetimes and cleanup schedules, 8) Fixture caching can lead to memory leaks if fixtures hold references to large objects that aren't properly cleaned up, 9) The FixtureDef.cached_result attribute stores fixture values, cache keys, and exception information, consuming memory for each cached fixture, 10) Large test suites with many fixtures can overwhelm the garbage collector, leading to performance degradation, 11) Fixture caching prevents parallel execution of tests that share the same fixture scope, limiting performance optimization opportunities, 12) Memory pressure from cached fixtures can cause system slowdowns and affect overall test execution performance.", "score": null, "retrieved_content": [{"start_line": 48000, "end_line": 50000, "belongs_to": {"file_name": "fixtures.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing/python", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "        DB_INITIALIZED = False\n\n            def setup_module():\n                assert DB_INITIALIZED\n\n            def teardown_module():\n                assert DB_INITIALIZED\n\n            class TestClass(object):\n\n                def setup_method(self, method):\n                    assert DB_INITIALIZED\n\n                def teardown_method(self, method):\n                    assert DB_INITIALIZED\n\n                def test_printer_1(self):\n                    pass\n\n                def test_printer_2(self):\n                    pass\n        \"\"\"\n        )\n        result = pytester.runpytest()\n        result.stdout.fnmatch_lines([\"* 2 passed in *\"])\n\n    def test_parameterized_fixture_caching(self, pytester: Pytester) -> None:\n        \"\"\"Regression test for #12600.\"\"\"\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n            from itertools import count\n\n            CACHE_MISSES = count(0)\n\n            def pytest_generate_tests(metafunc):\n                if \"my_fixture\" in metafunc.fixturenames:\n                    # Use unique objects for parametrization (as opposed to small strings\n                    # and small integers which are singletons).\n                    metafunc.parametrize(\"my_fixture\", [[1], [2]], indirect=True)\n\n            @pytest.fixture(scope='session')\n            def my_fixture(request):\n                next(CACHE_MISSES)\n\n            def test1(my_fixture):\n                pass\n\n            def test2(my_fixture):\n                pass\n\n            def teardown_module():\n                assert next(CACHE_MISSES) == 2\n            \"\"\"\n        )\n        result = pytester.runpytest()\n        result.stdout.no_fnmatch_line(\"* ERROR at teardown *\")\n\n    def test_unwrapping_pytest_fixture(self, pytester: Pytester) -> None:\n        \"\"\"Ensure the unwrap method on `FixtureFunctionDefinition` correctly wraps and unwraps methods and functions\"\"\"\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n            import inspect\n"}, {"start_line": 47000, "end_line": 49000, "belongs_to": {"file_name": "fixtures.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "(fixturefunc, request, kwargs)\n    except TEST_OUTCOME as e:\n        if isinstance(e, skip.Exception):\n            # The test requested a fixture which caused a skip.\n            # Don't show the fixture as the skip location, as then the user\n            # wouldn't know which test skipped.\n            e._use_item_location = True\n        fixturedef.cached_result = (None, my_cache_key, (e, e.__traceback__))\n        raise\n    fixturedef.cached_result = (result, my_cache_key, None)\n    return result\n\n\n@final\n@dataclasses.dataclass(frozen=True)\nclass FixtureFunctionMarker:\n    scope: _ScopeName | Callable[[str, Config], _ScopeName]\n    params: tuple[object, ...] | None\n    autouse: bool = False\n    ids: tuple[object | None, ...] | Callable[[Any], object | None] | None = None\n    name: str | None = None\n\n    _ispytest: dataclasses.InitVar[bool] = False\n\n    def __post_init__(self, _ispytest: bool) -> None:\n        check_ispytest(_ispytest)\n\n    def __call__(self, function: FixtureFunction) -> FixtureFunctionDefinition:\n        if inspect.isclass(function):\n            raise ValueError(\"class fixtures not supported (maybe in the future)\")\n\n        if isinstance(function, FixtureFunctionDefinition):\n            raise ValueError(\n                f\"@pytest.fixture is being applied more than once to the same function {function.__name__!r}\"\n            )\n\n        if hasattr(function, \"pytestmark\"):\n            warnings.warn(MARKED_FIXTURE, stacklevel=2)\n\n        fixture_definition = FixtureFunctionDefinition(\n            function=function, fixture_function_marker=self, _ispytest=True\n        )\n\n        name = self.name or function.__name__\n        if name == \"request\":\n            location = getlocation(function)\n            fail(\n                f\"'request' is a reserved word for fixtures, use another name:\\n  {location}\",\n                pytrace=False,\n            )\n\n        return fixture_definition\n\n\n# TODO: paramspec/return type annotation tracking and storing\nclass Fixtur"}, {"start_line": 0, "end_line": 2000, "belongs_to": {"file_name": "cacheprovider.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "# mypy: allow-untyped-defs\n\"\"\"Implementation of the cache provider.\"\"\"\n\n# This plugin was not named \"cache\" to avoid conflicts with the external\n# pytest-cache version.\nfrom __future__ import annotations\n\nfrom collections.abc import Generator\nfrom collections.abc import Iterable\nimport dataclasses\nimport errno\nimport json\nimport os\nfrom pathlib import Path\nimport tempfile\nfrom typing import final\n\nfrom .pathlib import resolve_from_str\nfrom .pathlib import rm_rf\nfrom .reports import CollectReport\nfrom _pytest import nodes\nfrom _pytest._io import TerminalWriter\nfrom _pytest.config import Config\nfrom _pytest.config import ExitCode\nfrom _pytest.config import hookimpl\nfrom _pytest.config.argparsing import Parser\nfrom _pytest.deprecated import check_ispytest\nfrom _pytest.fixtures import fixture\nfrom _pytest.fixtures import FixtureRequest\nfrom _pytest.main import Session\nfrom _pytest.nodes import Directory\nfrom _pytest.nodes import File\nfrom _pytest.reports import TestReport\n\n\nREADME_CONTENT = \"\"\"\\\n# pytest cache directory #\n\nThis directory contains data from the pytest's cache plugin,\nwhich provides the `--lf` and `--ff` options, as well as the `cache` fixture.\n\n**Do not** commit this to version control.\n\nSee [the docs](https://docs.pytest.org/en/stable/how-to/cache.html) for more information.\n\"\"\"\n\nCACHEDIR_TAG_CONTENT = b\"\"\"\\\nSignature: 8a477f597d28d172789f06886806bc55\n# This file is a cache directory tag created by pytest.\n# For information about cache directory tags, see:\n#\thttps://bford.info/cachedir/spec.html\n\"\"\"\n\n\n@final\n@dataclasses.dataclass\nclass Cache:\n    \"\"\"Instance of the `cache` fixture.\"\"\"\n\n    _cachedir: Path = dataclasses.field(repr=False)\n    _config: Config = dataclasses.field(repr=False)\n\n    # Sub-directory under cache-dir for directories created by `mkdir()`.\n    _CACHE_PREFIX_DIRS = \"d\"\n\n    # Sub-directory under cache-dir for values created by `set()`.\n    _CACHE_PREFIX_VALUES = \"v\"\n\n    def __init__(\n        self, cachedir: Path, config: Config, *"}, {"start_line": 22000, "end_line": 24000, "belongs_to": {"file_name": "fixtures.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing/python", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "\n\n    @pytest.mark.skipif(\n        hasattr(sys, \"pypy_version_info\"),\n        reason=\"this method of test doesn't work on pypy\",\n    )\n    def test_request_garbage(self, pytester: Pytester) -> None:\n        try:\n            import xdist  # noqa: F401\n        except ImportError:\n            pass\n        else:\n            pytest.xfail(\"this test is flaky when executed with xdist\")\n        pytester.makepyfile(\n            \"\"\"\n            import sys\n            import pytest\n            from _pytest.fixtures import PseudoFixtureDef\n            import gc\n\n            @pytest.fixture(autouse=True)\n            def something(request):\n                original = gc.get_debug()\n                gc.set_debug(gc.DEBUG_SAVEALL)\n                gc.collect()\n\n                yield\n\n                try:\n                    gc.collect()\n                    leaked = [x for _ in gc.garbage if isinstance(_, PseudoFixtureDef)]\n                    assert leaked == []\n                finally:\n                    gc.set_debug(original)\n\n            def test_func():\n                pass\n        \"\"\"\n        )\n        result = pytester.runpytest_subprocess()\n        result.stdout.fnmatch_lines([\"* 1 passed in *\"])\n\n    def test_getfixturevalue_recursive(self, pytester: Pytester) -> None:\n        pytester.makeconftest(\n            \"\"\"\n            import pytest\n\n            @pytest.fixture\n            def something(request):\n                return 1\n        \"\"\"\n        )\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n\n            @pytest.fixture\n            def something(request):\n                return request.getfixturevalue(\"something\") + 1\n            def test_func(something):\n                assert something == 2\n        \"\"\"\n        )\n        reprec = pytester.inline_run()\n        reprec.assertoutcome(passed=1)\n\n    def test_getfixturevalue_teardown(self, pytester: Pytester) -> None:\n        \"\"\"\n        Issue #1895\n\n        `test_inner` requests `inner` fixture, whic"}, {"start_line": 1000, "end_line": 3000, "belongs_to": {"file_name": "cacheprovider.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "= \"\"\"\\\n# pytest cache directory #\n\nThis directory contains data from the pytest's cache plugin,\nwhich provides the `--lf` and `--ff` options, as well as the `cache` fixture.\n\n**Do not** commit this to version control.\n\nSee [the docs](https://docs.pytest.org/en/stable/how-to/cache.html) for more information.\n\"\"\"\n\nCACHEDIR_TAG_CONTENT = b\"\"\"\\\nSignature: 8a477f597d28d172789f06886806bc55\n# This file is a cache directory tag created by pytest.\n# For information about cache directory tags, see:\n#\thttps://bford.info/cachedir/spec.html\n\"\"\"\n\n\n@final\n@dataclasses.dataclass\nclass Cache:\n    \"\"\"Instance of the `cache` fixture.\"\"\"\n\n    _cachedir: Path = dataclasses.field(repr=False)\n    _config: Config = dataclasses.field(repr=False)\n\n    # Sub-directory under cache-dir for directories created by `mkdir()`.\n    _CACHE_PREFIX_DIRS = \"d\"\n\n    # Sub-directory under cache-dir for values created by `set()`.\n    _CACHE_PREFIX_VALUES = \"v\"\n\n    def __init__(\n        self, cachedir: Path, config: Config, *, _ispytest: bool = False\n    ) -> None:\n        check_ispytest(_ispytest)\n        self._cachedir = cachedir\n        self._config = config\n\n    @classmethod\n    def for_config(cls, config: Config, *, _ispytest: bool = False) -> Cache:\n        \"\"\"Create the Cache instance for a Config.\n\n        :meta private:\n        \"\"\"\n        check_ispytest(_ispytest)\n        cachedir = cls.cache_dir_from_config(config, _ispytest=True)\n        if config.getoption(\"cacheclear\") and cachedir.is_dir():\n            cls.clear_cache(cachedir, _ispytest=True)\n        return cls(cachedir, config, _ispytest=True)\n\n    @classmethod\n    def clear_cache(cls, cachedir: Path, _ispytest: bool = False) -> None:\n        \"\"\"Clear the sub-directories used to hold cached directories and values.\n\n        :meta private:\n        \"\"\"\n        check_ispytest(_ispytest)\n        for prefix in (cls._CACHE_PREFIX_DIRS, cls._CACHE_PREFIX_VALUES):\n            d = cachedir / prefix\n            if d.is_dir():\n                rm_rf(d)"}, {"start_line": 2000, "end_line": 4000, "belongs_to": {"file_name": "fixtures.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "comes import fail\nfrom _pytest.outcomes import skip\nfrom _pytest.outcomes import TEST_OUTCOME\nfrom _pytest.pathlib import absolutepath\nfrom _pytest.pathlib import bestrelpath\nfrom _pytest.scope import _ScopeName\nfrom _pytest.scope import HIGH_SCOPES\nfrom _pytest.scope import Scope\nfrom _pytest.warning_types import PytestRemovedIn9Warning\nfrom _pytest.warning_types import PytestWarning\n\n\nif sys.version_info < (3, 11):\n    from exceptiongroup import BaseExceptionGroup\n\n\nif TYPE_CHECKING:\n    from _pytest.python import CallSpec2\n    from _pytest.python import Function\n    from _pytest.python import Metafunc\n\n\n# The value of the fixture -- return/yield of the fixture function (type variable).\nFixtureValue = TypeVar(\"FixtureValue\")\n# The type of the fixture function (type variable).\nFixtureFunction = TypeVar(\"FixtureFunction\", bound=Callable[..., object])\n# The type of a fixture function (type alias generic in fixture value).\n_FixtureFunc = Union[\n    Callable[..., FixtureValue], Callable[..., Generator[FixtureValue]]\n]\n# The type of FixtureDef.cached_result (type alias generic in fixture value).\n_FixtureCachedResult = Union[\n    tuple[\n        # The result.\n        FixtureValue,\n        # Cache key.\n        object,\n        None,\n    ],\n    tuple[\n        None,\n        # Cache key.\n        object,\n        # The exception and the original traceback.\n        tuple[BaseException, Optional[types.TracebackType]],\n    ],\n]\n\n\n@dataclasses.dataclass(frozen=True)\nclass PseudoFixtureDef(Generic[FixtureValue]):\n    cached_result: _FixtureCachedResult[FixtureValue]\n    _scope: Scope\n\n\ndef pytest_sessionstart(session: Session) -> None:\n    session._fixturemanager = FixtureManager(session)\n\n\ndef get_scope_package(\n    node: nodes.Item,\n    fixturedef: FixtureDef[object],\n) -> nodes.Node | None:\n    from _pytest.python import Package\n\n    for parent in node.iter_parents():\n        if isinstance(parent, Package) and parent.nodeid == fixturedef.baseid:\n            return parent\n    retur"}, {"start_line": 110000, "end_line": 112000, "belongs_to": {"file_name": "fixtures.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing/python", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "\n                return 1\n            def test_something():\n                pass\n        \"\"\"\n        )\n        result = pytester.runpytest()\n        assert result.ret != 0\n        result.stdout.fnmatch_lines(\n            [\"*def gen(qwe123):*\", \"*fixture*qwe123*not found*\", \"*1 error*\"]\n        )\n\n    def test_cached_exception_doesnt_get_longer(self, pytester: Pytester) -> None:\n        \"\"\"Regression test for #12204.\"\"\"\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n            @pytest.fixture(scope=\"session\")\n            def bad(): 1 / 0\n\n            def test_1(bad): pass\n            def test_2(bad): pass\n            def test_3(bad): pass\n            \"\"\"\n        )\n\n        result = pytester.runpytest_inprocess(\"--tb=native\")\n        assert result.ret == ExitCode.TESTS_FAILED\n        failures = result.reprec.getfailures()  # type: ignore[attr-defined]\n        assert len(failures) == 3\n        lines1 = failures[1].longrepr.reprtraceback.reprentries[0].lines\n        lines2 = failures[2].longrepr.reprtraceback.reprentries[0].lines\n        assert len(lines1) == len(lines2)\n\n\nclass TestShowFixtures:\n    def test_funcarg_compat(self, pytester: Pytester) -> None:\n        config = pytester.parseconfigure(\"--funcargs\")\n        assert config.option.showfixtures\n\n    def test_show_help(self, pytester: Pytester) -> None:\n        result = pytester.runpytest(\"--fixtures\", \"--help\")\n        assert not result.ret\n\n    def test_show_fixtures(self, pytester: Pytester) -> None:\n        result = pytester.runpytest(\"--fixtures\")\n        result.stdout.fnmatch_lines(\n            [\n                \"tmp_path_factory [[]session scope[]] -- .../_pytest/tmpdir.py:*\",\n                \"*for the test session*\",\n                \"tmp_path -- .../_pytest/tmpdir.py:*\",\n                \"*temporary directory*\",\n            ]\n        )\n\n    def test_show_fixtures_verbose(self, pytester: Pytester) -> None:\n        result = pytester.runpytest(\"--fixtures\", \"-v\")\n        result.stdou"}, {"start_line": 47000, "end_line": 49000, "belongs_to": {"file_name": "fixtures.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing/python", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "ope=\"module\", params=f())\n\n            @dec\n            def arg(request):\n                return request.param\n            @dec\n            def arg2(request):\n                return request.param\n\n            def test_1(arg):\n                values.append(arg)\n            def test_2(arg2):\n                values.append(arg2*10)\n        \"\"\"\n        )\n        reprec = pytester.inline_run(\"-v\")\n        reprec.assertoutcome(passed=4)\n        values = reprec.getcalls(\"pytest_runtest_call\")[0].item.module.values\n        assert values == [1, 2, 10, 20]\n\n    def test_setup_functions_as_fixtures(self, pytester: Pytester) -> None:\n        \"\"\"Ensure setup_* methods obey fixture scope rules (#517, #3094).\"\"\"\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n\n            DB_INITIALIZED = None\n\n            @pytest.fixture(scope=\"session\", autouse=True)\n            def db():\n                global DB_INITIALIZED\n                DB_INITIALIZED = True\n                yield\n                DB_INITIALIZED = False\n\n            def setup_module():\n                assert DB_INITIALIZED\n\n            def teardown_module():\n                assert DB_INITIALIZED\n\n            class TestClass(object):\n\n                def setup_method(self, method):\n                    assert DB_INITIALIZED\n\n                def teardown_method(self, method):\n                    assert DB_INITIALIZED\n\n                def test_printer_1(self):\n                    pass\n\n                def test_printer_2(self):\n                    pass\n        \"\"\"\n        )\n        result = pytester.runpytest()\n        result.stdout.fnmatch_lines([\"* 2 passed in *\"])\n\n    def test_parameterized_fixture_caching(self, pytester: Pytester) -> None:\n        \"\"\"Regression test for #12600.\"\"\"\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n            from itertools import count\n\n            CACHE_MISSES = count(0)\n\n            def pytest_generate_tests(metafunc):\n                if \"my_fixtur"}, {"start_line": 3000, "end_line": 5000, "belongs_to": {"file_name": "fixtures.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": ".., Generator[FixtureValue]]\n]\n# The type of FixtureDef.cached_result (type alias generic in fixture value).\n_FixtureCachedResult = Union[\n    tuple[\n        # The result.\n        FixtureValue,\n        # Cache key.\n        object,\n        None,\n    ],\n    tuple[\n        None,\n        # Cache key.\n        object,\n        # The exception and the original traceback.\n        tuple[BaseException, Optional[types.TracebackType]],\n    ],\n]\n\n\n@dataclasses.dataclass(frozen=True)\nclass PseudoFixtureDef(Generic[FixtureValue]):\n    cached_result: _FixtureCachedResult[FixtureValue]\n    _scope: Scope\n\n\ndef pytest_sessionstart(session: Session) -> None:\n    session._fixturemanager = FixtureManager(session)\n\n\ndef get_scope_package(\n    node: nodes.Item,\n    fixturedef: FixtureDef[object],\n) -> nodes.Node | None:\n    from _pytest.python import Package\n\n    for parent in node.iter_parents():\n        if isinstance(parent, Package) and parent.nodeid == fixturedef.baseid:\n            return parent\n    return node.session\n\n\ndef get_scope_node(node: nodes.Node, scope: Scope) -> nodes.Node | None:\n    \"\"\"Get the closest parent node (including self) which matches the given\n    scope.\n\n    If there is no parent node for the scope (e.g. asking for class scope on a\n    Module, or on a Function when not defined in a class), returns None.\n    \"\"\"\n    import _pytest.python\n\n    if scope is Scope.Function:\n        # Type ignored because this is actually safe, see:\n        # https://github.com/python/mypy/issues/4717\n        return node.getparent(nodes.Item)  # type: ignore[type-abstract]\n    elif scope is Scope.Class:\n        return node.getparent(_pytest.python.Class)\n    elif scope is Scope.Module:\n        return node.getparent(_pytest.python.Module)\n    elif scope is Scope.Package:\n        return node.getparent(_pytest.python.Package)\n    elif scope is Scope.Session:\n        return node.getparent(_pytest.main.Session)\n    else:\n        assert_never(scope)\n\n\n# TODO: Try to use FixtureFunctionDefi"}, {"start_line": 43000, "end_line": 45000, "belongs_to": {"file_name": "fixtures.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "y arrays -- #6497).\n                cache_hit = bool(request_cache_key == cache_key)\n            except (ValueError, RuntimeError):\n                # If the comparison raises, use 'is' as fallback.\n                cache_hit = request_cache_key is cache_key\n\n            if cache_hit:\n                if self.cached_result[2] is not None:\n                    exc, exc_tb = self.cached_result[2]\n                    raise exc.with_traceback(exc_tb)\n                else:\n                    return self.cached_result[0]\n            # We have a previous but differently parametrized fixture instance\n            # so we need to tear it down before creating a new one.\n            self.finish(request)\n            assert self.cached_result is None\n\n        # Add finalizer to requested fixtures we saved previously.\n        # We make sure to do this after checking for cached value to avoid\n        # adding our finalizer multiple times. (#12135)\n        finalizer = functools.partial(self.finish, request=request)\n        for parent_fixture in requested_fixtures_that_should_finalize_us:\n            parent_fixture.addfinalizer(finalizer)\n\n        ihook = request.node.ihook\n        try:\n            # Setup the fixture, run the code in it, and cache the value\n            # in self.cached_result.\n            result: FixtureValue = ihook.pytest_fixture_setup(\n                fixturedef=self, request=request\n            )\n        finally:\n            # Schedule our finalizer, even if the setup failed.\n            request.node.addfinalizer(finalizer)\n\n        return result\n\n    def cache_key(self, request: SubRequest) -> object:\n        return getattr(request, \"param\", None)\n\n    def __repr__(self) -> str:\n        return f\"<FixtureDef argname={self.argname!r} scope={self.scope!r} baseid={self.baseid!r}>\"\n\n\ndef resolve_fixture_function(\n    fixturedef: FixtureDef[FixtureValue], request: FixtureRequest\n) -> _FixtureFunc[FixtureValue]:\n    \"\"\"Get the actual callable that can be called to obtain"}], "retrieved_count": 10, "cost_time": 1.1111347675323486}
{"question": "Why does Pytest's assertion rewriting mechanism impact test execution performance compared to traditional assertion libraries?", "answer": null, "relative_code_list": null, "ground_truth": "Pytest's assertion rewriting mechanism impacts test execution performance compared to traditional assertion libraries due to several factors: 1) AST transformation overhead where assert statements are parsed and rewritten into more complex if-else blocks during module import, 2) Additional code execution during assertion evaluation as rewritten assertions execute multiple statements to capture intermediate values and build detailed error messages, 3) Memory overhead from storing rewritten bytecode and maintaining assertion state information, 4) Import hook overhead where the AssertionRewritingHook intercepts module imports to perform rewriting, 5) Caching mechanism overhead for storing and retrieving rewritten .pyc files, 6) Variable creation and management overhead as rewritten assertions create temporary variables to store intermediate values, 7) String formatting overhead for building detailed assertion failure messages with intermediate values, 8) Hook execution overhead when pytest_assertion_pass hook is enabled for passing assertions, 9) File I/O overhead for writing cached rewritten modules to disk, 10) Module loading overhead as rewritten modules are larger and more complex than original modules, 11) Startup time impact as assertion rewriting happens during the import phase before test execution begins, 12) Runtime overhead from executing the more complex rewritten assertion code compared to simple assert statements.", "score": null, "retrieved_content": [{"start_line": 3000, "end_line": 5000, "belongs_to": {"file_name": "test_assertion.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "st():\n                    def check(values, value):\n                        assert values.pop(0) == value\n                    return check\n            \"\"\",\n            \"foo/tests/test_foo.py\": \"\"\"\n                def test(check_first):\n                    check_first([10, 30], 30)\n            \"\"\",\n        }\n        pytester.makepyfile(**contents)\n        result = pytester.runpytest_subprocess(f\"--assert={mode}\")\n        if mode == \"plain\":\n            expected = \"E       AssertionError\"\n        elif mode == \"rewrite\":\n            expected = \"*assert 10 == 30*\"\n        else:\n            assert 0\n        result.stdout.fnmatch_lines([expected])\n\n    def test_rewrite_assertions_pytester_plugin(self, pytester: Pytester) -> None:\n        \"\"\"\n        Assertions in the pytester plugin must also benefit from assertion\n        rewriting (#1920).\n        \"\"\"\n        pytester.makepyfile(\n            \"\"\"\n            pytest_plugins = ['pytester']\n            def test_dummy_failure(pytester):  # how meta!\n                pytester.makepyfile('def test(): assert 0')\n                r = pytester.inline_run()\n                r.assertoutcome(passed=1)\n        \"\"\"\n        )\n        result = pytester.runpytest_subprocess()\n        result.stdout.fnmatch_lines(\n            [\n                \">       r.assertoutcome(passed=1)\",\n                \"E       AssertionError: ([[][]], [[][]], [[]<TestReport *>[]])*\",\n                \"E       assert {'failed': 1,... 'skipped': 0} == {'failed': 0,... 'skipped': 0}\",\n                \"E         Omitting 1 identical items, use -vv to show\",\n                \"E         Differing items:\",\n                \"E         Use -v to get more diff\",\n            ]\n        )\n        # XXX: unstable output.\n        result.stdout.fnmatch_lines_random(\n            [\n                \"E         {'failed': 1} != {'failed': 0}\",\n                \"E         {'passed': 0} != {'passed': 1}\",\n            ]\n        )\n\n    @pytest.mark.parametrize(\"mode\", [\"plain\", \"rewrite\"])\n   "}, {"start_line": 11000, "end_line": 13000, "belongs_to": {"file_name": "test_assertion.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": ":\n            result.assert_outcomes(failed=2)\n            result.stdout.fnmatch_lines([expected, expected])\n        else:\n            result.assert_outcomes(errors=2)\n            result.stdout.fnmatch_lines(\n                [\n                    \"E       fixture 'check_first' not found\",\n                    \"E       fixture 'check_first2' not found\",\n                ]\n            )\n\n    def test_rewrite_ast(self, pytester: Pytester) -> None:\n        pytester.mkdir(\"pkg\")\n        contents = {\n            \"pkg/__init__.py\": \"\"\"\n                import pytest\n                pytest.register_assert_rewrite('pkg.helper')\n            \"\"\",\n            \"pkg/helper.py\": \"\"\"\n                def tool():\n                    a, b = 2, 3\n                    assert a == b\n            \"\"\",\n            \"pkg/plugin.py\": \"\"\"\n                import pytest, pkg.helper\n                @pytest.fixture\n                def tool():\n                    return pkg.helper.tool\n            \"\"\",\n            \"pkg/other.py\": \"\"\"\n                values = [3, 2]\n                def tool():\n                    assert values.pop() == 3\n            \"\"\",\n            \"conftest.py\": \"\"\"\n                pytest_plugins = ['pkg.plugin']\n            \"\"\",\n            \"test_pkg.py\": \"\"\"\n                import pkg.other\n                def test_tool(tool):\n                    tool()\n                def test_other():\n                    pkg.other.tool()\n            \"\"\",\n        }\n        pytester.makepyfile(**contents)\n        result = pytester.runpytest_subprocess(\"--assert=rewrite\")\n        result.stdout.fnmatch_lines(\n            [\n                \">*assert a == b*\",\n                \"E*assert 2 == 3*\",\n                \">*assert values.pop() == 3*\",\n                \"E*AssertionError\",\n            ]\n        )\n\n    def test_register_assert_rewrite_checks_types(self) -> None:\n        with pytest.raises(TypeError):\n            pytest.register_assert_rewrite([\"pytest_tests_internal_non_existing\"])  # type: ignore\n   "}, {"start_line": 10000, "end_line": 12000, "belongs_to": {"file_name": "test_assertion.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "             return spamplugin\n\n            class DummyDistInfo(object):\n                version = '1.0'\n                files = ('spamplugin.py', 'hampkg/__init__.py')\n                entry_points = (DummyEntryPoint(),)\n                metadata = {'name': 'foo'}\n\n            def distributions():\n                return (DummyDistInfo(),)\n\n            importlib.metadata.distributions = distributions\n            pytest.main()\n            \"\"\",\n            \"test_foo.py\": \"\"\"\\\n            def test(check_first):\n                check_first([10, 30], 30)\n\n            def test2(check_first2):\n                check_first2([10, 30], 30)\n            \"\"\",\n        }\n        pytester.makepyfile(**contents)\n        result = pytester.run(sys.executable, *args)\n        if mode == \"plain\":\n            expected = \"E       AssertionError\"\n        elif mode == \"rewrite\":\n            expected = \"*assert 10 == 30*\"\n        else:\n            assert 0\n\n        if not disable_plugin_autoload or explicit_specify:\n            result.assert_outcomes(failed=2)\n            result.stdout.fnmatch_lines([expected, expected])\n        else:\n            result.assert_outcomes(errors=2)\n            result.stdout.fnmatch_lines(\n                [\n                    \"E       fixture 'check_first' not found\",\n                    \"E       fixture 'check_first2' not found\",\n                ]\n            )\n\n    def test_rewrite_ast(self, pytester: Pytester) -> None:\n        pytester.mkdir(\"pkg\")\n        contents = {\n            \"pkg/__init__.py\": \"\"\"\n                import pytest\n                pytest.register_assert_rewrite('pkg.helper')\n            \"\"\",\n            \"pkg/helper.py\": \"\"\"\n                def tool():\n                    a, b = 2, 3\n                    assert a == b\n            \"\"\",\n            \"pkg/plugin.py\": \"\"\"\n                import pytest, pkg.helper\n                @pytest.fixture\n                def tool():\n                    return pkg.helper.tool\n            \"\"\",\n            \"pkg/oth"}, {"start_line": 1000, "end_line": 3000, "belongs_to": {"file_name": "test_assertrewrite.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": " Config\nfrom _pytest.config import ExitCode\nfrom _pytest.pathlib import make_numbered_dir\nfrom _pytest.pytester import Pytester\nimport pytest\n\n\ndef rewrite(src: str) -> ast.Module:\n    tree = ast.parse(src)\n    rewrite_asserts(tree, src.encode())\n    return tree\n\n\ndef getmsg(\n    f, extra_ns: Mapping[str, object] | None = None, *, must_pass: bool = False\n) -> str | None:\n    \"\"\"Rewrite the assertions in f, run it, and get the failure message.\"\"\"\n    src = \"\\n\".join(_pytest._code.Code.from_function(f).source().lines)\n    mod = rewrite(src)\n    code = compile(mod, \"<test>\", \"exec\")\n    ns: dict[str, object] = {}\n    if extra_ns is not None:\n        ns.update(extra_ns)\n    exec(code, ns)\n    func = ns[f.__name__]\n    try:\n        func()  # type: ignore[operator]\n    except AssertionError:\n        if must_pass:\n            pytest.fail(\"shouldn't have raised\")\n        s = str(sys.exc_info()[1])\n        if not s.startswith(\"assert\"):\n            return \"AssertionError: \" + s\n        return s\n    else:\n        if not must_pass:\n            pytest.fail(\"function didn't raise at all\")\n        return None\n\n\nclass TestAssertionRewrite:\n    def test_place_initial_imports(self) -> None:\n        s = \"\"\"'Doc string'\\nother = stuff\"\"\"\n        m = rewrite(s)\n        assert isinstance(m.body[0], ast.Expr)\n        for imp in m.body[1:3]:\n            assert isinstance(imp, ast.Import)\n            assert imp.lineno == 2\n            assert imp.col_offset == 0\n        assert isinstance(m.body[3], ast.Assign)\n        s = \"\"\"from __future__ import division\\nother_stuff\"\"\"\n        m = rewrite(s)\n        assert isinstance(m.body[0], ast.ImportFrom)\n        for imp in m.body[1:3]:\n            assert isinstance(imp, ast.Import)\n            assert imp.lineno == 2\n            assert imp.col_offset == 0\n        assert isinstance(m.body[3], ast.Expr)\n        s = \"\"\"'doc string'\\nfrom __future__ import division\"\"\"\n        m = rewrite(s)\n        assert isinstance(m.body[0], ast.Expr)\n        assert i"}, {"start_line": 0, "end_line": 2000, "belongs_to": {"file_name": "test_assertrewrite.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "# mypy: allow-untyped-defs\nfrom __future__ import annotations\n\nimport ast\nfrom collections.abc import Generator\nfrom collections.abc import Mapping\nimport dis\nimport errno\nfrom functools import partial\nimport glob\nimport importlib\nimport inspect\nimport marshal\nimport os\nfrom pathlib import Path\nimport py_compile\nimport re\nimport stat\nimport sys\nimport textwrap\nfrom typing import cast\nfrom unittest import mock\nimport zipfile\n\nimport _pytest._code\nfrom _pytest._io.saferepr import DEFAULT_REPR_MAX_SIZE\nfrom _pytest.assertion import util\nfrom _pytest.assertion.rewrite import _get_assertion_exprs\nfrom _pytest.assertion.rewrite import _get_maxsize_for_saferepr\nfrom _pytest.assertion.rewrite import _saferepr\nfrom _pytest.assertion.rewrite import AssertionRewritingHook\nfrom _pytest.assertion.rewrite import get_cache_dir\nfrom _pytest.assertion.rewrite import PYC_TAIL\nfrom _pytest.assertion.rewrite import PYTEST_TAG\nfrom _pytest.assertion.rewrite import rewrite_asserts\nfrom _pytest.config import Config\nfrom _pytest.config import ExitCode\nfrom _pytest.pathlib import make_numbered_dir\nfrom _pytest.pytester import Pytester\nimport pytest\n\n\ndef rewrite(src: str) -> ast.Module:\n    tree = ast.parse(src)\n    rewrite_asserts(tree, src.encode())\n    return tree\n\n\ndef getmsg(\n    f, extra_ns: Mapping[str, object] | None = None, *, must_pass: bool = False\n) -> str | None:\n    \"\"\"Rewrite the assertions in f, run it, and get the failure message.\"\"\"\n    src = \"\\n\".join(_pytest._code.Code.from_function(f).source().lines)\n    mod = rewrite(src)\n    code = compile(mod, \"<test>\", \"exec\")\n    ns: dict[str, object] = {}\n    if extra_ns is not None:\n        ns.update(extra_ns)\n    exec(code, ns)\n    func = ns[f.__name__]\n    try:\n        func()  # type: ignore[operator]\n    except AssertionError:\n        if must_pass:\n            pytest.fail(\"shouldn't have raised\")\n        s = str(sys.exc_info()[1])\n        if not s.startswith(\"assert\"):\n            return \"AssertionError: \" + s\n        return s"}, {"start_line": 12000, "end_line": 14000, "belongs_to": {"file_name": "test_assertion.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "er.py\": \"\"\"\n                values = [3, 2]\n                def tool():\n                    assert values.pop() == 3\n            \"\"\",\n            \"conftest.py\": \"\"\"\n                pytest_plugins = ['pkg.plugin']\n            \"\"\",\n            \"test_pkg.py\": \"\"\"\n                import pkg.other\n                def test_tool(tool):\n                    tool()\n                def test_other():\n                    pkg.other.tool()\n            \"\"\",\n        }\n        pytester.makepyfile(**contents)\n        result = pytester.runpytest_subprocess(\"--assert=rewrite\")\n        result.stdout.fnmatch_lines(\n            [\n                \">*assert a == b*\",\n                \"E*assert 2 == 3*\",\n                \">*assert values.pop() == 3*\",\n                \"E*AssertionError\",\n            ]\n        )\n\n    def test_register_assert_rewrite_checks_types(self) -> None:\n        with pytest.raises(TypeError):\n            pytest.register_assert_rewrite([\"pytest_tests_internal_non_existing\"])  # type: ignore\n        pytest.register_assert_rewrite(\n            \"pytest_tests_internal_non_existing\", \"pytest_tests_internal_non_existing2\"\n        )\n\n\nclass TestBinReprIntegration:\n    def test_pytest_assertrepr_compare_called(self, pytester: Pytester) -> None:\n        pytester.makeconftest(\n            \"\"\"\n            import pytest\n            values = []\n            def pytest_assertrepr_compare(op, left, right):\n                values.append((op, left, right))\n\n            @pytest.fixture\n            def list(request):\n                return values\n        \"\"\"\n        )\n        pytester.makepyfile(\n            \"\"\"\n            def test_hello():\n                assert 0 == 1\n            def test_check(list):\n                assert list == [(\"==\", 0, 1)]\n        \"\"\"\n        )\n        result = pytester.runpytest(\"-v\")\n        result.stdout.fnmatch_lines([\"*test_hello*FAIL*\", \"*test_check*PASS*\"])\n\n\ndef callop(op: str, left: Any, right: Any, verbose: int = 0) -> list[str] | None:\n    config = mock_con"}, {"start_line": 9000, "end_line": 11000, "belongs_to": {"file_name": "test_assertrewrite.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "     class T:\n                    def __{name}__(self,other):\n                        loc()\n                        return True\n\n                assert  5 {op} T()\n                assert  (5\n                         {op}\n                         T\n                         ())\n        \"\"\")\n\n        preserved(\"\"\"\n            def func(value):\n                loc(\"func\")\n                return value\n\n            class T:\n                def __iter__(self):\n                    loc(\"iter\")\n                    return iter([5])\n\n            assert  func(*T()) == 5\n        \"\"\")\n\n        preserved(\"\"\"\n            class T:\n                def __getattr__(self,name):\n                    loc()\n                    return name\n\n            assert  T().attr == \"attr\"\n        \"\"\")\n\n    def test_dont_rewrite(self) -> None:\n        s = \"\"\"'PYTEST_DONT_REWRITE'\\nassert 14\"\"\"\n        m = rewrite(s)\n        assert len(m.body) == 2\n        assert isinstance(m.body[1], ast.Assert)\n        assert m.body[1].msg is None\n\n    def test_dont_rewrite_plugin(self, pytester: Pytester) -> None:\n        contents = {\n            \"conftest.py\": \"pytest_plugins = 'plugin'; import plugin\",\n            \"plugin.py\": \"'PYTEST_DONT_REWRITE'\",\n            \"test_foo.py\": \"def test_foo(): pass\",\n        }\n        pytester.makepyfile(**contents)\n        result = pytester.runpytest_subprocess()\n        assert \"warning\" not in \"\".join(result.outlines)\n\n    def test_rewrites_plugin_as_a_package(self, pytester: Pytester) -> None:\n        pkgdir = pytester.mkpydir(\"plugin\")\n        pkgdir.joinpath(\"__init__.py\").write_text(\n            \"import pytest\\n\"\n            \"@pytest.fixture\\n\"\n            \"def special_asserter():\\n\"\n            \"    def special_assert(x, y):\\n\"\n            \"        assert x == y\\n\"\n            \"    return special_assert\\n\",\n            encoding=\"utf-8\",\n        )\n        pytester.makeconftest('pytest_plugins = [\"plugin\"]')\n        pytester.makepyfile(\"def test(special_asserter): special_asser"}, {"start_line": 2000, "end_line": 4000, "belongs_to": {"file_name": "test_assertion.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "       config.get_verbosity(_Config.VERBOSITY_ASSERTIONS)\n            == TestMockConfig.SOME_OTHER_VERBOSITY_LEVEL\n        )\n\n    def test_get_unsupported_type_error(self):\n        config = mock_config(verbose=TestMockConfig.SOME_VERBOSITY_LEVEL)\n\n        with pytest.raises(KeyError):\n            config.get_verbosity(\"--- NOT A VERBOSITY LEVEL ---\")\n\n\nclass TestImportHookInstallation:\n    @pytest.mark.parametrize(\"initial_conftest\", [True, False])\n    @pytest.mark.parametrize(\"mode\", [\"plain\", \"rewrite\"])\n    def test_conftest_assertion_rewrite(\n        self, pytester: Pytester, initial_conftest, mode\n    ) -> None:\n        \"\"\"Test that conftest files are using assertion rewrite on import (#1619).\"\"\"\n        pytester.mkdir(\"foo\")\n        pytester.mkdir(\"foo/tests\")\n        conftest_path = \"conftest.py\" if initial_conftest else \"foo/conftest.py\"\n        contents = {\n            conftest_path: \"\"\"\n                import pytest\n                @pytest.fixture\n                def check_first():\n                    def check(values, value):\n                        assert values.pop(0) == value\n                    return check\n            \"\"\",\n            \"foo/tests/test_foo.py\": \"\"\"\n                def test(check_first):\n                    check_first([10, 30], 30)\n            \"\"\",\n        }\n        pytester.makepyfile(**contents)\n        result = pytester.runpytest_subprocess(f\"--assert={mode}\")\n        if mode == \"plain\":\n            expected = \"E       AssertionError\"\n        elif mode == \"rewrite\":\n            expected = \"*assert 10 == 30*\"\n        else:\n            assert 0\n        result.stdout.fnmatch_lines([expected])\n\n    def test_rewrite_assertions_pytester_plugin(self, pytester: Pytester) -> None:\n        \"\"\"\n        Assertions in the pytester plugin must also benefit from assertion\n        rewriting (#1920).\n        \"\"\"\n        pytester.makepyfile(\n            \"\"\"\n            pytest_plugins = ['pytester']\n            def test_dummy_failure(pytester):  # how "}, {"start_line": 21000, "end_line": 23000, "belongs_to": {"file_name": "rewrite.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest/assertion", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "  seen_lines.add(lineno)\n            # a non-nested comma separates the expression from the message\n            elif depth == 0 and tp == tokenize.OP and source == \",\":\n                # one line assert with message\n                if lineno in seen_lines and len(lines) == 1:\n                    offset_in_trimmed = offset + len(lines[-1]) - len(line)\n                    lines[-1] = lines[-1][:offset_in_trimmed]\n                # multi-line assert with message\n                elif lineno in seen_lines:\n                    lines[-1] = lines[-1][:offset]\n                # multi line assert with escaped newline before message\n                else:\n                    lines.append(line[:offset])\n                _write_and_reset()\n            elif tp in {tokenize.NEWLINE, tokenize.ENDMARKER}:\n                _write_and_reset()\n            elif lines and lineno not in seen_lines:\n                lines.append(line)\n                seen_lines.add(lineno)\n\n    return ret\n\n\nclass AssertionRewriter(ast.NodeVisitor):\n    \"\"\"Assertion rewriting implementation.\n\n    The main entrypoint is to call .run() with an ast.Module instance,\n    this will then find all the assert statements and rewrite them to\n    provide intermediate values and a detailed assertion error.  See\n    http://pybites.blogspot.be/2011/07/behind-scenes-of-pytests-new-assertion.html\n    for an overview of how this works.\n\n    The entry point here is .run() which will iterate over all the\n    statements in an ast.Module and for each ast.Assert statement it\n    finds call .visit() with it.  Then .visit_Assert() takes over and\n    is responsible for creating new ast statements to replace the\n    original assert statement: it rewrites the test of an assertion\n    to provide intermediate values and replace it with an if statement\n    which raises an assertion error with a detailed explanation in\n    case the expression is false and calls pytest_assertion_pass hook\n    if expression is true.\n\n    For this .visit_Assert("}, {"start_line": 0, "end_line": 2000, "belongs_to": {"file_name": "rewrite.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest/assertion", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "\"\"\"Rewrite assertion AST to produce nice error messages.\"\"\"\n\nfrom __future__ import annotations\n\nimport ast\nfrom collections import defaultdict\nfrom collections.abc import Callable\nfrom collections.abc import Iterable\nfrom collections.abc import Iterator\nfrom collections.abc import Sequence\nimport errno\nimport functools\nimport importlib.abc\nimport importlib.machinery\nimport importlib.util\nimport io\nimport itertools\nimport marshal\nimport os\nfrom pathlib import Path\nfrom pathlib import PurePath\nimport struct\nimport sys\nimport tokenize\nimport types\nfrom typing import IO\nfrom typing import TYPE_CHECKING\n\nfrom _pytest._io.saferepr import DEFAULT_REPR_MAX_SIZE\nfrom _pytest._io.saferepr import saferepr\nfrom _pytest._io.saferepr import saferepr_unlimited\nfrom _pytest._version import version\nfrom _pytest.assertion import util\nfrom _pytest.config import Config\nfrom _pytest.fixtures import FixtureFunctionDefinition\nfrom _pytest.main import Session\nfrom _pytest.pathlib import absolutepath\nfrom _pytest.pathlib import fnmatch_ex\nfrom _pytest.stash import StashKey\n\n\n# fmt: off\nfrom _pytest.assertion.util import format_explanation as _format_explanation  # noqa:F401, isort:skip\n# fmt:on\n\nif TYPE_CHECKING:\n    from _pytest.assertion import AssertionState\n\n\nclass Sentinel:\n    pass\n\n\nassertstate_key = StashKey[\"AssertionState\"]()\n\n# pytest caches rewritten pycs in pycache dirs\nPYTEST_TAG = f\"{sys.implementation.cache_tag}-pytest-{version}\"\nPYC_EXT = \".py\" + ((__debug__ and \"c\") or \"o\")\nPYC_TAIL = \".\" + PYTEST_TAG + PYC_EXT\n\n# Special marker that denotes we have just left a scope definition\n_SCOPE_END_MARKER = Sentinel()\n\n\nclass AssertionRewritingHook(importlib.abc.MetaPathFinder, importlib.abc.Loader):\n    \"\"\"PEP302/PEP451 import hook which rewrites asserts.\"\"\"\n\n    def __init__(self, config: Config) -> None:\n        self.config = config\n        try:\n            self.fnpats = config.getini(\"python_files\")\n        except ValueError:\n            self.fnpats = [\"test_*.py\", \"*_test.py\"]"}], "retrieved_count": 10, "cost_time": 1.1219756603240967}
{"question": "What is the relationship between Pytest's hook system and plugin execution order in the test lifecycle?", "answer": null, "relative_code_list": null, "ground_truth": "The relationship between Pytest's hook system and plugin execution order in the test lifecycle is fundamental to how pytest orchestrates test execution. The relationship works as follows: 1) Hook system provides the execution framework where plugins implement hook functions that are called at specific points in the test lifecycle, with execution order controlled by tryfirst/trylast markers and plugin loading order, 2) Plugin execution order is determined by the plugin discovery sequence: command line blocking, built-in plugins, external plugins, environment variables, and conftest files, with later-loaded plugins generally executing after earlier ones, 3) Hook execution follows a 1:N pattern where multiple plugins can implement the same hook specification, with the plugin manager calling all implementations in order, 4) Hook wrappers execute around other hook implementations, providing cross-cutting functionality and allowing pre/post processing of hook results, 5) The test lifecycle is divided into distinct phases (initialization, collection, test running, reporting) with specific hooks for each phase, and plugin execution order affects behavior at each phase, 6) Plugin execution order impacts fixture resolution, as plugins that define fixtures earlier in the loading order may be overridden by later plugins with the same fixture names, 7) Hook execution order affects configuration processing, as plugins that load earlier can influence configuration that affects later plugins, 8) The hook system enables plugin collaboration where plugins can access other plugins through the plugin manager and modify behavior based on execution order, 9) Plugin execution order affects error handling and reporting, as earlier plugins may handle errors that prevent later plugins from executing, 10) The hook system provides hooks like pytest_plugin_registered that allow plugins to be notified when other plugins are loaded, enabling coordination based on execution order, 11) Plugin execution order impacts the overall test execution flow, as plugins that implement critical hooks (like pytest_runtestloop) must execute in the correct order to maintain proper test lifecycle, 12) The relationship ensures that the test lifecycle proceeds in a predictable, coordinated manner while allowing plugins to extend and modify behavior at appropriate points.", "score": null, "retrieved_content": [{"start_line": 45000, "end_line": 47000, "belongs_to": {"file_name": "test_config.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "\n\n    has_loaded = config.pluginmanager.get_plugin(\"mytestplugin\") is not None\n    # it should load if it's enabled, or we haven't disabled autoloading\n    assert has_loaded == (bool(enable_plugin_method) or not disable_plugin_method)\n\n    # The reason for the discrepancy between 'has_loaded' and __loader__ being accessed\n    # appears to be the monkeypatching of importlib.metadata.distributions; where\n    # files being empty means that _mark_plugins_for_rewrite doesn't find the plugin.\n    # But enable_method==flag ends up in mark_rewrite being called and __loader__\n    # being accessed.\n    assert (\"__loader__\" in PseudoPlugin.attrs_used) == (\n        has_loaded\n        and not (enable_plugin_method in (\"env_var\", \"\") and not disable_plugin_method)\n    )\n\n    # __spec__ is accessed in AssertionRewritingHook.exec_module, which would be\n    # eventually called if we did a full pytest run; but it's only accessed with\n    # enable_plugin_method==\"env_var\" because that will early-load it.\n    # Except when autoloads aren't disabled, in which case PytestPluginManager.import_plugin\n    # bails out before importing it.. because it knows it'll be loaded later?\n    # The above seems a bit weird, but I *think* it's true.\n    if platform.python_implementation() != \"PyPy\":\n        assert (\"__spec__\" in PseudoPlugin.attrs_used) == bool(\n            enable_plugin_method == \"env_var\" and disable_plugin_method\n        )\n    # __spec__ is present when testing locally on pypy, but not in CI ????\n\n\ndef test_plugin_loading_order(pytester: Pytester) -> None:\n    \"\"\"Test order of plugin loading with `-p`.\"\"\"\n    p1 = pytester.makepyfile(\n        \"\"\"\n        def test_terminal_plugin(request):\n            import myplugin\n            assert myplugin.terminal_plugin == [False, True]\n        \"\"\",\n        myplugin=\"\"\"\n            terminal_plugin = []\n\n            def pytest_configure(config):\n                terminal_plugin.append(bool(config.pluginmanager.get_plugin(\"terminalreporter\")))\n\n  "}, {"start_line": 128000, "end_line": 130000, "belongs_to": {"file_name": "fixtures.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing/python", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "ytester: Pytester) -> None:\n    pytester.makeconftest(\n        \"\"\"\n        def pytest_fixture_setup(fixturedef, request):\n            print('ROOT setup hook called for {0} from {1}'.format(fixturedef.argname, request.node.name))\n        def pytest_fixture_post_finalizer(fixturedef, request):\n            print('ROOT finalizer hook called for {0} from {1}'.format(fixturedef.argname, request.node.name))\n    \"\"\"\n    )\n    pytester.makepyfile(\n        **{\n            \"tests/conftest.py\": \"\"\"\n            def pytest_fixture_setup(fixturedef, request):\n                print('TESTS setup hook called for {0} from {1}'.format(fixturedef.argname, request.node.name))\n            def pytest_fixture_post_finalizer(fixturedef, request):\n                print('TESTS finalizer hook called for {0} from {1}'.format(fixturedef.argname, request.node.name))\n        \"\"\",\n            \"tests/test_hooks.py\": \"\"\"\n            import pytest\n\n            @pytest.fixture()\n            def my_fixture():\n                return 'some'\n\n            def test_func(my_fixture):\n                print('TEST test_func')\n                assert my_fixture == 'some'\n        \"\"\",\n        }\n    )\n    result = pytester.runpytest(\"-s\")\n    assert result.ret == 0\n    result.stdout.fnmatch_lines(\n        [\n            \"*TESTS setup hook called for my_fixture from test_func*\",\n            \"*ROOT setup hook called for my_fixture from test_func*\",\n            \"*TEST test_func*\",\n            \"*TESTS finalizer hook called for my_fixture from test_func*\",\n            \"*ROOT finalizer hook called for my_fixture from test_func*\",\n        ]\n    )\n\n\nclass TestScopeOrdering:\n    \"\"\"Class of tests that ensure fixtures are ordered based on their scopes (#2405)\"\"\"\n\n    @pytest.mark.parametrize(\"variant\", [\"mark\", \"autouse\"])\n    def test_func_closure_module_auto(\n        self, pytester: Pytester, variant, monkeypatch\n    ) -> None:\n        \"\"\"Semantically identical to the example posted in #2405 when ``use_mark=True``\"\"\"\n        "}, {"start_line": 0, "end_line": 2000, "belongs_to": {"file_name": "test_pluginmanager.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "# mypy: allow-untyped-defs\nfrom __future__ import annotations\n\nimport os\nimport shutil\nimport sys\nimport types\n\nfrom _pytest.config import Config\nfrom _pytest.config import ExitCode\nfrom _pytest.config import PytestPluginManager\nfrom _pytest.config.exceptions import UsageError\nfrom _pytest.main import Session\nfrom _pytest.monkeypatch import MonkeyPatch\nfrom _pytest.pathlib import import_path\nfrom _pytest.pytester import Pytester\nimport pytest\n\n\n@pytest.fixture\ndef pytestpm() -> PytestPluginManager:\n    return PytestPluginManager()\n\n\nclass TestPytestPluginInteractions:\n    def test_addhooks_conftestplugin(\n        self, pytester: Pytester, _config_for_test: Config\n    ) -> None:\n        pytester.makepyfile(\n            newhooks=\"\"\"\n            def pytest_myhook(xyz):\n                \"new hook\"\n        \"\"\"\n        )\n        conf = pytester.makeconftest(\n            \"\"\"\n            import newhooks\n            def pytest_addhooks(pluginmanager):\n                pluginmanager.add_hookspecs(newhooks)\n            def pytest_myhook(xyz):\n                return xyz + 1\n        \"\"\"\n        )\n        config = _config_for_test\n        pm = config.pluginmanager\n        pm.hook.pytest_addhooks.call_historic(\n            kwargs=dict(pluginmanager=config.pluginmanager)\n        )\n        config.pluginmanager._importconftest(\n            conf,\n            importmode=\"prepend\",\n            rootpath=pytester.path,\n            consider_namespace_packages=False,\n        )\n        # print(config.pluginmanager.get_plugins())\n        res = config.hook.pytest_myhook(xyz=10)\n        assert res == [11]\n\n    def test_addhooks_nohooks(self, pytester: Pytester) -> None:\n        pytester.makeconftest(\n            \"\"\"\n            import sys\n            def pytest_addhooks(pluginmanager):\n                pluginmanager.add_hookspecs(sys)\n        \"\"\"\n        )\n        res = pytester.runpytest()\n        assert res.ret != 0\n        res.stderr.fnmatch_lines([\"*did not find*sys*\"])\n\n    def test_do_option"}, {"start_line": 1000, "end_line": 3000, "belongs_to": {"file_name": "hookspec.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "  from _pytest.nodes import Collector\n    from _pytest.nodes import Item\n    from _pytest.outcomes import Exit\n    from _pytest.python import Class\n    from _pytest.python import Function\n    from _pytest.python import Metafunc\n    from _pytest.python import Module\n    from _pytest.reports import CollectReport\n    from _pytest.reports import TestReport\n    from _pytest.runner import CallInfo\n    from _pytest.terminal import TerminalReporter\n    from _pytest.terminal import TestShortLogReport\n\n\nhookspec = HookspecMarker(\"pytest\")\n\n# -------------------------------------------------------------------------\n# Initialization hooks called for every plugin\n# -------------------------------------------------------------------------\n\n\n@hookspec(historic=True)\ndef pytest_addhooks(pluginmanager: PytestPluginManager) -> None:\n    \"\"\"Called at plugin registration time to allow adding new hooks via a call to\n    :func:`pluginmanager.add_hookspecs(module_or_class, prefix) <pytest.PytestPluginManager.add_hookspecs>`.\n\n    :param pluginmanager: The pytest plugin manager.\n\n    .. note::\n        This hook is incompatible with hook wrappers.\n\n    Use in conftest plugins\n    =======================\n\n    If a conftest plugin implements this hook, it will be called immediately\n    when the conftest is registered.\n    \"\"\"\n\n\n@hookspec(historic=True)\ndef pytest_plugin_registered(\n    plugin: _PluggyPlugin,\n    plugin_name: str,\n    manager: PytestPluginManager,\n) -> None:\n    \"\"\"A new pytest plugin got registered.\n\n    :param plugin: The plugin module or instance.\n    :param plugin_name: The name by which the plugin is registered.\n    :param manager: The pytest plugin manager.\n\n    .. note::\n        This hook is incompatible with hook wrappers.\n\n    Use in conftest plugins\n    =======================\n\n    If a conftest plugin implements this hook, it will be called immediately\n    when the conftest is registered, once for each plugin registered thus far\n    (including itself!), and for all "}, {"start_line": 8000, "end_line": 10000, "belongs_to": {"file_name": "test_assertion.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "h: pytest.MonkeyPatch,\n        disable_plugin_autoload: str,\n        explicit_specify: str,\n    ) -> None:\n        args = [\"mainwrapper.py\", \"-s\", f\"--assert={mode}\"]\n        if disable_plugin_autoload == \"env_var\":\n            monkeypatch.setenv(\"PYTEST_DISABLE_PLUGIN_AUTOLOAD\", \"1\")\n        elif disable_plugin_autoload == \"cli\":\n            monkeypatch.delenv(\"PYTEST_DISABLE_PLUGIN_AUTOLOAD\", raising=False)\n            args.append(\"--disable-plugin-autoload\")\n        else:\n            assert disable_plugin_autoload == \"\"\n            monkeypatch.delenv(\"PYTEST_DISABLE_PLUGIN_AUTOLOAD\", raising=False)\n\n        name = \"spamplugin\"\n\n        if explicit_specify == \"env_var\":\n            monkeypatch.setenv(\"PYTEST_PLUGINS\", name)\n        elif explicit_specify == \"cli\":\n            args.append(\"-p\")\n            args.append(name)\n        else:\n            assert explicit_specify == \"\"\n\n        # Make sure the hook is installed early enough so that plugins\n        # installed via distribution package are rewritten.\n        pytester.mkdir(\"hampkg\")\n        contents = {\n            \"hampkg/__init__.py\": \"\"\"\\\n                import pytest\n\n                @pytest.fixture\n                def check_first2():\n                    def check(values, value):\n                        assert values.pop(0) == value\n                    return check\n            \"\"\",\n            \"spamplugin.py\": \"\"\"\\\n            import pytest\n            from hampkg import check_first2\n\n            @pytest.fixture\n            def check_first():\n                def check(values, value):\n                    assert values.pop(0) == value\n                return check\n            \"\"\",\n            \"mainwrapper.py\": \"\"\"\\\n            import importlib.metadata\n            import pytest\n\n            class DummyEntryPoint(object):\n                name = 'spamplugin'\n                module_name = 'spam.py'\n                group = 'pytest11'\n\n                def load(self):\n                    import spamplugin\n       "}, {"start_line": 39000, "end_line": 41000, "belongs_to": {"file_name": "acceptance_test.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "test()\n    assert r.ret == 0\n\n\ndef test_pytest_plugins_as_module(pytester: Pytester) -> None:\n    \"\"\"Do not raise an error if pytest_plugins attribute is a module (#3899)\"\"\"\n    pytester.makepyfile(\n        **{\n            \"__init__.py\": \"\",\n            \"pytest_plugins.py\": \"\",\n            \"conftest.py\": \"from . import pytest_plugins\",\n            \"test_foo.py\": \"def test(): pass\",\n        }\n    )\n    result = pytester.runpytest()\n    result.stdout.fnmatch_lines([\"* 1 passed in *\"])\n\n\ndef test_deferred_hook_checking(pytester: Pytester) -> None:\n    \"\"\"Check hooks as late as possible (#1821).\"\"\"\n    pytester.syspathinsert()\n    pytester.makepyfile(\n        **{\n            \"plugin.py\": \"\"\"\n        class Hooks(object):\n            def pytest_my_hook(self, config):\n                pass\n\n        def pytest_configure(config):\n            config.pluginmanager.add_hookspecs(Hooks)\n        \"\"\",\n            \"conftest.py\": \"\"\"\n            pytest_plugins = ['plugin']\n            def pytest_my_hook(config):\n                return 40\n        \"\"\",\n            \"test_foo.py\": \"\"\"\n            def test(request):\n                assert request.config.hook.pytest_my_hook(config=request.config) == [40]\n        \"\"\",\n        }\n    )\n    result = pytester.runpytest()\n    result.stdout.fnmatch_lines([\"* 1 passed *\"])\n\n\ndef test_fixture_values_leak(pytester: Pytester) -> None:\n    \"\"\"Ensure that fixture objects are properly destroyed by the garbage collector at the end of their expected\n    life-times (#2981).\n    \"\"\"\n    pytester.makepyfile(\n        \"\"\"\n        import dataclasses\n        import gc\n        import pytest\n        import weakref\n\n        @dataclasses.dataclass\n        class SomeObj:\n            name: str\n\n        fix_of_test1_ref = None\n        session_ref = None\n\n        @pytest.fixture(scope='session')\n        def session_fix():\n            global session_ref\n            obj = SomeObj(name='session-fixture')\n            session_ref = weakref.ref(obj)\n            return obj\n\n  "}, {"start_line": 0, "end_line": 2000, "belongs_to": {"file_name": "hookspec.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "# mypy: allow-untyped-defs\n# ruff: noqa: T100\n\"\"\"Hook specifications for pytest plugins which are invoked by pytest itself\nand by builtin plugins.\"\"\"\n\nfrom __future__ import annotations\n\nfrom collections.abc import Mapping\nfrom collections.abc import Sequence\nfrom pathlib import Path\nfrom typing import Any\nfrom typing import TYPE_CHECKING\n\nfrom pluggy import HookspecMarker\n\nfrom .deprecated import HOOK_LEGACY_PATH_ARG\n\n\nif TYPE_CHECKING:\n    import pdb\n    from typing import Literal\n    import warnings\n\n    from _pytest._code.code import ExceptionInfo\n    from _pytest._code.code import ExceptionRepr\n    from _pytest.compat import LEGACY_PATH\n    from _pytest.config import _PluggyPlugin\n    from _pytest.config import Config\n    from _pytest.config import ExitCode\n    from _pytest.config import PytestPluginManager\n    from _pytest.config.argparsing import Parser\n    from _pytest.fixtures import FixtureDef\n    from _pytest.fixtures import SubRequest\n    from _pytest.main import Session\n    from _pytest.nodes import Collector\n    from _pytest.nodes import Item\n    from _pytest.outcomes import Exit\n    from _pytest.python import Class\n    from _pytest.python import Function\n    from _pytest.python import Metafunc\n    from _pytest.python import Module\n    from _pytest.reports import CollectReport\n    from _pytest.reports import TestReport\n    from _pytest.runner import CallInfo\n    from _pytest.terminal import TerminalReporter\n    from _pytest.terminal import TestShortLogReport\n\n\nhookspec = HookspecMarker(\"pytest\")\n\n# -------------------------------------------------------------------------\n# Initialization hooks called for every plugin\n# -------------------------------------------------------------------------\n\n\n@hookspec(historic=True)\ndef pytest_addhooks(pluginmanager: PytestPluginManager) -> None:\n    \"\"\"Called at plugin registration time to allow adding new hooks via a call to\n    :func:`pluginmanager.add_hookspecs(module_or_class, prefix) <pytest.PytestPluginManager"}, {"start_line": 16000, "end_line": 18000, "belongs_to": {"file_name": "__init__.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest/config", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "ict(\n                    plugin=plugin,\n                    plugin_name=plugin_name,\n                    manager=self,\n                )\n            )\n\n            if isinstance(plugin, types.ModuleType):\n                self.consider_module(plugin)\n        return plugin_name\n\n    def getplugin(self, name: str):\n        # Support deprecated naming because plugins (xdist e.g.) use it.\n        plugin: _PluggyPlugin | None = self.get_plugin(name)\n        return plugin\n\n    def hasplugin(self, name: str) -> bool:\n        \"\"\"Return whether a plugin with the given name is registered.\"\"\"\n        return bool(self.get_plugin(name))\n\n    def pytest_configure(self, config: Config) -> None:\n        \"\"\":meta private:\"\"\"\n        # XXX now that the pluginmanager exposes hookimpl(tryfirst...)\n        # we should remove tryfirst/trylast as markers.\n        config.addinivalue_line(\n            \"markers\",\n            \"tryfirst: mark a hook implementation function such that the \"\n            \"plugin machinery will try to call it first/as early as possible. \"\n            \"DEPRECATED, use @pytest.hookimpl(tryfirst=True) instead.\",\n        )\n        config.addinivalue_line(\n            \"markers\",\n            \"trylast: mark a hook implementation function such that the \"\n            \"plugin machinery will try to call it last/as late as possible. \"\n            \"DEPRECATED, use @pytest.hookimpl(trylast=True) instead.\",\n        )\n        self._configured = True\n\n    #\n    # Internal API for local conftest plugin handling.\n    #\n    def _set_initial_conftests(\n        self,\n        args: Sequence[str | pathlib.Path],\n        pyargs: bool,\n        noconftest: bool,\n        rootpath: pathlib.Path,\n        confcutdir: pathlib.Path | None,\n        invocation_dir: pathlib.Path,\n        importmode: ImportMode | str,\n        *,\n        consider_namespace_packages: bool,\n    ) -> None:\n        \"\"\"Load initial conftest files given a preparsed \"namespace\".\n\n        As conftest files may add their own com"}, {"start_line": 23000, "end_line": 25000, "belongs_to": {"file_name": "hookspec.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "nly conftest\n    files in the item's directory and its parent directories are consulted.\n    \"\"\"\n\n\ndef pytest_runtest_logfinish(\n    nodeid: str, location: tuple[str, int | None, str]\n) -> None:\n    \"\"\"Called at the end of running the runtest protocol for a single item.\n\n    See :hook:`pytest_runtest_protocol` for a description of the runtest protocol.\n\n    :param nodeid: Full node ID of the item.\n    :param location: A tuple of ``(filename, lineno, testname)``\n        where ``filename`` is a file path relative to ``config.rootpath``\n        and ``lineno`` is 0-based.\n\n    Use in conftest plugins\n    =======================\n\n    Any conftest file can implement this hook. For a given item, only conftest\n    files in the item's directory and its parent directories are consulted.\n    \"\"\"\n\n\ndef pytest_runtest_setup(item: Item) -> None:\n    \"\"\"Called to perform the setup phase for a test item.\n\n    The default implementation runs ``setup()`` on ``item`` and all of its\n    parents (which haven't been setup yet). This includes obtaining the\n    values of fixtures required by the item (which haven't been obtained\n    yet).\n\n    :param item:\n        The item.\n\n    Use in conftest plugins\n    =======================\n\n    Any conftest file can implement this hook. For a given item, only conftest\n    files in the item's directory and its parent directories are consulted.\n    \"\"\"\n\n\ndef pytest_runtest_call(item: Item) -> None:\n    \"\"\"Called to run the test for test item (the call phase).\n\n    The default implementation calls ``item.runtest()``.\n\n    :param item:\n        The item.\n\n    Use in conftest plugins\n    =======================\n\n    Any conftest file can implement this hook. For a given item, only conftest\n    files in the item's directory and its parent directories are consulted.\n    \"\"\"\n\n\ndef pytest_runtest_teardown(item: Item, nextitem: Item | None) -> None:\n    \"\"\"Called to perform the teardown phase for a test item.\n\n    The default implementation runs the finalizers"}, {"start_line": 29000, "end_line": 31000, "belongs_to": {"file_name": "hookspec.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "def pytest_fixture_post_finalizer(\n    fixturedef: FixtureDef[Any], request: SubRequest\n) -> None:\n    \"\"\"Called after fixture teardown, but before the cache is cleared, so\n    the fixture result ``fixturedef.cached_result`` is still available (not\n    ``None``).\n\n    :param fixturedef:\n        The fixture definition object.\n    :param request:\n        The fixture request object.\n\n    Use in conftest plugins\n    =======================\n\n    Any conftest file can implement this hook. For a given fixture, only\n    conftest files in the fixture scope's directory and its parent directories\n    are consulted.\n    \"\"\"\n\n\n# -------------------------------------------------------------------------\n# test session related hooks\n# -------------------------------------------------------------------------\n\n\ndef pytest_sessionstart(session: Session) -> None:\n    \"\"\"Called after the ``Session`` object has been created and before performing collection\n    and entering the run test loop.\n\n    :param session: The pytest session object.\n\n    Use in conftest plugins\n    =======================\n\n    This hook is only called for :ref:`initial conftests <pluginorder>`.\n    \"\"\"\n\n\ndef pytest_sessionfinish(\n    session: Session,\n    exitstatus: int | ExitCode,\n) -> None:\n    \"\"\"Called after whole test run finished, right before returning the exit status to the system.\n\n    :param session: The pytest session object.\n    :param exitstatus: The status which pytest will return to the system.\n\n    Use in conftest plugins\n    =======================\n\n    Any conftest file can implement this hook.\n    \"\"\"\n\n\ndef pytest_unconfigure(config: Config) -> None:\n    \"\"\"Called before test process is exited.\n\n    :param config: The pytest config object.\n\n    Use in conftest plugins\n    =======================\n\n    Any conftest file can implement this hook.\n    \"\"\"\n\n\n# -------------------------------------------------------------------------\n# hooks for customizing the assert methods\n# ------------------------"}], "retrieved_count": 10, "cost_time": 1.1435298919677734}
{"question": "Why does Pytest implement a plugin-based architecture instead of a monolithic testing framework?", "answer": null, "relative_code_list": null, "ground_truth": "Pytest implements a plugin-based architecture instead of a monolithic testing framework for several key architectural and practical reasons: 1) Plugin-based architecture enables modularity where each piece of functionality is implemented as a separate plugin, making the codebase more maintainable and easier to understand, 2) Plugin system allows for selective feature loading where users only load the plugins they need, reducing memory footprint and startup time, 3) Plugin architecture enables community-driven development where third-party developers can extend pytest without modifying core code, 4) Plugin system provides better separation of concerns where each plugin focuses on specific functionality (collection, execution, reporting, etc.), 5) Plugin-based approach enables easier testing and debugging as individual plugins can be tested in isolation, 6) Plugin architecture supports conditional loading where plugins can be enabled/disabled based on configuration or environment, 7) Plugin system enables better error isolation where a failing plugin doesn't break the entire testing framework, 8) Plugin-based architecture supports the ecosystem of over 1300+ external plugins that extend pytest's functionality, 9) Plugin system enables easier maintenance and updates as individual plugins can be updated independently, 10) Plugin architecture provides better extensibility where new features can be added without modifying core pytest code, 11) Plugin system enables better integration with different testing scenarios and frameworks through specialized plugins, 12) Plugin-based approach creates a more sustainable development model where the core team can focus on essential functionality while the community provides specialized features.", "score": null, "retrieved_content": [{"start_line": 11000, "end_line": 13000, "belongs_to": {"file_name": "__init__.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest/config", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "ed.HOOK_LEGACY_MARKING.format(\n            type=hook_type,\n            fullname=method.__qualname__,\n            hook_opts=hook_opts,\n        )\n        warn_explicit_for(cast(FunctionType, method), message)\n    return opts\n\n\n@final\nclass PytestPluginManager(PluginManager):\n    \"\"\"A :py:class:`pluggy.PluginManager <pluggy.PluginManager>` with\n    additional pytest-specific functionality:\n\n    * Loading plugins from the command line, ``PYTEST_PLUGINS`` env variable and\n      ``pytest_plugins`` global variables found in plugins being loaded.\n    * ``conftest.py`` loading during start-up.\n    \"\"\"\n\n    def __init__(self) -> None:\n        from _pytest.assertion import DummyRewriteHook\n        from _pytest.assertion import RewriteHook\n\n        super().__init__(\"pytest\")\n\n        # -- State related to local conftest plugins.\n        # All loaded conftest modules.\n        self._conftest_plugins: set[types.ModuleType] = set()\n        # All conftest modules applicable for a directory.\n        # This includes the directory's own conftest modules as well\n        # as those of its parent directories.\n        self._dirpath2confmods: dict[pathlib.Path, list[types.ModuleType]] = {}\n        # Cutoff directory above which conftests are no longer discovered.\n        self._confcutdir: pathlib.Path | None = None\n        # If set, conftest loading is skipped.\n        self._noconftest = False\n\n        # _getconftestmodules()'s call to _get_directory() causes a stat\n        # storm when it's called potentially thousands of times in a test\n        # session (#9478), often with the same path, so cache it.\n        self._get_directory = lru_cache(256)(_get_directory)\n\n        # plugins that were explicitly skipped with pytest.skip\n        # list of (module name, skip reason)\n        # previously we would issue a warning when a plugin was skipped, but\n        # since we refactored warnings as first citizens of Config, they are\n        # just stored here to be used later.\n        self.skipped_plu"}, {"start_line": 39000, "end_line": 41000, "belongs_to": {"file_name": "acceptance_test.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "test()\n    assert r.ret == 0\n\n\ndef test_pytest_plugins_as_module(pytester: Pytester) -> None:\n    \"\"\"Do not raise an error if pytest_plugins attribute is a module (#3899)\"\"\"\n    pytester.makepyfile(\n        **{\n            \"__init__.py\": \"\",\n            \"pytest_plugins.py\": \"\",\n            \"conftest.py\": \"from . import pytest_plugins\",\n            \"test_foo.py\": \"def test(): pass\",\n        }\n    )\n    result = pytester.runpytest()\n    result.stdout.fnmatch_lines([\"* 1 passed in *\"])\n\n\ndef test_deferred_hook_checking(pytester: Pytester) -> None:\n    \"\"\"Check hooks as late as possible (#1821).\"\"\"\n    pytester.syspathinsert()\n    pytester.makepyfile(\n        **{\n            \"plugin.py\": \"\"\"\n        class Hooks(object):\n            def pytest_my_hook(self, config):\n                pass\n\n        def pytest_configure(config):\n            config.pluginmanager.add_hookspecs(Hooks)\n        \"\"\",\n            \"conftest.py\": \"\"\"\n            pytest_plugins = ['plugin']\n            def pytest_my_hook(config):\n                return 40\n        \"\"\",\n            \"test_foo.py\": \"\"\"\n            def test(request):\n                assert request.config.hook.pytest_my_hook(config=request.config) == [40]\n        \"\"\",\n        }\n    )\n    result = pytester.runpytest()\n    result.stdout.fnmatch_lines([\"* 1 passed *\"])\n\n\ndef test_fixture_values_leak(pytester: Pytester) -> None:\n    \"\"\"Ensure that fixture objects are properly destroyed by the garbage collector at the end of their expected\n    life-times (#2981).\n    \"\"\"\n    pytester.makepyfile(\n        \"\"\"\n        import dataclasses\n        import gc\n        import pytest\n        import weakref\n\n        @dataclasses.dataclass\n        class SomeObj:\n            name: str\n\n        fix_of_test1_ref = None\n        session_ref = None\n\n        @pytest.fixture(scope='session')\n        def session_fix():\n            global session_ref\n            obj = SomeObj(name='session-fixture')\n            session_ref = weakref.ref(obj)\n            return obj\n\n  "}, {"start_line": 53000, "end_line": 55000, "belongs_to": {"file_name": "acceptance_test.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "    setup(name='my_package', packages=['my_package', 'my_package.plugin'])\n                \"\"\"\n            ),\n            \"my_package/__init__.py\": \"\",\n            \"my_package/conftest.py\": \"\",\n            \"my_package/test_foo.py\": \"def test(): pass\",\n            \"my_package/plugin/__init__.py\": \"\",\n            \"my_package/plugin/my_plugin.py\": (\n                \"\"\"\n                import pytest\n\n                def pytest_configure(config):\n\n                    class SimplePlugin:\n                        @pytest.fixture(params=[1, 2, 3])\n                        def my_fixture(self, request):\n                            yield request.param\n\n                    config.pluginmanager.register(SimplePlugin())\n                \"\"\"\n            ),\n        }\n    )\n\n    subprocess.run(\n        [sys.executable, \"-Im\", \"pip\", \"install\", \"-e\", \".\"],\n        check=True,\n    )\n    try:\n        # We are using subprocess.run rather than pytester.run on purpose.\n        # pytester.run is adding the current directory to PYTHONPATH which avoids\n        # the bug. We also use pytest rather than python -m pytest for the same\n        # PYTHONPATH reason.\n        subprocess.run(\n            [\"pytest\", \"my_package\"],\n            capture_output=True,\n            check=True,\n            encoding=\"utf-8\",\n            text=True,\n        )\n    except subprocess.CalledProcessError as exc:\n        raise AssertionError(\n            f\"pytest command failed:\\n{exc.stdout=!s}\\n{exc.stderr=!s}\"\n        ) from exc\n\n\ndef test_no_terminal_plugin(pytester: Pytester) -> None:\n    \"\"\"Smoke test to ensure pytest can execute without the terminal plugin (#9422).\"\"\"\n    pytester.makepyfile(\"def test(): assert 1 == 2\")\n    result = pytester.runpytest(\"-pno:terminal\", \"-s\")\n    assert result.ret == ExitCode.TESTS_FAILED\n\n\ndef test_stop_iteration_from_collect(pytester: Pytester) -> None:\n    pytester.makepyfile(test_it=\"raise StopIteration('hello')\")\n    result = pytester.runpytest()\n    assert result.ret == ExitCo"}, {"start_line": 8000, "end_line": 10000, "belongs_to": {"file_name": "test_assertion.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "h: pytest.MonkeyPatch,\n        disable_plugin_autoload: str,\n        explicit_specify: str,\n    ) -> None:\n        args = [\"mainwrapper.py\", \"-s\", f\"--assert={mode}\"]\n        if disable_plugin_autoload == \"env_var\":\n            monkeypatch.setenv(\"PYTEST_DISABLE_PLUGIN_AUTOLOAD\", \"1\")\n        elif disable_plugin_autoload == \"cli\":\n            monkeypatch.delenv(\"PYTEST_DISABLE_PLUGIN_AUTOLOAD\", raising=False)\n            args.append(\"--disable-plugin-autoload\")\n        else:\n            assert disable_plugin_autoload == \"\"\n            monkeypatch.delenv(\"PYTEST_DISABLE_PLUGIN_AUTOLOAD\", raising=False)\n\n        name = \"spamplugin\"\n\n        if explicit_specify == \"env_var\":\n            monkeypatch.setenv(\"PYTEST_PLUGINS\", name)\n        elif explicit_specify == \"cli\":\n            args.append(\"-p\")\n            args.append(name)\n        else:\n            assert explicit_specify == \"\"\n\n        # Make sure the hook is installed early enough so that plugins\n        # installed via distribution package are rewritten.\n        pytester.mkdir(\"hampkg\")\n        contents = {\n            \"hampkg/__init__.py\": \"\"\"\\\n                import pytest\n\n                @pytest.fixture\n                def check_first2():\n                    def check(values, value):\n                        assert values.pop(0) == value\n                    return check\n            \"\"\",\n            \"spamplugin.py\": \"\"\"\\\n            import pytest\n            from hampkg import check_first2\n\n            @pytest.fixture\n            def check_first():\n                def check(values, value):\n                    assert values.pop(0) == value\n                return check\n            \"\"\",\n            \"mainwrapper.py\": \"\"\"\\\n            import importlib.metadata\n            import pytest\n\n            class DummyEntryPoint(object):\n                name = 'spamplugin'\n                module_name = 'spam.py'\n                group = 'pytest11'\n\n                def load(self):\n                    import spamplugin\n       "}, {"start_line": 15000, "end_line": 17000, "belongs_to": {"file_name": "pytester.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "during initialization.\n\n    It is particularly useful for testing plugins. It is similar to the :fixture:`tmp_path`\n    fixture but provides methods which aid in testing pytest itself.\n    \"\"\"\n    return Pytester(request, tmp_path_factory, monkeypatch, _ispytest=True)\n\n\n@fixture\ndef _sys_snapshot() -> Generator[None]:\n    snappaths = SysPathsSnapshot()\n    snapmods = SysModulesSnapshot()\n    yield\n    snapmods.restore()\n    snappaths.restore()\n\n\n@fixture\ndef _config_for_test() -> Generator[Config]:\n    from _pytest.config import get_config\n\n    config = get_config()\n    yield config\n    config._ensure_unconfigure()  # cleanup, e.g. capman closing tmpfiles.\n\n\n# Regex to match the session duration string in the summary: \"74.34s\".\nrex_session_duration = re.compile(r\"\\d+\\.\\d\\ds\")\n# Regex to match all the counts and phrases in the summary line: \"34 passed, 111 skipped\".\nrex_outcome = re.compile(r\"(\\d+) (\\w+)\")\n\n\n@final\nclass RunResult:\n    \"\"\"The result of running a command from :class:`~pytest.Pytester`.\"\"\"\n\n    def __init__(\n        self,\n        ret: int | ExitCode,\n        outlines: list[str],\n        errlines: list[str],\n        duration: float,\n    ) -> None:\n        try:\n            self.ret: int | ExitCode = ExitCode(ret)\n            \"\"\"The return value.\"\"\"\n        except ValueError:\n            self.ret = ret\n        self.outlines = outlines\n        \"\"\"List of lines captured from stdout.\"\"\"\n        self.errlines = errlines\n        \"\"\"List of lines captured from stderr.\"\"\"\n        self.stdout = LineMatcher(outlines)\n        \"\"\":class:`~pytest.LineMatcher` of stdout.\n\n        Use e.g. :func:`str(stdout) <pytest.LineMatcher.__str__()>` to reconstruct stdout, or the commonly used\n        :func:`stdout.fnmatch_lines() <pytest.LineMatcher.fnmatch_lines()>` method.\n        \"\"\"\n        self.stderr = LineMatcher(errlines)\n        \"\"\":class:`~pytest.LineMatcher` of stderr.\"\"\"\n        self.duration = duration\n        \"\"\"Duration in seconds.\"\"\"\n\n    def __repr__(self) -> st"}, {"start_line": 4000, "end_line": 6000, "belongs_to": {"file_name": "acceptance_test.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "\")\n\n        pytester.makepyfile(mytestplugin1_module=\"\")\n        pytester.makepyfile(mytestplugin2_module=\"\")\n        pytester.makepyfile(mycov_module=\"\")\n        pytester.syspathinsert()\n\n        loaded = []\n\n        @dataclasses.dataclass\n        class DummyEntryPoint:\n            name: str\n            module: str\n            group: str = \"pytest11\"\n\n            def load(self):\n                __import__(self.module)\n                loaded.append(self.name)\n                return sys.modules[self.module]\n\n        entry_points = [\n            DummyEntryPoint(\"myplugin1\", \"mytestplugin1_module\"),\n            DummyEntryPoint(\"myplugin2\", \"mytestplugin2_module\"),\n            DummyEntryPoint(\"mycov\", \"mycov_module\"),\n        ]\n\n        @dataclasses.dataclass\n        class DummyDist:\n            entry_points: object\n            files: object = ()\n\n        def my_dists():\n            return (DummyDist(entry_points),)\n\n        monkeypatch.setattr(importlib.metadata, \"distributions\", my_dists)\n        params = (\"-p\", \"mycov\") if load_cov_early else ()\n        pytester.runpytest_inprocess(*params)\n        if load_cov_early:\n            assert loaded == [\"mycov\", \"myplugin1\", \"myplugin2\"]\n        else:\n            assert loaded == [\"myplugin1\", \"myplugin2\", \"mycov\"]\n\n    @pytest.mark.parametrize(\"import_mode\", [\"prepend\", \"append\", \"importlib\"])\n    def test_assertion_rewrite(self, pytester: Pytester, import_mode) -> None:\n        p = pytester.makepyfile(\n            \"\"\"\n            def test_this():\n                x = 0\n                assert x\n        \"\"\"\n        )\n        result = pytester.runpytest(p, f\"--import-mode={import_mode}\")\n        result.stdout.fnmatch_lines([\">       assert x\", \"E       assert 0\"])\n        assert result.ret == 1\n\n    def test_nested_import_error(self, pytester: Pytester) -> None:\n        p = pytester.makepyfile(\n            \"\"\"\n                import import_fails\n                def test_this():\n                    assert import_fails.a == 1\n "}, {"start_line": 3000, "end_line": 5000, "belongs_to": {"file_name": "acceptance_test.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "sult.stderr.fnmatch_lines([\"ERROR: file or directory not found: asd\"])\n        result.stdout.fnmatch_lines([\"*---configure\", \"*---unconfigure\"])\n\n    def test_config_preparse_plugin_option(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            pytest_xyz=\"\"\"\n            def pytest_addoption(parser):\n                parser.addoption(\"--xyz\", dest=\"xyz\", action=\"store\")\n        \"\"\"\n        )\n        pytester.makepyfile(\n            test_one=\"\"\"\n            def test_option(pytestconfig):\n                assert pytestconfig.option.xyz == \"123\"\n        \"\"\"\n        )\n        result = pytester.runpytest(\"-p\", \"pytest_xyz\", \"--xyz=123\", syspathinsert=True)\n        assert result.ret == 0\n        result.stdout.fnmatch_lines([\"*1 passed*\"])\n\n    @pytest.mark.parametrize(\"load_cov_early\", [True, False])\n    def test_early_load_setuptools_name(\n        self, pytester: Pytester, monkeypatch, load_cov_early\n    ) -> None:\n        monkeypatch.delenv(\"PYTEST_DISABLE_PLUGIN_AUTOLOAD\")\n\n        pytester.makepyfile(mytestplugin1_module=\"\")\n        pytester.makepyfile(mytestplugin2_module=\"\")\n        pytester.makepyfile(mycov_module=\"\")\n        pytester.syspathinsert()\n\n        loaded = []\n\n        @dataclasses.dataclass\n        class DummyEntryPoint:\n            name: str\n            module: str\n            group: str = \"pytest11\"\n\n            def load(self):\n                __import__(self.module)\n                loaded.append(self.name)\n                return sys.modules[self.module]\n\n        entry_points = [\n            DummyEntryPoint(\"myplugin1\", \"mytestplugin1_module\"),\n            DummyEntryPoint(\"myplugin2\", \"mytestplugin2_module\"),\n            DummyEntryPoint(\"mycov\", \"mycov_module\"),\n        ]\n\n        @dataclasses.dataclass\n        class DummyDist:\n            entry_points: object\n            files: object = ()\n\n        def my_dists():\n            return (DummyDist(entry_points),)\n\n        monkeypatch.setattr(importlib.metadata, \"distributions\", my_dists"}, {"start_line": 13000, "end_line": 15000, "belongs_to": {"file_name": "test_pluginmanager.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "h_lines([\"*1 passed*\"])\n\n    def test_import_plugin_importname(\n        self, pytester: Pytester, pytestpm: PytestPluginManager\n    ) -> None:\n        pytest.raises(ImportError, pytestpm.import_plugin, \"qweqwex.y\")\n        pytest.raises(ImportError, pytestpm.import_plugin, \"pytest_qweqwx.y\")\n\n        pytester.syspathinsert()\n        pluginname = \"pytest_hello\"\n        pytester.makepyfile(**{pluginname: \"\"})\n        pytestpm.import_plugin(\"pytest_hello\")\n        len1 = len(pytestpm.get_plugins())\n        pytestpm.import_plugin(\"pytest_hello\")\n        len2 = len(pytestpm.get_plugins())\n        assert len1 == len2\n        plugin1 = pytestpm.get_plugin(\"pytest_hello\")\n        assert plugin1 is not None\n        assert plugin1.__name__.endswith(\"pytest_hello\")\n        plugin2 = pytestpm.get_plugin(\"pytest_hello\")\n        assert plugin2 is plugin1\n\n    def test_import_plugin_dotted_name(\n        self, pytester: Pytester, pytestpm: PytestPluginManager\n    ) -> None:\n        pytest.raises(ImportError, pytestpm.import_plugin, \"qweqwex.y\")\n        pytest.raises(ImportError, pytestpm.import_plugin, \"pytest_qweqwex.y\")\n\n        pytester.syspathinsert()\n        pytester.mkpydir(\"pkg\").joinpath(\"plug.py\").write_text(\"x=3\", encoding=\"utf-8\")\n        pluginname = \"pkg.plug\"\n        pytestpm.import_plugin(pluginname)\n        mod = pytestpm.get_plugin(\"pkg.plug\")\n        assert mod is not None\n        assert mod.x == 3\n\n    def test_consider_conftest_deps(\n        self,\n        pytester: Pytester,\n        pytestpm: PytestPluginManager,\n    ) -> None:\n        mod = import_path(\n            pytester.makepyfile(\"pytest_plugins='xyz'\"),\n            root=pytester.path,\n            consider_namespace_packages=False,\n        )\n        with pytest.raises(ImportError):\n            pytestpm.consider_conftest(mod, registration_name=\"unused\")\n\n\nclass TestPytestPluginManagerBootstrapping:\n    def test_preparse_args(self, pytestpm: PytestPluginManager) -> None:\n        pytest.raises(\n            Im"}, {"start_line": 44000, "end_line": 46000, "belongs_to": {"file_name": "test_config.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "er__\", \"__spec__\")\n            self.attrs_used.append(name)\n            return object()\n\n    def distributions():\n        return (Distribution(),)\n\n    parse_args: list[str] = []\n\n    if disable_plugin_method == \"env_var\":\n        monkeypatch.setenv(\"PYTEST_DISABLE_PLUGIN_AUTOLOAD\", \"1\")\n    elif disable_plugin_method == \"flag\":\n        monkeypatch.delenv(\"PYTEST_DISABLE_PLUGIN_AUTOLOAD\")\n        parse_args.append(\"--disable-plugin-autoload\")\n    else:\n        assert disable_plugin_method == \"\"\n        monkeypatch.delenv(\"PYTEST_DISABLE_PLUGIN_AUTOLOAD\")\n\n    if enable_plugin_method == \"env_var\":\n        monkeypatch.setenv(\"PYTEST_PLUGINS\", \"mytestplugin\")\n    elif enable_plugin_method == \"flag\":\n        parse_args.extend([\"-p\", \"mytestplugin\"])\n    else:\n        assert enable_plugin_method == \"\"\n\n    monkeypatch.setattr(importlib.metadata, \"distributions\", distributions)\n    monkeypatch.setitem(sys.modules, \"mytestplugin\", PseudoPlugin())\n    config = pytester.parseconfig(*parse_args)\n\n    has_loaded = config.pluginmanager.get_plugin(\"mytestplugin\") is not None\n    # it should load if it's enabled, or we haven't disabled autoloading\n    assert has_loaded == (bool(enable_plugin_method) or not disable_plugin_method)\n\n    # The reason for the discrepancy between 'has_loaded' and __loader__ being accessed\n    # appears to be the monkeypatching of importlib.metadata.distributions; where\n    # files being empty means that _mark_plugins_for_rewrite doesn't find the plugin.\n    # But enable_method==flag ends up in mark_rewrite being called and __loader__\n    # being accessed.\n    assert (\"__loader__\" in PseudoPlugin.attrs_used) == (\n        has_loaded\n        and not (enable_plugin_method in (\"env_var\", \"\") and not disable_plugin_method)\n    )\n\n    # __spec__ is accessed in AssertionRewritingHook.exec_module, which would be\n    # eventually called if we did a full pytest run; but it's only accessed with\n    # enable_plugin_method==\"env_var\" because that will early-load it."}, {"start_line": 39000, "end_line": 41000, "belongs_to": {"file_name": "test_config.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "f test_options_on_small_file_do_not_blow_up(pytester: Pytester) -> None:\n    def runfiletest(opts: Sequence[str]) -> None:\n        reprec = pytester.inline_run(*opts)\n        passed, skipped, failed = reprec.countoutcomes()\n        assert failed == 2\n        assert skipped == passed == 0\n\n    path = str(\n        pytester.makepyfile(\n            \"\"\"\n        def test_f1(): assert 0\n        def test_f2(): assert 0\n    \"\"\"\n        )\n    )\n\n    runfiletest([path])\n    runfiletest([\"-l\", path])\n    runfiletest([\"-s\", path])\n    runfiletest([\"--tb=no\", path])\n    runfiletest([\"--tb=short\", path])\n    runfiletest([\"--tb=long\", path])\n    runfiletest([\"--fulltrace\", path])\n    runfiletest([\"--traceconfig\", path])\n    runfiletest([\"-v\", path])\n    runfiletest([\"-v\", \"-v\", path])\n\n\ndef test_preparse_ordering_with_setuptools(\n    pytester: Pytester, monkeypatch: MonkeyPatch\n) -> None:\n    monkeypatch.delenv(\"PYTEST_DISABLE_PLUGIN_AUTOLOAD\", raising=False)\n\n    class EntryPoint:\n        name = \"mytestplugin\"\n        group = \"pytest11\"\n\n        def load(self):\n            class PseudoPlugin:\n                x = 42\n\n            return PseudoPlugin()\n\n    class Dist:\n        files = ()\n        metadata = {\"name\": \"foo\"}\n        entry_points = (EntryPoint(),)\n\n    def my_dists():\n        return (Dist,)\n\n    monkeypatch.setattr(importlib.metadata, \"distributions\", my_dists)\n    pytester.makeconftest(\n        \"\"\"\n        pytest_plugins = \"mytestplugin\",\n    \"\"\"\n    )\n    monkeypatch.setenv(\"PYTEST_PLUGINS\", \"mytestplugin\")\n    config = pytester.parseconfig()\n    plugin = config.pluginmanager.getplugin(\"mytestplugin\")\n    assert plugin.x == 42\n\n\ndef test_setuptools_importerror_issue1479(\n    pytester: Pytester, monkeypatch: MonkeyPatch\n) -> None:\n    monkeypatch.delenv(\"PYTEST_DISABLE_PLUGIN_AUTOLOAD\", raising=False)\n\n    class DummyEntryPoint:\n        name = \"mytestplugin\"\n        group = \"pytest11\"\n\n        def load(self):\n            raise ImportError(\"Don't hide me!\")\n\n    class Di"}], "retrieved_count": 10, "cost_time": 1.1935837268829346}
{"question": "Where does Pytest's plugin system flow from plugin registration through hook execution to result collection?", "answer": null, "relative_code_list": null, "ground_truth": "Pytest's plugin system flow follows a structured sequence from plugin registration through hook execution to result collection: 1) Plugin discovery and registration phase begins with scanning command line for -p no:name options to block plugins, followed by loading builtin plugins, then external plugins through entry points, and finally conftest.py plugins, 2) Plugin registration occurs through PytestPluginManager.register() which adds plugins to the plugin manager and triggers pytest_plugin_registered hook for notification, 3) Hook specification registration happens when plugins define hook functions with pytest_ prefix, which are automatically discovered and registered with the plugin manager, 4) Hook execution follows a 1:N pattern where multiple plugins can implement the same hook specification, with execution order controlled by tryfirst/trylast markers, 5) Hook wrappers execute around other hook implementations, providing cross-cutting functionality and allowing pre/post processing of hook results, 6) Hook execution phases include bootstrapping hooks (pytest_cmdline_parse), initialization hooks (pytest_configure), collection hooks (pytest_collection), test running hooks (pytest_runtestloop), and reporting hooks (pytest_runtest_logreport), 7) Result collection occurs through TestReport objects that are created during test execution and passed to reporting hooks for processing, 8) Plugin system integrates with the main execution flow through hooks like pytest_cmdline_main which orchestrates the overall test execution process, 9) Hook results are collected and processed according to hook specifications, with firstresult hooks stopping at the first non-None result, 10) Plugin communication happens through the plugin manager's hook system, allowing plugins to interact and share data, 11) Error handling and exception propagation occurs through the hook system, with proper cleanup and reporting mechanisms, 12) The entire plugin system is built on the pluggy library, providing a robust foundation for extensible plugin architecture.", "score": null, "retrieved_content": [{"start_line": 1000, "end_line": 3000, "belongs_to": {"file_name": "hookspec.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "  from _pytest.nodes import Collector\n    from _pytest.nodes import Item\n    from _pytest.outcomes import Exit\n    from _pytest.python import Class\n    from _pytest.python import Function\n    from _pytest.python import Metafunc\n    from _pytest.python import Module\n    from _pytest.reports import CollectReport\n    from _pytest.reports import TestReport\n    from _pytest.runner import CallInfo\n    from _pytest.terminal import TerminalReporter\n    from _pytest.terminal import TestShortLogReport\n\n\nhookspec = HookspecMarker(\"pytest\")\n\n# -------------------------------------------------------------------------\n# Initialization hooks called for every plugin\n# -------------------------------------------------------------------------\n\n\n@hookspec(historic=True)\ndef pytest_addhooks(pluginmanager: PytestPluginManager) -> None:\n    \"\"\"Called at plugin registration time to allow adding new hooks via a call to\n    :func:`pluginmanager.add_hookspecs(module_or_class, prefix) <pytest.PytestPluginManager.add_hookspecs>`.\n\n    :param pluginmanager: The pytest plugin manager.\n\n    .. note::\n        This hook is incompatible with hook wrappers.\n\n    Use in conftest plugins\n    =======================\n\n    If a conftest plugin implements this hook, it will be called immediately\n    when the conftest is registered.\n    \"\"\"\n\n\n@hookspec(historic=True)\ndef pytest_plugin_registered(\n    plugin: _PluggyPlugin,\n    plugin_name: str,\n    manager: PytestPluginManager,\n) -> None:\n    \"\"\"A new pytest plugin got registered.\n\n    :param plugin: The plugin module or instance.\n    :param plugin_name: The name by which the plugin is registered.\n    :param manager: The pytest plugin manager.\n\n    .. note::\n        This hook is incompatible with hook wrappers.\n\n    Use in conftest plugins\n    =======================\n\n    If a conftest plugin implements this hook, it will be called immediately\n    when the conftest is registered, once for each plugin registered thus far\n    (including itself!), and for all "}, {"start_line": 0, "end_line": 2000, "belongs_to": {"file_name": "hookspec.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "# mypy: allow-untyped-defs\n# ruff: noqa: T100\n\"\"\"Hook specifications for pytest plugins which are invoked by pytest itself\nand by builtin plugins.\"\"\"\n\nfrom __future__ import annotations\n\nfrom collections.abc import Mapping\nfrom collections.abc import Sequence\nfrom pathlib import Path\nfrom typing import Any\nfrom typing import TYPE_CHECKING\n\nfrom pluggy import HookspecMarker\n\nfrom .deprecated import HOOK_LEGACY_PATH_ARG\n\n\nif TYPE_CHECKING:\n    import pdb\n    from typing import Literal\n    import warnings\n\n    from _pytest._code.code import ExceptionInfo\n    from _pytest._code.code import ExceptionRepr\n    from _pytest.compat import LEGACY_PATH\n    from _pytest.config import _PluggyPlugin\n    from _pytest.config import Config\n    from _pytest.config import ExitCode\n    from _pytest.config import PytestPluginManager\n    from _pytest.config.argparsing import Parser\n    from _pytest.fixtures import FixtureDef\n    from _pytest.fixtures import SubRequest\n    from _pytest.main import Session\n    from _pytest.nodes import Collector\n    from _pytest.nodes import Item\n    from _pytest.outcomes import Exit\n    from _pytest.python import Class\n    from _pytest.python import Function\n    from _pytest.python import Metafunc\n    from _pytest.python import Module\n    from _pytest.reports import CollectReport\n    from _pytest.reports import TestReport\n    from _pytest.runner import CallInfo\n    from _pytest.terminal import TerminalReporter\n    from _pytest.terminal import TestShortLogReport\n\n\nhookspec = HookspecMarker(\"pytest\")\n\n# -------------------------------------------------------------------------\n# Initialization hooks called for every plugin\n# -------------------------------------------------------------------------\n\n\n@hookspec(historic=True)\ndef pytest_addhooks(pluginmanager: PytestPluginManager) -> None:\n    \"\"\"Called at plugin registration time to allow adding new hooks via a call to\n    :func:`pluginmanager.add_hookspecs(module_or_class, prefix) <pytest.PytestPluginManager"}, {"start_line": 0, "end_line": 2000, "belongs_to": {"file_name": "test_pluginmanager.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "# mypy: allow-untyped-defs\nfrom __future__ import annotations\n\nimport os\nimport shutil\nimport sys\nimport types\n\nfrom _pytest.config import Config\nfrom _pytest.config import ExitCode\nfrom _pytest.config import PytestPluginManager\nfrom _pytest.config.exceptions import UsageError\nfrom _pytest.main import Session\nfrom _pytest.monkeypatch import MonkeyPatch\nfrom _pytest.pathlib import import_path\nfrom _pytest.pytester import Pytester\nimport pytest\n\n\n@pytest.fixture\ndef pytestpm() -> PytestPluginManager:\n    return PytestPluginManager()\n\n\nclass TestPytestPluginInteractions:\n    def test_addhooks_conftestplugin(\n        self, pytester: Pytester, _config_for_test: Config\n    ) -> None:\n        pytester.makepyfile(\n            newhooks=\"\"\"\n            def pytest_myhook(xyz):\n                \"new hook\"\n        \"\"\"\n        )\n        conf = pytester.makeconftest(\n            \"\"\"\n            import newhooks\n            def pytest_addhooks(pluginmanager):\n                pluginmanager.add_hookspecs(newhooks)\n            def pytest_myhook(xyz):\n                return xyz + 1\n        \"\"\"\n        )\n        config = _config_for_test\n        pm = config.pluginmanager\n        pm.hook.pytest_addhooks.call_historic(\n            kwargs=dict(pluginmanager=config.pluginmanager)\n        )\n        config.pluginmanager._importconftest(\n            conf,\n            importmode=\"prepend\",\n            rootpath=pytester.path,\n            consider_namespace_packages=False,\n        )\n        # print(config.pluginmanager.get_plugins())\n        res = config.hook.pytest_myhook(xyz=10)\n        assert res == [11]\n\n    def test_addhooks_nohooks(self, pytester: Pytester) -> None:\n        pytester.makeconftest(\n            \"\"\"\n            import sys\n            def pytest_addhooks(pluginmanager):\n                pluginmanager.add_hookspecs(sys)\n        \"\"\"\n        )\n        res = pytester.runpytest()\n        assert res.ret != 0\n        res.stderr.fnmatch_lines([\"*did not find*sys*\"])\n\n    def test_do_option"}, {"start_line": 13000, "end_line": 15000, "belongs_to": {"file_name": "__init__.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest/config", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "gins: list[tuple[str, str]] = []\n\n        self.add_hookspecs(_pytest.hookspec)\n        self.register(self)\n        if os.environ.get(\"PYTEST_DEBUG\"):\n            err: IO[str] = sys.stderr\n            encoding: str = getattr(err, \"encoding\", \"utf8\")\n            try:\n                err = open(\n                    os.dup(err.fileno()),\n                    mode=err.mode,\n                    buffering=1,\n                    encoding=encoding,\n                )\n            except Exception:\n                pass\n            self.trace.root.setwriter(err.write)\n            self.enable_tracing()\n\n        # Config._consider_importhook will set a real object if required.\n        self.rewrite_hook: RewriteHook = DummyRewriteHook()\n        # Used to know when we are importing conftests after the pytest_configure stage.\n        self._configured = False\n\n    def parse_hookimpl_opts(\n        self, plugin: _PluggyPlugin, name: str\n    ) -> HookimplOpts | None:\n        \"\"\":meta private:\"\"\"\n        # pytest hooks are always prefixed with \"pytest_\",\n        # so we avoid accessing possibly non-readable attributes\n        # (see issue #1073).\n        if not name.startswith(\"pytest_\"):\n            return None\n        # Ignore names which cannot be hooks.\n        if name == \"pytest_plugins\":\n            return None\n\n        opts = super().parse_hookimpl_opts(plugin, name)\n        if opts is not None:\n            return opts\n\n        method = getattr(plugin, name)\n        # Consider only actual functions for hooks (#3775).\n        if not inspect.isroutine(method):\n            return None\n        # Collect unmarked hooks as long as they have the `pytest_' prefix.\n        legacy = _get_legacy_hook_marks(\n            method, \"impl\", (\"tryfirst\", \"trylast\", \"optionalhook\", \"hookwrapper\")\n        )\n        return cast(HookimplOpts, legacy)\n\n    def parse_hookspec_opts(self, module_or_class, name: str) -> HookspecOpts | None:\n        \"\"\":meta private:\"\"\"\n        opts = super().parse_hookspec_op"}, {"start_line": 14000, "end_line": 16000, "belongs_to": {"file_name": "__init__.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest/config", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "test hooks are always prefixed with \"pytest_\",\n        # so we avoid accessing possibly non-readable attributes\n        # (see issue #1073).\n        if not name.startswith(\"pytest_\"):\n            return None\n        # Ignore names which cannot be hooks.\n        if name == \"pytest_plugins\":\n            return None\n\n        opts = super().parse_hookimpl_opts(plugin, name)\n        if opts is not None:\n            return opts\n\n        method = getattr(plugin, name)\n        # Consider only actual functions for hooks (#3775).\n        if not inspect.isroutine(method):\n            return None\n        # Collect unmarked hooks as long as they have the `pytest_' prefix.\n        legacy = _get_legacy_hook_marks(\n            method, \"impl\", (\"tryfirst\", \"trylast\", \"optionalhook\", \"hookwrapper\")\n        )\n        return cast(HookimplOpts, legacy)\n\n    def parse_hookspec_opts(self, module_or_class, name: str) -> HookspecOpts | None:\n        \"\"\":meta private:\"\"\"\n        opts = super().parse_hookspec_opts(module_or_class, name)\n        if opts is None:\n            method = getattr(module_or_class, name)\n            if name.startswith(\"pytest_\"):\n                legacy = _get_legacy_hook_marks(\n                    method, \"spec\", (\"firstresult\", \"historic\")\n                )\n                opts = cast(HookspecOpts, legacy)\n        return opts\n\n    def register(self, plugin: _PluggyPlugin, name: str | None = None) -> str | None:\n        if name in _pytest.deprecated.DEPRECATED_EXTERNAL_PLUGINS:\n            warnings.warn(\n                PytestConfigWarning(\n                    \"{} plugin has been merged into the core, \"\n                    \"please remove it from your requirements.\".format(\n                        name.replace(\"_\", \"-\")\n                    )\n                )\n            )\n            return None\n        plugin_name = super().register(plugin, name)\n        if plugin_name is not None:\n            self.hook.pytest_plugin_registered.call_historic(\n                kwargs=d"}, {"start_line": 6000, "end_line": 8000, "belongs_to": {"file_name": "hookspec.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "se in conftest plugins\n    =======================\n\n    This hook is not called for conftest files.\n    \"\"\"\n\n\ndef pytest_load_initial_conftests(\n    early_config: Config, parser: Parser, args: list[str]\n) -> None:\n    \"\"\"Called to implement the loading of :ref:`initial conftest files\n    <pluginorder>` ahead of command line option parsing.\n\n    :param early_config: The pytest config object.\n    :param args: Arguments passed on the command line.\n    :param parser: To add command line options.\n\n    Use in conftest plugins\n    =======================\n\n    This hook is not called for conftest files.\n    \"\"\"\n\n\n@hookspec(firstresult=True)\ndef pytest_cmdline_main(config: Config) -> ExitCode | int | None:\n    \"\"\"Called for performing the main command line action.\n\n    The default implementation will invoke the configure hooks and\n    :hook:`pytest_runtestloop`.\n\n    Stops at first non-None result, see :ref:`firstresult`.\n\n    :param config: The pytest config object.\n    :returns: The exit code.\n\n    Use in conftest plugins\n    =======================\n\n    This hook is only called for :ref:`initial conftests <pluginorder>`.\n    \"\"\"\n\n\n# -------------------------------------------------------------------------\n# collection hooks\n# -------------------------------------------------------------------------\n\n\n@hookspec(firstresult=True)\ndef pytest_collection(session: Session) -> object | None:\n    \"\"\"Perform the collection phase for the given session.\n\n    Stops at first non-None result, see :ref:`firstresult`.\n    The return value is not used, but only stops further processing.\n\n    The default collection phase is this (see individual hooks for full details):\n\n    1. Starting from ``session`` as the initial collector:\n\n      1. ``pytest_collectstart(collector)``\n      2. ``report = pytest_make_collect_report(collector)``\n      3. ``pytest_exception_interact(collector, call, report)`` if an interactive exception occurred\n      4. For each collected node:\n\n        1. If an item, ``"}, {"start_line": 51000, "end_line": 53000, "belongs_to": {"file_name": "test_config.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "   (\n            hookimpl.function.__module__,\n            \"wrapper\" if (hookimpl.wrapper or hookimpl.hookwrapper) else \"nonwrapper\",\n        )\n        for hookimpl in hc.get_hookimpls()\n    ]\n    assert hookimpls == [\n        (\"_pytest.config\", \"nonwrapper\"),\n        (m.__module__, \"nonwrapper\"),\n        (\"_pytest.legacypath\", \"nonwrapper\"),\n        (\"_pytest.capture\", \"wrapper\"),\n        (\"_pytest.warnings\", \"wrapper\"),\n    ]\n\n\ndef test_get_plugin_specs_as_list() -> None:\n    def exp_match(val: object) -> str:\n        return (\n            f\"Plugins may be specified as a sequence or a ','-separated string \"\n            f\"of plugin names. Got: {re.escape(repr(val))}\"\n        )\n\n    with pytest.raises(pytest.UsageError, match=exp_match({\"foo\"})):\n        _get_plugin_specs_as_list({\"foo\"})  # type: ignore[arg-type]\n    with pytest.raises(pytest.UsageError, match=exp_match({})):\n        _get_plugin_specs_as_list(dict())  # type: ignore[arg-type]\n\n    assert _get_plugin_specs_as_list(None) == []\n    assert _get_plugin_specs_as_list(\"\") == []\n    assert _get_plugin_specs_as_list(\"foo\") == [\"foo\"]\n    assert _get_plugin_specs_as_list(\"foo,bar\") == [\"foo\", \"bar\"]\n    assert _get_plugin_specs_as_list([\"foo\", \"bar\"]) == [\"foo\", \"bar\"]\n    assert _get_plugin_specs_as_list((\"foo\", \"bar\")) == [\"foo\", \"bar\"]\n\n\ndef test_collect_pytest_prefix_bug_integration(pytester: Pytester) -> None:\n    \"\"\"Integration test for issue #3775\"\"\"\n    p = pytester.copy_example(\"config/collect_pytest_prefix\")\n    result = pytester.runpytest(p)\n    result.stdout.fnmatch_lines([\"* 1 passed *\"])\n\n\ndef test_collect_pytest_prefix_bug(pytestconfig):\n    \"\"\"Ensure we collect only actual functions from conftest files (#3775)\"\"\"\n\n    class Dummy:\n        class pytest_something:\n            pass\n\n    pm = pytestconfig.pluginmanager\n    assert pm.parse_hookimpl_opts(Dummy(), \"pytest_something\") is None\n\n\nclass TestRootdir:\n    def test_simple_noini(self, tmp_path: Path, monkeypatch: MonkeyPatch) -> None:\n      "}, {"start_line": 39000, "end_line": 41000, "belongs_to": {"file_name": "acceptance_test.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "test()\n    assert r.ret == 0\n\n\ndef test_pytest_plugins_as_module(pytester: Pytester) -> None:\n    \"\"\"Do not raise an error if pytest_plugins attribute is a module (#3899)\"\"\"\n    pytester.makepyfile(\n        **{\n            \"__init__.py\": \"\",\n            \"pytest_plugins.py\": \"\",\n            \"conftest.py\": \"from . import pytest_plugins\",\n            \"test_foo.py\": \"def test(): pass\",\n        }\n    )\n    result = pytester.runpytest()\n    result.stdout.fnmatch_lines([\"* 1 passed in *\"])\n\n\ndef test_deferred_hook_checking(pytester: Pytester) -> None:\n    \"\"\"Check hooks as late as possible (#1821).\"\"\"\n    pytester.syspathinsert()\n    pytester.makepyfile(\n        **{\n            \"plugin.py\": \"\"\"\n        class Hooks(object):\n            def pytest_my_hook(self, config):\n                pass\n\n        def pytest_configure(config):\n            config.pluginmanager.add_hookspecs(Hooks)\n        \"\"\",\n            \"conftest.py\": \"\"\"\n            pytest_plugins = ['plugin']\n            def pytest_my_hook(config):\n                return 40\n        \"\"\",\n            \"test_foo.py\": \"\"\"\n            def test(request):\n                assert request.config.hook.pytest_my_hook(config=request.config) == [40]\n        \"\"\",\n        }\n    )\n    result = pytester.runpytest()\n    result.stdout.fnmatch_lines([\"* 1 passed *\"])\n\n\ndef test_fixture_values_leak(pytester: Pytester) -> None:\n    \"\"\"Ensure that fixture objects are properly destroyed by the garbage collector at the end of their expected\n    life-times (#2981).\n    \"\"\"\n    pytester.makepyfile(\n        \"\"\"\n        import dataclasses\n        import gc\n        import pytest\n        import weakref\n\n        @dataclasses.dataclass\n        class SomeObj:\n            name: str\n\n        fix_of_test1_ref = None\n        session_ref = None\n\n        @pytest.fixture(scope='session')\n        def session_fix():\n            global session_ref\n            obj = SomeObj(name='session-fixture')\n            session_ref = weakref.ref(obj)\n            return obj\n\n  "}, {"start_line": 5000, "end_line": 7000, "belongs_to": {"file_name": "test_pluginmanager.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": " list[str] = []\n        pytestpm.trace.root.setwriter(values.append)\n        undo = pytestpm.enable_tracing()\n        try:\n            indent = pytestpm.trace.root.indent\n            p = api1()\n            pytestpm.register(p)\n            assert pytestpm.trace.root.indent == indent\n            assert len(values) >= 2\n            assert \"pytest_plugin_registered\" in values[0]\n            assert \"finish\" in values[1]\n\n            values[:] = []\n            with pytest.raises(ValueError):\n                pytestpm.register(api2())\n            assert pytestpm.trace.root.indent == indent\n            assert saveindent[0] > indent\n        finally:\n            undo()\n\n    def test_hook_proxy(self, pytester: Pytester) -> None:\n        \"\"\"Test the gethookproxy function(#2016)\"\"\"\n        config = pytester.parseconfig()\n        session = Session.from_config(config)\n        pytester.makepyfile(**{\"tests/conftest.py\": \"\", \"tests/subdir/conftest.py\": \"\"})\n\n        conftest1 = pytester.path.joinpath(\"tests/conftest.py\")\n        conftest2 = pytester.path.joinpath(\"tests/subdir/conftest.py\")\n\n        config.pluginmanager._importconftest(\n            conftest1,\n            importmode=\"prepend\",\n            rootpath=pytester.path,\n            consider_namespace_packages=False,\n        )\n        ihook_a = session.gethookproxy(pytester.path / \"tests\")\n        assert ihook_a is not None\n        config.pluginmanager._importconftest(\n            conftest2,\n            importmode=\"prepend\",\n            rootpath=pytester.path,\n            consider_namespace_packages=False,\n        )\n        ihook_b = session.gethookproxy(pytester.path / \"tests\")\n        assert ihook_a is not ihook_b\n\n    def test_hook_with_addoption(self, pytester: Pytester) -> None:\n        \"\"\"Test that hooks can be used in a call to pytest_addoption\"\"\"\n        pytester.makepyfile(\n            newhooks=\"\"\"\n            import pytest\n            @pytest.hookspec(firstresult=True)\n            def pytest_default_value():\n        "}, {"start_line": 1000, "end_line": 3000, "belongs_to": {"file_name": "test_pluginmanager.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "newhooks)\n            def pytest_myhook(xyz):\n                return xyz + 1\n        \"\"\"\n        )\n        config = _config_for_test\n        pm = config.pluginmanager\n        pm.hook.pytest_addhooks.call_historic(\n            kwargs=dict(pluginmanager=config.pluginmanager)\n        )\n        config.pluginmanager._importconftest(\n            conf,\n            importmode=\"prepend\",\n            rootpath=pytester.path,\n            consider_namespace_packages=False,\n        )\n        # print(config.pluginmanager.get_plugins())\n        res = config.hook.pytest_myhook(xyz=10)\n        assert res == [11]\n\n    def test_addhooks_nohooks(self, pytester: Pytester) -> None:\n        pytester.makeconftest(\n            \"\"\"\n            import sys\n            def pytest_addhooks(pluginmanager):\n                pluginmanager.add_hookspecs(sys)\n        \"\"\"\n        )\n        res = pytester.runpytest()\n        assert res.ret != 0\n        res.stderr.fnmatch_lines([\"*did not find*sys*\"])\n\n    def test_do_option_postinitialize(self, pytester: Pytester) -> None:\n        config = pytester.parseconfigure()\n        assert not hasattr(config.option, \"test123\")\n        p = pytester.makepyfile(\n            \"\"\"\n            def pytest_addoption(parser):\n                parser.addoption('--test123', action=\"store_true\",\n                    default=True)\n        \"\"\"\n        )\n        config.pluginmanager._importconftest(\n            p,\n            importmode=\"prepend\",\n            rootpath=pytester.path,\n            consider_namespace_packages=False,\n        )\n        assert config.option.test123\n\n    def test_configure(self, pytester: Pytester) -> None:\n        config = pytester.parseconfig()\n        values = []\n\n        class A:\n            def pytest_configure(self):\n                values.append(self)\n\n        config.pluginmanager.register(A())\n        assert len(values) == 0\n        config._do_configure()\n        assert len(values) == 1\n        config.pluginmanager.register(A())  # leads to a confi"}], "retrieved_count": 10, "cost_time": 1.1880886554718018}
{"question": "Where does Pytest store its plugin implementations?", "answer": null, "relative_code_list": null, "ground_truth": "Pytest stores its plugin implementations across multiple locations in the codebase: 1) Built-in plugins are stored in the src/_pytest/ directory as individual modules, with each plugin implemented as a separate Python module containing hook functions, 2) Essential plugins (mark, main, runner, fixtures, helpconfig) are defined in src/_pytest/config/__init__.py in the essential_plugins tuple and cannot be disabled, 3) Default plugins are listed in src/_pytest/config/__init__.py in the default_plugins tuple and include core functionality like python, terminal, debugging, unittest, capture, skipping, etc., 4) Built-in plugins are stored in src/_pytest/config/__init__.py in the builtin_plugins set which includes all default plugins plus pytester and pytester_assertions, 5) Plugin modules are organized by functionality in the src/_pytest/ directory, such as src/_pytest/fixtures.py for fixture system, src/_pytest/assertion/ for assertion rewriting, src/_pytest/cacheprovider.py for caching functionality, 6) External plugins are discovered through entry points in their packaging metadata and loaded dynamically at runtime, 7) Local conftest.py plugins are auto-discovered in test directories and loaded as modules during test collection, 8) Plugin registration and management is handled by the PytestPluginManager class in src/_pytest/config/__init__.py, 9) Plugin loading order is controlled by the plugin discovery sequence: command line blocking, builtin plugins, external plugins, environment variables, and conftest files, 10) Plugin implementations are stored as Python modules with hook functions that follow the pytest_ prefix naming convention, 11) The plugin system is built on the pluggy library, with plugins registered through the plugin manager's register() method, 12) Plugin state and data can be stored using the stash mechanism on test items and configuration objects for cross-hook communication.", "score": null, "retrieved_content": [{"start_line": 11000, "end_line": 13000, "belongs_to": {"file_name": "__init__.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest/config", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "ed.HOOK_LEGACY_MARKING.format(\n            type=hook_type,\n            fullname=method.__qualname__,\n            hook_opts=hook_opts,\n        )\n        warn_explicit_for(cast(FunctionType, method), message)\n    return opts\n\n\n@final\nclass PytestPluginManager(PluginManager):\n    \"\"\"A :py:class:`pluggy.PluginManager <pluggy.PluginManager>` with\n    additional pytest-specific functionality:\n\n    * Loading plugins from the command line, ``PYTEST_PLUGINS`` env variable and\n      ``pytest_plugins`` global variables found in plugins being loaded.\n    * ``conftest.py`` loading during start-up.\n    \"\"\"\n\n    def __init__(self) -> None:\n        from _pytest.assertion import DummyRewriteHook\n        from _pytest.assertion import RewriteHook\n\n        super().__init__(\"pytest\")\n\n        # -- State related to local conftest plugins.\n        # All loaded conftest modules.\n        self._conftest_plugins: set[types.ModuleType] = set()\n        # All conftest modules applicable for a directory.\n        # This includes the directory's own conftest modules as well\n        # as those of its parent directories.\n        self._dirpath2confmods: dict[pathlib.Path, list[types.ModuleType]] = {}\n        # Cutoff directory above which conftests are no longer discovered.\n        self._confcutdir: pathlib.Path | None = None\n        # If set, conftest loading is skipped.\n        self._noconftest = False\n\n        # _getconftestmodules()'s call to _get_directory() causes a stat\n        # storm when it's called potentially thousands of times in a test\n        # session (#9478), often with the same path, so cache it.\n        self._get_directory = lru_cache(256)(_get_directory)\n\n        # plugins that were explicitly skipped with pytest.skip\n        # list of (module name, skip reason)\n        # previously we would issue a warning when a plugin was skipped, but\n        # since we refactored warnings as first citizens of Config, they are\n        # just stored here to be used later.\n        self.skipped_plu"}, {"start_line": 16000, "end_line": 18000, "belongs_to": {"file_name": "__init__.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest/config", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "ict(\n                    plugin=plugin,\n                    plugin_name=plugin_name,\n                    manager=self,\n                )\n            )\n\n            if isinstance(plugin, types.ModuleType):\n                self.consider_module(plugin)\n        return plugin_name\n\n    def getplugin(self, name: str):\n        # Support deprecated naming because plugins (xdist e.g.) use it.\n        plugin: _PluggyPlugin | None = self.get_plugin(name)\n        return plugin\n\n    def hasplugin(self, name: str) -> bool:\n        \"\"\"Return whether a plugin with the given name is registered.\"\"\"\n        return bool(self.get_plugin(name))\n\n    def pytest_configure(self, config: Config) -> None:\n        \"\"\":meta private:\"\"\"\n        # XXX now that the pluginmanager exposes hookimpl(tryfirst...)\n        # we should remove tryfirst/trylast as markers.\n        config.addinivalue_line(\n            \"markers\",\n            \"tryfirst: mark a hook implementation function such that the \"\n            \"plugin machinery will try to call it first/as early as possible. \"\n            \"DEPRECATED, use @pytest.hookimpl(tryfirst=True) instead.\",\n        )\n        config.addinivalue_line(\n            \"markers\",\n            \"trylast: mark a hook implementation function such that the \"\n            \"plugin machinery will try to call it last/as late as possible. \"\n            \"DEPRECATED, use @pytest.hookimpl(trylast=True) instead.\",\n        )\n        self._configured = True\n\n    #\n    # Internal API for local conftest plugin handling.\n    #\n    def _set_initial_conftests(\n        self,\n        args: Sequence[str | pathlib.Path],\n        pyargs: bool,\n        noconftest: bool,\n        rootpath: pathlib.Path,\n        confcutdir: pathlib.Path | None,\n        invocation_dir: pathlib.Path,\n        importmode: ImportMode | str,\n        *,\n        consider_namespace_packages: bool,\n    ) -> None:\n        \"\"\"Load initial conftest files given a preparsed \"namespace\".\n\n        As conftest files may add their own com"}, {"start_line": 13000, "end_line": 15000, "belongs_to": {"file_name": "__init__.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest/config", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "gins: list[tuple[str, str]] = []\n\n        self.add_hookspecs(_pytest.hookspec)\n        self.register(self)\n        if os.environ.get(\"PYTEST_DEBUG\"):\n            err: IO[str] = sys.stderr\n            encoding: str = getattr(err, \"encoding\", \"utf8\")\n            try:\n                err = open(\n                    os.dup(err.fileno()),\n                    mode=err.mode,\n                    buffering=1,\n                    encoding=encoding,\n                )\n            except Exception:\n                pass\n            self.trace.root.setwriter(err.write)\n            self.enable_tracing()\n\n        # Config._consider_importhook will set a real object if required.\n        self.rewrite_hook: RewriteHook = DummyRewriteHook()\n        # Used to know when we are importing conftests after the pytest_configure stage.\n        self._configured = False\n\n    def parse_hookimpl_opts(\n        self, plugin: _PluggyPlugin, name: str\n    ) -> HookimplOpts | None:\n        \"\"\":meta private:\"\"\"\n        # pytest hooks are always prefixed with \"pytest_\",\n        # so we avoid accessing possibly non-readable attributes\n        # (see issue #1073).\n        if not name.startswith(\"pytest_\"):\n            return None\n        # Ignore names which cannot be hooks.\n        if name == \"pytest_plugins\":\n            return None\n\n        opts = super().parse_hookimpl_opts(plugin, name)\n        if opts is not None:\n            return opts\n\n        method = getattr(plugin, name)\n        # Consider only actual functions for hooks (#3775).\n        if not inspect.isroutine(method):\n            return None\n        # Collect unmarked hooks as long as they have the `pytest_' prefix.\n        legacy = _get_legacy_hook_marks(\n            method, \"impl\", (\"tryfirst\", \"trylast\", \"optionalhook\", \"hookwrapper\")\n        )\n        return cast(HookimplOpts, legacy)\n\n    def parse_hookspec_opts(self, module_or_class, name: str) -> HookspecOpts | None:\n        \"\"\":meta private:\"\"\"\n        opts = super().parse_hookspec_op"}, {"start_line": 10000, "end_line": 12000, "belongs_to": {"file_name": "__init__.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest/config", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "ory.\"\"\"\n    if path.is_file():\n        return path.parent\n    else:\n        return path\n\n\ndef _get_legacy_hook_marks(\n    method: Any,\n    hook_type: str,\n    opt_names: tuple[str, ...],\n) -> dict[str, bool]:\n    if TYPE_CHECKING:\n        # abuse typeguard from importlib to avoid massive method type union that's lacking an alias\n        assert inspect.isroutine(method)\n    known_marks: set[str] = {m.name for m in getattr(method, \"pytestmark\", [])}\n    must_warn: list[str] = []\n    opts: dict[str, bool] = {}\n    for opt_name in opt_names:\n        opt_attr = getattr(method, opt_name, AttributeError)\n        if opt_attr is not AttributeError:\n            must_warn.append(f\"{opt_name}={opt_attr}\")\n            opts[opt_name] = True\n        elif opt_name in known_marks:\n            must_warn.append(f\"{opt_name}=True\")\n            opts[opt_name] = True\n        else:\n            opts[opt_name] = False\n    if must_warn:\n        hook_opts = \", \".join(must_warn)\n        message = _pytest.deprecated.HOOK_LEGACY_MARKING.format(\n            type=hook_type,\n            fullname=method.__qualname__,\n            hook_opts=hook_opts,\n        )\n        warn_explicit_for(cast(FunctionType, method), message)\n    return opts\n\n\n@final\nclass PytestPluginManager(PluginManager):\n    \"\"\"A :py:class:`pluggy.PluginManager <pluggy.PluginManager>` with\n    additional pytest-specific functionality:\n\n    * Loading plugins from the command line, ``PYTEST_PLUGINS`` env variable and\n      ``pytest_plugins`` global variables found in plugins being loaded.\n    * ``conftest.py`` loading during start-up.\n    \"\"\"\n\n    def __init__(self) -> None:\n        from _pytest.assertion import DummyRewriteHook\n        from _pytest.assertion import RewriteHook\n\n        super().__init__(\"pytest\")\n\n        # -- State related to local conftest plugins.\n        # All loaded conftest modules.\n        self._conftest_plugins: set[types.ModuleType] = set()\n        # All conftest modules applicable for a directory.\n        # T"}, {"start_line": 14000, "end_line": 16000, "belongs_to": {"file_name": "__init__.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest/config", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "test hooks are always prefixed with \"pytest_\",\n        # so we avoid accessing possibly non-readable attributes\n        # (see issue #1073).\n        if not name.startswith(\"pytest_\"):\n            return None\n        # Ignore names which cannot be hooks.\n        if name == \"pytest_plugins\":\n            return None\n\n        opts = super().parse_hookimpl_opts(plugin, name)\n        if opts is not None:\n            return opts\n\n        method = getattr(plugin, name)\n        # Consider only actual functions for hooks (#3775).\n        if not inspect.isroutine(method):\n            return None\n        # Collect unmarked hooks as long as they have the `pytest_' prefix.\n        legacy = _get_legacy_hook_marks(\n            method, \"impl\", (\"tryfirst\", \"trylast\", \"optionalhook\", \"hookwrapper\")\n        )\n        return cast(HookimplOpts, legacy)\n\n    def parse_hookspec_opts(self, module_or_class, name: str) -> HookspecOpts | None:\n        \"\"\":meta private:\"\"\"\n        opts = super().parse_hookspec_opts(module_or_class, name)\n        if opts is None:\n            method = getattr(module_or_class, name)\n            if name.startswith(\"pytest_\"):\n                legacy = _get_legacy_hook_marks(\n                    method, \"spec\", (\"firstresult\", \"historic\")\n                )\n                opts = cast(HookspecOpts, legacy)\n        return opts\n\n    def register(self, plugin: _PluggyPlugin, name: str | None = None) -> str | None:\n        if name in _pytest.deprecated.DEPRECATED_EXTERNAL_PLUGINS:\n            warnings.warn(\n                PytestConfigWarning(\n                    \"{} plugin has been merged into the core, \"\n                    \"please remove it from your requirements.\".format(\n                        name.replace(\"_\", \"-\")\n                    )\n                )\n            )\n            return None\n        plugin_name = super().register(plugin, name)\n        if plugin_name is not None:\n            self.hook.pytest_plugin_registered.call_historic(\n                kwargs=d"}, {"start_line": 15000, "end_line": 17000, "belongs_to": {"file_name": "__init__.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest/config", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "ts(module_or_class, name)\n        if opts is None:\n            method = getattr(module_or_class, name)\n            if name.startswith(\"pytest_\"):\n                legacy = _get_legacy_hook_marks(\n                    method, \"spec\", (\"firstresult\", \"historic\")\n                )\n                opts = cast(HookspecOpts, legacy)\n        return opts\n\n    def register(self, plugin: _PluggyPlugin, name: str | None = None) -> str | None:\n        if name in _pytest.deprecated.DEPRECATED_EXTERNAL_PLUGINS:\n            warnings.warn(\n                PytestConfigWarning(\n                    \"{} plugin has been merged into the core, \"\n                    \"please remove it from your requirements.\".format(\n                        name.replace(\"_\", \"-\")\n                    )\n                )\n            )\n            return None\n        plugin_name = super().register(plugin, name)\n        if plugin_name is not None:\n            self.hook.pytest_plugin_registered.call_historic(\n                kwargs=dict(\n                    plugin=plugin,\n                    plugin_name=plugin_name,\n                    manager=self,\n                )\n            )\n\n            if isinstance(plugin, types.ModuleType):\n                self.consider_module(plugin)\n        return plugin_name\n\n    def getplugin(self, name: str):\n        # Support deprecated naming because plugins (xdist e.g.) use it.\n        plugin: _PluggyPlugin | None = self.get_plugin(name)\n        return plugin\n\n    def hasplugin(self, name: str) -> bool:\n        \"\"\"Return whether a plugin with the given name is registered.\"\"\"\n        return bool(self.get_plugin(name))\n\n    def pytest_configure(self, config: Config) -> None:\n        \"\"\":meta private:\"\"\"\n        # XXX now that the pluginmanager exposes hookimpl(tryfirst...)\n        # we should remove tryfirst/trylast as markers.\n        config.addinivalue_line(\n            \"markers\",\n            \"tryfirst: mark a hook implementation function such that the \"\n            \"plugin machi"}, {"start_line": 51000, "end_line": 53000, "belongs_to": {"file_name": "test_config.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "   (\n            hookimpl.function.__module__,\n            \"wrapper\" if (hookimpl.wrapper or hookimpl.hookwrapper) else \"nonwrapper\",\n        )\n        for hookimpl in hc.get_hookimpls()\n    ]\n    assert hookimpls == [\n        (\"_pytest.config\", \"nonwrapper\"),\n        (m.__module__, \"nonwrapper\"),\n        (\"_pytest.legacypath\", \"nonwrapper\"),\n        (\"_pytest.capture\", \"wrapper\"),\n        (\"_pytest.warnings\", \"wrapper\"),\n    ]\n\n\ndef test_get_plugin_specs_as_list() -> None:\n    def exp_match(val: object) -> str:\n        return (\n            f\"Plugins may be specified as a sequence or a ','-separated string \"\n            f\"of plugin names. Got: {re.escape(repr(val))}\"\n        )\n\n    with pytest.raises(pytest.UsageError, match=exp_match({\"foo\"})):\n        _get_plugin_specs_as_list({\"foo\"})  # type: ignore[arg-type]\n    with pytest.raises(pytest.UsageError, match=exp_match({})):\n        _get_plugin_specs_as_list(dict())  # type: ignore[arg-type]\n\n    assert _get_plugin_specs_as_list(None) == []\n    assert _get_plugin_specs_as_list(\"\") == []\n    assert _get_plugin_specs_as_list(\"foo\") == [\"foo\"]\n    assert _get_plugin_specs_as_list(\"foo,bar\") == [\"foo\", \"bar\"]\n    assert _get_plugin_specs_as_list([\"foo\", \"bar\"]) == [\"foo\", \"bar\"]\n    assert _get_plugin_specs_as_list((\"foo\", \"bar\")) == [\"foo\", \"bar\"]\n\n\ndef test_collect_pytest_prefix_bug_integration(pytester: Pytester) -> None:\n    \"\"\"Integration test for issue #3775\"\"\"\n    p = pytester.copy_example(\"config/collect_pytest_prefix\")\n    result = pytester.runpytest(p)\n    result.stdout.fnmatch_lines([\"* 1 passed *\"])\n\n\ndef test_collect_pytest_prefix_bug(pytestconfig):\n    \"\"\"Ensure we collect only actual functions from conftest files (#3775)\"\"\"\n\n    class Dummy:\n        class pytest_something:\n            pass\n\n    pm = pytestconfig.pluginmanager\n    assert pm.parse_hookimpl_opts(Dummy(), \"pytest_something\") is None\n\n\nclass TestRootdir:\n    def test_simple_noini(self, tmp_path: Path, monkeypatch: MonkeyPatch) -> None:\n      "}, {"start_line": 9000, "end_line": 11000, "belongs_to": {"file_name": "test_pluginmanager.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "register, mod)\n        pytest.raises(ValueError, lambda: pm.register(mod))\n        # assert not pm.is_registered(mod2)\n        assert pm.get_plugins() == values\n\n    def test_canonical_import(self, monkeypatch):\n        mod = types.ModuleType(\"pytest_xyz\")\n        monkeypatch.setitem(sys.modules, \"pytest_xyz\", mod)\n        pm = PytestPluginManager()\n        pm.import_plugin(\"pytest_xyz\")\n        assert pm.get_plugin(\"pytest_xyz\") == mod\n        assert pm.is_registered(mod)\n\n    def test_consider_module(\n        self, pytester: Pytester, pytestpm: PytestPluginManager\n    ) -> None:\n        pytester.syspathinsert()\n        pytester.makepyfile(pytest_p1=\"#\")\n        pytester.makepyfile(pytest_p2=\"#\")\n        mod = types.ModuleType(\"temp\")\n        mod.__dict__[\"pytest_plugins\"] = [\"pytest_p1\", \"pytest_p2\"]\n        pytestpm.consider_module(mod)\n        p1 = pytestpm.get_plugin(\"pytest_p1\")\n        assert p1 is not None\n        assert p1.__name__ == \"pytest_p1\"\n        p2 = pytestpm.get_plugin(\"pytest_p2\")\n        assert p2 is not None\n        assert p2.__name__ == \"pytest_p2\"\n\n    def test_consider_module_import_module(\n        self, pytester: Pytester, _config_for_test: Config\n    ) -> None:\n        pytestpm = _config_for_test.pluginmanager\n        mod = types.ModuleType(\"x\")\n        mod.__dict__[\"pytest_plugins\"] = \"pytest_a\"\n        aplugin = pytester.makepyfile(pytest_a=\"#\")\n        reprec = pytester.make_hook_recorder(pytestpm)\n        pytester.syspathinsert(aplugin.parent)\n        pytestpm.consider_module(mod)\n        call = reprec.getcall(pytestpm.hook.pytest_plugin_registered.name)\n        assert call.plugin.__name__ == \"pytest_a\"\n\n        # check that it is not registered twice\n        pytestpm.consider_module(mod)\n        values = reprec.getcalls(\"pytest_plugin_registered\")\n        assert len(values) == 1\n\n    def test_consider_env_fails_to_import(\n        self, monkeypatch: MonkeyPatch, pytestpm: PytestPluginManager\n    ) -> None:\n        monkeypatch.setenv(\"P"}, {"start_line": 29000, "end_line": 31000, "belongs_to": {"file_name": "__init__.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest/config", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "      if consider_entry_points:\n            loaded = self.load_setuptools_entrypoints(\"pytest11\", name=modname)\n            if loaded:\n                return\n\n        try:\n            __import__(importspec)\n        except ImportError as e:\n            raise ImportError(\n                f'Error importing plugin \"{modname}\": {e.args[0]}'\n            ).with_traceback(e.__traceback__) from e\n\n        except Skipped as e:\n            self.skipped_plugins.append((modname, e.msg or \"\"))\n        else:\n            mod = sys.modules[importspec]\n            self.register(mod, modname)\n\n\ndef _get_plugin_specs_as_list(\n    specs: None | types.ModuleType | str | Sequence[str],\n) -> list[str]:\n    \"\"\"Parse a plugins specification into a list of plugin names.\"\"\"\n    # None means empty.\n    if specs is None:\n        return []\n    # Workaround for #3899 - a submodule which happens to be called \"pytest_plugins\".\n    if isinstance(specs, types.ModuleType):\n        return []\n    # Comma-separated list.\n    if isinstance(specs, str):\n        return specs.split(\",\") if specs else []\n    # Direct specification.\n    if isinstance(specs, collections.abc.Sequence):\n        return list(specs)\n    raise UsageError(\n        f\"Plugins may be specified as a sequence or a ','-separated string of plugin names. Got: {specs!r}\"\n    )\n\n\nclass Notset:\n    def __repr__(self):\n        return \"<NOTSET>\"\n\n\nnotset = Notset()\n\n\ndef _iter_rewritable_modules(package_files: Iterable[str]) -> Iterator[str]:\n    \"\"\"Given an iterable of file names in a source distribution, return the \"names\" that should\n    be marked for assertion rewrite.\n\n    For example the package \"pytest_mock/__init__.py\" should be added as \"pytest_mock\" in\n    the assertion rewrite mechanism.\n\n    This function has to deal with dist-info based distributions and egg based distributions\n    (which are still very much in use for \"editable\" installs).\n\n    Here are the file names as seen in a dist-info based distribution:\n\n        pytest_mock/__i"}, {"start_line": 13000, "end_line": 15000, "belongs_to": {"file_name": "test_pluginmanager.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "h_lines([\"*1 passed*\"])\n\n    def test_import_plugin_importname(\n        self, pytester: Pytester, pytestpm: PytestPluginManager\n    ) -> None:\n        pytest.raises(ImportError, pytestpm.import_plugin, \"qweqwex.y\")\n        pytest.raises(ImportError, pytestpm.import_plugin, \"pytest_qweqwx.y\")\n\n        pytester.syspathinsert()\n        pluginname = \"pytest_hello\"\n        pytester.makepyfile(**{pluginname: \"\"})\n        pytestpm.import_plugin(\"pytest_hello\")\n        len1 = len(pytestpm.get_plugins())\n        pytestpm.import_plugin(\"pytest_hello\")\n        len2 = len(pytestpm.get_plugins())\n        assert len1 == len2\n        plugin1 = pytestpm.get_plugin(\"pytest_hello\")\n        assert plugin1 is not None\n        assert plugin1.__name__.endswith(\"pytest_hello\")\n        plugin2 = pytestpm.get_plugin(\"pytest_hello\")\n        assert plugin2 is plugin1\n\n    def test_import_plugin_dotted_name(\n        self, pytester: Pytester, pytestpm: PytestPluginManager\n    ) -> None:\n        pytest.raises(ImportError, pytestpm.import_plugin, \"qweqwex.y\")\n        pytest.raises(ImportError, pytestpm.import_plugin, \"pytest_qweqwex.y\")\n\n        pytester.syspathinsert()\n        pytester.mkpydir(\"pkg\").joinpath(\"plug.py\").write_text(\"x=3\", encoding=\"utf-8\")\n        pluginname = \"pkg.plug\"\n        pytestpm.import_plugin(pluginname)\n        mod = pytestpm.get_plugin(\"pkg.plug\")\n        assert mod is not None\n        assert mod.x == 3\n\n    def test_consider_conftest_deps(\n        self,\n        pytester: Pytester,\n        pytestpm: PytestPluginManager,\n    ) -> None:\n        mod = import_path(\n            pytester.makepyfile(\"pytest_plugins='xyz'\"),\n            root=pytester.path,\n            consider_namespace_packages=False,\n        )\n        with pytest.raises(ImportError):\n            pytestpm.consider_conftest(mod, registration_name=\"unused\")\n\n\nclass TestPytestPluginManagerBootstrapping:\n    def test_preparse_args(self, pytestpm: PytestPluginManager) -> None:\n        pytest.raises(\n            Im"}], "retrieved_count": 10, "cost_time": 1.1898553371429443}
{"question": "Where in the Pytest codebase is the core test runner implemented?", "answer": null, "relative_code_list": null, "ground_truth": "The core test runner in pytest is implemented across several key modules in the codebase: 1) Main entry point is in src/_pytest/main.py which contains the core testing process implementation including initialization, session management, and the main runtest loop, 2) The Session class in src/_pytest/main.py serves as the root collector and orchestrates the overall test execution process, 3) The pytest_runtestloop hook in src/_pytest/main.py implements the main test execution loop that iterates through collected test items, 4) The pytest_runtest_protocol hook in src/_pytest/runner.py orchestrates the three-phase test execution (setup, call, teardown) for individual tests, 5) The SetupState class in src/_pytest/runner.py manages the setup and teardown of test items and collectors, 6) The collect_one_node function in src/_pytest/runner.py handles the collection of individual test nodes, 7) The _main function in src/_pytest/main.py provides the default command line protocol for initialization, session management, test running, and reporting, 8) The pytest_cmdline_main hook in src/_pytest/main.py serves as the main entry point for command line execution, 9) The wrap_session function in src/_pytest/main.py coordinates the overall test session lifecycle, 10) The Config class in src/_pytest/config/__init__.py provides the central configuration object that the test runner uses, 11) The PytestPluginManager in src/_pytest/config/__init__.py manages plugin registration and hook execution that the test runner relies on, 12) The entire test runner architecture is built on the pluggy library, with all major operations delegated to plugins through the hook system.", "score": null, "retrieved_content": [{"start_line": 0, "end_line": 2000, "belongs_to": {"file_name": "main.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "\"\"\"Core implementation of the testing process: init, session, runtest loop.\"\"\"\n\nfrom __future__ import annotations\n\nimport argparse\nfrom collections.abc import Callable\nfrom collections.abc import Iterable\nfrom collections.abc import Iterator\nfrom collections.abc import Sequence\nfrom collections.abc import Set as AbstractSet\nimport dataclasses\nimport fnmatch\nimport functools\nimport importlib\nimport importlib.util\nimport os\nfrom pathlib import Path\nimport sys\nfrom typing import final\nfrom typing import Literal\nfrom typing import overload\nfrom typing import TYPE_CHECKING\nimport warnings\n\nimport pluggy\n\nfrom _pytest import nodes\nimport _pytest._code\nfrom _pytest.config import Config\nfrom _pytest.config import directory_arg\nfrom _pytest.config import ExitCode\nfrom _pytest.config import hookimpl\nfrom _pytest.config import PytestPluginManager\nfrom _pytest.config import UsageError\nfrom _pytest.config.argparsing import Parser\nfrom _pytest.config.compat import PathAwareHookProxy\nfrom _pytest.outcomes import exit\nfrom _pytest.pathlib import absolutepath\nfrom _pytest.pathlib import bestrelpath\nfrom _pytest.pathlib import fnmatch_ex\nfrom _pytest.pathlib import safe_exists\nfrom _pytest.pathlib import scandir\nfrom _pytest.reports import CollectReport\nfrom _pytest.reports import TestReport\nfrom _pytest.runner import collect_one_node\nfrom _pytest.runner import SetupState\nfrom _pytest.warning_types import PytestWarning\n\n\nif TYPE_CHECKING:\n    from typing_extensions import Self\n\n    from _pytest.fixtures import FixtureManager\n\n\ndef pytest_addoption(parser: Parser) -> None:\n    group = parser.getgroup(\"general\", \"Running and selection options\")\n    group._addoption(  # private to use reserved lower-case short option\n        \"-x\",\n        \"--exitfirst\",\n        action=\"store_const\",\n        dest=\"maxfail\",\n        const=1,\n        help=\"Exit instantly on first error or failed test\",\n    )\n    group.addoption(\n        \"--maxfail\",\n        metavar=\"num\",\n        action=\"store\",\n        t"}, {"start_line": 34000, "end_line": 36000, "belongs_to": {"file_name": "pytester.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "containing the test method) must\n        provide a ``.getrunner()`` method which should return a runner which\n        can run the test protocol for a single item, e.g.\n        ``_pytest.runner.runtestprotocol``.\n        \"\"\"\n        # used from runner functional tests\n        item = self.getitem(source)\n        # the test class where we are called from wants to provide the runner\n        testclassinstance = self._request.instance\n        runner = testclassinstance.getrunner()\n        return runner(item)\n\n    def inline_runsource(self, source: str, *cmdlineargs) -> HookRecorder:\n        \"\"\"Run a test module in process using ``pytest.main()``.\n\n        This run writes \"source\" into a temporary file and runs\n        ``pytest.main()`` on it, returning a :py:class:`HookRecorder` instance\n        for the result.\n\n        :param source: The source code of the test module.\n        :param cmdlineargs: Any extra command line arguments to use.\n        \"\"\"\n        p = self.makepyfile(source)\n        values = [*list(cmdlineargs), p]\n        return self.inline_run(*values)\n\n    def inline_genitems(self, *args) -> tuple[list[Item], HookRecorder]:\n        \"\"\"Run ``pytest.main(['--collect-only'])`` in-process.\n\n        Runs the :py:func:`pytest.main` function to run all of pytest inside\n        the test process itself like :py:meth:`inline_run`, but returns a\n        tuple of the collected items and a :py:class:`HookRecorder` instance.\n        \"\"\"\n        rec = self.inline_run(\"--collect-only\", *args)\n        items = [x.item for x in rec.getcalls(\"pytest_itemcollected\")]\n        return items, rec\n\n    def inline_run(\n        self,\n        *args: str | os.PathLike[str],\n        plugins=(),\n        no_reraise_ctrlc: bool = False,\n    ) -> HookRecorder:\n        \"\"\"Run ``pytest.main()`` in-process, returning a HookRecorder.\n\n        Runs the :py:func:`pytest.main` function to run all of pytest inside\n        the test process itself.  This means it can return a\n        :py:class:`HookReco"}, {"start_line": 2000, "end_line": 4000, "belongs_to": {"file_name": "__init__.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest/config", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "\n\n\nif TYPE_CHECKING:\n    from _pytest.assertion.rewrite import AssertionRewritingHook\n    from _pytest.cacheprovider import Cache\n    from _pytest.terminal import TerminalReporter\n\n_PluggyPlugin = object\n\"\"\"A type to represent plugin objects.\n\nPlugins can be any namespace, so we can't narrow it down much, but we use an\nalias to make the intent clear.\n\nIdeally this type would be provided by pluggy itself.\n\"\"\"\n\n\nhookimpl = HookimplMarker(\"pytest\")\nhookspec = HookspecMarker(\"pytest\")\n\n\n@final\nclass ExitCode(enum.IntEnum):\n    \"\"\"Encodes the valid exit codes by pytest.\n\n    Currently users and plugins may supply other exit codes as well.\n\n    .. versionadded:: 5.0\n    \"\"\"\n\n    #: Tests passed.\n    OK = 0\n    #: Tests failed.\n    TESTS_FAILED = 1\n    #: pytest was interrupted.\n    INTERRUPTED = 2\n    #: An internal error got in the way.\n    INTERNAL_ERROR = 3\n    #: pytest was misused.\n    USAGE_ERROR = 4\n    #: pytest couldn't find tests.\n    NO_TESTS_COLLECTED = 5\n\n\nclass ConftestImportFailure(Exception):\n    def __init__(\n        self,\n        path: pathlib.Path,\n        *,\n        cause: Exception,\n    ) -> None:\n        self.path = path\n        self.cause = cause\n\n    def __str__(self) -> str:\n        return f\"{type(self.cause).__name__}: {self.cause} (from {self.path})\"\n\n\ndef filter_traceback_for_conftest_import_failure(\n    entry: _pytest._code.TracebackEntry,\n) -> bool:\n    \"\"\"Filter tracebacks entries which point to pytest internals or importlib.\n\n    Make a special case for importlib because we use it to import test modules and conftest files\n    in _pytest.pathlib.import_path.\n    \"\"\"\n    return filter_traceback(entry) and \"importlib\" not in str(entry.path).split(os.sep)\n\n\ndef main(\n    args: list[str] | os.PathLike[str] | None = None,\n    plugins: Sequence[str | _PluggyPlugin] | None = None,\n) -> int | ExitCode:\n    \"\"\"Perform an in-process test run.\n\n    :param args:\n        List of command line arguments. If `None` or not given, defaults to reading\n        "}, {"start_line": 3000, "end_line": 5000, "belongs_to": {"file_name": "__init__.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest/config", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "ilure(Exception):\n    def __init__(\n        self,\n        path: pathlib.Path,\n        *,\n        cause: Exception,\n    ) -> None:\n        self.path = path\n        self.cause = cause\n\n    def __str__(self) -> str:\n        return f\"{type(self.cause).__name__}: {self.cause} (from {self.path})\"\n\n\ndef filter_traceback_for_conftest_import_failure(\n    entry: _pytest._code.TracebackEntry,\n) -> bool:\n    \"\"\"Filter tracebacks entries which point to pytest internals or importlib.\n\n    Make a special case for importlib because we use it to import test modules and conftest files\n    in _pytest.pathlib.import_path.\n    \"\"\"\n    return filter_traceback(entry) and \"importlib\" not in str(entry.path).split(os.sep)\n\n\ndef main(\n    args: list[str] | os.PathLike[str] | None = None,\n    plugins: Sequence[str | _PluggyPlugin] | None = None,\n) -> int | ExitCode:\n    \"\"\"Perform an in-process test run.\n\n    :param args:\n        List of command line arguments. If `None` or not given, defaults to reading\n        arguments directly from the process command line (:data:`sys.argv`).\n    :param plugins: List of plugin objects to be auto-registered during initialization.\n\n    :returns: An exit code.\n    \"\"\"\n    old_pytest_version = os.environ.get(\"PYTEST_VERSION\")\n    try:\n        os.environ[\"PYTEST_VERSION\"] = __version__\n        try:\n            config = _prepareconfig(args, plugins)\n        except ConftestImportFailure as e:\n            exc_info = ExceptionInfo.from_exception(e.cause)\n            tw = TerminalWriter(sys.stderr)\n            tw.line(f\"ImportError while loading conftest '{e.path}'.\", red=True)\n            exc_info.traceback = exc_info.traceback.filter(\n                filter_traceback_for_conftest_import_failure\n            )\n            exc_repr = (\n                exc_info.getrepr(style=\"short\", chain=False)\n                if exc_info.traceback\n                else exc_info.exconly()\n            )\n            formatted_tb = str(exc_repr)\n            for line in formatted_tb.spli"}, {"start_line": 10000, "end_line": 12000, "belongs_to": {"file_name": "main.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "ion.startpath)\n        if initstate >= 2:\n            try:\n                config.hook.pytest_sessionfinish(\n                    session=session, exitstatus=session.exitstatus\n                )\n            except exit.Exception as exc:\n                if exc.returncode is not None:\n                    session.exitstatus = exc.returncode\n                sys.stderr.write(f\"{type(exc).__name__}: {exc}\\n\")\n        config._ensure_unconfigure()\n    return session.exitstatus\n\n\ndef pytest_cmdline_main(config: Config) -> int | ExitCode:\n    return wrap_session(config, _main)\n\n\ndef _main(config: Config, session: Session) -> int | ExitCode | None:\n    \"\"\"Default command line protocol for initialization, session,\n    running tests and reporting.\"\"\"\n    config.hook.pytest_collection(session=session)\n    config.hook.pytest_runtestloop(session=session)\n\n    if session.testsfailed:\n        return ExitCode.TESTS_FAILED\n    elif session.testscollected == 0:\n        return ExitCode.NO_TESTS_COLLECTED\n    return None\n\n\ndef pytest_collection(session: Session) -> None:\n    session.perform_collect()\n\n\ndef pytest_runtestloop(session: Session) -> bool:\n    if session.testsfailed and not session.config.option.continue_on_collection_errors:\n        raise session.Interrupted(\n            f\"{session.testsfailed} error{'s' if session.testsfailed != 1 else ''} during collection\"\n        )\n\n    if session.config.option.collectonly:\n        return True\n\n    for i, item in enumerate(session.items):\n        nextitem = session.items[i + 1] if i + 1 < len(session.items) else None\n        item.config.hook.pytest_runtest_protocol(item=item, nextitem=nextitem)\n        if session.shouldfail:\n            raise session.Failed(session.shouldfail)\n        if session.shouldstop:\n            raise session.Interrupted(session.shouldstop)\n    return True\n\n\ndef _in_venv(path: Path) -> bool:\n    \"\"\"Attempt to detect if ``path`` is the root of a Virtual Environment by\n    checking for the existence of the pyvenv.cfg "}, {"start_line": 0, "end_line": 2000, "belongs_to": {"file_name": "python.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "# mypy: allow-untyped-defs\n\"\"\"Python test discovery, setup and run of test functions.\"\"\"\n\nfrom __future__ import annotations\n\nimport abc\nfrom collections import Counter\nfrom collections import defaultdict\nfrom collections.abc import Callable\nfrom collections.abc import Generator\nfrom collections.abc import Iterable\nfrom collections.abc import Iterator\nfrom collections.abc import Mapping\nfrom collections.abc import Sequence\nimport dataclasses\nimport enum\nimport fnmatch\nfrom functools import partial\nimport inspect\nimport itertools\nimport os\nfrom pathlib import Path\nimport re\nimport types\nfrom typing import Any\nfrom typing import final\nfrom typing import Literal\nfrom typing import NoReturn\nfrom typing import TYPE_CHECKING\nimport warnings\n\nimport _pytest\nfrom _pytest import fixtures\nfrom _pytest import nodes\nfrom _pytest._code import filter_traceback\nfrom _pytest._code import getfslineno\nfrom _pytest._code.code import ExceptionInfo\nfrom _pytest._code.code import TerminalRepr\nfrom _pytest._code.code import Traceback\nfrom _pytest._io.saferepr import saferepr\nfrom _pytest.compat import ascii_escaped\nfrom _pytest.compat import get_default_arg_names\nfrom _pytest.compat import get_real_func\nfrom _pytest.compat import getimfunc\nfrom _pytest.compat import is_async_function\nfrom _pytest.compat import LEGACY_PATH\nfrom _pytest.compat import NOTSET\nfrom _pytest.compat import safe_getattr\nfrom _pytest.compat import safe_isclass\nfrom _pytest.config import Config\nfrom _pytest.config import hookimpl\nfrom _pytest.config.argparsing import Parser\nfrom _pytest.deprecated import check_ispytest\nfrom _pytest.fixtures import FixtureDef\nfrom _pytest.fixtures import FixtureRequest\nfrom _pytest.fixtures import FuncFixtureInfo\nfrom _pytest.fixtures import get_scope_node\nfrom _pytest.main import Session\nfrom _pytest.mark import ParameterSet\nfrom _pytest.mark.structures import _HiddenParam\nfrom _pytest.mark.structures import get_unpacked_marks\nfrom _pytest.mark.structures import HIDDEN_PARAM\nfrom _p"}, {"start_line": 1000, "end_line": 3000, "belongs_to": {"file_name": "python.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "code.code import Traceback\nfrom _pytest._io.saferepr import saferepr\nfrom _pytest.compat import ascii_escaped\nfrom _pytest.compat import get_default_arg_names\nfrom _pytest.compat import get_real_func\nfrom _pytest.compat import getimfunc\nfrom _pytest.compat import is_async_function\nfrom _pytest.compat import LEGACY_PATH\nfrom _pytest.compat import NOTSET\nfrom _pytest.compat import safe_getattr\nfrom _pytest.compat import safe_isclass\nfrom _pytest.config import Config\nfrom _pytest.config import hookimpl\nfrom _pytest.config.argparsing import Parser\nfrom _pytest.deprecated import check_ispytest\nfrom _pytest.fixtures import FixtureDef\nfrom _pytest.fixtures import FixtureRequest\nfrom _pytest.fixtures import FuncFixtureInfo\nfrom _pytest.fixtures import get_scope_node\nfrom _pytest.main import Session\nfrom _pytest.mark import ParameterSet\nfrom _pytest.mark.structures import _HiddenParam\nfrom _pytest.mark.structures import get_unpacked_marks\nfrom _pytest.mark.structures import HIDDEN_PARAM\nfrom _pytest.mark.structures import Mark\nfrom _pytest.mark.structures import MarkDecorator\nfrom _pytest.mark.structures import normalize_mark_list\nfrom _pytest.outcomes import fail\nfrom _pytest.outcomes import skip\nfrom _pytest.pathlib import fnmatch_ex\nfrom _pytest.pathlib import import_path\nfrom _pytest.pathlib import ImportPathMismatchError\nfrom _pytest.pathlib import scandir\nfrom _pytest.scope import _ScopeName\nfrom _pytest.scope import Scope\nfrom _pytest.stash import StashKey\nfrom _pytest.warning_types import PytestCollectionWarning\nfrom _pytest.warning_types import PytestReturnNotNoneWarning\n\n\nif TYPE_CHECKING:\n    from typing_extensions import Self\n\n\ndef pytest_addoption(parser: Parser) -> None:\n    parser.addini(\n        \"python_files\",\n        type=\"args\",\n        # NOTE: default is also used in AssertionRewritingHook.\n        default=[\"test_*.py\", \"*_test.py\"],\n        help=\"Glob-style file patterns for Python test module discovery\",\n    )\n    parser.addini(\n        \"python_classes\""}, {"start_line": 2000, "end_line": 4000, "belongs_to": {"file_name": "__init__.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "om _pytest.pytester import Pytester\nfrom _pytest.pytester import RecordedHookCall\nfrom _pytest.pytester import RunResult\nfrom _pytest.python import Class\nfrom _pytest.python import Function\nfrom _pytest.python import Metafunc\nfrom _pytest.python import Module\nfrom _pytest.python import Package\nfrom _pytest.python_api import approx\nfrom _pytest.raises import raises\nfrom _pytest.raises import RaisesExc\nfrom _pytest.raises import RaisesGroup\nfrom _pytest.recwarn import deprecated_call\nfrom _pytest.recwarn import WarningsRecorder\nfrom _pytest.recwarn import warns\nfrom _pytest.reports import CollectReport\nfrom _pytest.reports import TestReport\nfrom _pytest.runner import CallInfo\nfrom _pytest.stash import Stash\nfrom _pytest.stash import StashKey\nfrom _pytest.terminal import TerminalReporter\nfrom _pytest.terminal import TestShortLogReport\nfrom _pytest.tmpdir import TempPathFactory\nfrom _pytest.warning_types import PytestAssertRewriteWarning\nfrom _pytest.warning_types import PytestCacheWarning\nfrom _pytest.warning_types import PytestCollectionWarning\nfrom _pytest.warning_types import PytestConfigWarning\nfrom _pytest.warning_types import PytestDeprecationWarning\nfrom _pytest.warning_types import PytestExperimentalApiWarning\nfrom _pytest.warning_types import PytestFDWarning\nfrom _pytest.warning_types import PytestRemovedIn9Warning\nfrom _pytest.warning_types import PytestReturnNotNoneWarning\nfrom _pytest.warning_types import PytestUnhandledThreadExceptionWarning\nfrom _pytest.warning_types import PytestUnknownMarkWarning\nfrom _pytest.warning_types import PytestUnraisableExceptionWarning\nfrom _pytest.warning_types import PytestWarning\n\n\nset_trace = __pytestPDB.set_trace\n\n\n__all__ = [\n    \"HIDDEN_PARAM\",\n    \"Cache\",\n    \"CallInfo\",\n    \"CaptureFixture\",\n    \"Class\",\n    \"CollectReport\",\n    \"Collector\",\n    \"Config\",\n    \"Dir\",\n    \"Directory\",\n    \"DoctestItem\",\n    \"ExceptionInfo\",\n    \"ExitCode\",\n    \"File\",\n    \"FixtureDef\",\n    \"FixtureLookupError\",\n    \"FixtureRequest\",\n  "}, {"start_line": 0, "end_line": 2000, "belongs_to": {"file_name": "pytester.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "# mypy: allow-untyped-defs\n\"\"\"(Disabled by default) support for testing pytest and pytest plugins.\n\nPYTEST_DONT_REWRITE\n\"\"\"\n\nfrom __future__ import annotations\n\nimport collections.abc\nfrom collections.abc import Callable\nfrom collections.abc import Generator\nfrom collections.abc import Iterable\nfrom collections.abc import Sequence\nimport contextlib\nfrom fnmatch import fnmatch\nimport gc\nimport importlib\nfrom io import StringIO\nimport locale\nimport os\nfrom pathlib import Path\nimport platform\nimport re\nimport shutil\nimport subprocess\nimport sys\nimport traceback\nfrom typing import Any\nfrom typing import Final\nfrom typing import final\nfrom typing import IO\nfrom typing import Literal\nfrom typing import overload\nfrom typing import TextIO\nfrom typing import TYPE_CHECKING\nfrom weakref import WeakKeyDictionary\n\nfrom iniconfig import IniConfig\nfrom iniconfig import SectionWrapper\n\nfrom _pytest import timing\nfrom _pytest._code import Source\nfrom _pytest.capture import _get_multicapture\nfrom _pytest.compat import NOTSET\nfrom _pytest.compat import NotSetType\nfrom _pytest.config import _PluggyPlugin\nfrom _pytest.config import Config\nfrom _pytest.config import ExitCode\nfrom _pytest.config import hookimpl\nfrom _pytest.config import main\nfrom _pytest.config import PytestPluginManager\nfrom _pytest.config.argparsing import Parser\nfrom _pytest.deprecated import check_ispytest\nfrom _pytest.fixtures import fixture\nfrom _pytest.fixtures import FixtureRequest\nfrom _pytest.main import Session\nfrom _pytest.monkeypatch import MonkeyPatch\nfrom _pytest.nodes import Collector\nfrom _pytest.nodes import Item\nfrom _pytest.outcomes import fail\nfrom _pytest.outcomes import importorskip\nfrom _pytest.outcomes import skip\nfrom _pytest.pathlib import bestrelpath\nfrom _pytest.pathlib import make_numbered_dir\nfrom _pytest.reports import CollectReport\nfrom _pytest.reports import TestReport\nfrom _pytest.tmpdir import TempPathFactory\nfrom _pytest.warning_types import PytestFDWarning\n\n\nif TYPE_CHECKING:\n    imp"}, {"start_line": 0, "end_line": 2000, "belongs_to": {"file_name": "runner.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "# mypy: allow-untyped-defs\n\"\"\"Basic collect and runtest protocol implementations.\"\"\"\n\nfrom __future__ import annotations\n\nimport bdb\nfrom collections.abc import Callable\nimport dataclasses\nimport os\nimport sys\nimport types\nfrom typing import cast\nfrom typing import final\nfrom typing import Generic\nfrom typing import Literal\nfrom typing import TYPE_CHECKING\nfrom typing import TypeVar\n\nfrom .reports import BaseReport\nfrom .reports import CollectErrorRepr\nfrom .reports import CollectReport\nfrom .reports import TestReport\nfrom _pytest import timing\nfrom _pytest._code.code import ExceptionChainRepr\nfrom _pytest._code.code import ExceptionInfo\nfrom _pytest._code.code import TerminalRepr\nfrom _pytest.config.argparsing import Parser\nfrom _pytest.deprecated import check_ispytest\nfrom _pytest.nodes import Collector\nfrom _pytest.nodes import Directory\nfrom _pytest.nodes import Item\nfrom _pytest.nodes import Node\nfrom _pytest.outcomes import Exit\nfrom _pytest.outcomes import OutcomeException\nfrom _pytest.outcomes import Skipped\nfrom _pytest.outcomes import TEST_OUTCOME\n\n\nif sys.version_info < (3, 11):\n    from exceptiongroup import BaseExceptionGroup\n\nif TYPE_CHECKING:\n    from _pytest.main import Session\n    from _pytest.terminal import TerminalReporter\n\n#\n# pytest plugin hooks.\n\n\ndef pytest_addoption(parser: Parser) -> None:\n    group = parser.getgroup(\"terminal reporting\", \"Reporting\", after=\"general\")\n    group.addoption(\n        \"--durations\",\n        action=\"store\",\n        type=int,\n        default=None,\n        metavar=\"N\",\n        help=\"Show N slowest setup/test durations (N=0 for all)\",\n    )\n    group.addoption(\n        \"--durations-min\",\n        action=\"store\",\n        type=float,\n        default=None,\n        metavar=\"N\",\n        help=\"Minimal duration in seconds for inclusion in slowest list. \"\n        \"Default: 0.005 (or 0.0 if -vv is given).\",\n    )\n\n\ndef pytest_terminal_summary(terminalreporter: TerminalReporter) -> None:\n    durations = terminalreporter.config"}], "retrieved_count": 10, "cost_time": 1.207397222518921}
{"question": "Where does the configuration loading flow from file discovery to test execution?", "answer": null, "relative_code_list": null, "ground_truth": "The configuration loading flow in pytest follows a structured sequence from file discovery to test execution: 1) Configuration file discovery begins with locate_config() function which searches for configuration files in a specific order: pytest.ini, .pytest.ini, pyproject.toml, tox.ini, and setup.cfg, 2) Root directory determination occurs through get_common_ancestor() which finds the common ancestor directory of specified test paths or uses current working directory as fallback, 3) Configuration file parsing happens through load_config_dict_from_file() which reads and parses the selected configuration file format (INI, TOML, or CFG), 4) Configuration object creation occurs in Config.__init__() which initializes the configuration with parsed values and sets up the plugin manager, 5) Plugin loading phase begins with get_config() which loads essential plugins (mark, main, runner, fixtures, helpconfig) and default plugins, 6) Command-line argument parsing happens through Parser.parse() which processes command-line options and overrides configuration file settings, 7) Configuration validation occurs where settings are validated and any conflicts between command-line and file settings are resolved, 8) Plugin configuration phase happens through pytest_configure hook where plugins can access and modify configuration settings, 9) Test discovery configuration is applied where settings like testpaths, python_files, python_classes, and python_functions influence test collection, 10) Execution configuration is established where settings like addopts, maxfail, and verbosity affect test execution behavior, 11) Configuration integration occurs where the Config object provides access to all settings throughout the test execution process, 12) The entire configuration flow is coordinated through the Config class which serves as the central configuration object accessible to all pytest components and plugins.", "score": null, "retrieved_content": [{"start_line": 19000, "end_line": 21000, "belongs_to": {"file_name": "__init__.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest/config", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "         rootpath,\n                    consider_namespace_packages=consider_namespace_packages,\n                )\n                foundanchor = True\n        if not foundanchor:\n            self._try_load_conftest(\n                invocation_dir,\n                importmode,\n                rootpath,\n                consider_namespace_packages=consider_namespace_packages,\n            )\n\n    def _is_in_confcutdir(self, path: pathlib.Path) -> bool:\n        \"\"\"Whether to consider the given path to load conftests from.\"\"\"\n        if self._confcutdir is None:\n            return True\n        # The semantics here are literally:\n        #   Do not load a conftest if it is found upwards from confcut dir.\n        # But this is *not* the same as:\n        #   Load only conftests from confcutdir or below.\n        # At first glance they might seem the same thing, however we do support use cases where\n        # we want to load conftests that are not found in confcutdir or below, but are found\n        # in completely different directory hierarchies like packages installed\n        # in out-of-source trees.\n        # (see #9767 for a regression where the logic was inverted).\n        return path not in self._confcutdir.parents\n\n    def _try_load_conftest(\n        self,\n        anchor: pathlib.Path,\n        importmode: str | ImportMode,\n        rootpath: pathlib.Path,\n        *,\n        consider_namespace_packages: bool,\n    ) -> None:\n        self._loadconftestmodules(\n            anchor,\n            importmode,\n            rootpath,\n            consider_namespace_packages=consider_namespace_packages,\n        )\n        # let's also consider test* subdirs\n        if anchor.is_dir():\n            for x in anchor.glob(\"test*\"):\n                if x.is_dir():\n                    self._loadconftestmodules(\n                        x,\n                        importmode,\n                        rootpath,\n                        consider_namespace_packages=consider_namespace_packages,\n           "}, {"start_line": 17000, "end_line": 19000, "belongs_to": {"file_name": "test_config.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "monkeypatch.setenv(\"PYTEST_PLUGINS\", \"myplugin\")\n        pytester.syspathinsert()\n        result = pytester.runpytest(\"--foo=1\")\n        result.stdout.fnmatch_lines(\"* no tests ran in *\")\n\n    def test_args_source_args(self, pytester: Pytester):\n        config = pytester.parseconfig(\"--\", \"test_filename.py\")\n        assert config.args_source == Config.ArgsSource.ARGS\n\n    def test_args_source_invocation_dir(self, pytester: Pytester):\n        config = pytester.parseconfig()\n        assert config.args_source == Config.ArgsSource.INVOCATION_DIR\n\n    def test_args_source_testpaths(self, pytester: Pytester):\n        pytester.makeini(\n            \"\"\"\n            [pytest]\n            testpaths=*\n        \"\"\"\n        )\n        config = pytester.parseconfig()\n        assert config.args_source == Config.ArgsSource.TESTPATHS\n\n\nclass TestConfigCmdlineParsing:\n    def test_parsing_again_fails(self, pytester: Pytester) -> None:\n        config = pytester.parseconfig()\n        pytest.raises(AssertionError, lambda: config.parse([]))\n\n    def test_explicitly_specified_config_file_is_loaded(\n        self, pytester: Pytester\n    ) -> None:\n        pytester.makeconftest(\n            \"\"\"\n            def pytest_addoption(parser):\n                parser.addini(\"custom\", \"\")\n        \"\"\"\n        )\n        pytester.makeini(\n            \"\"\"\n            [pytest]\n            custom = 0\n        \"\"\"\n        )\n        pytester.makefile(\n            \".ini\",\n            custom=\"\"\"\n            [pytest]\n            custom = 1\n        \"\"\",\n        )\n        config = pytester.parseconfig(\"-c\", \"custom.ini\")\n        assert config.getini(\"custom\") == \"1\"\n        config = pytester.parseconfig(\"--config-file\", \"custom.ini\")\n        assert config.getini(\"custom\") == \"1\"\n\n        pytester.makefile(\n            \".cfg\",\n            custom_tool_pytest_section=\"\"\"\n            [tool:pytest]\n            custom = 1\n        \"\"\",\n        )\n        config = pytester.parseconfig(\"-c\", \"custom_tool_pytest_section.cfg\")\n   "}, {"start_line": 38000, "end_line": 40000, "belongs_to": {"file_name": "test_config.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "   option_dict = {\"inifilename\": inifilename, \"capture\": \"no\"}\n\n        cwd = tmp_path.joinpath(\"a/b\")\n        cwd.mkdir(parents=True)\n        p2 = cwd.joinpath(\"pytest.ini\")\n        p2.touch()\n        p2.write_text(\n            textwrap.dedent(\n                \"\"\"\\\n                [pytest]\n                name = wrong-value\n                should_not_be_set = true\n                \"\"\"\n            ),\n            encoding=\"utf-8\",\n        )\n        with MonkeyPatch.context() as mp:\n            mp.chdir(cwd)\n            config = Config.fromdictargs(option_dict, ())\n            inipath = absolutepath(inifilename)\n\n        assert config.args == [str(cwd)]\n        assert config.option.inifilename == inifilename\n        assert config.option.capture == \"no\"\n\n        # this indicates this is the file used for getting configuration values\n        assert config.inipath == inipath\n        assert config.inicfg.get(\"name\") == \"value\"\n        assert config.inicfg.get(\"should_not_be_set\") is None\n\n\ndef test_options_on_small_file_do_not_blow_up(pytester: Pytester) -> None:\n    def runfiletest(opts: Sequence[str]) -> None:\n        reprec = pytester.inline_run(*opts)\n        passed, skipped, failed = reprec.countoutcomes()\n        assert failed == 2\n        assert skipped == passed == 0\n\n    path = str(\n        pytester.makepyfile(\n            \"\"\"\n        def test_f1(): assert 0\n        def test_f2(): assert 0\n    \"\"\"\n        )\n    )\n\n    runfiletest([path])\n    runfiletest([\"-l\", path])\n    runfiletest([\"-s\", path])\n    runfiletest([\"--tb=no\", path])\n    runfiletest([\"--tb=short\", path])\n    runfiletest([\"--tb=long\", path])\n    runfiletest([\"--fulltrace\", path])\n    runfiletest([\"--traceconfig\", path])\n    runfiletest([\"-v\", path])\n    runfiletest([\"-v\", \"-v\", path])\n\n\ndef test_preparse_ordering_with_setuptools(\n    pytester: Pytester, monkeypatch: MonkeyPatch\n) -> None:\n    monkeypatch.delenv(\"PYTEST_DISABLE_PLUGIN_AUTOLOAD\", raising=False)\n\n    class EntryPoint:\n        name = \"myt"}, {"start_line": 17000, "end_line": 19000, "belongs_to": {"file_name": "__init__.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest/config", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "nery will try to call it first/as early as possible. \"\n            \"DEPRECATED, use @pytest.hookimpl(tryfirst=True) instead.\",\n        )\n        config.addinivalue_line(\n            \"markers\",\n            \"trylast: mark a hook implementation function such that the \"\n            \"plugin machinery will try to call it last/as late as possible. \"\n            \"DEPRECATED, use @pytest.hookimpl(trylast=True) instead.\",\n        )\n        self._configured = True\n\n    #\n    # Internal API for local conftest plugin handling.\n    #\n    def _set_initial_conftests(\n        self,\n        args: Sequence[str | pathlib.Path],\n        pyargs: bool,\n        noconftest: bool,\n        rootpath: pathlib.Path,\n        confcutdir: pathlib.Path | None,\n        invocation_dir: pathlib.Path,\n        importmode: ImportMode | str,\n        *,\n        consider_namespace_packages: bool,\n    ) -> None:\n        \"\"\"Load initial conftest files given a preparsed \"namespace\".\n\n        As conftest files may add their own command line options which have\n        arguments ('--my-opt somepath') we might get some false positives.\n        All builtin and 3rd party plugins will have been loaded, however, so\n        common options will not confuse our logic here.\n        \"\"\"\n        self._confcutdir = (\n            absolutepath(invocation_dir / confcutdir) if confcutdir else None\n        )\n        self._noconftest = noconftest\n        self._using_pyargs = pyargs\n        foundanchor = False\n        for initial_path in args:\n            path = str(initial_path)\n            # remove node-id syntax\n            i = path.find(\"::\")\n            if i != -1:\n                path = path[:i]\n            anchor = absolutepath(invocation_dir / path)\n\n            # Ensure we do not break if what appears to be an anchor\n            # is in fact a very long option (#10169, #11394).\n            if safe_exists(anchor):\n                self._try_load_conftest(\n                    anchor,\n                    importmode,\n           "}, {"start_line": 30000, "end_line": 32000, "belongs_to": {"file_name": "test_collection.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "ined]\n        assert ids == [\"TestCase.test_classmethod\"]\n\n    def test_class_and_functions_discovery_using_glob(self, pytester: Pytester) -> None:\n        \"\"\"Test that Python_classes and Python_functions config options work\n        as prefixes and glob-like patterns (#600).\"\"\"\n        pytester.makeini(\n            \"\"\"\n            [pytest]\n            python_classes = *Suite Test\n            python_functions = *_test test\n        \"\"\"\n        )\n        p = pytester.makepyfile(\n            \"\"\"\n            class MyTestSuite(object):\n                def x_test(self):\n                    pass\n\n            class TestCase(object):\n                def test_y(self):\n                    pass\n        \"\"\"\n        )\n        items, reprec = pytester.inline_genitems(p)\n        ids = [x.getmodpath() for x in items]  # type: ignore[attr-defined]\n        assert ids == [\"MyTestSuite.x_test\", \"TestCase.test_y\"]\n\n\ndef test_matchnodes_two_collections_same_file(pytester: Pytester) -> None:\n    pytester.makeconftest(\n        \"\"\"\n        import pytest\n        def pytest_configure(config):\n            config.pluginmanager.register(Plugin2())\n\n        class Plugin2(object):\n            def pytest_collect_file(self, file_path, parent):\n                if file_path.suffix == \".abc\":\n                    return MyFile2.from_parent(path=file_path, parent=parent)\n\n        def pytest_collect_file(file_path, parent):\n            if file_path.suffix == \".abc\":\n                return MyFile1.from_parent(path=file_path, parent=parent)\n\n        class MyFile1(pytest.File):\n            def collect(self):\n                yield Item1.from_parent(name=\"item1\", parent=self)\n\n        class MyFile2(pytest.File):\n            def collect(self):\n                yield Item2.from_parent(name=\"item2\", parent=self)\n\n        class Item1(pytest.Item):\n            def runtest(self):\n                pass\n\n        class Item2(pytest.Item):\n            def runtest(self):\n                pass\n    \"\"\"\n    )\n    p = pytester.ma"}, {"start_line": 18000, "end_line": 20000, "belongs_to": {"file_name": "test_config.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "ror, lambda: config.parse([]))\n\n    def test_explicitly_specified_config_file_is_loaded(\n        self, pytester: Pytester\n    ) -> None:\n        pytester.makeconftest(\n            \"\"\"\n            def pytest_addoption(parser):\n                parser.addini(\"custom\", \"\")\n        \"\"\"\n        )\n        pytester.makeini(\n            \"\"\"\n            [pytest]\n            custom = 0\n        \"\"\"\n        )\n        pytester.makefile(\n            \".ini\",\n            custom=\"\"\"\n            [pytest]\n            custom = 1\n        \"\"\",\n        )\n        config = pytester.parseconfig(\"-c\", \"custom.ini\")\n        assert config.getini(\"custom\") == \"1\"\n        config = pytester.parseconfig(\"--config-file\", \"custom.ini\")\n        assert config.getini(\"custom\") == \"1\"\n\n        pytester.makefile(\n            \".cfg\",\n            custom_tool_pytest_section=\"\"\"\n            [tool:pytest]\n            custom = 1\n        \"\"\",\n        )\n        config = pytester.parseconfig(\"-c\", \"custom_tool_pytest_section.cfg\")\n        assert config.getini(\"custom\") == \"1\"\n        config = pytester.parseconfig(\"--config-file\", \"custom_tool_pytest_section.cfg\")\n        assert config.getini(\"custom\") == \"1\"\n\n        pytester.makefile(\n            \".toml\",\n            custom=\"\"\"\n                [tool.pytest.ini_options]\n                custom = 1\n                value = [\n                ]  # this is here on purpose, as it makes this an invalid '.ini' file\n            \"\"\",\n        )\n        config = pytester.parseconfig(\"-c\", \"custom.toml\")\n        assert config.getini(\"custom\") == \"1\"\n        config = pytester.parseconfig(\"--config-file\", \"custom.toml\")\n        assert config.getini(\"custom\") == \"1\"\n\n    def test_absolute_win32_path(self, pytester: Pytester) -> None:\n        temp_ini_file = pytester.makefile(\n            \".ini\",\n            custom=\"\"\"\n            [pytest]\n            addopts = --version\n        \"\"\",\n        )\n        from os.path import normpath\n\n        temp_ini_file_norm = normpath(str(temp_ini_f"}, {"start_line": 49000, "end_line": 51000, "belongs_to": {"file_name": "__init__.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest/config", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "e)\n        if (\n            not os.environ.get(\"PYTEST_DISABLE_PLUGIN_AUTOLOAD\")\n            and not self.known_args_namespace.disable_plugin_autoload\n        ):\n            # Autoloading from distribution package entry point has\n            # not been disabled.\n            self.pluginmanager.load_setuptools_entrypoints(\"pytest11\")\n        # Otherwise only plugins explicitly specified in PYTEST_PLUGINS\n        # are going to be loaded.\n        self.pluginmanager.consider_env()\n\n        self.known_args_namespace = self._parser.parse_known_args(\n            args, namespace=copy.copy(self.known_args_namespace)\n        )\n\n        self._validate_plugins()\n        self._warn_about_skipped_plugins()\n\n        if self.known_args_namespace.confcutdir is None:\n            if self.inipath is not None:\n                confcutdir = str(self.inipath.parent)\n            else:\n                confcutdir = str(self.rootpath)\n            self.known_args_namespace.confcutdir = confcutdir\n        try:\n            self.hook.pytest_load_initial_conftests(\n                early_config=self, args=args, parser=self._parser\n            )\n        except ConftestImportFailure as e:\n            if self.known_args_namespace.help or self.known_args_namespace.version:\n                # we don't want to prevent --help/--version to work\n                # so just let it pass and print a warning at the end\n                self.issue_config_time_warning(\n                    PytestConfigWarning(f\"could not load initial conftests: {e.path}\"),\n                    stacklevel=2,\n                )\n            else:\n                raise\n\n    @hookimpl(wrapper=True)\n    def pytest_collection(self) -> Generator[None, object, object]:\n        # Validate invalid ini keys after collection is done so we take in account\n        # options added by late-loading conftest files.\n        try:\n            return (yield)\n        finally:\n            self._validate_config_options()\n\n    def _checkversion(self) -> None:\n    "}, {"start_line": 20000, "end_line": 22000, "belongs_to": {"file_name": "__init__.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest/config", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": " in completely different directory hierarchies like packages installed\n        # in out-of-source trees.\n        # (see #9767 for a regression where the logic was inverted).\n        return path not in self._confcutdir.parents\n\n    def _try_load_conftest(\n        self,\n        anchor: pathlib.Path,\n        importmode: str | ImportMode,\n        rootpath: pathlib.Path,\n        *,\n        consider_namespace_packages: bool,\n    ) -> None:\n        self._loadconftestmodules(\n            anchor,\n            importmode,\n            rootpath,\n            consider_namespace_packages=consider_namespace_packages,\n        )\n        # let's also consider test* subdirs\n        if anchor.is_dir():\n            for x in anchor.glob(\"test*\"):\n                if x.is_dir():\n                    self._loadconftestmodules(\n                        x,\n                        importmode,\n                        rootpath,\n                        consider_namespace_packages=consider_namespace_packages,\n                    )\n\n    def _loadconftestmodules(\n        self,\n        path: pathlib.Path,\n        importmode: str | ImportMode,\n        rootpath: pathlib.Path,\n        *,\n        consider_namespace_packages: bool,\n    ) -> None:\n        if self._noconftest:\n            return\n\n        directory = self._get_directory(path)\n\n        # Optimization: avoid repeated searches in the same directory.\n        # Assumes always called with same importmode and rootpath.\n        if directory in self._dirpath2confmods:\n            return\n\n        clist = []\n        for parent in reversed((directory, *directory.parents)):\n            if self._is_in_confcutdir(parent):\n                conftestpath = parent / \"conftest.py\"\n                if conftestpath.is_file():\n                    mod = self._importconftest(\n                        conftestpath,\n                        importmode,\n                        rootpath,\n                        consider_namespace_packages=consider_namespace_packages,\n          "}, {"start_line": 3000, "end_line": 5000, "belongs_to": {"file_name": "test_findpaths.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "configuration.\"\"\"\n        fn = tmp_path / \"myconfig.toml\"\n        fn.write_text(\n            dedent(\n                \"\"\"\n            [build_system]\n            x = 1\n            \"\"\"\n            ),\n            encoding=\"utf-8\",\n        )\n        assert load_config_dict_from_file(fn) is None\n\n    def test_valid_toml_file(self, tmp_path: Path) -> None:\n        \"\"\".toml files with [tool.pytest.ini_options] are read correctly, including changing\n        data types to str/list for compatibility with other configuration options.\"\"\"\n        fn = tmp_path / \"myconfig.toml\"\n        fn.write_text(\n            dedent(\n                \"\"\"\n            [tool.pytest.ini_options]\n            x = 1\n            y = 20.0\n            values = [\"tests\", \"integration\"]\n            name = \"foo\"\n            heterogeneous_array = [1, \"str\"]\n            \"\"\"\n            ),\n            encoding=\"utf-8\",\n        )\n        assert load_config_dict_from_file(fn) == {\n            \"x\": \"1\",\n            \"y\": \"20.0\",\n            \"values\": [\"tests\", \"integration\"],\n            \"name\": \"foo\",\n            \"heterogeneous_array\": [1, \"str\"],\n        }\n\n\nclass TestCommonAncestor:\n    def test_has_ancestor(self, tmp_path: Path) -> None:\n        fn1 = tmp_path / \"foo\" / \"bar\" / \"test_1.py\"\n        fn1.parent.mkdir(parents=True)\n        fn1.touch()\n        fn2 = tmp_path / \"foo\" / \"zaz\" / \"test_2.py\"\n        fn2.parent.mkdir(parents=True)\n        fn2.touch()\n        cwd = Path.cwd()\n        assert get_common_ancestor(cwd, [fn1, fn2]) == tmp_path / \"foo\"\n        assert get_common_ancestor(cwd, [fn1.parent, fn2]) == tmp_path / \"foo\"\n        assert get_common_ancestor(cwd, [fn1.parent, fn2.parent]) == tmp_path / \"foo\"\n        assert get_common_ancestor(cwd, [fn1, fn2.parent]) == tmp_path / \"foo\"\n\n    def test_single_dir(self, tmp_path: Path) -> None:\n        assert get_common_ancestor(Path.cwd(), [tmp_path]) == tmp_path\n\n    def test_single_file(self, tmp_path: Path) -> None:\n        fn = tmp_path / \"foo.py\"\n     "}, {"start_line": 1000, "end_line": 3000, "belongs_to": {"file_name": "test_findpaths.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "    def test_custom_ini(self, tmp_path: Path) -> None:\n        \"\"\"[pytest] section in any .ini file is read correctly\"\"\"\n        fn = tmp_path / \"custom.ini\"\n        fn.write_text(\"[pytest]\\nx=1\", encoding=\"utf-8\")\n        assert load_config_dict_from_file(fn) == {\"x\": \"1\"}\n\n    def test_custom_ini_without_section(self, tmp_path: Path) -> None:\n        \"\"\"Custom .ini files without [pytest] section are not considered for configuration\"\"\"\n        fn = tmp_path / \"custom.ini\"\n        fn.write_text(\"[custom]\", encoding=\"utf-8\")\n        assert load_config_dict_from_file(fn) is None\n\n    def test_custom_cfg_file(self, tmp_path: Path) -> None:\n        \"\"\"Custom .cfg files without [tool:pytest] section are not considered for configuration\"\"\"\n        fn = tmp_path / \"custom.cfg\"\n        fn.write_text(\"[custom]\", encoding=\"utf-8\")\n        assert load_config_dict_from_file(fn) is None\n\n    def test_valid_cfg_file(self, tmp_path: Path) -> None:\n        \"\"\"Custom .cfg files with [tool:pytest] section are read correctly\"\"\"\n        fn = tmp_path / \"custom.cfg\"\n        fn.write_text(\"[tool:pytest]\\nx=1\", encoding=\"utf-8\")\n        assert load_config_dict_from_file(fn) == {\"x\": \"1\"}\n\n    def test_unsupported_pytest_section_in_cfg_file(self, tmp_path: Path) -> None:\n        \"\"\".cfg files with [pytest] section are no longer supported and should fail to alert users\"\"\"\n        fn = tmp_path / \"custom.cfg\"\n        fn.write_text(\"[pytest]\", encoding=\"utf-8\")\n        with pytest.raises(pytest.fail.Exception):\n            load_config_dict_from_file(fn)\n\n    def test_invalid_toml_file(self, tmp_path: Path) -> None:\n        \"\"\"Invalid .toml files should raise `UsageError`.\"\"\"\n        fn = tmp_path / \"myconfig.toml\"\n        fn.write_text(\"]invalid toml[\", encoding=\"utf-8\")\n        with pytest.raises(UsageError):\n            load_config_dict_from_file(fn)\n\n    def test_custom_toml_file(self, tmp_path: Path) -> None:\n        \"\"\".toml files without [tool.pytest.ini_options] are not considered for "}], "retrieved_count": 10, "cost_time": 1.2250113487243652}
{"question": "Why does Pytest use incremental test discovery for performance improvement?", "answer": null, "relative_code_list": null, "ground_truth": "Pytest uses incremental test discovery for performance improvement to optimize test execution in large test suites and development workflows: 1) Incremental discovery allows pytest to skip tests that have already passed in previous runs, reducing redundant test execution and improving overall performance, 2) The --lf (last-failed) option runs only the tests that failed in the previous run, enabling developers to focus on fixing broken tests quickly, 3) The --ff (failed-first) option runs failed tests first, then previously passed tests, providing faster feedback on critical issues, 4) The --nf (new-first) option prioritizes newly added tests, ensuring new code is tested before running the full suite, 5) Incremental discovery reduces test execution time in development cycles where only a subset of tests need to be run, 6) Caching mechanisms store test results and node IDs to enable intelligent test selection in subsequent runs, 7) The stepwise plugin provides incremental testing for test classes, stopping execution when a test fails to avoid unnecessary test runs, 8) Incremental discovery supports CI/CD pipelines by allowing selective test execution based on code changes, 9) Large test suites benefit significantly from incremental discovery as only relevant tests are executed, 10) The caching system maintains test state across multiple pytest invocations, enabling persistent incremental behavior, 11) Incremental discovery reduces resource consumption by avoiding redundant test setup and teardown operations, 12) The approach improves developer productivity by providing faster feedback loops and reducing wait times for test results.", "score": null, "retrieved_content": [{"start_line": 33000, "end_line": 35000, "belongs_to": {"file_name": "collect.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing/python", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "   This tests a performance optimization, not correctness, really,\n        although it tests PytestCollectionWarning is not raised, while\n        it would have been raised otherwise.\n        \"\"\"\n        pytester.makeini(\n            \"\"\"\n            [pytest]\n            python_classes=*\n            python_functions=*\n        \"\"\"\n        )\n        pytester.makepyfile(\n            \"\"\"\n            class TestEmpty:\n                pass\n            test_empty = TestEmpty()\n            def test_real():\n                pass\n        \"\"\"\n        )\n        items, rec = pytester.inline_genitems()\n        assert rec.ret == 0\n        assert len(items) == 1\n\n\ndef test_setup_only_available_in_subdir(pytester: Pytester) -> None:\n    sub1 = pytester.mkpydir(\"sub1\")\n    sub2 = pytester.mkpydir(\"sub2\")\n    sub1.joinpath(\"conftest.py\").write_text(\n        textwrap.dedent(\n            \"\"\"\\\n            import pytest\n            def pytest_runtest_setup(item):\n                assert item.path.stem == \"test_in_sub1\"\n            def pytest_runtest_call(item):\n                assert item.path.stem == \"test_in_sub1\"\n            def pytest_runtest_teardown(item):\n                assert item.path.stem == \"test_in_sub1\"\n            \"\"\"\n        ),\n        encoding=\"utf-8\",\n    )\n    sub2.joinpath(\"conftest.py\").write_text(\n        textwrap.dedent(\n            \"\"\"\\\n            import pytest\n            def pytest_runtest_setup(item):\n                assert item.path.stem == \"test_in_sub2\"\n            def pytest_runtest_call(item):\n                assert item.path.stem == \"test_in_sub2\"\n            def pytest_runtest_teardown(item):\n                assert item.path.stem == \"test_in_sub2\"\n            \"\"\"\n        ),\n        encoding=\"utf-8\",\n    )\n    sub1.joinpath(\"test_in_sub1.py\").write_text(\"def test_1(): pass\", encoding=\"utf-8\")\n    sub2.joinpath(\"test_in_sub2.py\").write_text(\"def test_2(): pass\", encoding=\"utf-8\")\n    result = pytester.runpytest(\"-v\", \"-s\")\n    result.assert_outcomes(passed=2)\n\n"}, {"start_line": 23000, "end_line": 25000, "belongs_to": {"file_name": "test_collection.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": " hookrec.assert_contains(\n            [\n                (\"pytest_collectstart\", \"collector.path == test_aaa\"),\n                (\"pytest_pycollect_makeitem\", \"name == 'test_func'\"),\n                (\"pytest_collectreport\", \"report.nodeid.startswith('aaa/test_aaa.py')\"),\n            ]\n        )\n\n    def test_collect_two_commandline_args(self, pytester: Pytester) -> None:\n        p = pytester.makepyfile(\"def test_func(): pass\")\n        aaa = pytester.mkpydir(\"aaa\")\n        bbb = pytester.mkpydir(\"bbb\")\n        test_aaa = aaa.joinpath(\"test_aaa.py\")\n        shutil.copy(p, test_aaa)\n        test_bbb = bbb.joinpath(\"test_bbb.py\")\n        p.replace(test_bbb)\n\n        id = \".\"\n\n        items, hookrec = pytester.inline_genitems(id)\n        assert len(items) == 2\n        pprint.pprint(hookrec.calls)\n        hookrec.assert_contains(\n            [\n                (\"pytest_collectstart\", \"collector.path == test_aaa\"),\n                (\"pytest_pycollect_makeitem\", \"name == 'test_func'\"),\n                (\"pytest_collectreport\", \"report.nodeid == 'aaa/test_aaa.py'\"),\n                (\"pytest_collectstart\", \"collector.path == test_bbb\"),\n                (\"pytest_pycollect_makeitem\", \"name == 'test_func'\"),\n                (\"pytest_collectreport\", \"report.nodeid == 'bbb/test_bbb.py'\"),\n            ]\n        )\n\n    def test_serialization_byid(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\"def test_func(): pass\")\n        items, hookrec = pytester.inline_genitems()\n        assert len(items) == 1\n        (item,) = items\n        items2, hookrec = pytester.inline_genitems(item.nodeid)\n        (item2,) = items2\n        assert item2.name == item.name\n        assert item2.path == item.path\n\n    def test_find_byid_without_instance_parents(self, pytester: Pytester) -> None:\n        p = pytester.makepyfile(\n            \"\"\"\n            class TestClass(object):\n                def test_method(self):\n                    pass\n        \"\"\"\n        )\n        arg = p.name + \"::TestClas"}, {"start_line": 2000, "end_line": 4000, "belongs_to": {"file_name": "test_conftest.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "s(\n            p, importmode=\"prepend\", rootpath=basedir, consider_namespace_packages=False\n        )\n        assert conftest._rget_with_confmod(\"a\", p)[1] == 1\n\n    def test_immediate_initialization_and_incremental_are_the_same(\n        self, basedir: Path\n    ) -> None:\n        conftest = PytestPluginManager()\n        assert not len(conftest._dirpath2confmods)\n        conftest._loadconftestmodules(\n            basedir,\n            importmode=\"prepend\",\n            rootpath=basedir,\n            consider_namespace_packages=False,\n        )\n        snap1 = len(conftest._dirpath2confmods)\n        assert snap1 == 1\n        conftest._loadconftestmodules(\n            basedir / \"adir\",\n            importmode=\"prepend\",\n            rootpath=basedir,\n            consider_namespace_packages=False,\n        )\n        assert len(conftest._dirpath2confmods) == snap1 + 1\n        conftest._loadconftestmodules(\n            basedir / \"b\",\n            importmode=\"prepend\",\n            rootpath=basedir,\n            consider_namespace_packages=False,\n        )\n        assert len(conftest._dirpath2confmods) == snap1 + 2\n\n    def test_value_access_not_existing(self, basedir: Path) -> None:\n        conftest = ConftestWithSetinitial(basedir)\n        with pytest.raises(KeyError):\n            conftest._rget_with_confmod(\"a\", basedir)\n\n    def test_value_access_by_path(self, basedir: Path) -> None:\n        conftest = ConftestWithSetinitial(basedir)\n        adir = basedir / \"adir\"\n        conftest._loadconftestmodules(\n            adir,\n            importmode=\"prepend\",\n            rootpath=basedir,\n            consider_namespace_packages=False,\n        )\n        assert conftest._rget_with_confmod(\"a\", adir)[1] == 1\n        conftest._loadconftestmodules(\n            adir / \"b\",\n            importmode=\"prepend\",\n            rootpath=basedir,\n            consider_namespace_packages=False,\n        )\n        assert conftest._rget_with_confmod(\"a\", adir / \"b\")[1] == 1.5\n\n    def test_value_access_w"}, {"start_line": 16000, "end_line": 18000, "belongs_to": {"file_name": "cacheprovider.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "nodeids = set(config.cache.get(\"cache/nodeids\", []))\n\n    @hookimpl(wrapper=True, tryfirst=True)\n    def pytest_collection_modifyitems(self, items: list[nodes.Item]) -> Generator[None]:\n        res = yield\n\n        if self.active:\n            new_items: dict[str, nodes.Item] = {}\n            other_items: dict[str, nodes.Item] = {}\n            for item in items:\n                if item.nodeid not in self.cached_nodeids:\n                    new_items[item.nodeid] = item\n                else:\n                    other_items[item.nodeid] = item\n\n            items[:] = self._get_increasing_order(\n                new_items.values()\n            ) + self._get_increasing_order(other_items.values())\n            self.cached_nodeids.update(new_items)\n        else:\n            self.cached_nodeids.update(item.nodeid for item in items)\n\n        return res\n\n    def _get_increasing_order(self, items: Iterable[nodes.Item]) -> list[nodes.Item]:\n        return sorted(items, key=lambda item: item.path.stat().st_mtime, reverse=True)\n\n    def pytest_sessionfinish(self) -> None:\n        config = self.config\n        if config.getoption(\"cacheshow\") or hasattr(config, \"workerinput\"):\n            return\n\n        if config.getoption(\"collectonly\"):\n            return\n\n        assert config.cache is not None\n        config.cache.set(\"cache/nodeids\", sorted(self.cached_nodeids))\n\n\ndef pytest_addoption(parser: Parser) -> None:\n    group = parser.getgroup(\"general\")\n    group.addoption(\n        \"--lf\",\n        \"--last-failed\",\n        action=\"store_true\",\n        dest=\"lf\",\n        help=\"Rerun only the tests that failed at the last run (or all if none failed)\",\n    )\n    group.addoption(\n        \"--ff\",\n        \"--failed-first\",\n        action=\"store_true\",\n        dest=\"failedfirst\",\n        help=\"Run all tests, but run the last failures first. \"\n        \"This may re-order tests and thus lead to \"\n        \"repeated fixture setup/teardown.\",\n    )\n    group.addoption(\n        \"--nf\",\n        \"--ne"}, {"start_line": 11000, "end_line": 13000, "belongs_to": {"file_name": "main.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": " return None\n\n\ndef pytest_collection(session: Session) -> None:\n    session.perform_collect()\n\n\ndef pytest_runtestloop(session: Session) -> bool:\n    if session.testsfailed and not session.config.option.continue_on_collection_errors:\n        raise session.Interrupted(\n            f\"{session.testsfailed} error{'s' if session.testsfailed != 1 else ''} during collection\"\n        )\n\n    if session.config.option.collectonly:\n        return True\n\n    for i, item in enumerate(session.items):\n        nextitem = session.items[i + 1] if i + 1 < len(session.items) else None\n        item.config.hook.pytest_runtest_protocol(item=item, nextitem=nextitem)\n        if session.shouldfail:\n            raise session.Failed(session.shouldfail)\n        if session.shouldstop:\n            raise session.Interrupted(session.shouldstop)\n    return True\n\n\ndef _in_venv(path: Path) -> bool:\n    \"\"\"Attempt to detect if ``path`` is the root of a Virtual Environment by\n    checking for the existence of the pyvenv.cfg file.\n\n    [https://peps.python.org/pep-0405/]\n\n    For regression protection we also check for conda environments that do not include pyenv.cfg yet --\n    https://github.com/conda/conda/issues/13337 is the conda issue tracking adding pyenv.cfg.\n\n    Checking for the `conda-meta/history` file per https://github.com/pytest-dev/pytest/issues/12652#issuecomment-2246336902.\n\n    \"\"\"\n    try:\n        return (\n            path.joinpath(\"pyvenv.cfg\").is_file()\n            or path.joinpath(\"conda-meta\", \"history\").is_file()\n        )\n    except OSError:\n        return False\n\n\ndef pytest_ignore_collect(collection_path: Path, config: Config) -> bool | None:\n    if collection_path.name == \"__pycache__\":\n        return True\n\n    ignore_paths = config._getconftest_pathlist(\n        \"collect_ignore\", path=collection_path.parent\n    )\n    ignore_paths = ignore_paths or []\n    excludeopt = config.getoption(\"ignore\")\n    if excludeopt:\n        ignore_paths.extend(absolutepath(x) for x in excludeopt)\n\n "}, {"start_line": 42000, "end_line": 44000, "belongs_to": {"file_name": "test_cacheprovider.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "\n        )\n\n        result = pytester.runpytest(\"-v\", \"--nf\")\n        result.stdout.fnmatch_lines(\n            [\n                \"*test_2/test_2.py::test_1[1*\",\n                \"*test_2/test_2.py::test_1[2*\",\n                \"*test_1/test_1.py::test_1[1*\",\n                \"*test_1/test_1.py::test_1[2*\",\n            ]\n        )\n\n        p1.write_text(\n            \"import pytest\\n\"\n            \"@pytest.mark.parametrize('num', [1, 2, 3])\\n\"\n            \"def test_1(num): assert num\\n\",\n            encoding=\"utf-8\",\n        )\n        os.utime(p1, ns=(p1.stat().st_atime_ns, int(1e9)))\n\n        # Running only a subset does not forget about existing ones.\n        result = pytester.runpytest(\"-v\", \"--nf\", \"test_2/test_2.py\")\n        result.stdout.fnmatch_lines(\n            [\"*test_2/test_2.py::test_1[1*\", \"*test_2/test_2.py::test_1[2*\"]\n        )\n\n        result = pytester.runpytest(\"-v\", \"--nf\")\n        result.stdout.fnmatch_lines(\n            [\n                \"*test_1/test_1.py::test_1[3*\",\n                \"*test_2/test_2.py::test_1[1*\",\n                \"*test_2/test_2.py::test_1[2*\",\n                \"*test_1/test_1.py::test_1[1*\",\n                \"*test_1/test_1.py::test_1[2*\",\n            ]\n        )\n\n\nclass TestReadme:\n    def check_readme(self, pytester: Pytester) -> bool:\n        config = pytester.parseconfigure()\n        assert config.cache is not None\n        readme = config.cache._cachedir.joinpath(\"README.md\")\n        return readme.is_file()\n\n    def test_readme_passed(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\"def test_always_passes(): pass\")\n        pytester.runpytest()\n        assert self.check_readme(pytester) is True\n\n    def test_readme_failed(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\"def test_always_fails(): assert 0\")\n        pytester.runpytest()\n        assert self.check_readme(pytester) is True\n\n\nclass Action(Enum):\n    \"\"\"Action to perform on the cache directory.\"\"\"\n\n    MKDIR = auto()\n    SET = auto()\n\n\n@pyte"}, {"start_line": 32000, "end_line": 34000, "belongs_to": {"file_name": "test_assertrewrite.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "pycs) == 1\n            os.rename(pycs[0], \"orphan.pyc\")\n\n        assert pytester.runpytest().ret == 0\n\n    def test_cached_pyc_includes_pytest_version(\n        self, pytester: Pytester, monkeypatch\n    ) -> None:\n        \"\"\"Avoid stale caches (#1671)\"\"\"\n        monkeypatch.delenv(\"PYTHONDONTWRITEBYTECODE\", raising=False)\n        monkeypatch.delenv(\"PYTHONPYCACHEPREFIX\", raising=False)\n        pytester.makepyfile(\n            test_foo=\"\"\"\n            def test_foo():\n                assert True\n            \"\"\"\n        )\n        result = pytester.runpytest_subprocess()\n        assert result.ret == 0\n        found_names = glob.glob(f\"__pycache__/*-pytest-{pytest.__version__}.pyc\")\n        assert found_names, \"pyc with expected tag not found in names: {}\".format(\n            glob.glob(\"__pycache__/*.pyc\")\n        )\n\n    @pytest.mark.skipif('\"__pypy__\" in sys.modules')\n    def test_pyc_vs_pyo(\n        self,\n        pytester: Pytester,\n        monkeypatch: pytest.MonkeyPatch,\n    ) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n            def test_optimized():\n                \"hello\"\n                assert test_optimized.__doc__ is None\"\"\"\n        )\n        p = make_numbered_dir(root=Path(pytester.path), prefix=\"runpytest-\")\n        tmp = f\"--basetemp={p}\"\n        with monkeypatch.context() as mp:\n            mp.setenv(\"PYTHONOPTIMIZE\", \"2\")\n            mp.delenv(\"PYTHONDONTWRITEBYTECODE\", raising=False)\n            mp.delenv(\"PYTHONPYCACHEPREFIX\", raising=False)\n            assert pytester.runpytest_subprocess(tmp).ret == 0\n            tagged = \"test_pyc_vs_pyo.\" + PYTEST_TAG\n            assert tagged + \".pyo\" in os.listdir(\"__pycache__\")\n        monkeypatch.delenv(\"PYTHONDONTWRITEBYTECODE\", raising=False)\n        monkeypatch.delenv(\"PYTHONPYCACHEPREFIX\", raising=False)\n        assert pytester.runpytest_subprocess(tmp).ret == 1\n        assert tagged + \".pyc\" in os.listdir(\"__pycache__\")\n\n    def test_package(self, pytester: Pytester) -> N"}, {"start_line": 50000, "end_line": 52000, "belongs_to": {"file_name": "test_collection.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "d not contain \"sub/\"!\n            \"test_real.py::test_nodeid PASSED\"\n        ]\n    )\n    assert result.ret == 0\n\n\ndef test_collect_symlink_dir(pytester: Pytester) -> None:\n    \"\"\"A symlinked directory is collected.\"\"\"\n    dir = pytester.mkdir(\"dir\")\n    dir.joinpath(\"test_it.py\").write_text(\"def test_it(): pass\", \"utf-8\")\n    symlink_or_skip(pytester.path.joinpath(\"symlink_dir\"), dir)\n    result = pytester.runpytest()\n    result.assert_outcomes(passed=2)\n\n\ndef test_collectignore_via_conftest(pytester: Pytester) -> None:\n    \"\"\"collect_ignore in parent conftest skips importing child (issue #4592).\"\"\"\n    tests = pytester.mkpydir(\"tests\")\n    tests.joinpath(\"conftest.py\").write_text(\n        \"collect_ignore = ['ignore_me']\", encoding=\"utf-8\"\n    )\n\n    ignore_me = tests.joinpath(\"ignore_me\")\n    ignore_me.mkdir()\n    ignore_me.joinpath(\"__init__.py\").touch()\n    ignore_me.joinpath(\"conftest.py\").write_text(\n        \"assert 0, 'should_not_be_called'\", encoding=\"utf-8\"\n    )\n\n    result = pytester.runpytest()\n    assert result.ret == ExitCode.NO_TESTS_COLLECTED\n\n\ndef test_collect_pkg_init_and_file_in_args(pytester: Pytester) -> None:\n    subdir = pytester.mkdir(\"sub\")\n    init = subdir.joinpath(\"__init__.py\")\n    init.write_text(\"def test_init(): pass\", encoding=\"utf-8\")\n    p = subdir.joinpath(\"test_file.py\")\n    p.write_text(\"def test_file(): pass\", encoding=\"utf-8\")\n\n    # Just the package directory, the __init__.py module is filtered out.\n    result = pytester.runpytest(\"-v\", subdir)\n    result.stdout.fnmatch_lines(\n        [\n            \"sub/test_file.py::test_file PASSED*\",\n            \"*1 passed in*\",\n        ]\n    )\n\n    # But it's included if specified directly.\n    result = pytester.runpytest(\"-v\", init, p)\n    result.stdout.fnmatch_lines(\n        [\n            \"sub/__init__.py::test_init PASSED*\",\n            \"sub/test_file.py::test_file PASSED*\",\n            \"*2 passed in*\",\n        ]\n    )\n\n    # Or if the pattern allows it.\n    result = pytester.runpytest("}, {"start_line": 17000, "end_line": 19000, "belongs_to": {"file_name": "cacheprovider.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "().st_mtime, reverse=True)\n\n    def pytest_sessionfinish(self) -> None:\n        config = self.config\n        if config.getoption(\"cacheshow\") or hasattr(config, \"workerinput\"):\n            return\n\n        if config.getoption(\"collectonly\"):\n            return\n\n        assert config.cache is not None\n        config.cache.set(\"cache/nodeids\", sorted(self.cached_nodeids))\n\n\ndef pytest_addoption(parser: Parser) -> None:\n    group = parser.getgroup(\"general\")\n    group.addoption(\n        \"--lf\",\n        \"--last-failed\",\n        action=\"store_true\",\n        dest=\"lf\",\n        help=\"Rerun only the tests that failed at the last run (or all if none failed)\",\n    )\n    group.addoption(\n        \"--ff\",\n        \"--failed-first\",\n        action=\"store_true\",\n        dest=\"failedfirst\",\n        help=\"Run all tests, but run the last failures first. \"\n        \"This may re-order tests and thus lead to \"\n        \"repeated fixture setup/teardown.\",\n    )\n    group.addoption(\n        \"--nf\",\n        \"--new-first\",\n        action=\"store_true\",\n        dest=\"newfirst\",\n        help=\"Run tests from new files first, then the rest of the tests \"\n        \"sorted by file mtime\",\n    )\n    group.addoption(\n        \"--cache-show\",\n        action=\"append\",\n        nargs=\"?\",\n        dest=\"cacheshow\",\n        help=(\n            \"Show cache contents, don't perform collection or tests. \"\n            \"Optional argument: glob (default: '*').\"\n        ),\n    )\n    group.addoption(\n        \"--cache-clear\",\n        action=\"store_true\",\n        dest=\"cacheclear\",\n        help=\"Remove all cache contents at start of test run\",\n    )\n    cache_dir_default = \".pytest_cache\"\n    if \"TOX_ENV_DIR\" in os.environ:\n        cache_dir_default = os.path.join(os.environ[\"TOX_ENV_DIR\"], cache_dir_default)\n    parser.addini(\"cache_dir\", default=cache_dir_default, help=\"Cache directory path\")\n    group.addoption(\n        \"--lfnf\",\n        \"--last-failed-no-failures\",\n        action=\"store\",\n        dest=\"last_failed_no_f"}, {"start_line": 27000, "end_line": 29000, "belongs_to": {"file_name": "test_collection.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "h.context() as mp:\n            mp.chdir(subdir)\n            config = pytester.parseconfigure(x)\n        col = pytester.getnode(config, x)\n        assert col is not None\n        assert col.name == \"x.py\"\n        assert isinstance(col, pytest.Module)\n        assert isinstance(col.parent, pytest.Package)\n        assert isinstance(col.parent.parent, pytest.Session)\n        # session is batman (has no parents)\n        assert col.parent.parent.parent is None\n        for parent in col.listchain():\n            assert parent.config is config\n\n\nclass Test_genitems:\n    def test_check_collect_hashes(self, pytester: Pytester) -> None:\n        p = pytester.makepyfile(\n            \"\"\"\n            def test_1():\n                pass\n\n            def test_2():\n                pass\n        \"\"\"\n        )\n        shutil.copy(p, p.parent / (p.stem + \"2\" + \".py\"))\n        items, reprec = pytester.inline_genitems(p.parent)\n        assert len(items) == 4\n        for numi, i in enumerate(items):\n            for numj, j in enumerate(items):\n                if numj != numi:\n                    assert hash(i) != hash(j)\n                    assert i != j\n\n    def test_example_items1(self, pytester: Pytester) -> None:\n        p = pytester.makepyfile(\n            \"\"\"\n            import pytest\n\n            def testone():\n                pass\n\n            class TestX(object):\n                def testmethod_one(self):\n                    pass\n\n            class TestY(TestX):\n                @pytest.mark.parametrize(\"arg0\", [\".[\"])\n                def testmethod_two(self, arg0):\n                    pass\n        \"\"\"\n        )\n        items, reprec = pytester.inline_genitems(p)\n        assert len(items) == 4\n        assert items[0].name == \"testone\"\n        assert items[1].name == \"testmethod_one\"\n        assert items[2].name == \"testmethod_one\"\n        assert items[3].name == \"testmethod_two[.[]\"\n\n        # let's also test getmodpath here\n        assert items[0].getmodpath() == \"testone\"  # type: igno"}], "retrieved_count": 10, "cost_time": 1.231902837753296}
{"question": "Where does Pytest implement its test discovery logic?", "answer": null, "relative_code_list": null, "ground_truth": "Pytest implements its test discovery logic across several key modules in the codebase: 1) The main test discovery entry point is in src/_pytest/main.py where the Session.perform_collect() method initiates the collection process, 2) The pytest_collection hook in src/_pytest/main.py orchestrates the overall collection phase and coordinates the discovery process, 3) The collector hierarchy is implemented in src/_pytest/nodes.py with classes like Session, Directory, File, Module, Class, and Function that form the collection tree, 4) Python-specific test discovery is implemented in src/_pytest/python.py which handles discovery of test files, classes, and functions based on naming conventions, 5) The pytest_addoption hook in src/_pytest/python.py defines configuration options for test discovery like python_files, python_classes, and python_functions, 6) File system scanning and path handling is implemented in src/_pytest/pathlib.py with functions like scandir() and fnmatch_ex() for directory traversal and pattern matching, 7) Configuration-based discovery settings are managed in src/_pytest/config/__init__.py where testpaths, norecursedirs, and other discovery options are processed, 8) The _decide_args method in Config class determines which paths to search based on command line arguments, testpaths configuration, or current directory, 9) Test file pattern matching is handled through configuration options that define which files are considered test files (default: test_*.py, *_test.py), 10) Test class and function discovery uses pattern matching against configured prefixes (default: Test for classes, test for functions), 11) The collect_one_node function in src/_pytest/runner.py handles the collection of individual test nodes during the discovery process, 12) The entire discovery system is extensible through the plugin system, allowing custom collectors to be implemented for different file types or test frameworks.", "score": null, "retrieved_content": [{"start_line": 42000, "end_line": 44000, "belongs_to": {"file_name": "collect.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing/python", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "def intest_foo(self):\n                    pass\n\n                def test_bar(self):\n                    pass\n        \"\"\"\n        )\n        classcol = pytester.collect_by_name(modcol, \"TestClass\")\n        assert isinstance(classcol, Class)\n        path, lineno, msg = classcol.reportinfo()\n        func = next(iter(classcol.collect()))\n        assert isinstance(func, Function)\n        path, lineno, msg = func.reportinfo()\n\n\ndef test_customized_python_discovery(pytester: Pytester) -> None:\n    pytester.makeini(\n        \"\"\"\n        [pytest]\n        python_files=check_*.py\n        python_classes=Check\n        python_functions=check\n    \"\"\"\n    )\n    p = pytester.makepyfile(\n        \"\"\"\n        def check_simple():\n            pass\n        class CheckMyApp(object):\n            def check_meth(self):\n                pass\n    \"\"\"\n    )\n    p2 = p.with_name(p.name.replace(\"test\", \"check\"))\n    p.rename(p2)\n    result = pytester.runpytest(\"--collect-only\", \"-s\")\n    result.stdout.fnmatch_lines(\n        [\"*check_customized*\", \"*check_simple*\", \"*CheckMyApp*\", \"*check_meth*\"]\n    )\n\n    result = pytester.runpytest()\n    assert result.ret == 0\n    result.stdout.fnmatch_lines([\"*2 passed*\"])\n\n\ndef test_customized_python_discovery_functions(pytester: Pytester) -> None:\n    pytester.makeini(\n        \"\"\"\n        [pytest]\n        python_functions=_test\n    \"\"\"\n    )\n    pytester.makepyfile(\n        \"\"\"\n        def _test_underscore():\n            pass\n    \"\"\"\n    )\n    result = pytester.runpytest(\"--collect-only\", \"-s\")\n    result.stdout.fnmatch_lines([\"*_test_underscore*\"])\n\n    result = pytester.runpytest()\n    assert result.ret == 0\n    result.stdout.fnmatch_lines([\"*1 passed*\"])\n\n\ndef test_unorderable_types(pytester: Pytester) -> None:\n    pytester.makepyfile(\n        \"\"\"\n        class TestJoinEmpty(object):\n            pass\n\n        def make_test():\n            class Test(object):\n                pass\n            Test.__name__ = \"TestFoo\"\n            return Test\n        TestFoo = ma"}, {"start_line": 6000, "end_line": 8000, "belongs_to": {"file_name": "python.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "f pytest_collect_directory(\n    path: Path, parent: nodes.Collector\n) -> nodes.Collector | None:\n    pkginit = path / \"__init__.py\"\n    try:\n        has_pkginit = pkginit.is_file()\n    except PermissionError:\n        # See https://github.com/pytest-dev/pytest/issues/12120#issuecomment-2106349096.\n        return None\n    if has_pkginit:\n        return Package.from_parent(parent, path=path)\n    return None\n\n\ndef pytest_collect_file(file_path: Path, parent: nodes.Collector) -> Module | None:\n    if file_path.suffix == \".py\":\n        if not parent.session.isinitpath(file_path):\n            if not path_matches_patterns(\n                file_path, parent.config.getini(\"python_files\")\n            ):\n                return None\n        ihook = parent.session.gethookproxy(file_path)\n        module: Module = ihook.pytest_pycollect_makemodule(\n            module_path=file_path, parent=parent\n        )\n        return module\n    return None\n\n\ndef path_matches_patterns(path: Path, patterns: Iterable[str]) -> bool:\n    \"\"\"Return whether path matches any of the patterns in the list of globs given.\"\"\"\n    return any(fnmatch_ex(pattern, path) for pattern in patterns)\n\n\ndef pytest_pycollect_makemodule(module_path: Path, parent) -> Module:\n    return Module.from_parent(parent, path=module_path)\n\n\n@hookimpl(trylast=True)\ndef pytest_pycollect_makeitem(\n    collector: Module | Class, name: str, obj: object\n) -> None | nodes.Item | nodes.Collector | list[nodes.Item | nodes.Collector]:\n    assert isinstance(collector, (Class, Module)), type(collector)\n    # Nothing was collected elsewhere, let's do it here.\n    if safe_isclass(obj):\n        if collector.istestclass(obj, name):\n            return Class.from_parent(collector, name=name, obj=obj)\n    elif collector.istestfunction(obj, name):\n        # mock seems to store unbound methods (issue473), normalize it.\n        obj = getattr(obj, \"__func__\", obj)\n        # We need to try and unwrap the function if it's a functools.partial\n        # or"}, {"start_line": 2000, "end_line": 4000, "belongs_to": {"file_name": "python.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "ytest.mark.structures import Mark\nfrom _pytest.mark.structures import MarkDecorator\nfrom _pytest.mark.structures import normalize_mark_list\nfrom _pytest.outcomes import fail\nfrom _pytest.outcomes import skip\nfrom _pytest.pathlib import fnmatch_ex\nfrom _pytest.pathlib import import_path\nfrom _pytest.pathlib import ImportPathMismatchError\nfrom _pytest.pathlib import scandir\nfrom _pytest.scope import _ScopeName\nfrom _pytest.scope import Scope\nfrom _pytest.stash import StashKey\nfrom _pytest.warning_types import PytestCollectionWarning\nfrom _pytest.warning_types import PytestReturnNotNoneWarning\n\n\nif TYPE_CHECKING:\n    from typing_extensions import Self\n\n\ndef pytest_addoption(parser: Parser) -> None:\n    parser.addini(\n        \"python_files\",\n        type=\"args\",\n        # NOTE: default is also used in AssertionRewritingHook.\n        default=[\"test_*.py\", \"*_test.py\"],\n        help=\"Glob-style file patterns for Python test module discovery\",\n    )\n    parser.addini(\n        \"python_classes\",\n        type=\"args\",\n        default=[\"Test\"],\n        help=\"Prefixes or glob names for Python test class discovery\",\n    )\n    parser.addini(\n        \"python_functions\",\n        type=\"args\",\n        default=[\"test\"],\n        help=\"Prefixes or glob names for Python test function and method discovery\",\n    )\n    parser.addini(\n        \"disable_test_id_escaping_and_forfeit_all_rights_to_community_support\",\n        type=\"bool\",\n        default=False,\n        help=\"Disable string escape non-ASCII characters, might cause unwanted \"\n        \"side effects(use at your own risk)\",\n    )\n\n\ndef pytest_generate_tests(metafunc: Metafunc) -> None:\n    for marker in metafunc.definition.iter_markers(name=\"parametrize\"):\n        metafunc.parametrize(*marker.args, **marker.kwargs, _param_mark=marker)\n\n\ndef pytest_configure(config: Config) -> None:\n    config.addinivalue_line(\n        \"markers\",\n        \"parametrize(argnames, argvalues): call a test function multiple \"\n        \"times passing in differe"}, {"start_line": 1000, "end_line": 3000, "belongs_to": {"file_name": "python.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "code.code import Traceback\nfrom _pytest._io.saferepr import saferepr\nfrom _pytest.compat import ascii_escaped\nfrom _pytest.compat import get_default_arg_names\nfrom _pytest.compat import get_real_func\nfrom _pytest.compat import getimfunc\nfrom _pytest.compat import is_async_function\nfrom _pytest.compat import LEGACY_PATH\nfrom _pytest.compat import NOTSET\nfrom _pytest.compat import safe_getattr\nfrom _pytest.compat import safe_isclass\nfrom _pytest.config import Config\nfrom _pytest.config import hookimpl\nfrom _pytest.config.argparsing import Parser\nfrom _pytest.deprecated import check_ispytest\nfrom _pytest.fixtures import FixtureDef\nfrom _pytest.fixtures import FixtureRequest\nfrom _pytest.fixtures import FuncFixtureInfo\nfrom _pytest.fixtures import get_scope_node\nfrom _pytest.main import Session\nfrom _pytest.mark import ParameterSet\nfrom _pytest.mark.structures import _HiddenParam\nfrom _pytest.mark.structures import get_unpacked_marks\nfrom _pytest.mark.structures import HIDDEN_PARAM\nfrom _pytest.mark.structures import Mark\nfrom _pytest.mark.structures import MarkDecorator\nfrom _pytest.mark.structures import normalize_mark_list\nfrom _pytest.outcomes import fail\nfrom _pytest.outcomes import skip\nfrom _pytest.pathlib import fnmatch_ex\nfrom _pytest.pathlib import import_path\nfrom _pytest.pathlib import ImportPathMismatchError\nfrom _pytest.pathlib import scandir\nfrom _pytest.scope import _ScopeName\nfrom _pytest.scope import Scope\nfrom _pytest.stash import StashKey\nfrom _pytest.warning_types import PytestCollectionWarning\nfrom _pytest.warning_types import PytestReturnNotNoneWarning\n\n\nif TYPE_CHECKING:\n    from typing_extensions import Self\n\n\ndef pytest_addoption(parser: Parser) -> None:\n    parser.addini(\n        \"python_files\",\n        type=\"args\",\n        # NOTE: default is also used in AssertionRewritingHook.\n        default=[\"test_*.py\", \"*_test.py\"],\n        help=\"Glob-style file patterns for Python test module discovery\",\n    )\n    parser.addini(\n        \"python_classes\""}, {"start_line": 23000, "end_line": 25000, "belongs_to": {"file_name": "test_collection.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": " hookrec.assert_contains(\n            [\n                (\"pytest_collectstart\", \"collector.path == test_aaa\"),\n                (\"pytest_pycollect_makeitem\", \"name == 'test_func'\"),\n                (\"pytest_collectreport\", \"report.nodeid.startswith('aaa/test_aaa.py')\"),\n            ]\n        )\n\n    def test_collect_two_commandline_args(self, pytester: Pytester) -> None:\n        p = pytester.makepyfile(\"def test_func(): pass\")\n        aaa = pytester.mkpydir(\"aaa\")\n        bbb = pytester.mkpydir(\"bbb\")\n        test_aaa = aaa.joinpath(\"test_aaa.py\")\n        shutil.copy(p, test_aaa)\n        test_bbb = bbb.joinpath(\"test_bbb.py\")\n        p.replace(test_bbb)\n\n        id = \".\"\n\n        items, hookrec = pytester.inline_genitems(id)\n        assert len(items) == 2\n        pprint.pprint(hookrec.calls)\n        hookrec.assert_contains(\n            [\n                (\"pytest_collectstart\", \"collector.path == test_aaa\"),\n                (\"pytest_pycollect_makeitem\", \"name == 'test_func'\"),\n                (\"pytest_collectreport\", \"report.nodeid == 'aaa/test_aaa.py'\"),\n                (\"pytest_collectstart\", \"collector.path == test_bbb\"),\n                (\"pytest_pycollect_makeitem\", \"name == 'test_func'\"),\n                (\"pytest_collectreport\", \"report.nodeid == 'bbb/test_bbb.py'\"),\n            ]\n        )\n\n    def test_serialization_byid(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\"def test_func(): pass\")\n        items, hookrec = pytester.inline_genitems()\n        assert len(items) == 1\n        (item,) = items\n        items2, hookrec = pytester.inline_genitems(item.nodeid)\n        (item2,) = items2\n        assert item2.name == item.name\n        assert item2.path == item.path\n\n    def test_find_byid_without_instance_parents(self, pytester: Pytester) -> None:\n        p = pytester.makepyfile(\n            \"\"\"\n            class TestClass(object):\n                def test_method(self):\n                    pass\n        \"\"\"\n        )\n        arg = p.name + \"::TestClas"}, {"start_line": 16000, "end_line": 18000, "belongs_to": {"file_name": "test_collection.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "ignore_glob[:] = []\n        \"\"\"\n        )\n        pytester.makepyfile(test_world=\"def test_hello(): pass\")\n        pytester.makepyfile(test_welt=\"def test_hallo(): pass\")\n        result = pytester.runpytest()\n        assert result.ret == ExitCode.NO_TESTS_COLLECTED\n        result.stdout.fnmatch_lines([\"*collected 0 items*\"])\n        result = pytester.runpytest(\"--XX\")\n        assert result.ret == 0\n        result.stdout.fnmatch_lines([\"*2 passed*\"])\n\n    def test_pytest_fs_collect_hooks_are_seen(self, pytester: Pytester) -> None:\n        pytester.makeconftest(\n            \"\"\"\n            import pytest\n            class MyModule(pytest.Module):\n                pass\n            def pytest_collect_file(file_path, parent):\n                if file_path.suffix == \".py\":\n                    return MyModule.from_parent(path=file_path, parent=parent)\n        \"\"\"\n        )\n        pytester.mkdir(\"sub\")\n        pytester.makepyfile(\"def test_x(): pass\")\n        result = pytester.runpytest(\"--co\")\n        result.stdout.fnmatch_lines([\"*MyModule*\", \"*test_x*\"])\n\n    def test_pytest_collect_file_from_sister_dir(self, pytester: Pytester) -> None:\n        sub1 = pytester.mkpydir(\"sub1\")\n        sub2 = pytester.mkpydir(\"sub2\")\n        conf1 = pytester.makeconftest(\n            \"\"\"\n            import pytest\n            class MyModule1(pytest.Module):\n                pass\n            def pytest_collect_file(file_path, parent):\n                if file_path.suffix == \".py\":\n                    return MyModule1.from_parent(path=file_path, parent=parent)\n        \"\"\"\n        )\n        conf1.replace(sub1.joinpath(conf1.name))\n        conf2 = pytester.makeconftest(\n            \"\"\"\n            import pytest\n            class MyModule2(pytest.Module):\n                pass\n            def pytest_collect_file(file_path, parent):\n                if file_path.suffix == \".py\":\n                    return MyModule2.from_parent(path=file_path, parent=parent)\n        \"\"\"\n        )\n        conf2.replace("}, {"start_line": 29000, "end_line": 31000, "belongs_to": {"file_name": "test_collection.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "re[attr-defined]\n        assert items[1].getmodpath() == \"TestX.testmethod_one\"  # type: ignore[attr-defined]\n        assert items[2].getmodpath() == \"TestY.testmethod_one\"  # type: ignore[attr-defined]\n        # PR #6202: Fix incorrect result of getmodpath method. (Resolves issue #6189)\n        assert items[3].getmodpath() == \"TestY.testmethod_two[.[]\"  # type: ignore[attr-defined]\n\n        s = items[0].getmodpath(stopatmodule=False)  # type: ignore[attr-defined]\n        assert s.endswith(\"test_example_items1.testone\")\n        print(s)\n\n    def test_classmethod_is_discovered(self, pytester: Pytester) -> None:\n        \"\"\"Test that classmethods are discovered\"\"\"\n        p = pytester.makepyfile(\n            \"\"\"\n            class TestCase:\n                @classmethod\n                def test_classmethod(cls) -> None:\n                    pass\n            \"\"\"\n        )\n        items, reprec = pytester.inline_genitems(p)\n        ids = [x.getmodpath() for x in items]  # type: ignore[attr-defined]\n        assert ids == [\"TestCase.test_classmethod\"]\n\n    def test_class_and_functions_discovery_using_glob(self, pytester: Pytester) -> None:\n        \"\"\"Test that Python_classes and Python_functions config options work\n        as prefixes and glob-like patterns (#600).\"\"\"\n        pytester.makeini(\n            \"\"\"\n            [pytest]\n            python_classes = *Suite Test\n            python_functions = *_test test\n        \"\"\"\n        )\n        p = pytester.makepyfile(\n            \"\"\"\n            class MyTestSuite(object):\n                def x_test(self):\n                    pass\n\n            class TestCase(object):\n                def test_y(self):\n                    pass\n        \"\"\"\n        )\n        items, reprec = pytester.inline_genitems(p)\n        ids = [x.getmodpath() for x in items]  # type: ignore[attr-defined]\n        assert ids == [\"MyTestSuite.x_test\", \"TestCase.test_y\"]\n\n\ndef test_matchnodes_two_collections_same_file(pytester: Pytester) -> None:\n    pytester.makec"}, {"start_line": 41000, "end_line": 43000, "belongs_to": {"file_name": "collect.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing/python", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "            \"\"\"\n            # lineno 0\n            class TestClass(object):\n                def test_hello(self): pass\n        \"\"\"\n        )\n        classcol = pytester.collect_by_name(modcol, \"TestClass\")\n        assert isinstance(classcol, Class)\n        path, lineno, msg = classcol.reportinfo()\n        assert os.fspath(path) == str(modcol.path)\n        assert lineno == 1\n        assert msg == \"TestClass\"\n\n    @pytest.mark.filterwarnings(\n        \"ignore:usage of Generator.Function is deprecated, please use pytest.Function instead\"\n    )\n    def test_reportinfo_with_nasty_getattr(self, pytester: Pytester) -> None:\n        # https://github.com/pytest-dev/pytest/issues/1204\n        modcol = pytester.getmodulecol(\n            \"\"\"\n            # lineno 0\n            class TestClass:\n                def __getattr__(self, name):\n                    return \"this is not an int\"\n\n                def __class_getattr__(cls, name):\n                    return \"this is not an int\"\n\n                def intest_foo(self):\n                    pass\n\n                def test_bar(self):\n                    pass\n        \"\"\"\n        )\n        classcol = pytester.collect_by_name(modcol, \"TestClass\")\n        assert isinstance(classcol, Class)\n        path, lineno, msg = classcol.reportinfo()\n        func = next(iter(classcol.collect()))\n        assert isinstance(func, Function)\n        path, lineno, msg = func.reportinfo()\n\n\ndef test_customized_python_discovery(pytester: Pytester) -> None:\n    pytester.makeini(\n        \"\"\"\n        [pytest]\n        python_files=check_*.py\n        python_classes=Check\n        python_functions=check\n    \"\"\"\n    )\n    p = pytester.makepyfile(\n        \"\"\"\n        def check_simple():\n            pass\n        class CheckMyApp(object):\n            def check_meth(self):\n                pass\n    \"\"\"\n    )\n    p2 = p.with_name(p.name.replace(\"test\", \"check\"))\n    p.rename(p2)\n    result = pytester.runpytest(\"--collect-only\", \"-s\")\n    result.stdout.fnmatch_lines(\n   "}, {"start_line": 43000, "end_line": 45000, "belongs_to": {"file_name": "collect.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing/python", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "     [\"*check_customized*\", \"*check_simple*\", \"*CheckMyApp*\", \"*check_meth*\"]\n    )\n\n    result = pytester.runpytest()\n    assert result.ret == 0\n    result.stdout.fnmatch_lines([\"*2 passed*\"])\n\n\ndef test_customized_python_discovery_functions(pytester: Pytester) -> None:\n    pytester.makeini(\n        \"\"\"\n        [pytest]\n        python_functions=_test\n    \"\"\"\n    )\n    pytester.makepyfile(\n        \"\"\"\n        def _test_underscore():\n            pass\n    \"\"\"\n    )\n    result = pytester.runpytest(\"--collect-only\", \"-s\")\n    result.stdout.fnmatch_lines([\"*_test_underscore*\"])\n\n    result = pytester.runpytest()\n    assert result.ret == 0\n    result.stdout.fnmatch_lines([\"*1 passed*\"])\n\n\ndef test_unorderable_types(pytester: Pytester) -> None:\n    pytester.makepyfile(\n        \"\"\"\n        class TestJoinEmpty(object):\n            pass\n\n        def make_test():\n            class Test(object):\n                pass\n            Test.__name__ = \"TestFoo\"\n            return Test\n        TestFoo = make_test()\n    \"\"\"\n    )\n    result = pytester.runpytest()\n    result.stdout.no_fnmatch_line(\"*TypeError*\")\n    assert result.ret == ExitCode.NO_TESTS_COLLECTED\n\n\n@pytest.mark.filterwarnings(\"default::pytest.PytestCollectionWarning\")\ndef test_dont_collect_non_function_callable(pytester: Pytester) -> None:\n    \"\"\"Test for issue https://github.com/pytest-dev/pytest/issues/331\n\n    In this case an INTERNALERROR occurred trying to report the failure of\n    a test like this one because pytest failed to get the source lines.\n    \"\"\"\n    pytester.makepyfile(\n        \"\"\"\n        class Oh(object):\n            def __call__(self):\n                pass\n\n        test_a = Oh()\n\n        def test_real():\n            pass\n    \"\"\"\n    )\n    result = pytester.runpytest()\n    result.stdout.fnmatch_lines(\n        [\n            \"*collected 1 item*\",\n            \"*test_dont_collect_non_function_callable.py:2: *cannot collect 'test_a' because it is not a function*\",\n            \"*1 passed, 1 warning in *\",\n   "}, {"start_line": 0, "end_line": 2000, "belongs_to": {"file_name": "python.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "# mypy: allow-untyped-defs\n\"\"\"Python test discovery, setup and run of test functions.\"\"\"\n\nfrom __future__ import annotations\n\nimport abc\nfrom collections import Counter\nfrom collections import defaultdict\nfrom collections.abc import Callable\nfrom collections.abc import Generator\nfrom collections.abc import Iterable\nfrom collections.abc import Iterator\nfrom collections.abc import Mapping\nfrom collections.abc import Sequence\nimport dataclasses\nimport enum\nimport fnmatch\nfrom functools import partial\nimport inspect\nimport itertools\nimport os\nfrom pathlib import Path\nimport re\nimport types\nfrom typing import Any\nfrom typing import final\nfrom typing import Literal\nfrom typing import NoReturn\nfrom typing import TYPE_CHECKING\nimport warnings\n\nimport _pytest\nfrom _pytest import fixtures\nfrom _pytest import nodes\nfrom _pytest._code import filter_traceback\nfrom _pytest._code import getfslineno\nfrom _pytest._code.code import ExceptionInfo\nfrom _pytest._code.code import TerminalRepr\nfrom _pytest._code.code import Traceback\nfrom _pytest._io.saferepr import saferepr\nfrom _pytest.compat import ascii_escaped\nfrom _pytest.compat import get_default_arg_names\nfrom _pytest.compat import get_real_func\nfrom _pytest.compat import getimfunc\nfrom _pytest.compat import is_async_function\nfrom _pytest.compat import LEGACY_PATH\nfrom _pytest.compat import NOTSET\nfrom _pytest.compat import safe_getattr\nfrom _pytest.compat import safe_isclass\nfrom _pytest.config import Config\nfrom _pytest.config import hookimpl\nfrom _pytest.config.argparsing import Parser\nfrom _pytest.deprecated import check_ispytest\nfrom _pytest.fixtures import FixtureDef\nfrom _pytest.fixtures import FixtureRequest\nfrom _pytest.fixtures import FuncFixtureInfo\nfrom _pytest.fixtures import get_scope_node\nfrom _pytest.main import Session\nfrom _pytest.mark import ParameterSet\nfrom _pytest.mark.structures import _HiddenParam\nfrom _pytest.mark.structures import get_unpacked_marks\nfrom _pytest.mark.structures import HIDDEN_PARAM\nfrom _p"}], "retrieved_count": 10, "cost_time": 1.2252790927886963}
{"question": "Where does the fixture resolution flow from dependency analysis to fixture execution?", "answer": null, "relative_code_list": null, "ground_truth": "The fixture resolution flow in pytest follows a structured sequence from dependency analysis to fixture execution: 1) Fixture discovery phase begins during collection where FixtureManager.parsefactories() scans for fixture definitions and creates FixtureDef objects, 2) Dependency analysis occurs through FixtureManager.getfixtureinfo() which analyzes test functions to identify required fixtures and their dependencies, 3) Fixture closure calculation happens in getfixtureclosure() which computes the transitive closure of all fixtures needed by a test, including dependencies of dependencies, 4) Fixture ordering determination follows three factors: scope hierarchy (higher-scoped fixtures first), dependency relationships (dependencies before dependents), and autouse status (autouse fixtures first within their scope), 5) Fixture lookup occurs through FixtureRequest._get_active_fixturedef() which finds the appropriate FixtureDef for each requested fixture name, 6) Cache checking happens in FixtureDef.execute() where pytest checks if a fixture value is already cached and returns it if available, 7) Dependency resolution occurs where fixtures recursively resolve their own dependencies through request.getfixturevalue() calls, 8) Fixture execution happens through pytest_fixture_setup hook which calls the actual fixture function with resolved dependencies as keyword arguments, 9) Result caching occurs where fixture results are stored in FixtureDef.cached_result for reuse within the fixture's scope, 10) Fixture finalization setup happens where finalizers are registered to ensure proper cleanup when fixtures go out of scope, 11) Error handling occurs where fixture execution errors are captured and stored in the cache to prevent repeated failures, 12) The entire resolution flow is coordinated through the FixtureManager class which maintains the fixture registry and manages the resolution process.", "score": null, "retrieved_content": [{"start_line": 44000, "end_line": 46000, "belongs_to": {"file_name": "fixtures.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "t=request)\n        for parent_fixture in requested_fixtures_that_should_finalize_us:\n            parent_fixture.addfinalizer(finalizer)\n\n        ihook = request.node.ihook\n        try:\n            # Setup the fixture, run the code in it, and cache the value\n            # in self.cached_result.\n            result: FixtureValue = ihook.pytest_fixture_setup(\n                fixturedef=self, request=request\n            )\n        finally:\n            # Schedule our finalizer, even if the setup failed.\n            request.node.addfinalizer(finalizer)\n\n        return result\n\n    def cache_key(self, request: SubRequest) -> object:\n        return getattr(request, \"param\", None)\n\n    def __repr__(self) -> str:\n        return f\"<FixtureDef argname={self.argname!r} scope={self.scope!r} baseid={self.baseid!r}>\"\n\n\ndef resolve_fixture_function(\n    fixturedef: FixtureDef[FixtureValue], request: FixtureRequest\n) -> _FixtureFunc[FixtureValue]:\n    \"\"\"Get the actual callable that can be called to obtain the fixture\n    value.\"\"\"\n    fixturefunc = fixturedef.func\n    # The fixture function needs to be bound to the actual\n    # request.instance so that code working with \"fixturedef\" behaves\n    # as expected.\n    instance = request.instance\n    if instance is not None:\n        # Handle the case where fixture is defined not in a test class, but some other class\n        # (for example a plugin class with a fixture), see #2270.\n        if hasattr(fixturefunc, \"__self__\") and not isinstance(\n            instance,\n            fixturefunc.__self__.__class__,\n        ):\n            return fixturefunc\n        fixturefunc = getimfunc(fixturedef.func)\n        if fixturefunc != fixturedef.func:\n            fixturefunc = fixturefunc.__get__(instance)\n    return fixturefunc\n\n\ndef pytest_fixture_setup(\n    fixturedef: FixtureDef[FixtureValue], request: SubRequest\n) -> FixtureValue:\n    \"\"\"Execution of fixture setup.\"\"\"\n    kwargs = {}\n    for argname in fixturedef.argnames:\n        kwargs[argname] ="}, {"start_line": 0, "end_line": 584, "belongs_to": {"file_name": "test_fixtures_order_dependencies.py", "upper_path": "/data2/raymone/swebench-repos/pytest/doc/en/example/fixtures", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "from __future__ import annotations\n\nimport pytest\n\n\n@pytest.fixture\ndef order():\n    return []\n\n\n@pytest.fixture\ndef a(order):\n    order.append(\"a\")\n\n\n@pytest.fixture\ndef b(a, order):\n    order.append(\"b\")\n\n\n@pytest.fixture\ndef c(b, order):\n    order.append(\"c\")\n\n\n@pytest.fixture\ndef d(c, b, order):\n    order.append(\"d\")\n\n\n@pytest.fixture\ndef e(d, b, order):\n    order.append(\"e\")\n\n\n@pytest.fixture\ndef f(e, order):\n    order.append(\"f\")\n\n\n@pytest.fixture\ndef g(f, c, order):\n    order.append(\"g\")\n\n\ndef test_order(g, order):\n    assert order == [\"a\", \"b\", \"c\", \"d\", \"e\", \"f\", \"g\"]\n"}, {"start_line": 133000, "end_line": 135000, "belongs_to": {"file_name": "fixtures.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing/python", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "DER  # type: ignore[attr-defined]\n        assert FIXTURE_ORDER == \"s1 my_tmp_path_factory p1 m1 my_tmp_path f1 f2\".split()\n\n    def test_func_closure_module(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n\n            @pytest.fixture(scope='module')\n            def m1(): pass\n\n            @pytest.fixture(scope='function')\n            def f1(): pass\n\n            def test_func(f1, m1):\n                pass\n        \"\"\"\n        )\n        items, _ = pytester.inline_genitems()\n        assert isinstance(items[0], Function)\n        request = TopRequest(items[0], _ispytest=True)\n        assert request.fixturenames == \"m1 f1\".split()\n\n    def test_func_closure_scopes_reordered(self, pytester: Pytester) -> None:\n        \"\"\"Test ensures that fixtures are ordered by scope regardless of the order of the parameters, although\n        fixtures of same scope keep the declared order\n        \"\"\"\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n\n            @pytest.fixture(scope='session')\n            def s1(): pass\n\n            @pytest.fixture(scope='module')\n            def m1(): pass\n\n            @pytest.fixture(scope='function')\n            def f1(): pass\n\n            @pytest.fixture(scope='function')\n            def f2(): pass\n\n            class Test:\n\n                @pytest.fixture(scope='class')\n                def c1(cls): pass\n\n                def test_func(self, f2, f1, c1, m1, s1):\n                    pass\n        \"\"\"\n        )\n        items, _ = pytester.inline_genitems()\n        assert isinstance(items[0], Function)\n        request = TopRequest(items[0], _ispytest=True)\n        assert request.fixturenames == \"s1 m1 c1 f2 f1\".split()\n\n    def test_func_closure_same_scope_closer_root_first(\n        self, pytester: Pytester\n    ) -> None:\n        \"\"\"Auto-use fixtures of same scope are ordered by closer-to-root first\"\"\"\n        pytester.makeconftest(\n            \"\"\"\n            import pytest\n\n     "}, {"start_line": 132000, "end_line": 134000, "belongs_to": {"file_name": "fixtures.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing/python", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": ":\n                FIXTURE_ORDER.append('my_tmp_path_factory')\n\n            @pytest.fixture\n            def my_tmp_path(my_tmp_path_factory):\n                FIXTURE_ORDER.append('my_tmp_path')\n\n            @pytest.fixture\n            def f1(my_tmp_path):\n                FIXTURE_ORDER.append('f1')\n\n            @pytest.fixture\n            def f2():\n                FIXTURE_ORDER.append('f2')\n\n            def test_foo(f1, p1, m1, f2, s1): pass\n        \"\"\"\n        )\n        items, _ = pytester.inline_genitems()\n        assert isinstance(items[0], Function)\n        request = TopRequest(items[0], _ispytest=True)\n        # order of fixtures based on their scope and position in the parameter list\n        assert (\n            request.fixturenames\n            == \"s1 my_tmp_path_factory p1 m1 f1 f2 my_tmp_path\".split()\n        )\n        pytester.runpytest()\n        # actual fixture execution differs: dependent fixtures must be created first (\"my_tmp_path\")\n        FIXTURE_ORDER = pytest.FIXTURE_ORDER  # type: ignore[attr-defined]\n        assert FIXTURE_ORDER == \"s1 my_tmp_path_factory p1 m1 my_tmp_path f1 f2\".split()\n\n    def test_func_closure_module(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n\n            @pytest.fixture(scope='module')\n            def m1(): pass\n\n            @pytest.fixture(scope='function')\n            def f1(): pass\n\n            def test_func(f1, m1):\n                pass\n        \"\"\"\n        )\n        items, _ = pytester.inline_genitems()\n        assert isinstance(items[0], Function)\n        request = TopRequest(items[0], _ispytest=True)\n        assert request.fixturenames == \"m1 f1\".split()\n\n    def test_func_closure_scopes_reordered(self, pytester: Pytester) -> None:\n        \"\"\"Test ensures that fixtures are ordered by scope regardless of the order of the parameters, although\n        fixtures of same scope keep the declared order\n        \"\"\"\n        pytester.makepyfile(\n            \"\"\"\n        "}, {"start_line": 131000, "end_line": 133000, "belongs_to": {"file_name": "fixtures.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing/python", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "test=True)\n        assert request.fixturenames == \"m1 f1\".split()\n\n    def test_func_closure_with_native_fixtures(\n        self, pytester: Pytester, monkeypatch: MonkeyPatch\n    ) -> None:\n        \"\"\"Sanity check that verifies the order returned by the closures and the actual fixture execution order:\n        The execution order may differ because of fixture inter-dependencies.\n        \"\"\"\n        monkeypatch.setattr(pytest, \"FIXTURE_ORDER\", [], raising=False)\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n\n            FIXTURE_ORDER = pytest.FIXTURE_ORDER\n\n            @pytest.fixture(scope=\"session\")\n            def s1():\n                FIXTURE_ORDER.append('s1')\n\n            @pytest.fixture(scope=\"package\")\n            def p1():\n                FIXTURE_ORDER.append('p1')\n\n            @pytest.fixture(scope=\"module\")\n            def m1():\n                FIXTURE_ORDER.append('m1')\n\n            @pytest.fixture(scope='session')\n            def my_tmp_path_factory():\n                FIXTURE_ORDER.append('my_tmp_path_factory')\n\n            @pytest.fixture\n            def my_tmp_path(my_tmp_path_factory):\n                FIXTURE_ORDER.append('my_tmp_path')\n\n            @pytest.fixture\n            def f1(my_tmp_path):\n                FIXTURE_ORDER.append('f1')\n\n            @pytest.fixture\n            def f2():\n                FIXTURE_ORDER.append('f2')\n\n            def test_foo(f1, p1, m1, f2, s1): pass\n        \"\"\"\n        )\n        items, _ = pytester.inline_genitems()\n        assert isinstance(items[0], Function)\n        request = TopRequest(items[0], _ispytest=True)\n        # order of fixtures based on their scope and position in the parameter list\n        assert (\n            request.fixturenames\n            == \"s1 my_tmp_path_factory p1 m1 f1 f2 my_tmp_path\".split()\n        )\n        pytester.runpytest()\n        # actual fixture execution differs: dependent fixtures must be created first (\"my_tmp_path\")\n        FIXTURE_ORDER = pytest.FIXTURE_OR"}, {"start_line": 10000, "end_line": 12000, "belongs_to": {"file_name": "fixtures.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "key_dict[i] = None\n                                argkey_dict.move_to_end(i, last=False)\n                            else:\n                                # Work around a bug in PyPy:\n                                # https://github.com/pypy/pypy/issues/5257\n                                # https://github.com/pytest-dev/pytest/issues/13312\n                                bkp = argkey_dict.copy()\n                                argkey_dict.clear()\n                                argkey_dict[i] = None\n                                argkey_dict.update(bkp)\n                break\n        if no_argkey_items:\n            reordered_no_argkey_items = reorder_items_atscope(\n                no_argkey_items, argkeys_by_item, items_by_argkey, scope.next_lower()\n            )\n            items_done.update(reordered_no_argkey_items)\n        if slicing_argkey is not None:\n            ignore.add(slicing_argkey)\n    return items_done\n\n\n@dataclasses.dataclass(frozen=True)\nclass FuncFixtureInfo:\n    \"\"\"Fixture-related information for a fixture-requesting item (e.g. test\n    function).\n\n    This is used to examine the fixtures which an item requests statically\n    (known during collection). This includes autouse fixtures, fixtures\n    requested by the `usefixtures` marker, fixtures requested in the function\n    parameters, and the transitive closure of these.\n\n    An item may also request fixtures dynamically (using `request.getfixturevalue`);\n    these are not reflected here.\n    \"\"\"\n\n    __slots__ = (\"argnames\", \"initialnames\", \"name2fixturedefs\", \"names_closure\")\n\n    # Fixture names that the item requests directly by function parameters.\n    argnames: tuple[str, ...]\n    # Fixture names that the item immediately requires. These include\n    # argnames + fixture names specified via usefixtures and via autouse=True in\n    # fixture definitions.\n    initialnames: tuple[str, ...]\n    # The transitive closure of the fixture names that the item requires.\n    # Note: can't include dynami"}, {"start_line": 45000, "end_line": 47000, "belongs_to": {"file_name": "fixtures.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": " the fixture\n    value.\"\"\"\n    fixturefunc = fixturedef.func\n    # The fixture function needs to be bound to the actual\n    # request.instance so that code working with \"fixturedef\" behaves\n    # as expected.\n    instance = request.instance\n    if instance is not None:\n        # Handle the case where fixture is defined not in a test class, but some other class\n        # (for example a plugin class with a fixture), see #2270.\n        if hasattr(fixturefunc, \"__self__\") and not isinstance(\n            instance,\n            fixturefunc.__self__.__class__,\n        ):\n            return fixturefunc\n        fixturefunc = getimfunc(fixturedef.func)\n        if fixturefunc != fixturedef.func:\n            fixturefunc = fixturefunc.__get__(instance)\n    return fixturefunc\n\n\ndef pytest_fixture_setup(\n    fixturedef: FixtureDef[FixtureValue], request: SubRequest\n) -> FixtureValue:\n    \"\"\"Execution of fixture setup.\"\"\"\n    kwargs = {}\n    for argname in fixturedef.argnames:\n        kwargs[argname] = request.getfixturevalue(argname)\n\n    fixturefunc = resolve_fixture_function(fixturedef, request)\n    my_cache_key = fixturedef.cache_key(request)\n\n    if inspect.isasyncgenfunction(fixturefunc) or inspect.iscoroutinefunction(\n        fixturefunc\n    ):\n        auto_str = \" with autouse=True\" if fixturedef._autouse else \"\"\n\n        warnings.warn(\n            PytestRemovedIn9Warning(\n                f\"{request.node.name!r} requested an async fixture \"\n                f\"{request.fixturename!r}{auto_str}, with no plugin or hook that \"\n                \"handled it. This is usually an error, as pytest does not natively \"\n                \"support it. \"\n                \"This will turn into an error in pytest 9.\\n\"\n                \"See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture\"\n            ),\n            # no stacklevel will point at users code, so we just point here\n            stacklevel=1,\n        )\n\n    try:\n        result = call_fixture_func"}, {"start_line": 130000, "end_line": 132000, "belongs_to": {"file_name": "fixtures.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing/python", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "monkeypatch.setenv(\"FIXTURE_ACTIVATION_VARIANT\", variant)\n        pytester.makepyfile(\n            \"\"\"\n            import warnings\n            import os\n            import pytest\n            VAR = 'FIXTURE_ACTIVATION_VARIANT'\n            VALID_VARS = ('autouse', 'mark')\n\n            VARIANT = os.environ.get(VAR)\n            if VARIANT is None or VARIANT not in VALID_VARS:\n                warnings.warn(\"{!r} is not  in {}, assuming autouse\".format(VARIANT, VALID_VARS) )\n                variant = 'mark'\n\n            @pytest.fixture(scope='module', autouse=VARIANT == 'autouse')\n            def m1(): pass\n\n            if VARIANT=='mark':\n                pytestmark = pytest.mark.usefixtures('m1')\n\n            @pytest.fixture(scope='function', autouse=True)\n            def f1(): pass\n\n            def test_func(m1):\n                pass\n        \"\"\"\n        )\n        items, _ = pytester.inline_genitems()\n        assert isinstance(items[0], Function)\n        request = TopRequest(items[0], _ispytest=True)\n        assert request.fixturenames == \"m1 f1\".split()\n\n    def test_func_closure_with_native_fixtures(\n        self, pytester: Pytester, monkeypatch: MonkeyPatch\n    ) -> None:\n        \"\"\"Sanity check that verifies the order returned by the closures and the actual fixture execution order:\n        The execution order may differ because of fixture inter-dependencies.\n        \"\"\"\n        monkeypatch.setattr(pytest, \"FIXTURE_ORDER\", [], raising=False)\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n\n            FIXTURE_ORDER = pytest.FIXTURE_ORDER\n\n            @pytest.fixture(scope=\"session\")\n            def s1():\n                FIXTURE_ORDER.append('s1')\n\n            @pytest.fixture(scope=\"package\")\n            def p1():\n                FIXTURE_ORDER.append('p1')\n\n            @pytest.fixture(scope=\"module\")\n            def m1():\n                FIXTURE_ORDER.append('m1')\n\n            @pytest.fixture(scope='session')\n            def my_tmp_path_factory()"}, {"start_line": 134000, "end_line": 136000, "belongs_to": {"file_name": "fixtures.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing/python", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "    import pytest\n\n            @pytest.fixture(scope='session')\n            def s1(): pass\n\n            @pytest.fixture(scope='module')\n            def m1(): pass\n\n            @pytest.fixture(scope='function')\n            def f1(): pass\n\n            @pytest.fixture(scope='function')\n            def f2(): pass\n\n            class Test:\n\n                @pytest.fixture(scope='class')\n                def c1(cls): pass\n\n                def test_func(self, f2, f1, c1, m1, s1):\n                    pass\n        \"\"\"\n        )\n        items, _ = pytester.inline_genitems()\n        assert isinstance(items[0], Function)\n        request = TopRequest(items[0], _ispytest=True)\n        assert request.fixturenames == \"s1 m1 c1 f2 f1\".split()\n\n    def test_func_closure_same_scope_closer_root_first(\n        self, pytester: Pytester\n    ) -> None:\n        \"\"\"Auto-use fixtures of same scope are ordered by closer-to-root first\"\"\"\n        pytester.makeconftest(\n            \"\"\"\n            import pytest\n\n            @pytest.fixture(scope='module', autouse=True)\n            def m_conf(): pass\n        \"\"\"\n        )\n        pytester.makepyfile(\n            **{\n                \"sub/conftest.py\": \"\"\"\n                import pytest\n\n                @pytest.fixture(scope='package', autouse=True)\n                def p_sub(): pass\n\n                @pytest.fixture(scope='module', autouse=True)\n                def m_sub(): pass\n            \"\"\",\n                \"sub/__init__.py\": \"\",\n                \"sub/test_func.py\": \"\"\"\n                import pytest\n\n                @pytest.fixture(scope='module', autouse=True)\n                def m_test(): pass\n\n                @pytest.fixture(scope='function')\n                def f1(): pass\n\n                def test_func(m_test, f1):\n                    pass\n        \"\"\",\n            }\n        )\n        items, _ = pytester.inline_genitems()\n        assert isinstance(items[0], Function)\n        request = TopRequest(items[0], _ispytest=True)\n        assert request.fix"}, {"start_line": 0, "end_line": 321, "belongs_to": {"file_name": "test_getfixturevalue_dynamic.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing/example_scripts/fixtures", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "# mypy: allow-untyped-defs\nfrom __future__ import annotations\n\nimport pytest\n\n\n@pytest.fixture\ndef dynamic():\n    pass\n\n\n@pytest.fixture\ndef a(request):\n    request.getfixturevalue(\"dynamic\")\n\n\n@pytest.fixture\ndef b(a):\n    pass\n\n\ndef test(b, request):\n    assert request.fixturenames == [\"b\", \"request\", \"a\", \"dynamic\"]\n"}], "retrieved_count": 10, "cost_time": 1.234522819519043}
{"question": "Why does Pytest include built-in support for test parametrization and marking?", "answer": null, "relative_code_list": null, "ground_truth": "Pytest includes built-in support for test parametrization and marking to provide essential testing functionality that addresses common testing needs: 1) Test parametrization allows the same test logic to be executed with multiple sets of input data, reducing code duplication and improving test coverage, 2) Built-in parametrization through @pytest.mark.parametrize decorator provides a clean, declarative way to define multiple test scenarios, 3) Test marking enables categorization and organization of tests through metadata that can be used for selective test execution, 4) Built-in markers like skip, xfail, usefixtures, and filterwarnings provide common testing patterns that users need frequently, 5) Marking system enables test selection and filtering through command-line options like -m for running specific test categories, 6) Parametrization supports both direct and indirect parameter passing, allowing flexible test data handling, 7) Built-in support ensures consistent behavior and reduces the need for users to implement common testing patterns themselves, 8) Marking system integrates with pytest's plugin architecture, allowing plugins to define and use custom markers, 9) Parametrization supports individual test marking within parameter sets using pytest.param for fine-grained control, 10) Built-in markers provide standardized ways to handle common testing scenarios like conditional skipping and expected failures, 11) The combination of parametrization and marking enables complex test organization and execution strategies, 12) Built-in support ensures that these essential features are always available without requiring additional dependencies or plugins.", "score": null, "retrieved_content": [{"start_line": 0, "end_line": 2000, "belongs_to": {"file_name": "__init__.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest/mark", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "\"\"\"Generic mechanism for marking and selecting python functions.\"\"\"\n\nfrom __future__ import annotations\n\nimport collections\nfrom collections.abc import Collection\nfrom collections.abc import Iterable\nfrom collections.abc import Set as AbstractSet\nimport dataclasses\nfrom typing import Optional\nfrom typing import TYPE_CHECKING\n\nfrom .expression import Expression\nfrom .expression import ParseError\nfrom .structures import _HiddenParam\nfrom .structures import EMPTY_PARAMETERSET_OPTION\nfrom .structures import get_empty_parameterset_mark\nfrom .structures import HIDDEN_PARAM\nfrom .structures import Mark\nfrom .structures import MARK_GEN\nfrom .structures import MarkDecorator\nfrom .structures import MarkGenerator\nfrom .structures import ParameterSet\nfrom _pytest.config import Config\nfrom _pytest.config import ExitCode\nfrom _pytest.config import hookimpl\nfrom _pytest.config import UsageError\nfrom _pytest.config.argparsing import NOT_SET\nfrom _pytest.config.argparsing import Parser\nfrom _pytest.stash import StashKey\n\n\nif TYPE_CHECKING:\n    from _pytest.nodes import Item\n\n\n__all__ = [\n    \"HIDDEN_PARAM\",\n    \"MARK_GEN\",\n    \"Mark\",\n    \"MarkDecorator\",\n    \"MarkGenerator\",\n    \"ParameterSet\",\n    \"get_empty_parameterset_mark\",\n]\n\n\nold_mark_config_key = StashKey[Optional[Config]]()\n\n\ndef param(\n    *values: object,\n    marks: MarkDecorator | Collection[MarkDecorator | Mark] = (),\n    id: str | _HiddenParam | None = None,\n) -> ParameterSet:\n    \"\"\"Specify a parameter in `pytest.mark.parametrize`_ calls or\n    :ref:`parametrized fixtures <fixture-parametrize-marks>`.\n\n    .. code-block:: python\n\n        @pytest.mark.parametrize(\n            \"test_input,expected\",\n            [\n                (\"3+5\", 8),\n                pytest.param(\"6*9\", 42, marks=pytest.mark.xfail),\n            ],\n        )\n        def test_eval(test_input, expected):\n            assert eval(test_input) == expected\n\n    :param values: Variable args of the values of the parameter set, in order.\n\n    :param marks:\n"}, {"start_line": 2000, "end_line": 4000, "belongs_to": {"file_name": "python.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "ytest.mark.structures import Mark\nfrom _pytest.mark.structures import MarkDecorator\nfrom _pytest.mark.structures import normalize_mark_list\nfrom _pytest.outcomes import fail\nfrom _pytest.outcomes import skip\nfrom _pytest.pathlib import fnmatch_ex\nfrom _pytest.pathlib import import_path\nfrom _pytest.pathlib import ImportPathMismatchError\nfrom _pytest.pathlib import scandir\nfrom _pytest.scope import _ScopeName\nfrom _pytest.scope import Scope\nfrom _pytest.stash import StashKey\nfrom _pytest.warning_types import PytestCollectionWarning\nfrom _pytest.warning_types import PytestReturnNotNoneWarning\n\n\nif TYPE_CHECKING:\n    from typing_extensions import Self\n\n\ndef pytest_addoption(parser: Parser) -> None:\n    parser.addini(\n        \"python_files\",\n        type=\"args\",\n        # NOTE: default is also used in AssertionRewritingHook.\n        default=[\"test_*.py\", \"*_test.py\"],\n        help=\"Glob-style file patterns for Python test module discovery\",\n    )\n    parser.addini(\n        \"python_classes\",\n        type=\"args\",\n        default=[\"Test\"],\n        help=\"Prefixes or glob names for Python test class discovery\",\n    )\n    parser.addini(\n        \"python_functions\",\n        type=\"args\",\n        default=[\"test\"],\n        help=\"Prefixes or glob names for Python test function and method discovery\",\n    )\n    parser.addini(\n        \"disable_test_id_escaping_and_forfeit_all_rights_to_community_support\",\n        type=\"bool\",\n        default=False,\n        help=\"Disable string escape non-ASCII characters, might cause unwanted \"\n        \"side effects(use at your own risk)\",\n    )\n\n\ndef pytest_generate_tests(metafunc: Metafunc) -> None:\n    for marker in metafunc.definition.iter_markers(name=\"parametrize\"):\n        metafunc.parametrize(*marker.args, **marker.kwargs, _param_mark=marker)\n\n\ndef pytest_configure(config: Config) -> None:\n    config.addinivalue_line(\n        \"markers\",\n        \"parametrize(argnames, argvalues): call a test function multiple \"\n        \"times passing in differe"}, {"start_line": 3000, "end_line": 5000, "belongs_to": {"file_name": "python.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": ",\n        type=\"args\",\n        default=[\"Test\"],\n        help=\"Prefixes or glob names for Python test class discovery\",\n    )\n    parser.addini(\n        \"python_functions\",\n        type=\"args\",\n        default=[\"test\"],\n        help=\"Prefixes or glob names for Python test function and method discovery\",\n    )\n    parser.addini(\n        \"disable_test_id_escaping_and_forfeit_all_rights_to_community_support\",\n        type=\"bool\",\n        default=False,\n        help=\"Disable string escape non-ASCII characters, might cause unwanted \"\n        \"side effects(use at your own risk)\",\n    )\n\n\ndef pytest_generate_tests(metafunc: Metafunc) -> None:\n    for marker in metafunc.definition.iter_markers(name=\"parametrize\"):\n        metafunc.parametrize(*marker.args, **marker.kwargs, _param_mark=marker)\n\n\ndef pytest_configure(config: Config) -> None:\n    config.addinivalue_line(\n        \"markers\",\n        \"parametrize(argnames, argvalues): call a test function multiple \"\n        \"times passing in different arguments in turn. argvalues generally \"\n        \"needs to be a list of values if argnames specifies only one name \"\n        \"or a list of tuples of values if argnames specifies multiple names. \"\n        \"Example: @parametrize('arg1', [1,2]) would lead to two calls of the \"\n        \"decorated test function, one with arg1=1 and another with arg1=2.\"\n        \"see https://docs.pytest.org/en/stable/how-to/parametrize.html for more info \"\n        \"and examples.\",\n    )\n    config.addinivalue_line(\n        \"markers\",\n        \"usefixtures(fixturename1, fixturename2, ...): mark tests as needing \"\n        \"all of the specified fixtures. see \"\n        \"https://docs.pytest.org/en/stable/explanation/fixtures.html#usefixtures \",\n    )\n\n\ndef async_fail(nodeid: str) -> None:\n    msg = (\n        \"async def functions are not natively supported.\\n\"\n        \"You need to install a suitable plugin for your async framework, for example:\\n\"\n        \"  - anyio\\n\"\n        \"  - pytest-asyncio\\n\"\n        \"  -"}, {"start_line": 34000, "end_line": 36000, "belongs_to": {"file_name": "test_mark.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "stom_mark_non_parametrized():\n            print(\"Hey from test\")\n\n        @pytest.mark.parametrize(\n            \"obj_type\",\n            [\n                first_custom_mark(\"first custom mark\")(\"template\"),\n                pytest.param( # Think this should be recommended way?\n                    \"disk\",\n                    marks=custom_mark('custom mark1')\n                ),\n                custom_mark(\"custom mark2\")(\"vm\"),  # Tried also this\n            ]\n        )\n        def test_custom_mark_parametrized(obj_type):\n            print(\"obj_type is:\", obj_type)\n    \"\"\"\n    )\n\n    result = pytester.runpytest()\n    result.assert_outcomes(passed=4)\n\n\ndef test_pytest_param_id_requires_string() -> None:\n    with pytest.raises(TypeError) as excinfo:\n        pytest.param(id=True)  # type: ignore[arg-type]\n    (msg,) = excinfo.value.args\n    expected = (\n        \"Expected id to be a string or a `pytest.HIDDEN_PARAM` sentinel, \"\n        \"got <class 'bool'>: True\"\n    )\n    assert msg == expected\n\n\n@pytest.mark.parametrize(\"s\", (None, \"hello world\"))\ndef test_pytest_param_id_allows_none_or_string(s) -> None:\n    assert pytest.param(id=s)\n\n\n@pytest.mark.parametrize(\"expr\", (\"NOT internal_err\", \"NOT (internal_err)\", \"bogus=\"))\ndef test_marker_expr_eval_failure_handling(pytester: Pytester, expr) -> None:\n    foo = pytester.makepyfile(\n        \"\"\"\n        import pytest\n\n        @pytest.mark.internal_err\n        def test_foo():\n            pass\n        \"\"\"\n    )\n    expected = f\"ERROR: Wrong expression passed to '-m': {expr}: *\"\n    result = pytester.runpytest(foo, \"-m\", expr)\n    result.stderr.fnmatch_lines([expected])\n    assert result.ret == ExitCode.USAGE_ERROR\n\n\ndef test_mark_mro() -> None:\n    xfail = pytest.mark.xfail\n\n    @xfail(\"a\")\n    class A:\n        pass\n\n    @xfail(\"b\")\n    class B:\n        pass\n\n    @xfail(\"c\")\n    class C(A, B):\n        pass\n\n    from _pytest.mark.structures import get_unpacked_marks\n\n    all_marks = get_unpacked_marks(C)\n\n    assert all_marks == ["}, {"start_line": 18000, "end_line": 20000, "belongs_to": {"file_name": "collect.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing/python", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "  @pytest.mark.parametrize('fix2', ['2'])\n            def test_it(fix1):\n               assert fix1 == '21'\n               assert not fix3_instantiated\n        \"\"\"\n        )\n        rec = pytester.inline_run()\n        rec.assertoutcome(passed=1)\n\n    def test_parametrize_with_mark(self, pytester: Pytester) -> None:\n        items = pytester.getitems(\n            \"\"\"\n            import pytest\n            @pytest.mark.foo\n            @pytest.mark.parametrize('arg', [\n                1,\n                pytest.param(2, marks=[pytest.mark.baz, pytest.mark.bar])\n            ])\n            def test_function(arg):\n                pass\n        \"\"\"\n        )\n        keywords = [item.keywords for item in items]\n        assert (\n            \"foo\" in keywords[0]\n            and \"bar\" not in keywords[0]\n            and \"baz\" not in keywords[0]\n        )\n        assert \"foo\" in keywords[1] and \"bar\" in keywords[1] and \"baz\" in keywords[1]\n\n    def test_parametrize_with_empty_string_arguments(self, pytester: Pytester) -> None:\n        items = pytester.getitems(\n            \"\"\"\\\n            import pytest\n\n            @pytest.mark.parametrize('v', ('', ' '))\n            @pytest.mark.parametrize('w', ('', ' '))\n            def test(v, w): ...\n            \"\"\"\n        )\n        names = {item.name for item in items}\n        assert names == {\"test[-]\", \"test[ -]\", \"test[- ]\", \"test[ - ]\"}\n\n    def test_function_equality_with_callspec(self, pytester: Pytester) -> None:\n        items = pytester.getitems(\n            \"\"\"\n            import pytest\n            @pytest.mark.parametrize('arg', [1,2])\n            def test_function(arg):\n                pass\n        \"\"\"\n        )\n        assert items[0] != items[1]\n        assert not (items[0] == items[1])\n\n    def test_pyfunc_call(self, pytester: Pytester) -> None:\n        item = pytester.getitem(\"def test_func(): raise ValueError\")\n        config = item.config\n\n        class MyPlugin1:\n            def pytest_pyfunc_call(self):\n                rai"}, {"start_line": 67000, "end_line": 69000, "belongs_to": {"file_name": "metafunc.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing/python", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "f test_limit(limit, myfixture):\n                return\n        \"\"\"\n        )\n        reprec = pytester.inline_run()\n        reprec.assertoutcome(passed=2)\n\n    @pytest.mark.parametrize(\"strict\", [True, False])\n    def test_parametrize_marked_value(self, pytester: Pytester, strict: bool) -> None:\n        s = f\"\"\"\n            import pytest\n\n            @pytest.mark.parametrize((\"n\", \"expected\"), [\n                pytest.param(\n                    2,3,\n                    marks=pytest.mark.xfail(\"sys.version_info > (0, 0, 0)\", reason=\"some bug\", strict={strict}),\n                ),\n                pytest.param(\n                    2,3,\n                    marks=[pytest.mark.xfail(\"sys.version_info > (0, 0, 0)\", reason=\"some bug\", strict={strict})],\n                ),\n            ])\n            def test_increment(n, expected):\n                assert n + 1 == expected\n        \"\"\"\n        pytester.makepyfile(s)\n        reprec = pytester.inline_run()\n        passed, failed = (0, 2) if strict else (2, 0)\n        reprec.assertoutcome(passed=passed, failed=failed)\n\n    def test_pytest_make_parametrize_id(self, pytester: Pytester) -> None:\n        pytester.makeconftest(\n            \"\"\"\n            def pytest_make_parametrize_id(config, val):\n                return str(val * 2)\n        \"\"\"\n        )\n        pytester.makepyfile(\n            \"\"\"\n                import pytest\n\n                @pytest.mark.parametrize(\"x\", range(2))\n                def test_func(x):\n                    pass\n                \"\"\"\n        )\n        result = pytester.runpytest(\"-v\")\n        result.stdout.fnmatch_lines([\"*test_func*0*PASS*\", \"*test_func*2*PASS*\"])\n\n    def test_pytest_make_parametrize_id_with_argname(self, pytester: Pytester) -> None:\n        pytester.makeconftest(\n            \"\"\"\n            def pytest_make_parametrize_id(config, val, argname):\n                return str(val * 2 if argname == 'x' else val * 10)\n        \"\"\"\n        )\n        pytester.makepyfile(\n            \"\"\"\n         "}, {"start_line": 11000, "end_line": 13000, "belongs_to": {"file_name": "integration.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing/python", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "test_idfn_marker(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n\n            def idfn(param):\n                if param == 0:\n                    return 'spam'\n                elif param == 1:\n                    return 'ham'\n                else:\n                    return None\n\n            @pytest.mark.parametrize('a,b', [(0, 2), (1, 2)], ids=idfn)\n            def test_params(a, b):\n                pass\n        \"\"\"\n        )\n        res = pytester.runpytest(\"--collect-only\")\n        res.stdout.fnmatch_lines([\"*spam-2*\", \"*ham-2*\"])\n\n    def test_idfn_fixture(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n\n            def idfn(param):\n                if param == 0:\n                    return 'spam'\n                elif param == 1:\n                    return 'ham'\n                else:\n                    return None\n\n            @pytest.fixture(params=[0, 1], ids=idfn)\n            def a(request):\n                return request.param\n\n            @pytest.fixture(params=[1, 2], ids=idfn)\n            def b(request):\n                return request.param\n\n            def test_params(a, b):\n                pass\n        \"\"\"\n        )\n        res = pytester.runpytest(\"--collect-only\")\n        res.stdout.fnmatch_lines([\"*spam-2*\", \"*ham-2*\"])\n\n    def test_param_rejects_usefixtures(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n\n            @pytest.mark.parametrize(\"x\", [\n                pytest.param(1, marks=[pytest.mark.usefixtures(\"foo\")]),\n            ])\n            def test_foo(x):\n                pass\n        \"\"\"\n        )\n        res = pytester.runpytest(\"--collect-only\")\n        res.stdout.fnmatch_lines(\n            [\"*test_param_rejects_usefixtures.py:4*\", \"*pytest.param(*\"]\n        )\n\n\ndef test_function_instance(pytester: Pytester) -> None:\n    items = pytester.getitems(\n        \"\"\"\n        "}, {"start_line": 68000, "end_line": 70000, "belongs_to": {"file_name": "metafunc.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing/python", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "else (2, 0)\n        reprec.assertoutcome(passed=passed, failed=failed)\n\n    def test_pytest_make_parametrize_id(self, pytester: Pytester) -> None:\n        pytester.makeconftest(\n            \"\"\"\n            def pytest_make_parametrize_id(config, val):\n                return str(val * 2)\n        \"\"\"\n        )\n        pytester.makepyfile(\n            \"\"\"\n                import pytest\n\n                @pytest.mark.parametrize(\"x\", range(2))\n                def test_func(x):\n                    pass\n                \"\"\"\n        )\n        result = pytester.runpytest(\"-v\")\n        result.stdout.fnmatch_lines([\"*test_func*0*PASS*\", \"*test_func*2*PASS*\"])\n\n    def test_pytest_make_parametrize_id_with_argname(self, pytester: Pytester) -> None:\n        pytester.makeconftest(\n            \"\"\"\n            def pytest_make_parametrize_id(config, val, argname):\n                return str(val * 2 if argname == 'x' else val * 10)\n        \"\"\"\n        )\n        pytester.makepyfile(\n            \"\"\"\n                import pytest\n\n                @pytest.mark.parametrize(\"x\", range(2))\n                def test_func_a(x):\n                    pass\n\n                @pytest.mark.parametrize(\"y\", [1])\n                def test_func_b(y):\n                    pass\n                \"\"\"\n        )\n        result = pytester.runpytest(\"-v\")\n        result.stdout.fnmatch_lines(\n            [\"*test_func_a*0*PASS*\", \"*test_func_a*2*PASS*\", \"*test_func_b*10*PASS*\"]\n        )\n\n    def test_parametrize_positional_args(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n\n            @pytest.mark.parametrize(\"a\", [1], False)\n            def test_foo(a):\n                pass\n        \"\"\"\n        )\n        result = pytester.runpytest()\n        result.assert_outcomes(passed=1)\n\n    def test_parametrize_iterator(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            import itertools\n            import pytest\n\n            id_par"}, {"start_line": 60000, "end_line": 62000, "belongs_to": {"file_name": "metafunc.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing/python", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "[\"* 4 passed in *\"])\n        assert func_fix_setup == [True] * 4\n        assert class_fix_setup == [10, 20]\n\n    def test_parametrize_issue634(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n\n            @pytest.fixture(scope='module')\n            def foo(request):\n                print('preparing foo-%d' % request.param)\n                return 'foo-%d' % request.param\n\n            def test_one(foo):\n                pass\n\n            def test_two(foo):\n                pass\n\n            test_two.test_with = (2, 3)\n\n            def pytest_generate_tests(metafunc):\n                params = (1, 2, 3, 4)\n                if not 'foo' in metafunc.fixturenames:\n                    return\n\n                test_with = getattr(metafunc.function, 'test_with', None)\n                if test_with:\n                    params = test_with\n                metafunc.parametrize('foo', params, indirect=True)\n        \"\"\"\n        )\n        result = pytester.runpytest(\"-s\")\n        output = result.stdout.str()\n        assert output.count(\"preparing foo-2\") == 1\n        assert output.count(\"preparing foo-3\") == 1\n\n\nclass TestMarkersWithParametrization:\n    \"\"\"#308\"\"\"\n\n    def test_simple_mark(self, pytester: Pytester) -> None:\n        s = \"\"\"\n            import pytest\n\n            @pytest.mark.foo\n            @pytest.mark.parametrize((\"n\", \"expected\"), [\n                (1, 2),\n                pytest.param(1, 3, marks=pytest.mark.bar),\n                (2, 3),\n            ])\n            def test_increment(n, expected):\n                assert n + 1 == expected\n        \"\"\"\n        items = pytester.getitems(s)\n        assert len(items) == 3\n        for item in items:\n            assert \"foo\" in item.keywords\n        assert \"bar\" not in items[0].keywords\n        assert \"bar\" in items[1].keywords\n        assert \"bar\" not in items[2].keywords\n\n    def test_select_based_on_mark(self, pytester: Pytester) -> None:\n        s = \"\"\"\n            im"}, {"start_line": 61000, "end_line": 63000, "belongs_to": {"file_name": "metafunc.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing/python", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "ester.runpytest(\"-s\")\n        output = result.stdout.str()\n        assert output.count(\"preparing foo-2\") == 1\n        assert output.count(\"preparing foo-3\") == 1\n\n\nclass TestMarkersWithParametrization:\n    \"\"\"#308\"\"\"\n\n    def test_simple_mark(self, pytester: Pytester) -> None:\n        s = \"\"\"\n            import pytest\n\n            @pytest.mark.foo\n            @pytest.mark.parametrize((\"n\", \"expected\"), [\n                (1, 2),\n                pytest.param(1, 3, marks=pytest.mark.bar),\n                (2, 3),\n            ])\n            def test_increment(n, expected):\n                assert n + 1 == expected\n        \"\"\"\n        items = pytester.getitems(s)\n        assert len(items) == 3\n        for item in items:\n            assert \"foo\" in item.keywords\n        assert \"bar\" not in items[0].keywords\n        assert \"bar\" in items[1].keywords\n        assert \"bar\" not in items[2].keywords\n\n    def test_select_based_on_mark(self, pytester: Pytester) -> None:\n        s = \"\"\"\n            import pytest\n\n            @pytest.mark.parametrize((\"n\", \"expected\"), [\n                (1, 2),\n                pytest.param(2, 3, marks=pytest.mark.foo),\n                (3, 4),\n            ])\n            def test_increment(n, expected):\n                assert n + 1 == expected\n        \"\"\"\n        pytester.makepyfile(s)\n        rec = pytester.inline_run(\"-m\", \"foo\")\n        passed, skipped, fail = rec.listoutcomes()\n        assert len(passed) == 1\n        assert len(skipped) == 0\n        assert len(fail) == 0\n\n    def test_simple_xfail(self, pytester: Pytester) -> None:\n        s = \"\"\"\n            import pytest\n\n            @pytest.mark.parametrize((\"n\", \"expected\"), [\n                (1, 2),\n                pytest.param(1, 3, marks=pytest.mark.xfail),\n                (2, 3),\n            ])\n            def test_increment(n, expected):\n                assert n + 1 == expected\n        \"\"\"\n        pytester.makepyfile(s)\n        reprec = pytester.inline_run()\n        # xfail is skip??\n    "}], "retrieved_count": 10, "cost_time": 1.2734882831573486}
{"question": "Why does Pytest use a hook-based plugin system instead of inheritance-based extension mechanisms?", "answer": null, "relative_code_list": null, "ground_truth": "Pytest uses a hook-based plugin system instead of inheritance-based extension mechanisms for several key architectural and practical reasons: 1) Hook-based system provides loose coupling where plugins can be added or removed without modifying core code, unlike inheritance which creates tight coupling between base and derived classes, 2) Hook system enables multiple plugins to implement the same hook specification (1:N relationship), while inheritance typically creates a 1:1 relationship between base and derived classes, 3) Hook system allows for dynamic plugin discovery and registration at runtime, whereas inheritance requires compile-time class definitions, 4) Hook system provides better separation of concerns where each plugin focuses on specific functionality without needing to understand the entire inheritance hierarchy, 5) Hook system enables conditional plugin loading and plugin conflicts resolution through the plugin manager, 6) Hook system supports hook wrappers that can execute around other hook implementations, providing cross-cutting functionality, 7) Hook system allows for future-compatible extensions where new hook parameters can be added without breaking existing plugin signatures, 8) Hook system provides better testability as plugins can be tested in isolation without complex inheritance hierarchies, 9) Hook system enables plugin ordering control through tryfirst/trylast markers, which is difficult to achieve with inheritance, 10) Hook system supports plugin collaboration where plugins can access other plugins through the plugin manager, 11) Hook system provides better error isolation where a failing plugin doesn't break the entire system, 12) Hook system enables the core test runner to remain minimal while all functionality is provided through plugins, creating a more modular and maintainable architecture.", "score": null, "retrieved_content": [{"start_line": 11000, "end_line": 13000, "belongs_to": {"file_name": "__init__.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest/config", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "ed.HOOK_LEGACY_MARKING.format(\n            type=hook_type,\n            fullname=method.__qualname__,\n            hook_opts=hook_opts,\n        )\n        warn_explicit_for(cast(FunctionType, method), message)\n    return opts\n\n\n@final\nclass PytestPluginManager(PluginManager):\n    \"\"\"A :py:class:`pluggy.PluginManager <pluggy.PluginManager>` with\n    additional pytest-specific functionality:\n\n    * Loading plugins from the command line, ``PYTEST_PLUGINS`` env variable and\n      ``pytest_plugins`` global variables found in plugins being loaded.\n    * ``conftest.py`` loading during start-up.\n    \"\"\"\n\n    def __init__(self) -> None:\n        from _pytest.assertion import DummyRewriteHook\n        from _pytest.assertion import RewriteHook\n\n        super().__init__(\"pytest\")\n\n        # -- State related to local conftest plugins.\n        # All loaded conftest modules.\n        self._conftest_plugins: set[types.ModuleType] = set()\n        # All conftest modules applicable for a directory.\n        # This includes the directory's own conftest modules as well\n        # as those of its parent directories.\n        self._dirpath2confmods: dict[pathlib.Path, list[types.ModuleType]] = {}\n        # Cutoff directory above which conftests are no longer discovered.\n        self._confcutdir: pathlib.Path | None = None\n        # If set, conftest loading is skipped.\n        self._noconftest = False\n\n        # _getconftestmodules()'s call to _get_directory() causes a stat\n        # storm when it's called potentially thousands of times in a test\n        # session (#9478), often with the same path, so cache it.\n        self._get_directory = lru_cache(256)(_get_directory)\n\n        # plugins that were explicitly skipped with pytest.skip\n        # list of (module name, skip reason)\n        # previously we would issue a warning when a plugin was skipped, but\n        # since we refactored warnings as first citizens of Config, they are\n        # just stored here to be used later.\n        self.skipped_plu"}, {"start_line": 13000, "end_line": 15000, "belongs_to": {"file_name": "__init__.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest/config", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "gins: list[tuple[str, str]] = []\n\n        self.add_hookspecs(_pytest.hookspec)\n        self.register(self)\n        if os.environ.get(\"PYTEST_DEBUG\"):\n            err: IO[str] = sys.stderr\n            encoding: str = getattr(err, \"encoding\", \"utf8\")\n            try:\n                err = open(\n                    os.dup(err.fileno()),\n                    mode=err.mode,\n                    buffering=1,\n                    encoding=encoding,\n                )\n            except Exception:\n                pass\n            self.trace.root.setwriter(err.write)\n            self.enable_tracing()\n\n        # Config._consider_importhook will set a real object if required.\n        self.rewrite_hook: RewriteHook = DummyRewriteHook()\n        # Used to know when we are importing conftests after the pytest_configure stage.\n        self._configured = False\n\n    def parse_hookimpl_opts(\n        self, plugin: _PluggyPlugin, name: str\n    ) -> HookimplOpts | None:\n        \"\"\":meta private:\"\"\"\n        # pytest hooks are always prefixed with \"pytest_\",\n        # so we avoid accessing possibly non-readable attributes\n        # (see issue #1073).\n        if not name.startswith(\"pytest_\"):\n            return None\n        # Ignore names which cannot be hooks.\n        if name == \"pytest_plugins\":\n            return None\n\n        opts = super().parse_hookimpl_opts(plugin, name)\n        if opts is not None:\n            return opts\n\n        method = getattr(plugin, name)\n        # Consider only actual functions for hooks (#3775).\n        if not inspect.isroutine(method):\n            return None\n        # Collect unmarked hooks as long as they have the `pytest_' prefix.\n        legacy = _get_legacy_hook_marks(\n            method, \"impl\", (\"tryfirst\", \"trylast\", \"optionalhook\", \"hookwrapper\")\n        )\n        return cast(HookimplOpts, legacy)\n\n    def parse_hookspec_opts(self, module_or_class, name: str) -> HookspecOpts | None:\n        \"\"\":meta private:\"\"\"\n        opts = super().parse_hookspec_op"}, {"start_line": 0, "end_line": 2000, "belongs_to": {"file_name": "test_pluginmanager.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "# mypy: allow-untyped-defs\nfrom __future__ import annotations\n\nimport os\nimport shutil\nimport sys\nimport types\n\nfrom _pytest.config import Config\nfrom _pytest.config import ExitCode\nfrom _pytest.config import PytestPluginManager\nfrom _pytest.config.exceptions import UsageError\nfrom _pytest.main import Session\nfrom _pytest.monkeypatch import MonkeyPatch\nfrom _pytest.pathlib import import_path\nfrom _pytest.pytester import Pytester\nimport pytest\n\n\n@pytest.fixture\ndef pytestpm() -> PytestPluginManager:\n    return PytestPluginManager()\n\n\nclass TestPytestPluginInteractions:\n    def test_addhooks_conftestplugin(\n        self, pytester: Pytester, _config_for_test: Config\n    ) -> None:\n        pytester.makepyfile(\n            newhooks=\"\"\"\n            def pytest_myhook(xyz):\n                \"new hook\"\n        \"\"\"\n        )\n        conf = pytester.makeconftest(\n            \"\"\"\n            import newhooks\n            def pytest_addhooks(pluginmanager):\n                pluginmanager.add_hookspecs(newhooks)\n            def pytest_myhook(xyz):\n                return xyz + 1\n        \"\"\"\n        )\n        config = _config_for_test\n        pm = config.pluginmanager\n        pm.hook.pytest_addhooks.call_historic(\n            kwargs=dict(pluginmanager=config.pluginmanager)\n        )\n        config.pluginmanager._importconftest(\n            conf,\n            importmode=\"prepend\",\n            rootpath=pytester.path,\n            consider_namespace_packages=False,\n        )\n        # print(config.pluginmanager.get_plugins())\n        res = config.hook.pytest_myhook(xyz=10)\n        assert res == [11]\n\n    def test_addhooks_nohooks(self, pytester: Pytester) -> None:\n        pytester.makeconftest(\n            \"\"\"\n            import sys\n            def pytest_addhooks(pluginmanager):\n                pluginmanager.add_hookspecs(sys)\n        \"\"\"\n        )\n        res = pytester.runpytest()\n        assert res.ret != 0\n        res.stderr.fnmatch_lines([\"*did not find*sys*\"])\n\n    def test_do_option"}, {"start_line": 1000, "end_line": 3000, "belongs_to": {"file_name": "hookspec.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "  from _pytest.nodes import Collector\n    from _pytest.nodes import Item\n    from _pytest.outcomes import Exit\n    from _pytest.python import Class\n    from _pytest.python import Function\n    from _pytest.python import Metafunc\n    from _pytest.python import Module\n    from _pytest.reports import CollectReport\n    from _pytest.reports import TestReport\n    from _pytest.runner import CallInfo\n    from _pytest.terminal import TerminalReporter\n    from _pytest.terminal import TestShortLogReport\n\n\nhookspec = HookspecMarker(\"pytest\")\n\n# -------------------------------------------------------------------------\n# Initialization hooks called for every plugin\n# -------------------------------------------------------------------------\n\n\n@hookspec(historic=True)\ndef pytest_addhooks(pluginmanager: PytestPluginManager) -> None:\n    \"\"\"Called at plugin registration time to allow adding new hooks via a call to\n    :func:`pluginmanager.add_hookspecs(module_or_class, prefix) <pytest.PytestPluginManager.add_hookspecs>`.\n\n    :param pluginmanager: The pytest plugin manager.\n\n    .. note::\n        This hook is incompatible with hook wrappers.\n\n    Use in conftest plugins\n    =======================\n\n    If a conftest plugin implements this hook, it will be called immediately\n    when the conftest is registered.\n    \"\"\"\n\n\n@hookspec(historic=True)\ndef pytest_plugin_registered(\n    plugin: _PluggyPlugin,\n    plugin_name: str,\n    manager: PytestPluginManager,\n) -> None:\n    \"\"\"A new pytest plugin got registered.\n\n    :param plugin: The plugin module or instance.\n    :param plugin_name: The name by which the plugin is registered.\n    :param manager: The pytest plugin manager.\n\n    .. note::\n        This hook is incompatible with hook wrappers.\n\n    Use in conftest plugins\n    =======================\n\n    If a conftest plugin implements this hook, it will be called immediately\n    when the conftest is registered, once for each plugin registered thus far\n    (including itself!), and for all "}, {"start_line": 0, "end_line": 2000, "belongs_to": {"file_name": "hookspec.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "# mypy: allow-untyped-defs\n# ruff: noqa: T100\n\"\"\"Hook specifications for pytest plugins which are invoked by pytest itself\nand by builtin plugins.\"\"\"\n\nfrom __future__ import annotations\n\nfrom collections.abc import Mapping\nfrom collections.abc import Sequence\nfrom pathlib import Path\nfrom typing import Any\nfrom typing import TYPE_CHECKING\n\nfrom pluggy import HookspecMarker\n\nfrom .deprecated import HOOK_LEGACY_PATH_ARG\n\n\nif TYPE_CHECKING:\n    import pdb\n    from typing import Literal\n    import warnings\n\n    from _pytest._code.code import ExceptionInfo\n    from _pytest._code.code import ExceptionRepr\n    from _pytest.compat import LEGACY_PATH\n    from _pytest.config import _PluggyPlugin\n    from _pytest.config import Config\n    from _pytest.config import ExitCode\n    from _pytest.config import PytestPluginManager\n    from _pytest.config.argparsing import Parser\n    from _pytest.fixtures import FixtureDef\n    from _pytest.fixtures import SubRequest\n    from _pytest.main import Session\n    from _pytest.nodes import Collector\n    from _pytest.nodes import Item\n    from _pytest.outcomes import Exit\n    from _pytest.python import Class\n    from _pytest.python import Function\n    from _pytest.python import Metafunc\n    from _pytest.python import Module\n    from _pytest.reports import CollectReport\n    from _pytest.reports import TestReport\n    from _pytest.runner import CallInfo\n    from _pytest.terminal import TerminalReporter\n    from _pytest.terminal import TestShortLogReport\n\n\nhookspec = HookspecMarker(\"pytest\")\n\n# -------------------------------------------------------------------------\n# Initialization hooks called for every plugin\n# -------------------------------------------------------------------------\n\n\n@hookspec(historic=True)\ndef pytest_addhooks(pluginmanager: PytestPluginManager) -> None:\n    \"\"\"Called at plugin registration time to allow adding new hooks via a call to\n    :func:`pluginmanager.add_hookspecs(module_or_class, prefix) <pytest.PytestPluginManager"}, {"start_line": 14000, "end_line": 16000, "belongs_to": {"file_name": "__init__.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest/config", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "test hooks are always prefixed with \"pytest_\",\n        # so we avoid accessing possibly non-readable attributes\n        # (see issue #1073).\n        if not name.startswith(\"pytest_\"):\n            return None\n        # Ignore names which cannot be hooks.\n        if name == \"pytest_plugins\":\n            return None\n\n        opts = super().parse_hookimpl_opts(plugin, name)\n        if opts is not None:\n            return opts\n\n        method = getattr(plugin, name)\n        # Consider only actual functions for hooks (#3775).\n        if not inspect.isroutine(method):\n            return None\n        # Collect unmarked hooks as long as they have the `pytest_' prefix.\n        legacy = _get_legacy_hook_marks(\n            method, \"impl\", (\"tryfirst\", \"trylast\", \"optionalhook\", \"hookwrapper\")\n        )\n        return cast(HookimplOpts, legacy)\n\n    def parse_hookspec_opts(self, module_or_class, name: str) -> HookspecOpts | None:\n        \"\"\":meta private:\"\"\"\n        opts = super().parse_hookspec_opts(module_or_class, name)\n        if opts is None:\n            method = getattr(module_or_class, name)\n            if name.startswith(\"pytest_\"):\n                legacy = _get_legacy_hook_marks(\n                    method, \"spec\", (\"firstresult\", \"historic\")\n                )\n                opts = cast(HookspecOpts, legacy)\n        return opts\n\n    def register(self, plugin: _PluggyPlugin, name: str | None = None) -> str | None:\n        if name in _pytest.deprecated.DEPRECATED_EXTERNAL_PLUGINS:\n            warnings.warn(\n                PytestConfigWarning(\n                    \"{} plugin has been merged into the core, \"\n                    \"please remove it from your requirements.\".format(\n                        name.replace(\"_\", \"-\")\n                    )\n                )\n            )\n            return None\n        plugin_name = super().register(plugin, name)\n        if plugin_name is not None:\n            self.hook.pytest_plugin_registered.call_historic(\n                kwargs=d"}, {"start_line": 5000, "end_line": 7000, "belongs_to": {"file_name": "test_pluginmanager.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": " list[str] = []\n        pytestpm.trace.root.setwriter(values.append)\n        undo = pytestpm.enable_tracing()\n        try:\n            indent = pytestpm.trace.root.indent\n            p = api1()\n            pytestpm.register(p)\n            assert pytestpm.trace.root.indent == indent\n            assert len(values) >= 2\n            assert \"pytest_plugin_registered\" in values[0]\n            assert \"finish\" in values[1]\n\n            values[:] = []\n            with pytest.raises(ValueError):\n                pytestpm.register(api2())\n            assert pytestpm.trace.root.indent == indent\n            assert saveindent[0] > indent\n        finally:\n            undo()\n\n    def test_hook_proxy(self, pytester: Pytester) -> None:\n        \"\"\"Test the gethookproxy function(#2016)\"\"\"\n        config = pytester.parseconfig()\n        session = Session.from_config(config)\n        pytester.makepyfile(**{\"tests/conftest.py\": \"\", \"tests/subdir/conftest.py\": \"\"})\n\n        conftest1 = pytester.path.joinpath(\"tests/conftest.py\")\n        conftest2 = pytester.path.joinpath(\"tests/subdir/conftest.py\")\n\n        config.pluginmanager._importconftest(\n            conftest1,\n            importmode=\"prepend\",\n            rootpath=pytester.path,\n            consider_namespace_packages=False,\n        )\n        ihook_a = session.gethookproxy(pytester.path / \"tests\")\n        assert ihook_a is not None\n        config.pluginmanager._importconftest(\n            conftest2,\n            importmode=\"prepend\",\n            rootpath=pytester.path,\n            consider_namespace_packages=False,\n        )\n        ihook_b = session.gethookproxy(pytester.path / \"tests\")\n        assert ihook_a is not ihook_b\n\n    def test_hook_with_addoption(self, pytester: Pytester) -> None:\n        \"\"\"Test that hooks can be used in a call to pytest_addoption\"\"\"\n        pytester.makepyfile(\n            newhooks=\"\"\"\n            import pytest\n            @pytest.hookspec(firstresult=True)\n            def pytest_default_value():\n        "}, {"start_line": 1000, "end_line": 3000, "belongs_to": {"file_name": "test_pluginmanager.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "newhooks)\n            def pytest_myhook(xyz):\n                return xyz + 1\n        \"\"\"\n        )\n        config = _config_for_test\n        pm = config.pluginmanager\n        pm.hook.pytest_addhooks.call_historic(\n            kwargs=dict(pluginmanager=config.pluginmanager)\n        )\n        config.pluginmanager._importconftest(\n            conf,\n            importmode=\"prepend\",\n            rootpath=pytester.path,\n            consider_namespace_packages=False,\n        )\n        # print(config.pluginmanager.get_plugins())\n        res = config.hook.pytest_myhook(xyz=10)\n        assert res == [11]\n\n    def test_addhooks_nohooks(self, pytester: Pytester) -> None:\n        pytester.makeconftest(\n            \"\"\"\n            import sys\n            def pytest_addhooks(pluginmanager):\n                pluginmanager.add_hookspecs(sys)\n        \"\"\"\n        )\n        res = pytester.runpytest()\n        assert res.ret != 0\n        res.stderr.fnmatch_lines([\"*did not find*sys*\"])\n\n    def test_do_option_postinitialize(self, pytester: Pytester) -> None:\n        config = pytester.parseconfigure()\n        assert not hasattr(config.option, \"test123\")\n        p = pytester.makepyfile(\n            \"\"\"\n            def pytest_addoption(parser):\n                parser.addoption('--test123', action=\"store_true\",\n                    default=True)\n        \"\"\"\n        )\n        config.pluginmanager._importconftest(\n            p,\n            importmode=\"prepend\",\n            rootpath=pytester.path,\n            consider_namespace_packages=False,\n        )\n        assert config.option.test123\n\n    def test_configure(self, pytester: Pytester) -> None:\n        config = pytester.parseconfig()\n        values = []\n\n        class A:\n            def pytest_configure(self):\n                values.append(self)\n\n        config.pluginmanager.register(A())\n        assert len(values) == 0\n        config._do_configure()\n        assert len(values) == 1\n        config.pluginmanager.register(A())  # leads to a confi"}, {"start_line": 10000, "end_line": 12000, "belongs_to": {"file_name": "__init__.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest/config", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "ory.\"\"\"\n    if path.is_file():\n        return path.parent\n    else:\n        return path\n\n\ndef _get_legacy_hook_marks(\n    method: Any,\n    hook_type: str,\n    opt_names: tuple[str, ...],\n) -> dict[str, bool]:\n    if TYPE_CHECKING:\n        # abuse typeguard from importlib to avoid massive method type union that's lacking an alias\n        assert inspect.isroutine(method)\n    known_marks: set[str] = {m.name for m in getattr(method, \"pytestmark\", [])}\n    must_warn: list[str] = []\n    opts: dict[str, bool] = {}\n    for opt_name in opt_names:\n        opt_attr = getattr(method, opt_name, AttributeError)\n        if opt_attr is not AttributeError:\n            must_warn.append(f\"{opt_name}={opt_attr}\")\n            opts[opt_name] = True\n        elif opt_name in known_marks:\n            must_warn.append(f\"{opt_name}=True\")\n            opts[opt_name] = True\n        else:\n            opts[opt_name] = False\n    if must_warn:\n        hook_opts = \", \".join(must_warn)\n        message = _pytest.deprecated.HOOK_LEGACY_MARKING.format(\n            type=hook_type,\n            fullname=method.__qualname__,\n            hook_opts=hook_opts,\n        )\n        warn_explicit_for(cast(FunctionType, method), message)\n    return opts\n\n\n@final\nclass PytestPluginManager(PluginManager):\n    \"\"\"A :py:class:`pluggy.PluginManager <pluggy.PluginManager>` with\n    additional pytest-specific functionality:\n\n    * Loading plugins from the command line, ``PYTEST_PLUGINS`` env variable and\n      ``pytest_plugins`` global variables found in plugins being loaded.\n    * ``conftest.py`` loading during start-up.\n    \"\"\"\n\n    def __init__(self) -> None:\n        from _pytest.assertion import DummyRewriteHook\n        from _pytest.assertion import RewriteHook\n\n        super().__init__(\"pytest\")\n\n        # -- State related to local conftest plugins.\n        # All loaded conftest modules.\n        self._conftest_plugins: set[types.ModuleType] = set()\n        # All conftest modules applicable for a directory.\n        # T"}, {"start_line": 51000, "end_line": 53000, "belongs_to": {"file_name": "test_config.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "   (\n            hookimpl.function.__module__,\n            \"wrapper\" if (hookimpl.wrapper or hookimpl.hookwrapper) else \"nonwrapper\",\n        )\n        for hookimpl in hc.get_hookimpls()\n    ]\n    assert hookimpls == [\n        (\"_pytest.config\", \"nonwrapper\"),\n        (m.__module__, \"nonwrapper\"),\n        (\"_pytest.legacypath\", \"nonwrapper\"),\n        (\"_pytest.capture\", \"wrapper\"),\n        (\"_pytest.warnings\", \"wrapper\"),\n    ]\n\n\ndef test_get_plugin_specs_as_list() -> None:\n    def exp_match(val: object) -> str:\n        return (\n            f\"Plugins may be specified as a sequence or a ','-separated string \"\n            f\"of plugin names. Got: {re.escape(repr(val))}\"\n        )\n\n    with pytest.raises(pytest.UsageError, match=exp_match({\"foo\"})):\n        _get_plugin_specs_as_list({\"foo\"})  # type: ignore[arg-type]\n    with pytest.raises(pytest.UsageError, match=exp_match({})):\n        _get_plugin_specs_as_list(dict())  # type: ignore[arg-type]\n\n    assert _get_plugin_specs_as_list(None) == []\n    assert _get_plugin_specs_as_list(\"\") == []\n    assert _get_plugin_specs_as_list(\"foo\") == [\"foo\"]\n    assert _get_plugin_specs_as_list(\"foo,bar\") == [\"foo\", \"bar\"]\n    assert _get_plugin_specs_as_list([\"foo\", \"bar\"]) == [\"foo\", \"bar\"]\n    assert _get_plugin_specs_as_list((\"foo\", \"bar\")) == [\"foo\", \"bar\"]\n\n\ndef test_collect_pytest_prefix_bug_integration(pytester: Pytester) -> None:\n    \"\"\"Integration test for issue #3775\"\"\"\n    p = pytester.copy_example(\"config/collect_pytest_prefix\")\n    result = pytester.runpytest(p)\n    result.stdout.fnmatch_lines([\"* 1 passed *\"])\n\n\ndef test_collect_pytest_prefix_bug(pytestconfig):\n    \"\"\"Ensure we collect only actual functions from conftest files (#3775)\"\"\"\n\n    class Dummy:\n        class pytest_something:\n            pass\n\n    pm = pytestconfig.pluginmanager\n    assert pm.parse_hookimpl_opts(Dummy(), \"pytest_something\") is None\n\n\nclass TestRootdir:\n    def test_simple_noini(self, tmp_path: Path, monkeypatch: MonkeyPatch) -> None:\n      "}], "retrieved_count": 10, "cost_time": 1.2968251705169678}
{"question": "Where in Pytest is the fixture system implemented?", "answer": null, "relative_code_list": null, "ground_truth": "The fixture system in pytest is implemented primarily in the src/_pytest/fixtures.py module, which contains the core fixture functionality: 1) The FixtureManager class serves as the central manager for fixture definitions and information, handling fixture discovery, registration, and resolution, 2) The FixtureDef class represents individual fixture definitions, containing metadata about fixtures including their function, scope, parameters, and caching behavior, 3) The FixtureRequest class provides access to the requesting test context and fixture information during fixture execution, 4) The SubRequest class handles fixture execution within specific scopes and manages parameter passing for parametrized fixtures, 5) The FuncFixtureInfo class holds fixture-related information for test functions, including fixture names, dependencies, and closure calculations, 6) The fixture decorator function in src/_pytest/fixtures.py provides the @pytest.fixture decorator for defining fixtures, 7) The pytest_fixture_setup hook in src/_pytest/fixtures.py handles the actual execution of fixture functions, 8) Fixture resolution logic is implemented in methods like getfixtureclosure() which computes the transitive closure of fixture dependencies, 9) Fixture caching and scope management is handled through the FixtureDef.cached_result attribute and scope-based execution, 10) Fixture finalization and cleanup is managed through the finish() method in FixtureDef and finalizer registration, 11) The fixture system integrates with the plugin system through the PytestPluginManager, allowing fixtures to be defined in plugins and conftest files, 12) Fixture discovery and parsing occurs during collection through FixtureManager.parsefactories() which scans for fixture definitions in modules and plugins.", "score": null, "retrieved_content": [{"start_line": 2000, "end_line": 4000, "belongs_to": {"file_name": "fixtures.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "comes import fail\nfrom _pytest.outcomes import skip\nfrom _pytest.outcomes import TEST_OUTCOME\nfrom _pytest.pathlib import absolutepath\nfrom _pytest.pathlib import bestrelpath\nfrom _pytest.scope import _ScopeName\nfrom _pytest.scope import HIGH_SCOPES\nfrom _pytest.scope import Scope\nfrom _pytest.warning_types import PytestRemovedIn9Warning\nfrom _pytest.warning_types import PytestWarning\n\n\nif sys.version_info < (3, 11):\n    from exceptiongroup import BaseExceptionGroup\n\n\nif TYPE_CHECKING:\n    from _pytest.python import CallSpec2\n    from _pytest.python import Function\n    from _pytest.python import Metafunc\n\n\n# The value of the fixture -- return/yield of the fixture function (type variable).\nFixtureValue = TypeVar(\"FixtureValue\")\n# The type of the fixture function (type variable).\nFixtureFunction = TypeVar(\"FixtureFunction\", bound=Callable[..., object])\n# The type of a fixture function (type alias generic in fixture value).\n_FixtureFunc = Union[\n    Callable[..., FixtureValue], Callable[..., Generator[FixtureValue]]\n]\n# The type of FixtureDef.cached_result (type alias generic in fixture value).\n_FixtureCachedResult = Union[\n    tuple[\n        # The result.\n        FixtureValue,\n        # Cache key.\n        object,\n        None,\n    ],\n    tuple[\n        None,\n        # Cache key.\n        object,\n        # The exception and the original traceback.\n        tuple[BaseException, Optional[types.TracebackType]],\n    ],\n]\n\n\n@dataclasses.dataclass(frozen=True)\nclass PseudoFixtureDef(Generic[FixtureValue]):\n    cached_result: _FixtureCachedResult[FixtureValue]\n    _scope: Scope\n\n\ndef pytest_sessionstart(session: Session) -> None:\n    session._fixturemanager = FixtureManager(session)\n\n\ndef get_scope_package(\n    node: nodes.Item,\n    fixturedef: FixtureDef[object],\n) -> nodes.Node | None:\n    from _pytest.python import Package\n\n    for parent in node.iter_parents():\n        if isinstance(parent, Package) and parent.nodeid == fixturedef.baseid:\n            return parent\n    retur"}, {"start_line": 3000, "end_line": 5000, "belongs_to": {"file_name": "fixtures.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": ".., Generator[FixtureValue]]\n]\n# The type of FixtureDef.cached_result (type alias generic in fixture value).\n_FixtureCachedResult = Union[\n    tuple[\n        # The result.\n        FixtureValue,\n        # Cache key.\n        object,\n        None,\n    ],\n    tuple[\n        None,\n        # Cache key.\n        object,\n        # The exception and the original traceback.\n        tuple[BaseException, Optional[types.TracebackType]],\n    ],\n]\n\n\n@dataclasses.dataclass(frozen=True)\nclass PseudoFixtureDef(Generic[FixtureValue]):\n    cached_result: _FixtureCachedResult[FixtureValue]\n    _scope: Scope\n\n\ndef pytest_sessionstart(session: Session) -> None:\n    session._fixturemanager = FixtureManager(session)\n\n\ndef get_scope_package(\n    node: nodes.Item,\n    fixturedef: FixtureDef[object],\n) -> nodes.Node | None:\n    from _pytest.python import Package\n\n    for parent in node.iter_parents():\n        if isinstance(parent, Package) and parent.nodeid == fixturedef.baseid:\n            return parent\n    return node.session\n\n\ndef get_scope_node(node: nodes.Node, scope: Scope) -> nodes.Node | None:\n    \"\"\"Get the closest parent node (including self) which matches the given\n    scope.\n\n    If there is no parent node for the scope (e.g. asking for class scope on a\n    Module, or on a Function when not defined in a class), returns None.\n    \"\"\"\n    import _pytest.python\n\n    if scope is Scope.Function:\n        # Type ignored because this is actually safe, see:\n        # https://github.com/python/mypy/issues/4717\n        return node.getparent(nodes.Item)  # type: ignore[type-abstract]\n    elif scope is Scope.Class:\n        return node.getparent(_pytest.python.Class)\n    elif scope is Scope.Module:\n        return node.getparent(_pytest.python.Module)\n    elif scope is Scope.Package:\n        return node.getparent(_pytest.python.Package)\n    elif scope is Scope.Session:\n        return node.getparent(_pytest.main.Session)\n    else:\n        assert_never(scope)\n\n\n# TODO: Try to use FixtureFunctionDefi"}, {"start_line": 47000, "end_line": 49000, "belongs_to": {"file_name": "fixtures.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "(fixturefunc, request, kwargs)\n    except TEST_OUTCOME as e:\n        if isinstance(e, skip.Exception):\n            # The test requested a fixture which caused a skip.\n            # Don't show the fixture as the skip location, as then the user\n            # wouldn't know which test skipped.\n            e._use_item_location = True\n        fixturedef.cached_result = (None, my_cache_key, (e, e.__traceback__))\n        raise\n    fixturedef.cached_result = (result, my_cache_key, None)\n    return result\n\n\n@final\n@dataclasses.dataclass(frozen=True)\nclass FixtureFunctionMarker:\n    scope: _ScopeName | Callable[[str, Config], _ScopeName]\n    params: tuple[object, ...] | None\n    autouse: bool = False\n    ids: tuple[object | None, ...] | Callable[[Any], object | None] | None = None\n    name: str | None = None\n\n    _ispytest: dataclasses.InitVar[bool] = False\n\n    def __post_init__(self, _ispytest: bool) -> None:\n        check_ispytest(_ispytest)\n\n    def __call__(self, function: FixtureFunction) -> FixtureFunctionDefinition:\n        if inspect.isclass(function):\n            raise ValueError(\"class fixtures not supported (maybe in the future)\")\n\n        if isinstance(function, FixtureFunctionDefinition):\n            raise ValueError(\n                f\"@pytest.fixture is being applied more than once to the same function {function.__name__!r}\"\n            )\n\n        if hasattr(function, \"pytestmark\"):\n            warnings.warn(MARKED_FIXTURE, stacklevel=2)\n\n        fixture_definition = FixtureFunctionDefinition(\n            function=function, fixture_function_marker=self, _ispytest=True\n        )\n\n        name = self.name or function.__name__\n        if name == \"request\":\n            location = getlocation(function)\n            fail(\n                f\"'request' is a reserved word for fixtures, use another name:\\n  {location}\",\n                pytrace=False,\n            )\n\n        return fixture_definition\n\n\n# TODO: paramspec/return type annotation tracking and storing\nclass Fixtur"}, {"start_line": 1000, "end_line": 3000, "belongs_to": {"file_name": "fixtures.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "_code import Source\nfrom _pytest._code.code import FormattedExcinfo\nfrom _pytest._code.code import TerminalRepr\nfrom _pytest._io import TerminalWriter\nfrom _pytest.compat import assert_never\nfrom _pytest.compat import get_real_func\nfrom _pytest.compat import getfuncargnames\nfrom _pytest.compat import getimfunc\nfrom _pytest.compat import getlocation\nfrom _pytest.compat import NOTSET\nfrom _pytest.compat import NotSetType\nfrom _pytest.compat import safe_getattr\nfrom _pytest.compat import safe_isclass\nfrom _pytest.compat import signature\nfrom _pytest.config import _PluggyPlugin\nfrom _pytest.config import Config\nfrom _pytest.config import ExitCode\nfrom _pytest.config.argparsing import Parser\nfrom _pytest.deprecated import check_ispytest\nfrom _pytest.deprecated import MARKED_FIXTURE\nfrom _pytest.deprecated import YIELD_FIXTURE\nfrom _pytest.main import Session\nfrom _pytest.mark import Mark\nfrom _pytest.mark import ParameterSet\nfrom _pytest.mark.structures import MarkDecorator\nfrom _pytest.outcomes import fail\nfrom _pytest.outcomes import skip\nfrom _pytest.outcomes import TEST_OUTCOME\nfrom _pytest.pathlib import absolutepath\nfrom _pytest.pathlib import bestrelpath\nfrom _pytest.scope import _ScopeName\nfrom _pytest.scope import HIGH_SCOPES\nfrom _pytest.scope import Scope\nfrom _pytest.warning_types import PytestRemovedIn9Warning\nfrom _pytest.warning_types import PytestWarning\n\n\nif sys.version_info < (3, 11):\n    from exceptiongroup import BaseExceptionGroup\n\n\nif TYPE_CHECKING:\n    from _pytest.python import CallSpec2\n    from _pytest.python import Function\n    from _pytest.python import Metafunc\n\n\n# The value of the fixture -- return/yield of the fixture function (type variable).\nFixtureValue = TypeVar(\"FixtureValue\")\n# The type of the fixture function (type variable).\nFixtureFunction = TypeVar(\"FixtureFunction\", bound=Callable[..., object])\n# The type of a fixture function (type alias generic in fixture value).\n_FixtureFunc = Union[\n    Callable[..., FixtureValue], Callable[."}, {"start_line": 52000, "end_line": 54000, "belongs_to": {"file_name": "fixtures.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing/python", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "               return request._fixturemanager\n\n            @pytest.fixture\n            def item(request):\n                return request._pyfuncitem\n        \"\"\"\n        )\n        return pytester\n\n    def test_parsefactories_evil_objects_issue214(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            class A(object):\n                def __call__(self):\n                    pass\n                def __getattr__(self, name):\n                    raise RuntimeError()\n            a = A()\n            def test_hello():\n                pass\n        \"\"\"\n        )\n        reprec = pytester.inline_run()\n        reprec.assertoutcome(passed=1, failed=0)\n\n    def test_parsefactories_conftest(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            def test_hello(item, fm):\n                for name in (\"fm\", \"hello\", \"item\"):\n                    faclist = fm.getfixturedefs(name, item)\n                    assert len(faclist) == 1\n                    fac = faclist[0]\n                    assert fac.func.__name__ == name\n        \"\"\"\n        )\n        reprec = pytester.inline_run(\"-s\")\n        reprec.assertoutcome(passed=1)\n\n    def test_parsefactories_conftest_and_module_and_class(\n        self, pytester: Pytester\n    ) -> None:\n        pytester.makepyfile(\n            \"\"\"\\\n            import pytest\n\n            @pytest.fixture\n            def hello(request):\n                return \"module\"\n            class TestClass(object):\n                @pytest.fixture\n                def hello(self, request):\n                    return \"class\"\n                def test_hello(self, item, fm):\n                    faclist = fm.getfixturedefs(\"hello\", item)\n                    print(faclist)\n                    assert len(faclist) == 3\n\n                    assert faclist[0].func(item._request) == \"conftest\"\n                    assert faclist[1].func(item._request) == \"module\"\n                    assert faclist[2].func(item._request"}, {"start_line": 32000, "end_line": 34000, "belongs_to": {"file_name": "fixtures.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing/python", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "value_dynamic.py\")\n        result = pytester.runpytest()\n        result.stdout.fnmatch_lines([\"*1 passed*\"])\n\n    def test_setupdecorator_and_xunit(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n            values = []\n            @pytest.fixture(scope='module', autouse=True)\n            def setup_module():\n                values.append(\"module\")\n            @pytest.fixture(autouse=True)\n            def setup_function():\n                values.append(\"function\")\n\n            def test_func():\n                pass\n\n            class TestClass(object):\n                @pytest.fixture(scope=\"class\", autouse=True)\n                def setup_class(self):\n                    values.append(\"class\")\n                @pytest.fixture(autouse=True)\n                def setup_method(self):\n                    values.append(\"method\")\n                def test_method(self):\n                    pass\n            def test_all():\n                assert values == [\"module\", \"function\", \"class\",\n                             \"function\", \"method\", \"function\"]\n        \"\"\"\n        )\n        reprec = pytester.inline_run(\"-v\")\n        reprec.assertoutcome(passed=3)\n\n    def test_fixtures_sub_subdir_normalize_sep(self, pytester: Pytester) -> None:\n        # this tests that normalization of nodeids takes place\n        b = pytester.path.joinpath(\"tests\", \"unit\")\n        b.mkdir(parents=True)\n        b.joinpath(\"conftest.py\").write_text(\n            textwrap.dedent(\n                \"\"\"\\\n                import pytest\n                @pytest.fixture\n                def arg1():\n                    pass\n                \"\"\"\n            ),\n            encoding=\"utf-8\",\n        )\n        p = b.joinpath(\"test_module.py\")\n        p.write_text(\"def test_func(arg1): pass\", encoding=\"utf-8\")\n        result = pytester.runpytest(p, \"--fixtures\")\n        assert result.ret == 0\n        result.stdout.fnmatch_lines(\n            \"\"\"\n            *fixtures define"}, {"start_line": 53000, "end_line": 55000, "belongs_to": {"file_name": "fixtures.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing/python", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "                 fac = faclist[0]\n                    assert fac.func.__name__ == name\n        \"\"\"\n        )\n        reprec = pytester.inline_run(\"-s\")\n        reprec.assertoutcome(passed=1)\n\n    def test_parsefactories_conftest_and_module_and_class(\n        self, pytester: Pytester\n    ) -> None:\n        pytester.makepyfile(\n            \"\"\"\\\n            import pytest\n\n            @pytest.fixture\n            def hello(request):\n                return \"module\"\n            class TestClass(object):\n                @pytest.fixture\n                def hello(self, request):\n                    return \"class\"\n                def test_hello(self, item, fm):\n                    faclist = fm.getfixturedefs(\"hello\", item)\n                    print(faclist)\n                    assert len(faclist) == 3\n\n                    assert faclist[0].func(item._request) == \"conftest\"\n                    assert faclist[1].func(item._request) == \"module\"\n                    assert faclist[2].func(item._request) == \"class\"\n            \"\"\"\n        )\n        reprec = pytester.inline_run(\"-s\")\n        reprec.assertoutcome(passed=1)\n\n    def test_parsefactories_relative_node_ids(\n        self, pytester: Pytester, monkeypatch: MonkeyPatch\n    ) -> None:\n        # example mostly taken from:\n        # https://mail.python.org/pipermail/pytest-dev/2014-September/002617.html\n        runner = pytester.mkdir(\"runner\")\n        package = pytester.mkdir(\"package\")\n        package.joinpath(\"conftest.py\").write_text(\n            textwrap.dedent(\n                \"\"\"\\\n            import pytest\n            @pytest.fixture\n            def one():\n                return 1\n            \"\"\"\n            ),\n            encoding=\"utf-8\",\n        )\n        package.joinpath(\"test_x.py\").write_text(\n            textwrap.dedent(\n                \"\"\"\\\n                def test_x(one):\n                    assert one == 1\n                \"\"\"\n            ),\n            encoding=\"utf-8\",\n        )\n        sub = package.joinpath(\"s"}, {"start_line": 33000, "end_line": 35000, "belongs_to": {"file_name": "fixtures.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing/python", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "rt values == [\"module\", \"function\", \"class\",\n                             \"function\", \"method\", \"function\"]\n        \"\"\"\n        )\n        reprec = pytester.inline_run(\"-v\")\n        reprec.assertoutcome(passed=3)\n\n    def test_fixtures_sub_subdir_normalize_sep(self, pytester: Pytester) -> None:\n        # this tests that normalization of nodeids takes place\n        b = pytester.path.joinpath(\"tests\", \"unit\")\n        b.mkdir(parents=True)\n        b.joinpath(\"conftest.py\").write_text(\n            textwrap.dedent(\n                \"\"\"\\\n                import pytest\n                @pytest.fixture\n                def arg1():\n                    pass\n                \"\"\"\n            ),\n            encoding=\"utf-8\",\n        )\n        p = b.joinpath(\"test_module.py\")\n        p.write_text(\"def test_func(arg1): pass\", encoding=\"utf-8\")\n        result = pytester.runpytest(p, \"--fixtures\")\n        assert result.ret == 0\n        result.stdout.fnmatch_lines(\n            \"\"\"\n            *fixtures defined*conftest*\n            *arg1*\n        \"\"\"\n        )\n\n    def test_show_fixtures_color_yes(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\"def test_this(): assert 1\")\n        result = pytester.runpytest(\"--color=yes\", \"--fixtures\")\n        assert \"\\x1b[32mtmp_path\" in result.stdout.str()\n\n    def test_newstyle_with_request(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n            @pytest.fixture()\n            def arg(request):\n                pass\n            def test_1(arg):\n                pass\n        \"\"\"\n        )\n        reprec = pytester.inline_run()\n        reprec.assertoutcome(passed=1)\n\n    def test_setupcontext_no_param(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n            @pytest.fixture(params=[1,2])\n            def arg(request):\n                return request.param\n\n            @pytest.fixture(autouse=True)\n            def mysetup(requ"}, {"start_line": 134000, "end_line": 136000, "belongs_to": {"file_name": "fixtures.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing/python", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "    import pytest\n\n            @pytest.fixture(scope='session')\n            def s1(): pass\n\n            @pytest.fixture(scope='module')\n            def m1(): pass\n\n            @pytest.fixture(scope='function')\n            def f1(): pass\n\n            @pytest.fixture(scope='function')\n            def f2(): pass\n\n            class Test:\n\n                @pytest.fixture(scope='class')\n                def c1(cls): pass\n\n                def test_func(self, f2, f1, c1, m1, s1):\n                    pass\n        \"\"\"\n        )\n        items, _ = pytester.inline_genitems()\n        assert isinstance(items[0], Function)\n        request = TopRequest(items[0], _ispytest=True)\n        assert request.fixturenames == \"s1 m1 c1 f2 f1\".split()\n\n    def test_func_closure_same_scope_closer_root_first(\n        self, pytester: Pytester\n    ) -> None:\n        \"\"\"Auto-use fixtures of same scope are ordered by closer-to-root first\"\"\"\n        pytester.makeconftest(\n            \"\"\"\n            import pytest\n\n            @pytest.fixture(scope='module', autouse=True)\n            def m_conf(): pass\n        \"\"\"\n        )\n        pytester.makepyfile(\n            **{\n                \"sub/conftest.py\": \"\"\"\n                import pytest\n\n                @pytest.fixture(scope='package', autouse=True)\n                def p_sub(): pass\n\n                @pytest.fixture(scope='module', autouse=True)\n                def m_sub(): pass\n            \"\"\",\n                \"sub/__init__.py\": \"\",\n                \"sub/test_func.py\": \"\"\"\n                import pytest\n\n                @pytest.fixture(scope='module', autouse=True)\n                def m_test(): pass\n\n                @pytest.fixture(scope='function')\n                def f1(): pass\n\n                def test_func(m_test, f1):\n                    pass\n        \"\"\",\n            }\n        )\n        items, _ = pytester.inline_genitems()\n        assert isinstance(items[0], Function)\n        request = TopRequest(items[0], _ispytest=True)\n        assert request.fix"}, {"start_line": 18000, "end_line": 20000, "belongs_to": {"file_name": "fixtures.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing/python", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "\n                assert request.function.foo == 7\n        \"\"\"\n        )\n        result = pytester.runpytest()\n        assert result.ret == 0\n\n    def test_funcarg_lookup_error(self, pytester: Pytester) -> None:\n        pytester.makeconftest(\n            \"\"\"\n            import pytest\n\n            @pytest.fixture\n            def a_fixture(): pass\n\n            @pytest.fixture\n            def b_fixture(): pass\n\n            @pytest.fixture\n            def c_fixture(): pass\n\n            @pytest.fixture\n            def d_fixture(): pass\n        \"\"\"\n        )\n        pytester.makepyfile(\n            \"\"\"\n            def test_lookup_error(unknown):\n                pass\n        \"\"\"\n        )\n        result = pytester.runpytest()\n        result.stdout.fnmatch_lines(\n            [\n                \"*ERROR at setup of test_lookup_error*\",\n                \"  def test_lookup_error(unknown):*\",\n                \"E       fixture 'unknown' not found\",\n                \">       available fixtures:*a_fixture,*b_fixture,*c_fixture,*d_fixture*monkeypatch,*\",\n                # sorted\n                \">       use 'py*test --fixtures *' for help on them.\",\n                \"*1 error*\",\n            ]\n        )\n        result.stdout.no_fnmatch_line(\"*INTERNAL*\")\n\n    def test_fixture_excinfo_leak(self, pytester: Pytester) -> None:\n        # on python2 sys.excinfo would leak into fixture executions\n        pytester.makepyfile(\n            \"\"\"\n            import sys\n            import traceback\n            import pytest\n\n            @pytest.fixture\n            def leak():\n                if sys.exc_info()[0]:  # python3 bug :)\n                    traceback.print_exc()\n                #fails\n                assert sys.exc_info() == (None, None, None)\n\n            def test_leak(leak):\n                if sys.exc_info()[0]:  # python3 bug :)\n                    traceback.print_exc()\n                assert sys.exc_info() == (None, None, None)\n        \"\"\"\n        )\n        result = pytester.runpytest()\n  "}], "retrieved_count": 10, "cost_time": 1.2622802257537842}
{"question": "Where does Pytest's test execution flow from test discovery through fixture setup to test execution and teardown?", "answer": null, "relative_code_list": null, "ground_truth": "Pytest's test execution flow follows a structured sequence from test discovery through fixture setup to test execution and teardown: 1) Test discovery phase begins with Session.perform_collect() which scans filesystem paths and identifies test files, modules, classes, and functions, 2) Collection phase uses the collector hierarchy (Session -> Directory -> Package -> Module -> Class -> Function) to build a tree of test items, 3) Fixture discovery occurs during collection where pytest identifies fixtures used by each test through FixtureManager.parsefactories(), 4) Fixture dependency analysis determines the order of fixture execution based on scope hierarchy and dependency relationships, 5) Test execution phase starts with pytest_runtestloop hook which iterates through collected test items, 6) For each test, pytest_runtest_protocol hook orchestrates the three-phase execution: setup, call, and teardown, 7) Setup phase (pytest_runtest_setup) resolves and executes fixtures in dependency order, with higher-scoped fixtures executed first, 8) Call phase (pytest_runtest_call) executes the actual test function with resolved fixture values injected as parameters, 9) Teardown phase (pytest_runtest_teardown) executes fixture finalizers and cleanup operations in reverse order, 10) Fixture execution follows scope-based caching where fixtures are created once per scope and reused across tests, 11) Test results are collected through TestReport objects and passed to reporting hooks for output generation, 12) The entire flow is coordinated through the hook system, allowing plugins to intercept and modify behavior at each phase.", "score": null, "retrieved_content": [{"start_line": 69000, "end_line": 71000, "belongs_to": {"file_name": "fixtures.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing/python", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "ter.makepyfile(\n            \"\"\"\n            import pytest\n\n            class TestClass(object):\n                def test_1(self):\n                    pass\n            class TestClass2(object):\n                def test_2(self):\n                    pass\n        \"\"\"\n        )\n        reprec = pytester.inline_run(\"-v\", \"-s\", \"--confcutdir\", pytester.path)\n        reprec.assertoutcome(passed=8)\n        config = reprec.getcalls(\"pytest_unconfigure\")[0].config\n        values = config.pluginmanager._getconftestmodules(p)[0].values\n        assert values == [\"fin_a1\", \"fin_a2\", \"fin_b1\", \"fin_b2\"] * 2\n\n    def test_scope_ordering(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n            values = []\n            @pytest.fixture(scope=\"function\", autouse=True)\n            def fappend2():\n                values.append(2)\n            @pytest.fixture(scope=\"class\", autouse=True)\n            def classappend3():\n                values.append(3)\n            @pytest.fixture(scope=\"module\", autouse=True)\n            def mappend():\n                values.append(1)\n\n            class TestHallo(object):\n                def test_method(self):\n                    assert values == [1,3,2]\n        \"\"\"\n        )\n        reprec = pytester.inline_run()\n        reprec.assertoutcome(passed=1)\n\n    def test_parametrization_setup_teardown_ordering(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n            values = []\n            def pytest_generate_tests(metafunc):\n                if metafunc.cls is None:\n                    assert metafunc.function is test_finish\n                if metafunc.cls is not None:\n                    metafunc.parametrize(\"item\", [1,2], scope=\"class\")\n            class TestClass(object):\n                @pytest.fixture(scope=\"class\", autouse=True)\n                def addteardown(self, item, request):\n                    values.append(\"setup-%d\" % item)\n    "}, {"start_line": 4000, "end_line": 6000, "belongs_to": {"file_name": "runner.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "ailures.\n        item._initrequest()  # type: ignore[attr-defined]\n    rep = call_and_report(item, \"setup\", log)\n    reports = [rep]\n    if rep.passed:\n        if item.config.getoption(\"setupshow\", False):\n            show_test_item(item)\n        if not item.config.getoption(\"setuponly\", False):\n            reports.append(call_and_report(item, \"call\", log))\n    # If the session is about to fail or stop, teardown everything - this is\n    # necessary to correctly report fixture teardown errors (see #11706)\n    if item.session.shouldfail or item.session.shouldstop:\n        nextitem = None\n    reports.append(call_and_report(item, \"teardown\", log, nextitem=nextitem))\n    # After all teardown hooks have been called\n    # want funcargs and request info to go away.\n    if hasrequest:\n        item._request = False  # type: ignore[attr-defined]\n        item.funcargs = None  # type: ignore[attr-defined]\n    return reports\n\n\ndef show_test_item(item: Item) -> None:\n    \"\"\"Show test function, parameters and the fixtures of the test item.\"\"\"\n    tw = item.config.get_terminal_writer()\n    tw.line()\n    tw.write(\" \" * 8)\n    tw.write(item.nodeid)\n    used_fixtures = sorted(getattr(item, \"fixturenames\", []))\n    if used_fixtures:\n        tw.write(\" (fixtures used: {})\".format(\", \".join(used_fixtures)))\n    tw.flush()\n\n\ndef pytest_runtest_setup(item: Item) -> None:\n    _update_current_test_var(item, \"setup\")\n    item.session._setupstate.setup(item)\n\n\ndef pytest_runtest_call(item: Item) -> None:\n    _update_current_test_var(item, \"call\")\n    try:\n        del sys.last_type\n        del sys.last_value\n        del sys.last_traceback\n        if sys.version_info >= (3, 12, 0):\n            del sys.last_exc  # type:ignore[attr-defined]\n    except AttributeError:\n        pass\n    try:\n        item.runtest()\n    except Exception as e:\n        # Store trace info to allow postmortem debugging\n        sys.last_type = type(e)\n        sys.last_value = e\n        if sys.version_info >= (3, 12, 0):\n    "}, {"start_line": 33000, "end_line": 35000, "belongs_to": {"file_name": "fixtures.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing/python", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "rt values == [\"module\", \"function\", \"class\",\n                             \"function\", \"method\", \"function\"]\n        \"\"\"\n        )\n        reprec = pytester.inline_run(\"-v\")\n        reprec.assertoutcome(passed=3)\n\n    def test_fixtures_sub_subdir_normalize_sep(self, pytester: Pytester) -> None:\n        # this tests that normalization of nodeids takes place\n        b = pytester.path.joinpath(\"tests\", \"unit\")\n        b.mkdir(parents=True)\n        b.joinpath(\"conftest.py\").write_text(\n            textwrap.dedent(\n                \"\"\"\\\n                import pytest\n                @pytest.fixture\n                def arg1():\n                    pass\n                \"\"\"\n            ),\n            encoding=\"utf-8\",\n        )\n        p = b.joinpath(\"test_module.py\")\n        p.write_text(\"def test_func(arg1): pass\", encoding=\"utf-8\")\n        result = pytester.runpytest(p, \"--fixtures\")\n        assert result.ret == 0\n        result.stdout.fnmatch_lines(\n            \"\"\"\n            *fixtures defined*conftest*\n            *arg1*\n        \"\"\"\n        )\n\n    def test_show_fixtures_color_yes(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\"def test_this(): assert 1\")\n        result = pytester.runpytest(\"--color=yes\", \"--fixtures\")\n        assert \"\\x1b[32mtmp_path\" in result.stdout.str()\n\n    def test_newstyle_with_request(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n            @pytest.fixture()\n            def arg(request):\n                pass\n            def test_1(arg):\n                pass\n        \"\"\"\n        )\n        reprec = pytester.inline_run()\n        reprec.assertoutcome(passed=1)\n\n    def test_setupcontext_no_param(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n            @pytest.fixture(params=[1,2])\n            def arg(request):\n                return request.param\n\n            @pytest.fixture(autouse=True)\n            def mysetup(requ"}, {"start_line": 5000, "end_line": 7000, "belongs_to": {"file_name": "test_setuponly.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": ", 'bar'], ids=lambda p: p.upper())\n        def foobar():\n            pass\n        def test_foobar(foobar):\n            pass\n    \"\"\"\n    )\n\n    result = pytester.runpytest(mode, p)\n    assert result.ret == 0\n\n    result.stdout.fnmatch_lines(\n        [\"*SETUP    F foobar?'FOO'?\", \"*SETUP    F foobar?'BAR'?\"]\n    )\n\n\ndef test_dynamic_fixture_request(pytester: Pytester) -> None:\n    p = pytester.makepyfile(\n        \"\"\"\n        import pytest\n        @pytest.fixture()\n        def dynamically_requested_fixture():\n            pass\n        @pytest.fixture()\n        def dependent_fixture(request):\n            request.getfixturevalue('dynamically_requested_fixture')\n        def test_dyn(dependent_fixture):\n            pass\n    \"\"\"\n    )\n\n    result = pytester.runpytest(\"--setup-only\", p)\n    assert result.ret == 0\n\n    result.stdout.fnmatch_lines(\n        [\n            \"*SETUP    F dynamically_requested_fixture\",\n            \"*TEARDOWN F dynamically_requested_fixture\",\n        ]\n    )\n\n\ndef test_capturing(pytester: Pytester) -> None:\n    p = pytester.makepyfile(\n        \"\"\"\n        import pytest, sys\n        @pytest.fixture()\n        def one():\n            sys.stdout.write('this should be captured')\n            sys.stderr.write('this should also be captured')\n        @pytest.fixture()\n        def two(one):\n            assert 0\n        def test_capturing(two):\n            pass\n    \"\"\"\n    )\n\n    result = pytester.runpytest(\"--setup-only\", p)\n    result.stdout.fnmatch_lines(\n        [\"this should be captured\", \"this should also be captured\"]\n    )\n\n\ndef test_show_fixtures_and_execute_test(pytester: Pytester) -> None:\n    \"\"\"Verify that setups are shown and tests are executed.\"\"\"\n    p = pytester.makepyfile(\n        \"\"\"\n        import pytest\n        @pytest.fixture\n        def arg():\n            assert True\n        def test_arg(arg):\n            assert False\n    \"\"\"\n    )\n\n    result = pytester.runpytest(\"--setup-show\", p)\n    assert result.ret == 1\n\n    result.stdout.fnmatch_lin"}, {"start_line": 1000, "end_line": 3000, "belongs_to": {"file_name": "test_setuponly.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "er.makepyfile(\n        '''\n        import pytest\n        @pytest.fixture\n        def arg_function():\n            \"\"\"function scoped fixture\"\"\"\n        @pytest.fixture(scope='session')\n        def arg_session():\n            \"\"\"session scoped fixture\"\"\"\n        def test_arg1(arg_session, arg_function):\n            pass\n    '''\n    )\n\n    result = pytester.runpytest(mode, p)\n    assert result.ret == 0\n\n    result.stdout.fnmatch_lines(\n        [\n            \"SETUP    S arg_session*\",\n            \"*SETUP    F arg_function*\",\n            \"*test_arg1 (fixtures used: arg_function, arg_session)*\",\n            \"*TEARDOWN F arg_function*\",\n            \"TEARDOWN S arg_session*\",\n        ]\n    )\n\n\ndef test_show_nested_fixtures(pytester: Pytester, mode) -> None:\n    pytester.makeconftest(\n        '''\n        import pytest\n        @pytest.fixture(scope='session')\n        def arg_same():\n            \"\"\"session scoped fixture\"\"\"\n        '''\n    )\n    p = pytester.makepyfile(\n        '''\n        import pytest\n        @pytest.fixture(scope='function')\n        def arg_same(arg_same):\n            \"\"\"function scoped fixture\"\"\"\n        def test_arg1(arg_same):\n            pass\n    '''\n    )\n\n    result = pytester.runpytest(mode, p)\n    assert result.ret == 0\n\n    result.stdout.fnmatch_lines(\n        [\n            \"SETUP    S arg_same*\",\n            \"*SETUP    F arg_same (fixtures used: arg_same)*\",\n            \"*test_arg1 (fixtures used: arg_same)*\",\n            \"*TEARDOWN F arg_same*\",\n            \"TEARDOWN S arg_same*\",\n        ]\n    )\n\n\ndef test_show_fixtures_with_autouse(pytester: Pytester, mode) -> None:\n    p = pytester.makepyfile(\n        '''\n        import pytest\n        @pytest.fixture\n        def arg_function():\n            \"\"\"function scoped fixture\"\"\"\n        @pytest.fixture(scope='session', autouse=True)\n        def arg_session():\n            \"\"\"session scoped fixture\"\"\"\n        def test_arg1(arg_function):\n            pass\n    '''\n    )\n\n    result = pytester.runpytest(mode,"}, {"start_line": 0, "end_line": 2000, "belongs_to": {"file_name": "test_setuponly.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "# mypy: allow-untyped-defs\nfrom __future__ import annotations\n\nimport sys\n\nfrom _pytest.config import ExitCode\nfrom _pytest.pytester import Pytester\nimport pytest\n\n\n@pytest.fixture(params=[\"--setup-only\", \"--setup-plan\", \"--setup-show\"], scope=\"module\")\ndef mode(request):\n    return request.param\n\n\ndef test_show_only_active_fixtures(\n    pytester: Pytester, mode, dummy_yaml_custom_test\n) -> None:\n    pytester.makepyfile(\n        '''\n        import pytest\n        @pytest.fixture\n        def _arg0():\n            \"\"\"hidden arg0 fixture\"\"\"\n        @pytest.fixture\n        def arg1():\n            \"\"\"arg1 docstring\"\"\"\n        def test_arg1(arg1):\n            pass\n    '''\n    )\n\n    result = pytester.runpytest(mode)\n    assert result.ret == 0\n\n    result.stdout.fnmatch_lines(\n        [\"*SETUP    F arg1*\", \"*test_arg1 (fixtures used: arg1)*\", \"*TEARDOWN F arg1*\"]\n    )\n    result.stdout.no_fnmatch_line(\"*_arg0*\")\n\n\ndef test_show_different_scopes(pytester: Pytester, mode) -> None:\n    p = pytester.makepyfile(\n        '''\n        import pytest\n        @pytest.fixture\n        def arg_function():\n            \"\"\"function scoped fixture\"\"\"\n        @pytest.fixture(scope='session')\n        def arg_session():\n            \"\"\"session scoped fixture\"\"\"\n        def test_arg1(arg_session, arg_function):\n            pass\n    '''\n    )\n\n    result = pytester.runpytest(mode, p)\n    assert result.ret == 0\n\n    result.stdout.fnmatch_lines(\n        [\n            \"SETUP    S arg_session*\",\n            \"*SETUP    F arg_function*\",\n            \"*test_arg1 (fixtures used: arg_function, arg_session)*\",\n            \"*TEARDOWN F arg_function*\",\n            \"TEARDOWN S arg_session*\",\n        ]\n    )\n\n\ndef test_show_nested_fixtures(pytester: Pytester, mode) -> None:\n    pytester.makeconftest(\n        '''\n        import pytest\n        @pytest.fixture(scope='session')\n        def arg_same():\n            \"\"\"session scoped fixture\"\"\"\n        '''\n    )\n    p = pytester.makepyfile(\n        '''\n        import "}, {"start_line": 34000, "end_line": 36000, "belongs_to": {"file_name": "collect.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing/python", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "_sub1\"\n            def pytest_runtest_call(item):\n                assert item.path.stem == \"test_in_sub1\"\n            def pytest_runtest_teardown(item):\n                assert item.path.stem == \"test_in_sub1\"\n            \"\"\"\n        ),\n        encoding=\"utf-8\",\n    )\n    sub2.joinpath(\"conftest.py\").write_text(\n        textwrap.dedent(\n            \"\"\"\\\n            import pytest\n            def pytest_runtest_setup(item):\n                assert item.path.stem == \"test_in_sub2\"\n            def pytest_runtest_call(item):\n                assert item.path.stem == \"test_in_sub2\"\n            def pytest_runtest_teardown(item):\n                assert item.path.stem == \"test_in_sub2\"\n            \"\"\"\n        ),\n        encoding=\"utf-8\",\n    )\n    sub1.joinpath(\"test_in_sub1.py\").write_text(\"def test_1(): pass\", encoding=\"utf-8\")\n    sub2.joinpath(\"test_in_sub2.py\").write_text(\"def test_2(): pass\", encoding=\"utf-8\")\n    result = pytester.runpytest(\"-v\", \"-s\")\n    result.assert_outcomes(passed=2)\n\n\ndef test_modulecol_roundtrip(pytester: Pytester) -> None:\n    modcol = pytester.getmodulecol(\"pass\", withinit=False)\n    trail = modcol.nodeid\n    newcol = modcol.session.perform_collect([trail], genitems=0)[0]\n    assert modcol.name == newcol.name\n\n\nclass TestTracebackCutting:\n    def test_skip_simple(self):\n        with pytest.raises(pytest.skip.Exception) as excinfo:\n            pytest.skip(\"xxx\")\n        if sys.version_info >= (3, 11):\n            assert excinfo.traceback[-1].frame.code.raw.co_qualname == \"_Skip.__call__\"\n        assert excinfo.traceback[-1].ishidden(excinfo)\n        assert excinfo.traceback[-2].frame.code.name == \"test_skip_simple\"\n        assert not excinfo.traceback[-2].ishidden(excinfo)\n\n    def test_traceback_argsetup(self, pytester: Pytester) -> None:\n        pytester.makeconftest(\n            \"\"\"\n            import pytest\n\n            @pytest.fixture\n            def hello(request):\n                raise ValueError(\"xyz\")\n        \"\"\"\n        )\n        p = py"}, {"start_line": 3000, "end_line": 5000, "belongs_to": {"file_name": "runner.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "v to show these durations.\"\n            message += \")\"\n            tr.write_line(message)\n            break\n        tr.write_line(f\"{rep.duration:02.2f}s {rep.when:<8} {rep.nodeid}\")\n\n\ndef pytest_sessionstart(session: Session) -> None:\n    session._setupstate = SetupState()\n\n\ndef pytest_sessionfinish(session: Session) -> None:\n    session._setupstate.teardown_exact(None)\n\n\ndef pytest_runtest_protocol(item: Item, nextitem: Item | None) -> bool:\n    ihook = item.ihook\n    ihook.pytest_runtest_logstart(nodeid=item.nodeid, location=item.location)\n    runtestprotocol(item, nextitem=nextitem)\n    ihook.pytest_runtest_logfinish(nodeid=item.nodeid, location=item.location)\n    return True\n\n\ndef runtestprotocol(\n    item: Item, log: bool = True, nextitem: Item | None = None\n) -> list[TestReport]:\n    hasrequest = hasattr(item, \"_request\")\n    if hasrequest and not item._request:  # type: ignore[attr-defined]\n        # This only happens if the item is re-run, as is done by\n        # pytest-rerunfailures.\n        item._initrequest()  # type: ignore[attr-defined]\n    rep = call_and_report(item, \"setup\", log)\n    reports = [rep]\n    if rep.passed:\n        if item.config.getoption(\"setupshow\", False):\n            show_test_item(item)\n        if not item.config.getoption(\"setuponly\", False):\n            reports.append(call_and_report(item, \"call\", log))\n    # If the session is about to fail or stop, teardown everything - this is\n    # necessary to correctly report fixture teardown errors (see #11706)\n    if item.session.shouldfail or item.session.shouldstop:\n        nextitem = None\n    reports.append(call_and_report(item, \"teardown\", log, nextitem=nextitem))\n    # After all teardown hooks have been called\n    # want funcargs and request info to go away.\n    if hasrequest:\n        item._request = False  # type: ignore[attr-defined]\n        item.funcargs = None  # type: ignore[attr-defined]\n    return reports\n\n\ndef show_test_item(item: Item) -> None:\n    \"\"\"Show test function, parame"}, {"start_line": 103000, "end_line": 105000, "belongs_to": {"file_name": "fixtures.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing/python", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "bda: values.append(\"fin%s\" % arg))\n                values.append(\"setup%s\" % arg)\n\n            values = []\n            def test_1(arg):\n                values.append(arg)\n            def test_2(arg):\n                values.append(arg)\n            def test_3():\n                import pprint\n                pprint.pprint(values)\n                if arg == 1:\n                    assert values == [\"setup1\", 1, 1, ]\n                elif arg == 2:\n                    assert values == [\"setup1\", 1, 1, \"fin1\",\n                                 \"setup2\", 2, 2, ]\n\n        \"\"\"\n        )\n        reprec = pytester.inline_run(\"-v\")\n        reprec.assertoutcome(passed=6)\n\n    def test_fixture_marked_function_not_collected_as_test(\n        self, pytester: Pytester\n    ) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n            @pytest.fixture\n            def test_app():\n                return 1\n\n            def test_something(test_app):\n                assert test_app == 1\n        \"\"\"\n        )\n        reprec = pytester.inline_run()\n        reprec.assertoutcome(passed=1)\n\n    def test_params_and_ids(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n\n            @pytest.fixture(params=[object(), object()],\n                            ids=['alpha', 'beta'])\n            def fix(request):\n                return request.param\n\n            def test_foo(fix):\n                assert 1\n        \"\"\"\n        )\n        res = pytester.runpytest(\"-v\")\n        res.stdout.fnmatch_lines([\"*test_foo*alpha*\", \"*test_foo*beta*\"])\n\n    def test_params_and_ids_yieldfixture(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n\n            @pytest.fixture(params=[object(), object()], ids=['alpha', 'beta'])\n            def fix(request):\n                 yield request.param\n\n            def test_foo(fix):\n                assert 1\n        \"\"\"\n        )\n        res = pyte"}, {"start_line": 23000, "end_line": 25000, "belongs_to": {"file_name": "hookspec.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "nly conftest\n    files in the item's directory and its parent directories are consulted.\n    \"\"\"\n\n\ndef pytest_runtest_logfinish(\n    nodeid: str, location: tuple[str, int | None, str]\n) -> None:\n    \"\"\"Called at the end of running the runtest protocol for a single item.\n\n    See :hook:`pytest_runtest_protocol` for a description of the runtest protocol.\n\n    :param nodeid: Full node ID of the item.\n    :param location: A tuple of ``(filename, lineno, testname)``\n        where ``filename`` is a file path relative to ``config.rootpath``\n        and ``lineno`` is 0-based.\n\n    Use in conftest plugins\n    =======================\n\n    Any conftest file can implement this hook. For a given item, only conftest\n    files in the item's directory and its parent directories are consulted.\n    \"\"\"\n\n\ndef pytest_runtest_setup(item: Item) -> None:\n    \"\"\"Called to perform the setup phase for a test item.\n\n    The default implementation runs ``setup()`` on ``item`` and all of its\n    parents (which haven't been setup yet). This includes obtaining the\n    values of fixtures required by the item (which haven't been obtained\n    yet).\n\n    :param item:\n        The item.\n\n    Use in conftest plugins\n    =======================\n\n    Any conftest file can implement this hook. For a given item, only conftest\n    files in the item's directory and its parent directories are consulted.\n    \"\"\"\n\n\ndef pytest_runtest_call(item: Item) -> None:\n    \"\"\"Called to run the test for test item (the call phase).\n\n    The default implementation calls ``item.runtest()``.\n\n    :param item:\n        The item.\n\n    Use in conftest plugins\n    =======================\n\n    Any conftest file can implement this hook. For a given item, only conftest\n    files in the item's directory and its parent directories are consulted.\n    \"\"\"\n\n\ndef pytest_runtest_teardown(item: Item, nextitem: Item | None) -> None:\n    \"\"\"Called to perform the teardown phase for a test item.\n\n    The default implementation runs the finalizers"}], "retrieved_count": 10, "cost_time": 1.281297206878662}
{"question": "Where in Pytest's codebase is the \"pytest_configure\" hook defined?", "answer": null, "relative_code_list": null, "ground_truth": "The \"pytest_configure\" hook is defined in the pytest codebase in src/_pytest/hookspec.py at line 141. This hook specification is defined using the @hookspec decorator and serves as the initialization hook that allows plugins and conftest files to perform initial configuration. The hook is called for every initial conftest file after command line options have been parsed, and then called for other conftest files as they are registered. The hook signature takes a single parameter 'config' of type Config, which is the pytest config object. The hook is marked as historic=True, meaning it can be called multiple times during the test session lifecycle. The hook is incompatible with hook wrappers and is part of the initialization hooks category in pytest's hook system. The actual implementation of this hook is provided by various plugins and conftest files throughout the pytest ecosystem, with the hook system calling all registered implementations when the hook is invoked.", "score": null, "retrieved_content": [{"start_line": 4000, "end_line": 6000, "belongs_to": {"file_name": "hookspec.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "ption.\n\n    - :py:func:`config.getini(name) <pytest.Config.getini>` to retrieve\n      a value read from an ini-style file.\n\n    The config object is passed around on many internal objects via the ``.config``\n    attribute or can be retrieved as the ``pytestconfig`` fixture.\n\n    .. note::\n        This hook is incompatible with hook wrappers.\n\n    Use in conftest plugins\n    =======================\n\n    If a conftest plugin implements this hook, it will be called immediately\n    when the conftest is registered.\n\n    This hook is only called for :ref:`initial conftests <pluginorder>`.\n    \"\"\"\n\n\n@hookspec(historic=True)\ndef pytest_configure(config: Config) -> None:\n    \"\"\"Allow plugins and conftest files to perform initial configuration.\n\n    .. note::\n        This hook is incompatible with hook wrappers.\n\n    :param config: The pytest config object.\n\n    Use in conftest plugins\n    =======================\n\n    This hook is called for every :ref:`initial conftest <pluginorder>` file\n    after command line options have been parsed. After that, the hook is called\n    for other conftest files as they are registered.\n    \"\"\"\n\n\n# -------------------------------------------------------------------------\n# Bootstrapping hooks called for plugins registered early enough:\n# internal and 3rd party plugins.\n# -------------------------------------------------------------------------\n\n\n@hookspec(firstresult=True)\ndef pytest_cmdline_parse(\n    pluginmanager: PytestPluginManager, args: list[str]\n) -> Config | None:\n    \"\"\"Return an initialized :class:`~pytest.Config`, parsing the specified args.\n\n    Stops at first non-None result, see :ref:`firstresult`.\n\n    .. note::\n        This hook is only called for plugin classes passed to the\n        ``plugins`` arg when using `pytest.main`_ to perform an in-process\n        test run.\n\n    :param pluginmanager: The pytest plugin manager.\n    :param args: List of arguments passed on the command line.\n    :returns: A pytest config object.\n\n    U"}, {"start_line": 1000, "end_line": 3000, "belongs_to": {"file_name": "test_pluginmanager.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "newhooks)\n            def pytest_myhook(xyz):\n                return xyz + 1\n        \"\"\"\n        )\n        config = _config_for_test\n        pm = config.pluginmanager\n        pm.hook.pytest_addhooks.call_historic(\n            kwargs=dict(pluginmanager=config.pluginmanager)\n        )\n        config.pluginmanager._importconftest(\n            conf,\n            importmode=\"prepend\",\n            rootpath=pytester.path,\n            consider_namespace_packages=False,\n        )\n        # print(config.pluginmanager.get_plugins())\n        res = config.hook.pytest_myhook(xyz=10)\n        assert res == [11]\n\n    def test_addhooks_nohooks(self, pytester: Pytester) -> None:\n        pytester.makeconftest(\n            \"\"\"\n            import sys\n            def pytest_addhooks(pluginmanager):\n                pluginmanager.add_hookspecs(sys)\n        \"\"\"\n        )\n        res = pytester.runpytest()\n        assert res.ret != 0\n        res.stderr.fnmatch_lines([\"*did not find*sys*\"])\n\n    def test_do_option_postinitialize(self, pytester: Pytester) -> None:\n        config = pytester.parseconfigure()\n        assert not hasattr(config.option, \"test123\")\n        p = pytester.makepyfile(\n            \"\"\"\n            def pytest_addoption(parser):\n                parser.addoption('--test123', action=\"store_true\",\n                    default=True)\n        \"\"\"\n        )\n        config.pluginmanager._importconftest(\n            p,\n            importmode=\"prepend\",\n            rootpath=pytester.path,\n            consider_namespace_packages=False,\n        )\n        assert config.option.test123\n\n    def test_configure(self, pytester: Pytester) -> None:\n        config = pytester.parseconfig()\n        values = []\n\n        class A:\n            def pytest_configure(self):\n                values.append(self)\n\n        config.pluginmanager.register(A())\n        assert len(values) == 0\n        config._do_configure()\n        assert len(values) == 1\n        config.pluginmanager.register(A())  # leads to a confi"}, {"start_line": 3000, "end_line": 5000, "belongs_to": {"file_name": "hookspec.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "plugins thereafter when they are\n    registered.\n    \"\"\"\n\n\n@hookspec(historic=True)\ndef pytest_addoption(parser: Parser, pluginmanager: PytestPluginManager) -> None:\n    \"\"\"Register argparse-style options and ini-style config values,\n    called once at the beginning of a test run.\n\n    :param parser:\n        To add command line options, call\n        :py:func:`parser.addoption(...) <pytest.Parser.addoption>`.\n        To add ini-file values call :py:func:`parser.addini(...)\n        <pytest.Parser.addini>`.\n\n    :param pluginmanager:\n        The pytest plugin manager, which can be used to install :py:func:`~pytest.hookspec`'s\n        or :py:func:`~pytest.hookimpl`'s and allow one plugin to call another plugin's hooks\n        to change how command line options are added.\n\n    Options can later be accessed through the\n    :py:class:`config <pytest.Config>` object, respectively:\n\n    - :py:func:`config.getoption(name) <pytest.Config.getoption>` to\n      retrieve the value of a command line option.\n\n    - :py:func:`config.getini(name) <pytest.Config.getini>` to retrieve\n      a value read from an ini-style file.\n\n    The config object is passed around on many internal objects via the ``.config``\n    attribute or can be retrieved as the ``pytestconfig`` fixture.\n\n    .. note::\n        This hook is incompatible with hook wrappers.\n\n    Use in conftest plugins\n    =======================\n\n    If a conftest plugin implements this hook, it will be called immediately\n    when the conftest is registered.\n\n    This hook is only called for :ref:`initial conftests <pluginorder>`.\n    \"\"\"\n\n\n@hookspec(historic=True)\ndef pytest_configure(config: Config) -> None:\n    \"\"\"Allow plugins and conftest files to perform initial configuration.\n\n    .. note::\n        This hook is incompatible with hook wrappers.\n\n    :param config: The pytest config object.\n\n    Use in conftest plugins\n    =======================\n\n    This hook is called for every :ref:`initial conftest <pluginorder>` file\n    a"}, {"start_line": 36000, "end_line": 38000, "belongs_to": {"file_name": "__init__.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest/config", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": " and hook invocation.\n\n        :type: PytestPluginManager\n        \"\"\"\n\n        self.stash = Stash()\n        \"\"\"A place where plugins can store information on the config for their\n        own use.\n\n        :type: Stash\n        \"\"\"\n        # Deprecated alias. Was never public. Can be removed in a few releases.\n        self._store = self.stash\n\n        self.trace = self.pluginmanager.trace.root.get(\"config\")\n        self.hook: pluggy.HookRelay = PathAwareHookProxy(self.pluginmanager.hook)  # type: ignore[assignment]\n        self._inicache: dict[str, Any] = {}\n        self._override_ini: Sequence[str] = ()\n        self._opt2dest: dict[str, str] = {}\n        self._cleanup_stack = contextlib.ExitStack()\n        self.pluginmanager.register(self, \"pytestconfig\")\n        self._configured = False\n        self.hook.pytest_addoption.call_historic(\n            kwargs=dict(parser=self._parser, pluginmanager=self.pluginmanager)\n        )\n        self.args_source = Config.ArgsSource.ARGS\n        self.args: list[str] = []\n\n    @property\n    def rootpath(self) -> pathlib.Path:\n        \"\"\"The path to the :ref:`rootdir <rootdir>`.\n\n        :type: pathlib.Path\n\n        .. versionadded:: 6.1\n        \"\"\"\n        return self._rootpath\n\n    @property\n    def inipath(self) -> pathlib.Path | None:\n        \"\"\"The path to the :ref:`configfile <configfiles>`.\n\n        .. versionadded:: 6.1\n        \"\"\"\n        return self._inipath\n\n    def add_cleanup(self, func: Callable[[], None]) -> None:\n        \"\"\"Add a function to be called when the config object gets out of\n        use (usually coinciding with pytest_unconfigure).\n        \"\"\"\n        self._cleanup_stack.callback(func)\n\n    def _do_configure(self) -> None:\n        assert not self._configured\n        self._configured = True\n        self.hook.pytest_configure.call_historic(kwargs=dict(config=self))\n\n    def _ensure_unconfigure(self) -> None:\n        try:\n            if self._configured:\n                self._configured = False\n               "}, {"start_line": 16000, "end_line": 18000, "belongs_to": {"file_name": "__init__.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest/config", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "ict(\n                    plugin=plugin,\n                    plugin_name=plugin_name,\n                    manager=self,\n                )\n            )\n\n            if isinstance(plugin, types.ModuleType):\n                self.consider_module(plugin)\n        return plugin_name\n\n    def getplugin(self, name: str):\n        # Support deprecated naming because plugins (xdist e.g.) use it.\n        plugin: _PluggyPlugin | None = self.get_plugin(name)\n        return plugin\n\n    def hasplugin(self, name: str) -> bool:\n        \"\"\"Return whether a plugin with the given name is registered.\"\"\"\n        return bool(self.get_plugin(name))\n\n    def pytest_configure(self, config: Config) -> None:\n        \"\"\":meta private:\"\"\"\n        # XXX now that the pluginmanager exposes hookimpl(tryfirst...)\n        # we should remove tryfirst/trylast as markers.\n        config.addinivalue_line(\n            \"markers\",\n            \"tryfirst: mark a hook implementation function such that the \"\n            \"plugin machinery will try to call it first/as early as possible. \"\n            \"DEPRECATED, use @pytest.hookimpl(tryfirst=True) instead.\",\n        )\n        config.addinivalue_line(\n            \"markers\",\n            \"trylast: mark a hook implementation function such that the \"\n            \"plugin machinery will try to call it last/as late as possible. \"\n            \"DEPRECATED, use @pytest.hookimpl(trylast=True) instead.\",\n        )\n        self._configured = True\n\n    #\n    # Internal API for local conftest plugin handling.\n    #\n    def _set_initial_conftests(\n        self,\n        args: Sequence[str | pathlib.Path],\n        pyargs: bool,\n        noconftest: bool,\n        rootpath: pathlib.Path,\n        confcutdir: pathlib.Path | None,\n        invocation_dir: pathlib.Path,\n        importmode: ImportMode | str,\n        *,\n        consider_namespace_packages: bool,\n    ) -> None:\n        \"\"\"Load initial conftest files given a preparsed \"namespace\".\n\n        As conftest files may add their own com"}, {"start_line": 6000, "end_line": 8000, "belongs_to": {"file_name": "hookspec.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "se in conftest plugins\n    =======================\n\n    This hook is not called for conftest files.\n    \"\"\"\n\n\ndef pytest_load_initial_conftests(\n    early_config: Config, parser: Parser, args: list[str]\n) -> None:\n    \"\"\"Called to implement the loading of :ref:`initial conftest files\n    <pluginorder>` ahead of command line option parsing.\n\n    :param early_config: The pytest config object.\n    :param args: Arguments passed on the command line.\n    :param parser: To add command line options.\n\n    Use in conftest plugins\n    =======================\n\n    This hook is not called for conftest files.\n    \"\"\"\n\n\n@hookspec(firstresult=True)\ndef pytest_cmdline_main(config: Config) -> ExitCode | int | None:\n    \"\"\"Called for performing the main command line action.\n\n    The default implementation will invoke the configure hooks and\n    :hook:`pytest_runtestloop`.\n\n    Stops at first non-None result, see :ref:`firstresult`.\n\n    :param config: The pytest config object.\n    :returns: The exit code.\n\n    Use in conftest plugins\n    =======================\n\n    This hook is only called for :ref:`initial conftests <pluginorder>`.\n    \"\"\"\n\n\n# -------------------------------------------------------------------------\n# collection hooks\n# -------------------------------------------------------------------------\n\n\n@hookspec(firstresult=True)\ndef pytest_collection(session: Session) -> object | None:\n    \"\"\"Perform the collection phase for the given session.\n\n    Stops at first non-None result, see :ref:`firstresult`.\n    The return value is not used, but only stops further processing.\n\n    The default collection phase is this (see individual hooks for full details):\n\n    1. Starting from ``session`` as the initial collector:\n\n      1. ``pytest_collectstart(collector)``\n      2. ``report = pytest_make_collect_report(collector)``\n      3. ``pytest_exception_interact(collector, call, report)`` if an interactive exception occurred\n      4. For each collected node:\n\n        1. If an item, ``"}, {"start_line": 0, "end_line": 2000, "belongs_to": {"file_name": "hookspec.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "# mypy: allow-untyped-defs\n# ruff: noqa: T100\n\"\"\"Hook specifications for pytest plugins which are invoked by pytest itself\nand by builtin plugins.\"\"\"\n\nfrom __future__ import annotations\n\nfrom collections.abc import Mapping\nfrom collections.abc import Sequence\nfrom pathlib import Path\nfrom typing import Any\nfrom typing import TYPE_CHECKING\n\nfrom pluggy import HookspecMarker\n\nfrom .deprecated import HOOK_LEGACY_PATH_ARG\n\n\nif TYPE_CHECKING:\n    import pdb\n    from typing import Literal\n    import warnings\n\n    from _pytest._code.code import ExceptionInfo\n    from _pytest._code.code import ExceptionRepr\n    from _pytest.compat import LEGACY_PATH\n    from _pytest.config import _PluggyPlugin\n    from _pytest.config import Config\n    from _pytest.config import ExitCode\n    from _pytest.config import PytestPluginManager\n    from _pytest.config.argparsing import Parser\n    from _pytest.fixtures import FixtureDef\n    from _pytest.fixtures import SubRequest\n    from _pytest.main import Session\n    from _pytest.nodes import Collector\n    from _pytest.nodes import Item\n    from _pytest.outcomes import Exit\n    from _pytest.python import Class\n    from _pytest.python import Function\n    from _pytest.python import Metafunc\n    from _pytest.python import Module\n    from _pytest.reports import CollectReport\n    from _pytest.reports import TestReport\n    from _pytest.runner import CallInfo\n    from _pytest.terminal import TerminalReporter\n    from _pytest.terminal import TestShortLogReport\n\n\nhookspec = HookspecMarker(\"pytest\")\n\n# -------------------------------------------------------------------------\n# Initialization hooks called for every plugin\n# -------------------------------------------------------------------------\n\n\n@hookspec(historic=True)\ndef pytest_addhooks(pluginmanager: PytestPluginManager) -> None:\n    \"\"\"Called at plugin registration time to allow adding new hooks via a call to\n    :func:`pluginmanager.add_hookspecs(module_or_class, prefix) <pytest.PytestPluginManager"}, {"start_line": 6000, "end_line": 8000, "belongs_to": {"file_name": "test_pluginmanager.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "ests/conftest.py\")\n        conftest2 = pytester.path.joinpath(\"tests/subdir/conftest.py\")\n\n        config.pluginmanager._importconftest(\n            conftest1,\n            importmode=\"prepend\",\n            rootpath=pytester.path,\n            consider_namespace_packages=False,\n        )\n        ihook_a = session.gethookproxy(pytester.path / \"tests\")\n        assert ihook_a is not None\n        config.pluginmanager._importconftest(\n            conftest2,\n            importmode=\"prepend\",\n            rootpath=pytester.path,\n            consider_namespace_packages=False,\n        )\n        ihook_b = session.gethookproxy(pytester.path / \"tests\")\n        assert ihook_a is not ihook_b\n\n    def test_hook_with_addoption(self, pytester: Pytester) -> None:\n        \"\"\"Test that hooks can be used in a call to pytest_addoption\"\"\"\n        pytester.makepyfile(\n            newhooks=\"\"\"\n            import pytest\n            @pytest.hookspec(firstresult=True)\n            def pytest_default_value():\n                pass\n        \"\"\"\n        )\n        pytester.makepyfile(\n            myplugin=\"\"\"\n            import newhooks\n            def pytest_addhooks(pluginmanager):\n                pluginmanager.add_hookspecs(newhooks)\n            def pytest_addoption(parser, pluginmanager):\n                default_value = pluginmanager.hook.pytest_default_value()\n                parser.addoption(\"--config\", help=\"Config, defaults to %(default)s\", default=default_value)\n        \"\"\"\n        )\n        pytester.makeconftest(\n            \"\"\"\n            pytest_plugins=(\"myplugin\",)\n            def pytest_default_value():\n                return \"default_value\"\n        \"\"\"\n        )\n        res = pytester.runpytest(\"--help\")\n        res.stdout.fnmatch_lines([\"*--config=CONFIG*default_value*\"])\n\n\ndef test_default_markers(pytester: Pytester) -> None:\n    result = pytester.runpytest(\"--markers\")\n    result.stdout.fnmatch_lines([\"*tryfirst*first*\", \"*trylast*last*\"])\n\n\ndef test_importplugin_error_message(\n    py"}, {"start_line": 13000, "end_line": 15000, "belongs_to": {"file_name": "__init__.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest/config", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "gins: list[tuple[str, str]] = []\n\n        self.add_hookspecs(_pytest.hookspec)\n        self.register(self)\n        if os.environ.get(\"PYTEST_DEBUG\"):\n            err: IO[str] = sys.stderr\n            encoding: str = getattr(err, \"encoding\", \"utf8\")\n            try:\n                err = open(\n                    os.dup(err.fileno()),\n                    mode=err.mode,\n                    buffering=1,\n                    encoding=encoding,\n                )\n            except Exception:\n                pass\n            self.trace.root.setwriter(err.write)\n            self.enable_tracing()\n\n        # Config._consider_importhook will set a real object if required.\n        self.rewrite_hook: RewriteHook = DummyRewriteHook()\n        # Used to know when we are importing conftests after the pytest_configure stage.\n        self._configured = False\n\n    def parse_hookimpl_opts(\n        self, plugin: _PluggyPlugin, name: str\n    ) -> HookimplOpts | None:\n        \"\"\":meta private:\"\"\"\n        # pytest hooks are always prefixed with \"pytest_\",\n        # so we avoid accessing possibly non-readable attributes\n        # (see issue #1073).\n        if not name.startswith(\"pytest_\"):\n            return None\n        # Ignore names which cannot be hooks.\n        if name == \"pytest_plugins\":\n            return None\n\n        opts = super().parse_hookimpl_opts(plugin, name)\n        if opts is not None:\n            return opts\n\n        method = getattr(plugin, name)\n        # Consider only actual functions for hooks (#3775).\n        if not inspect.isroutine(method):\n            return None\n        # Collect unmarked hooks as long as they have the `pytest_' prefix.\n        legacy = _get_legacy_hook_marks(\n            method, \"impl\", (\"tryfirst\", \"trylast\", \"optionalhook\", \"hookwrapper\")\n        )\n        return cast(HookimplOpts, legacy)\n\n    def parse_hookspec_opts(self, module_or_class, name: str) -> HookspecOpts | None:\n        \"\"\":meta private:\"\"\"\n        opts = super().parse_hookspec_op"}, {"start_line": 1000, "end_line": 3000, "belongs_to": {"file_name": "hookspec.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "  from _pytest.nodes import Collector\n    from _pytest.nodes import Item\n    from _pytest.outcomes import Exit\n    from _pytest.python import Class\n    from _pytest.python import Function\n    from _pytest.python import Metafunc\n    from _pytest.python import Module\n    from _pytest.reports import CollectReport\n    from _pytest.reports import TestReport\n    from _pytest.runner import CallInfo\n    from _pytest.terminal import TerminalReporter\n    from _pytest.terminal import TestShortLogReport\n\n\nhookspec = HookspecMarker(\"pytest\")\n\n# -------------------------------------------------------------------------\n# Initialization hooks called for every plugin\n# -------------------------------------------------------------------------\n\n\n@hookspec(historic=True)\ndef pytest_addhooks(pluginmanager: PytestPluginManager) -> None:\n    \"\"\"Called at plugin registration time to allow adding new hooks via a call to\n    :func:`pluginmanager.add_hookspecs(module_or_class, prefix) <pytest.PytestPluginManager.add_hookspecs>`.\n\n    :param pluginmanager: The pytest plugin manager.\n\n    .. note::\n        This hook is incompatible with hook wrappers.\n\n    Use in conftest plugins\n    =======================\n\n    If a conftest plugin implements this hook, it will be called immediately\n    when the conftest is registered.\n    \"\"\"\n\n\n@hookspec(historic=True)\ndef pytest_plugin_registered(\n    plugin: _PluggyPlugin,\n    plugin_name: str,\n    manager: PytestPluginManager,\n) -> None:\n    \"\"\"A new pytest plugin got registered.\n\n    :param plugin: The plugin module or instance.\n    :param plugin_name: The name by which the plugin is registered.\n    :param manager: The pytest plugin manager.\n\n    .. note::\n        This hook is incompatible with hook wrappers.\n\n    Use in conftest plugins\n    =======================\n\n    If a conftest plugin implements this hook, it will be called immediately\n    when the conftest is registered, once for each plugin registered thus far\n    (including itself!), and for all "}], "retrieved_count": 10, "cost_time": 0.3238377571105957}
{"question": "Where is the \"pytest_runtest_setup\" hook defined in the plugin hierarchy?", "answer": null, "relative_code_list": null, "ground_truth": "The \"pytest_runtest_setup\" hook is defined in the plugin hierarchy in src/_pytest/hookspec.py at line 732. This hook specification is defined using the @hookspec decorator and serves as part of the test running (runtest) hooks category in pytest's hook system. The hook is called to perform the setup phase for a test item and is part of the three-phase test execution protocol (setup, call, teardown). The hook signature takes a single parameter 'item' of type Item, which represents the test item being set up. The default implementation runs setup() on the item and all of its parents that haven't been setup yet, including obtaining the values of fixtures required by the item. The hook can be implemented by any conftest plugin, and for a given item, only conftest files in the item's directory and its parent directories are consulted. The hook is part of the runtest protocol that includes pytest_runtest_logstart, pytest_runtest_setup, pytest_runtest_call, pytest_runtest_teardown, and pytest_runtest_logfinish hooks, all orchestrated by the pytest_runtest_protocol hook.", "score": null, "retrieved_content": [{"start_line": 22000, "end_line": 24000, "belongs_to": {"file_name": "hookspec.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "am item: Test item for which the runtest protocol is performed.\n    :param nextitem: The scheduled-to-be-next test item (or None if this is the end my friend).\n\n    Stops at first non-None result, see :ref:`firstresult`.\n    The return value is not used, but only stops further processing.\n\n    Use in conftest plugins\n    =======================\n\n    Any conftest file can implement this hook.\n    \"\"\"\n\n\ndef pytest_runtest_logstart(nodeid: str, location: tuple[str, int | None, str]) -> None:\n    \"\"\"Called at the start of running the runtest protocol for a single item.\n\n    See :hook:`pytest_runtest_protocol` for a description of the runtest protocol.\n\n    :param nodeid: Full node ID of the item.\n    :param location: A tuple of ``(filename, lineno, testname)``\n        where ``filename`` is a file path relative to ``config.rootpath``\n        and ``lineno`` is 0-based.\n\n    Use in conftest plugins\n    =======================\n\n    Any conftest file can implement this hook. For a given item, only conftest\n    files in the item's directory and its parent directories are consulted.\n    \"\"\"\n\n\ndef pytest_runtest_logfinish(\n    nodeid: str, location: tuple[str, int | None, str]\n) -> None:\n    \"\"\"Called at the end of running the runtest protocol for a single item.\n\n    See :hook:`pytest_runtest_protocol` for a description of the runtest protocol.\n\n    :param nodeid: Full node ID of the item.\n    :param location: A tuple of ``(filename, lineno, testname)``\n        where ``filename`` is a file path relative to ``config.rootpath``\n        and ``lineno`` is 0-based.\n\n    Use in conftest plugins\n    =======================\n\n    Any conftest file can implement this hook. For a given item, only conftest\n    files in the item's directory and its parent directories are consulted.\n    \"\"\"\n\n\ndef pytest_runtest_setup(item: Item) -> None:\n    \"\"\"Called to perform the setup phase for a test item.\n\n    The default implementation runs ``setup()`` on ``item`` and all of its\n    parents (which hav"}, {"start_line": 23000, "end_line": 25000, "belongs_to": {"file_name": "hookspec.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "nly conftest\n    files in the item's directory and its parent directories are consulted.\n    \"\"\"\n\n\ndef pytest_runtest_logfinish(\n    nodeid: str, location: tuple[str, int | None, str]\n) -> None:\n    \"\"\"Called at the end of running the runtest protocol for a single item.\n\n    See :hook:`pytest_runtest_protocol` for a description of the runtest protocol.\n\n    :param nodeid: Full node ID of the item.\n    :param location: A tuple of ``(filename, lineno, testname)``\n        where ``filename`` is a file path relative to ``config.rootpath``\n        and ``lineno`` is 0-based.\n\n    Use in conftest plugins\n    =======================\n\n    Any conftest file can implement this hook. For a given item, only conftest\n    files in the item's directory and its parent directories are consulted.\n    \"\"\"\n\n\ndef pytest_runtest_setup(item: Item) -> None:\n    \"\"\"Called to perform the setup phase for a test item.\n\n    The default implementation runs ``setup()`` on ``item`` and all of its\n    parents (which haven't been setup yet). This includes obtaining the\n    values of fixtures required by the item (which haven't been obtained\n    yet).\n\n    :param item:\n        The item.\n\n    Use in conftest plugins\n    =======================\n\n    Any conftest file can implement this hook. For a given item, only conftest\n    files in the item's directory and its parent directories are consulted.\n    \"\"\"\n\n\ndef pytest_runtest_call(item: Item) -> None:\n    \"\"\"Called to run the test for test item (the call phase).\n\n    The default implementation calls ``item.runtest()``.\n\n    :param item:\n        The item.\n\n    Use in conftest plugins\n    =======================\n\n    Any conftest file can implement this hook. For a given item, only conftest\n    files in the item's directory and its parent directories are consulted.\n    \"\"\"\n\n\ndef pytest_runtest_teardown(item: Item, nextitem: Item | None) -> None:\n    \"\"\"Called to perform the teardown phase for a test item.\n\n    The default implementation runs the finalizers"}, {"start_line": 21000, "end_line": 23000, "belongs_to": {"file_name": "hookspec.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "(wrapped in ``CallInfo(when=\"setup\")``)\n        - ``report = pytest_runtest_makereport(item, call)``\n        - ``pytest_runtest_logreport(report)``\n        - ``pytest_exception_interact(call, report)`` if an interactive exception occurred\n\n    - Call phase, if the setup passed and the ``setuponly`` pytest option is not set:\n        - ``call = pytest_runtest_call(item)`` (wrapped in ``CallInfo(when=\"call\")``)\n        - ``report = pytest_runtest_makereport(item, call)``\n        - ``pytest_runtest_logreport(report)``\n        - ``pytest_exception_interact(call, report)`` if an interactive exception occurred\n\n    - Teardown phase:\n        - ``call = pytest_runtest_teardown(item, nextitem)`` (wrapped in ``CallInfo(when=\"teardown\")``)\n        - ``report = pytest_runtest_makereport(item, call)``\n        - ``pytest_runtest_logreport(report)``\n        - ``pytest_exception_interact(call, report)`` if an interactive exception occurred\n\n    - ``pytest_runtest_logfinish(nodeid, location)``\n\n    :param item: Test item for which the runtest protocol is performed.\n    :param nextitem: The scheduled-to-be-next test item (or None if this is the end my friend).\n\n    Stops at first non-None result, see :ref:`firstresult`.\n    The return value is not used, but only stops further processing.\n\n    Use in conftest plugins\n    =======================\n\n    Any conftest file can implement this hook.\n    \"\"\"\n\n\ndef pytest_runtest_logstart(nodeid: str, location: tuple[str, int | None, str]) -> None:\n    \"\"\"Called at the start of running the runtest protocol for a single item.\n\n    See :hook:`pytest_runtest_protocol` for a description of the runtest protocol.\n\n    :param nodeid: Full node ID of the item.\n    :param location: A tuple of ``(filename, lineno, testname)``\n        where ``filename`` is a file path relative to ``config.rootpath``\n        and ``lineno`` is 0-based.\n\n    Use in conftest plugins\n    =======================\n\n    Any conftest file can implement this hook. For a given item, o"}, {"start_line": 24000, "end_line": 26000, "belongs_to": {"file_name": "hookspec.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "en't been setup yet). This includes obtaining the\n    values of fixtures required by the item (which haven't been obtained\n    yet).\n\n    :param item:\n        The item.\n\n    Use in conftest plugins\n    =======================\n\n    Any conftest file can implement this hook. For a given item, only conftest\n    files in the item's directory and its parent directories are consulted.\n    \"\"\"\n\n\ndef pytest_runtest_call(item: Item) -> None:\n    \"\"\"Called to run the test for test item (the call phase).\n\n    The default implementation calls ``item.runtest()``.\n\n    :param item:\n        The item.\n\n    Use in conftest plugins\n    =======================\n\n    Any conftest file can implement this hook. For a given item, only conftest\n    files in the item's directory and its parent directories are consulted.\n    \"\"\"\n\n\ndef pytest_runtest_teardown(item: Item, nextitem: Item | None) -> None:\n    \"\"\"Called to perform the teardown phase for a test item.\n\n    The default implementation runs the finalizers and calls ``teardown()``\n    on ``item`` and all of its parents (which need to be torn down). This\n    includes running the teardown phase of fixtures required by the item (if\n    they go out of scope).\n\n    :param item:\n        The item.\n    :param nextitem:\n        The scheduled-to-be-next test item (None if no further test item is\n        scheduled). This argument is used to perform exact teardowns, i.e.\n        calling just enough finalizers so that nextitem only needs to call\n        setup functions.\n\n    Use in conftest plugins\n    =======================\n\n    Any conftest file can implement this hook. For a given item, only conftest\n    files in the item's directory and its parent directories are consulted.\n    \"\"\"\n\n\n@hookspec(firstresult=True)\ndef pytest_runtest_makereport(item: Item, call: CallInfo[None]) -> TestReport | None:\n    \"\"\"Called to create a :class:`~pytest.TestReport` for each of\n    the setup, call and teardown runtest phases of a test item.\n\n    See :hook:`pytes"}, {"start_line": 20000, "end_line": 22000, "belongs_to": {"file_name": "hookspec.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": " the collection failed\n    or the ``collectonly`` pytest option is set.\n\n    If at any point :py:func:`pytest.exit` is called, the loop is\n    terminated immediately.\n\n    If at any point ``session.shouldfail`` or ``session.shouldstop`` are set, the\n    loop is terminated after the runtest protocol for the current item is finished.\n\n    :param session: The pytest session object.\n\n    Stops at first non-None result, see :ref:`firstresult`.\n    The return value is not used, but only stops further processing.\n\n    Use in conftest plugins\n    =======================\n\n    Any conftest file can implement this hook.\n    \"\"\"\n\n\n@hookspec(firstresult=True)\ndef pytest_runtest_protocol(item: Item, nextitem: Item | None) -> object | None:\n    \"\"\"Perform the runtest protocol for a single test item.\n\n    The default runtest protocol is this (see individual hooks for full details):\n\n    - ``pytest_runtest_logstart(nodeid, location)``\n\n    - Setup phase:\n        - ``call = pytest_runtest_setup(item)`` (wrapped in ``CallInfo(when=\"setup\")``)\n        - ``report = pytest_runtest_makereport(item, call)``\n        - ``pytest_runtest_logreport(report)``\n        - ``pytest_exception_interact(call, report)`` if an interactive exception occurred\n\n    - Call phase, if the setup passed and the ``setuponly`` pytest option is not set:\n        - ``call = pytest_runtest_call(item)`` (wrapped in ``CallInfo(when=\"call\")``)\n        - ``report = pytest_runtest_makereport(item, call)``\n        - ``pytest_runtest_logreport(report)``\n        - ``pytest_exception_interact(call, report)`` if an interactive exception occurred\n\n    - Teardown phase:\n        - ``call = pytest_runtest_teardown(item, nextitem)`` (wrapped in ``CallInfo(when=\"teardown\")``)\n        - ``report = pytest_runtest_makereport(item, call)``\n        - ``pytest_runtest_logreport(report)``\n        - ``pytest_exception_interact(call, report)`` if an interactive exception occurred\n\n    - ``pytest_runtest_logfinish(nodeid, location)``\n\n    :par"}, {"start_line": 19000, "end_line": 21000, "belongs_to": {"file_name": "hookspec.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "tion of the given ``val``\n    that will be used by @pytest.mark.parametrize calls, or None if the hook\n    doesn't know about ``val``.\n\n    The parameter name is available as ``argname``, if required.\n\n    Stops at first non-None result, see :ref:`firstresult`.\n\n    :param config: The pytest config object.\n    :param val: The parametrized value.\n    :param argname: The automatic parameter name produced by pytest.\n\n    Use in conftest plugins\n    =======================\n\n    Any conftest file can implement this hook.\n    \"\"\"\n\n\n# -------------------------------------------------------------------------\n# runtest related hooks\n# -------------------------------------------------------------------------\n\n\n@hookspec(firstresult=True)\ndef pytest_runtestloop(session: Session) -> object | None:\n    \"\"\"Perform the main runtest loop (after collection finished).\n\n    The default hook implementation performs the runtest protocol for all items\n    collected in the session (``session.items``), unless the collection failed\n    or the ``collectonly`` pytest option is set.\n\n    If at any point :py:func:`pytest.exit` is called, the loop is\n    terminated immediately.\n\n    If at any point ``session.shouldfail`` or ``session.shouldstop`` are set, the\n    loop is terminated after the runtest protocol for the current item is finished.\n\n    :param session: The pytest session object.\n\n    Stops at first non-None result, see :ref:`firstresult`.\n    The return value is not used, but only stops further processing.\n\n    Use in conftest plugins\n    =======================\n\n    Any conftest file can implement this hook.\n    \"\"\"\n\n\n@hookspec(firstresult=True)\ndef pytest_runtest_protocol(item: Item, nextitem: Item | None) -> object | None:\n    \"\"\"Perform the runtest protocol for a single test item.\n\n    The default runtest protocol is this (see individual hooks for full details):\n\n    - ``pytest_runtest_logstart(nodeid, location)``\n\n    - Setup phase:\n        - ``call = pytest_runtest_setup(item)`` "}, {"start_line": 1000, "end_line": 3000, "belongs_to": {"file_name": "hookspec.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "  from _pytest.nodes import Collector\n    from _pytest.nodes import Item\n    from _pytest.outcomes import Exit\n    from _pytest.python import Class\n    from _pytest.python import Function\n    from _pytest.python import Metafunc\n    from _pytest.python import Module\n    from _pytest.reports import CollectReport\n    from _pytest.reports import TestReport\n    from _pytest.runner import CallInfo\n    from _pytest.terminal import TerminalReporter\n    from _pytest.terminal import TestShortLogReport\n\n\nhookspec = HookspecMarker(\"pytest\")\n\n# -------------------------------------------------------------------------\n# Initialization hooks called for every plugin\n# -------------------------------------------------------------------------\n\n\n@hookspec(historic=True)\ndef pytest_addhooks(pluginmanager: PytestPluginManager) -> None:\n    \"\"\"Called at plugin registration time to allow adding new hooks via a call to\n    :func:`pluginmanager.add_hookspecs(module_or_class, prefix) <pytest.PytestPluginManager.add_hookspecs>`.\n\n    :param pluginmanager: The pytest plugin manager.\n\n    .. note::\n        This hook is incompatible with hook wrappers.\n\n    Use in conftest plugins\n    =======================\n\n    If a conftest plugin implements this hook, it will be called immediately\n    when the conftest is registered.\n    \"\"\"\n\n\n@hookspec(historic=True)\ndef pytest_plugin_registered(\n    plugin: _PluggyPlugin,\n    plugin_name: str,\n    manager: PytestPluginManager,\n) -> None:\n    \"\"\"A new pytest plugin got registered.\n\n    :param plugin: The plugin module or instance.\n    :param plugin_name: The name by which the plugin is registered.\n    :param manager: The pytest plugin manager.\n\n    .. note::\n        This hook is incompatible with hook wrappers.\n\n    Use in conftest plugins\n    =======================\n\n    If a conftest plugin implements this hook, it will be called immediately\n    when the conftest is registered, once for each plugin registered thus far\n    (including itself!), and for all "}, {"start_line": 0, "end_line": 2000, "belongs_to": {"file_name": "hookspec.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "# mypy: allow-untyped-defs\n# ruff: noqa: T100\n\"\"\"Hook specifications for pytest plugins which are invoked by pytest itself\nand by builtin plugins.\"\"\"\n\nfrom __future__ import annotations\n\nfrom collections.abc import Mapping\nfrom collections.abc import Sequence\nfrom pathlib import Path\nfrom typing import Any\nfrom typing import TYPE_CHECKING\n\nfrom pluggy import HookspecMarker\n\nfrom .deprecated import HOOK_LEGACY_PATH_ARG\n\n\nif TYPE_CHECKING:\n    import pdb\n    from typing import Literal\n    import warnings\n\n    from _pytest._code.code import ExceptionInfo\n    from _pytest._code.code import ExceptionRepr\n    from _pytest.compat import LEGACY_PATH\n    from _pytest.config import _PluggyPlugin\n    from _pytest.config import Config\n    from _pytest.config import ExitCode\n    from _pytest.config import PytestPluginManager\n    from _pytest.config.argparsing import Parser\n    from _pytest.fixtures import FixtureDef\n    from _pytest.fixtures import SubRequest\n    from _pytest.main import Session\n    from _pytest.nodes import Collector\n    from _pytest.nodes import Item\n    from _pytest.outcomes import Exit\n    from _pytest.python import Class\n    from _pytest.python import Function\n    from _pytest.python import Metafunc\n    from _pytest.python import Module\n    from _pytest.reports import CollectReport\n    from _pytest.reports import TestReport\n    from _pytest.runner import CallInfo\n    from _pytest.terminal import TerminalReporter\n    from _pytest.terminal import TestShortLogReport\n\n\nhookspec = HookspecMarker(\"pytest\")\n\n# -------------------------------------------------------------------------\n# Initialization hooks called for every plugin\n# -------------------------------------------------------------------------\n\n\n@hookspec(historic=True)\ndef pytest_addhooks(pluginmanager: PytestPluginManager) -> None:\n    \"\"\"Called at plugin registration time to allow adding new hooks via a call to\n    :func:`pluginmanager.add_hookspecs(module_or_class, prefix) <pytest.PytestPluginManager"}, {"start_line": 25000, "end_line": 27000, "belongs_to": {"file_name": "hookspec.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": " and calls ``teardown()``\n    on ``item`` and all of its parents (which need to be torn down). This\n    includes running the teardown phase of fixtures required by the item (if\n    they go out of scope).\n\n    :param item:\n        The item.\n    :param nextitem:\n        The scheduled-to-be-next test item (None if no further test item is\n        scheduled). This argument is used to perform exact teardowns, i.e.\n        calling just enough finalizers so that nextitem only needs to call\n        setup functions.\n\n    Use in conftest plugins\n    =======================\n\n    Any conftest file can implement this hook. For a given item, only conftest\n    files in the item's directory and its parent directories are consulted.\n    \"\"\"\n\n\n@hookspec(firstresult=True)\ndef pytest_runtest_makereport(item: Item, call: CallInfo[None]) -> TestReport | None:\n    \"\"\"Called to create a :class:`~pytest.TestReport` for each of\n    the setup, call and teardown runtest phases of a test item.\n\n    See :hook:`pytest_runtest_protocol` for a description of the runtest protocol.\n\n    :param item: The item.\n    :param call: The :class:`~pytest.CallInfo` for the phase.\n\n    Stops at first non-None result, see :ref:`firstresult`.\n\n    Use in conftest plugins\n    =======================\n\n    Any conftest file can implement this hook. For a given item, only conftest\n    files in the item's directory and its parent directories are consulted.\n    \"\"\"\n\n\ndef pytest_runtest_logreport(report: TestReport) -> None:\n    \"\"\"Process the :class:`~pytest.TestReport` produced for each\n    of the setup, call and teardown runtest phases of an item.\n\n    See :hook:`pytest_runtest_protocol` for a description of the runtest protocol.\n\n    Use in conftest plugins\n    =======================\n\n    Any conftest file can implement this hook. For a given item, only conftest\n    files in the item's directory and its parent directories are consulted.\n    \"\"\"\n\n\n@hookspec(firstresult=True)\ndef pytest_report_to_serializable(\n    con"}, {"start_line": 26000, "end_line": 28000, "belongs_to": {"file_name": "hookspec.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "t_runtest_protocol` for a description of the runtest protocol.\n\n    :param item: The item.\n    :param call: The :class:`~pytest.CallInfo` for the phase.\n\n    Stops at first non-None result, see :ref:`firstresult`.\n\n    Use in conftest plugins\n    =======================\n\n    Any conftest file can implement this hook. For a given item, only conftest\n    files in the item's directory and its parent directories are consulted.\n    \"\"\"\n\n\ndef pytest_runtest_logreport(report: TestReport) -> None:\n    \"\"\"Process the :class:`~pytest.TestReport` produced for each\n    of the setup, call and teardown runtest phases of an item.\n\n    See :hook:`pytest_runtest_protocol` for a description of the runtest protocol.\n\n    Use in conftest plugins\n    =======================\n\n    Any conftest file can implement this hook. For a given item, only conftest\n    files in the item's directory and its parent directories are consulted.\n    \"\"\"\n\n\n@hookspec(firstresult=True)\ndef pytest_report_to_serializable(\n    config: Config,\n    report: CollectReport | TestReport,\n) -> dict[str, Any] | None:\n    \"\"\"Serialize the given report object into a data structure suitable for\n    sending over the wire, e.g. converted to JSON.\n\n    :param config: The pytest config object.\n    :param report: The report.\n\n    Use in conftest plugins\n    =======================\n\n    Any conftest file can implement this hook. The exact details may depend\n    on the plugin which calls the hook.\n    \"\"\"\n\n\n@hookspec(firstresult=True)\ndef pytest_report_from_serializable(\n    config: Config,\n    data: dict[str, Any],\n) -> CollectReport | TestReport | None:\n    \"\"\"Restore a report object previously serialized with\n    :hook:`pytest_report_to_serializable`.\n\n    :param config: The pytest config object.\n\n    Use in conftest plugins\n    =======================\n\n    Any conftest file can implement this hook. The exact details may depend\n    on the plugin which calls the hook.\n    \"\"\"\n\n\n# -----------------------------------------------"}], "retrieved_count": 10, "cost_time": 0.336153507232666}
{"question": "Where in Pytest's codebase is the \"Session\" class defined?", "answer": null, "relative_code_list": null, "ground_truth": "The \"Session\" class is defined in the pytest codebase in src/_pytest/main.py at line 548. This class inherits from nodes.Collector and serves as the root of the collection tree in pytest's test discovery and execution system. The Session class is responsible for collecting the initial paths given as arguments to pytest and orchestrating the overall test session. Key attributes of the Session class include testsfailed and testscollected counters, shouldstop and shouldfail flags for controlling test execution flow, and items list containing all discovered test items. The class has a from_config class method for creating Session instances from Config objects, and it registers itself as a plugin with the name \"session\" in the plugin manager. The Session class is marked with the @final decorator, indicating it is not meant to be subclassed. It serves as the main orchestrator for the pytest test execution process, coordinating between test collection, fixture management, and test execution phases.", "score": null, "retrieved_content": [{"start_line": 18000, "end_line": 20000, "belongs_to": {"file_name": "main.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "= frozenset()\n        self._initialpaths_with_parents: frozenset[Path] = frozenset()\n        self._notfound: list[tuple[str, Sequence[nodes.Collector]]] = []\n        self._initial_parts: list[CollectionArgument] = []\n        self._collection_cache: dict[nodes.Collector, CollectReport] = {}\n        self.items: list[nodes.Item] = []\n\n        self._bestrelpathcache: dict[Path, str] = _bestrelpath_cache(config.rootpath)\n\n        self.config.pluginmanager.register(self, name=\"session\")\n\n    @classmethod\n    def from_config(cls, config: Config) -> Session:\n        session: Session = cls._create(config=config)\n        return session\n\n    def __repr__(self) -> str:\n        return (\n            f\"<{self.__class__.__name__} {self.name} \"\n            f\"exitstatus=%r \"\n            f\"testsfailed={self.testsfailed} \"\n            f\"testscollected={self.testscollected}>\"\n        ) % getattr(self, \"exitstatus\", \"<UNSET>\")\n\n    @property\n    def shouldstop(self) -> bool | str:\n        return self._shouldstop\n\n    @shouldstop.setter\n    def shouldstop(self, value: bool | str) -> None:\n        # The runner checks shouldfail and assumes that if it is set we are\n        # definitely stopping, so prevent unsetting it.\n        if value is False and self._shouldstop:\n            warnings.warn(\n                PytestWarning(\n                    \"session.shouldstop cannot be unset after it has been set; ignoring.\"\n                ),\n                stacklevel=2,\n            )\n            return\n        self._shouldstop = value\n\n    @property\n    def shouldfail(self) -> bool | str:\n        return self._shouldfail\n\n    @shouldfail.setter\n    def shouldfail(self, value: bool | str) -> None:\n        # The runner checks shouldfail and assumes that if it is set we are\n        # definitely stopping, so prevent unsetting it.\n        if value is False and self._shouldfail:\n            warnings.warn(\n                PytestWarning(\n                    \"session.shouldfail cannot be unset after it has bee"}, {"start_line": 17000, "end_line": 19000, "belongs_to": {"file_name": "main.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "le_path=path, parent=self)\n                yield from cols\n\n\n@final\nclass Session(nodes.Collector):\n    \"\"\"The root of the collection tree.\n\n    ``Session`` collects the initial paths given as arguments to pytest.\n    \"\"\"\n\n    Interrupted = Interrupted\n    Failed = Failed\n    # Set on the session by runner.pytest_sessionstart.\n    _setupstate: SetupState\n    # Set on the session by fixtures.pytest_sessionstart.\n    _fixturemanager: FixtureManager\n    exitstatus: int | ExitCode\n\n    def __init__(self, config: Config) -> None:\n        super().__init__(\n            name=\"\",\n            path=config.rootpath,\n            fspath=None,\n            parent=None,\n            config=config,\n            session=self,\n            nodeid=\"\",\n        )\n        self.testsfailed = 0\n        self.testscollected = 0\n        self._shouldstop: bool | str = False\n        self._shouldfail: bool | str = False\n        self.trace = config.trace.root.get(\"collection\")\n        self._initialpaths: frozenset[Path] = frozenset()\n        self._initialpaths_with_parents: frozenset[Path] = frozenset()\n        self._notfound: list[tuple[str, Sequence[nodes.Collector]]] = []\n        self._initial_parts: list[CollectionArgument] = []\n        self._collection_cache: dict[nodes.Collector, CollectReport] = {}\n        self.items: list[nodes.Item] = []\n\n        self._bestrelpathcache: dict[Path, str] = _bestrelpath_cache(config.rootpath)\n\n        self.config.pluginmanager.register(self, name=\"session\")\n\n    @classmethod\n    def from_config(cls, config: Config) -> Session:\n        session: Session = cls._create(config=config)\n        return session\n\n    def __repr__(self) -> str:\n        return (\n            f\"<{self.__class__.__name__} {self.name} \"\n            f\"exitstatus=%r \"\n            f\"testsfailed={self.testsfailed} \"\n            f\"testscollected={self.testscollected}>\"\n        ) % getattr(self, \"exitstatus\", \"<UNSET>\")\n\n    @property\n    def shouldstop(self) -> bool | str:\n        return self._shoul"}, {"start_line": 19000, "end_line": 21000, "belongs_to": {"file_name": "main.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "dstop\n\n    @shouldstop.setter\n    def shouldstop(self, value: bool | str) -> None:\n        # The runner checks shouldfail and assumes that if it is set we are\n        # definitely stopping, so prevent unsetting it.\n        if value is False and self._shouldstop:\n            warnings.warn(\n                PytestWarning(\n                    \"session.shouldstop cannot be unset after it has been set; ignoring.\"\n                ),\n                stacklevel=2,\n            )\n            return\n        self._shouldstop = value\n\n    @property\n    def shouldfail(self) -> bool | str:\n        return self._shouldfail\n\n    @shouldfail.setter\n    def shouldfail(self, value: bool | str) -> None:\n        # The runner checks shouldfail and assumes that if it is set we are\n        # definitely stopping, so prevent unsetting it.\n        if value is False and self._shouldfail:\n            warnings.warn(\n                PytestWarning(\n                    \"session.shouldfail cannot be unset after it has been set; ignoring.\"\n                ),\n                stacklevel=2,\n            )\n            return\n        self._shouldfail = value\n\n    @property\n    def startpath(self) -> Path:\n        \"\"\"The path from which pytest was invoked.\n\n        .. versionadded:: 7.0.0\n        \"\"\"\n        return self.config.invocation_params.dir\n\n    def _node_location_to_relpath(self, node_path: Path) -> str:\n        # bestrelpath is a quite slow function.\n        return self._bestrelpathcache[node_path]\n\n    @hookimpl(tryfirst=True)\n    def pytest_collectstart(self) -> None:\n        if self.shouldfail:\n            raise self.Failed(self.shouldfail)\n        if self.shouldstop:\n            raise self.Interrupted(self.shouldstop)\n\n    @hookimpl(tryfirst=True)\n    def pytest_runtest_logreport(self, report: TestReport | CollectReport) -> None:\n        if report.failed and not hasattr(report, \"wasxfail\"):\n            self.testsfailed += 1\n            maxfail = self.config.getvalue(\"maxfail\")\n            if maxf"}, {"start_line": 0, "end_line": 2000, "belongs_to": {"file_name": "test_session.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "# mypy: allow-untyped-defs\nfrom __future__ import annotations\n\nfrom _pytest.config import ExitCode\nfrom _pytest.monkeypatch import MonkeyPatch\nfrom _pytest.pytester import Pytester\nimport pytest\n\n\nclass SessionTests:\n    def test_basic_testitem_events(self, pytester: Pytester) -> None:\n        tfile = pytester.makepyfile(\n            \"\"\"\n            def test_one():\n                pass\n            def test_one_one():\n                assert 0\n            def test_other():\n                raise ValueError(23)\n            class TestClass(object):\n                def test_two(self, someargs):\n                    pass\n        \"\"\"\n        )\n        reprec = pytester.inline_run(tfile)\n        passed, skipped, failed = reprec.listoutcomes()\n        assert len(skipped) == 0\n        assert len(passed) == 1\n        assert len(failed) == 3\n\n        def end(x):\n            return x.nodeid.split(\"::\")[-1]\n\n        assert end(failed[0]) == \"test_one_one\"\n        assert end(failed[1]) == \"test_other\"\n        itemstarted = reprec.getcalls(\"pytest_itemcollected\")\n        assert len(itemstarted) == 4\n        # XXX check for failing funcarg setup\n        # colreports = reprec.getcalls(\"pytest_collectreport\")\n        # assert len(colreports) == 4\n        # assert colreports[1].report.failed\n\n    def test_nested_import_error(self, pytester: Pytester) -> None:\n        tfile = pytester.makepyfile(\n            \"\"\"\n            import import_fails\n            def test_this():\n                assert import_fails.a == 1\n        \"\"\",\n            import_fails=\"\"\"\n            import does_not_work\n            a = 1\n        \"\"\",\n        )\n        reprec = pytester.inline_run(tfile)\n        values = reprec.getfailedcollections()\n        assert len(values) == 1\n        out = str(values[0].longrepr)\n        assert out.find(\"does_not_work\") != -1\n\n    def test_raises_output(self, pytester: Pytester) -> None:\n        reprec = pytester.inline_runsource(\n            \"\"\"\n            import pytest\n          "}, {"start_line": 6000, "end_line": 8000, "belongs_to": {"file_name": "test_session.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "rec.getreports(\"pytest_collectreport\")\n        # Session, Dir\n        assert len(reports) == 2\n        assert reports[1].skipped\n\n\nclass TestNewSession(SessionTests):\n    def test_order_of_execution(self, pytester: Pytester) -> None:\n        reprec = pytester.inline_runsource(\n            \"\"\"\n            values = []\n            def test_1():\n                values.append(1)\n            def test_2():\n                values.append(2)\n            def test_3():\n                assert values == [1,2]\n            class Testmygroup(object):\n                reslist = values\n                def test_1(self):\n                    self.reslist.append(1)\n                def test_2(self):\n                    self.reslist.append(2)\n                def test_3(self):\n                    self.reslist.append(3)\n                def test_4(self):\n                    assert self.reslist == [1,2,1,2,3]\n        \"\"\"\n        )\n        passed, skipped, failed = reprec.countoutcomes()\n        assert failed == skipped == 0\n        assert passed == 7\n\n    def test_collect_only_with_various_situations(self, pytester: Pytester) -> None:\n        p = pytester.makepyfile(\n            test_one=\"\"\"\n                def test_one():\n                    raise ValueError()\n\n                class TestX(object):\n                    def test_method_one(self):\n                        pass\n\n                class TestY(TestX):\n                    pass\n            \"\"\",\n            test_three=\"xxxdsadsadsadsa\",\n            __init__=\"\",\n        )\n        reprec = pytester.inline_run(\"--collect-only\", p.parent)\n\n        itemstarted = reprec.getcalls(\"pytest_itemcollected\")\n        assert len(itemstarted) == 3\n        assert not reprec.getreports(\"pytest_runtest_logreport\")\n        started = reprec.getcalls(\"pytest_collectstart\")\n        finished = reprec.getreports(\"pytest_collectreport\")\n        assert len(started) == len(finished)\n        assert len(started) == 6\n        colfail = [x for x in finished if x.failed]\n"}, {"start_line": 5000, "end_line": 7000, "belongs_to": {"file_name": "test_session.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "c.listoutcomes()\n        assert (len(passed), len(skipped), len(failed)) == (0, 0, 1)\n        entries = failed[0].longrepr.reprtraceback.reprentries  # type: ignore[union-attr]\n        assert len(entries) == 1\n        repr_locals = entries[0].reprlocals\n        assert repr_locals.lines\n        assert len(repr_locals.lines) == 1\n        assert repr_locals.lines[0].startswith(\n            \"x          = <[NotImplementedError() raised in repr()] ObjWithErrorInRepr\"\n        )\n\n    def test_skip_file_by_conftest(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            conftest=\"\"\"\n            import pytest\n            def pytest_collect_file():\n                pytest.skip(\"intentional\")\n        \"\"\",\n            test_file=\"\"\"\n            def test_one(): pass\n        \"\"\",\n        )\n        try:\n            reprec = pytester.inline_run(pytester.path)\n        except pytest.skip.Exception:  # pragma: no cover\n            pytest.fail(\"wrong skipped caught\")\n        reports = reprec.getreports(\"pytest_collectreport\")\n        # Session, Dir\n        assert len(reports) == 2\n        assert reports[1].skipped\n\n\nclass TestNewSession(SessionTests):\n    def test_order_of_execution(self, pytester: Pytester) -> None:\n        reprec = pytester.inline_runsource(\n            \"\"\"\n            values = []\n            def test_1():\n                values.append(1)\n            def test_2():\n                values.append(2)\n            def test_3():\n                assert values == [1,2]\n            class Testmygroup(object):\n                reslist = values\n                def test_1(self):\n                    self.reslist.append(1)\n                def test_2(self):\n                    self.reslist.append(2)\n                def test_3(self):\n                    self.reslist.append(3)\n                def test_4(self):\n                    assert self.reslist == [1,2,1,2,3]\n        \"\"\"\n        )\n        passed, skipped, failed = reprec.countoutcomes()\n        assert failed == ski"}, {"start_line": 15000, "end_line": 17000, "belongs_to": {"file_name": "pytester.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "during initialization.\n\n    It is particularly useful for testing plugins. It is similar to the :fixture:`tmp_path`\n    fixture but provides methods which aid in testing pytest itself.\n    \"\"\"\n    return Pytester(request, tmp_path_factory, monkeypatch, _ispytest=True)\n\n\n@fixture\ndef _sys_snapshot() -> Generator[None]:\n    snappaths = SysPathsSnapshot()\n    snapmods = SysModulesSnapshot()\n    yield\n    snapmods.restore()\n    snappaths.restore()\n\n\n@fixture\ndef _config_for_test() -> Generator[Config]:\n    from _pytest.config import get_config\n\n    config = get_config()\n    yield config\n    config._ensure_unconfigure()  # cleanup, e.g. capman closing tmpfiles.\n\n\n# Regex to match the session duration string in the summary: \"74.34s\".\nrex_session_duration = re.compile(r\"\\d+\\.\\d\\ds\")\n# Regex to match all the counts and phrases in the summary line: \"34 passed, 111 skipped\".\nrex_outcome = re.compile(r\"(\\d+) (\\w+)\")\n\n\n@final\nclass RunResult:\n    \"\"\"The result of running a command from :class:`~pytest.Pytester`.\"\"\"\n\n    def __init__(\n        self,\n        ret: int | ExitCode,\n        outlines: list[str],\n        errlines: list[str],\n        duration: float,\n    ) -> None:\n        try:\n            self.ret: int | ExitCode = ExitCode(ret)\n            \"\"\"The return value.\"\"\"\n        except ValueError:\n            self.ret = ret\n        self.outlines = outlines\n        \"\"\"List of lines captured from stdout.\"\"\"\n        self.errlines = errlines\n        \"\"\"List of lines captured from stderr.\"\"\"\n        self.stdout = LineMatcher(outlines)\n        \"\"\":class:`~pytest.LineMatcher` of stdout.\n\n        Use e.g. :func:`str(stdout) <pytest.LineMatcher.__str__()>` to reconstruct stdout, or the commonly used\n        :func:`stdout.fnmatch_lines() <pytest.LineMatcher.fnmatch_lines()>` method.\n        \"\"\"\n        self.stderr = LineMatcher(errlines)\n        \"\"\":class:`~pytest.LineMatcher` of stderr.\"\"\"\n        self.duration = duration\n        \"\"\"Duration in seconds.\"\"\"\n\n    def __repr__(self) -> st"}, {"start_line": 0, "end_line": 2000, "belongs_to": {"file_name": "main.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "\"\"\"Core implementation of the testing process: init, session, runtest loop.\"\"\"\n\nfrom __future__ import annotations\n\nimport argparse\nfrom collections.abc import Callable\nfrom collections.abc import Iterable\nfrom collections.abc import Iterator\nfrom collections.abc import Sequence\nfrom collections.abc import Set as AbstractSet\nimport dataclasses\nimport fnmatch\nimport functools\nimport importlib\nimport importlib.util\nimport os\nfrom pathlib import Path\nimport sys\nfrom typing import final\nfrom typing import Literal\nfrom typing import overload\nfrom typing import TYPE_CHECKING\nimport warnings\n\nimport pluggy\n\nfrom _pytest import nodes\nimport _pytest._code\nfrom _pytest.config import Config\nfrom _pytest.config import directory_arg\nfrom _pytest.config import ExitCode\nfrom _pytest.config import hookimpl\nfrom _pytest.config import PytestPluginManager\nfrom _pytest.config import UsageError\nfrom _pytest.config.argparsing import Parser\nfrom _pytest.config.compat import PathAwareHookProxy\nfrom _pytest.outcomes import exit\nfrom _pytest.pathlib import absolutepath\nfrom _pytest.pathlib import bestrelpath\nfrom _pytest.pathlib import fnmatch_ex\nfrom _pytest.pathlib import safe_exists\nfrom _pytest.pathlib import scandir\nfrom _pytest.reports import CollectReport\nfrom _pytest.reports import TestReport\nfrom _pytest.runner import collect_one_node\nfrom _pytest.runner import SetupState\nfrom _pytest.warning_types import PytestWarning\n\n\nif TYPE_CHECKING:\n    from typing_extensions import Self\n\n    from _pytest.fixtures import FixtureManager\n\n\ndef pytest_addoption(parser: Parser) -> None:\n    group = parser.getgroup(\"general\", \"Running and selection options\")\n    group._addoption(  # private to use reserved lower-case short option\n        \"-x\",\n        \"--exitfirst\",\n        action=\"store_const\",\n        dest=\"maxfail\",\n        const=1,\n        help=\"Exit instantly on first error or failed test\",\n    )\n    group.addoption(\n        \"--maxfail\",\n        metavar=\"num\",\n        action=\"store\",\n        t"}, {"start_line": 3000, "end_line": 5000, "belongs_to": {"file_name": "__init__.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "\nfrom _pytest.warning_types import PytestCollectionWarning\nfrom _pytest.warning_types import PytestConfigWarning\nfrom _pytest.warning_types import PytestDeprecationWarning\nfrom _pytest.warning_types import PytestExperimentalApiWarning\nfrom _pytest.warning_types import PytestFDWarning\nfrom _pytest.warning_types import PytestRemovedIn9Warning\nfrom _pytest.warning_types import PytestReturnNotNoneWarning\nfrom _pytest.warning_types import PytestUnhandledThreadExceptionWarning\nfrom _pytest.warning_types import PytestUnknownMarkWarning\nfrom _pytest.warning_types import PytestUnraisableExceptionWarning\nfrom _pytest.warning_types import PytestWarning\n\n\nset_trace = __pytestPDB.set_trace\n\n\n__all__ = [\n    \"HIDDEN_PARAM\",\n    \"Cache\",\n    \"CallInfo\",\n    \"CaptureFixture\",\n    \"Class\",\n    \"CollectReport\",\n    \"Collector\",\n    \"Config\",\n    \"Dir\",\n    \"Directory\",\n    \"DoctestItem\",\n    \"ExceptionInfo\",\n    \"ExitCode\",\n    \"File\",\n    \"FixtureDef\",\n    \"FixtureLookupError\",\n    \"FixtureRequest\",\n    \"Function\",\n    \"HookRecorder\",\n    \"Item\",\n    \"LineMatcher\",\n    \"LogCaptureFixture\",\n    \"Mark\",\n    \"MarkDecorator\",\n    \"MarkGenerator\",\n    \"Metafunc\",\n    \"Module\",\n    \"MonkeyPatch\",\n    \"OptionGroup\",\n    \"Package\",\n    \"Parser\",\n    \"PytestAssertRewriteWarning\",\n    \"PytestCacheWarning\",\n    \"PytestCollectionWarning\",\n    \"PytestConfigWarning\",\n    \"PytestDeprecationWarning\",\n    \"PytestExperimentalApiWarning\",\n    \"PytestFDWarning\",\n    \"PytestPluginManager\",\n    \"PytestRemovedIn9Warning\",\n    \"PytestReturnNotNoneWarning\",\n    \"PytestUnhandledThreadExceptionWarning\",\n    \"PytestUnknownMarkWarning\",\n    \"PytestUnraisableExceptionWarning\",\n    \"PytestWarning\",\n    \"Pytester\",\n    \"RaisesExc\",\n    \"RaisesGroup\",\n    \"RecordedHookCall\",\n    \"RunResult\",\n    \"Session\",\n    \"Stash\",\n    \"StashKey\",\n    \"TempPathFactory\",\n    \"TempdirFactory\",\n    \"TerminalReporter\",\n    \"TestReport\",\n    \"TestShortLogReport\",\n    \"Testdir\",\n    \"UsageError\",\n    \"WarningsRecorder\",\n    \"__versio"}, {"start_line": 1000, "end_line": 3000, "belongs_to": {"file_name": "__init__.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "upError\nfrom _pytest.fixtures import FixtureRequest\nfrom _pytest.fixtures import yield_fixture\nfrom _pytest.freeze_support import freeze_includes\nfrom _pytest.legacypath import TempdirFactory\nfrom _pytest.legacypath import Testdir\nfrom _pytest.logging import LogCaptureFixture\nfrom _pytest.main import Dir\nfrom _pytest.main import Session\nfrom _pytest.mark import HIDDEN_PARAM\nfrom _pytest.mark import Mark\nfrom _pytest.mark import MARK_GEN as mark\nfrom _pytest.mark import MarkDecorator\nfrom _pytest.mark import MarkGenerator\nfrom _pytest.mark import param\nfrom _pytest.monkeypatch import MonkeyPatch\nfrom _pytest.nodes import Collector\nfrom _pytest.nodes import Directory\nfrom _pytest.nodes import File\nfrom _pytest.nodes import Item\nfrom _pytest.outcomes import exit\nfrom _pytest.outcomes import fail\nfrom _pytest.outcomes import importorskip\nfrom _pytest.outcomes import skip\nfrom _pytest.outcomes import xfail\nfrom _pytest.pytester import HookRecorder\nfrom _pytest.pytester import LineMatcher\nfrom _pytest.pytester import Pytester\nfrom _pytest.pytester import RecordedHookCall\nfrom _pytest.pytester import RunResult\nfrom _pytest.python import Class\nfrom _pytest.python import Function\nfrom _pytest.python import Metafunc\nfrom _pytest.python import Module\nfrom _pytest.python import Package\nfrom _pytest.python_api import approx\nfrom _pytest.raises import raises\nfrom _pytest.raises import RaisesExc\nfrom _pytest.raises import RaisesGroup\nfrom _pytest.recwarn import deprecated_call\nfrom _pytest.recwarn import WarningsRecorder\nfrom _pytest.recwarn import warns\nfrom _pytest.reports import CollectReport\nfrom _pytest.reports import TestReport\nfrom _pytest.runner import CallInfo\nfrom _pytest.stash import Stash\nfrom _pytest.stash import StashKey\nfrom _pytest.terminal import TerminalReporter\nfrom _pytest.terminal import TestShortLogReport\nfrom _pytest.tmpdir import TempPathFactory\nfrom _pytest.warning_types import PytestAssertRewriteWarning\nfrom _pytest.warning_types import PytestCacheWarning"}], "retrieved_count": 10, "cost_time": 0.3493380546569824}
{"question": "Where are Pytest's built-in fixture implementations located?", "answer": null, "relative_code_list": null, "ground_truth": "Pytest's built-in fixture implementations are located across multiple modules in the src/_pytest/ directory, with each fixture implemented in its respective plugin module: 1) Capture-related fixtures (capfd, capfdbinary, capsys, capsysbinary, capteesys) are implemented in src/_pytest/capture.py, 2) Logging fixture (caplog) is implemented in src/_pytest/logging.py, 3) Cache fixture is implemented in src/_pytest/cacheprovider.py, 4) Monkeypatch fixture is implemented in src/_pytest/monkeypatch.py, 5) Temporary directory fixtures (tmp_path, tmp_path_factory) are implemented in src/_pytest/tmpdir.py, 6) Warning recording fixture (recwarn) is implemented in src/_pytest/recwarn.py, 7) Configuration fixture (pytestconfig) is implemented in src/_pytest/config/__init__.py, 8) Request fixture is implemented in src/_pytest/fixtures.py as part of the FixtureRequest class, 9) Test directory fixture (testdir) is implemented in src/_pytest/pytester.py, 10) Doctest namespace fixture is implemented in src/_pytest/doctest.py, 11) Property recording fixtures (record_property, record_testsuite_property) are implemented in src/_pytest/junitxml.py, 12) These fixtures are automatically loaded as part of the default plugins defined in src/_pytest/config/__init__.py and are available to all tests without requiring explicit import or registration.", "score": null, "retrieved_content": [{"start_line": 75000, "end_line": 77000, "belongs_to": {"file_name": "fixtures.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "  tw.sep(\"-\", f\"({get_best_relpath(item.function)})\")  # type: ignore[attr-defined]\n        # dict key not used in loop but needed for sorting.\n        for _, fixturedefs in sorted(info.name2fixturedefs.items()):\n            assert fixturedefs is not None\n            if not fixturedefs:\n                continue\n            # Last item is expected to be the one used by the test item.\n            write_fixture(fixturedefs[-1])\n\n    for session_item in session.items:\n        write_item(session_item)\n\n\ndef showfixtures(config: Config) -> int | ExitCode:\n    from _pytest.main import wrap_session\n\n    return wrap_session(config, _showfixtures_main)\n\n\ndef _showfixtures_main(config: Config, session: Session) -> None:\n    import _pytest.config\n\n    session.perform_collect()\n    invocation_dir = config.invocation_params.dir\n    tw = _pytest.config.create_terminal_writer(config)\n    verbose = config.get_verbosity()\n\n    fm = session._fixturemanager\n\n    available = []\n    seen: set[tuple[str, str]] = set()\n\n    for argname, fixturedefs in fm._arg2fixturedefs.items():\n        assert fixturedefs is not None\n        if not fixturedefs:\n            continue\n        for fixturedef in fixturedefs:\n            loc = getlocation(fixturedef.func, invocation_dir)\n            if (fixturedef.argname, loc) in seen:\n                continue\n            seen.add((fixturedef.argname, loc))\n            available.append(\n                (\n                    len(fixturedef.baseid),\n                    fixturedef.func.__module__,\n                    _pretty_fixture_path(invocation_dir, fixturedef.func),\n                    fixturedef.argname,\n                    fixturedef,\n                )\n            )\n\n    available.sort()\n    currentmodule = None\n    for baseid, module, prettypath, argname, fixturedef in available:\n        if currentmodule != module:\n            if not module.startswith(\"_pytest.\"):\n                tw.line()\n                tw.sep(\"-\", f\"fixtures defined from {module}\")\n   "}, {"start_line": 1000, "end_line": 3000, "belongs_to": {"file_name": "fixtures.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "_code import Source\nfrom _pytest._code.code import FormattedExcinfo\nfrom _pytest._code.code import TerminalRepr\nfrom _pytest._io import TerminalWriter\nfrom _pytest.compat import assert_never\nfrom _pytest.compat import get_real_func\nfrom _pytest.compat import getfuncargnames\nfrom _pytest.compat import getimfunc\nfrom _pytest.compat import getlocation\nfrom _pytest.compat import NOTSET\nfrom _pytest.compat import NotSetType\nfrom _pytest.compat import safe_getattr\nfrom _pytest.compat import safe_isclass\nfrom _pytest.compat import signature\nfrom _pytest.config import _PluggyPlugin\nfrom _pytest.config import Config\nfrom _pytest.config import ExitCode\nfrom _pytest.config.argparsing import Parser\nfrom _pytest.deprecated import check_ispytest\nfrom _pytest.deprecated import MARKED_FIXTURE\nfrom _pytest.deprecated import YIELD_FIXTURE\nfrom _pytest.main import Session\nfrom _pytest.mark import Mark\nfrom _pytest.mark import ParameterSet\nfrom _pytest.mark.structures import MarkDecorator\nfrom _pytest.outcomes import fail\nfrom _pytest.outcomes import skip\nfrom _pytest.outcomes import TEST_OUTCOME\nfrom _pytest.pathlib import absolutepath\nfrom _pytest.pathlib import bestrelpath\nfrom _pytest.scope import _ScopeName\nfrom _pytest.scope import HIGH_SCOPES\nfrom _pytest.scope import Scope\nfrom _pytest.warning_types import PytestRemovedIn9Warning\nfrom _pytest.warning_types import PytestWarning\n\n\nif sys.version_info < (3, 11):\n    from exceptiongroup import BaseExceptionGroup\n\n\nif TYPE_CHECKING:\n    from _pytest.python import CallSpec2\n    from _pytest.python import Function\n    from _pytest.python import Metafunc\n\n\n# The value of the fixture -- return/yield of the fixture function (type variable).\nFixtureValue = TypeVar(\"FixtureValue\")\n# The type of the fixture function (type variable).\nFixtureFunction = TypeVar(\"FixtureFunction\", bound=Callable[..., object])\n# The type of a fixture function (type alias generic in fixture value).\n_FixtureFunc = Union[\n    Callable[..., FixtureValue], Callable[."}, {"start_line": 52000, "end_line": 54000, "belongs_to": {"file_name": "fixtures.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing/python", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "               return request._fixturemanager\n\n            @pytest.fixture\n            def item(request):\n                return request._pyfuncitem\n        \"\"\"\n        )\n        return pytester\n\n    def test_parsefactories_evil_objects_issue214(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            class A(object):\n                def __call__(self):\n                    pass\n                def __getattr__(self, name):\n                    raise RuntimeError()\n            a = A()\n            def test_hello():\n                pass\n        \"\"\"\n        )\n        reprec = pytester.inline_run()\n        reprec.assertoutcome(passed=1, failed=0)\n\n    def test_parsefactories_conftest(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            def test_hello(item, fm):\n                for name in (\"fm\", \"hello\", \"item\"):\n                    faclist = fm.getfixturedefs(name, item)\n                    assert len(faclist) == 1\n                    fac = faclist[0]\n                    assert fac.func.__name__ == name\n        \"\"\"\n        )\n        reprec = pytester.inline_run(\"-s\")\n        reprec.assertoutcome(passed=1)\n\n    def test_parsefactories_conftest_and_module_and_class(\n        self, pytester: Pytester\n    ) -> None:\n        pytester.makepyfile(\n            \"\"\"\\\n            import pytest\n\n            @pytest.fixture\n            def hello(request):\n                return \"module\"\n            class TestClass(object):\n                @pytest.fixture\n                def hello(self, request):\n                    return \"class\"\n                def test_hello(self, item, fm):\n                    faclist = fm.getfixturedefs(\"hello\", item)\n                    print(faclist)\n                    assert len(faclist) == 3\n\n                    assert faclist[0].func(item._request) == \"conftest\"\n                    assert faclist[1].func(item._request) == \"module\"\n                    assert faclist[2].func(item._request"}, {"start_line": 1000, "end_line": 3000, "belongs_to": {"file_name": "__init__.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "upError\nfrom _pytest.fixtures import FixtureRequest\nfrom _pytest.fixtures import yield_fixture\nfrom _pytest.freeze_support import freeze_includes\nfrom _pytest.legacypath import TempdirFactory\nfrom _pytest.legacypath import Testdir\nfrom _pytest.logging import LogCaptureFixture\nfrom _pytest.main import Dir\nfrom _pytest.main import Session\nfrom _pytest.mark import HIDDEN_PARAM\nfrom _pytest.mark import Mark\nfrom _pytest.mark import MARK_GEN as mark\nfrom _pytest.mark import MarkDecorator\nfrom _pytest.mark import MarkGenerator\nfrom _pytest.mark import param\nfrom _pytest.monkeypatch import MonkeyPatch\nfrom _pytest.nodes import Collector\nfrom _pytest.nodes import Directory\nfrom _pytest.nodes import File\nfrom _pytest.nodes import Item\nfrom _pytest.outcomes import exit\nfrom _pytest.outcomes import fail\nfrom _pytest.outcomes import importorskip\nfrom _pytest.outcomes import skip\nfrom _pytest.outcomes import xfail\nfrom _pytest.pytester import HookRecorder\nfrom _pytest.pytester import LineMatcher\nfrom _pytest.pytester import Pytester\nfrom _pytest.pytester import RecordedHookCall\nfrom _pytest.pytester import RunResult\nfrom _pytest.python import Class\nfrom _pytest.python import Function\nfrom _pytest.python import Metafunc\nfrom _pytest.python import Module\nfrom _pytest.python import Package\nfrom _pytest.python_api import approx\nfrom _pytest.raises import raises\nfrom _pytest.raises import RaisesExc\nfrom _pytest.raises import RaisesGroup\nfrom _pytest.recwarn import deprecated_call\nfrom _pytest.recwarn import WarningsRecorder\nfrom _pytest.recwarn import warns\nfrom _pytest.reports import CollectReport\nfrom _pytest.reports import TestReport\nfrom _pytest.runner import CallInfo\nfrom _pytest.stash import Stash\nfrom _pytest.stash import StashKey\nfrom _pytest.terminal import TerminalReporter\nfrom _pytest.terminal import TestShortLogReport\nfrom _pytest.tmpdir import TempPathFactory\nfrom _pytest.warning_types import PytestAssertRewriteWarning\nfrom _pytest.warning_types import PytestCacheWarning"}, {"start_line": 73000, "end_line": 75000, "belongs_to": {"file_name": "fixtures.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "Config) -> int | ExitCode:\n    from _pytest.main import wrap_session\n\n    return wrap_session(config, _show_fixtures_per_test)\n\n\n_PYTEST_DIR = Path(_pytest.__file__).parent\n\n\ndef _pretty_fixture_path(invocation_dir: Path, func) -> str:\n    loc = Path(getlocation(func, invocation_dir))\n    prefix = Path(\"...\", \"_pytest\")\n    try:\n        return str(prefix / loc.relative_to(_PYTEST_DIR))\n    except ValueError:\n        return bestrelpath(invocation_dir, loc)\n\n\ndef _show_fixtures_per_test(config: Config, session: Session) -> None:\n    import _pytest.config\n\n    session.perform_collect()\n    invocation_dir = config.invocation_params.dir\n    tw = _pytest.config.create_terminal_writer(config)\n    verbose = config.get_verbosity()\n\n    def get_best_relpath(func) -> str:\n        loc = getlocation(func, invocation_dir)\n        return bestrelpath(invocation_dir, Path(loc))\n\n    def write_fixture(fixture_def: FixtureDef[object]) -> None:\n        argname = fixture_def.argname\n        if verbose <= 0 and argname.startswith(\"_\"):\n            return\n        prettypath = _pretty_fixture_path(invocation_dir, fixture_def.func)\n        tw.write(f\"{argname}\", green=True)\n        tw.write(f\" -- {prettypath}\", yellow=True)\n        tw.write(\"\\n\")\n        fixture_doc = inspect.getdoc(fixture_def.func)\n        if fixture_doc:\n            write_docstring(\n                tw,\n                fixture_doc.split(\"\\n\\n\", maxsplit=1)[0]\n                if verbose <= 0\n                else fixture_doc,\n            )\n        else:\n            tw.line(\"    no docstring available\", red=True)\n\n    def write_item(item: nodes.Item) -> None:\n        # Not all items have _fixtureinfo attribute.\n        info: FuncFixtureInfo | None = getattr(item, \"_fixtureinfo\", None)\n        if info is None or not info.name2fixturedefs:\n            # This test item does not use any fixtures.\n            return\n        tw.line()\n        tw.sep(\"-\", f\"fixtures used by {item.name}\")\n        # TODO: Fix this type ignore.\n      "}, {"start_line": 2000, "end_line": 4000, "belongs_to": {"file_name": "fixtures.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "comes import fail\nfrom _pytest.outcomes import skip\nfrom _pytest.outcomes import TEST_OUTCOME\nfrom _pytest.pathlib import absolutepath\nfrom _pytest.pathlib import bestrelpath\nfrom _pytest.scope import _ScopeName\nfrom _pytest.scope import HIGH_SCOPES\nfrom _pytest.scope import Scope\nfrom _pytest.warning_types import PytestRemovedIn9Warning\nfrom _pytest.warning_types import PytestWarning\n\n\nif sys.version_info < (3, 11):\n    from exceptiongroup import BaseExceptionGroup\n\n\nif TYPE_CHECKING:\n    from _pytest.python import CallSpec2\n    from _pytest.python import Function\n    from _pytest.python import Metafunc\n\n\n# The value of the fixture -- return/yield of the fixture function (type variable).\nFixtureValue = TypeVar(\"FixtureValue\")\n# The type of the fixture function (type variable).\nFixtureFunction = TypeVar(\"FixtureFunction\", bound=Callable[..., object])\n# The type of a fixture function (type alias generic in fixture value).\n_FixtureFunc = Union[\n    Callable[..., FixtureValue], Callable[..., Generator[FixtureValue]]\n]\n# The type of FixtureDef.cached_result (type alias generic in fixture value).\n_FixtureCachedResult = Union[\n    tuple[\n        # The result.\n        FixtureValue,\n        # Cache key.\n        object,\n        None,\n    ],\n    tuple[\n        None,\n        # Cache key.\n        object,\n        # The exception and the original traceback.\n        tuple[BaseException, Optional[types.TracebackType]],\n    ],\n]\n\n\n@dataclasses.dataclass(frozen=True)\nclass PseudoFixtureDef(Generic[FixtureValue]):\n    cached_result: _FixtureCachedResult[FixtureValue]\n    _scope: Scope\n\n\ndef pytest_sessionstart(session: Session) -> None:\n    session._fixturemanager = FixtureManager(session)\n\n\ndef get_scope_package(\n    node: nodes.Item,\n    fixturedef: FixtureDef[object],\n) -> nodes.Node | None:\n    from _pytest.python import Package\n\n    for parent in node.iter_parents():\n        if isinstance(parent, Package) and parent.nodeid == fixturedef.baseid:\n            return parent\n    retur"}, {"start_line": 53000, "end_line": 55000, "belongs_to": {"file_name": "fixtures.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing/python", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "                 fac = faclist[0]\n                    assert fac.func.__name__ == name\n        \"\"\"\n        )\n        reprec = pytester.inline_run(\"-s\")\n        reprec.assertoutcome(passed=1)\n\n    def test_parsefactories_conftest_and_module_and_class(\n        self, pytester: Pytester\n    ) -> None:\n        pytester.makepyfile(\n            \"\"\"\\\n            import pytest\n\n            @pytest.fixture\n            def hello(request):\n                return \"module\"\n            class TestClass(object):\n                @pytest.fixture\n                def hello(self, request):\n                    return \"class\"\n                def test_hello(self, item, fm):\n                    faclist = fm.getfixturedefs(\"hello\", item)\n                    print(faclist)\n                    assert len(faclist) == 3\n\n                    assert faclist[0].func(item._request) == \"conftest\"\n                    assert faclist[1].func(item._request) == \"module\"\n                    assert faclist[2].func(item._request) == \"class\"\n            \"\"\"\n        )\n        reprec = pytester.inline_run(\"-s\")\n        reprec.assertoutcome(passed=1)\n\n    def test_parsefactories_relative_node_ids(\n        self, pytester: Pytester, monkeypatch: MonkeyPatch\n    ) -> None:\n        # example mostly taken from:\n        # https://mail.python.org/pipermail/pytest-dev/2014-September/002617.html\n        runner = pytester.mkdir(\"runner\")\n        package = pytester.mkdir(\"package\")\n        package.joinpath(\"conftest.py\").write_text(\n            textwrap.dedent(\n                \"\"\"\\\n            import pytest\n            @pytest.fixture\n            def one():\n                return 1\n            \"\"\"\n            ),\n            encoding=\"utf-8\",\n        )\n        package.joinpath(\"test_x.py\").write_text(\n            textwrap.dedent(\n                \"\"\"\\\n                def test_x(one):\n                    assert one == 1\n                \"\"\"\n            ),\n            encoding=\"utf-8\",\n        )\n        sub = package.joinpath(\"s"}, {"start_line": 74000, "end_line": 76000, "belongs_to": {"file_name": "fixtures.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": " and argname.startswith(\"_\"):\n            return\n        prettypath = _pretty_fixture_path(invocation_dir, fixture_def.func)\n        tw.write(f\"{argname}\", green=True)\n        tw.write(f\" -- {prettypath}\", yellow=True)\n        tw.write(\"\\n\")\n        fixture_doc = inspect.getdoc(fixture_def.func)\n        if fixture_doc:\n            write_docstring(\n                tw,\n                fixture_doc.split(\"\\n\\n\", maxsplit=1)[0]\n                if verbose <= 0\n                else fixture_doc,\n            )\n        else:\n            tw.line(\"    no docstring available\", red=True)\n\n    def write_item(item: nodes.Item) -> None:\n        # Not all items have _fixtureinfo attribute.\n        info: FuncFixtureInfo | None = getattr(item, \"_fixtureinfo\", None)\n        if info is None or not info.name2fixturedefs:\n            # This test item does not use any fixtures.\n            return\n        tw.line()\n        tw.sep(\"-\", f\"fixtures used by {item.name}\")\n        # TODO: Fix this type ignore.\n        tw.sep(\"-\", f\"({get_best_relpath(item.function)})\")  # type: ignore[attr-defined]\n        # dict key not used in loop but needed for sorting.\n        for _, fixturedefs in sorted(info.name2fixturedefs.items()):\n            assert fixturedefs is not None\n            if not fixturedefs:\n                continue\n            # Last item is expected to be the one used by the test item.\n            write_fixture(fixturedefs[-1])\n\n    for session_item in session.items:\n        write_item(session_item)\n\n\ndef showfixtures(config: Config) -> int | ExitCode:\n    from _pytest.main import wrap_session\n\n    return wrap_session(config, _showfixtures_main)\n\n\ndef _showfixtures_main(config: Config, session: Session) -> None:\n    import _pytest.config\n\n    session.perform_collect()\n    invocation_dir = config.invocation_params.dir\n    tw = _pytest.config.create_terminal_writer(config)\n    verbose = config.get_verbosity()\n\n    fm = session._fixturemanager\n\n    available = []\n    seen: set[tuple[str, str"}, {"start_line": 0, "end_line": 2000, "belongs_to": {"file_name": "__init__.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "# PYTHON_ARGCOMPLETE_OK\n\"\"\"pytest: unit and functional testing with Python.\"\"\"\n\nfrom __future__ import annotations\n\nfrom _pytest import __version__\nfrom _pytest import version_tuple\nfrom _pytest._code import ExceptionInfo\nfrom _pytest.assertion import register_assert_rewrite\nfrom _pytest.cacheprovider import Cache\nfrom _pytest.capture import CaptureFixture\nfrom _pytest.config import cmdline\nfrom _pytest.config import Config\nfrom _pytest.config import console_main\nfrom _pytest.config import ExitCode\nfrom _pytest.config import hookimpl\nfrom _pytest.config import hookspec\nfrom _pytest.config import main\nfrom _pytest.config import PytestPluginManager\nfrom _pytest.config import UsageError\nfrom _pytest.config.argparsing import OptionGroup\nfrom _pytest.config.argparsing import Parser\nfrom _pytest.debugging import pytestPDB as __pytestPDB\nfrom _pytest.doctest import DoctestItem\nfrom _pytest.fixtures import fixture\nfrom _pytest.fixtures import FixtureDef\nfrom _pytest.fixtures import FixtureLookupError\nfrom _pytest.fixtures import FixtureRequest\nfrom _pytest.fixtures import yield_fixture\nfrom _pytest.freeze_support import freeze_includes\nfrom _pytest.legacypath import TempdirFactory\nfrom _pytest.legacypath import Testdir\nfrom _pytest.logging import LogCaptureFixture\nfrom _pytest.main import Dir\nfrom _pytest.main import Session\nfrom _pytest.mark import HIDDEN_PARAM\nfrom _pytest.mark import Mark\nfrom _pytest.mark import MARK_GEN as mark\nfrom _pytest.mark import MarkDecorator\nfrom _pytest.mark import MarkGenerator\nfrom _pytest.mark import param\nfrom _pytest.monkeypatch import MonkeyPatch\nfrom _pytest.nodes import Collector\nfrom _pytest.nodes import Directory\nfrom _pytest.nodes import File\nfrom _pytest.nodes import Item\nfrom _pytest.outcomes import exit\nfrom _pytest.outcomes import fail\nfrom _pytest.outcomes import importorskip\nfrom _pytest.outcomes import skip\nfrom _pytest.outcomes import xfail\nfrom _pytest.pytester import HookRecorder\nfrom _pytest.pytester import LineMatcher\nfr"}, {"start_line": 33000, "end_line": 35000, "belongs_to": {"file_name": "fixtures.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing/python", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "rt values == [\"module\", \"function\", \"class\",\n                             \"function\", \"method\", \"function\"]\n        \"\"\"\n        )\n        reprec = pytester.inline_run(\"-v\")\n        reprec.assertoutcome(passed=3)\n\n    def test_fixtures_sub_subdir_normalize_sep(self, pytester: Pytester) -> None:\n        # this tests that normalization of nodeids takes place\n        b = pytester.path.joinpath(\"tests\", \"unit\")\n        b.mkdir(parents=True)\n        b.joinpath(\"conftest.py\").write_text(\n            textwrap.dedent(\n                \"\"\"\\\n                import pytest\n                @pytest.fixture\n                def arg1():\n                    pass\n                \"\"\"\n            ),\n            encoding=\"utf-8\",\n        )\n        p = b.joinpath(\"test_module.py\")\n        p.write_text(\"def test_func(arg1): pass\", encoding=\"utf-8\")\n        result = pytester.runpytest(p, \"--fixtures\")\n        assert result.ret == 0\n        result.stdout.fnmatch_lines(\n            \"\"\"\n            *fixtures defined*conftest*\n            *arg1*\n        \"\"\"\n        )\n\n    def test_show_fixtures_color_yes(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\"def test_this(): assert 1\")\n        result = pytester.runpytest(\"--color=yes\", \"--fixtures\")\n        assert \"\\x1b[32mtmp_path\" in result.stdout.str()\n\n    def test_newstyle_with_request(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n            @pytest.fixture()\n            def arg(request):\n                pass\n            def test_1(arg):\n                pass\n        \"\"\"\n        )\n        reprec = pytester.inline_run()\n        reprec.assertoutcome(passed=1)\n\n    def test_setupcontext_no_param(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n            @pytest.fixture(params=[1,2])\n            def arg(request):\n                return request.param\n\n            @pytest.fixture(autouse=True)\n            def mysetup(requ"}], "retrieved_count": 10, "cost_time": 0.3369481563568115}
{"question": "How does Pytest's design facilitate integration with other development tools?", "answer": null, "relative_code_list": null, "ground_truth": "Pytest's design facilitates integration with other development tools through multiple architectural and design choices: 1) Command-line interface that follows standard conventions and can be easily invoked from build systems, CI/CD pipelines, and IDEs, 2) Exit code system that provides clear success/failure indicators for automated systems to interpret test results, 3) Plugin architecture that allows third-party tools to extend pytest functionality through hooks and custom plugins, 4) Configuration system that supports multiple file formats (pytest.ini, pyproject.toml, tox.ini, setup.cfg) for integration with different build tools, 5) JUnit XML reporting through the junitxml plugin that enables integration with CI/CD systems like Jenkins, GitLab CI, and GitHub Actions, 6) Environment variable support (PYTEST_ADDOPTS, PYTEST_PLUGINS) for configuration without file modification, 7) Python API through pytest.main() function that allows programmatic execution from other Python tools, 8) Modular fixture system that enables sharing test resources and setup across different tools and frameworks, 9) Standard test discovery conventions that work with most Python project structures, 10) Support for running existing unittest test suites without modification, enabling gradual migration from other testing frameworks, 11) Rich plugin ecosystem with over 1300+ external plugins that provide integrations with specific tools and frameworks, 12) Documentation and examples for integration with popular tools like tox, pre-commit, and various CI/CD platforms.", "score": null, "retrieved_content": [{"start_line": 15000, "end_line": 17000, "belongs_to": {"file_name": "pytester.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "during initialization.\n\n    It is particularly useful for testing plugins. It is similar to the :fixture:`tmp_path`\n    fixture but provides methods which aid in testing pytest itself.\n    \"\"\"\n    return Pytester(request, tmp_path_factory, monkeypatch, _ispytest=True)\n\n\n@fixture\ndef _sys_snapshot() -> Generator[None]:\n    snappaths = SysPathsSnapshot()\n    snapmods = SysModulesSnapshot()\n    yield\n    snapmods.restore()\n    snappaths.restore()\n\n\n@fixture\ndef _config_for_test() -> Generator[Config]:\n    from _pytest.config import get_config\n\n    config = get_config()\n    yield config\n    config._ensure_unconfigure()  # cleanup, e.g. capman closing tmpfiles.\n\n\n# Regex to match the session duration string in the summary: \"74.34s\".\nrex_session_duration = re.compile(r\"\\d+\\.\\d\\ds\")\n# Regex to match all the counts and phrases in the summary line: \"34 passed, 111 skipped\".\nrex_outcome = re.compile(r\"(\\d+) (\\w+)\")\n\n\n@final\nclass RunResult:\n    \"\"\"The result of running a command from :class:`~pytest.Pytester`.\"\"\"\n\n    def __init__(\n        self,\n        ret: int | ExitCode,\n        outlines: list[str],\n        errlines: list[str],\n        duration: float,\n    ) -> None:\n        try:\n            self.ret: int | ExitCode = ExitCode(ret)\n            \"\"\"The return value.\"\"\"\n        except ValueError:\n            self.ret = ret\n        self.outlines = outlines\n        \"\"\"List of lines captured from stdout.\"\"\"\n        self.errlines = errlines\n        \"\"\"List of lines captured from stderr.\"\"\"\n        self.stdout = LineMatcher(outlines)\n        \"\"\":class:`~pytest.LineMatcher` of stdout.\n\n        Use e.g. :func:`str(stdout) <pytest.LineMatcher.__str__()>` to reconstruct stdout, or the commonly used\n        :func:`stdout.fnmatch_lines() <pytest.LineMatcher.fnmatch_lines()>` method.\n        \"\"\"\n        self.stderr = LineMatcher(errlines)\n        \"\"\":class:`~pytest.LineMatcher` of stderr.\"\"\"\n        self.duration = duration\n        \"\"\"Duration in seconds.\"\"\"\n\n    def __repr__(self) -> st"}, {"start_line": 3000, "end_line": 4297, "belongs_to": {"file_name": "test_helpconfig.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "None:\n    pytester.makeconftest(\n        \"\"\"\n        def pytest_hello(xyz):\n            pass\n    \"\"\"\n    )\n    result = pytester.runpytest()\n    assert result.ret != 0\n    result.stdout.fnmatch_lines([\"*unknown hook*pytest_hello*\"])\n\n\ndef test_hookvalidation_optional(pytester: Pytester) -> None:\n    pytester.makeconftest(\n        \"\"\"\n        import pytest\n        @pytest.hookimpl(optionalhook=True)\n        def pytest_hello(xyz):\n            pass\n    \"\"\"\n    )\n    result = pytester.runpytest()\n    assert result.ret == ExitCode.NO_TESTS_COLLECTED\n\n\ndef test_traceconfig(pytester: Pytester) -> None:\n    result = pytester.runpytest(\"--traceconfig\")\n    result.stdout.fnmatch_lines([\"*using*pytest*\", \"*active plugins*\"])\n\n\ndef test_debug(pytester: Pytester) -> None:\n    result = pytester.runpytest_subprocess(\"--debug\")\n    assert result.ret == ExitCode.NO_TESTS_COLLECTED\n    p = pytester.path.joinpath(\"pytestdebug.log\")\n    assert \"pytest_sessionstart\" in p.read_text(\"utf-8\")\n\n\ndef test_PYTEST_DEBUG(pytester: Pytester, monkeypatch) -> None:\n    monkeypatch.setenv(\"PYTEST_DEBUG\", \"1\")\n    result = pytester.runpytest_subprocess()\n    assert result.ret == ExitCode.NO_TESTS_COLLECTED\n    result.stderr.fnmatch_lines(\n        [\"*pytest_plugin_registered*\", \"*manager*PluginManager*\"]\n    )\n"}, {"start_line": 1000, "end_line": 3000, "belongs_to": {"file_name": "pytester.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "t.compat import NOTSET\nfrom _pytest.compat import NotSetType\nfrom _pytest.config import _PluggyPlugin\nfrom _pytest.config import Config\nfrom _pytest.config import ExitCode\nfrom _pytest.config import hookimpl\nfrom _pytest.config import main\nfrom _pytest.config import PytestPluginManager\nfrom _pytest.config.argparsing import Parser\nfrom _pytest.deprecated import check_ispytest\nfrom _pytest.fixtures import fixture\nfrom _pytest.fixtures import FixtureRequest\nfrom _pytest.main import Session\nfrom _pytest.monkeypatch import MonkeyPatch\nfrom _pytest.nodes import Collector\nfrom _pytest.nodes import Item\nfrom _pytest.outcomes import fail\nfrom _pytest.outcomes import importorskip\nfrom _pytest.outcomes import skip\nfrom _pytest.pathlib import bestrelpath\nfrom _pytest.pathlib import make_numbered_dir\nfrom _pytest.reports import CollectReport\nfrom _pytest.reports import TestReport\nfrom _pytest.tmpdir import TempPathFactory\nfrom _pytest.warning_types import PytestFDWarning\n\n\nif TYPE_CHECKING:\n    import pexpect\n\n\npytest_plugins = [\"pytester_assertions\"]\n\n\nIGNORE_PAM = [  # filenames added when obtaining details about the current user\n    \"/var/lib/sss/mc/passwd\"\n]\n\n\ndef pytest_addoption(parser: Parser) -> None:\n    parser.addoption(\n        \"--lsof\",\n        action=\"store_true\",\n        dest=\"lsof\",\n        default=False,\n        help=\"Run FD checks if lsof is available\",\n    )\n\n    parser.addoption(\n        \"--runpytest\",\n        default=\"inprocess\",\n        dest=\"runpytest\",\n        choices=(\"inprocess\", \"subprocess\"),\n        help=(\n            \"Run pytest sub runs in tests using an 'inprocess' \"\n            \"or 'subprocess' (python -m main) method\"\n        ),\n    )\n\n    parser.addini(\n        \"pytester_example_dir\", help=\"Directory to take the pytester example files from\"\n    )\n\n\ndef pytest_configure(config: Config) -> None:\n    if config.getvalue(\"lsof\"):\n        checker = LsofFdLeakChecker()\n        if checker.matching_platform():\n            config.pluginmanager.register(ch"}, {"start_line": 1000, "end_line": 3000, "belongs_to": {"file_name": "test_pytester.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "alse\n        failed = True\n        skipped = False\n        when = \"call\"\n\n    recorder.hook.pytest_runtest_logreport(report=rep)  # type: ignore[attr-defined]\n    failures = recorder.getfailures()\n    assert failures == [rep]  # type: ignore[comparison-overlap]\n    failures = recorder.getfailures()\n    assert failures == [rep]  # type: ignore[comparison-overlap]\n\n    class rep2:\n        excinfo = None\n        passed = False\n        failed = False\n        skipped = True\n        when = \"call\"\n\n    rep2.passed = False\n    rep2.skipped = True\n    recorder.hook.pytest_runtest_logreport(report=rep2)  # type: ignore[attr-defined]\n\n    modcol = pytester.getmodulecol(\"\")\n    rep3 = modcol.config.hook.pytest_make_collect_report(collector=modcol)\n    rep3.passed = False\n    rep3.failed = True\n    rep3.skipped = False\n    recorder.hook.pytest_collectreport(report=rep3)  # type: ignore[attr-defined]\n\n    passed, skipped, failed = recorder.listoutcomes()\n    assert not passed and skipped and failed\n\n    numpassed, numskipped, numfailed = recorder.countoutcomes()\n    assert numpassed == 0\n    assert numskipped == 1\n    assert numfailed == 1\n    assert len(recorder.getfailedcollections()) == 1\n\n    recorder.unregister()  # type: ignore[attr-defined]\n    recorder.clear()\n    recorder.hook.pytest_runtest_logreport(report=rep3)  # type: ignore[attr-defined]\n    pytest.raises(ValueError, recorder.getfailures)\n\n\ndef test_parseconfig(pytester: Pytester) -> None:\n    config1 = pytester.parseconfig()\n    config2 = pytester.parseconfig()\n    assert config2 is not config1\n\n\ndef test_pytester_runs_with_plugin(pytester: Pytester) -> None:\n    pytester.makepyfile(\n        \"\"\"\n        pytest_plugins = \"pytester\"\n        def test_hello(pytester):\n            assert 1\n    \"\"\"\n    )\n    result = pytester.runpytest()\n    result.assert_outcomes(passed=1)\n\n\ndef test_pytester_with_doctest(pytester: Pytester) -> None:\n    \"\"\"Check that pytester can be used within doctests.\n\n    It used to use `request.f"}, {"start_line": 2000, "end_line": 4000, "belongs_to": {"file_name": "__init__.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest/config", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "\n\n\nif TYPE_CHECKING:\n    from _pytest.assertion.rewrite import AssertionRewritingHook\n    from _pytest.cacheprovider import Cache\n    from _pytest.terminal import TerminalReporter\n\n_PluggyPlugin = object\n\"\"\"A type to represent plugin objects.\n\nPlugins can be any namespace, so we can't narrow it down much, but we use an\nalias to make the intent clear.\n\nIdeally this type would be provided by pluggy itself.\n\"\"\"\n\n\nhookimpl = HookimplMarker(\"pytest\")\nhookspec = HookspecMarker(\"pytest\")\n\n\n@final\nclass ExitCode(enum.IntEnum):\n    \"\"\"Encodes the valid exit codes by pytest.\n\n    Currently users and plugins may supply other exit codes as well.\n\n    .. versionadded:: 5.0\n    \"\"\"\n\n    #: Tests passed.\n    OK = 0\n    #: Tests failed.\n    TESTS_FAILED = 1\n    #: pytest was interrupted.\n    INTERRUPTED = 2\n    #: An internal error got in the way.\n    INTERNAL_ERROR = 3\n    #: pytest was misused.\n    USAGE_ERROR = 4\n    #: pytest couldn't find tests.\n    NO_TESTS_COLLECTED = 5\n\n\nclass ConftestImportFailure(Exception):\n    def __init__(\n        self,\n        path: pathlib.Path,\n        *,\n        cause: Exception,\n    ) -> None:\n        self.path = path\n        self.cause = cause\n\n    def __str__(self) -> str:\n        return f\"{type(self.cause).__name__}: {self.cause} (from {self.path})\"\n\n\ndef filter_traceback_for_conftest_import_failure(\n    entry: _pytest._code.TracebackEntry,\n) -> bool:\n    \"\"\"Filter tracebacks entries which point to pytest internals or importlib.\n\n    Make a special case for importlib because we use it to import test modules and conftest files\n    in _pytest.pathlib.import_path.\n    \"\"\"\n    return filter_traceback(entry) and \"importlib\" not in str(entry.path).split(os.sep)\n\n\ndef main(\n    args: list[str] | os.PathLike[str] | None = None,\n    plugins: Sequence[str | _PluggyPlugin] | None = None,\n) -> int | ExitCode:\n    \"\"\"Perform an in-process test run.\n\n    :param args:\n        List of command line arguments. If `None` or not given, defaults to reading\n        "}, {"start_line": 0, "end_line": 154, "belongs_to": {"file_name": "__main__.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "\"\"\"The pytest entry point.\"\"\"\n\nfrom __future__ import annotations\n\nimport pytest\n\n\nif __name__ == \"__main__\":\n    raise SystemExit(pytest.console_main())\n"}, {"start_line": 20000, "end_line": 22000, "belongs_to": {"file_name": "acceptance_test.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": " test_earlyinit(self, pytester: Pytester) -> None:\n        p = pytester.makepyfile(\n            \"\"\"\n            import pytest\n            assert hasattr(pytest, 'mark')\n        \"\"\"\n        )\n        result = pytester.runpython(p)\n        assert result.ret == 0\n\n    def test_pydoc(self, pytester: Pytester) -> None:\n        result = pytester.runpython_c(\"import pytest;help(pytest)\")\n        assert result.ret == 0\n        s = result.stdout.str()\n        assert \"MarkGenerator\" in s\n\n    def test_import_star_pytest(self, pytester: Pytester) -> None:\n        p = pytester.makepyfile(\n            \"\"\"\n            from pytest import *\n            #Item\n            #File\n            main\n            skip\n            xfail\n        \"\"\"\n        )\n        result = pytester.runpython(p)\n        assert result.ret == 0\n\n    def test_double_pytestcmdline(self, pytester: Pytester) -> None:\n        p = pytester.makepyfile(\n            run=\"\"\"\n            import pytest\n            pytest.main()\n            pytest.main()\n        \"\"\"\n        )\n        pytester.makepyfile(\n            \"\"\"\n            def test_hello():\n                pass\n        \"\"\"\n        )\n        result = pytester.runpython(p)\n        result.stdout.fnmatch_lines([\"*1 passed*\", \"*1 passed*\"])\n\n    def test_python_minus_m_invocation_ok(self, pytester: Pytester) -> None:\n        p1 = pytester.makepyfile(\"def test_hello(): pass\")\n        res = pytester.run(sys.executable, \"-m\", \"pytest\", str(p1))\n        assert res.ret == 0\n\n    def test_python_minus_m_invocation_fail(self, pytester: Pytester) -> None:\n        p1 = pytester.makepyfile(\"def test_fail(): 0/0\")\n        res = pytester.run(sys.executable, \"-m\", \"pytest\", str(p1))\n        assert res.ret == 1\n\n    def test_python_pytest_package(self, pytester: Pytester) -> None:\n        p1 = pytester.makepyfile(\"def test_pass(): pass\")\n        res = pytester.run(sys.executable, \"-m\", \"pytest\", str(p1))\n        assert res.ret == 0\n        res.stdout.fnmatch_lines([\"*1 passed*\"])\n\n"}, {"start_line": 2000, "end_line": 4000, "belongs_to": {"file_name": "acceptance_test.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "> None:\n        pytester.makeconftest(\n            \"\"\"\n            def pytest_configure():\n                0 / 0\n        \"\"\"\n        )\n        result = pytester.runpytest(pytester.path)\n        assert result.ret != 0\n        # here we get it on stderr\n        result.stderr.fnmatch_lines(\n            [\"*INTERNALERROR*File*conftest.py*line 2*\", \"*0 / 0*\"]\n        )\n\n    def test_file_not_found(self, pytester: Pytester) -> None:\n        result = pytester.runpytest(\"asd\")\n        assert result.ret != 0\n        result.stderr.fnmatch_lines([\"ERROR: file or directory not found: asd\"])\n\n    def test_file_not_found_unconfigure_issue143(self, pytester: Pytester) -> None:\n        pytester.makeconftest(\n            \"\"\"\n            def pytest_configure():\n                print(\"---configure\")\n            def pytest_unconfigure():\n                print(\"---unconfigure\")\n        \"\"\"\n        )\n        result = pytester.runpytest(\"-s\", \"asd\")\n        assert result.ret == ExitCode.USAGE_ERROR\n        result.stderr.fnmatch_lines([\"ERROR: file or directory not found: asd\"])\n        result.stdout.fnmatch_lines([\"*---configure\", \"*---unconfigure\"])\n\n    def test_config_preparse_plugin_option(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            pytest_xyz=\"\"\"\n            def pytest_addoption(parser):\n                parser.addoption(\"--xyz\", dest=\"xyz\", action=\"store\")\n        \"\"\"\n        )\n        pytester.makepyfile(\n            test_one=\"\"\"\n            def test_option(pytestconfig):\n                assert pytestconfig.option.xyz == \"123\"\n        \"\"\"\n        )\n        result = pytester.runpytest(\"-p\", \"pytest_xyz\", \"--xyz=123\", syspathinsert=True)\n        assert result.ret == 0\n        result.stdout.fnmatch_lines([\"*1 passed*\"])\n\n    @pytest.mark.parametrize(\"load_cov_early\", [True, False])\n    def test_early_load_setuptools_name(\n        self, pytester: Pytester, monkeypatch, load_cov_early\n    ) -> None:\n        monkeypatch.delenv(\"PYTEST_DISABLE_PLUGIN_AUTOLOAD"}, {"start_line": 0, "end_line": 2000, "belongs_to": {"file_name": "__init__.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "# PYTHON_ARGCOMPLETE_OK\n\"\"\"pytest: unit and functional testing with Python.\"\"\"\n\nfrom __future__ import annotations\n\nfrom _pytest import __version__\nfrom _pytest import version_tuple\nfrom _pytest._code import ExceptionInfo\nfrom _pytest.assertion import register_assert_rewrite\nfrom _pytest.cacheprovider import Cache\nfrom _pytest.capture import CaptureFixture\nfrom _pytest.config import cmdline\nfrom _pytest.config import Config\nfrom _pytest.config import console_main\nfrom _pytest.config import ExitCode\nfrom _pytest.config import hookimpl\nfrom _pytest.config import hookspec\nfrom _pytest.config import main\nfrom _pytest.config import PytestPluginManager\nfrom _pytest.config import UsageError\nfrom _pytest.config.argparsing import OptionGroup\nfrom _pytest.config.argparsing import Parser\nfrom _pytest.debugging import pytestPDB as __pytestPDB\nfrom _pytest.doctest import DoctestItem\nfrom _pytest.fixtures import fixture\nfrom _pytest.fixtures import FixtureDef\nfrom _pytest.fixtures import FixtureLookupError\nfrom _pytest.fixtures import FixtureRequest\nfrom _pytest.fixtures import yield_fixture\nfrom _pytest.freeze_support import freeze_includes\nfrom _pytest.legacypath import TempdirFactory\nfrom _pytest.legacypath import Testdir\nfrom _pytest.logging import LogCaptureFixture\nfrom _pytest.main import Dir\nfrom _pytest.main import Session\nfrom _pytest.mark import HIDDEN_PARAM\nfrom _pytest.mark import Mark\nfrom _pytest.mark import MARK_GEN as mark\nfrom _pytest.mark import MarkDecorator\nfrom _pytest.mark import MarkGenerator\nfrom _pytest.mark import param\nfrom _pytest.monkeypatch import MonkeyPatch\nfrom _pytest.nodes import Collector\nfrom _pytest.nodes import Directory\nfrom _pytest.nodes import File\nfrom _pytest.nodes import Item\nfrom _pytest.outcomes import exit\nfrom _pytest.outcomes import fail\nfrom _pytest.outcomes import importorskip\nfrom _pytest.outcomes import skip\nfrom _pytest.outcomes import xfail\nfrom _pytest.pytester import HookRecorder\nfrom _pytest.pytester import LineMatcher\nfr"}, {"start_line": 6000, "end_line": 8000, "belongs_to": {"file_name": "legacypath.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "ugins, no_reraise_ctrlc=no_reraise_ctrlc\n        )\n\n    def runpytest_inprocess(self, *args, **kwargs) -> RunResult:\n        \"\"\"See :meth:`Pytester.runpytest_inprocess`.\"\"\"\n        return self._pytester.runpytest_inprocess(*args, **kwargs)\n\n    def runpytest(self, *args, **kwargs) -> RunResult:\n        \"\"\"See :meth:`Pytester.runpytest`.\"\"\"\n        return self._pytester.runpytest(*args, **kwargs)\n\n    def parseconfig(self, *args) -> Config:\n        \"\"\"See :meth:`Pytester.parseconfig`.\"\"\"\n        return self._pytester.parseconfig(*args)\n\n    def parseconfigure(self, *args) -> Config:\n        \"\"\"See :meth:`Pytester.parseconfigure`.\"\"\"\n        return self._pytester.parseconfigure(*args)\n\n    def getitem(self, source, funcname=\"test_func\"):\n        \"\"\"See :meth:`Pytester.getitem`.\"\"\"\n        return self._pytester.getitem(source, funcname)\n\n    def getitems(self, source):\n        \"\"\"See :meth:`Pytester.getitems`.\"\"\"\n        return self._pytester.getitems(source)\n\n    def getmodulecol(self, source, configargs=(), withinit=False):\n        \"\"\"See :meth:`Pytester.getmodulecol`.\"\"\"\n        return self._pytester.getmodulecol(\n            source, configargs=configargs, withinit=withinit\n        )\n\n    def collect_by_name(self, modcol: Collector, name: str) -> Item | Collector | None:\n        \"\"\"See :meth:`Pytester.collect_by_name`.\"\"\"\n        return self._pytester.collect_by_name(modcol, name)\n\n    def popen(\n        self,\n        cmdargs,\n        stdout=subprocess.PIPE,\n        stderr=subprocess.PIPE,\n        stdin=CLOSE_STDIN,\n        **kw,\n    ):\n        \"\"\"See :meth:`Pytester.popen`.\"\"\"\n        return self._pytester.popen(cmdargs, stdout, stderr, stdin, **kw)\n\n    def run(self, *cmdargs, timeout=None, stdin=CLOSE_STDIN) -> RunResult:\n        \"\"\"See :meth:`Pytester.run`.\"\"\"\n        return self._pytester.run(*cmdargs, timeout=timeout, stdin=stdin)\n\n    def runpython(self, script) -> RunResult:\n        \"\"\"See :meth:`Pytester.runpython`.\"\"\"\n        return self._pytester.runpytho"}], "retrieved_count": 10, "cost_time": 0.32577991485595703}
{"question": "How does Pytest implement its plugin architecture for extensibility?", "answer": null, "relative_code_list": null, "ground_truth": "Pytest implements its plugin architecture for extensibility through a comprehensive hook-based system built on the pluggy library: 1) Hook specification system where all pytest functionality is defined through hook specifications in src/_pytest/hookspec.py using the @hookspec decorator, 2) Plugin manager (PytestPluginManager) that extends pluggy.PluginManager to handle pytest-specific plugin loading and discovery, 3) Multiple plugin types including built-in plugins (stored in src/_pytest/), external plugins (discovered through entry points), and local conftest.py plugins (auto-discovered in test directories), 4) Plugin discovery order that loads plugins in a specific sequence: command line blocking, built-in plugins, external plugins, environment variables, and conftest files, 5) Hook implementation system where plugins implement hook functions with the @hookimpl decorator to provide functionality, 6) 1:N relationship where multiple plugins can implement the same hook specification, with execution order controlled by tryfirst/trylast markers, 7) Hook wrappers that execute around other hook implementations for cross-cutting functionality, 8) Plugin registration through entry points in pyproject.toml or setup.py for external plugins, 9) Local plugin support through conftest.py files that can be placed in any directory for directory-specific functionality, 10) Plugin communication through the config object and stash mechanism for sharing data between plugins, 11) Plugin validation and error handling with proper cleanup mechanisms, 12) Backward compatibility through dynamic argument pruning that allows new hook parameters without breaking existing implementations.", "score": null, "retrieved_content": [{"start_line": 11000, "end_line": 13000, "belongs_to": {"file_name": "__init__.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest/config", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "ed.HOOK_LEGACY_MARKING.format(\n            type=hook_type,\n            fullname=method.__qualname__,\n            hook_opts=hook_opts,\n        )\n        warn_explicit_for(cast(FunctionType, method), message)\n    return opts\n\n\n@final\nclass PytestPluginManager(PluginManager):\n    \"\"\"A :py:class:`pluggy.PluginManager <pluggy.PluginManager>` with\n    additional pytest-specific functionality:\n\n    * Loading plugins from the command line, ``PYTEST_PLUGINS`` env variable and\n      ``pytest_plugins`` global variables found in plugins being loaded.\n    * ``conftest.py`` loading during start-up.\n    \"\"\"\n\n    def __init__(self) -> None:\n        from _pytest.assertion import DummyRewriteHook\n        from _pytest.assertion import RewriteHook\n\n        super().__init__(\"pytest\")\n\n        # -- State related to local conftest plugins.\n        # All loaded conftest modules.\n        self._conftest_plugins: set[types.ModuleType] = set()\n        # All conftest modules applicable for a directory.\n        # This includes the directory's own conftest modules as well\n        # as those of its parent directories.\n        self._dirpath2confmods: dict[pathlib.Path, list[types.ModuleType]] = {}\n        # Cutoff directory above which conftests are no longer discovered.\n        self._confcutdir: pathlib.Path | None = None\n        # If set, conftest loading is skipped.\n        self._noconftest = False\n\n        # _getconftestmodules()'s call to _get_directory() causes a stat\n        # storm when it's called potentially thousands of times in a test\n        # session (#9478), often with the same path, so cache it.\n        self._get_directory = lru_cache(256)(_get_directory)\n\n        # plugins that were explicitly skipped with pytest.skip\n        # list of (module name, skip reason)\n        # previously we would issue a warning when a plugin was skipped, but\n        # since we refactored warnings as first citizens of Config, they are\n        # just stored here to be used later.\n        self.skipped_plu"}, {"start_line": 3000, "end_line": 5000, "belongs_to": {"file_name": "acceptance_test.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "sult.stderr.fnmatch_lines([\"ERROR: file or directory not found: asd\"])\n        result.stdout.fnmatch_lines([\"*---configure\", \"*---unconfigure\"])\n\n    def test_config_preparse_plugin_option(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            pytest_xyz=\"\"\"\n            def pytest_addoption(parser):\n                parser.addoption(\"--xyz\", dest=\"xyz\", action=\"store\")\n        \"\"\"\n        )\n        pytester.makepyfile(\n            test_one=\"\"\"\n            def test_option(pytestconfig):\n                assert pytestconfig.option.xyz == \"123\"\n        \"\"\"\n        )\n        result = pytester.runpytest(\"-p\", \"pytest_xyz\", \"--xyz=123\", syspathinsert=True)\n        assert result.ret == 0\n        result.stdout.fnmatch_lines([\"*1 passed*\"])\n\n    @pytest.mark.parametrize(\"load_cov_early\", [True, False])\n    def test_early_load_setuptools_name(\n        self, pytester: Pytester, monkeypatch, load_cov_early\n    ) -> None:\n        monkeypatch.delenv(\"PYTEST_DISABLE_PLUGIN_AUTOLOAD\")\n\n        pytester.makepyfile(mytestplugin1_module=\"\")\n        pytester.makepyfile(mytestplugin2_module=\"\")\n        pytester.makepyfile(mycov_module=\"\")\n        pytester.syspathinsert()\n\n        loaded = []\n\n        @dataclasses.dataclass\n        class DummyEntryPoint:\n            name: str\n            module: str\n            group: str = \"pytest11\"\n\n            def load(self):\n                __import__(self.module)\n                loaded.append(self.name)\n                return sys.modules[self.module]\n\n        entry_points = [\n            DummyEntryPoint(\"myplugin1\", \"mytestplugin1_module\"),\n            DummyEntryPoint(\"myplugin2\", \"mytestplugin2_module\"),\n            DummyEntryPoint(\"mycov\", \"mycov_module\"),\n        ]\n\n        @dataclasses.dataclass\n        class DummyDist:\n            entry_points: object\n            files: object = ()\n\n        def my_dists():\n            return (DummyDist(entry_points),)\n\n        monkeypatch.setattr(importlib.metadata, \"distributions\", my_dists"}, {"start_line": 13000, "end_line": 15000, "belongs_to": {"file_name": "__init__.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest/config", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "gins: list[tuple[str, str]] = []\n\n        self.add_hookspecs(_pytest.hookspec)\n        self.register(self)\n        if os.environ.get(\"PYTEST_DEBUG\"):\n            err: IO[str] = sys.stderr\n            encoding: str = getattr(err, \"encoding\", \"utf8\")\n            try:\n                err = open(\n                    os.dup(err.fileno()),\n                    mode=err.mode,\n                    buffering=1,\n                    encoding=encoding,\n                )\n            except Exception:\n                pass\n            self.trace.root.setwriter(err.write)\n            self.enable_tracing()\n\n        # Config._consider_importhook will set a real object if required.\n        self.rewrite_hook: RewriteHook = DummyRewriteHook()\n        # Used to know when we are importing conftests after the pytest_configure stage.\n        self._configured = False\n\n    def parse_hookimpl_opts(\n        self, plugin: _PluggyPlugin, name: str\n    ) -> HookimplOpts | None:\n        \"\"\":meta private:\"\"\"\n        # pytest hooks are always prefixed with \"pytest_\",\n        # so we avoid accessing possibly non-readable attributes\n        # (see issue #1073).\n        if not name.startswith(\"pytest_\"):\n            return None\n        # Ignore names which cannot be hooks.\n        if name == \"pytest_plugins\":\n            return None\n\n        opts = super().parse_hookimpl_opts(plugin, name)\n        if opts is not None:\n            return opts\n\n        method = getattr(plugin, name)\n        # Consider only actual functions for hooks (#3775).\n        if not inspect.isroutine(method):\n            return None\n        # Collect unmarked hooks as long as they have the `pytest_' prefix.\n        legacy = _get_legacy_hook_marks(\n            method, \"impl\", (\"tryfirst\", \"trylast\", \"optionalhook\", \"hookwrapper\")\n        )\n        return cast(HookimplOpts, legacy)\n\n    def parse_hookspec_opts(self, module_or_class, name: str) -> HookspecOpts | None:\n        \"\"\":meta private:\"\"\"\n        opts = super().parse_hookspec_op"}, {"start_line": 1000, "end_line": 3000, "belongs_to": {"file_name": "hookspec.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "  from _pytest.nodes import Collector\n    from _pytest.nodes import Item\n    from _pytest.outcomes import Exit\n    from _pytest.python import Class\n    from _pytest.python import Function\n    from _pytest.python import Metafunc\n    from _pytest.python import Module\n    from _pytest.reports import CollectReport\n    from _pytest.reports import TestReport\n    from _pytest.runner import CallInfo\n    from _pytest.terminal import TerminalReporter\n    from _pytest.terminal import TestShortLogReport\n\n\nhookspec = HookspecMarker(\"pytest\")\n\n# -------------------------------------------------------------------------\n# Initialization hooks called for every plugin\n# -------------------------------------------------------------------------\n\n\n@hookspec(historic=True)\ndef pytest_addhooks(pluginmanager: PytestPluginManager) -> None:\n    \"\"\"Called at plugin registration time to allow adding new hooks via a call to\n    :func:`pluginmanager.add_hookspecs(module_or_class, prefix) <pytest.PytestPluginManager.add_hookspecs>`.\n\n    :param pluginmanager: The pytest plugin manager.\n\n    .. note::\n        This hook is incompatible with hook wrappers.\n\n    Use in conftest plugins\n    =======================\n\n    If a conftest plugin implements this hook, it will be called immediately\n    when the conftest is registered.\n    \"\"\"\n\n\n@hookspec(historic=True)\ndef pytest_plugin_registered(\n    plugin: _PluggyPlugin,\n    plugin_name: str,\n    manager: PytestPluginManager,\n) -> None:\n    \"\"\"A new pytest plugin got registered.\n\n    :param plugin: The plugin module or instance.\n    :param plugin_name: The name by which the plugin is registered.\n    :param manager: The pytest plugin manager.\n\n    .. note::\n        This hook is incompatible with hook wrappers.\n\n    Use in conftest plugins\n    =======================\n\n    If a conftest plugin implements this hook, it will be called immediately\n    when the conftest is registered, once for each plugin registered thus far\n    (including itself!), and for all "}, {"start_line": 0, "end_line": 2000, "belongs_to": {"file_name": "test_pluginmanager.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "# mypy: allow-untyped-defs\nfrom __future__ import annotations\n\nimport os\nimport shutil\nimport sys\nimport types\n\nfrom _pytest.config import Config\nfrom _pytest.config import ExitCode\nfrom _pytest.config import PytestPluginManager\nfrom _pytest.config.exceptions import UsageError\nfrom _pytest.main import Session\nfrom _pytest.monkeypatch import MonkeyPatch\nfrom _pytest.pathlib import import_path\nfrom _pytest.pytester import Pytester\nimport pytest\n\n\n@pytest.fixture\ndef pytestpm() -> PytestPluginManager:\n    return PytestPluginManager()\n\n\nclass TestPytestPluginInteractions:\n    def test_addhooks_conftestplugin(\n        self, pytester: Pytester, _config_for_test: Config\n    ) -> None:\n        pytester.makepyfile(\n            newhooks=\"\"\"\n            def pytest_myhook(xyz):\n                \"new hook\"\n        \"\"\"\n        )\n        conf = pytester.makeconftest(\n            \"\"\"\n            import newhooks\n            def pytest_addhooks(pluginmanager):\n                pluginmanager.add_hookspecs(newhooks)\n            def pytest_myhook(xyz):\n                return xyz + 1\n        \"\"\"\n        )\n        config = _config_for_test\n        pm = config.pluginmanager\n        pm.hook.pytest_addhooks.call_historic(\n            kwargs=dict(pluginmanager=config.pluginmanager)\n        )\n        config.pluginmanager._importconftest(\n            conf,\n            importmode=\"prepend\",\n            rootpath=pytester.path,\n            consider_namespace_packages=False,\n        )\n        # print(config.pluginmanager.get_plugins())\n        res = config.hook.pytest_myhook(xyz=10)\n        assert res == [11]\n\n    def test_addhooks_nohooks(self, pytester: Pytester) -> None:\n        pytester.makeconftest(\n            \"\"\"\n            import sys\n            def pytest_addhooks(pluginmanager):\n                pluginmanager.add_hookspecs(sys)\n        \"\"\"\n        )\n        res = pytester.runpytest()\n        assert res.ret != 0\n        res.stderr.fnmatch_lines([\"*did not find*sys*\"])\n\n    def test_do_option"}, {"start_line": 13000, "end_line": 15000, "belongs_to": {"file_name": "test_pluginmanager.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "h_lines([\"*1 passed*\"])\n\n    def test_import_plugin_importname(\n        self, pytester: Pytester, pytestpm: PytestPluginManager\n    ) -> None:\n        pytest.raises(ImportError, pytestpm.import_plugin, \"qweqwex.y\")\n        pytest.raises(ImportError, pytestpm.import_plugin, \"pytest_qweqwx.y\")\n\n        pytester.syspathinsert()\n        pluginname = \"pytest_hello\"\n        pytester.makepyfile(**{pluginname: \"\"})\n        pytestpm.import_plugin(\"pytest_hello\")\n        len1 = len(pytestpm.get_plugins())\n        pytestpm.import_plugin(\"pytest_hello\")\n        len2 = len(pytestpm.get_plugins())\n        assert len1 == len2\n        plugin1 = pytestpm.get_plugin(\"pytest_hello\")\n        assert plugin1 is not None\n        assert plugin1.__name__.endswith(\"pytest_hello\")\n        plugin2 = pytestpm.get_plugin(\"pytest_hello\")\n        assert plugin2 is plugin1\n\n    def test_import_plugin_dotted_name(\n        self, pytester: Pytester, pytestpm: PytestPluginManager\n    ) -> None:\n        pytest.raises(ImportError, pytestpm.import_plugin, \"qweqwex.y\")\n        pytest.raises(ImportError, pytestpm.import_plugin, \"pytest_qweqwex.y\")\n\n        pytester.syspathinsert()\n        pytester.mkpydir(\"pkg\").joinpath(\"plug.py\").write_text(\"x=3\", encoding=\"utf-8\")\n        pluginname = \"pkg.plug\"\n        pytestpm.import_plugin(pluginname)\n        mod = pytestpm.get_plugin(\"pkg.plug\")\n        assert mod is not None\n        assert mod.x == 3\n\n    def test_consider_conftest_deps(\n        self,\n        pytester: Pytester,\n        pytestpm: PytestPluginManager,\n    ) -> None:\n        mod = import_path(\n            pytester.makepyfile(\"pytest_plugins='xyz'\"),\n            root=pytester.path,\n            consider_namespace_packages=False,\n        )\n        with pytest.raises(ImportError):\n            pytestpm.consider_conftest(mod, registration_name=\"unused\")\n\n\nclass TestPytestPluginManagerBootstrapping:\n    def test_preparse_args(self, pytestpm: PytestPluginManager) -> None:\n        pytest.raises(\n            Im"}, {"start_line": 16000, "end_line": 18000, "belongs_to": {"file_name": "__init__.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest/config", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "ict(\n                    plugin=plugin,\n                    plugin_name=plugin_name,\n                    manager=self,\n                )\n            )\n\n            if isinstance(plugin, types.ModuleType):\n                self.consider_module(plugin)\n        return plugin_name\n\n    def getplugin(self, name: str):\n        # Support deprecated naming because plugins (xdist e.g.) use it.\n        plugin: _PluggyPlugin | None = self.get_plugin(name)\n        return plugin\n\n    def hasplugin(self, name: str) -> bool:\n        \"\"\"Return whether a plugin with the given name is registered.\"\"\"\n        return bool(self.get_plugin(name))\n\n    def pytest_configure(self, config: Config) -> None:\n        \"\"\":meta private:\"\"\"\n        # XXX now that the pluginmanager exposes hookimpl(tryfirst...)\n        # we should remove tryfirst/trylast as markers.\n        config.addinivalue_line(\n            \"markers\",\n            \"tryfirst: mark a hook implementation function such that the \"\n            \"plugin machinery will try to call it first/as early as possible. \"\n            \"DEPRECATED, use @pytest.hookimpl(tryfirst=True) instead.\",\n        )\n        config.addinivalue_line(\n            \"markers\",\n            \"trylast: mark a hook implementation function such that the \"\n            \"plugin machinery will try to call it last/as late as possible. \"\n            \"DEPRECATED, use @pytest.hookimpl(trylast=True) instead.\",\n        )\n        self._configured = True\n\n    #\n    # Internal API for local conftest plugin handling.\n    #\n    def _set_initial_conftests(\n        self,\n        args: Sequence[str | pathlib.Path],\n        pyargs: bool,\n        noconftest: bool,\n        rootpath: pathlib.Path,\n        confcutdir: pathlib.Path | None,\n        invocation_dir: pathlib.Path,\n        importmode: ImportMode | str,\n        *,\n        consider_namespace_packages: bool,\n    ) -> None:\n        \"\"\"Load initial conftest files given a preparsed \"namespace\".\n\n        As conftest files may add their own com"}, {"start_line": 10000, "end_line": 12000, "belongs_to": {"file_name": "test_pluginmanager.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "in(\"pytest_p2\")\n        assert p2 is not None\n        assert p2.__name__ == \"pytest_p2\"\n\n    def test_consider_module_import_module(\n        self, pytester: Pytester, _config_for_test: Config\n    ) -> None:\n        pytestpm = _config_for_test.pluginmanager\n        mod = types.ModuleType(\"x\")\n        mod.__dict__[\"pytest_plugins\"] = \"pytest_a\"\n        aplugin = pytester.makepyfile(pytest_a=\"#\")\n        reprec = pytester.make_hook_recorder(pytestpm)\n        pytester.syspathinsert(aplugin.parent)\n        pytestpm.consider_module(mod)\n        call = reprec.getcall(pytestpm.hook.pytest_plugin_registered.name)\n        assert call.plugin.__name__ == \"pytest_a\"\n\n        # check that it is not registered twice\n        pytestpm.consider_module(mod)\n        values = reprec.getcalls(\"pytest_plugin_registered\")\n        assert len(values) == 1\n\n    def test_consider_env_fails_to_import(\n        self, monkeypatch: MonkeyPatch, pytestpm: PytestPluginManager\n    ) -> None:\n        monkeypatch.setenv(\"PYTEST_PLUGINS\", \"nonexisting\", prepend=\",\")\n        with pytest.raises(ImportError):\n            pytestpm.consider_env()\n\n    @pytest.mark.filterwarnings(\"always\")\n    def test_plugin_skip(self, pytester: Pytester, monkeypatch: MonkeyPatch) -> None:\n        p = pytester.makepyfile(\n            skipping1=\"\"\"\n            import pytest\n            pytest.skip(\"hello\", allow_module_level=True)\n        \"\"\"\n        )\n        shutil.copy(p, p.with_name(\"skipping2.py\"))\n        monkeypatch.setenv(\"PYTEST_PLUGINS\", \"skipping2\")\n        result = pytester.runpytest(\"-p\", \"skipping1\", syspathinsert=True)\n        assert result.ret == ExitCode.NO_TESTS_COLLECTED\n        result.stdout.fnmatch_lines(\n            [\"*skipped plugin*skipping1*hello*\", \"*skipped plugin*skipping2*hello*\"]\n        )\n\n    def test_consider_env_plugin_instantiation(\n        self,\n        pytester: Pytester,\n        monkeypatch: MonkeyPatch,\n        pytestpm: PytestPluginManager,\n    ) -> None:\n        pytester.syspathinsert()"}, {"start_line": 4000, "end_line": 6000, "belongs_to": {"file_name": "acceptance_test.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "\")\n\n        pytester.makepyfile(mytestplugin1_module=\"\")\n        pytester.makepyfile(mytestplugin2_module=\"\")\n        pytester.makepyfile(mycov_module=\"\")\n        pytester.syspathinsert()\n\n        loaded = []\n\n        @dataclasses.dataclass\n        class DummyEntryPoint:\n            name: str\n            module: str\n            group: str = \"pytest11\"\n\n            def load(self):\n                __import__(self.module)\n                loaded.append(self.name)\n                return sys.modules[self.module]\n\n        entry_points = [\n            DummyEntryPoint(\"myplugin1\", \"mytestplugin1_module\"),\n            DummyEntryPoint(\"myplugin2\", \"mytestplugin2_module\"),\n            DummyEntryPoint(\"mycov\", \"mycov_module\"),\n        ]\n\n        @dataclasses.dataclass\n        class DummyDist:\n            entry_points: object\n            files: object = ()\n\n        def my_dists():\n            return (DummyDist(entry_points),)\n\n        monkeypatch.setattr(importlib.metadata, \"distributions\", my_dists)\n        params = (\"-p\", \"mycov\") if load_cov_early else ()\n        pytester.runpytest_inprocess(*params)\n        if load_cov_early:\n            assert loaded == [\"mycov\", \"myplugin1\", \"myplugin2\"]\n        else:\n            assert loaded == [\"myplugin1\", \"myplugin2\", \"mycov\"]\n\n    @pytest.mark.parametrize(\"import_mode\", [\"prepend\", \"append\", \"importlib\"])\n    def test_assertion_rewrite(self, pytester: Pytester, import_mode) -> None:\n        p = pytester.makepyfile(\n            \"\"\"\n            def test_this():\n                x = 0\n                assert x\n        \"\"\"\n        )\n        result = pytester.runpytest(p, f\"--import-mode={import_mode}\")\n        result.stdout.fnmatch_lines([\">       assert x\", \"E       assert 0\"])\n        assert result.ret == 1\n\n    def test_nested_import_error(self, pytester: Pytester) -> None:\n        p = pytester.makepyfile(\n            \"\"\"\n                import import_fails\n                def test_this():\n                    assert import_fails.a == 1\n "}, {"start_line": 12000, "end_line": 14000, "belongs_to": {"file_name": "test_pluginmanager.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "\n        pytester.makepyfile(xy123=\"#\")\n        monkeypatch.setitem(os.environ, \"PYTEST_PLUGINS\", \"xy123\")\n        l1 = len(pytestpm.get_plugins())\n        pytestpm.consider_env()\n        l2 = len(pytestpm.get_plugins())\n        assert l2 == l1 + 1\n        assert pytestpm.get_plugin(\"xy123\")\n        pytestpm.consider_env()\n        l3 = len(pytestpm.get_plugins())\n        assert l2 == l3\n\n    def test_pluginmanager_ENV_startup(\n        self, pytester: Pytester, monkeypatch: MonkeyPatch\n    ) -> None:\n        pytester.makepyfile(pytest_x500=\"#\")\n        p = pytester.makepyfile(\n            \"\"\"\n            import pytest\n            def test_hello(pytestconfig):\n                plugin = pytestconfig.pluginmanager.get_plugin('pytest_x500')\n                assert plugin is not None\n        \"\"\"\n        )\n        monkeypatch.setenv(\"PYTEST_PLUGINS\", \"pytest_x500\", prepend=\",\")\n        result = pytester.runpytest(p, syspathinsert=True)\n        assert result.ret == 0\n        result.stdout.fnmatch_lines([\"*1 passed*\"])\n\n    def test_import_plugin_importname(\n        self, pytester: Pytester, pytestpm: PytestPluginManager\n    ) -> None:\n        pytest.raises(ImportError, pytestpm.import_plugin, \"qweqwex.y\")\n        pytest.raises(ImportError, pytestpm.import_plugin, \"pytest_qweqwx.y\")\n\n        pytester.syspathinsert()\n        pluginname = \"pytest_hello\"\n        pytester.makepyfile(**{pluginname: \"\"})\n        pytestpm.import_plugin(\"pytest_hello\")\n        len1 = len(pytestpm.get_plugins())\n        pytestpm.import_plugin(\"pytest_hello\")\n        len2 = len(pytestpm.get_plugins())\n        assert len1 == len2\n        plugin1 = pytestpm.get_plugin(\"pytest_hello\")\n        assert plugin1 is not None\n        assert plugin1.__name__.endswith(\"pytest_hello\")\n        plugin2 = pytestpm.get_plugin(\"pytest_hello\")\n        assert plugin2 is plugin1\n\n    def test_import_plugin_dotted_name(\n        self, pytester: Pytester, pytestpm: PytestPluginManager\n    ) -> None:\n        pytest.raises(Impor"}], "retrieved_count": 10, "cost_time": 0.34830474853515625}
{"question": "How does Pytest ensure backward compatibility when introducing new features?", "answer": null, "relative_code_list": null, "ground_truth": "Pytest ensures backward compatibility when introducing new features through a comprehensive policy and implementation strategy: 1) Backward compatibility policy that categorizes changes into three types: trivial (APIs that trivially translate to new mechanisms), transitional (old and new APIs don't conflict and can coexist), and true breakage (only for APIs with very small user bases), 2) Deprecation warning system using custom warning hierarchy (PytestDeprecationWarning, PytestRemovedInXWarning) to communicate upcoming changes to users, 3) Gradual deprecation process where deprecated features are kept for at least two minor releases before removal, with deprecation warnings becoming errors by default in the release before removal, 4) Dynamic argument pruning in hook system that allows new hook parameters to be added without breaking existing implementations, 5) Plugin system design that enables multiple plugins to implement the same hook specification, maintaining compatibility while allowing new functionality, 6) Configuration system that supports multiple file formats (pytest.ini, pyproject.toml, tox.ini, setup.cfg) and allows gradual migration between formats, 7) Fixture system that maintains compatibility with both old funcarg-style fixtures and new @pytest.fixture decorator, 8) Mark system that preserves old marker behavior while introducing new functionality, 9) Python version support policy that maintains compatibility with actively maintained Python versions, 10) Documentation of deprecations and migration paths in doc/en/deprecations.rst to help users transition, 11) Changelog tracking that clearly documents breaking changes, deprecations, and new features, 12) Community coordination through GitHub issues and pull requests to assess impact before making breaking changes.", "score": null, "retrieved_content": [{"start_line": 0, "end_line": 2000, "belongs_to": {"file_name": "legacypath.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "# mypy: allow-untyped-defs\n\"\"\"Add backward compatibility support for the legacy py path type.\"\"\"\n\nfrom __future__ import annotations\n\nimport dataclasses\nfrom pathlib import Path\nimport shlex\nimport subprocess\nfrom typing import Final\nfrom typing import final\nfrom typing import TYPE_CHECKING\n\nfrom iniconfig import SectionWrapper\n\nfrom _pytest.cacheprovider import Cache\nfrom _pytest.compat import LEGACY_PATH\nfrom _pytest.compat import legacy_path\nfrom _pytest.config import Config\nfrom _pytest.config import hookimpl\nfrom _pytest.config import PytestPluginManager\nfrom _pytest.deprecated import check_ispytest\nfrom _pytest.fixtures import fixture\nfrom _pytest.fixtures import FixtureRequest\nfrom _pytest.main import Session\nfrom _pytest.monkeypatch import MonkeyPatch\nfrom _pytest.nodes import Collector\nfrom _pytest.nodes import Item\nfrom _pytest.nodes import Node\nfrom _pytest.pytester import HookRecorder\nfrom _pytest.pytester import Pytester\nfrom _pytest.pytester import RunResult\nfrom _pytest.terminal import TerminalReporter\nfrom _pytest.tmpdir import TempPathFactory\n\n\nif TYPE_CHECKING:\n    import pexpect\n\n\n@final\nclass Testdir:\n    \"\"\"\n    Similar to :class:`Pytester`, but this class works with legacy legacy_path objects instead.\n\n    All methods just forward to an internal :class:`Pytester` instance, converting results\n    to `legacy_path` objects as necessary.\n    \"\"\"\n\n    __test__ = False\n\n    CLOSE_STDIN: Final = Pytester.CLOSE_STDIN\n    TimeoutExpired: Final = Pytester.TimeoutExpired\n\n    def __init__(self, pytester: Pytester, *, _ispytest: bool = False) -> None:\n        check_ispytest(_ispytest)\n        self._pytester = pytester\n\n    @property\n    def tmpdir(self) -> LEGACY_PATH:\n        \"\"\"Temporary directory where tests are executed.\"\"\"\n        return legacy_path(self._pytester.path)\n\n    @property\n    def test_tmproot(self) -> LEGACY_PATH:\n        return legacy_path(self._pytester._test_tmproot)\n\n    @property\n    def request(self):\n        return self._pytester._"}, {"start_line": 0, "end_line": 2000, "belongs_to": {"file_name": "test_cacheprovider.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "from __future__ import annotations\n\nfrom collections.abc import Generator\nfrom collections.abc import Sequence\nfrom enum import auto\nfrom enum import Enum\nimport os\nfrom pathlib import Path\nimport shutil\nfrom typing import Any\n\nfrom _pytest.compat import assert_never\nfrom _pytest.config import ExitCode\nfrom _pytest.monkeypatch import MonkeyPatch\nfrom _pytest.pytester import Pytester\nfrom _pytest.tmpdir import TempPathFactory\nimport pytest\n\n\npytest_plugins = (\"pytester\",)\n\n\nclass TestNewAPI:\n    def test_config_cache_mkdir(self, pytester: Pytester) -> None:\n        pytester.makeini(\"[pytest]\")\n        config = pytester.parseconfigure()\n        assert config.cache is not None\n        with pytest.raises(ValueError):\n            config.cache.mkdir(\"key/name\")\n\n        p = config.cache.mkdir(\"name\")\n        assert p.is_dir()\n\n    def test_cache_dir_permissions(self, pytester: Pytester) -> None:\n        \"\"\"The .pytest_cache directory should have world-readable permissions\n        (depending on umask).\n\n        Regression test for #12308.\n        \"\"\"\n        pytester.makeini(\"[pytest]\")\n        config = pytester.parseconfigure()\n        assert config.cache is not None\n        p = config.cache.mkdir(\"name\")\n        assert p.is_dir()\n        # Instead of messing with umask, make sure .pytest_cache has the same\n        # permissions as the default that `mkdir` gives `p`.\n        assert (p.parent.stat().st_mode & 0o777) == (p.stat().st_mode & 0o777)\n\n    def test_config_cache_dataerror(self, pytester: Pytester) -> None:\n        pytester.makeini(\"[pytest]\")\n        config = pytester.parseconfigure()\n        assert config.cache is not None\n        cache = config.cache\n        pytest.raises(TypeError, lambda: cache.set(\"key/name\", cache))\n        config.cache.set(\"key/name\", 0)\n        config.cache._getvaluepath(\"key/name\").write_bytes(b\"123invalid\")\n        val = config.cache.get(\"key/name\", -2)\n        assert val == -2\n\n    @pytest.mark.filterwarnings(\"ignore:could not create c"}, {"start_line": 9000, "end_line": 11000, "belongs_to": {"file_name": "legacypath.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "Testdir:\n        \"\"\"\n        Identical to :fixture:`pytester`, and provides an instance whose methods return\n        legacy ``LEGACY_PATH`` objects instead when applicable.\n\n        New code should avoid using :fixture:`testdir` in favor of :fixture:`pytester`.\n        \"\"\"\n        return Testdir(pytester, _ispytest=True)\n\n\n@final\n@dataclasses.dataclass\nclass TempdirFactory:\n    \"\"\"Backward compatibility wrapper that implements ``py.path.local``\n    for :class:`TempPathFactory`.\n\n    .. note::\n        These days, it is preferred to use ``tmp_path_factory``.\n\n        :ref:`About the tmpdir and tmpdir_factory fixtures<tmpdir and tmpdir_factory>`.\n\n    \"\"\"\n\n    _tmppath_factory: TempPathFactory\n\n    def __init__(\n        self, tmppath_factory: TempPathFactory, *, _ispytest: bool = False\n    ) -> None:\n        check_ispytest(_ispytest)\n        self._tmppath_factory = tmppath_factory\n\n    def mktemp(self, basename: str, numbered: bool = True) -> LEGACY_PATH:\n        \"\"\"Same as :meth:`TempPathFactory.mktemp`, but returns a ``py.path.local`` object.\"\"\"\n        return legacy_path(self._tmppath_factory.mktemp(basename, numbered).resolve())\n\n    def getbasetemp(self) -> LEGACY_PATH:\n        \"\"\"Same as :meth:`TempPathFactory.getbasetemp`, but returns a ``py.path.local`` object.\"\"\"\n        return legacy_path(self._tmppath_factory.getbasetemp().resolve())\n\n\nclass LegacyTmpdirPlugin:\n    @staticmethod\n    @fixture(scope=\"session\")\n    def tmpdir_factory(request: FixtureRequest) -> TempdirFactory:\n        \"\"\"Return a :class:`pytest.TempdirFactory` instance for the test session.\"\"\"\n        # Set dynamically by pytest_configure().\n        return request.config._tmpdirhandler  # type: ignore\n\n    @staticmethod\n    @fixture\n    def tmpdir(tmp_path: Path) -> LEGACY_PATH:\n        \"\"\"Return a temporary directory (as `legacy_path`_ object)\n        which is unique to each test function invocation.\n        The temporary directory is created as a subdirectory\n        of the base temporary dir"}, {"start_line": 1000, "end_line": 3000, "belongs_to": {"file_name": "pytester.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "t.compat import NOTSET\nfrom _pytest.compat import NotSetType\nfrom _pytest.config import _PluggyPlugin\nfrom _pytest.config import Config\nfrom _pytest.config import ExitCode\nfrom _pytest.config import hookimpl\nfrom _pytest.config import main\nfrom _pytest.config import PytestPluginManager\nfrom _pytest.config.argparsing import Parser\nfrom _pytest.deprecated import check_ispytest\nfrom _pytest.fixtures import fixture\nfrom _pytest.fixtures import FixtureRequest\nfrom _pytest.main import Session\nfrom _pytest.monkeypatch import MonkeyPatch\nfrom _pytest.nodes import Collector\nfrom _pytest.nodes import Item\nfrom _pytest.outcomes import fail\nfrom _pytest.outcomes import importorskip\nfrom _pytest.outcomes import skip\nfrom _pytest.pathlib import bestrelpath\nfrom _pytest.pathlib import make_numbered_dir\nfrom _pytest.reports import CollectReport\nfrom _pytest.reports import TestReport\nfrom _pytest.tmpdir import TempPathFactory\nfrom _pytest.warning_types import PytestFDWarning\n\n\nif TYPE_CHECKING:\n    import pexpect\n\n\npytest_plugins = [\"pytester_assertions\"]\n\n\nIGNORE_PAM = [  # filenames added when obtaining details about the current user\n    \"/var/lib/sss/mc/passwd\"\n]\n\n\ndef pytest_addoption(parser: Parser) -> None:\n    parser.addoption(\n        \"--lsof\",\n        action=\"store_true\",\n        dest=\"lsof\",\n        default=False,\n        help=\"Run FD checks if lsof is available\",\n    )\n\n    parser.addoption(\n        \"--runpytest\",\n        default=\"inprocess\",\n        dest=\"runpytest\",\n        choices=(\"inprocess\", \"subprocess\"),\n        help=(\n            \"Run pytest sub runs in tests using an 'inprocess' \"\n            \"or 'subprocess' (python -m main) method\"\n        ),\n    )\n\n    parser.addini(\n        \"pytester_example_dir\", help=\"Directory to take the pytester example files from\"\n    )\n\n\ndef pytest_configure(config: Config) -> None:\n    if config.getvalue(\"lsof\"):\n        checker = LsofFdLeakChecker()\n        if checker.matching_platform():\n            config.pluginmanager.register(ch"}, {"start_line": 0, "end_line": 2000, "belongs_to": {"file_name": "test_legacypath.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "# mypy: allow-untyped-defs\nfrom __future__ import annotations\n\nfrom pathlib import Path\n\nfrom _pytest.compat import LEGACY_PATH\nfrom _pytest.fixtures import TopRequest\nfrom _pytest.legacypath import TempdirFactory\nfrom _pytest.legacypath import Testdir\nimport pytest\n\n\ndef test_item_fspath(pytester: pytest.Pytester) -> None:\n    pytester.makepyfile(\"def test_func(): pass\")\n    items, hookrec = pytester.inline_genitems()\n    assert len(items) == 1\n    (item,) = items\n    items2, hookrec = pytester.inline_genitems(item.nodeid)\n    (item2,) = items2\n    assert item2.name == item.name\n    assert item2.fspath == item.fspath\n    assert item2.path == item.path\n\n\ndef test_testdir_testtmproot(testdir: Testdir) -> None:\n    \"\"\"Check test_tmproot is a py.path attribute for backward compatibility.\"\"\"\n    assert testdir.test_tmproot.check(dir=1)\n\n\ndef test_testdir_makefile_dot_prefixes_extension_silently(\n    testdir: Testdir,\n) -> None:\n    \"\"\"For backwards compat #8192\"\"\"\n    p1 = testdir.makefile(\"foo.bar\", \"\")\n    assert \".foo.bar\" in str(p1)\n\n\ndef test_testdir_makefile_ext_none_raises_type_error(testdir: Testdir) -> None:\n    \"\"\"For backwards compat #8192\"\"\"\n    with pytest.raises(TypeError):\n        testdir.makefile(None, \"\")\n\n\ndef test_testdir_makefile_ext_empty_string_makes_file(testdir: Testdir) -> None:\n    \"\"\"For backwards compat #8192\"\"\"\n    p1 = testdir.makefile(\"\", \"\")\n    assert \"test_testdir_makefile\" in str(p1)\n\n\ndef attempt_symlink_to(path: str, to_path: str) -> None:\n    \"\"\"Try to make a symlink from \"path\" to \"to_path\", skipping in case this platform\n    does not support it or we don't have sufficient privileges (common on Windows).\"\"\"\n    try:\n        Path(path).symlink_to(Path(to_path))\n    except OSError:\n        pytest.skip(\"could not create symbolic link\")\n\n\ndef test_tmpdir_factory(\n    tmpdir_factory: TempdirFactory,\n    tmp_path_factory: pytest.TempPathFactory,\n) -> None:\n    assert str(tmpdir_factory.getbasetemp()) == str(tmp_path_factory.getbasetemp()"}, {"start_line": 8000, "end_line": 10000, "belongs_to": {"file_name": "legacypath.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "n(script)\n\n    def runpython_c(self, command):\n        \"\"\"See :meth:`Pytester.runpython_c`.\"\"\"\n        return self._pytester.runpython_c(command)\n\n    def runpytest_subprocess(self, *args, timeout=None) -> RunResult:\n        \"\"\"See :meth:`Pytester.runpytest_subprocess`.\"\"\"\n        return self._pytester.runpytest_subprocess(*args, timeout=timeout)\n\n    def spawn_pytest(self, string: str, expect_timeout: float = 10.0) -> pexpect.spawn:\n        \"\"\"See :meth:`Pytester.spawn_pytest`.\"\"\"\n        return self._pytester.spawn_pytest(string, expect_timeout=expect_timeout)\n\n    def spawn(self, cmd: str, expect_timeout: float = 10.0) -> pexpect.spawn:\n        \"\"\"See :meth:`Pytester.spawn`.\"\"\"\n        return self._pytester.spawn(cmd, expect_timeout=expect_timeout)\n\n    def __repr__(self) -> str:\n        return f\"<Testdir {self.tmpdir!r}>\"\n\n    def __str__(self) -> str:\n        return str(self.tmpdir)\n\n\nclass LegacyTestdirPlugin:\n    @staticmethod\n    @fixture\n    def testdir(pytester: Pytester) -> Testdir:\n        \"\"\"\n        Identical to :fixture:`pytester`, and provides an instance whose methods return\n        legacy ``LEGACY_PATH`` objects instead when applicable.\n\n        New code should avoid using :fixture:`testdir` in favor of :fixture:`pytester`.\n        \"\"\"\n        return Testdir(pytester, _ispytest=True)\n\n\n@final\n@dataclasses.dataclass\nclass TempdirFactory:\n    \"\"\"Backward compatibility wrapper that implements ``py.path.local``\n    for :class:`TempPathFactory`.\n\n    .. note::\n        These days, it is preferred to use ``tmp_path_factory``.\n\n        :ref:`About the tmpdir and tmpdir_factory fixtures<tmpdir and tmpdir_factory>`.\n\n    \"\"\"\n\n    _tmppath_factory: TempPathFactory\n\n    def __init__(\n        self, tmppath_factory: TempPathFactory, *, _ispytest: bool = False\n    ) -> None:\n        check_ispytest(_ispytest)\n        self._tmppath_factory = tmppath_factory\n\n    def mktemp(self, basename: str, numbered: bool = True) -> LEGACY_PATH:\n        \"\"\"Same as :meth:`TempPat"}, {"start_line": 0, "end_line": 2000, "belongs_to": {"file_name": "conftest.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "# mypy: allow-untyped-defs\nfrom __future__ import annotations\n\nfrom collections.abc import Generator\nimport importlib.metadata\nimport re\nimport sys\n\nfrom packaging.version import Version\n\nfrom _pytest.monkeypatch import MonkeyPatch\nfrom _pytest.pytester import Pytester\nimport pytest\n\n\nif sys.gettrace():\n\n    @pytest.fixture(autouse=True)\n    def restore_tracing():\n        \"\"\"Restore tracing function (when run with Coverage.py).\n\n        https://bugs.python.org/issue37011\n        \"\"\"\n        orig_trace = sys.gettrace()\n        yield\n        if sys.gettrace() != orig_trace:\n            sys.settrace(orig_trace)\n\n\n@pytest.fixture(autouse=True)\ndef set_column_width(monkeypatch: pytest.MonkeyPatch) -> None:\n    \"\"\"\n    Force terminal width to 80: some tests check the formatting of --help, which is sensible\n    to terminal width.\n    \"\"\"\n    monkeypatch.setenv(\"COLUMNS\", \"80\")\n\n\n@pytest.fixture(autouse=True)\ndef reset_colors(monkeypatch: pytest.MonkeyPatch) -> None:\n    \"\"\"\n    Reset all color-related variables to prevent them from affecting internal pytest output\n    in tests that depend on it.\n    \"\"\"\n    monkeypatch.delenv(\"PY_COLORS\", raising=False)\n    monkeypatch.delenv(\"NO_COLOR\", raising=False)\n    monkeypatch.delenv(\"FORCE_COLOR\", raising=False)\n\n\n@pytest.hookimpl(wrapper=True, tryfirst=True)\ndef pytest_collection_modifyitems(items) -> Generator[None]:\n    \"\"\"Prefer faster tests.\n\n    Use a hook wrapper to do this in the beginning, so e.g. --ff still works\n    correctly.\n    \"\"\"\n    fast_items = []\n    slow_items = []\n    slowest_items = []\n    neutral_items = []\n\n    spawn_names = {\"spawn_pytest\", \"spawn\"}\n\n    for item in items:\n        try:\n            fixtures = item.fixturenames\n        except AttributeError:\n            # doctest at least\n            # (https://github.com/pytest-dev/pytest/issues/5070)\n            neutral_items.append(item)\n        else:\n            if \"pytester\" in fixtures:\n                co_names = item.function.__code__.co_names\n       "}, {"start_line": 0, "end_line": 2000, "belongs_to": {"file_name": "pytester.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "# mypy: allow-untyped-defs\n\"\"\"(Disabled by default) support for testing pytest and pytest plugins.\n\nPYTEST_DONT_REWRITE\n\"\"\"\n\nfrom __future__ import annotations\n\nimport collections.abc\nfrom collections.abc import Callable\nfrom collections.abc import Generator\nfrom collections.abc import Iterable\nfrom collections.abc import Sequence\nimport contextlib\nfrom fnmatch import fnmatch\nimport gc\nimport importlib\nfrom io import StringIO\nimport locale\nimport os\nfrom pathlib import Path\nimport platform\nimport re\nimport shutil\nimport subprocess\nimport sys\nimport traceback\nfrom typing import Any\nfrom typing import Final\nfrom typing import final\nfrom typing import IO\nfrom typing import Literal\nfrom typing import overload\nfrom typing import TextIO\nfrom typing import TYPE_CHECKING\nfrom weakref import WeakKeyDictionary\n\nfrom iniconfig import IniConfig\nfrom iniconfig import SectionWrapper\n\nfrom _pytest import timing\nfrom _pytest._code import Source\nfrom _pytest.capture import _get_multicapture\nfrom _pytest.compat import NOTSET\nfrom _pytest.compat import NotSetType\nfrom _pytest.config import _PluggyPlugin\nfrom _pytest.config import Config\nfrom _pytest.config import ExitCode\nfrom _pytest.config import hookimpl\nfrom _pytest.config import main\nfrom _pytest.config import PytestPluginManager\nfrom _pytest.config.argparsing import Parser\nfrom _pytest.deprecated import check_ispytest\nfrom _pytest.fixtures import fixture\nfrom _pytest.fixtures import FixtureRequest\nfrom _pytest.main import Session\nfrom _pytest.monkeypatch import MonkeyPatch\nfrom _pytest.nodes import Collector\nfrom _pytest.nodes import Item\nfrom _pytest.outcomes import fail\nfrom _pytest.outcomes import importorskip\nfrom _pytest.outcomes import skip\nfrom _pytest.pathlib import bestrelpath\nfrom _pytest.pathlib import make_numbered_dir\nfrom _pytest.reports import CollectReport\nfrom _pytest.reports import TestReport\nfrom _pytest.tmpdir import TempPathFactory\nfrom _pytest.warning_types import PytestFDWarning\n\n\nif TYPE_CHECKING:\n    imp"}, {"start_line": 1000, "end_line": 3000, "belongs_to": {"file_name": "legacypath.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "terminal import TerminalReporter\nfrom _pytest.tmpdir import TempPathFactory\n\n\nif TYPE_CHECKING:\n    import pexpect\n\n\n@final\nclass Testdir:\n    \"\"\"\n    Similar to :class:`Pytester`, but this class works with legacy legacy_path objects instead.\n\n    All methods just forward to an internal :class:`Pytester` instance, converting results\n    to `legacy_path` objects as necessary.\n    \"\"\"\n\n    __test__ = False\n\n    CLOSE_STDIN: Final = Pytester.CLOSE_STDIN\n    TimeoutExpired: Final = Pytester.TimeoutExpired\n\n    def __init__(self, pytester: Pytester, *, _ispytest: bool = False) -> None:\n        check_ispytest(_ispytest)\n        self._pytester = pytester\n\n    @property\n    def tmpdir(self) -> LEGACY_PATH:\n        \"\"\"Temporary directory where tests are executed.\"\"\"\n        return legacy_path(self._pytester.path)\n\n    @property\n    def test_tmproot(self) -> LEGACY_PATH:\n        return legacy_path(self._pytester._test_tmproot)\n\n    @property\n    def request(self):\n        return self._pytester._request\n\n    @property\n    def plugins(self):\n        return self._pytester.plugins\n\n    @plugins.setter\n    def plugins(self, plugins):\n        self._pytester.plugins = plugins\n\n    @property\n    def monkeypatch(self) -> MonkeyPatch:\n        return self._pytester._monkeypatch\n\n    def make_hook_recorder(self, pluginmanager) -> HookRecorder:\n        \"\"\"See :meth:`Pytester.make_hook_recorder`.\"\"\"\n        return self._pytester.make_hook_recorder(pluginmanager)\n\n    def chdir(self) -> None:\n        \"\"\"See :meth:`Pytester.chdir`.\"\"\"\n        return self._pytester.chdir()\n\n    def finalize(self) -> None:\n        return self._pytester._finalize()\n\n    def makefile(self, ext, *args, **kwargs) -> LEGACY_PATH:\n        \"\"\"See :meth:`Pytester.makefile`.\"\"\"\n        if ext and not ext.startswith(\".\"):\n            # pytester.makefile is going to throw a ValueError in a way that\n            # testdir.makefile did not, because\n            # pathlib.Path is stricter suffixes than py.path\n            # T"}, {"start_line": 13000, "end_line": 15000, "belongs_to": {"file_name": "legacypath.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "\"\"\"The path from which pytest was invoked.\n\n    Prefer to use ``startpath`` which is a :class:`pathlib.Path`.\n\n    :type: LEGACY_PATH\n    \"\"\"\n    return legacy_path(self.startpath)\n\n\ndef Config__getini_unknown_type(self, name: str, type: str, value: str | list[str]):\n    if type == \"pathlist\":\n        # TODO: This assert is probably not valid in all cases.\n        assert self.inipath is not None\n        dp = self.inipath.parent\n        input_values = shlex.split(value) if isinstance(value, str) else value\n        return [legacy_path(str(dp / x)) for x in input_values]\n    else:\n        raise ValueError(f\"unknown configuration type: {type}\", value)\n\n\ndef Node_fspath(self: Node) -> LEGACY_PATH:\n    \"\"\"(deprecated) returns a legacy_path copy of self.path\"\"\"\n    return legacy_path(self.path)\n\n\ndef Node_fspath_set(self: Node, value: LEGACY_PATH) -> None:\n    self.path = Path(value)\n\n\n@hookimpl(tryfirst=True)\ndef pytest_load_initial_conftests(early_config: Config) -> None:\n    \"\"\"Monkeypatch legacy path attributes in several classes, as early as possible.\"\"\"\n    mp = MonkeyPatch()\n    early_config.add_cleanup(mp.undo)\n\n    # Add Cache.makedir().\n    mp.setattr(Cache, \"makedir\", Cache_makedir, raising=False)\n\n    # Add FixtureRequest.fspath property.\n    mp.setattr(FixtureRequest, \"fspath\", property(FixtureRequest_fspath), raising=False)\n\n    # Add TerminalReporter.startdir property.\n    mp.setattr(\n        TerminalReporter, \"startdir\", property(TerminalReporter_startdir), raising=False\n    )\n\n    # Add Config.{invocation_dir,rootdir,inifile} properties.\n    mp.setattr(Config, \"invocation_dir\", property(Config_invocation_dir), raising=False)\n    mp.setattr(Config, \"rootdir\", property(Config_rootdir), raising=False)\n    mp.setattr(Config, \"inifile\", property(Config_inifile), raising=False)\n\n    # Add Session.startdir property.\n    mp.setattr(Session, \"startdir\", property(Session_startdir), raising=False)\n\n    # Add pathlist configuration type.\n    mp.setattr(Config, \"_getin"}], "retrieved_count": 10, "cost_time": 0.33885741233825684}
{"question": "How does Pytest implement its configuration management system?", "answer": null, "relative_code_list": null, "ground_truth": "Pytest implements its configuration management system through a comprehensive multi-layered approach: 1) Config class in src/_pytest/config/__init__.py serves as the central configuration object that provides access to all settings, plugin manager, and plugin hooks, 2) Multiple configuration file formats support including pytest.ini (highest precedence), pyproject.toml with [tool.pytest.ini_options] section, tox.ini with [pytest] section, and setup.cfg with [tool:pytest] section, 3) Configuration file discovery through locate_config() function that searches for configuration files in a specific order and determines rootdir and configfile, 4) Command-line argument parsing through Parser class that processes both command-line options and ini-file values, 5) Environment variable support through PYTEST_ADDOPTS for adding default command-line options and PYTEST_PLUGINS for loading plugins, 6) Configuration value access through methods like getini() for ini-file values and getoption() for command-line options, 7) Plugin configuration through pytest_addoption hook that allows plugins to register their own configuration options, 8) Configuration validation and error handling with proper error messages for invalid configurations, 9) Configuration inheritance and override system where command-line options take precedence over configuration file settings, 10) Root directory determination that finds the common ancestor of specified test paths or uses current working directory, 11) Configuration caching through _inicache attribute to avoid repeated file parsing, 12) Integration with the plugin system where configuration is accessible to all plugins through the config object.", "score": null, "retrieved_content": [{"start_line": 36000, "end_line": 38000, "belongs_to": {"file_name": "__init__.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest/config", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": " and hook invocation.\n\n        :type: PytestPluginManager\n        \"\"\"\n\n        self.stash = Stash()\n        \"\"\"A place where plugins can store information on the config for their\n        own use.\n\n        :type: Stash\n        \"\"\"\n        # Deprecated alias. Was never public. Can be removed in a few releases.\n        self._store = self.stash\n\n        self.trace = self.pluginmanager.trace.root.get(\"config\")\n        self.hook: pluggy.HookRelay = PathAwareHookProxy(self.pluginmanager.hook)  # type: ignore[assignment]\n        self._inicache: dict[str, Any] = {}\n        self._override_ini: Sequence[str] = ()\n        self._opt2dest: dict[str, str] = {}\n        self._cleanup_stack = contextlib.ExitStack()\n        self.pluginmanager.register(self, \"pytestconfig\")\n        self._configured = False\n        self.hook.pytest_addoption.call_historic(\n            kwargs=dict(parser=self._parser, pluginmanager=self.pluginmanager)\n        )\n        self.args_source = Config.ArgsSource.ARGS\n        self.args: list[str] = []\n\n    @property\n    def rootpath(self) -> pathlib.Path:\n        \"\"\"The path to the :ref:`rootdir <rootdir>`.\n\n        :type: pathlib.Path\n\n        .. versionadded:: 6.1\n        \"\"\"\n        return self._rootpath\n\n    @property\n    def inipath(self) -> pathlib.Path | None:\n        \"\"\"The path to the :ref:`configfile <configfiles>`.\n\n        .. versionadded:: 6.1\n        \"\"\"\n        return self._inipath\n\n    def add_cleanup(self, func: Callable[[], None]) -> None:\n        \"\"\"Add a function to be called when the config object gets out of\n        use (usually coinciding with pytest_unconfigure).\n        \"\"\"\n        self._cleanup_stack.callback(func)\n\n    def _do_configure(self) -> None:\n        assert not self._configured\n        self._configured = True\n        self.hook.pytest_configure.call_historic(kwargs=dict(config=self))\n\n    def _ensure_unconfigure(self) -> None:\n        try:\n            if self._configured:\n                self._configured = False\n               "}, {"start_line": 33000, "end_line": 35000, "belongs_to": {"file_name": "__init__.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest/config", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "e_files)\n\n\n@final\nclass Config:\n    \"\"\"Access to configuration values, pluginmanager and plugin hooks.\n\n    :param PytestPluginManager pluginmanager:\n        A pytest PluginManager.\n\n    :param InvocationParams invocation_params:\n        Object containing parameters regarding the :func:`pytest.main`\n        invocation.\n    \"\"\"\n\n    @final\n    @dataclasses.dataclass(frozen=True)\n    class InvocationParams:\n        \"\"\"Holds parameters passed during :func:`pytest.main`.\n\n        The object attributes are read-only.\n\n        .. versionadded:: 5.1\n\n        .. note::\n\n            Note that the environment variable ``PYTEST_ADDOPTS`` and the ``addopts``\n            ini option are handled by pytest, not being included in the ``args`` attribute.\n\n            Plugins accessing ``InvocationParams`` must be aware of that.\n        \"\"\"\n\n        args: tuple[str, ...]\n        \"\"\"The command-line arguments as passed to :func:`pytest.main`.\"\"\"\n        plugins: Sequence[str | _PluggyPlugin] | None\n        \"\"\"Extra plugins, might be `None`.\"\"\"\n        dir: pathlib.Path\n        \"\"\"The directory from which :func:`pytest.main` was invoked. :type: pathlib.Path\"\"\"\n\n        def __init__(\n            self,\n            *,\n            args: Iterable[str],\n            plugins: Sequence[str | _PluggyPlugin] | None,\n            dir: pathlib.Path,\n        ) -> None:\n            object.__setattr__(self, \"args\", tuple(args))\n            object.__setattr__(self, \"plugins\", plugins)\n            object.__setattr__(self, \"dir\", dir)\n\n    class ArgsSource(enum.Enum):\n        \"\"\"Indicates the source of the test arguments.\n\n        .. versionadded:: 7.2\n        \"\"\"\n\n        #: Command line arguments.\n        ARGS = enum.auto()\n        #: Invocation directory.\n        INVOCATION_DIR = enum.auto()\n        INCOVATION_DIR = INVOCATION_DIR  # backwards compatibility alias\n        #: 'testpaths' configuration value.\n        TESTPATHS = enum.auto()\n\n    # Set by cacheprovider plugin.\n    cache: Cache\n\n    def __in"}, {"start_line": 37000, "end_line": 39000, "belongs_to": {"file_name": "__init__.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest/config", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "args: list[str] = []\n\n    @property\n    def rootpath(self) -> pathlib.Path:\n        \"\"\"The path to the :ref:`rootdir <rootdir>`.\n\n        :type: pathlib.Path\n\n        .. versionadded:: 6.1\n        \"\"\"\n        return self._rootpath\n\n    @property\n    def inipath(self) -> pathlib.Path | None:\n        \"\"\"The path to the :ref:`configfile <configfiles>`.\n\n        .. versionadded:: 6.1\n        \"\"\"\n        return self._inipath\n\n    def add_cleanup(self, func: Callable[[], None]) -> None:\n        \"\"\"Add a function to be called when the config object gets out of\n        use (usually coinciding with pytest_unconfigure).\n        \"\"\"\n        self._cleanup_stack.callback(func)\n\n    def _do_configure(self) -> None:\n        assert not self._configured\n        self._configured = True\n        self.hook.pytest_configure.call_historic(kwargs=dict(config=self))\n\n    def _ensure_unconfigure(self) -> None:\n        try:\n            if self._configured:\n                self._configured = False\n                try:\n                    self.hook.pytest_unconfigure(config=self)\n                finally:\n                    self.hook.pytest_configure._call_history = []\n        finally:\n            try:\n                self._cleanup_stack.close()\n            finally:\n                self._cleanup_stack = contextlib.ExitStack()\n\n    def get_terminal_writer(self) -> TerminalWriter:\n        terminalreporter: TerminalReporter | None = self.pluginmanager.get_plugin(\n            \"terminalreporter\"\n        )\n        assert terminalreporter is not None\n        return terminalreporter._tw\n\n    def pytest_cmdline_parse(\n        self, pluginmanager: PytestPluginManager, args: list[str]\n    ) -> Config:\n        try:\n            self.parse(args)\n        except UsageError:\n            # Handle --version and --help here in a minimal fashion.\n            # This gets done via helpconfig normally, but its\n            # pytest_cmdline_main is not called in case of errors.\n            if getattr(self.option, \"versi"}, {"start_line": 35000, "end_line": 37000, "belongs_to": {"file_name": "__init__.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest/config", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "it__(\n        self,\n        pluginmanager: PytestPluginManager,\n        *,\n        invocation_params: InvocationParams | None = None,\n    ) -> None:\n        from .argparsing import FILE_OR_DIR\n        from .argparsing import Parser\n\n        if invocation_params is None:\n            invocation_params = self.InvocationParams(\n                args=(), plugins=None, dir=pathlib.Path.cwd()\n            )\n\n        self.option = argparse.Namespace()\n        \"\"\"Access to command line option as attributes.\n\n        :type: argparse.Namespace\n        \"\"\"\n\n        self.invocation_params = invocation_params\n        \"\"\"The parameters with which pytest was invoked.\n\n        :type: InvocationParams\n        \"\"\"\n\n        _a = FILE_OR_DIR\n        self._parser = Parser(\n            usage=f\"%(prog)s [options] [{_a}] [{_a}] [...]\",\n            processopt=self._processopt,\n            _ispytest=True,\n        )\n        self.pluginmanager = pluginmanager\n        \"\"\"The plugin manager handles plugin registration and hook invocation.\n\n        :type: PytestPluginManager\n        \"\"\"\n\n        self.stash = Stash()\n        \"\"\"A place where plugins can store information on the config for their\n        own use.\n\n        :type: Stash\n        \"\"\"\n        # Deprecated alias. Was never public. Can be removed in a few releases.\n        self._store = self.stash\n\n        self.trace = self.pluginmanager.trace.root.get(\"config\")\n        self.hook: pluggy.HookRelay = PathAwareHookProxy(self.pluginmanager.hook)  # type: ignore[assignment]\n        self._inicache: dict[str, Any] = {}\n        self._override_ini: Sequence[str] = ()\n        self._opt2dest: dict[str, str] = {}\n        self._cleanup_stack = contextlib.ExitStack()\n        self.pluginmanager.register(self, \"pytestconfig\")\n        self._configured = False\n        self.hook.pytest_addoption.call_historic(\n            kwargs=dict(parser=self._parser, pluginmanager=self.pluginmanager)\n        )\n        self.args_source = Config.ArgsSource.ARGS\n        self."}, {"start_line": 12000, "end_line": 14000, "belongs_to": {"file_name": "__init__.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest/config", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "his includes the directory's own conftest modules as well\n        # as those of its parent directories.\n        self._dirpath2confmods: dict[pathlib.Path, list[types.ModuleType]] = {}\n        # Cutoff directory above which conftests are no longer discovered.\n        self._confcutdir: pathlib.Path | None = None\n        # If set, conftest loading is skipped.\n        self._noconftest = False\n\n        # _getconftestmodules()'s call to _get_directory() causes a stat\n        # storm when it's called potentially thousands of times in a test\n        # session (#9478), often with the same path, so cache it.\n        self._get_directory = lru_cache(256)(_get_directory)\n\n        # plugins that were explicitly skipped with pytest.skip\n        # list of (module name, skip reason)\n        # previously we would issue a warning when a plugin was skipped, but\n        # since we refactored warnings as first citizens of Config, they are\n        # just stored here to be used later.\n        self.skipped_plugins: list[tuple[str, str]] = []\n\n        self.add_hookspecs(_pytest.hookspec)\n        self.register(self)\n        if os.environ.get(\"PYTEST_DEBUG\"):\n            err: IO[str] = sys.stderr\n            encoding: str = getattr(err, \"encoding\", \"utf8\")\n            try:\n                err = open(\n                    os.dup(err.fileno()),\n                    mode=err.mode,\n                    buffering=1,\n                    encoding=encoding,\n                )\n            except Exception:\n                pass\n            self.trace.root.setwriter(err.write)\n            self.enable_tracing()\n\n        # Config._consider_importhook will set a real object if required.\n        self.rewrite_hook: RewriteHook = DummyRewriteHook()\n        # Used to know when we are importing conftests after the pytest_configure stage.\n        self._configured = False\n\n    def parse_hookimpl_opts(\n        self, plugin: _PluggyPlugin, name: str\n    ) -> HookimplOpts | None:\n        \"\"\":meta private:\"\"\"\n        # py"}, {"start_line": 37000, "end_line": 39000, "belongs_to": {"file_name": "test_config.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": " config.option.foo == \"bar\"\n        assert config.option.capture == \"no\"\n        assert config.args == args\n\n    def test_invocation_params_args(self, _sys_snapshot) -> None:\n        \"\"\"Show that fromdictargs can handle args in their \"orig\" format\"\"\"\n        option_dict: dict[str, object] = {}\n        args = [\"-vvvv\", \"-s\", \"a\", \"b\"]\n\n        config = Config.fromdictargs(option_dict, args)\n        assert config.args == [\"a\", \"b\"]\n        assert config.invocation_params.args == tuple(args)\n        assert config.option.verbose == 4\n        assert config.option.capture == \"no\"\n\n    def test_inifilename(self, tmp_path: Path) -> None:\n        d1 = tmp_path.joinpath(\"foo\")\n        d1.mkdir()\n        p1 = d1.joinpath(\"bar.ini\")\n        p1.touch()\n        p1.write_text(\n            textwrap.dedent(\n                \"\"\"\\\n                [pytest]\n                name = value\n                \"\"\"\n            ),\n            encoding=\"utf-8\",\n        )\n\n        inifilename = \"../../foo/bar.ini\"\n        option_dict = {\"inifilename\": inifilename, \"capture\": \"no\"}\n\n        cwd = tmp_path.joinpath(\"a/b\")\n        cwd.mkdir(parents=True)\n        p2 = cwd.joinpath(\"pytest.ini\")\n        p2.touch()\n        p2.write_text(\n            textwrap.dedent(\n                \"\"\"\\\n                [pytest]\n                name = wrong-value\n                should_not_be_set = true\n                \"\"\"\n            ),\n            encoding=\"utf-8\",\n        )\n        with MonkeyPatch.context() as mp:\n            mp.chdir(cwd)\n            config = Config.fromdictargs(option_dict, ())\n            inipath = absolutepath(inifilename)\n\n        assert config.args == [str(cwd)]\n        assert config.option.inifilename == inifilename\n        assert config.option.capture == \"no\"\n\n        # this indicates this is the file used for getting configuration values\n        assert config.inipath == inipath\n        assert config.inicfg.get(\"name\") == \"value\"\n        assert config.inicfg.get(\"should_not_be_set\") is None\n\n\nde"}, {"start_line": 7000, "end_line": 9000, "belongs_to": {"file_name": "__init__.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest/config", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "r(f\"{optname} must be a directory, given: {path}\")\n    return path\n\n\n# Plugins that cannot be disabled via \"-p no:X\" currently.\nessential_plugins = (\n    \"mark\",\n    \"main\",\n    \"runner\",\n    \"fixtures\",\n    \"helpconfig\",  # Provides -p.\n)\n\ndefault_plugins = (\n    *essential_plugins,\n    \"python\",\n    \"terminal\",\n    \"debugging\",\n    \"unittest\",\n    \"capture\",\n    \"skipping\",\n    \"legacypath\",\n    \"tmpdir\",\n    \"monkeypatch\",\n    \"recwarn\",\n    \"pastebin\",\n    \"assertion\",\n    \"junitxml\",\n    \"doctest\",\n    \"cacheprovider\",\n    \"freeze_support\",\n    \"setuponly\",\n    \"setupplan\",\n    \"stepwise\",\n    \"unraisableexception\",\n    \"threadexception\",\n    \"warnings\",\n    \"logging\",\n    \"reports\",\n    \"faulthandler\",\n)\n\nbuiltin_plugins = {\n    *default_plugins,\n    \"pytester\",\n    \"pytester_assertions\",\n}\n\n\ndef get_config(\n    args: list[str] | None = None,\n    plugins: Sequence[str | _PluggyPlugin] | None = None,\n) -> Config:\n    # Subsequent calls to main will create a fresh instance.\n    pluginmanager = PytestPluginManager()\n    config = Config(\n        pluginmanager,\n        invocation_params=Config.InvocationParams(\n            args=args or (),\n            plugins=plugins,\n            dir=pathlib.Path.cwd(),\n        ),\n    )\n\n    if args is not None:\n        # Handle any \"-p no:plugin\" args.\n        pluginmanager.consider_preparse(args, exclude_only=True)\n\n    for spec in default_plugins:\n        pluginmanager.import_plugin(spec)\n\n    return config\n\n\ndef get_plugin_manager() -> PytestPluginManager:\n    \"\"\"Obtain a new instance of the\n    :py:class:`pytest.PytestPluginManager`, with default plugins\n    already loaded.\n\n    This function can be used by integration with other tools, like hooking\n    into pytest to run tests into an IDE.\n    \"\"\"\n    return get_config().pluginmanager\n\n\ndef _prepareconfig(\n    args: list[str] | os.PathLike[str] | None = None,\n    plugins: Sequence[str | _PluggyPlugin] | None = None,\n) -> Config:\n    if args is None:\n        args = sys.argv[1:"}, {"start_line": 38000, "end_line": 40000, "belongs_to": {"file_name": "test_config.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "   option_dict = {\"inifilename\": inifilename, \"capture\": \"no\"}\n\n        cwd = tmp_path.joinpath(\"a/b\")\n        cwd.mkdir(parents=True)\n        p2 = cwd.joinpath(\"pytest.ini\")\n        p2.touch()\n        p2.write_text(\n            textwrap.dedent(\n                \"\"\"\\\n                [pytest]\n                name = wrong-value\n                should_not_be_set = true\n                \"\"\"\n            ),\n            encoding=\"utf-8\",\n        )\n        with MonkeyPatch.context() as mp:\n            mp.chdir(cwd)\n            config = Config.fromdictargs(option_dict, ())\n            inipath = absolutepath(inifilename)\n\n        assert config.args == [str(cwd)]\n        assert config.option.inifilename == inifilename\n        assert config.option.capture == \"no\"\n\n        # this indicates this is the file used for getting configuration values\n        assert config.inipath == inipath\n        assert config.inicfg.get(\"name\") == \"value\"\n        assert config.inicfg.get(\"should_not_be_set\") is None\n\n\ndef test_options_on_small_file_do_not_blow_up(pytester: Pytester) -> None:\n    def runfiletest(opts: Sequence[str]) -> None:\n        reprec = pytester.inline_run(*opts)\n        passed, skipped, failed = reprec.countoutcomes()\n        assert failed == 2\n        assert skipped == passed == 0\n\n    path = str(\n        pytester.makepyfile(\n            \"\"\"\n        def test_f1(): assert 0\n        def test_f2(): assert 0\n    \"\"\"\n        )\n    )\n\n    runfiletest([path])\n    runfiletest([\"-l\", path])\n    runfiletest([\"-s\", path])\n    runfiletest([\"--tb=no\", path])\n    runfiletest([\"--tb=short\", path])\n    runfiletest([\"--tb=long\", path])\n    runfiletest([\"--fulltrace\", path])\n    runfiletest([\"--traceconfig\", path])\n    runfiletest([\"-v\", path])\n    runfiletest([\"-v\", \"-v\", path])\n\n\ndef test_preparse_ordering_with_setuptools(\n    pytester: Pytester, monkeypatch: MonkeyPatch\n) -> None:\n    monkeypatch.delenv(\"PYTEST_DISABLE_PLUGIN_AUTOLOAD\", raising=False)\n\n    class EntryPoint:\n        name = \"myt"}, {"start_line": 0, "end_line": 2000, "belongs_to": {"file_name": "test_config.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "# mypy: allow-untyped-defs\nfrom __future__ import annotations\n\nfrom collections.abc import Sequence\nimport dataclasses\nimport importlib.metadata\nimport os\nfrom pathlib import Path\nimport platform\nimport re\nimport sys\nimport textwrap\nfrom typing import Any\n\nimport _pytest._code\nfrom _pytest.config import _get_plugin_specs_as_list\nfrom _pytest.config import _iter_rewritable_modules\nfrom _pytest.config import _strtobool\nfrom _pytest.config import Config\nfrom _pytest.config import ConftestImportFailure\nfrom _pytest.config import ExitCode\nfrom _pytest.config import parse_warning_filter\nfrom _pytest.config.argparsing import get_ini_default_for_type\nfrom _pytest.config.argparsing import Parser\nfrom _pytest.config.exceptions import UsageError\nfrom _pytest.config.findpaths import determine_setup\nfrom _pytest.config.findpaths import get_common_ancestor\nfrom _pytest.config.findpaths import locate_config\nfrom _pytest.monkeypatch import MonkeyPatch\nfrom _pytest.pathlib import absolutepath\nfrom _pytest.pytester import Pytester\nimport pytest\n\n\nclass TestParseIni:\n    @pytest.mark.parametrize(\n        \"section, filename\", [(\"pytest\", \"pytest.ini\"), (\"tool:pytest\", \"setup.cfg\")]\n    )\n    def test_getcfg_and_config(\n        self,\n        pytester: Pytester,\n        tmp_path: Path,\n        section: str,\n        filename: str,\n        monkeypatch: MonkeyPatch,\n    ) -> None:\n        sub = tmp_path / \"sub\"\n        sub.mkdir()\n        monkeypatch.chdir(sub)\n        (tmp_path / filename).write_text(\n            textwrap.dedent(\n                f\"\"\"\\\n                [{section}]\n                name = value\n                \"\"\"\n            ),\n            encoding=\"utf-8\",\n        )\n        _, _, cfg = locate_config(Path.cwd(), [sub])\n        assert cfg[\"name\"] == \"value\"\n        config = pytester.parseconfigure(str(sub))\n        assert config.inicfg[\"name\"] == \"value\"\n\n    def test_setupcfg_uses_toolpytest_with_pytest(self, pytester: Pytester) -> None:\n        p1 = pytester.makepyfile(\"def "}, {"start_line": 36000, "end_line": 38000, "belongs_to": {"file_name": "test_config.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "  def cleanup_last():\n            report.append(\"cleanup_last\")\n\n        @config.add_cleanup\n        def raise_2():\n            report.append(\"raise_2\")\n            raise MyError(\"raise_2\")\n\n        @config.add_cleanup\n        def raise_1():\n            report.append(\"raise_1\")\n            raise MyError(\"raise_1\")\n\n        @config.add_cleanup\n        def cleanup_first():\n            report.append(\"cleanup_first\")\n\n        with pytest.raises(MyError, match=r\"raise_2\"):\n            config._ensure_unconfigure()\n\n        assert report == [\"cleanup_first\", \"raise_1\", \"raise_2\", \"cleanup_last\"]\n\n\nclass TestConfigFromdictargs:\n    def test_basic_behavior(self, _sys_snapshot) -> None:\n        option_dict = {\"verbose\": 444, \"foo\": \"bar\", \"capture\": \"no\"}\n        args = [\"a\", \"b\"]\n\n        config = Config.fromdictargs(option_dict, args)\n        with pytest.raises(AssertionError):\n            config.parse([\"should refuse to parse again\"])\n        assert config.option.verbose == 444\n        assert config.option.foo == \"bar\"\n        assert config.option.capture == \"no\"\n        assert config.args == args\n\n    def test_invocation_params_args(self, _sys_snapshot) -> None:\n        \"\"\"Show that fromdictargs can handle args in their \"orig\" format\"\"\"\n        option_dict: dict[str, object] = {}\n        args = [\"-vvvv\", \"-s\", \"a\", \"b\"]\n\n        config = Config.fromdictargs(option_dict, args)\n        assert config.args == [\"a\", \"b\"]\n        assert config.invocation_params.args == tuple(args)\n        assert config.option.verbose == 4\n        assert config.option.capture == \"no\"\n\n    def test_inifilename(self, tmp_path: Path) -> None:\n        d1 = tmp_path.joinpath(\"foo\")\n        d1.mkdir()\n        p1 = d1.joinpath(\"bar.ini\")\n        p1.touch()\n        p1.write_text(\n            textwrap.dedent(\n                \"\"\"\\\n                [pytest]\n                name = value\n                \"\"\"\n            ),\n            encoding=\"utf-8\",\n        )\n\n        inifilename = \"../../foo/bar.ini\"\n     "}], "retrieved_count": 10, "cost_time": 0.33940649032592773}
{"question": "How does Pytest identify test functions and classes?", "answer": null, "relative_code_list": null, "ground_truth": "Pytest identifies test functions and classes through a combination of naming conventions and configuration-based pattern matching: 1) Test function identification using the funcnamefilter() method in PyCollector class that checks if function names match the python_functions configuration pattern (default: 'test' prefix), 2) Test class identification using the classnamefilter() method that checks if class names match the python_classes configuration pattern (default: 'Test' prefix), 3) Configuration-based pattern matching through _matches_prefix_or_glob_option() method that supports both prefix matching and glob-style patterns, 4) Support for nose-style test identification through isnosetest() method that looks for the __test__ attribute set to True, 5) Function validation through istestfunction() method that ensures the object is callable and not a fixture (checked via fixtures.getfixturemarker()), 6) Class validation through istestclass() method that excludes abstract classes and ensures the class matches naming patterns, 7) Special handling for staticmethods and classmethods by unwrapping them to check their underlying functions, 8) Automatic collection of unittest.TestCase subclasses regardless of naming patterns, as pytest delegates to unittest's collection framework, 9) Configuration options that allow customization of naming patterns through python_files, python_classes, and python_functions settings, 10) Support for multiple glob patterns by adding spaces between patterns in configuration, 11) Node ID generation that creates unique identifiers based on the discovered test structure, 12) Plugin integration through pytest_pycollect_makeitem hook that allows plugins to customize test item creation.", "score": null, "retrieved_content": [{"start_line": 12000, "end_line": 14000, "belongs_to": {"file_name": "python.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "he above doesn't catch.\n    {\"__builtins__\", \"__file__\", \"__cached__\"},\n    # Class.\n    dir(_EmptyClass),\n    # Instance.\n    dir(_EmptyClass()),\n)\ndel _EmptyClass\n# fmt: on\n\n\nclass PyCollector(PyobjMixin, nodes.Collector, abc.ABC):\n    def funcnamefilter(self, name: str) -> bool:\n        return self._matches_prefix_or_glob_option(\"python_functions\", name)\n\n    def isnosetest(self, obj: object) -> bool:\n        \"\"\"Look for the __test__ attribute, which is applied by the\n        @nose.tools.istest decorator.\n        \"\"\"\n        # We explicitly check for \"is True\" here to not mistakenly treat\n        # classes with a custom __getattr__ returning something truthy (like a\n        # function) as test classes.\n        return safe_getattr(obj, \"__test__\", False) is True\n\n    def classnamefilter(self, name: str) -> bool:\n        return self._matches_prefix_or_glob_option(\"python_classes\", name)\n\n    def istestfunction(self, obj: object, name: str) -> bool:\n        if self.funcnamefilter(name) or self.isnosetest(obj):\n            if isinstance(obj, (staticmethod, classmethod)):\n                # staticmethods and classmethods need to be unwrapped.\n                obj = safe_getattr(obj, \"__func__\", False)\n            return callable(obj) and fixtures.getfixturemarker(obj) is None\n        else:\n            return False\n\n    def istestclass(self, obj: object, name: str) -> bool:\n        if not (self.classnamefilter(name) or self.isnosetest(obj)):\n            return False\n        if inspect.isabstract(obj):\n            return False\n        return True\n\n    def _matches_prefix_or_glob_option(self, option_name: str, name: str) -> bool:\n        \"\"\"Check if the given name matches the prefix or glob-pattern defined\n        in ini configuration.\"\"\"\n        for option in self.config.getini(option_name):\n            if name.startswith(option):\n                return True\n            # Check that name looks like a glob-string before calling fnmatch\n            # because this is called "}, {"start_line": 42000, "end_line": 44000, "belongs_to": {"file_name": "collect.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing/python", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "def intest_foo(self):\n                    pass\n\n                def test_bar(self):\n                    pass\n        \"\"\"\n        )\n        classcol = pytester.collect_by_name(modcol, \"TestClass\")\n        assert isinstance(classcol, Class)\n        path, lineno, msg = classcol.reportinfo()\n        func = next(iter(classcol.collect()))\n        assert isinstance(func, Function)\n        path, lineno, msg = func.reportinfo()\n\n\ndef test_customized_python_discovery(pytester: Pytester) -> None:\n    pytester.makeini(\n        \"\"\"\n        [pytest]\n        python_files=check_*.py\n        python_classes=Check\n        python_functions=check\n    \"\"\"\n    )\n    p = pytester.makepyfile(\n        \"\"\"\n        def check_simple():\n            pass\n        class CheckMyApp(object):\n            def check_meth(self):\n                pass\n    \"\"\"\n    )\n    p2 = p.with_name(p.name.replace(\"test\", \"check\"))\n    p.rename(p2)\n    result = pytester.runpytest(\"--collect-only\", \"-s\")\n    result.stdout.fnmatch_lines(\n        [\"*check_customized*\", \"*check_simple*\", \"*CheckMyApp*\", \"*check_meth*\"]\n    )\n\n    result = pytester.runpytest()\n    assert result.ret == 0\n    result.stdout.fnmatch_lines([\"*2 passed*\"])\n\n\ndef test_customized_python_discovery_functions(pytester: Pytester) -> None:\n    pytester.makeini(\n        \"\"\"\n        [pytest]\n        python_functions=_test\n    \"\"\"\n    )\n    pytester.makepyfile(\n        \"\"\"\n        def _test_underscore():\n            pass\n    \"\"\"\n    )\n    result = pytester.runpytest(\"--collect-only\", \"-s\")\n    result.stdout.fnmatch_lines([\"*_test_underscore*\"])\n\n    result = pytester.runpytest()\n    assert result.ret == 0\n    result.stdout.fnmatch_lines([\"*1 passed*\"])\n\n\ndef test_unorderable_types(pytester: Pytester) -> None:\n    pytester.makepyfile(\n        \"\"\"\n        class TestJoinEmpty(object):\n            pass\n\n        def make_test():\n            class Test(object):\n                pass\n            Test.__name__ = \"TestFoo\"\n            return Test\n        TestFoo = ma"}, {"start_line": 30000, "end_line": 32000, "belongs_to": {"file_name": "test_collection.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "ined]\n        assert ids == [\"TestCase.test_classmethod\"]\n\n    def test_class_and_functions_discovery_using_glob(self, pytester: Pytester) -> None:\n        \"\"\"Test that Python_classes and Python_functions config options work\n        as prefixes and glob-like patterns (#600).\"\"\"\n        pytester.makeini(\n            \"\"\"\n            [pytest]\n            python_classes = *Suite Test\n            python_functions = *_test test\n        \"\"\"\n        )\n        p = pytester.makepyfile(\n            \"\"\"\n            class MyTestSuite(object):\n                def x_test(self):\n                    pass\n\n            class TestCase(object):\n                def test_y(self):\n                    pass\n        \"\"\"\n        )\n        items, reprec = pytester.inline_genitems(p)\n        ids = [x.getmodpath() for x in items]  # type: ignore[attr-defined]\n        assert ids == [\"MyTestSuite.x_test\", \"TestCase.test_y\"]\n\n\ndef test_matchnodes_two_collections_same_file(pytester: Pytester) -> None:\n    pytester.makeconftest(\n        \"\"\"\n        import pytest\n        def pytest_configure(config):\n            config.pluginmanager.register(Plugin2())\n\n        class Plugin2(object):\n            def pytest_collect_file(self, file_path, parent):\n                if file_path.suffix == \".abc\":\n                    return MyFile2.from_parent(path=file_path, parent=parent)\n\n        def pytest_collect_file(file_path, parent):\n            if file_path.suffix == \".abc\":\n                return MyFile1.from_parent(path=file_path, parent=parent)\n\n        class MyFile1(pytest.File):\n            def collect(self):\n                yield Item1.from_parent(name=\"item1\", parent=self)\n\n        class MyFile2(pytest.File):\n            def collect(self):\n                yield Item2.from_parent(name=\"item2\", parent=self)\n\n        class Item1(pytest.Item):\n            def runtest(self):\n                pass\n\n        class Item2(pytest.Item):\n            def runtest(self):\n                pass\n    \"\"\"\n    )\n    p = pytester.ma"}, {"start_line": 29000, "end_line": 31000, "belongs_to": {"file_name": "test_collection.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "re[attr-defined]\n        assert items[1].getmodpath() == \"TestX.testmethod_one\"  # type: ignore[attr-defined]\n        assert items[2].getmodpath() == \"TestY.testmethod_one\"  # type: ignore[attr-defined]\n        # PR #6202: Fix incorrect result of getmodpath method. (Resolves issue #6189)\n        assert items[3].getmodpath() == \"TestY.testmethod_two[.[]\"  # type: ignore[attr-defined]\n\n        s = items[0].getmodpath(stopatmodule=False)  # type: ignore[attr-defined]\n        assert s.endswith(\"test_example_items1.testone\")\n        print(s)\n\n    def test_classmethod_is_discovered(self, pytester: Pytester) -> None:\n        \"\"\"Test that classmethods are discovered\"\"\"\n        p = pytester.makepyfile(\n            \"\"\"\n            class TestCase:\n                @classmethod\n                def test_classmethod(cls) -> None:\n                    pass\n            \"\"\"\n        )\n        items, reprec = pytester.inline_genitems(p)\n        ids = [x.getmodpath() for x in items]  # type: ignore[attr-defined]\n        assert ids == [\"TestCase.test_classmethod\"]\n\n    def test_class_and_functions_discovery_using_glob(self, pytester: Pytester) -> None:\n        \"\"\"Test that Python_classes and Python_functions config options work\n        as prefixes and glob-like patterns (#600).\"\"\"\n        pytester.makeini(\n            \"\"\"\n            [pytest]\n            python_classes = *Suite Test\n            python_functions = *_test test\n        \"\"\"\n        )\n        p = pytester.makepyfile(\n            \"\"\"\n            class MyTestSuite(object):\n                def x_test(self):\n                    pass\n\n            class TestCase(object):\n                def test_y(self):\n                    pass\n        \"\"\"\n        )\n        items, reprec = pytester.inline_genitems(p)\n        ids = [x.getmodpath() for x in items]  # type: ignore[attr-defined]\n        assert ids == [\"MyTestSuite.x_test\", \"TestCase.test_y\"]\n\n\ndef test_matchnodes_two_collections_same_file(pytester: Pytester) -> None:\n    pytester.makec"}, {"start_line": 3000, "end_line": 5000, "belongs_to": {"file_name": "test_collection.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "dule is not None\n        assert fn.cls is not None\n        assert fn.instance is not None\n        assert fn.function is not None\n\n    def test_getcustomfile_roundtrip(self, pytester: Pytester) -> None:\n        hello = pytester.makefile(\".xxx\", hello=\"world\")\n        pytester.makepyfile(\n            conftest=\"\"\"\n            import pytest\n            class CustomFile(pytest.File):\n                def collect(self):\n                    return []\n            def pytest_collect_file(file_path, parent):\n                if file_path.suffix == \".xxx\":\n                    return CustomFile.from_parent(path=file_path, parent=parent)\n        \"\"\"\n        )\n        node = pytester.getpathnode(hello)\n        assert isinstance(node, pytest.File)\n        assert node.name == \"hello.xxx\"\n        nodes = node.session.perform_collect([node.nodeid], genitems=False)\n        assert len(nodes) == 1\n        assert isinstance(nodes[0], pytest.File)\n\n    def test_can_skip_class_with_test_attr(self, pytester: Pytester) -> None:\n        \"\"\"Assure test class is skipped when using `__test__=False` (See #2007).\"\"\"\n        pytester.makepyfile(\n            \"\"\"\n            class TestFoo(object):\n                __test__ = False\n                def __init__(self):\n                    pass\n                def test_foo():\n                    assert True\n        \"\"\"\n        )\n        result = pytester.runpytest()\n        result.stdout.fnmatch_lines([\"collected 0 items\", \"*no tests ran in*\"])\n\n\nclass TestCollectFS:\n    def test_ignored_certain_directories(self, pytester: Pytester) -> None:\n        tmp_path = pytester.path\n        ensure_file(tmp_path / \"build\" / \"test_notfound.py\")\n        ensure_file(tmp_path / \"dist\" / \"test_notfound.py\")\n        ensure_file(tmp_path / \"_darcs\" / \"test_notfound.py\")\n        ensure_file(tmp_path / \"CVS\" / \"test_notfound.py\")\n        ensure_file(tmp_path / \"{arch}\" / \"test_notfound.py\")\n        ensure_file(tmp_path / \".whatever\" / \"test_notfound.py\")\n        ensure_file(t"}, {"start_line": 8000, "end_line": 10000, "belongs_to": {"file_name": "integration.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing/python", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "\"\"\"\n            *fix count 0*\n            *fix count 1*\n        \"\"\"\n        )\n        result.stdout.fnmatch_lines(\n            \"\"\"\n            *2 passed*\n        \"\"\"\n        )\n\n\ndef test_pytestconfig_is_session_scoped() -> None:\n    from _pytest.fixtures import pytestconfig\n\n    marker = getfixturemarker(pytestconfig)\n    assert marker is not None\n    assert marker.scope == \"session\"\n\n\nclass TestNoselikeTestAttribute:\n    def test_module_with_global_test(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            __test__ = False\n            def test_hello():\n                pass\n        \"\"\"\n        )\n        reprec = pytester.inline_run()\n        assert not reprec.getfailedcollections()\n        calls = reprec.getreports(\"pytest_runtest_logreport\")\n        assert not calls\n\n    def test_class_and_method(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            __test__ = True\n            def test_func():\n                pass\n            test_func.__test__ = False\n\n            class TestSome(object):\n                __test__ = False\n                def test_method(self):\n                    pass\n        \"\"\"\n        )\n        reprec = pytester.inline_run()\n        assert not reprec.getfailedcollections()\n        calls = reprec.getreports(\"pytest_runtest_logreport\")\n        assert not calls\n\n    def test_unittest_class(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            import unittest\n            class TC(unittest.TestCase):\n                def test_1(self):\n                    pass\n            class TC2(unittest.TestCase):\n                __test__ = False\n                def test_2(self):\n                    pass\n        \"\"\"\n        )\n        reprec = pytester.inline_run()\n        assert not reprec.getfailedcollections()\n        call = reprec.getcalls(\"pytest_collection_modifyitems\")[0]\n        assert len(call.items) == 1\n        assert call.items[0].cls.__name__"}, {"start_line": 41000, "end_line": 43000, "belongs_to": {"file_name": "collect.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing/python", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "            \"\"\"\n            # lineno 0\n            class TestClass(object):\n                def test_hello(self): pass\n        \"\"\"\n        )\n        classcol = pytester.collect_by_name(modcol, \"TestClass\")\n        assert isinstance(classcol, Class)\n        path, lineno, msg = classcol.reportinfo()\n        assert os.fspath(path) == str(modcol.path)\n        assert lineno == 1\n        assert msg == \"TestClass\"\n\n    @pytest.mark.filterwarnings(\n        \"ignore:usage of Generator.Function is deprecated, please use pytest.Function instead\"\n    )\n    def test_reportinfo_with_nasty_getattr(self, pytester: Pytester) -> None:\n        # https://github.com/pytest-dev/pytest/issues/1204\n        modcol = pytester.getmodulecol(\n            \"\"\"\n            # lineno 0\n            class TestClass:\n                def __getattr__(self, name):\n                    return \"this is not an int\"\n\n                def __class_getattr__(cls, name):\n                    return \"this is not an int\"\n\n                def intest_foo(self):\n                    pass\n\n                def test_bar(self):\n                    pass\n        \"\"\"\n        )\n        classcol = pytester.collect_by_name(modcol, \"TestClass\")\n        assert isinstance(classcol, Class)\n        path, lineno, msg = classcol.reportinfo()\n        func = next(iter(classcol.collect()))\n        assert isinstance(func, Function)\n        path, lineno, msg = func.reportinfo()\n\n\ndef test_customized_python_discovery(pytester: Pytester) -> None:\n    pytester.makeini(\n        \"\"\"\n        [pytest]\n        python_files=check_*.py\n        python_classes=Check\n        python_functions=check\n    \"\"\"\n    )\n    p = pytester.makepyfile(\n        \"\"\"\n        def check_simple():\n            pass\n        class CheckMyApp(object):\n            def check_meth(self):\n                pass\n    \"\"\"\n    )\n    p2 = p.with_name(p.name.replace(\"test\", \"check\"))\n    p.rename(p2)\n    result = pytester.runpytest(\"--collect-only\", \"-s\")\n    result.stdout.fnmatch_lines(\n   "}, {"start_line": 43000, "end_line": 45000, "belongs_to": {"file_name": "collect.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing/python", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "     [\"*check_customized*\", \"*check_simple*\", \"*CheckMyApp*\", \"*check_meth*\"]\n    )\n\n    result = pytester.runpytest()\n    assert result.ret == 0\n    result.stdout.fnmatch_lines([\"*2 passed*\"])\n\n\ndef test_customized_python_discovery_functions(pytester: Pytester) -> None:\n    pytester.makeini(\n        \"\"\"\n        [pytest]\n        python_functions=_test\n    \"\"\"\n    )\n    pytester.makepyfile(\n        \"\"\"\n        def _test_underscore():\n            pass\n    \"\"\"\n    )\n    result = pytester.runpytest(\"--collect-only\", \"-s\")\n    result.stdout.fnmatch_lines([\"*_test_underscore*\"])\n\n    result = pytester.runpytest()\n    assert result.ret == 0\n    result.stdout.fnmatch_lines([\"*1 passed*\"])\n\n\ndef test_unorderable_types(pytester: Pytester) -> None:\n    pytester.makepyfile(\n        \"\"\"\n        class TestJoinEmpty(object):\n            pass\n\n        def make_test():\n            class Test(object):\n                pass\n            Test.__name__ = \"TestFoo\"\n            return Test\n        TestFoo = make_test()\n    \"\"\"\n    )\n    result = pytester.runpytest()\n    result.stdout.no_fnmatch_line(\"*TypeError*\")\n    assert result.ret == ExitCode.NO_TESTS_COLLECTED\n\n\n@pytest.mark.filterwarnings(\"default::pytest.PytestCollectionWarning\")\ndef test_dont_collect_non_function_callable(pytester: Pytester) -> None:\n    \"\"\"Test for issue https://github.com/pytest-dev/pytest/issues/331\n\n    In this case an INTERNALERROR occurred trying to report the failure of\n    a test like this one because pytest failed to get the source lines.\n    \"\"\"\n    pytester.makepyfile(\n        \"\"\"\n        class Oh(object):\n            def __call__(self):\n                pass\n\n        test_a = Oh()\n\n        def test_real():\n            pass\n    \"\"\"\n    )\n    result = pytester.runpytest()\n    result.stdout.fnmatch_lines(\n        [\n            \"*collected 1 item*\",\n            \"*test_dont_collect_non_function_callable.py:2: *cannot collect 'test_a' because it is not a function*\",\n            \"*1 passed, 1 warning in *\",\n   "}, {"start_line": 4000, "end_line": 6000, "belongs_to": {"file_name": "test_collection.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "ester) -> None:\n        \"\"\"Assure test class is skipped when using `__test__=False` (See #2007).\"\"\"\n        pytester.makepyfile(\n            \"\"\"\n            class TestFoo(object):\n                __test__ = False\n                def __init__(self):\n                    pass\n                def test_foo():\n                    assert True\n        \"\"\"\n        )\n        result = pytester.runpytest()\n        result.stdout.fnmatch_lines([\"collected 0 items\", \"*no tests ran in*\"])\n\n\nclass TestCollectFS:\n    def test_ignored_certain_directories(self, pytester: Pytester) -> None:\n        tmp_path = pytester.path\n        ensure_file(tmp_path / \"build\" / \"test_notfound.py\")\n        ensure_file(tmp_path / \"dist\" / \"test_notfound.py\")\n        ensure_file(tmp_path / \"_darcs\" / \"test_notfound.py\")\n        ensure_file(tmp_path / \"CVS\" / \"test_notfound.py\")\n        ensure_file(tmp_path / \"{arch}\" / \"test_notfound.py\")\n        ensure_file(tmp_path / \".whatever\" / \"test_notfound.py\")\n        ensure_file(tmp_path / \".bzr\" / \"test_notfound.py\")\n        ensure_file(tmp_path / \"normal\" / \"test_found.py\")\n        for x in tmp_path.rglob(\"test_*.py\"):\n            x.write_text(\"def test_hello(): pass\", encoding=\"utf-8\")\n\n        result = pytester.runpytest(\"--collect-only\")\n        s = result.stdout.str()\n        assert \"test_notfound\" not in s\n        assert \"test_found\" in s\n\n    known_environment_types = pytest.mark.parametrize(\n        \"env_path\",\n        [\n            pytest.param(PurePath(\"pyvenv.cfg\"), id=\"venv\"),\n            pytest.param(PurePath(\"conda-meta\", \"history\"), id=\"conda\"),\n        ],\n    )\n\n    @known_environment_types\n    def test_ignored_virtualenvs(self, pytester: Pytester, env_path: PurePath) -> None:\n        ensure_file(pytester.path / \"virtual\" / env_path)\n        testfile = ensure_file(pytester.path / \"virtual\" / \"test_invenv.py\")\n        testfile.write_text(\"def test_hello(): pass\", encoding=\"utf-8\")\n\n        # by default, ignore tests inside a virtualenv\n        r"}, {"start_line": 11000, "end_line": 13000, "belongs_to": {"file_name": "python.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "    parts = []\n        for node in self.iter_parents():\n            name = node.name\n            if isinstance(node, Module):\n                name = os.path.splitext(name)[0]\n                if stopatmodule:\n                    if includemodule:\n                        parts.append(name)\n                    break\n            parts.append(name)\n        parts.reverse()\n        return \".\".join(parts)\n\n    def reportinfo(self) -> tuple[os.PathLike[str] | str, int | None, str]:\n        # XXX caching?\n        path, lineno = getfslineno(self.obj)\n        modpath = self.getmodpath()\n        return path, lineno, modpath\n\n\n# As an optimization, these builtin attribute names are pre-ignored when\n# iterating over an object during collection -- the pytest_pycollect_makeitem\n# hook is not called for them.\n# fmt: off\nclass _EmptyClass: pass  # noqa: E701\nIGNORED_ATTRIBUTES = frozenset.union(\n    frozenset(),\n    # Module.\n    dir(types.ModuleType(\"empty_module\")),\n    # Some extra module attributes the above doesn't catch.\n    {\"__builtins__\", \"__file__\", \"__cached__\"},\n    # Class.\n    dir(_EmptyClass),\n    # Instance.\n    dir(_EmptyClass()),\n)\ndel _EmptyClass\n# fmt: on\n\n\nclass PyCollector(PyobjMixin, nodes.Collector, abc.ABC):\n    def funcnamefilter(self, name: str) -> bool:\n        return self._matches_prefix_or_glob_option(\"python_functions\", name)\n\n    def isnosetest(self, obj: object) -> bool:\n        \"\"\"Look for the __test__ attribute, which is applied by the\n        @nose.tools.istest decorator.\n        \"\"\"\n        # We explicitly check for \"is True\" here to not mistakenly treat\n        # classes with a custom __getattr__ returning something truthy (like a\n        # function) as test classes.\n        return safe_getattr(obj, \"__test__\", False) is True\n\n    def classnamefilter(self, name: str) -> bool:\n        return self._matches_prefix_or_glob_option(\"python_classes\", name)\n\n    def istestfunction(self, obj: object, name: str) -> bool:\n        if self.funcnamefilter(name)"}], "retrieved_count": 10, "cost_time": 0.3402862548828125}
{"question": "How does Pytest's fixture system work?", "answer": null, "relative_code_list": null, "ground_truth": "Pytest's fixture system works through a comprehensive dependency injection and lifecycle management system: 1) Fixture definition using the @pytest.fixture decorator that marks functions as fixture factories, with configurable scope, parameters, and autouse behavior, 2) FixtureManager class that serves as the central registry storing all fixture definitions in _arg2fixturedefs mapping fixture names to FixtureDef objects, 3) Fixture discovery during collection through parsefactories() method that scans modules and plugins for fixture definitions, 4) Dependency resolution through getfixtureinfo() method that analyzes test functions to identify required fixtures and their dependencies, 5) Fixture execution through pytest_fixture_setup hook that calls fixture functions and manages their lifecycle, 6) Scope management with five levels (function, class, module, package, session) that determine when fixtures are created and destroyed, 7) Caching mechanism where fixture instances are stored in FixtureDef.cached_result and reused within their scope, 8) Parameter support through params attribute that allows fixtures to be parametrized and run multiple times, 9) Teardown/cleanup through yield statements in fixtures that execute cleanup code regardless of test outcome, 10) Autouse fixtures that are automatically activated for all tests in their scope without explicit requests, 11) FixtureRequest class that provides access to test context and parameter values during fixture execution, 12) Integration with the plugin system where fixtures can be defined in plugins, conftest files, or test modules.", "score": null, "retrieved_content": [{"start_line": 33000, "end_line": 35000, "belongs_to": {"file_name": "fixtures.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing/python", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "rt values == [\"module\", \"function\", \"class\",\n                             \"function\", \"method\", \"function\"]\n        \"\"\"\n        )\n        reprec = pytester.inline_run(\"-v\")\n        reprec.assertoutcome(passed=3)\n\n    def test_fixtures_sub_subdir_normalize_sep(self, pytester: Pytester) -> None:\n        # this tests that normalization of nodeids takes place\n        b = pytester.path.joinpath(\"tests\", \"unit\")\n        b.mkdir(parents=True)\n        b.joinpath(\"conftest.py\").write_text(\n            textwrap.dedent(\n                \"\"\"\\\n                import pytest\n                @pytest.fixture\n                def arg1():\n                    pass\n                \"\"\"\n            ),\n            encoding=\"utf-8\",\n        )\n        p = b.joinpath(\"test_module.py\")\n        p.write_text(\"def test_func(arg1): pass\", encoding=\"utf-8\")\n        result = pytester.runpytest(p, \"--fixtures\")\n        assert result.ret == 0\n        result.stdout.fnmatch_lines(\n            \"\"\"\n            *fixtures defined*conftest*\n            *arg1*\n        \"\"\"\n        )\n\n    def test_show_fixtures_color_yes(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\"def test_this(): assert 1\")\n        result = pytester.runpytest(\"--color=yes\", \"--fixtures\")\n        assert \"\\x1b[32mtmp_path\" in result.stdout.str()\n\n    def test_newstyle_with_request(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n            @pytest.fixture()\n            def arg(request):\n                pass\n            def test_1(arg):\n                pass\n        \"\"\"\n        )\n        reprec = pytester.inline_run()\n        reprec.assertoutcome(passed=1)\n\n    def test_setupcontext_no_param(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n            @pytest.fixture(params=[1,2])\n            def arg(request):\n                return request.param\n\n            @pytest.fixture(autouse=True)\n            def mysetup(requ"}, {"start_line": 52000, "end_line": 54000, "belongs_to": {"file_name": "fixtures.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing/python", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "               return request._fixturemanager\n\n            @pytest.fixture\n            def item(request):\n                return request._pyfuncitem\n        \"\"\"\n        )\n        return pytester\n\n    def test_parsefactories_evil_objects_issue214(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            class A(object):\n                def __call__(self):\n                    pass\n                def __getattr__(self, name):\n                    raise RuntimeError()\n            a = A()\n            def test_hello():\n                pass\n        \"\"\"\n        )\n        reprec = pytester.inline_run()\n        reprec.assertoutcome(passed=1, failed=0)\n\n    def test_parsefactories_conftest(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            def test_hello(item, fm):\n                for name in (\"fm\", \"hello\", \"item\"):\n                    faclist = fm.getfixturedefs(name, item)\n                    assert len(faclist) == 1\n                    fac = faclist[0]\n                    assert fac.func.__name__ == name\n        \"\"\"\n        )\n        reprec = pytester.inline_run(\"-s\")\n        reprec.assertoutcome(passed=1)\n\n    def test_parsefactories_conftest_and_module_and_class(\n        self, pytester: Pytester\n    ) -> None:\n        pytester.makepyfile(\n            \"\"\"\\\n            import pytest\n\n            @pytest.fixture\n            def hello(request):\n                return \"module\"\n            class TestClass(object):\n                @pytest.fixture\n                def hello(self, request):\n                    return \"class\"\n                def test_hello(self, item, fm):\n                    faclist = fm.getfixturedefs(\"hello\", item)\n                    print(faclist)\n                    assert len(faclist) == 3\n\n                    assert faclist[0].func(item._request) == \"conftest\"\n                    assert faclist[1].func(item._request) == \"module\"\n                    assert faclist[2].func(item._request"}, {"start_line": 42000, "end_line": 44000, "belongs_to": {"file_name": "fixtures.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing/python", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "stdout.fnmatch_lines([\"*4 passed*\"])\n\n    def test_funcarg_parametrized_and_used_twice(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n            values = []\n            @pytest.fixture(params=[1,2])\n            def arg1(request):\n                values.append(1)\n                return request.param\n\n            @pytest.fixture()\n            def arg2(arg1):\n                return arg1 + 1\n\n            def test_add(arg1, arg2):\n                assert arg2 == arg1 + 1\n                assert len(values) == arg1\n        \"\"\"\n        )\n        result = pytester.runpytest()\n        result.stdout.fnmatch_lines([\"*2 passed*\"])\n\n    def test_factory_uses_unknown_funcarg_as_dependency_error(\n        self, pytester: Pytester\n    ) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n\n            @pytest.fixture()\n            def fail(missing):\n                return\n\n            @pytest.fixture()\n            def call_fail(fail):\n                return\n\n            def test_missing(call_fail):\n                pass\n            \"\"\"\n        )\n        result = pytester.runpytest()\n        result.stdout.fnmatch_lines(\n            \"\"\"\n            *pytest.fixture()*\n            *def call_fail(fail)*\n            *pytest.fixture()*\n            *def fail*\n            *fixture*'missing'*not found*\n        \"\"\"\n        )\n\n    def test_factory_setup_as_classes_fails(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n            class arg1(object):\n                def __init__(self, request):\n                    self.x = 1\n            arg1 = pytest.fixture()(arg1)\n\n        \"\"\"\n        )\n        reprec = pytester.inline_run()\n        values = reprec.getfailedcollections()\n        assert len(values) == 1\n\n    def test_usefixtures_marker(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n\n            val"}, {"start_line": 53000, "end_line": 55000, "belongs_to": {"file_name": "fixtures.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing/python", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "                 fac = faclist[0]\n                    assert fac.func.__name__ == name\n        \"\"\"\n        )\n        reprec = pytester.inline_run(\"-s\")\n        reprec.assertoutcome(passed=1)\n\n    def test_parsefactories_conftest_and_module_and_class(\n        self, pytester: Pytester\n    ) -> None:\n        pytester.makepyfile(\n            \"\"\"\\\n            import pytest\n\n            @pytest.fixture\n            def hello(request):\n                return \"module\"\n            class TestClass(object):\n                @pytest.fixture\n                def hello(self, request):\n                    return \"class\"\n                def test_hello(self, item, fm):\n                    faclist = fm.getfixturedefs(\"hello\", item)\n                    print(faclist)\n                    assert len(faclist) == 3\n\n                    assert faclist[0].func(item._request) == \"conftest\"\n                    assert faclist[1].func(item._request) == \"module\"\n                    assert faclist[2].func(item._request) == \"class\"\n            \"\"\"\n        )\n        reprec = pytester.inline_run(\"-s\")\n        reprec.assertoutcome(passed=1)\n\n    def test_parsefactories_relative_node_ids(\n        self, pytester: Pytester, monkeypatch: MonkeyPatch\n    ) -> None:\n        # example mostly taken from:\n        # https://mail.python.org/pipermail/pytest-dev/2014-September/002617.html\n        runner = pytester.mkdir(\"runner\")\n        package = pytester.mkdir(\"package\")\n        package.joinpath(\"conftest.py\").write_text(\n            textwrap.dedent(\n                \"\"\"\\\n            import pytest\n            @pytest.fixture\n            def one():\n                return 1\n            \"\"\"\n            ),\n            encoding=\"utf-8\",\n        )\n        package.joinpath(\"test_x.py\").write_text(\n            textwrap.dedent(\n                \"\"\"\\\n                def test_x(one):\n                    assert one == 1\n                \"\"\"\n            ),\n            encoding=\"utf-8\",\n        )\n        sub = package.joinpath(\"s"}, {"start_line": 32000, "end_line": 34000, "belongs_to": {"file_name": "fixtures.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing/python", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "value_dynamic.py\")\n        result = pytester.runpytest()\n        result.stdout.fnmatch_lines([\"*1 passed*\"])\n\n    def test_setupdecorator_and_xunit(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n            values = []\n            @pytest.fixture(scope='module', autouse=True)\n            def setup_module():\n                values.append(\"module\")\n            @pytest.fixture(autouse=True)\n            def setup_function():\n                values.append(\"function\")\n\n            def test_func():\n                pass\n\n            class TestClass(object):\n                @pytest.fixture(scope=\"class\", autouse=True)\n                def setup_class(self):\n                    values.append(\"class\")\n                @pytest.fixture(autouse=True)\n                def setup_method(self):\n                    values.append(\"method\")\n                def test_method(self):\n                    pass\n            def test_all():\n                assert values == [\"module\", \"function\", \"class\",\n                             \"function\", \"method\", \"function\"]\n        \"\"\"\n        )\n        reprec = pytester.inline_run(\"-v\")\n        reprec.assertoutcome(passed=3)\n\n    def test_fixtures_sub_subdir_normalize_sep(self, pytester: Pytester) -> None:\n        # this tests that normalization of nodeids takes place\n        b = pytester.path.joinpath(\"tests\", \"unit\")\n        b.mkdir(parents=True)\n        b.joinpath(\"conftest.py\").write_text(\n            textwrap.dedent(\n                \"\"\"\\\n                import pytest\n                @pytest.fixture\n                def arg1():\n                    pass\n                \"\"\"\n            ),\n            encoding=\"utf-8\",\n        )\n        p = b.joinpath(\"test_module.py\")\n        p.write_text(\"def test_func(arg1): pass\", encoding=\"utf-8\")\n        result = pytester.runpytest(p, \"--fixtures\")\n        assert result.ret == 0\n        result.stdout.fnmatch_lines(\n            \"\"\"\n            *fixtures define"}, {"start_line": 103000, "end_line": 105000, "belongs_to": {"file_name": "fixtures.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing/python", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "bda: values.append(\"fin%s\" % arg))\n                values.append(\"setup%s\" % arg)\n\n            values = []\n            def test_1(arg):\n                values.append(arg)\n            def test_2(arg):\n                values.append(arg)\n            def test_3():\n                import pprint\n                pprint.pprint(values)\n                if arg == 1:\n                    assert values == [\"setup1\", 1, 1, ]\n                elif arg == 2:\n                    assert values == [\"setup1\", 1, 1, \"fin1\",\n                                 \"setup2\", 2, 2, ]\n\n        \"\"\"\n        )\n        reprec = pytester.inline_run(\"-v\")\n        reprec.assertoutcome(passed=6)\n\n    def test_fixture_marked_function_not_collected_as_test(\n        self, pytester: Pytester\n    ) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n            @pytest.fixture\n            def test_app():\n                return 1\n\n            def test_something(test_app):\n                assert test_app == 1\n        \"\"\"\n        )\n        reprec = pytester.inline_run()\n        reprec.assertoutcome(passed=1)\n\n    def test_params_and_ids(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n\n            @pytest.fixture(params=[object(), object()],\n                            ids=['alpha', 'beta'])\n            def fix(request):\n                return request.param\n\n            def test_foo(fix):\n                assert 1\n        \"\"\"\n        )\n        res = pytester.runpytest(\"-v\")\n        res.stdout.fnmatch_lines([\"*test_foo*alpha*\", \"*test_foo*beta*\"])\n\n    def test_params_and_ids_yieldfixture(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n\n            @pytest.fixture(params=[object(), object()], ids=['alpha', 'beta'])\n            def fix(request):\n                 yield request.param\n\n            def test_foo(fix):\n                assert 1\n        \"\"\"\n        )\n        res = pyte"}, {"start_line": 17000, "end_line": 19000, "belongs_to": {"file_name": "fixtures.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing/python", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "ram\n            \"\"\"\n        )\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n\n            @pytest.fixture(params=[10, 20])\n            def foo(foo, request):\n                assert request.param == foo\n                return foo * 2\n\n            def test_spam(foo):\n                assert foo in (20, 40)\n            \"\"\"\n        )\n        result = pytester.runpytest()\n        result.stdout.fnmatch_lines([\"*2 passed*\"])\n\n    def test_autouse_fixture_plugin(self, pytester: Pytester) -> None:\n        # A fixture from a plugin has no baseid set, which screwed up\n        # the autouse fixture handling.\n        pytester.makepyfile(\n            testplugin=\"\"\"\n            import pytest\n\n            @pytest.fixture(autouse=True)\n            def foo(request):\n                request.function.foo = 7\n        \"\"\"\n        )\n        pytester.syspathinsert()\n        pytester.makepyfile(\n            \"\"\"\n            pytest_plugins = 'testplugin'\n\n            def test_foo(request):\n                assert request.function.foo == 7\n        \"\"\"\n        )\n        result = pytester.runpytest()\n        assert result.ret == 0\n\n    def test_funcarg_lookup_error(self, pytester: Pytester) -> None:\n        pytester.makeconftest(\n            \"\"\"\n            import pytest\n\n            @pytest.fixture\n            def a_fixture(): pass\n\n            @pytest.fixture\n            def b_fixture(): pass\n\n            @pytest.fixture\n            def c_fixture(): pass\n\n            @pytest.fixture\n            def d_fixture(): pass\n        \"\"\"\n        )\n        pytester.makepyfile(\n            \"\"\"\n            def test_lookup_error(unknown):\n                pass\n        \"\"\"\n        )\n        result = pytester.runpytest()\n        result.stdout.fnmatch_lines(\n            [\n                \"*ERROR at setup of test_lookup_error*\",\n                \"  def test_lookup_error(unknown):*\",\n                \"E       fixture 'unknown' not found\",\n                \">       available fixtures:*a_fixture,"}, {"start_line": 38000, "end_line": 40000, "belongs_to": {"file_name": "fixtures.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing/python", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "fixturedec(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n            @pytest.fixture\n            def arg1():\n                return 1\n\n            def test_func(arg1):\n                assert arg1 == 1\n        \"\"\"\n        )\n        reprec = pytester.inline_run()\n        reprec.assertoutcome(passed=1)\n\n    def test_receives_funcargs(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n            @pytest.fixture()\n            def arg1():\n                return 1\n\n            @pytest.fixture()\n            def arg2(arg1):\n                return arg1 + 1\n\n            def test_add(arg2):\n                assert arg2 == 2\n            def test_all(arg1, arg2):\n                assert arg1 == 1\n                assert arg2 == 2\n        \"\"\"\n        )\n        reprec = pytester.inline_run()\n        reprec.assertoutcome(passed=2)\n\n    def test_receives_funcargs_scope_mismatch(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n            @pytest.fixture(scope=\"function\")\n            def arg1():\n                return 1\n\n            @pytest.fixture(scope=\"module\")\n            def arg2(arg1):\n                return arg1 + 1\n\n            def test_add(arg2):\n                assert arg2 == 2\n        \"\"\"\n        )\n        result = pytester.runpytest()\n        result.stdout.fnmatch_lines(\n            [\n                \"*ScopeMismatch*Requesting fixture stack*\",\n                \"test_receives_funcargs_scope_mismatch.py:6:  def arg2(arg1)\",\n                \"Requested fixture:\",\n                \"test_receives_funcargs_scope_mismatch.py:2:  def arg1()\",\n                \"*1 error*\",\n            ]\n        )\n\n    def test_receives_funcargs_scope_mismatch_issue660(\n        self, pytester: Pytester\n    ) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n            @pytest.fixture(scope=\"function\")\n    "}, {"start_line": 2000, "end_line": 4000, "belongs_to": {"file_name": "test_setuponly.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "pytest\n        @pytest.fixture(scope='function')\n        def arg_same(arg_same):\n            \"\"\"function scoped fixture\"\"\"\n        def test_arg1(arg_same):\n            pass\n    '''\n    )\n\n    result = pytester.runpytest(mode, p)\n    assert result.ret == 0\n\n    result.stdout.fnmatch_lines(\n        [\n            \"SETUP    S arg_same*\",\n            \"*SETUP    F arg_same (fixtures used: arg_same)*\",\n            \"*test_arg1 (fixtures used: arg_same)*\",\n            \"*TEARDOWN F arg_same*\",\n            \"TEARDOWN S arg_same*\",\n        ]\n    )\n\n\ndef test_show_fixtures_with_autouse(pytester: Pytester, mode) -> None:\n    p = pytester.makepyfile(\n        '''\n        import pytest\n        @pytest.fixture\n        def arg_function():\n            \"\"\"function scoped fixture\"\"\"\n        @pytest.fixture(scope='session', autouse=True)\n        def arg_session():\n            \"\"\"session scoped fixture\"\"\"\n        def test_arg1(arg_function):\n            pass\n    '''\n    )\n\n    result = pytester.runpytest(mode, p)\n    assert result.ret == 0\n\n    result.stdout.fnmatch_lines(\n        [\n            \"SETUP    S arg_session*\",\n            \"*SETUP    F arg_function*\",\n            \"*test_arg1 (fixtures used: arg_function, arg_session)*\",\n        ]\n    )\n\n\ndef test_show_fixtures_with_parameters(pytester: Pytester, mode) -> None:\n    pytester.makeconftest(\n        '''\n        import pytest\n        @pytest.fixture(scope='session', params=['foo', 'bar'])\n        def arg_same():\n            \"\"\"session scoped fixture\"\"\"\n        '''\n    )\n    p = pytester.makepyfile(\n        '''\n        import pytest\n        @pytest.fixture(scope='function')\n        def arg_other(arg_same):\n            \"\"\"function scoped fixture\"\"\"\n        def test_arg1(arg_other):\n            pass\n    '''\n    )\n\n    result = pytester.runpytest(mode, p)\n    assert result.ret == 0\n\n    result.stdout.fnmatch_lines(\n        [\n            \"SETUP    S arg_same?'foo'?\",\n            \"TEARDOWN S arg_same?'foo'?\",\n            \"SETUP    S arg_same?"}, {"start_line": 1000, "end_line": 3000, "belongs_to": {"file_name": "test_setuponly.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "er.makepyfile(\n        '''\n        import pytest\n        @pytest.fixture\n        def arg_function():\n            \"\"\"function scoped fixture\"\"\"\n        @pytest.fixture(scope='session')\n        def arg_session():\n            \"\"\"session scoped fixture\"\"\"\n        def test_arg1(arg_session, arg_function):\n            pass\n    '''\n    )\n\n    result = pytester.runpytest(mode, p)\n    assert result.ret == 0\n\n    result.stdout.fnmatch_lines(\n        [\n            \"SETUP    S arg_session*\",\n            \"*SETUP    F arg_function*\",\n            \"*test_arg1 (fixtures used: arg_function, arg_session)*\",\n            \"*TEARDOWN F arg_function*\",\n            \"TEARDOWN S arg_session*\",\n        ]\n    )\n\n\ndef test_show_nested_fixtures(pytester: Pytester, mode) -> None:\n    pytester.makeconftest(\n        '''\n        import pytest\n        @pytest.fixture(scope='session')\n        def arg_same():\n            \"\"\"session scoped fixture\"\"\"\n        '''\n    )\n    p = pytester.makepyfile(\n        '''\n        import pytest\n        @pytest.fixture(scope='function')\n        def arg_same(arg_same):\n            \"\"\"function scoped fixture\"\"\"\n        def test_arg1(arg_same):\n            pass\n    '''\n    )\n\n    result = pytester.runpytest(mode, p)\n    assert result.ret == 0\n\n    result.stdout.fnmatch_lines(\n        [\n            \"SETUP    S arg_same*\",\n            \"*SETUP    F arg_same (fixtures used: arg_same)*\",\n            \"*test_arg1 (fixtures used: arg_same)*\",\n            \"*TEARDOWN F arg_same*\",\n            \"TEARDOWN S arg_same*\",\n        ]\n    )\n\n\ndef test_show_fixtures_with_autouse(pytester: Pytester, mode) -> None:\n    p = pytester.makepyfile(\n        '''\n        import pytest\n        @pytest.fixture\n        def arg_function():\n            \"\"\"function scoped fixture\"\"\"\n        @pytest.fixture(scope='session', autouse=True)\n        def arg_session():\n            \"\"\"session scoped fixture\"\"\"\n        def test_arg1(arg_function):\n            pass\n    '''\n    )\n\n    result = pytester.runpytest(mode,"}], "retrieved_count": 10, "cost_time": 0.34513306617736816}
{"question": "How does Pytest implement its reporting system?", "answer": null, "relative_code_list": null, "ground_truth": "Pytest implements its reporting system through a comprehensive hook-based architecture that captures and presents test execution results: 1) BaseReport class in src/_pytest/reports.py that serves as the foundation for all report types with common attributes like outcome, longrepr, sections, and nodeid, 2) TestReport class that extends BaseReport to represent individual test execution results with specific attributes like location, keywords, when (setup/call/teardown), and user_properties, 3) Hook-based reporting through pytest_runtest_logreport hook that is called for each test phase (setup, call, teardown) to generate and distribute reports, 4) Terminal reporting through TerminalReporter class that formats and displays reports in the console with configurable output styles and verbosity levels, 5) Report serialization through pytest_report_to_serializable and pytest_report_from_serializable hooks for storing and transmitting reports, 6) Capture integration where reports include sections for captured stdout, stderr, and log output through the sections attribute, 7) Exception handling where failed tests include detailed exception information in the longrepr attribute with traceback formatting, 8) Status reporting through pytest_report_teststatus hook that allows plugins to customize how test outcomes are displayed, 9) Summary reporting through pytest_terminal_summary hook that generates final test execution summaries, 10) Plugin extensibility where custom plugins can implement reporting hooks to add their own report types or modify existing ones, 11) JUnit XML reporting through the junitxml plugin that generates XML reports compatible with CI/CD systems, 12) Integration with the test execution protocol where reports are generated at each phase of test execution and can be intercepted or modified by plugins.", "score": null, "retrieved_content": [{"start_line": 48000, "end_line": 50000, "belongs_to": {"file_name": "test_terminal.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "a\"\n    assert getreportopt(config) == \"sxXEf\"\n\n    config.option.reportchars = \"A\"\n    assert getreportopt(config) == \"PpsxXEf\"\n\n    config.option.reportchars = \"AN\"\n    assert getreportopt(config) == \"\"\n\n    config.option.reportchars = \"NwfE\"\n    assert getreportopt(config) == \"fE\"\n\n\ndef test_terminalreporter_reportopt_addopts(pytester: Pytester) -> None:\n    pytester.makeini(\"[pytest]\\naddopts=-rs\")\n    pytester.makepyfile(\n        \"\"\"\n        import pytest\n\n        @pytest.fixture\n        def tr(request):\n            tr = request.config.pluginmanager.getplugin(\"terminalreporter\")\n            return tr\n        def test_opt(tr):\n            assert tr.hasopt('skipped')\n            assert not tr.hasopt('qwe')\n    \"\"\"\n    )\n    result = pytester.runpytest()\n    result.stdout.fnmatch_lines([\"*1 passed*\"])\n\n\ndef test_tbstyle_short(pytester: Pytester) -> None:\n    p = pytester.makepyfile(\n        \"\"\"\n        import pytest\n\n        @pytest.fixture\n        def arg(request):\n            return 42\n        def test_opt(arg):\n            x = 0\n            assert x\n    \"\"\"\n    )\n    result = pytester.runpytest(\"--tb=short\")\n    s = result.stdout.str()\n    assert \"arg = 42\" not in s\n    assert \"x = 0\" not in s\n    result.stdout.fnmatch_lines([f\"*{p.name}:8*\", \"    assert x\", \"E   assert*\"])\n    result = pytester.runpytest()\n    s = result.stdout.str()\n    assert \"x = 0\" in s\n    assert \"assert x\" in s\n\n\ndef test_traceconfig(pytester: Pytester) -> None:\n    result = pytester.runpytest(\"--traceconfig\")\n    result.stdout.fnmatch_lines([\"*active plugins*\"])\n    assert result.ret == ExitCode.NO_TESTS_COLLECTED\n\n\nclass TestGenericReporting:\n    \"\"\"Test class which can be subclassed with a different option provider to\n    run e.g. distributed tests.\"\"\"\n\n    def test_collect_fail(self, pytester: Pytester, option) -> None:\n        pytester.makepyfile(\"import xyz\\n\")\n        result = pytester.runpytest(*option.args)\n        result.stdout.fnmatch_lines(\n            [\"ImportError while impo"}, {"start_line": 41000, "end_line": 43000, "belongs_to": {"file_name": "test_terminal.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "monkeypatch.setenv(\"CI\", \"true\")\n    else:\n        monkeypatch.delenv(\"CI\", raising=False)\n    monkeypatch.setenv(\"COLUMNS\", \"80\")\n    pytester.makepyfile(\"def test_this(): assert 0, 'this_failed' * 100\")\n    result = pytester.runpytest(\"-rN\")\n    result.stdout.no_fnmatch_line(\"*short test summary*\")\n    result = pytester.runpytest()\n    result.stdout.fnmatch_lines(\n        [\n            \"*test summary*\",\n            f\"FAILED test_fail_extra_reporting.py::test_this {expected_message}\",\n        ]\n    )\n\n\ndef test_fail_reporting_on_pass(pytester: Pytester) -> None:\n    pytester.makepyfile(\"def test_this(): assert 1\")\n    result = pytester.runpytest(\"-rf\")\n    result.stdout.no_fnmatch_line(\"*short test summary*\")\n\n\ndef test_pass_extra_reporting(pytester: Pytester) -> None:\n    pytester.makepyfile(\"def test_this(): assert 1\")\n    result = pytester.runpytest()\n    result.stdout.no_fnmatch_line(\"*short test summary*\")\n    result = pytester.runpytest(\"-rp\")\n    result.stdout.fnmatch_lines([\"*test summary*\", \"PASS*test_pass_extra_reporting*\"])\n\n\ndef test_pass_reporting_on_fail(pytester: Pytester) -> None:\n    pytester.makepyfile(\"def test_this(): assert 0\")\n    result = pytester.runpytest(\"-rp\")\n    result.stdout.no_fnmatch_line(\"*short test summary*\")\n\n\ndef test_pass_output_reporting(pytester: Pytester) -> None:\n    pytester.makepyfile(\n        \"\"\"\n        def setup_module():\n            print(\"setup_module\")\n\n        def teardown_module():\n            print(\"teardown_module\")\n\n        def test_pass_has_output():\n            print(\"Four score and seven years ago...\")\n\n        def test_pass_no_output():\n            pass\n    \"\"\"\n    )\n    result = pytester.runpytest()\n    s = result.stdout.str()\n    assert \"test_pass_has_output\" not in s\n    assert \"Four score and seven years ago...\" not in s\n    assert \"test_pass_no_output\" not in s\n    result = pytester.runpytest(\"-rPp\")\n    result.stdout.fnmatch_lines(\n        [\n            \"*= PASSES =*\",\n            \"*_ test_pass_has_ou"}, {"start_line": 1000, "end_line": 3000, "belongs_to": {"file_name": "reports.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "t.config import Config\nfrom _pytest.nodes import Collector\nfrom _pytest.nodes import Item\nfrom _pytest.outcomes import fail\nfrom _pytest.outcomes import skip\n\n\nif TYPE_CHECKING:\n    from typing_extensions import Self\n\n    from _pytest.runner import CallInfo\n\n\ndef getworkerinfoline(node):\n    try:\n        return node._workerinfocache\n    except AttributeError:\n        d = node.workerinfo\n        ver = \"{}.{}.{}\".format(*d[\"version_info\"][:3])\n        node._workerinfocache = s = \"[{}] {} -- Python {} {}\".format(\n            d[\"id\"], d[\"sysplatform\"], ver, d[\"executable\"]\n        )\n        return s\n\n\nclass BaseReport:\n    when: str | None\n    location: tuple[str, int | None, str] | None\n    longrepr: (\n        None | ExceptionInfo[BaseException] | tuple[str, int, str] | str | TerminalRepr\n    )\n    sections: list[tuple[str, str]]\n    nodeid: str\n    outcome: Literal[\"passed\", \"failed\", \"skipped\"]\n\n    def __init__(self, **kw: Any) -> None:\n        self.__dict__.update(kw)\n\n    if TYPE_CHECKING:\n        # Can have arbitrary fields given to __init__().\n        def __getattr__(self, key: str) -> Any: ...\n\n    def toterminal(self, out: TerminalWriter) -> None:\n        if hasattr(self, \"node\"):\n            worker_info = getworkerinfoline(self.node)\n            if worker_info:\n                out.line(worker_info)\n\n        longrepr = self.longrepr\n        if longrepr is None:\n            return\n\n        if hasattr(longrepr, \"toterminal\"):\n            longrepr_terminal = cast(TerminalRepr, longrepr)\n            longrepr_terminal.toterminal(out)\n        else:\n            try:\n                s = str(longrepr)\n            except UnicodeEncodeError:\n                s = \"<unprintable longrepr>\"\n            out.line(s)\n\n    def get_sections(self, prefix: str) -> Iterator[tuple[str, str]]:\n        for name, content in self.sections:\n            if name.startswith(prefix):\n                yield prefix, content\n\n    @property\n    def longreprtext(self) -> str:\n        \"\"\"Read-only pr"}, {"start_line": 42000, "end_line": 44000, "belongs_to": {"file_name": "test_terminal.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "test summary*\", \"PASS*test_pass_extra_reporting*\"])\n\n\ndef test_pass_reporting_on_fail(pytester: Pytester) -> None:\n    pytester.makepyfile(\"def test_this(): assert 0\")\n    result = pytester.runpytest(\"-rp\")\n    result.stdout.no_fnmatch_line(\"*short test summary*\")\n\n\ndef test_pass_output_reporting(pytester: Pytester) -> None:\n    pytester.makepyfile(\n        \"\"\"\n        def setup_module():\n            print(\"setup_module\")\n\n        def teardown_module():\n            print(\"teardown_module\")\n\n        def test_pass_has_output():\n            print(\"Four score and seven years ago...\")\n\n        def test_pass_no_output():\n            pass\n    \"\"\"\n    )\n    result = pytester.runpytest()\n    s = result.stdout.str()\n    assert \"test_pass_has_output\" not in s\n    assert \"Four score and seven years ago...\" not in s\n    assert \"test_pass_no_output\" not in s\n    result = pytester.runpytest(\"-rPp\")\n    result.stdout.fnmatch_lines(\n        [\n            \"*= PASSES =*\",\n            \"*_ test_pass_has_output _*\",\n            \"*- Captured stdout setup -*\",\n            \"setup_module\",\n            \"*- Captured stdout call -*\",\n            \"Four score and seven years ago...\",\n            \"*- Captured stdout teardown -*\",\n            \"teardown_module\",\n            \"*= short test summary info =*\",\n            \"PASSED test_pass_output_reporting.py::test_pass_has_output\",\n            \"PASSED test_pass_output_reporting.py::test_pass_no_output\",\n            \"*= 2 passed in *\",\n        ]\n    )\n\n\ndef test_color_yes(pytester: Pytester, color_mapping) -> None:\n    p1 = pytester.makepyfile(\n        \"\"\"\n        def fail():\n            assert 0\n\n        def test_this():\n            fail()\n        \"\"\"\n    )\n    result = pytester.runpytest(\"--color=yes\", str(p1))\n    result.stdout.fnmatch_lines(\n        color_mapping.format_for_fnmatch(\n            [\n                \"{bold}=*= test session starts =*={reset}\",\n                \"collected 1 item\",\n                \"\",\n                \"test_color_yes.py {red"}, {"start_line": 0, "end_line": 2000, "belongs_to": {"file_name": "test_terminal.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "# mypy: allow-untyped-defs\n\"\"\"Terminal reporting of the full testing process.\"\"\"\n\nfrom __future__ import annotations\n\nfrom io import StringIO\nimport os\nfrom pathlib import Path\nimport sys\nimport textwrap\nfrom types import SimpleNamespace\nfrom typing import cast\nfrom typing import NamedTuple\n\nimport pluggy\n\nfrom _pytest._io.wcwidth import wcswidth\nimport _pytest.config\nfrom _pytest.config import Config\nfrom _pytest.config import ExitCode\nfrom _pytest.monkeypatch import MonkeyPatch\nfrom _pytest.pytester import Pytester\nfrom _pytest.reports import BaseReport\nfrom _pytest.reports import CollectReport\nfrom _pytest.reports import TestReport\nimport _pytest.terminal\nfrom _pytest.terminal import _folded_skips\nfrom _pytest.terminal import _format_trimmed\nfrom _pytest.terminal import _get_line_with_reprcrash_message\nfrom _pytest.terminal import _get_raw_skip_reason\nfrom _pytest.terminal import _plugin_nameversions\nfrom _pytest.terminal import getreportopt\nfrom _pytest.terminal import TerminalReporter\nimport pytest\n\n\nclass DistInfo(NamedTuple):\n    project_name: str\n    version: int\n\n\nTRANS_FNMATCH = str.maketrans({\"[\": \"[[]\", \"]\": \"[]]\"})\n\n\nclass Option:\n    def __init__(self, verbosity=0):\n        self.verbosity = verbosity\n\n    @property\n    def args(self):\n        values = []\n        values.append(f\"--verbosity={self.verbosity}\")\n        return values\n\n\n@pytest.fixture(\n    params=[Option(verbosity=0), Option(verbosity=1), Option(verbosity=-1)],\n    ids=[\"default\", \"verbose\", \"quiet\"],\n)\ndef option(request):\n    return request.param\n\n\n@pytest.mark.parametrize(\n    \"input,expected\",\n    [\n        ([DistInfo(project_name=\"test\", version=1)], [\"test-1\"]),\n        ([DistInfo(project_name=\"pytest-test\", version=1)], [\"test-1\"]),\n        (\n            [\n                DistInfo(project_name=\"test\", version=1),\n                DistInfo(project_name=\"test\", version=1),\n            ],\n            [\"test-1\"],\n        ),\n    ],\n    ids=[\"normal\", \"prefix-strip\", \"deduplicate\"],\n)\ndef "}, {"start_line": 1000, "end_line": 3000, "belongs_to": {"file_name": "terminal.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "mport _pytest._version\nfrom _pytest.assertion.util import running_on_ci\nfrom _pytest.config import _PluggyPlugin\nfrom _pytest.config import Config\nfrom _pytest.config import ExitCode\nfrom _pytest.config import hookimpl\nfrom _pytest.config.argparsing import Parser\nfrom _pytest.nodes import Item\nfrom _pytest.nodes import Node\nfrom _pytest.pathlib import absolutepath\nfrom _pytest.pathlib import bestrelpath\nfrom _pytest.reports import BaseReport\nfrom _pytest.reports import CollectReport\nfrom _pytest.reports import TestReport\n\n\nif TYPE_CHECKING:\n    from _pytest.main import Session\n\n\nREPORT_COLLECTING_RESOLUTION = 0.5\n\nKNOWN_TYPES = (\n    \"failed\",\n    \"passed\",\n    \"skipped\",\n    \"deselected\",\n    \"xfailed\",\n    \"xpassed\",\n    \"warnings\",\n    \"error\",\n)\n\n_REPORTCHARS_DEFAULT = \"fE\"\n\n\nclass MoreQuietAction(argparse.Action):\n    \"\"\"A modified copy of the argparse count action which counts down and updates\n    the legacy quiet attribute at the same time.\n\n    Used to unify verbosity handling.\n    \"\"\"\n\n    def __init__(\n        self,\n        option_strings: Sequence[str],\n        dest: str,\n        default: object = None,\n        required: bool = False,\n        help: str | None = None,\n    ) -> None:\n        super().__init__(\n            option_strings=option_strings,\n            dest=dest,\n            nargs=0,\n            default=default,\n            required=required,\n            help=help,\n        )\n\n    def __call__(\n        self,\n        parser: argparse.ArgumentParser,\n        namespace: argparse.Namespace,\n        values: str | Sequence[object] | None,\n        option_string: str | None = None,\n    ) -> None:\n        new_count = getattr(namespace, self.dest, 0) - 1\n        setattr(namespace, self.dest, new_count)\n        # todo Deprecate config.quiet\n        namespace.quiet = getattr(namespace, \"quiet\", 0) + 1\n\n\nclass TestShortLogReport(NamedTuple):\n    \"\"\"Used to store the test status result category, shortletter and verbose word.\n    For example ``\"rerun\", \"R\", (\"RE"}, {"start_line": 36000, "end_line": 38000, "belongs_to": {"file_name": "test_terminal.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "ass::test_skip *SKIP*\",\n            ]\n        )\n        assert result.ret == 1\n\n    def test_verbose_reporting_xdist(\n        self,\n        verbose_testfile,\n        monkeypatch: MonkeyPatch,\n        pytester: Pytester,\n        pytestconfig,\n    ) -> None:\n        if not pytestconfig.pluginmanager.get_plugin(\"xdist\"):\n            pytest.skip(\"xdist plugin not installed\")\n\n        monkeypatch.delenv(\"PYTEST_DISABLE_PLUGIN_AUTOLOAD\")\n        result = pytester.runpytest(\n            verbose_testfile, \"-v\", \"-n 1\", \"-Walways::pytest.PytestWarning\"\n        )\n        result.stdout.fnmatch_lines(\n            [\"*FAIL*test_verbose_reporting_xdist.py::test_fail*\"]\n        )\n        assert result.ret == 1\n\n    def test_quiet_reporting(self, pytester: Pytester) -> None:\n        p1 = pytester.makepyfile(\"def test_pass(): pass\")\n        result = pytester.runpytest(p1, \"-q\")\n        s = result.stdout.str()\n        assert \"test session starts\" not in s\n        assert p1.name not in s\n        assert \"===\" not in s\n        assert \"passed\" in s\n\n    def test_more_quiet_reporting(self, pytester: Pytester) -> None:\n        p1 = pytester.makepyfile(\"def test_pass(): pass\")\n        result = pytester.runpytest(p1, \"-qq\")\n        s = result.stdout.str()\n        assert \"test session starts\" not in s\n        assert p1.name not in s\n        assert \"===\" not in s\n        assert \"passed\" not in s\n\n    @pytest.mark.parametrize(\n        \"params\", [(), (\"--collect-only\",)], ids=[\"no-params\", \"collect-only\"]\n    )\n    def test_report_collectionfinish_hook(self, pytester: Pytester, params) -> None:\n        pytester.makeconftest(\n            \"\"\"\n            def pytest_report_collectionfinish(config, start_path, items):\n                return [f'hello from hook: {len(items)} items']\n        \"\"\"\n        )\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n            @pytest.mark.parametrize('i', range(3))\n            def test(i):\n                pass\n        \"\"\"\n        )\n        re"}, {"start_line": 1000, "end_line": 3000, "belongs_to": {"file_name": "test_pytester.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "alse\n        failed = True\n        skipped = False\n        when = \"call\"\n\n    recorder.hook.pytest_runtest_logreport(report=rep)  # type: ignore[attr-defined]\n    failures = recorder.getfailures()\n    assert failures == [rep]  # type: ignore[comparison-overlap]\n    failures = recorder.getfailures()\n    assert failures == [rep]  # type: ignore[comparison-overlap]\n\n    class rep2:\n        excinfo = None\n        passed = False\n        failed = False\n        skipped = True\n        when = \"call\"\n\n    rep2.passed = False\n    rep2.skipped = True\n    recorder.hook.pytest_runtest_logreport(report=rep2)  # type: ignore[attr-defined]\n\n    modcol = pytester.getmodulecol(\"\")\n    rep3 = modcol.config.hook.pytest_make_collect_report(collector=modcol)\n    rep3.passed = False\n    rep3.failed = True\n    rep3.skipped = False\n    recorder.hook.pytest_collectreport(report=rep3)  # type: ignore[attr-defined]\n\n    passed, skipped, failed = recorder.listoutcomes()\n    assert not passed and skipped and failed\n\n    numpassed, numskipped, numfailed = recorder.countoutcomes()\n    assert numpassed == 0\n    assert numskipped == 1\n    assert numfailed == 1\n    assert len(recorder.getfailedcollections()) == 1\n\n    recorder.unregister()  # type: ignore[attr-defined]\n    recorder.clear()\n    recorder.hook.pytest_runtest_logreport(report=rep3)  # type: ignore[attr-defined]\n    pytest.raises(ValueError, recorder.getfailures)\n\n\ndef test_parseconfig(pytester: Pytester) -> None:\n    config1 = pytester.parseconfig()\n    config2 = pytester.parseconfig()\n    assert config2 is not config1\n\n\ndef test_pytester_runs_with_plugin(pytester: Pytester) -> None:\n    pytester.makepyfile(\n        \"\"\"\n        pytest_plugins = \"pytester\"\n        def test_hello(pytester):\n            assert 1\n    \"\"\"\n    )\n    result = pytester.runpytest()\n    result.assert_outcomes(passed=1)\n\n\ndef test_pytester_with_doctest(pytester: Pytester) -> None:\n    \"\"\"Check that pytester can be used within doctests.\n\n    It used to use `request.f"}, {"start_line": 0, "end_line": 2000, "belongs_to": {"file_name": "terminal.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "# mypy: allow-untyped-defs\n\"\"\"Terminal reporting of the full testing process.\n\nThis is a good source for looking at the various reporting hooks.\n\"\"\"\n\nfrom __future__ import annotations\n\nimport argparse\nfrom collections import Counter\nfrom collections.abc import Callable\nfrom collections.abc import Generator\nfrom collections.abc import Mapping\nfrom collections.abc import Sequence\nimport dataclasses\nimport datetime\nfrom functools import partial\nimport inspect\nfrom pathlib import Path\nimport platform\nimport sys\nimport textwrap\nfrom typing import Any\nfrom typing import ClassVar\nfrom typing import final\nfrom typing import Literal\nfrom typing import NamedTuple\nfrom typing import TextIO\nfrom typing import TYPE_CHECKING\nimport warnings\n\nimport pluggy\n\nfrom _pytest import compat\nfrom _pytest import nodes\nfrom _pytest import timing\nfrom _pytest._code import ExceptionInfo\nfrom _pytest._code.code import ExceptionRepr\nfrom _pytest._io import TerminalWriter\nfrom _pytest._io.wcwidth import wcswidth\nimport _pytest._version\nfrom _pytest.assertion.util import running_on_ci\nfrom _pytest.config import _PluggyPlugin\nfrom _pytest.config import Config\nfrom _pytest.config import ExitCode\nfrom _pytest.config import hookimpl\nfrom _pytest.config.argparsing import Parser\nfrom _pytest.nodes import Item\nfrom _pytest.nodes import Node\nfrom _pytest.pathlib import absolutepath\nfrom _pytest.pathlib import bestrelpath\nfrom _pytest.reports import BaseReport\nfrom _pytest.reports import CollectReport\nfrom _pytest.reports import TestReport\n\n\nif TYPE_CHECKING:\n    from _pytest.main import Session\n\n\nREPORT_COLLECTING_RESOLUTION = 0.5\n\nKNOWN_TYPES = (\n    \"failed\",\n    \"passed\",\n    \"skipped\",\n    \"deselected\",\n    \"xfailed\",\n    \"xpassed\",\n    \"warnings\",\n    \"error\",\n)\n\n_REPORTCHARS_DEFAULT = \"fE\"\n\n\nclass MoreQuietAction(argparse.Action):\n    \"\"\"A modified copy of the argparse count action which counts down and updates\n    the legacy quiet attribute at the same time.\n\n    Used to unify verbosity handling."}, {"start_line": 9000, "end_line": 11000, "belongs_to": {"file_name": "terminal.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "portopts = \"PpsxXEf\"\n        elif char == \"N\":\n            reportopts = \"\"\n        elif char not in reportopts:\n            reportopts += char\n\n    if not config.option.disable_warnings and \"w\" not in reportopts:\n        reportopts = \"w\" + reportopts\n    elif config.option.disable_warnings and \"w\" in reportopts:\n        reportopts = reportopts.replace(\"w\", \"\")\n\n    return reportopts\n\n\n@hookimpl(trylast=True)  # after _pytest.runner\ndef pytest_report_teststatus(report: BaseReport) -> tuple[str, str, str]:\n    letter = \"F\"\n    if report.passed:\n        letter = \".\"\n    elif report.skipped:\n        letter = \"s\"\n\n    outcome: str = report.outcome\n    if report.when in (\"collect\", \"setup\", \"teardown\") and outcome == \"failed\":\n        outcome = \"error\"\n        letter = \"E\"\n\n    return outcome, letter, outcome.upper()\n\n\n@dataclasses.dataclass\nclass WarningReport:\n    \"\"\"Simple structure to hold warnings information captured by ``pytest_warning_recorded``.\n\n    :ivar str message:\n        User friendly message about the warning.\n    :ivar str|None nodeid:\n        nodeid that generated the warning (see ``get_location``).\n    :ivar tuple fslocation:\n        File system location of the source of the warning (see ``get_location``).\n    \"\"\"\n\n    message: str\n    nodeid: str | None = None\n    fslocation: tuple[str, int] | None = None\n\n    count_towards_summary: ClassVar = True\n\n    def get_location(self, config: Config) -> str | None:\n        \"\"\"Return the more user-friendly information about the location of a warning, or None.\"\"\"\n        if self.nodeid:\n            return self.nodeid\n        if self.fslocation:\n            filename, linenum = self.fslocation\n            relpath = bestrelpath(config.invocation_params.dir, absolutepath(filename))\n            return f\"{relpath}:{linenum}\"\n        return None\n\n\n@final\nclass TerminalReporter:\n    def __init__(self, config: Config, file: TextIO | None = None) -> None:\n        import _pytest.config\n\n        self.config = config\n        "}], "retrieved_count": 10, "cost_time": 0.3357667922973633}
{"question": "How does Pytest implement its plugin architecture?", "answer": null, "relative_code_list": null, "ground_truth": "Pytest implements its plugin architecture through a comprehensive hook-based system built on the pluggy library: 1) PytestPluginManager class that extends pluggy.PluginManager to handle pytest-specific plugin loading and discovery, 2) Hook specification system where all pytest functionality is defined through hook specifications in src/_pytest/hookspec.py using the @hookspec decorator, 3) Multiple plugin types including built-in plugins (stored in src/_pytest/), external plugins (discovered through entry points), and local conftest.py plugins (auto-discovered in test directories), 4) Plugin discovery order that loads plugins in a specific sequence: command line blocking, built-in plugins, external plugins, environment variables, and conftest files, 5) Hook implementation system where plugins implement hook functions with the @hookimpl decorator to provide functionality, 6) 1:N relationship where multiple plugins can implement the same hook specification, with execution order controlled by tryfirst/trylast markers, 7) Hook wrappers that execute around other hook implementations for cross-cutting functionality, 8) Plugin registration through entry points in pyproject.toml or setup.py for external plugins, 9) Local plugin support through conftest.py files that can be placed in any directory for directory-specific functionality, 10) Plugin communication through the config object and stash mechanism for sharing data between plugins, 11) Plugin validation and error handling with proper cleanup mechanisms, 12) Backward compatibility through dynamic argument pruning that allows new hook parameters without breaking existing implementations.", "score": null, "retrieved_content": [{"start_line": 11000, "end_line": 13000, "belongs_to": {"file_name": "__init__.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest/config", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "ed.HOOK_LEGACY_MARKING.format(\n            type=hook_type,\n            fullname=method.__qualname__,\n            hook_opts=hook_opts,\n        )\n        warn_explicit_for(cast(FunctionType, method), message)\n    return opts\n\n\n@final\nclass PytestPluginManager(PluginManager):\n    \"\"\"A :py:class:`pluggy.PluginManager <pluggy.PluginManager>` with\n    additional pytest-specific functionality:\n\n    * Loading plugins from the command line, ``PYTEST_PLUGINS`` env variable and\n      ``pytest_plugins`` global variables found in plugins being loaded.\n    * ``conftest.py`` loading during start-up.\n    \"\"\"\n\n    def __init__(self) -> None:\n        from _pytest.assertion import DummyRewriteHook\n        from _pytest.assertion import RewriteHook\n\n        super().__init__(\"pytest\")\n\n        # -- State related to local conftest plugins.\n        # All loaded conftest modules.\n        self._conftest_plugins: set[types.ModuleType] = set()\n        # All conftest modules applicable for a directory.\n        # This includes the directory's own conftest modules as well\n        # as those of its parent directories.\n        self._dirpath2confmods: dict[pathlib.Path, list[types.ModuleType]] = {}\n        # Cutoff directory above which conftests are no longer discovered.\n        self._confcutdir: pathlib.Path | None = None\n        # If set, conftest loading is skipped.\n        self._noconftest = False\n\n        # _getconftestmodules()'s call to _get_directory() causes a stat\n        # storm when it's called potentially thousands of times in a test\n        # session (#9478), often with the same path, so cache it.\n        self._get_directory = lru_cache(256)(_get_directory)\n\n        # plugins that were explicitly skipped with pytest.skip\n        # list of (module name, skip reason)\n        # previously we would issue a warning when a plugin was skipped, but\n        # since we refactored warnings as first citizens of Config, they are\n        # just stored here to be used later.\n        self.skipped_plu"}, {"start_line": 13000, "end_line": 15000, "belongs_to": {"file_name": "__init__.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest/config", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "gins: list[tuple[str, str]] = []\n\n        self.add_hookspecs(_pytest.hookspec)\n        self.register(self)\n        if os.environ.get(\"PYTEST_DEBUG\"):\n            err: IO[str] = sys.stderr\n            encoding: str = getattr(err, \"encoding\", \"utf8\")\n            try:\n                err = open(\n                    os.dup(err.fileno()),\n                    mode=err.mode,\n                    buffering=1,\n                    encoding=encoding,\n                )\n            except Exception:\n                pass\n            self.trace.root.setwriter(err.write)\n            self.enable_tracing()\n\n        # Config._consider_importhook will set a real object if required.\n        self.rewrite_hook: RewriteHook = DummyRewriteHook()\n        # Used to know when we are importing conftests after the pytest_configure stage.\n        self._configured = False\n\n    def parse_hookimpl_opts(\n        self, plugin: _PluggyPlugin, name: str\n    ) -> HookimplOpts | None:\n        \"\"\":meta private:\"\"\"\n        # pytest hooks are always prefixed with \"pytest_\",\n        # so we avoid accessing possibly non-readable attributes\n        # (see issue #1073).\n        if not name.startswith(\"pytest_\"):\n            return None\n        # Ignore names which cannot be hooks.\n        if name == \"pytest_plugins\":\n            return None\n\n        opts = super().parse_hookimpl_opts(plugin, name)\n        if opts is not None:\n            return opts\n\n        method = getattr(plugin, name)\n        # Consider only actual functions for hooks (#3775).\n        if not inspect.isroutine(method):\n            return None\n        # Collect unmarked hooks as long as they have the `pytest_' prefix.\n        legacy = _get_legacy_hook_marks(\n            method, \"impl\", (\"tryfirst\", \"trylast\", \"optionalhook\", \"hookwrapper\")\n        )\n        return cast(HookimplOpts, legacy)\n\n    def parse_hookspec_opts(self, module_or_class, name: str) -> HookspecOpts | None:\n        \"\"\":meta private:\"\"\"\n        opts = super().parse_hookspec_op"}, {"start_line": 16000, "end_line": 18000, "belongs_to": {"file_name": "__init__.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest/config", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "ict(\n                    plugin=plugin,\n                    plugin_name=plugin_name,\n                    manager=self,\n                )\n            )\n\n            if isinstance(plugin, types.ModuleType):\n                self.consider_module(plugin)\n        return plugin_name\n\n    def getplugin(self, name: str):\n        # Support deprecated naming because plugins (xdist e.g.) use it.\n        plugin: _PluggyPlugin | None = self.get_plugin(name)\n        return plugin\n\n    def hasplugin(self, name: str) -> bool:\n        \"\"\"Return whether a plugin with the given name is registered.\"\"\"\n        return bool(self.get_plugin(name))\n\n    def pytest_configure(self, config: Config) -> None:\n        \"\"\":meta private:\"\"\"\n        # XXX now that the pluginmanager exposes hookimpl(tryfirst...)\n        # we should remove tryfirst/trylast as markers.\n        config.addinivalue_line(\n            \"markers\",\n            \"tryfirst: mark a hook implementation function such that the \"\n            \"plugin machinery will try to call it first/as early as possible. \"\n            \"DEPRECATED, use @pytest.hookimpl(tryfirst=True) instead.\",\n        )\n        config.addinivalue_line(\n            \"markers\",\n            \"trylast: mark a hook implementation function such that the \"\n            \"plugin machinery will try to call it last/as late as possible. \"\n            \"DEPRECATED, use @pytest.hookimpl(trylast=True) instead.\",\n        )\n        self._configured = True\n\n    #\n    # Internal API for local conftest plugin handling.\n    #\n    def _set_initial_conftests(\n        self,\n        args: Sequence[str | pathlib.Path],\n        pyargs: bool,\n        noconftest: bool,\n        rootpath: pathlib.Path,\n        confcutdir: pathlib.Path | None,\n        invocation_dir: pathlib.Path,\n        importmode: ImportMode | str,\n        *,\n        consider_namespace_packages: bool,\n    ) -> None:\n        \"\"\"Load initial conftest files given a preparsed \"namespace\".\n\n        As conftest files may add their own com"}, {"start_line": 13000, "end_line": 15000, "belongs_to": {"file_name": "test_pluginmanager.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "h_lines([\"*1 passed*\"])\n\n    def test_import_plugin_importname(\n        self, pytester: Pytester, pytestpm: PytestPluginManager\n    ) -> None:\n        pytest.raises(ImportError, pytestpm.import_plugin, \"qweqwex.y\")\n        pytest.raises(ImportError, pytestpm.import_plugin, \"pytest_qweqwx.y\")\n\n        pytester.syspathinsert()\n        pluginname = \"pytest_hello\"\n        pytester.makepyfile(**{pluginname: \"\"})\n        pytestpm.import_plugin(\"pytest_hello\")\n        len1 = len(pytestpm.get_plugins())\n        pytestpm.import_plugin(\"pytest_hello\")\n        len2 = len(pytestpm.get_plugins())\n        assert len1 == len2\n        plugin1 = pytestpm.get_plugin(\"pytest_hello\")\n        assert plugin1 is not None\n        assert plugin1.__name__.endswith(\"pytest_hello\")\n        plugin2 = pytestpm.get_plugin(\"pytest_hello\")\n        assert plugin2 is plugin1\n\n    def test_import_plugin_dotted_name(\n        self, pytester: Pytester, pytestpm: PytestPluginManager\n    ) -> None:\n        pytest.raises(ImportError, pytestpm.import_plugin, \"qweqwex.y\")\n        pytest.raises(ImportError, pytestpm.import_plugin, \"pytest_qweqwex.y\")\n\n        pytester.syspathinsert()\n        pytester.mkpydir(\"pkg\").joinpath(\"plug.py\").write_text(\"x=3\", encoding=\"utf-8\")\n        pluginname = \"pkg.plug\"\n        pytestpm.import_plugin(pluginname)\n        mod = pytestpm.get_plugin(\"pkg.plug\")\n        assert mod is not None\n        assert mod.x == 3\n\n    def test_consider_conftest_deps(\n        self,\n        pytester: Pytester,\n        pytestpm: PytestPluginManager,\n    ) -> None:\n        mod = import_path(\n            pytester.makepyfile(\"pytest_plugins='xyz'\"),\n            root=pytester.path,\n            consider_namespace_packages=False,\n        )\n        with pytest.raises(ImportError):\n            pytestpm.consider_conftest(mod, registration_name=\"unused\")\n\n\nclass TestPytestPluginManagerBootstrapping:\n    def test_preparse_args(self, pytestpm: PytestPluginManager) -> None:\n        pytest.raises(\n            Im"}, {"start_line": 10000, "end_line": 12000, "belongs_to": {"file_name": "test_pluginmanager.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "in(\"pytest_p2\")\n        assert p2 is not None\n        assert p2.__name__ == \"pytest_p2\"\n\n    def test_consider_module_import_module(\n        self, pytester: Pytester, _config_for_test: Config\n    ) -> None:\n        pytestpm = _config_for_test.pluginmanager\n        mod = types.ModuleType(\"x\")\n        mod.__dict__[\"pytest_plugins\"] = \"pytest_a\"\n        aplugin = pytester.makepyfile(pytest_a=\"#\")\n        reprec = pytester.make_hook_recorder(pytestpm)\n        pytester.syspathinsert(aplugin.parent)\n        pytestpm.consider_module(mod)\n        call = reprec.getcall(pytestpm.hook.pytest_plugin_registered.name)\n        assert call.plugin.__name__ == \"pytest_a\"\n\n        # check that it is not registered twice\n        pytestpm.consider_module(mod)\n        values = reprec.getcalls(\"pytest_plugin_registered\")\n        assert len(values) == 1\n\n    def test_consider_env_fails_to_import(\n        self, monkeypatch: MonkeyPatch, pytestpm: PytestPluginManager\n    ) -> None:\n        monkeypatch.setenv(\"PYTEST_PLUGINS\", \"nonexisting\", prepend=\",\")\n        with pytest.raises(ImportError):\n            pytestpm.consider_env()\n\n    @pytest.mark.filterwarnings(\"always\")\n    def test_plugin_skip(self, pytester: Pytester, monkeypatch: MonkeyPatch) -> None:\n        p = pytester.makepyfile(\n            skipping1=\"\"\"\n            import pytest\n            pytest.skip(\"hello\", allow_module_level=True)\n        \"\"\"\n        )\n        shutil.copy(p, p.with_name(\"skipping2.py\"))\n        monkeypatch.setenv(\"PYTEST_PLUGINS\", \"skipping2\")\n        result = pytester.runpytest(\"-p\", \"skipping1\", syspathinsert=True)\n        assert result.ret == ExitCode.NO_TESTS_COLLECTED\n        result.stdout.fnmatch_lines(\n            [\"*skipped plugin*skipping1*hello*\", \"*skipped plugin*skipping2*hello*\"]\n        )\n\n    def test_consider_env_plugin_instantiation(\n        self,\n        pytester: Pytester,\n        monkeypatch: MonkeyPatch,\n        pytestpm: PytestPluginManager,\n    ) -> None:\n        pytester.syspathinsert()"}, {"start_line": 3000, "end_line": 5000, "belongs_to": {"file_name": "acceptance_test.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "sult.stderr.fnmatch_lines([\"ERROR: file or directory not found: asd\"])\n        result.stdout.fnmatch_lines([\"*---configure\", \"*---unconfigure\"])\n\n    def test_config_preparse_plugin_option(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            pytest_xyz=\"\"\"\n            def pytest_addoption(parser):\n                parser.addoption(\"--xyz\", dest=\"xyz\", action=\"store\")\n        \"\"\"\n        )\n        pytester.makepyfile(\n            test_one=\"\"\"\n            def test_option(pytestconfig):\n                assert pytestconfig.option.xyz == \"123\"\n        \"\"\"\n        )\n        result = pytester.runpytest(\"-p\", \"pytest_xyz\", \"--xyz=123\", syspathinsert=True)\n        assert result.ret == 0\n        result.stdout.fnmatch_lines([\"*1 passed*\"])\n\n    @pytest.mark.parametrize(\"load_cov_early\", [True, False])\n    def test_early_load_setuptools_name(\n        self, pytester: Pytester, monkeypatch, load_cov_early\n    ) -> None:\n        monkeypatch.delenv(\"PYTEST_DISABLE_PLUGIN_AUTOLOAD\")\n\n        pytester.makepyfile(mytestplugin1_module=\"\")\n        pytester.makepyfile(mytestplugin2_module=\"\")\n        pytester.makepyfile(mycov_module=\"\")\n        pytester.syspathinsert()\n\n        loaded = []\n\n        @dataclasses.dataclass\n        class DummyEntryPoint:\n            name: str\n            module: str\n            group: str = \"pytest11\"\n\n            def load(self):\n                __import__(self.module)\n                loaded.append(self.name)\n                return sys.modules[self.module]\n\n        entry_points = [\n            DummyEntryPoint(\"myplugin1\", \"mytestplugin1_module\"),\n            DummyEntryPoint(\"myplugin2\", \"mytestplugin2_module\"),\n            DummyEntryPoint(\"mycov\", \"mycov_module\"),\n        ]\n\n        @dataclasses.dataclass\n        class DummyDist:\n            entry_points: object\n            files: object = ()\n\n        def my_dists():\n            return (DummyDist(entry_points),)\n\n        monkeypatch.setattr(importlib.metadata, \"distributions\", my_dists"}, {"start_line": 14000, "end_line": 16000, "belongs_to": {"file_name": "__init__.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest/config", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "test hooks are always prefixed with \"pytest_\",\n        # so we avoid accessing possibly non-readable attributes\n        # (see issue #1073).\n        if not name.startswith(\"pytest_\"):\n            return None\n        # Ignore names which cannot be hooks.\n        if name == \"pytest_plugins\":\n            return None\n\n        opts = super().parse_hookimpl_opts(plugin, name)\n        if opts is not None:\n            return opts\n\n        method = getattr(plugin, name)\n        # Consider only actual functions for hooks (#3775).\n        if not inspect.isroutine(method):\n            return None\n        # Collect unmarked hooks as long as they have the `pytest_' prefix.\n        legacy = _get_legacy_hook_marks(\n            method, \"impl\", (\"tryfirst\", \"trylast\", \"optionalhook\", \"hookwrapper\")\n        )\n        return cast(HookimplOpts, legacy)\n\n    def parse_hookspec_opts(self, module_or_class, name: str) -> HookspecOpts | None:\n        \"\"\":meta private:\"\"\"\n        opts = super().parse_hookspec_opts(module_or_class, name)\n        if opts is None:\n            method = getattr(module_or_class, name)\n            if name.startswith(\"pytest_\"):\n                legacy = _get_legacy_hook_marks(\n                    method, \"spec\", (\"firstresult\", \"historic\")\n                )\n                opts = cast(HookspecOpts, legacy)\n        return opts\n\n    def register(self, plugin: _PluggyPlugin, name: str | None = None) -> str | None:\n        if name in _pytest.deprecated.DEPRECATED_EXTERNAL_PLUGINS:\n            warnings.warn(\n                PytestConfigWarning(\n                    \"{} plugin has been merged into the core, \"\n                    \"please remove it from your requirements.\".format(\n                        name.replace(\"_\", \"-\")\n                    )\n                )\n            )\n            return None\n        plugin_name = super().register(plugin, name)\n        if plugin_name is not None:\n            self.hook.pytest_plugin_registered.call_historic(\n                kwargs=d"}, {"start_line": 25000, "end_line": 27000, "belongs_to": {"file_name": "__init__.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest/config", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "od, \"pytest_plugins\")\n            and self._configured\n            and not self._using_pyargs\n        ):\n            msg = (\n                \"Defining 'pytest_plugins' in a non-top-level conftest is no longer supported:\\n\"\n                \"It affects the entire test suite instead of just below the conftest as expected.\\n\"\n                \"  {}\\n\"\n                \"Please move it to a top level conftest file at the rootdir:\\n\"\n                \"  {}\\n\"\n                \"For more information, visit:\\n\"\n                \"  https://docs.pytest.org/en/stable/deprecations.html#pytest-plugins-in-non-top-level-conftest-files\"\n            )\n            fail(msg.format(conftestpath, self._confcutdir), pytrace=False)\n\n    #\n    # API for bootstrapping plugin loading\n    #\n    #\n\n    def consider_preparse(\n        self, args: Sequence[str], *, exclude_only: bool = False\n    ) -> None:\n        \"\"\":meta private:\"\"\"\n        i = 0\n        n = len(args)\n        while i < n:\n            opt = args[i]\n            i += 1\n            if isinstance(opt, str):\n                if opt == \"-p\":\n                    try:\n                        parg = args[i]\n                    except IndexError:\n                        return\n                    i += 1\n                elif opt.startswith(\"-p\"):\n                    parg = opt[2:]\n                else:\n                    continue\n                parg = parg.strip()\n                if exclude_only and not parg.startswith(\"no:\"):\n                    continue\n                self.consider_pluginarg(parg)\n\n    def consider_pluginarg(self, arg: str) -> None:\n        \"\"\":meta private:\"\"\"\n        if arg.startswith(\"no:\"):\n            name = arg[3:]\n            if name in essential_plugins:\n                raise UsageError(f\"plugin {name} cannot be disabled\")\n\n            # PR #4304: remove stepwise if cacheprovider is blocked.\n            if name == \"cacheprovider\":\n                self.set_blocked(\"stepwise\")\n                self.set_blocked(\"pytest_st"}, {"start_line": 9000, "end_line": 11000, "belongs_to": {"file_name": "test_pluginmanager.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "register, mod)\n        pytest.raises(ValueError, lambda: pm.register(mod))\n        # assert not pm.is_registered(mod2)\n        assert pm.get_plugins() == values\n\n    def test_canonical_import(self, monkeypatch):\n        mod = types.ModuleType(\"pytest_xyz\")\n        monkeypatch.setitem(sys.modules, \"pytest_xyz\", mod)\n        pm = PytestPluginManager()\n        pm.import_plugin(\"pytest_xyz\")\n        assert pm.get_plugin(\"pytest_xyz\") == mod\n        assert pm.is_registered(mod)\n\n    def test_consider_module(\n        self, pytester: Pytester, pytestpm: PytestPluginManager\n    ) -> None:\n        pytester.syspathinsert()\n        pytester.makepyfile(pytest_p1=\"#\")\n        pytester.makepyfile(pytest_p2=\"#\")\n        mod = types.ModuleType(\"temp\")\n        mod.__dict__[\"pytest_plugins\"] = [\"pytest_p1\", \"pytest_p2\"]\n        pytestpm.consider_module(mod)\n        p1 = pytestpm.get_plugin(\"pytest_p1\")\n        assert p1 is not None\n        assert p1.__name__ == \"pytest_p1\"\n        p2 = pytestpm.get_plugin(\"pytest_p2\")\n        assert p2 is not None\n        assert p2.__name__ == \"pytest_p2\"\n\n    def test_consider_module_import_module(\n        self, pytester: Pytester, _config_for_test: Config\n    ) -> None:\n        pytestpm = _config_for_test.pluginmanager\n        mod = types.ModuleType(\"x\")\n        mod.__dict__[\"pytest_plugins\"] = \"pytest_a\"\n        aplugin = pytester.makepyfile(pytest_a=\"#\")\n        reprec = pytester.make_hook_recorder(pytestpm)\n        pytester.syspathinsert(aplugin.parent)\n        pytestpm.consider_module(mod)\n        call = reprec.getcall(pytestpm.hook.pytest_plugin_registered.name)\n        assert call.plugin.__name__ == \"pytest_a\"\n\n        # check that it is not registered twice\n        pytestpm.consider_module(mod)\n        values = reprec.getcalls(\"pytest_plugin_registered\")\n        assert len(values) == 1\n\n    def test_consider_env_fails_to_import(\n        self, monkeypatch: MonkeyPatch, pytestpm: PytestPluginManager\n    ) -> None:\n        monkeypatch.setenv(\"P"}, {"start_line": 26000, "end_line": 28000, "belongs_to": {"file_name": "__init__.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest/config", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "      i += 1\n            if isinstance(opt, str):\n                if opt == \"-p\":\n                    try:\n                        parg = args[i]\n                    except IndexError:\n                        return\n                    i += 1\n                elif opt.startswith(\"-p\"):\n                    parg = opt[2:]\n                else:\n                    continue\n                parg = parg.strip()\n                if exclude_only and not parg.startswith(\"no:\"):\n                    continue\n                self.consider_pluginarg(parg)\n\n    def consider_pluginarg(self, arg: str) -> None:\n        \"\"\":meta private:\"\"\"\n        if arg.startswith(\"no:\"):\n            name = arg[3:]\n            if name in essential_plugins:\n                raise UsageError(f\"plugin {name} cannot be disabled\")\n\n            # PR #4304: remove stepwise if cacheprovider is blocked.\n            if name == \"cacheprovider\":\n                self.set_blocked(\"stepwise\")\n                self.set_blocked(\"pytest_stepwise\")\n\n            self.set_blocked(name)\n            if not name.startswith(\"pytest_\"):\n                self.set_blocked(\"pytest_\" + name)\n        else:\n            name = arg\n            # Unblock the plugin.\n            self.unblock(name)\n            if not name.startswith(\"pytest_\"):\n                self.unblock(\"pytest_\" + name)\n            self.import_plugin(arg, consider_entry_points=True)\n\n    def consider_conftest(\n        self, conftestmodule: types.ModuleType, registration_name: str\n    ) -> None:\n        \"\"\":meta private:\"\"\"\n        self.register(conftestmodule, name=registration_name)\n\n    def consider_env(self) -> None:\n        \"\"\":meta private:\"\"\"\n        self._import_plugin_specs(os.environ.get(\"PYTEST_PLUGINS\"))\n\n    def consider_module(self, mod: types.ModuleType) -> None:\n        \"\"\":meta private:\"\"\"\n        self._import_plugin_specs(getattr(mod, \"pytest_plugins\", []))\n\n    def _import_plugin_specs(\n        self, spec: None | types.ModuleType | str | Sequence[str]"}], "retrieved_count": 10, "cost_time": 0.34105634689331055}
{"question": "How does Pytest support testing asynchronous code using the asyncio framework?", "answer": null, "relative_code_list": null, "ground_truth": "Pytest does not natively support testing asynchronous code using the asyncio framework, but provides integration points for third-party plugins. The core implementation includes: 1) Detection of async test functions through the is_async_function() helper that checks for coroutine functions and async generator functions, 2) The pytest_pyfunc_call hook that detects async functions and calls async_fail() to provide helpful error messages, 3) Integration with external async testing plugins like pytest-asyncio, pytest-trio, pytest-twisted, and anyio that handle async test execution, 4) Support for async fixtures through plugins that can handle async fixture setup and teardown, 5) Warning system for sync tests that depend on async fixtures without proper plugin support, 6) Configuration options like asyncio_mode in pytest.ini for plugin-specific settings, 7) Integration with unittest's IsolatedAsyncioTestCase for async test support in unittest-style tests, 8) Error messages that guide users to install appropriate async testing plugins, 9) Support for async test functions in plugin integration tests using @pytest.mark.asyncio decorator, 10) Deprecation warnings for sync tests using async fixtures without proper handling, 11) Plugin architecture that allows async frameworks to register their own test execution hooks, 12) Integration with the test execution protocol where async plugins can intercept and handle async test execution.", "score": null, "retrieved_content": [{"start_line": 43000, "end_line": 45000, "belongs_to": {"file_name": "acceptance_test.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "       assert 0\n\n        def test2():\n            gc.collect()\n            assert ref() is None\n    \"\"\"\n    )\n    result = pytester.runpytest_subprocess()\n    result.stdout.fnmatch_lines([\"*1 failed, 1 passed in*\"])\n\n\ndef test_fixture_mock_integration(pytester: Pytester) -> None:\n    \"\"\"Test that decorators applied to fixture are left working (#3774)\"\"\"\n    p = pytester.copy_example(\"acceptance/fixture_mock_integration.py\")\n    result = pytester.runpytest(p)\n    result.stdout.fnmatch_lines([\"*1 passed*\"])\n\n\ndef test_usage_error_code(pytester: Pytester) -> None:\n    result = pytester.runpytest(\"-unknown-option-\")\n    assert result.ret == ExitCode.USAGE_ERROR\n\n\ndef test_error_on_async_function(pytester: Pytester) -> None:\n    # In the below we .close() the coroutine only to avoid\n    # \"RuntimeWarning: coroutine 'test_2' was never awaited\"\n    # which messes with other tests.\n    pytester.makepyfile(\n        test_async=\"\"\"\n        async def test_1():\n            pass\n        async def test_2():\n            pass\n        def test_3():\n            coro = test_2()\n            coro.close()\n            return coro\n    \"\"\"\n    )\n    result = pytester.runpytest()\n    result.stdout.fnmatch_lines(\n        [\n            \"*async def functions are not natively supported*\",\n            \"*test_async.py::test_1*\",\n            \"*test_async.py::test_2*\",\n            \"*test_async.py::test_3*\",\n        ]\n    )\n    result.assert_outcomes(failed=3)\n\n\ndef test_error_on_async_gen_function(pytester: Pytester) -> None:\n    pytester.makepyfile(\n        test_async=\"\"\"\n        async def test_1():\n            yield\n        async def test_2():\n            yield\n        def test_3():\n            return test_2()\n    \"\"\"\n    )\n    result = pytester.runpytest()\n    result.stdout.fnmatch_lines(\n        [\n            \"*async def functions are not natively supported*\",\n            \"*test_async.py::test_1*\",\n            \"*test_async.py::test_2*\",\n            \"*test_async.py::test_3*\",\n        ]\n    )\n    r"}, {"start_line": 4000, "end_line": 6000, "belongs_to": {"file_name": "python.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "nt arguments in turn. argvalues generally \"\n        \"needs to be a list of values if argnames specifies only one name \"\n        \"or a list of tuples of values if argnames specifies multiple names. \"\n        \"Example: @parametrize('arg1', [1,2]) would lead to two calls of the \"\n        \"decorated test function, one with arg1=1 and another with arg1=2.\"\n        \"see https://docs.pytest.org/en/stable/how-to/parametrize.html for more info \"\n        \"and examples.\",\n    )\n    config.addinivalue_line(\n        \"markers\",\n        \"usefixtures(fixturename1, fixturename2, ...): mark tests as needing \"\n        \"all of the specified fixtures. see \"\n        \"https://docs.pytest.org/en/stable/explanation/fixtures.html#usefixtures \",\n    )\n\n\ndef async_fail(nodeid: str) -> None:\n    msg = (\n        \"async def functions are not natively supported.\\n\"\n        \"You need to install a suitable plugin for your async framework, for example:\\n\"\n        \"  - anyio\\n\"\n        \"  - pytest-asyncio\\n\"\n        \"  - pytest-tornasync\\n\"\n        \"  - pytest-trio\\n\"\n        \"  - pytest-twisted\"\n    )\n    fail(msg, pytrace=False)\n\n\n@hookimpl(trylast=True)\ndef pytest_pyfunc_call(pyfuncitem: Function) -> object | None:\n    testfunction = pyfuncitem.obj\n    if is_async_function(testfunction):\n        async_fail(pyfuncitem.nodeid)\n    funcargs = pyfuncitem.funcargs\n    testargs = {arg: funcargs[arg] for arg in pyfuncitem._fixtureinfo.argnames}\n    result = testfunction(**testargs)\n    if hasattr(result, \"__await__\") or hasattr(result, \"__aiter__\"):\n        async_fail(pyfuncitem.nodeid)\n    elif result is not None:\n        warnings.warn(\n            PytestReturnNotNoneWarning(\n                f\"Test functions should return None, but {pyfuncitem.nodeid} returned {type(result)!r}.\\n\"\n                \"Did you mean to use `assert` instead of `return`?\\n\"\n                \"See https://docs.pytest.org/en/stable/how-to/assert.html#return-not-none for more information.\"\n            )\n        )\n    return True\n\n\nde"}, {"start_line": 0, "end_line": 167, "belongs_to": {"file_name": "pytest_asyncio_integration.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing/plugins_integration", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "# mypy: allow-untyped-defs\nfrom __future__ import annotations\n\nimport asyncio\n\nimport pytest\n\n\n@pytest.mark.asyncio\nasync def test_sleep():\n    await asyncio.sleep(0)\n"}, {"start_line": 42000, "end_line": 44000, "belongs_to": {"file_name": "acceptance_test.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "clean_data():\n            data.clear()\n\n        @pytest.fixture(autouse=True)\n        def add_data():\n            data.update(value=True)\n\n        @pytest.mark.usefixtures('clean_data')\n        def test_value():\n            assert data.get('value')\n    \"\"\"\n    )\n    result = pytester.runpytest()\n    assert result.ret == 0\n\n\ndef test_frame_leak_on_failing_test(pytester: Pytester) -> None:\n    \"\"\"Pytest would leak garbage referencing the frames of tests that failed\n    that could never be reclaimed (#2798).\n\n    Unfortunately it was not possible to remove the actual circles because most of them\n    are made of traceback objects which cannot be weakly referenced. Those objects at least\n    can be eventually claimed by the garbage collector.\n    \"\"\"\n    pytester.makepyfile(\n        \"\"\"\n        import gc\n        import weakref\n\n        class Obj:\n            pass\n\n        ref = None\n\n        def test1():\n            obj = Obj()\n            global ref\n            ref = weakref.ref(obj)\n            assert 0\n\n        def test2():\n            gc.collect()\n            assert ref() is None\n    \"\"\"\n    )\n    result = pytester.runpytest_subprocess()\n    result.stdout.fnmatch_lines([\"*1 failed, 1 passed in*\"])\n\n\ndef test_fixture_mock_integration(pytester: Pytester) -> None:\n    \"\"\"Test that decorators applied to fixture are left working (#3774)\"\"\"\n    p = pytester.copy_example(\"acceptance/fixture_mock_integration.py\")\n    result = pytester.runpytest(p)\n    result.stdout.fnmatch_lines([\"*1 passed*\"])\n\n\ndef test_usage_error_code(pytester: Pytester) -> None:\n    result = pytester.runpytest(\"-unknown-option-\")\n    assert result.ret == ExitCode.USAGE_ERROR\n\n\ndef test_error_on_async_function(pytester: Pytester) -> None:\n    # In the below we .close() the coroutine only to avoid\n    # \"RuntimeWarning: coroutine 'test_2' was never awaited\"\n    # which messes with other tests.\n    pytester.makepyfile(\n        test_async=\"\"\"\n        async def test_1():\n            pass\n        async def te"}, {"start_line": 44000, "end_line": 46000, "belongs_to": {"file_name": "acceptance_test.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "st_2():\n            pass\n        def test_3():\n            coro = test_2()\n            coro.close()\n            return coro\n    \"\"\"\n    )\n    result = pytester.runpytest()\n    result.stdout.fnmatch_lines(\n        [\n            \"*async def functions are not natively supported*\",\n            \"*test_async.py::test_1*\",\n            \"*test_async.py::test_2*\",\n            \"*test_async.py::test_3*\",\n        ]\n    )\n    result.assert_outcomes(failed=3)\n\n\ndef test_error_on_async_gen_function(pytester: Pytester) -> None:\n    pytester.makepyfile(\n        test_async=\"\"\"\n        async def test_1():\n            yield\n        async def test_2():\n            yield\n        def test_3():\n            return test_2()\n    \"\"\"\n    )\n    result = pytester.runpytest()\n    result.stdout.fnmatch_lines(\n        [\n            \"*async def functions are not natively supported*\",\n            \"*test_async.py::test_1*\",\n            \"*test_async.py::test_2*\",\n            \"*test_async.py::test_3*\",\n        ]\n    )\n    result.assert_outcomes(failed=3)\n\n\ndef test_warning_on_sync_test_async_fixture(pytester: Pytester) -> None:\n    pytester.makepyfile(\n        test_sync=\"\"\"\n            import pytest\n\n            @pytest.fixture\n            async def async_fixture():\n                ...\n\n            def test_foo(async_fixture):\n                # suppress unawaited coroutine warning\n                try:\n                    async_fixture.send(None)\n                except StopIteration:\n                    pass\n        \"\"\"\n    )\n    result = pytester.runpytest()\n    result.stdout.fnmatch_lines(\n        [\n            \"*== warnings summary ==*\",\n            (\n                \"*PytestRemovedIn9Warning: 'test_foo' requested an async \"\n                \"fixture 'async_fixture', with no plugin or hook that handled it. \"\n                \"This is usually an error, as pytest does not natively support it. \"\n                \"This will turn into an error in pytest 9.\"\n            ),\n            \"  See: https://docs.pytes"}, {"start_line": 47000, "end_line": 49000, "belongs_to": {"file_name": "acceptance_test.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "cs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture\",\n        ]\n    )\n    result.assert_outcomes(passed=1, warnings=1)\n\n\ndef test_warning_on_sync_test_async_autouse_fixture(pytester: Pytester) -> None:\n    pytester.makepyfile(\n        test_sync=\"\"\"\n            import pytest\n\n            @pytest.fixture(autouse=True)\n            async def async_fixture():\n                ...\n\n            # We explicitly request the fixture to be able to\n            # suppress the RuntimeWarning for unawaited coroutine.\n            def test_foo(async_fixture):\n                try:\n                    async_fixture.send(None)\n                except StopIteration:\n                    pass\n        \"\"\"\n    )\n    result = pytester.runpytest()\n    result.stdout.fnmatch_lines(\n        [\n            \"*== warnings summary ==*\",\n            (\n                \"*PytestRemovedIn9Warning: 'test_foo' requested an async \"\n                \"fixture 'async_fixture' with autouse=True, with no plugin or hook \"\n                \"that handled it. \"\n                \"This is usually an error, as pytest does not natively support it. \"\n                \"This will turn into an error in pytest 9.\"\n            ),\n            \"  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture\",\n        ]\n    )\n    result.assert_outcomes(passed=1, warnings=1)\n\n\ndef test_pdb_can_be_rewritten(pytester: Pytester) -> None:\n    pytester.makepyfile(\n        **{\n            \"conftest.py\": \"\"\"\n                import pytest\n                pytest.register_assert_rewrite(\"pdb\")\n                \"\"\",\n            \"__init__.py\": \"\",\n            \"pdb.py\": \"\"\"\n                def check():\n                    assert 1 == 2\n                \"\"\",\n            \"test_pdb.py\": \"\"\"\n                def test():\n                    import pdb\n                    assert pdb.check()\n                \"\"\",\n        }\n    )\n    # Disable debugging plugin itself to avoid:\n    # > INTERNALERROR> Att"}, {"start_line": 48000, "end_line": 50000, "belongs_to": {"file_name": "acceptance_test.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "in or hook \"\n                \"that handled it. \"\n                \"This is usually an error, as pytest does not natively support it. \"\n                \"This will turn into an error in pytest 9.\"\n            ),\n            \"  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture\",\n        ]\n    )\n    result.assert_outcomes(passed=1, warnings=1)\n\n\ndef test_pdb_can_be_rewritten(pytester: Pytester) -> None:\n    pytester.makepyfile(\n        **{\n            \"conftest.py\": \"\"\"\n                import pytest\n                pytest.register_assert_rewrite(\"pdb\")\n                \"\"\",\n            \"__init__.py\": \"\",\n            \"pdb.py\": \"\"\"\n                def check():\n                    assert 1 == 2\n                \"\"\",\n            \"test_pdb.py\": \"\"\"\n                def test():\n                    import pdb\n                    assert pdb.check()\n                \"\"\",\n        }\n    )\n    # Disable debugging plugin itself to avoid:\n    # > INTERNALERROR> AttributeError: module 'pdb' has no attribute 'set_trace'\n    result = pytester.runpytest_subprocess(\"-p\", \"no:debugging\", \"-vv\")\n    result.stdout.fnmatch_lines(\n        [\n            \"    def check():\",\n            \">       assert 1 == 2\",\n            \"E       assert 1 == 2\",\n            \"\",\n            \"pdb.py:2: AssertionError\",\n            \"*= 1 failed in *\",\n        ]\n    )\n    assert result.ret == 1\n\n\ndef test_tee_stdio_captures_and_live_prints(pytester: Pytester) -> None:\n    testpath = pytester.makepyfile(\n        \"\"\"\n        import sys\n        def test_simple():\n            print (\"@this is stdout@\")\n            print (\"@this is stderr@\", file=sys.stderr)\n    \"\"\"\n    )\n    result = pytester.runpytest_subprocess(\n        testpath,\n        \"--capture=tee-sys\",\n        \"--junitxml=output.xml\",\n        \"-o\",\n        \"junit_logging=all\",\n    )\n\n    # ensure stdout/stderr were 'live printed'\n    result.stdout.fnmatch_lines([\"*@this is stdout@*\"])\n    result.stderr.fnmatch_lines([\"*@th"}, {"start_line": 0, "end_line": 2000, "belongs_to": {"file_name": "python.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "# mypy: allow-untyped-defs\n\"\"\"Python test discovery, setup and run of test functions.\"\"\"\n\nfrom __future__ import annotations\n\nimport abc\nfrom collections import Counter\nfrom collections import defaultdict\nfrom collections.abc import Callable\nfrom collections.abc import Generator\nfrom collections.abc import Iterable\nfrom collections.abc import Iterator\nfrom collections.abc import Mapping\nfrom collections.abc import Sequence\nimport dataclasses\nimport enum\nimport fnmatch\nfrom functools import partial\nimport inspect\nimport itertools\nimport os\nfrom pathlib import Path\nimport re\nimport types\nfrom typing import Any\nfrom typing import final\nfrom typing import Literal\nfrom typing import NoReturn\nfrom typing import TYPE_CHECKING\nimport warnings\n\nimport _pytest\nfrom _pytest import fixtures\nfrom _pytest import nodes\nfrom _pytest._code import filter_traceback\nfrom _pytest._code import getfslineno\nfrom _pytest._code.code import ExceptionInfo\nfrom _pytest._code.code import TerminalRepr\nfrom _pytest._code.code import Traceback\nfrom _pytest._io.saferepr import saferepr\nfrom _pytest.compat import ascii_escaped\nfrom _pytest.compat import get_default_arg_names\nfrom _pytest.compat import get_real_func\nfrom _pytest.compat import getimfunc\nfrom _pytest.compat import is_async_function\nfrom _pytest.compat import LEGACY_PATH\nfrom _pytest.compat import NOTSET\nfrom _pytest.compat import safe_getattr\nfrom _pytest.compat import safe_isclass\nfrom _pytest.config import Config\nfrom _pytest.config import hookimpl\nfrom _pytest.config.argparsing import Parser\nfrom _pytest.deprecated import check_ispytest\nfrom _pytest.fixtures import FixtureDef\nfrom _pytest.fixtures import FixtureRequest\nfrom _pytest.fixtures import FuncFixtureInfo\nfrom _pytest.fixtures import get_scope_node\nfrom _pytest.main import Session\nfrom _pytest.mark import ParameterSet\nfrom _pytest.mark.structures import _HiddenParam\nfrom _pytest.mark.structures import get_unpacked_marks\nfrom _pytest.mark.structures import HIDDEN_PARAM\nfrom _p"}, {"start_line": 1000, "end_line": 3000, "belongs_to": {"file_name": "python.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "code.code import Traceback\nfrom _pytest._io.saferepr import saferepr\nfrom _pytest.compat import ascii_escaped\nfrom _pytest.compat import get_default_arg_names\nfrom _pytest.compat import get_real_func\nfrom _pytest.compat import getimfunc\nfrom _pytest.compat import is_async_function\nfrom _pytest.compat import LEGACY_PATH\nfrom _pytest.compat import NOTSET\nfrom _pytest.compat import safe_getattr\nfrom _pytest.compat import safe_isclass\nfrom _pytest.config import Config\nfrom _pytest.config import hookimpl\nfrom _pytest.config.argparsing import Parser\nfrom _pytest.deprecated import check_ispytest\nfrom _pytest.fixtures import FixtureDef\nfrom _pytest.fixtures import FixtureRequest\nfrom _pytest.fixtures import FuncFixtureInfo\nfrom _pytest.fixtures import get_scope_node\nfrom _pytest.main import Session\nfrom _pytest.mark import ParameterSet\nfrom _pytest.mark.structures import _HiddenParam\nfrom _pytest.mark.structures import get_unpacked_marks\nfrom _pytest.mark.structures import HIDDEN_PARAM\nfrom _pytest.mark.structures import Mark\nfrom _pytest.mark.structures import MarkDecorator\nfrom _pytest.mark.structures import normalize_mark_list\nfrom _pytest.outcomes import fail\nfrom _pytest.outcomes import skip\nfrom _pytest.pathlib import fnmatch_ex\nfrom _pytest.pathlib import import_path\nfrom _pytest.pathlib import ImportPathMismatchError\nfrom _pytest.pathlib import scandir\nfrom _pytest.scope import _ScopeName\nfrom _pytest.scope import Scope\nfrom _pytest.stash import StashKey\nfrom _pytest.warning_types import PytestCollectionWarning\nfrom _pytest.warning_types import PytestReturnNotNoneWarning\n\n\nif TYPE_CHECKING:\n    from typing_extensions import Self\n\n\ndef pytest_addoption(parser: Parser) -> None:\n    parser.addini(\n        \"python_files\",\n        type=\"args\",\n        # NOTE: default is also used in AssertionRewritingHook.\n        default=[\"test_*.py\", \"*_test.py\"],\n        help=\"Glob-style file patterns for Python test module discovery\",\n    )\n    parser.addini(\n        \"python_classes\""}, {"start_line": 0, "end_line": 161, "belongs_to": {"file_name": "pytest_anyio_integration.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing/plugins_integration", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "# mypy: allow-untyped-defs\nfrom __future__ import annotations\n\nimport anyio\n\nimport pytest\n\n\n@pytest.mark.anyio\nasync def test_sleep():\n    await anyio.sleep(0)\n"}], "retrieved_count": 10, "cost_time": 0.33910703659057617}
{"question": "How does Pytest integrate with Django for testing web applications?", "answer": null, "relative_code_list": null, "ground_truth": "Pytest integrates with Django for testing web applications through the pytest-django plugin, which is a third-party plugin that provides seamless integration. The integration includes: 1) Installation of pytest-django plugin that extends pytest's functionality for Django applications, 2) Configuration through Django settings using --ds command-line option to specify Django settings module, 3) Automatic Django setup and teardown for test sessions including database configuration and management, 4) Integration with Django's test client for making HTTP requests and testing views, 5) Support for Django fixtures and model testing with automatic database transaction management, 6) Integration with Django's ORM for database operations during testing, 7) Support for Django's middleware and authentication systems in test environment, 8) Configuration options in pytest.ini or pyproject.toml for Django-specific settings, 9) Integration with Django's test discovery and test runner compatibility, 10) Support for Django's static files and media handling during tests, 11) Integration with Django's cache and session management for testing, 12) Plugin architecture that allows pytest-django to hook into pytest's test execution lifecycle.", "score": null, "retrieved_content": [{"start_line": 20000, "end_line": 22000, "belongs_to": {"file_name": "acceptance_test.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": " test_earlyinit(self, pytester: Pytester) -> None:\n        p = pytester.makepyfile(\n            \"\"\"\n            import pytest\n            assert hasattr(pytest, 'mark')\n        \"\"\"\n        )\n        result = pytester.runpython(p)\n        assert result.ret == 0\n\n    def test_pydoc(self, pytester: Pytester) -> None:\n        result = pytester.runpython_c(\"import pytest;help(pytest)\")\n        assert result.ret == 0\n        s = result.stdout.str()\n        assert \"MarkGenerator\" in s\n\n    def test_import_star_pytest(self, pytester: Pytester) -> None:\n        p = pytester.makepyfile(\n            \"\"\"\n            from pytest import *\n            #Item\n            #File\n            main\n            skip\n            xfail\n        \"\"\"\n        )\n        result = pytester.runpython(p)\n        assert result.ret == 0\n\n    def test_double_pytestcmdline(self, pytester: Pytester) -> None:\n        p = pytester.makepyfile(\n            run=\"\"\"\n            import pytest\n            pytest.main()\n            pytest.main()\n        \"\"\"\n        )\n        pytester.makepyfile(\n            \"\"\"\n            def test_hello():\n                pass\n        \"\"\"\n        )\n        result = pytester.runpython(p)\n        result.stdout.fnmatch_lines([\"*1 passed*\", \"*1 passed*\"])\n\n    def test_python_minus_m_invocation_ok(self, pytester: Pytester) -> None:\n        p1 = pytester.makepyfile(\"def test_hello(): pass\")\n        res = pytester.run(sys.executable, \"-m\", \"pytest\", str(p1))\n        assert res.ret == 0\n\n    def test_python_minus_m_invocation_fail(self, pytester: Pytester) -> None:\n        p1 = pytester.makepyfile(\"def test_fail(): 0/0\")\n        res = pytester.run(sys.executable, \"-m\", \"pytest\", str(p1))\n        assert res.ret == 1\n\n    def test_python_pytest_package(self, pytester: Pytester) -> None:\n        p1 = pytester.makepyfile(\"def test_pass(): pass\")\n        res = pytester.run(sys.executable, \"-m\", \"pytest\", str(p1))\n        assert res.ret == 0\n        res.stdout.fnmatch_lines([\"*1 passed*\"])\n\n"}, {"start_line": 0, "end_line": 2000, "belongs_to": {"file_name": "__init__.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "# PYTHON_ARGCOMPLETE_OK\n\"\"\"pytest: unit and functional testing with Python.\"\"\"\n\nfrom __future__ import annotations\n\nfrom _pytest import __version__\nfrom _pytest import version_tuple\nfrom _pytest._code import ExceptionInfo\nfrom _pytest.assertion import register_assert_rewrite\nfrom _pytest.cacheprovider import Cache\nfrom _pytest.capture import CaptureFixture\nfrom _pytest.config import cmdline\nfrom _pytest.config import Config\nfrom _pytest.config import console_main\nfrom _pytest.config import ExitCode\nfrom _pytest.config import hookimpl\nfrom _pytest.config import hookspec\nfrom _pytest.config import main\nfrom _pytest.config import PytestPluginManager\nfrom _pytest.config import UsageError\nfrom _pytest.config.argparsing import OptionGroup\nfrom _pytest.config.argparsing import Parser\nfrom _pytest.debugging import pytestPDB as __pytestPDB\nfrom _pytest.doctest import DoctestItem\nfrom _pytest.fixtures import fixture\nfrom _pytest.fixtures import FixtureDef\nfrom _pytest.fixtures import FixtureLookupError\nfrom _pytest.fixtures import FixtureRequest\nfrom _pytest.fixtures import yield_fixture\nfrom _pytest.freeze_support import freeze_includes\nfrom _pytest.legacypath import TempdirFactory\nfrom _pytest.legacypath import Testdir\nfrom _pytest.logging import LogCaptureFixture\nfrom _pytest.main import Dir\nfrom _pytest.main import Session\nfrom _pytest.mark import HIDDEN_PARAM\nfrom _pytest.mark import Mark\nfrom _pytest.mark import MARK_GEN as mark\nfrom _pytest.mark import MarkDecorator\nfrom _pytest.mark import MarkGenerator\nfrom _pytest.mark import param\nfrom _pytest.monkeypatch import MonkeyPatch\nfrom _pytest.nodes import Collector\nfrom _pytest.nodes import Directory\nfrom _pytest.nodes import File\nfrom _pytest.nodes import Item\nfrom _pytest.outcomes import exit\nfrom _pytest.outcomes import fail\nfrom _pytest.outcomes import importorskip\nfrom _pytest.outcomes import skip\nfrom _pytest.outcomes import xfail\nfrom _pytest.pytester import HookRecorder\nfrom _pytest.pytester import LineMatcher\nfr"}, {"start_line": 15000, "end_line": 17000, "belongs_to": {"file_name": "pytester.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "during initialization.\n\n    It is particularly useful for testing plugins. It is similar to the :fixture:`tmp_path`\n    fixture but provides methods which aid in testing pytest itself.\n    \"\"\"\n    return Pytester(request, tmp_path_factory, monkeypatch, _ispytest=True)\n\n\n@fixture\ndef _sys_snapshot() -> Generator[None]:\n    snappaths = SysPathsSnapshot()\n    snapmods = SysModulesSnapshot()\n    yield\n    snapmods.restore()\n    snappaths.restore()\n\n\n@fixture\ndef _config_for_test() -> Generator[Config]:\n    from _pytest.config import get_config\n\n    config = get_config()\n    yield config\n    config._ensure_unconfigure()  # cleanup, e.g. capman closing tmpfiles.\n\n\n# Regex to match the session duration string in the summary: \"74.34s\".\nrex_session_duration = re.compile(r\"\\d+\\.\\d\\ds\")\n# Regex to match all the counts and phrases in the summary line: \"34 passed, 111 skipped\".\nrex_outcome = re.compile(r\"(\\d+) (\\w+)\")\n\n\n@final\nclass RunResult:\n    \"\"\"The result of running a command from :class:`~pytest.Pytester`.\"\"\"\n\n    def __init__(\n        self,\n        ret: int | ExitCode,\n        outlines: list[str],\n        errlines: list[str],\n        duration: float,\n    ) -> None:\n        try:\n            self.ret: int | ExitCode = ExitCode(ret)\n            \"\"\"The return value.\"\"\"\n        except ValueError:\n            self.ret = ret\n        self.outlines = outlines\n        \"\"\"List of lines captured from stdout.\"\"\"\n        self.errlines = errlines\n        \"\"\"List of lines captured from stderr.\"\"\"\n        self.stdout = LineMatcher(outlines)\n        \"\"\":class:`~pytest.LineMatcher` of stdout.\n\n        Use e.g. :func:`str(stdout) <pytest.LineMatcher.__str__()>` to reconstruct stdout, or the commonly used\n        :func:`stdout.fnmatch_lines() <pytest.LineMatcher.fnmatch_lines()>` method.\n        \"\"\"\n        self.stderr = LineMatcher(errlines)\n        \"\"\":class:`~pytest.LineMatcher` of stderr.\"\"\"\n        self.duration = duration\n        \"\"\"Duration in seconds.\"\"\"\n\n    def __repr__(self) -> st"}, {"start_line": 47000, "end_line": 49000, "belongs_to": {"file_name": "acceptance_test.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "cs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture\",\n        ]\n    )\n    result.assert_outcomes(passed=1, warnings=1)\n\n\ndef test_warning_on_sync_test_async_autouse_fixture(pytester: Pytester) -> None:\n    pytester.makepyfile(\n        test_sync=\"\"\"\n            import pytest\n\n            @pytest.fixture(autouse=True)\n            async def async_fixture():\n                ...\n\n            # We explicitly request the fixture to be able to\n            # suppress the RuntimeWarning for unawaited coroutine.\n            def test_foo(async_fixture):\n                try:\n                    async_fixture.send(None)\n                except StopIteration:\n                    pass\n        \"\"\"\n    )\n    result = pytester.runpytest()\n    result.stdout.fnmatch_lines(\n        [\n            \"*== warnings summary ==*\",\n            (\n                \"*PytestRemovedIn9Warning: 'test_foo' requested an async \"\n                \"fixture 'async_fixture' with autouse=True, with no plugin or hook \"\n                \"that handled it. \"\n                \"This is usually an error, as pytest does not natively support it. \"\n                \"This will turn into an error in pytest 9.\"\n            ),\n            \"  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture\",\n        ]\n    )\n    result.assert_outcomes(passed=1, warnings=1)\n\n\ndef test_pdb_can_be_rewritten(pytester: Pytester) -> None:\n    pytester.makepyfile(\n        **{\n            \"conftest.py\": \"\"\"\n                import pytest\n                pytest.register_assert_rewrite(\"pdb\")\n                \"\"\",\n            \"__init__.py\": \"\",\n            \"pdb.py\": \"\"\"\n                def check():\n                    assert 1 == 2\n                \"\"\",\n            \"test_pdb.py\": \"\"\"\n                def test():\n                    import pdb\n                    assert pdb.check()\n                \"\"\",\n        }\n    )\n    # Disable debugging plugin itself to avoid:\n    # > INTERNALERROR> Att"}, {"start_line": 0, "end_line": 154, "belongs_to": {"file_name": "__main__.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "\"\"\"The pytest entry point.\"\"\"\n\nfrom __future__ import annotations\n\nimport pytest\n\n\nif __name__ == \"__main__\":\n    raise SystemExit(pytest.console_main())\n"}, {"start_line": 1000, "end_line": 3000, "belongs_to": {"file_name": "pytester.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "t.compat import NOTSET\nfrom _pytest.compat import NotSetType\nfrom _pytest.config import _PluggyPlugin\nfrom _pytest.config import Config\nfrom _pytest.config import ExitCode\nfrom _pytest.config import hookimpl\nfrom _pytest.config import main\nfrom _pytest.config import PytestPluginManager\nfrom _pytest.config.argparsing import Parser\nfrom _pytest.deprecated import check_ispytest\nfrom _pytest.fixtures import fixture\nfrom _pytest.fixtures import FixtureRequest\nfrom _pytest.main import Session\nfrom _pytest.monkeypatch import MonkeyPatch\nfrom _pytest.nodes import Collector\nfrom _pytest.nodes import Item\nfrom _pytest.outcomes import fail\nfrom _pytest.outcomes import importorskip\nfrom _pytest.outcomes import skip\nfrom _pytest.pathlib import bestrelpath\nfrom _pytest.pathlib import make_numbered_dir\nfrom _pytest.reports import CollectReport\nfrom _pytest.reports import TestReport\nfrom _pytest.tmpdir import TempPathFactory\nfrom _pytest.warning_types import PytestFDWarning\n\n\nif TYPE_CHECKING:\n    import pexpect\n\n\npytest_plugins = [\"pytester_assertions\"]\n\n\nIGNORE_PAM = [  # filenames added when obtaining details about the current user\n    \"/var/lib/sss/mc/passwd\"\n]\n\n\ndef pytest_addoption(parser: Parser) -> None:\n    parser.addoption(\n        \"--lsof\",\n        action=\"store_true\",\n        dest=\"lsof\",\n        default=False,\n        help=\"Run FD checks if lsof is available\",\n    )\n\n    parser.addoption(\n        \"--runpytest\",\n        default=\"inprocess\",\n        dest=\"runpytest\",\n        choices=(\"inprocess\", \"subprocess\"),\n        help=(\n            \"Run pytest sub runs in tests using an 'inprocess' \"\n            \"or 'subprocess' (python -m main) method\"\n        ),\n    )\n\n    parser.addini(\n        \"pytester_example_dir\", help=\"Directory to take the pytester example files from\"\n    )\n\n\ndef pytest_configure(config: Config) -> None:\n    if config.getvalue(\"lsof\"):\n        checker = LsofFdLeakChecker()\n        if checker.matching_platform():\n            config.pluginmanager.register(ch"}, {"start_line": 0, "end_line": 2000, "belongs_to": {"file_name": "pytester.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "# mypy: allow-untyped-defs\n\"\"\"(Disabled by default) support for testing pytest and pytest plugins.\n\nPYTEST_DONT_REWRITE\n\"\"\"\n\nfrom __future__ import annotations\n\nimport collections.abc\nfrom collections.abc import Callable\nfrom collections.abc import Generator\nfrom collections.abc import Iterable\nfrom collections.abc import Sequence\nimport contextlib\nfrom fnmatch import fnmatch\nimport gc\nimport importlib\nfrom io import StringIO\nimport locale\nimport os\nfrom pathlib import Path\nimport platform\nimport re\nimport shutil\nimport subprocess\nimport sys\nimport traceback\nfrom typing import Any\nfrom typing import Final\nfrom typing import final\nfrom typing import IO\nfrom typing import Literal\nfrom typing import overload\nfrom typing import TextIO\nfrom typing import TYPE_CHECKING\nfrom weakref import WeakKeyDictionary\n\nfrom iniconfig import IniConfig\nfrom iniconfig import SectionWrapper\n\nfrom _pytest import timing\nfrom _pytest._code import Source\nfrom _pytest.capture import _get_multicapture\nfrom _pytest.compat import NOTSET\nfrom _pytest.compat import NotSetType\nfrom _pytest.config import _PluggyPlugin\nfrom _pytest.config import Config\nfrom _pytest.config import ExitCode\nfrom _pytest.config import hookimpl\nfrom _pytest.config import main\nfrom _pytest.config import PytestPluginManager\nfrom _pytest.config.argparsing import Parser\nfrom _pytest.deprecated import check_ispytest\nfrom _pytest.fixtures import fixture\nfrom _pytest.fixtures import FixtureRequest\nfrom _pytest.main import Session\nfrom _pytest.monkeypatch import MonkeyPatch\nfrom _pytest.nodes import Collector\nfrom _pytest.nodes import Item\nfrom _pytest.outcomes import fail\nfrom _pytest.outcomes import importorskip\nfrom _pytest.outcomes import skip\nfrom _pytest.pathlib import bestrelpath\nfrom _pytest.pathlib import make_numbered_dir\nfrom _pytest.reports import CollectReport\nfrom _pytest.reports import TestReport\nfrom _pytest.tmpdir import TempPathFactory\nfrom _pytest.warning_types import PytestFDWarning\n\n\nif TYPE_CHECKING:\n    imp"}, {"start_line": 0, "end_line": 2000, "belongs_to": {"file_name": "test_main.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "# mypy: allow-untyped-defs\nfrom __future__ import annotations\n\nimport argparse\nimport os\nfrom pathlib import Path\nimport re\n\nfrom _pytest.config import ExitCode\nfrom _pytest.config import UsageError\nfrom _pytest.main import CollectionArgument\nfrom _pytest.main import resolve_collection_argument\nfrom _pytest.main import validate_basetemp\nfrom _pytest.pytester import Pytester\nimport pytest\n\n\n@pytest.mark.parametrize(\n    \"ret_exc\",\n    (\n        pytest.param((None, ValueError)),\n        pytest.param((42, SystemExit)),\n        pytest.param((False, SystemExit)),\n    ),\n)\ndef test_wrap_session_notify_exception(ret_exc, pytester: Pytester) -> None:\n    returncode, exc = ret_exc\n    c1 = pytester.makeconftest(\n        f\"\"\"\n        import pytest\n\n        def pytest_sessionstart():\n            raise {exc.__name__}(\"boom\")\n\n        def pytest_internalerror(excrepr, excinfo):\n            returncode = {returncode!r}\n            if returncode is not False:\n                pytest.exit(\"exiting after %s...\" % excinfo.typename, returncode={returncode!r})\n    \"\"\"\n    )\n    result = pytester.runpytest()\n    if returncode:\n        assert result.ret == returncode\n    else:\n        assert result.ret == ExitCode.INTERNAL_ERROR\n    assert result.stdout.lines[0] == \"INTERNALERROR> Traceback (most recent call last):\"\n\n    end_lines = result.stdout.lines[-3:]\n\n    if exc == SystemExit:\n        assert end_lines == [\n            f'INTERNALERROR>   File \"{c1}\", line 4, in pytest_sessionstart',\n            'INTERNALERROR>     raise SystemExit(\"boom\")',\n            \"INTERNALERROR> SystemExit: boom\",\n        ]\n    else:\n        assert end_lines == [\n            f'INTERNALERROR>   File \"{c1}\", line 4, in pytest_sessionstart',\n            'INTERNALERROR>     raise ValueError(\"boom\")',\n            \"INTERNALERROR> ValueError: boom\",\n        ]\n    if returncode is False:\n        assert result.stderr.lines == [\"mainloop: caught unexpected SystemExit!\"]\n    else:\n        assert result.stderr.lines == [f\""}, {"start_line": 17000, "end_line": 19000, "belongs_to": {"file_name": "fixtures.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing/python", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "ram\n            \"\"\"\n        )\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n\n            @pytest.fixture(params=[10, 20])\n            def foo(foo, request):\n                assert request.param == foo\n                return foo * 2\n\n            def test_spam(foo):\n                assert foo in (20, 40)\n            \"\"\"\n        )\n        result = pytester.runpytest()\n        result.stdout.fnmatch_lines([\"*2 passed*\"])\n\n    def test_autouse_fixture_plugin(self, pytester: Pytester) -> None:\n        # A fixture from a plugin has no baseid set, which screwed up\n        # the autouse fixture handling.\n        pytester.makepyfile(\n            testplugin=\"\"\"\n            import pytest\n\n            @pytest.fixture(autouse=True)\n            def foo(request):\n                request.function.foo = 7\n        \"\"\"\n        )\n        pytester.syspathinsert()\n        pytester.makepyfile(\n            \"\"\"\n            pytest_plugins = 'testplugin'\n\n            def test_foo(request):\n                assert request.function.foo == 7\n        \"\"\"\n        )\n        result = pytester.runpytest()\n        assert result.ret == 0\n\n    def test_funcarg_lookup_error(self, pytester: Pytester) -> None:\n        pytester.makeconftest(\n            \"\"\"\n            import pytest\n\n            @pytest.fixture\n            def a_fixture(): pass\n\n            @pytest.fixture\n            def b_fixture(): pass\n\n            @pytest.fixture\n            def c_fixture(): pass\n\n            @pytest.fixture\n            def d_fixture(): pass\n        \"\"\"\n        )\n        pytester.makepyfile(\n            \"\"\"\n            def test_lookup_error(unknown):\n                pass\n        \"\"\"\n        )\n        result = pytester.runpytest()\n        result.stdout.fnmatch_lines(\n            [\n                \"*ERROR at setup of test_lookup_error*\",\n                \"  def test_lookup_error(unknown):*\",\n                \"E       fixture 'unknown' not found\",\n                \">       available fixtures:*a_fixture,"}, {"start_line": 3000, "end_line": 4297, "belongs_to": {"file_name": "test_helpconfig.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "None:\n    pytester.makeconftest(\n        \"\"\"\n        def pytest_hello(xyz):\n            pass\n    \"\"\"\n    )\n    result = pytester.runpytest()\n    assert result.ret != 0\n    result.stdout.fnmatch_lines([\"*unknown hook*pytest_hello*\"])\n\n\ndef test_hookvalidation_optional(pytester: Pytester) -> None:\n    pytester.makeconftest(\n        \"\"\"\n        import pytest\n        @pytest.hookimpl(optionalhook=True)\n        def pytest_hello(xyz):\n            pass\n    \"\"\"\n    )\n    result = pytester.runpytest()\n    assert result.ret == ExitCode.NO_TESTS_COLLECTED\n\n\ndef test_traceconfig(pytester: Pytester) -> None:\n    result = pytester.runpytest(\"--traceconfig\")\n    result.stdout.fnmatch_lines([\"*using*pytest*\", \"*active plugins*\"])\n\n\ndef test_debug(pytester: Pytester) -> None:\n    result = pytester.runpytest_subprocess(\"--debug\")\n    assert result.ret == ExitCode.NO_TESTS_COLLECTED\n    p = pytester.path.joinpath(\"pytestdebug.log\")\n    assert \"pytest_sessionstart\" in p.read_text(\"utf-8\")\n\n\ndef test_PYTEST_DEBUG(pytester: Pytester, monkeypatch) -> None:\n    monkeypatch.setenv(\"PYTEST_DEBUG\", \"1\")\n    result = pytester.runpytest_subprocess()\n    assert result.ret == ExitCode.NO_TESTS_COLLECTED\n    result.stderr.fnmatch_lines(\n        [\"*pytest_plugin_registered*\", \"*manager*PluginManager*\"]\n    )\n"}], "retrieved_count": 10, "cost_time": 0.3219316005706787}
{"question": "How does Pytest support parameterized testing for different API endpoints?", "answer": null, "relative_code_list": null, "ground_truth": "Pytest supports parameterized testing for different API endpoints through multiple mechanisms: 1) @pytest.mark.parametrize decorator that allows defining multiple sets of arguments for test functions, enabling testing of different endpoints with various parameters, 2) Metafunc.parametrize() method that can be called within pytest_generate_tests hook for dynamic parametrization based on configuration or external data, 3) Support for multiple parametrize decorators that can be stacked to test combinations of different HTTP methods, endpoints, and parameters, 4) Custom ID generation through the ids parameter to provide meaningful test names for different API endpoint combinations, 5) Integration with pytest's test discovery and execution system for organizing API endpoint tests, 6) Support for indirect parametrization where endpoint URLs or parameters can be passed as fixtures for more complex setup, 7) Command-line driven parametrization through pytest_addoption and pytest_generate_tests hooks for dynamic endpoint selection, 8) Scenario-based testing where different API endpoint scenarios can be defined and tested systematically, 9) Integration with monkeypatch fixture for mocking different API responses based on parametrized endpoints, 10) Support for testing different HTTP status codes, response formats, and error conditions across multiple endpoints, 11) Class-level parametrization where all test methods in a class can be parametrized for different API endpoints, 12) Module-level parametrization using pytestmark for applying endpoint parameters to all tests in a module.", "score": null, "retrieved_content": [{"start_line": 12000, "end_line": 14000, "belongs_to": {"file_name": "acceptance_test.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "s(metafunc):\n                metafunc.parametrize('i', [1, 2], ids=[\"1\", \"2\"])\n            def test_func(i):\n                pass\n        \"\"\"\n        )\n        res = pytester.runpytest(p.name + \"::\" + \"test_func[1]\")\n        assert res.ret == 0\n        res.stdout.fnmatch_lines([\"*1 passed*\"])\n\n    def test_direct_addressing_selects_duplicates(self, pytester: Pytester) -> None:\n        p = pytester.makepyfile(\n            \"\"\"\n            import pytest\n\n            @pytest.mark.parametrize(\"a\", [1, 2, 10, 11, 2, 1, 12, 11])\n            def test_func(a):\n                pass\n            \"\"\"\n        )\n        result = pytester.runpytest(p)\n        result.assert_outcomes(failed=0, passed=8)\n\n    def test_direct_addressing_selects_duplicates_1(self, pytester: Pytester) -> None:\n        p = pytester.makepyfile(\n            \"\"\"\n            import pytest\n\n            @pytest.mark.parametrize(\"a\", [1, 2, 10, 11, 2, 1, 12, 1_1,2_1])\n            def test_func(a):\n                pass\n            \"\"\"\n        )\n        result = pytester.runpytest(p)\n        result.assert_outcomes(failed=0, passed=9)\n\n    def test_direct_addressing_selects_duplicates_2(self, pytester: Pytester) -> None:\n        p = pytester.makepyfile(\n            \"\"\"\n            import pytest\n\n            @pytest.mark.parametrize(\"a\", [\"a\",\"b\",\"c\",\"a\",\"a1\"])\n            def test_func(a):\n                pass\n            \"\"\"\n        )\n        result = pytester.runpytest(p)\n        result.assert_outcomes(failed=0, passed=5)\n\n    def test_direct_addressing_notfound(self, pytester: Pytester) -> None:\n        p = pytester.makepyfile(\n            \"\"\"\n            def test_func():\n                pass\n        \"\"\"\n        )\n        res = pytester.runpytest(p.name + \"::\" + \"test_notfound\")\n        assert res.ret\n        res.stderr.fnmatch_lines([\"*ERROR*not found*\"])\n\n    def test_docstring_on_hookspec(self) -> None:\n        from _pytest import hookspec\n\n        for name, value in vars(hookspec).items():\n            if nam"}, {"start_line": 34000, "end_line": 36000, "belongs_to": {"file_name": "metafunc.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing/python", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "alls[0].params == dict(x=1, y=2)\n        assert metafunc._calls[0].id == \"1-2\"\n        assert metafunc._calls[1].params == dict(x=3, y=4)\n        assert metafunc._calls[1].id == \"3-4\"\n\n    def test_high_scoped_parametrize_reordering(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n\n            @pytest.mark.parametrize(\"arg2\", [3, 4])\n            @pytest.mark.parametrize(\"arg1\", [0, 1, 2], scope='module')\n            def test1(arg1, arg2):\n                pass\n\n            def test2():\n                pass\n\n            @pytest.mark.parametrize(\"arg1\", [0, 1, 2], scope='module')\n            def test3(arg1):\n                pass\n        \"\"\"\n        )\n        result = pytester.runpytest(\"--collect-only\")\n        result.stdout.re_match_lines(\n            [\n                r\"    <Function test1\\[0-3\\]>\",\n                r\"    <Function test3\\[0\\]>\",\n                r\"    <Function test1\\[0-4\\]>\",\n                r\"    <Function test3\\[1\\]>\",\n                r\"    <Function test1\\[1-3\\]>\",\n                r\"    <Function test3\\[2\\]>\",\n                r\"    <Function test1\\[1-4\\]>\",\n                r\"    <Function test1\\[2-3\\]>\",\n                r\"    <Function test1\\[2-4\\]>\",\n                r\"    <Function test2>\",\n            ]\n        )\n\n    def test_parametrize_multiple_times(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n            pytestmark = pytest.mark.parametrize(\"x\", [1,2])\n            def test_func(x):\n                assert 0, x\n            class TestClass(object):\n                pytestmark = pytest.mark.parametrize(\"y\", [3,4])\n                def test_meth(self, x, y):\n                    assert 0, x\n        \"\"\"\n        )\n        result = pytester.runpytest()\n        assert result.ret == 1\n        result.assert_outcomes(failed=6)\n\n    def test_parametrize_CSV(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            \"\"\"\n     "}, {"start_line": 40000, "end_line": 42000, "belongs_to": {"file_name": "metafunc.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing/python", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "ster.makepyfile(\n            \"\"\"\n            class TestClass(object):\n                def pytest_generate_tests(self, metafunc):\n                    metafunc.parametrize('hello', ['world'], ids=['hellow'])\n\n                def test_myfunc(self, hello):\n                    assert hello == \"world\"\n        \"\"\"\n        )\n        result = pytester.runpytest(\"-v\", p)\n        result.stdout.fnmatch_lines([\"*test_myfunc*hello*PASS*\", \"*1 passed*\"])\n\n    def test_two_functions_not_same_instance(self, pytester: Pytester) -> None:\n        p = pytester.makepyfile(\n            \"\"\"\n            def pytest_generate_tests(metafunc):\n                metafunc.parametrize('arg1', [10, 20], ids=[\"0\", \"1\"])\n\n            class TestClass(object):\n                def test_func(self, arg1):\n                    assert not hasattr(self, 'x')\n                    self.x = 1\n        \"\"\"\n        )\n        result = pytester.runpytest(\"-v\", p)\n        result.stdout.fnmatch_lines(\n            [\"*test_func*0*PASS*\", \"*test_func*1*PASS*\", \"*2 pass*\"]\n        )\n\n    def test_issue28_setup_method_in_generate_tests(self, pytester: Pytester) -> None:\n        p = pytester.makepyfile(\n            \"\"\"\n            def pytest_generate_tests(metafunc):\n                metafunc.parametrize('arg1', [1])\n\n            class TestClass(object):\n                def test_method(self, arg1):\n                    assert arg1 == self.val\n                def setup_method(self, func):\n                    self.val = 1\n            \"\"\"\n        )\n        result = pytester.runpytest(p)\n        result.assert_outcomes(passed=1)\n\n    def test_parametrize_functional2(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            def pytest_generate_tests(metafunc):\n                metafunc.parametrize(\"arg1\", [1,2])\n                metafunc.parametrize(\"arg2\", [4,5])\n            def test_hello(arg1, arg2):\n                assert 0, (arg1, arg2)\n        \"\"\"\n        )\n        result = pytester.runpytest()\n   "}, {"start_line": 19000, "end_line": 21000, "belongs_to": {"file_name": "collect.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing/python", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "ester: Pytester) -> None:\n        items = pytester.getitems(\n            \"\"\"\\\n            import pytest\n\n            @pytest.mark.parametrize('v', ('', ' '))\n            @pytest.mark.parametrize('w', ('', ' '))\n            def test(v, w): ...\n            \"\"\"\n        )\n        names = {item.name for item in items}\n        assert names == {\"test[-]\", \"test[ -]\", \"test[- ]\", \"test[ - ]\"}\n\n    def test_function_equality_with_callspec(self, pytester: Pytester) -> None:\n        items = pytester.getitems(\n            \"\"\"\n            import pytest\n            @pytest.mark.parametrize('arg', [1,2])\n            def test_function(arg):\n                pass\n        \"\"\"\n        )\n        assert items[0] != items[1]\n        assert not (items[0] == items[1])\n\n    def test_pyfunc_call(self, pytester: Pytester) -> None:\n        item = pytester.getitem(\"def test_func(): raise ValueError\")\n        config = item.config\n\n        class MyPlugin1:\n            def pytest_pyfunc_call(self):\n                raise ValueError\n\n        class MyPlugin2:\n            def pytest_pyfunc_call(self):\n                return True\n\n        config.pluginmanager.register(MyPlugin1())\n        config.pluginmanager.register(MyPlugin2())\n        config.hook.pytest_runtest_setup(item=item)\n        config.hook.pytest_pyfunc_call(pyfuncitem=item)\n\n    def test_multiple_parametrize(self, pytester: Pytester) -> None:\n        modcol = pytester.getmodulecol(\n            \"\"\"\n            import pytest\n            @pytest.mark.parametrize('x', [0, 1])\n            @pytest.mark.parametrize('y', [2, 3])\n            def test1(x, y):\n                pass\n        \"\"\"\n        )\n        colitems = modcol.collect()\n        assert colitems[0].name == \"test1[2-0]\"\n        assert colitems[1].name == \"test1[2-1]\"\n        assert colitems[2].name == \"test1[3-0]\"\n        assert colitems[3].name == \"test1[3-1]\"\n\n    def test_issue751_multiple_parametrize_with_ids(self, pytester: Pytester) -> None:\n        modcol = pytester.getmodulecol("}, {"start_line": 68000, "end_line": 70000, "belongs_to": {"file_name": "metafunc.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing/python", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "else (2, 0)\n        reprec.assertoutcome(passed=passed, failed=failed)\n\n    def test_pytest_make_parametrize_id(self, pytester: Pytester) -> None:\n        pytester.makeconftest(\n            \"\"\"\n            def pytest_make_parametrize_id(config, val):\n                return str(val * 2)\n        \"\"\"\n        )\n        pytester.makepyfile(\n            \"\"\"\n                import pytest\n\n                @pytest.mark.parametrize(\"x\", range(2))\n                def test_func(x):\n                    pass\n                \"\"\"\n        )\n        result = pytester.runpytest(\"-v\")\n        result.stdout.fnmatch_lines([\"*test_func*0*PASS*\", \"*test_func*2*PASS*\"])\n\n    def test_pytest_make_parametrize_id_with_argname(self, pytester: Pytester) -> None:\n        pytester.makeconftest(\n            \"\"\"\n            def pytest_make_parametrize_id(config, val, argname):\n                return str(val * 2 if argname == 'x' else val * 10)\n        \"\"\"\n        )\n        pytester.makepyfile(\n            \"\"\"\n                import pytest\n\n                @pytest.mark.parametrize(\"x\", range(2))\n                def test_func_a(x):\n                    pass\n\n                @pytest.mark.parametrize(\"y\", [1])\n                def test_func_b(y):\n                    pass\n                \"\"\"\n        )\n        result = pytester.runpytest(\"-v\")\n        result.stdout.fnmatch_lines(\n            [\"*test_func_a*0*PASS*\", \"*test_func_a*2*PASS*\", \"*test_func_b*10*PASS*\"]\n        )\n\n    def test_parametrize_positional_args(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n\n            @pytest.mark.parametrize(\"a\", [1], False)\n            def test_foo(a):\n                pass\n        \"\"\"\n        )\n        result = pytester.runpytest()\n        result.assert_outcomes(passed=1)\n\n    def test_parametrize_iterator(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            import itertools\n            import pytest\n\n            id_par"}, {"start_line": 69000, "end_line": 71000, "belongs_to": {"file_name": "metafunc.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing/python", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "       import pytest\n\n                @pytest.mark.parametrize(\"x\", range(2))\n                def test_func_a(x):\n                    pass\n\n                @pytest.mark.parametrize(\"y\", [1])\n                def test_func_b(y):\n                    pass\n                \"\"\"\n        )\n        result = pytester.runpytest(\"-v\")\n        result.stdout.fnmatch_lines(\n            [\"*test_func_a*0*PASS*\", \"*test_func_a*2*PASS*\", \"*test_func_b*10*PASS*\"]\n        )\n\n    def test_parametrize_positional_args(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n\n            @pytest.mark.parametrize(\"a\", [1], False)\n            def test_foo(a):\n                pass\n        \"\"\"\n        )\n        result = pytester.runpytest()\n        result.assert_outcomes(passed=1)\n\n    def test_parametrize_iterator(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            import itertools\n            import pytest\n\n            id_parametrize = pytest.mark.parametrize(\n                ids=(\"param%d\" % i for i in itertools.count())\n            )\n\n            @id_parametrize('y', ['a', 'b'])\n            def test1(y):\n                pass\n\n            @id_parametrize('y', ['a', 'b'])\n            def test2(y):\n                pass\n\n            @pytest.mark.parametrize(\"a, b\", [(1, 2), (3, 4)], ids=itertools.count())\n            def test_converted_to_str(a, b):\n                pass\n        \"\"\"\n        )\n        result = pytester.runpytest(\"-vv\", \"-s\")\n        result.stdout.fnmatch_lines(\n            [\n                \"test_parametrize_iterator.py::test1[param0] PASSED\",\n                \"test_parametrize_iterator.py::test1[param1] PASSED\",\n                \"test_parametrize_iterator.py::test2[param0] PASSED\",\n                \"test_parametrize_iterator.py::test2[param1] PASSED\",\n                \"test_parametrize_iterator.py::test_converted_to_str[0] PASSED\",\n                \"test_parametrize_iterator.py::test_converted_to_"}, {"start_line": 33000, "end_line": 35000, "belongs_to": {"file_name": "metafunc.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing/python", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "simple*2-2*\", \"*2 passed*\"]\n        )\n\n    def test_parametrize_onearg(self) -> None:\n        metafunc = self.Metafunc(lambda x: None)\n        metafunc.parametrize(\"x\", [1, 2])\n        assert len(metafunc._calls) == 2\n        assert metafunc._calls[0].params == dict(x=1)\n        assert metafunc._calls[0].id == \"1\"\n        assert metafunc._calls[1].params == dict(x=2)\n        assert metafunc._calls[1].id == \"2\"\n\n    def test_parametrize_onearg_indirect(self) -> None:\n        metafunc = self.Metafunc(lambda x: None)\n        metafunc.parametrize(\"x\", [1, 2], indirect=True)\n        assert metafunc._calls[0].params == dict(x=1)\n        assert metafunc._calls[0].id == \"1\"\n        assert metafunc._calls[1].params == dict(x=2)\n        assert metafunc._calls[1].id == \"2\"\n\n    def test_parametrize_twoargs(self) -> None:\n        metafunc = self.Metafunc(lambda x, y: None)\n        metafunc.parametrize((\"x\", \"y\"), [(1, 2), (3, 4)])\n        assert len(metafunc._calls) == 2\n        assert metafunc._calls[0].params == dict(x=1, y=2)\n        assert metafunc._calls[0].id == \"1-2\"\n        assert metafunc._calls[1].params == dict(x=3, y=4)\n        assert metafunc._calls[1].id == \"3-4\"\n\n    def test_high_scoped_parametrize_reordering(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n\n            @pytest.mark.parametrize(\"arg2\", [3, 4])\n            @pytest.mark.parametrize(\"arg1\", [0, 1, 2], scope='module')\n            def test1(arg1, arg2):\n                pass\n\n            def test2():\n                pass\n\n            @pytest.mark.parametrize(\"arg1\", [0, 1, 2], scope='module')\n            def test3(arg1):\n                pass\n        \"\"\"\n        )\n        result = pytester.runpytest(\"--collect-only\")\n        result.stdout.re_match_lines(\n            [\n                r\"    <Function test1\\[0-3\\]>\",\n                r\"    <Function test3\\[0\\]>\",\n                r\"    <Function test1\\[0-4\\]>\",\n                r\"    <Function test3\\["}, {"start_line": 43000, "end_line": 45000, "belongs_to": {"file_name": "metafunc.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing/python", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": ":\n        p = pytester.makepyfile(\n            \"\"\"\n            def pytest_generate_tests(metafunc):\n                assert \"arg1\" in metafunc.fixturenames\n                metafunc.parametrize(\"arg1\", [1], indirect=True)\n\n            import pytest\n            @pytest.fixture\n            def arg1(request):\n                return request.param\n\n            @pytest.fixture\n            def arg2(request, arg1):\n                return 10 * arg1\n\n            def test_func(arg2):\n                assert arg2 == 10\n        \"\"\"\n        )\n        result = pytester.runpytest(\"-v\", p)\n        result.stdout.fnmatch_lines([\"*test_func*1*PASS*\", \"*1 passed*\"])\n\n    def test_parametrize_with_ids(self, pytester: Pytester) -> None:\n        pytester.makeini(\n            \"\"\"\n            [pytest]\n            console_output_style=classic\n        \"\"\"\n        )\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n            def pytest_generate_tests(metafunc):\n                metafunc.parametrize((\"a\", \"b\"), [(1,1), (1,2)],\n                                     ids=[\"basic\", \"advanced\"])\n\n            def test_function(a, b):\n                assert a == b\n        \"\"\"\n        )\n        result = pytester.runpytest(\"-v\")\n        assert result.ret == 1\n        result.stdout.fnmatch_lines_random(\n            [\"*test_function*basic*PASSED\", \"*test_function*advanced*FAILED\"]\n        )\n\n    def test_parametrize_without_ids(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n            def pytest_generate_tests(metafunc):\n                metafunc.parametrize((\"a\", \"b\"),\n                                     [(1,object()), (1.3,object())])\n\n            def test_function(a, b):\n                assert 1\n        \"\"\"\n        )\n        result = pytester.runpytest(\"-v\")\n        result.stdout.fnmatch_lines(\n            \"\"\"\n            *test_function*1-b0*\n            *test_function*1.3-b1*\n        \"\"\"\n        )\n\n    def test_parametrize_wi"}, {"start_line": 47000, "end_line": 49000, "belongs_to": {"file_name": "metafunc.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing/python", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "], ids=(None, 2, OSError()))\n            def test_ids_numbers(x,expected):\n                assert x * 2 == expected\n        \"\"\"\n        )\n        result = pytester.runpytest()\n        result.stdout.fnmatch_lines(\n            [\n                \"In test_ids_numbers: ids contains unsupported value OSError() (type: <class 'OSError'>) at index 2. \"\n                \"Supported types are: str, bytes, int, float, complex, bool, enum, regex or anything with a __name__.\"\n            ]\n        )\n\n    def test_parametrize_with_identical_ids_get_unique_names(\n        self, pytester: Pytester\n    ) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n            def pytest_generate_tests(metafunc):\n                metafunc.parametrize((\"a\", \"b\"), [(1,1), (1,2)],\n                                     ids=[\"a\", \"a\"])\n\n            def test_function(a, b):\n                assert a == b\n        \"\"\"\n        )\n        result = pytester.runpytest(\"-v\")\n        assert result.ret == 1\n        result.stdout.fnmatch_lines_random(\n            [\"*test_function*a0*PASSED*\", \"*test_function*a1*FAILED*\"]\n        )\n\n    @pytest.mark.parametrize((\"scope\", \"length\"), [(\"module\", 2), (\"function\", 4)])\n    def test_parametrize_scope_overrides(\n        self, pytester: Pytester, scope: str, length: int\n    ) -> None:\n        pytester.makepyfile(\n            f\"\"\"\n            import pytest\n            values = []\n            def pytest_generate_tests(metafunc):\n                if \"arg\" in metafunc.fixturenames:\n                    metafunc.parametrize(\"arg\", [1,2], indirect=True,\n                                         scope={scope!r})\n            @pytest.fixture\n            def arg(request):\n                values.append(request.param)\n                return request.param\n            def test_hello(arg):\n                assert arg in (1,2)\n            def test_world(arg):\n                assert arg in (1,2)\n            def test_checklength():\n                assert len(values) ="}, {"start_line": 35000, "end_line": 37000, "belongs_to": {"file_name": "metafunc.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing/python", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "1\\]>\",\n                r\"    <Function test1\\[1-3\\]>\",\n                r\"    <Function test3\\[2\\]>\",\n                r\"    <Function test1\\[1-4\\]>\",\n                r\"    <Function test1\\[2-3\\]>\",\n                r\"    <Function test1\\[2-4\\]>\",\n                r\"    <Function test2>\",\n            ]\n        )\n\n    def test_parametrize_multiple_times(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n            pytestmark = pytest.mark.parametrize(\"x\", [1,2])\n            def test_func(x):\n                assert 0, x\n            class TestClass(object):\n                pytestmark = pytest.mark.parametrize(\"y\", [3,4])\n                def test_meth(self, x, y):\n                    assert 0, x\n        \"\"\"\n        )\n        result = pytester.runpytest()\n        assert result.ret == 1\n        result.assert_outcomes(failed=6)\n\n    def test_parametrize_CSV(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n            @pytest.mark.parametrize(\"x, y,\", [(1,2), (2,3)])\n            def test_func(x, y):\n                assert x+1 == y\n        \"\"\"\n        )\n        reprec = pytester.inline_run()\n        reprec.assertoutcome(passed=2)\n\n    def test_parametrize_class_scenarios(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            \"\"\"\n        # same as doc/en/example/parametrize scenario example\n        def pytest_generate_tests(metafunc):\n            idlist = []\n            argvalues = []\n            for scenario in metafunc.cls.scenarios:\n                idlist.append(scenario[0])\n                items = scenario[1].items()\n                argnames = [x[0] for x in items]\n                argvalues.append(([x[1] for x in items]))\n            metafunc.parametrize(argnames, argvalues, ids=idlist, scope=\"class\")\n\n        class Test(object):\n               scenarios = [['1', {'arg': {1: 2}, \"arg2\": \"value2\"}],\n                            ['2', {'arg':'valu"}], "retrieved_count": 10, "cost_time": 0.32796621322631836}
{"question": "How does Pytest facilitate testing RESTful APIs with the requests library?", "answer": null, "relative_code_list": null, "ground_truth": "Pytest facilitates testing RESTful APIs with the requests library through several built-in mechanisms: 1) The monkeypatch fixture that allows mocking of requests.get, requests.post, and other HTTP methods to return controlled test responses, 2) MockResponse class pattern for creating custom response objects that simulate requests.Response behavior with methods like json() and properties like status_code, 3) Automatic cleanup of monkeypatched requests methods after each test to prevent test pollution, 4) Fixture-based mocking where requests methods can be mocked globally using autouse fixtures in conftest.py, 5) Context-based patching using monkeypatch.context() for scoped mocking of requests functionality, 6) Integration with pytest's assertion system for validating API response data, status codes, and headers, 7) Support for testing different HTTP methods (GET, POST, PUT, DELETE) through targeted mocking, 8) Error handling testing by mocking requests to raise exceptions like ConnectionError or HTTPError, 9) Parameterized testing support for testing multiple API endpoints with different request parameters, 10) Integration with pytest's test discovery and execution for organizing API tests, 11) Support for testing authentication and headers through mock response configuration, 12) Global request prevention using monkeypatch.delattr() to block all HTTP requests during testing.", "score": null, "retrieved_content": [{"start_line": 34000, "end_line": 36000, "belongs_to": {"file_name": "fixtures.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing/python", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "d*conftest*\n            *arg1*\n        \"\"\"\n        )\n\n    def test_show_fixtures_color_yes(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\"def test_this(): assert 1\")\n        result = pytester.runpytest(\"--color=yes\", \"--fixtures\")\n        assert \"\\x1b[32mtmp_path\" in result.stdout.str()\n\n    def test_newstyle_with_request(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n            @pytest.fixture()\n            def arg(request):\n                pass\n            def test_1(arg):\n                pass\n        \"\"\"\n        )\n        reprec = pytester.inline_run()\n        reprec.assertoutcome(passed=1)\n\n    def test_setupcontext_no_param(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n            @pytest.fixture(params=[1,2])\n            def arg(request):\n                return request.param\n\n            @pytest.fixture(autouse=True)\n            def mysetup(request, arg):\n                assert not hasattr(request, \"param\")\n            def test_1(arg):\n                assert arg in (1,2)\n        \"\"\"\n        )\n        reprec = pytester.inline_run()\n        reprec.assertoutcome(passed=2)\n\n\nclass TestRequestSessionScoped:\n    @pytest.fixture(scope=\"session\")\n    def session_request(self, request):\n        return request\n\n    @pytest.mark.parametrize(\"name\", [\"path\", \"module\"])\n    def test_session_scoped_unavailable_attributes(self, session_request, name):\n        with pytest.raises(\n            AttributeError,\n            match=f\"{name} not available in session-scoped context\",\n        ):\n            getattr(session_request, name)\n\n\nclass TestRequestMarking:\n    def test_applymarker(self, pytester: Pytester) -> None:\n        item1, item2 = pytester.getitems(\n            \"\"\"\n            import pytest\n\n            @pytest.fixture\n            def something(request):\n                pass\n            class TestClass(object):\n                def test"}, {"start_line": 20000, "end_line": 22000, "belongs_to": {"file_name": "fixtures.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing/python", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "      assert result.ret == 0\n\n\nclass TestRequestBasic:\n    def test_request_attributes(self, pytester: Pytester) -> None:\n        item = pytester.getitem(\n            \"\"\"\n            import pytest\n\n            @pytest.fixture\n            def something(request): pass\n            def test_func(something): pass\n        \"\"\"\n        )\n        assert isinstance(item, Function)\n        req = TopRequest(item, _ispytest=True)\n        assert req.function == item.obj\n        assert req.keywords == item.keywords\n        assert hasattr(req.module, \"test_func\")\n        assert req.cls is None\n        assert req.function.__name__ == \"test_func\"\n        assert req.config == item.config\n        assert repr(req).find(req.function.__name__) != -1\n\n    def test_request_attributes_method(self, pytester: Pytester) -> None:\n        (item,) = pytester.getitems(\n            \"\"\"\n            import pytest\n            class TestB(object):\n\n                @pytest.fixture\n                def something(self, request):\n                    return 1\n                def test_func(self, something):\n                    pass\n        \"\"\"\n        )\n        assert isinstance(item, Function)\n        req = item._request\n        assert req.cls.__name__ == \"TestB\"\n        assert req.instance.__class__ == req.cls\n\n    def test_request_contains_funcarg_arg2fixturedefs(self, pytester: Pytester) -> None:\n        modcol = pytester.getmodulecol(\n            \"\"\"\n            import pytest\n            @pytest.fixture\n            def something(request):\n                pass\n            class TestClass(object):\n                def test_method(self, something):\n                    pass\n        \"\"\"\n        )\n        (item1,) = pytester.genitems([modcol])\n        assert isinstance(item1, Function)\n        assert item1.name == \"test_method\"\n        arg2fixturedefs = TopRequest(item1, _ispytest=True)._arg2fixturedefs\n        assert len(arg2fixturedefs) == 1\n        assert arg2fixturedefs[\"something\"][0].argname == \"something\""}, {"start_line": 19000, "end_line": 21000, "belongs_to": {"file_name": "fixtures.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing/python", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "*b_fixture,*c_fixture,*d_fixture*monkeypatch,*\",\n                # sorted\n                \">       use 'py*test --fixtures *' for help on them.\",\n                \"*1 error*\",\n            ]\n        )\n        result.stdout.no_fnmatch_line(\"*INTERNAL*\")\n\n    def test_fixture_excinfo_leak(self, pytester: Pytester) -> None:\n        # on python2 sys.excinfo would leak into fixture executions\n        pytester.makepyfile(\n            \"\"\"\n            import sys\n            import traceback\n            import pytest\n\n            @pytest.fixture\n            def leak():\n                if sys.exc_info()[0]:  # python3 bug :)\n                    traceback.print_exc()\n                #fails\n                assert sys.exc_info() == (None, None, None)\n\n            def test_leak(leak):\n                if sys.exc_info()[0]:  # python3 bug :)\n                    traceback.print_exc()\n                assert sys.exc_info() == (None, None, None)\n        \"\"\"\n        )\n        result = pytester.runpytest()\n        assert result.ret == 0\n\n\nclass TestRequestBasic:\n    def test_request_attributes(self, pytester: Pytester) -> None:\n        item = pytester.getitem(\n            \"\"\"\n            import pytest\n\n            @pytest.fixture\n            def something(request): pass\n            def test_func(something): pass\n        \"\"\"\n        )\n        assert isinstance(item, Function)\n        req = TopRequest(item, _ispytest=True)\n        assert req.function == item.obj\n        assert req.keywords == item.keywords\n        assert hasattr(req.module, \"test_func\")\n        assert req.cls is None\n        assert req.function.__name__ == \"test_func\"\n        assert req.config == item.config\n        assert repr(req).find(req.function.__name__) != -1\n\n    def test_request_attributes_method(self, pytester: Pytester) -> None:\n        (item,) = pytester.getitems(\n            \"\"\"\n            import pytest\n            class TestB(object):\n\n                @pytest.fixture\n                def something(self, request"}, {"start_line": 25000, "end_line": 27000, "belongs_to": {"file_name": "fixtures.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing/python", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "     result = pytester.runpytest()\n        result.stdout.fnmatch_lines([\"* 2 passed in *\"])\n\n    def test_getfixturevalue(self, pytester: Pytester) -> None:\n        item = pytester.getitem(\n            \"\"\"\n            import pytest\n\n            @pytest.fixture\n            def something(request):\n                return 1\n\n            values = [2]\n            @pytest.fixture\n            def other(request):\n                return values.pop()\n\n            def test_func(something): pass\n        \"\"\"\n        )\n        assert isinstance(item, Function)\n        req = item._request\n\n        # Execute item's setup.\n        item.session._setupstate.setup(item)\n\n        with pytest.raises(pytest.FixtureLookupError):\n            req.getfixturevalue(\"notexists\")\n        val = req.getfixturevalue(\"something\")\n        assert val == 1\n        val = req.getfixturevalue(\"something\")\n        assert val == 1\n        val2 = req.getfixturevalue(\"other\")\n        assert val2 == 2\n        val2 = req.getfixturevalue(\"other\")  # see about caching\n        assert val2 == 2\n        assert item.funcargs[\"something\"] == 1\n        assert len(get_public_names(item.funcargs)) == 2\n        assert \"request\" in item.funcargs\n\n    def test_request_addfinalizer(self, pytester: Pytester) -> None:\n        item = pytester.getitem(\n            \"\"\"\n            import pytest\n            teardownlist = []\n            @pytest.fixture\n            def something(request):\n                request.addfinalizer(lambda: teardownlist.append(1))\n            def test_func(something): pass\n        \"\"\"\n        )\n        assert isinstance(item, Function)\n        item.session._setupstate.setup(item)\n        item._request._fillfixtures()\n        # successively check finalization calls\n        parent = item.getparent(pytest.Module)\n        assert parent is not None\n        teardownlist = parent.obj.teardownlist\n        ss = item.session._setupstate\n        assert not teardownlist\n        ss.teardown_exact(None)\n        print(ss.s"}, {"start_line": 123000, "end_line": 125000, "belongs_to": {"file_name": "fixtures.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing/python", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "sult = pytester.runpytest(\"-s\")\n        result.stdout.fnmatch_lines([\"*mew*\"])\n\n\nclass TestParameterizedSubRequest:\n    def test_call_from_fixture(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            test_call_from_fixture=\"\"\"\n            import pytest\n\n            @pytest.fixture(params=[0, 1, 2])\n            def fix_with_param(request):\n                return request.param\n\n            @pytest.fixture\n            def get_named_fixture(request):\n                return request.getfixturevalue('fix_with_param')\n\n            def test_foo(request, get_named_fixture):\n                pass\n            \"\"\"\n        )\n        result = pytester.runpytest()\n        result.stdout.fnmatch_lines(\n            [\n                \"The requested fixture has no parameter defined for test:\",\n                \"    test_call_from_fixture.py::test_foo\",\n                \"Requested fixture 'fix_with_param' defined in:\",\n                \"test_call_from_fixture.py:4\",\n                \"Requested here:\",\n                \"test_call_from_fixture.py:9\",\n                \"*1 error in*\",\n            ]\n        )\n\n    def test_call_from_test(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            test_call_from_test=\"\"\"\n            import pytest\n\n            @pytest.fixture(params=[0, 1, 2])\n            def fix_with_param(request):\n                return request.param\n\n            def test_foo(request):\n                request.getfixturevalue('fix_with_param')\n            \"\"\"\n        )\n        result = pytester.runpytest()\n        result.stdout.fnmatch_lines(\n            [\n                \"The requested fixture has no parameter defined for test:\",\n                \"    test_call_from_test.py::test_foo\",\n                \"Requested fixture 'fix_with_param' defined in:\",\n                \"test_call_from_test.py:4\",\n                \"Requested here:\",\n                \"test_call_from_test.py:8\",\n                \"*1 failed*\",\n            ]\n        )\n\n    def test_extern"}, {"start_line": 65000, "end_line": 67000, "belongs_to": {"file_name": "fixtures.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing/python", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "use_conftest_mid_directory(self, pytester: Pytester) -> None:\n        pkgdir = pytester.mkpydir(\"xyz123\")\n        pkgdir.joinpath(\"conftest.py\").write_text(\n            textwrap.dedent(\n                \"\"\"\\\n                import pytest\n                @pytest.fixture(autouse=True)\n                def app():\n                    import sys\n                    sys._myapp = \"hello\"\n                \"\"\"\n            ),\n            encoding=\"utf-8\",\n        )\n        sub = pkgdir.joinpath(\"tests\")\n        sub.mkdir()\n        t = sub.joinpath(\"test_app.py\")\n        t.touch()\n        t.write_text(\n            textwrap.dedent(\n                \"\"\"\\\n                import sys\n                def test_app():\n                    assert sys._myapp == \"hello\"\n                \"\"\"\n            ),\n            encoding=\"utf-8\",\n        )\n        reprec = pytester.inline_run(\"-s\")\n        reprec.assertoutcome(passed=1)\n\n    def test_funcarg_and_setup(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n            values = []\n            @pytest.fixture(scope=\"module\")\n            def arg():\n                values.append(1)\n                return 0\n            @pytest.fixture(scope=\"module\", autouse=True)\n            def something(arg):\n                values.append(2)\n\n            def test_hello(arg):\n                assert len(values) == 2\n                assert values == [1,2]\n                assert arg == 0\n\n            def test_hello2(arg):\n                assert len(values) == 2\n                assert values == [1,2]\n                assert arg == 0\n        \"\"\"\n        )\n        reprec = pytester.inline_run()\n        reprec.assertoutcome(passed=2)\n\n    def test_uses_parametrized_resource(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n            values = []\n            @pytest.fixture(params=[1,2])\n            def arg(request):\n                return request.param\n\n       "}, {"start_line": 96000, "end_line": 98000, "belongs_to": {"file_name": "fixtures.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing/python", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "ter) -> None:\n        pytester.makeconftest(\n            \"\"\"\n            import pytest\n            import sys\n\n            @pytest.fixture\n            def browser(request):\n\n                def finalize():\n                    sys.stdout.write_text('Finalized', encoding='utf-8')\n                request.addfinalizer(finalize)\n                return {}\n        \"\"\"\n        )\n        b = pytester.mkdir(\"subdir\")\n        b.joinpath(\"test_overridden_fixture_finalizer.py\").write_text(\n            textwrap.dedent(\n                \"\"\"\\\n                import pytest\n                @pytest.fixture\n                def browser(browser):\n                    browser['visited'] = True\n                    return browser\n\n                def test_browser(browser):\n                    assert browser['visited'] is True\n                \"\"\"\n            ),\n            encoding=\"utf-8\",\n        )\n        reprec = pytester.runpytest(\"-s\")\n        for test in [\"test_browser\"]:\n            reprec.stdout.fnmatch_lines([\"*Finalized*\"])\n\n    def test_class_scope_with_normal_tests(self, pytester: Pytester) -> None:\n        testpath = pytester.makepyfile(\n            \"\"\"\n            import pytest\n\n            class Box(object):\n                value = 0\n\n            @pytest.fixture(scope='class')\n            def a(request):\n                Box.value += 1\n                return Box.value\n\n            def test_a(a):\n                assert a == 1\n\n            class Test1(object):\n                def test_b(self, a):\n                    assert a == 2\n\n            class Test2(object):\n                def test_c(self, a):\n                    assert a == 3\"\"\"\n        )\n        reprec = pytester.inline_run(testpath)\n        for test in [\"test_a\", \"test_b\", \"test_c\"]:\n            assert reprec.matchreport(test).passed\n\n    def test_request_is_clean(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n            values = []\n            @pytest.fixture(pa"}, {"start_line": 33000, "end_line": 35000, "belongs_to": {"file_name": "fixtures.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing/python", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "rt values == [\"module\", \"function\", \"class\",\n                             \"function\", \"method\", \"function\"]\n        \"\"\"\n        )\n        reprec = pytester.inline_run(\"-v\")\n        reprec.assertoutcome(passed=3)\n\n    def test_fixtures_sub_subdir_normalize_sep(self, pytester: Pytester) -> None:\n        # this tests that normalization of nodeids takes place\n        b = pytester.path.joinpath(\"tests\", \"unit\")\n        b.mkdir(parents=True)\n        b.joinpath(\"conftest.py\").write_text(\n            textwrap.dedent(\n                \"\"\"\\\n                import pytest\n                @pytest.fixture\n                def arg1():\n                    pass\n                \"\"\"\n            ),\n            encoding=\"utf-8\",\n        )\n        p = b.joinpath(\"test_module.py\")\n        p.write_text(\"def test_func(arg1): pass\", encoding=\"utf-8\")\n        result = pytester.runpytest(p, \"--fixtures\")\n        assert result.ret == 0\n        result.stdout.fnmatch_lines(\n            \"\"\"\n            *fixtures defined*conftest*\n            *arg1*\n        \"\"\"\n        )\n\n    def test_show_fixtures_color_yes(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\"def test_this(): assert 1\")\n        result = pytester.runpytest(\"--color=yes\", \"--fixtures\")\n        assert \"\\x1b[32mtmp_path\" in result.stdout.str()\n\n    def test_newstyle_with_request(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n            @pytest.fixture()\n            def arg(request):\n                pass\n            def test_1(arg):\n                pass\n        \"\"\"\n        )\n        reprec = pytester.inline_run()\n        reprec.assertoutcome(passed=1)\n\n    def test_setupcontext_no_param(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n            @pytest.fixture(params=[1,2])\n            def arg(request):\n                return request.param\n\n            @pytest.fixture(autouse=True)\n            def mysetup(requ"}, {"start_line": 31000, "end_line": 33000, "belongs_to": {"file_name": "fixtures.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing/python", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "sert req.path == modcol.path\n\n    def test_request_fixturenames(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n            from _pytest.pytester import get_public_names\n            @pytest.fixture()\n            def arg1():\n                pass\n            @pytest.fixture()\n            def farg(arg1):\n                pass\n            @pytest.fixture(autouse=True)\n            def sarg(tmp_path):\n                pass\n            def test_function(request, farg):\n                assert set(get_public_names(request.fixturenames)) == \\\n                       set([\"sarg\", \"arg1\", \"request\", \"farg\",\n                            \"tmp_path\", \"tmp_path_factory\"])\n        \"\"\"\n        )\n        reprec = pytester.inline_run()\n        reprec.assertoutcome(passed=1)\n\n    def test_request_fixturenames_dynamic_fixture(self, pytester: Pytester) -> None:\n        \"\"\"Regression test for #3057\"\"\"\n        pytester.copy_example(\"fixtures/test_getfixturevalue_dynamic.py\")\n        result = pytester.runpytest()\n        result.stdout.fnmatch_lines([\"*1 passed*\"])\n\n    def test_setupdecorator_and_xunit(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n            values = []\n            @pytest.fixture(scope='module', autouse=True)\n            def setup_module():\n                values.append(\"module\")\n            @pytest.fixture(autouse=True)\n            def setup_function():\n                values.append(\"function\")\n\n            def test_func():\n                pass\n\n            class TestClass(object):\n                @pytest.fixture(scope=\"class\", autouse=True)\n                def setup_class(self):\n                    values.append(\"class\")\n                @pytest.fixture(autouse=True)\n                def setup_method(self):\n                    values.append(\"method\")\n                def test_method(self):\n                    pass\n            def test_all():\n                asse"}, {"start_line": 17000, "end_line": 19000, "belongs_to": {"file_name": "fixtures.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing/python", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "ram\n            \"\"\"\n        )\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n\n            @pytest.fixture(params=[10, 20])\n            def foo(foo, request):\n                assert request.param == foo\n                return foo * 2\n\n            def test_spam(foo):\n                assert foo in (20, 40)\n            \"\"\"\n        )\n        result = pytester.runpytest()\n        result.stdout.fnmatch_lines([\"*2 passed*\"])\n\n    def test_autouse_fixture_plugin(self, pytester: Pytester) -> None:\n        # A fixture from a plugin has no baseid set, which screwed up\n        # the autouse fixture handling.\n        pytester.makepyfile(\n            testplugin=\"\"\"\n            import pytest\n\n            @pytest.fixture(autouse=True)\n            def foo(request):\n                request.function.foo = 7\n        \"\"\"\n        )\n        pytester.syspathinsert()\n        pytester.makepyfile(\n            \"\"\"\n            pytest_plugins = 'testplugin'\n\n            def test_foo(request):\n                assert request.function.foo == 7\n        \"\"\"\n        )\n        result = pytester.runpytest()\n        assert result.ret == 0\n\n    def test_funcarg_lookup_error(self, pytester: Pytester) -> None:\n        pytester.makeconftest(\n            \"\"\"\n            import pytest\n\n            @pytest.fixture\n            def a_fixture(): pass\n\n            @pytest.fixture\n            def b_fixture(): pass\n\n            @pytest.fixture\n            def c_fixture(): pass\n\n            @pytest.fixture\n            def d_fixture(): pass\n        \"\"\"\n        )\n        pytester.makepyfile(\n            \"\"\"\n            def test_lookup_error(unknown):\n                pass\n        \"\"\"\n        )\n        result = pytester.runpytest()\n        result.stdout.fnmatch_lines(\n            [\n                \"*ERROR at setup of test_lookup_error*\",\n                \"  def test_lookup_error(unknown):*\",\n                \"E       fixture 'unknown' not found\",\n                \">       available fixtures:*a_fixture,"}], "retrieved_count": 10, "cost_time": 0.43298840522766113}
