{"question": "What is the validation logic in the FixtureFunctionMarker.__call__ method that prevents double-decoration of fixture functions, and what is the semantic difference between detecting a FixtureFunctionDefinition instance versus checking for pytestmark attributes?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"start_line": 48000, "end_line": 50000, "belongs_to": {"file_name": "fixtures.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "> FixtureFunctionDefinition:\n        if inspect.isclass(function):\n            raise ValueError(\"class fixtures not supported (maybe in the future)\")\n\n        if isinstance(function, FixtureFunctionDefinition):\n            raise ValueError(\n                f\"@pytest.fixture is being applied more than once to the same function {function.__name__!r}\"\n            )\n\n        if hasattr(function, \"pytestmark\"):\n            warnings.warn(MARKED_FIXTURE, stacklevel=2)\n\n        fixture_definition = FixtureFunctionDefinition(\n            function=function, fixture_function_marker=self, _ispytest=True\n        )\n\n        name = self.name or function.__name__\n        if name == \"request\":\n            location = getlocation(function)\n            fail(\n                f\"'request' is a reserved word for fixtures, use another name:\\n  {location}\",\n                pytrace=False,\n            )\n\n        return fixture_definition\n\n\n# TODO: paramspec/return type annotation tracking and storing\nclass FixtureFunctionDefinition:\n    def __init__(\n        self,\n        *,\n        function: Callable[..., Any],\n        fixture_function_marker: FixtureFunctionMarker,\n        instance: object | None = None,\n        _ispytest: bool = False,\n    ) -> None:\n        check_ispytest(_ispytest)\n        self.name = fixture_function_marker.name or function.__name__\n        # In order to show the function that this fixture contains in messages.\n        # Set the __name__ to be same as the function __name__ or the given fixture name.\n        self.__name__ = self.name\n        self._fixture_function_marker = fixture_function_marker\n        if instance is not None:\n            self._fixture_function = cast(\n                Callable[..., Any], function.__get__(instance)\n            )\n        else:\n            self._fixture_function = function\n        functools.update_wrapper(self, function)\n\n    def __repr__(self) -> str:\n        return f\"<pytest_fixture({self._fixture_function})>\"\n\n    def __get__(self, inst"}, {"start_line": 49000, "end_line": 51000, "belongs_to": {"file_name": "fixtures.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "eFunctionDefinition:\n    def __init__(\n        self,\n        *,\n        function: Callable[..., Any],\n        fixture_function_marker: FixtureFunctionMarker,\n        instance: object | None = None,\n        _ispytest: bool = False,\n    ) -> None:\n        check_ispytest(_ispytest)\n        self.name = fixture_function_marker.name or function.__name__\n        # In order to show the function that this fixture contains in messages.\n        # Set the __name__ to be same as the function __name__ or the given fixture name.\n        self.__name__ = self.name\n        self._fixture_function_marker = fixture_function_marker\n        if instance is not None:\n            self._fixture_function = cast(\n                Callable[..., Any], function.__get__(instance)\n            )\n        else:\n            self._fixture_function = function\n        functools.update_wrapper(self, function)\n\n    def __repr__(self) -> str:\n        return f\"<pytest_fixture({self._fixture_function})>\"\n\n    def __get__(self, instance, owner=None):\n        \"\"\"Behave like a method if the function it was applied to was a method.\"\"\"\n        return FixtureFunctionDefinition(\n            function=self._fixture_function,\n            fixture_function_marker=self._fixture_function_marker,\n            instance=instance,\n            _ispytest=True,\n        )\n\n    def __call__(self, *args: Any, **kwds: Any) -> Any:\n        message = (\n            f'Fixture \"{self.name}\" called directly. Fixtures are not meant to be called directly,\\n'\n            \"but are created automatically when test functions request them as parameters.\\n\"\n            \"See https://docs.pytest.org/en/stable/explanation/fixtures.html for more information about fixtures, and\\n\"\n            \"https://docs.pytest.org/en/stable/deprecations.html#calling-fixtures-directly\"\n        )\n        fail(message, pytrace=False)\n\n    def _get_wrapped_function(self) -> Callable[..., Any]:\n        return self._fixture_function\n\n\n@overload\ndef fixture(\n    fixture_functio"}, {"start_line": 47000, "end_line": 49000, "belongs_to": {"file_name": "fixtures.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "(fixturefunc, request, kwargs)\n    except TEST_OUTCOME as e:\n        if isinstance(e, skip.Exception):\n            # The test requested a fixture which caused a skip.\n            # Don't show the fixture as the skip location, as then the user\n            # wouldn't know which test skipped.\n            e._use_item_location = True\n        fixturedef.cached_result = (None, my_cache_key, (e, e.__traceback__))\n        raise\n    fixturedef.cached_result = (result, my_cache_key, None)\n    return result\n\n\n@final\n@dataclasses.dataclass(frozen=True)\nclass FixtureFunctionMarker:\n    scope: _ScopeName | Callable[[str, Config], _ScopeName]\n    params: tuple[object, ...] | None\n    autouse: bool = False\n    ids: tuple[object | None, ...] | Callable[[Any], object | None] | None = None\n    name: str | None = None\n\n    _ispytest: dataclasses.InitVar[bool] = False\n\n    def __post_init__(self, _ispytest: bool) -> None:\n        check_ispytest(_ispytest)\n\n    def __call__(self, function: FixtureFunction) -> FixtureFunctionDefinition:\n        if inspect.isclass(function):\n            raise ValueError(\"class fixtures not supported (maybe in the future)\")\n\n        if isinstance(function, FixtureFunctionDefinition):\n            raise ValueError(\n                f\"@pytest.fixture is being applied more than once to the same function {function.__name__!r}\"\n            )\n\n        if hasattr(function, \"pytestmark\"):\n            warnings.warn(MARKED_FIXTURE, stacklevel=2)\n\n        fixture_definition = FixtureFunctionDefinition(\n            function=function, fixture_function_marker=self, _ispytest=True\n        )\n\n        name = self.name or function.__name__\n        if name == \"request\":\n            location = getlocation(function)\n            fail(\n                f\"'request' is a reserved word for fixtures, use another name:\\n  {location}\",\n                pytrace=False,\n            )\n\n        return fixture_definition\n\n\n# TODO: paramspec/return type annotation tracking and storing\nclass Fixtur"}, {"start_line": 141000, "end_line": 143000, "belongs_to": {"file_name": "fixtures.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing/python", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "ment fixtures receive the plugin instance\n        as self (see #2270).\n        \"\"\"\n        pytester.makeconftest(\n            \"\"\"\n            import pytest\n\n            def pytest_configure(config):\n                config.pluginmanager.register(MyPlugin())\n\n            class MyPlugin():\n                def __init__(self):\n                    self.arg = 1\n\n                @pytest.fixture(scope='function')\n                def myfix(self):\n                    assert isinstance(self, MyPlugin)\n                    return self.arg\n        \"\"\"\n        )\n\n        pytester.makepyfile(\n            \"\"\"\n            class TestClass(object):\n                def test_1(self, myfix):\n                    assert myfix == 1\n        \"\"\"\n        )\n        reprec = pytester.inline_run()\n        reprec.assertoutcome(passed=1)\n\n\ndef test_call_fixture_function_error():\n    \"\"\"Check if an error is raised if a fixture function is called directly (#4545)\"\"\"\n\n    @pytest.fixture\n    def fix():\n        raise NotImplementedError()\n\n    with pytest.raises(pytest.fail.Exception):\n        assert fix() == 1\n\n\ndef test_fixture_double_decorator(pytester: Pytester) -> None:\n    \"\"\"Check if an error is raised when using @pytest.fixture twice.\"\"\"\n    pytester.makepyfile(\n        \"\"\"\n        import pytest\n\n        @pytest.fixture\n        @pytest.fixture\n        def fixt():\n            pass\n        \"\"\"\n    )\n    result = pytester.runpytest()\n    result.assert_outcomes(errors=1)\n    result.stdout.fnmatch_lines(\n        [\n            \"E * ValueError: @pytest.fixture is being applied more than once to the same function 'fixt'\"\n        ]\n    )\n\n\ndef test_fixture_class(pytester: Pytester) -> None:\n    \"\"\"Check if an error is raised when using @pytest.fixture on a class.\"\"\"\n    pytester.makepyfile(\n        \"\"\"\n        import pytest\n\n        @pytest.fixture\n        class A:\n            pass\n        \"\"\"\n    )\n    result = pytester.runpytest()\n    result.assert_outcomes(errors=1)\n\n\ndef test_fixture_param_shadowing(p"}, {"start_line": 50000, "end_line": 52000, "belongs_to": {"file_name": "fixtures.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "ance, owner=None):\n        \"\"\"Behave like a method if the function it was applied to was a method.\"\"\"\n        return FixtureFunctionDefinition(\n            function=self._fixture_function,\n            fixture_function_marker=self._fixture_function_marker,\n            instance=instance,\n            _ispytest=True,\n        )\n\n    def __call__(self, *args: Any, **kwds: Any) -> Any:\n        message = (\n            f'Fixture \"{self.name}\" called directly. Fixtures are not meant to be called directly,\\n'\n            \"but are created automatically when test functions request them as parameters.\\n\"\n            \"See https://docs.pytest.org/en/stable/explanation/fixtures.html for more information about fixtures, and\\n\"\n            \"https://docs.pytest.org/en/stable/deprecations.html#calling-fixtures-directly\"\n        )\n        fail(message, pytrace=False)\n\n    def _get_wrapped_function(self) -> Callable[..., Any]:\n        return self._fixture_function\n\n\n@overload\ndef fixture(\n    fixture_function: Callable[..., object],\n    *,\n    scope: _ScopeName | Callable[[str, Config], _ScopeName] = ...,\n    params: Iterable[object] | None = ...,\n    autouse: bool = ...,\n    ids: Sequence[object | None] | Callable[[Any], object | None] | None = ...,\n    name: str | None = ...,\n) -> FixtureFunctionDefinition: ...\n\n\n@overload\ndef fixture(\n    fixture_function: None = ...,\n    *,\n    scope: _ScopeName | Callable[[str, Config], _ScopeName] = ...,\n    params: Iterable[object] | None = ...,\n    autouse: bool = ...,\n    ids: Sequence[object | None] | Callable[[Any], object | None] | None = ...,\n    name: str | None = None,\n) -> FixtureFunctionMarker: ...\n\n\ndef fixture(\n    fixture_function: FixtureFunction | None = None,\n    *,\n    scope: _ScopeName | Callable[[str, Config], _ScopeName] = \"function\",\n    params: Iterable[object] | None = None,\n    autouse: bool = False,\n    ids: Sequence[object | None] | Callable[[Any], object | None] | None = None,\n    name: str | None = None,\n) -> FixtureFunc"}, {"start_line": 52000, "end_line": 54000, "belongs_to": {"file_name": "fixtures.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "tionMarker | FixtureFunctionDefinition:\n    \"\"\"Decorator to mark a fixture factory function.\n\n    This decorator can be used, with or without parameters, to define a\n    fixture function.\n\n    The name of the fixture function can later be referenced to cause its\n    invocation ahead of running tests: test modules or classes can use the\n    ``pytest.mark.usefixtures(fixturename)`` marker.\n\n    Test functions can directly use fixture names as input arguments in which\n    case the fixture instance returned from the fixture function will be\n    injected.\n\n    Fixtures can provide their values to test functions using ``return`` or\n    ``yield`` statements. When using ``yield`` the code block after the\n    ``yield`` statement is executed as teardown code regardless of the test\n    outcome, and must yield exactly once.\n\n    :param scope:\n        The scope for which this fixture is shared; one of ``\"function\"``\n        (default), ``\"class\"``, ``\"module\"``, ``\"package\"`` or ``\"session\"``.\n\n        This parameter may also be a callable which receives ``(fixture_name, config)``\n        as parameters, and must return a ``str`` with one of the values mentioned above.\n\n        See :ref:`dynamic scope` in the docs for more information.\n\n    :param params:\n        An optional list of parameters which will cause multiple invocations\n        of the fixture function and all of the tests using it. The current\n        parameter is available in ``request.param``.\n\n    :param autouse:\n        If True, the fixture func is activated for all tests that can see it.\n        If False (the default), an explicit reference is needed to activate\n        the fixture.\n\n    :param ids:\n        Sequence of ids each corresponding to the params so that they are\n        part of the test id. If no ids are provided they will be generated\n        automatically from the params.\n\n    :param name:\n        The name of the fixture. This defaults to the name of the decorated\n        function. If a fixture is used "}, {"start_line": 53000, "end_line": 55000, "belongs_to": {"file_name": "fixtures.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "    This parameter may also be a callable which receives ``(fixture_name, config)``\n        as parameters, and must return a ``str`` with one of the values mentioned above.\n\n        See :ref:`dynamic scope` in the docs for more information.\n\n    :param params:\n        An optional list of parameters which will cause multiple invocations\n        of the fixture function and all of the tests using it. The current\n        parameter is available in ``request.param``.\n\n    :param autouse:\n        If True, the fixture func is activated for all tests that can see it.\n        If False (the default), an explicit reference is needed to activate\n        the fixture.\n\n    :param ids:\n        Sequence of ids each corresponding to the params so that they are\n        part of the test id. If no ids are provided they will be generated\n        automatically from the params.\n\n    :param name:\n        The name of the fixture. This defaults to the name of the decorated\n        function. If a fixture is used in the same module in which it is\n        defined, the function name of the fixture will be shadowed by the\n        function arg that requests the fixture; one way to resolve this is to\n        name the decorated function ``fixture_<fixturename>`` and then use\n        ``@pytest.fixture(name='<fixturename>')``.\n    \"\"\"\n    fixture_marker = FixtureFunctionMarker(\n        scope=scope,\n        params=tuple(params) if params is not None else None,\n        autouse=autouse,\n        ids=None if ids is None else ids if callable(ids) else tuple(ids),\n        name=name,\n        _ispytest=True,\n    )\n\n    # Direct decoration.\n    if fixture_function:\n        return fixture_marker(fixture_function)\n\n    return fixture_marker\n\n\ndef yield_fixture(\n    fixture_function=None,\n    *args,\n    scope=\"function\",\n    params=None,\n    autouse=False,\n    ids=None,\n    name=None,\n):\n    \"\"\"(Return a) decorator to mark a yield-fixture factory function.\n\n    .. deprecated:: 3.0\n        Use :py:func:`pytest.fixtu"}, {"start_line": 54000, "end_line": 56000, "belongs_to": {"file_name": "fixtures.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "in the same module in which it is\n        defined, the function name of the fixture will be shadowed by the\n        function arg that requests the fixture; one way to resolve this is to\n        name the decorated function ``fixture_<fixturename>`` and then use\n        ``@pytest.fixture(name='<fixturename>')``.\n    \"\"\"\n    fixture_marker = FixtureFunctionMarker(\n        scope=scope,\n        params=tuple(params) if params is not None else None,\n        autouse=autouse,\n        ids=None if ids is None else ids if callable(ids) else tuple(ids),\n        name=name,\n        _ispytest=True,\n    )\n\n    # Direct decoration.\n    if fixture_function:\n        return fixture_marker(fixture_function)\n\n    return fixture_marker\n\n\ndef yield_fixture(\n    fixture_function=None,\n    *args,\n    scope=\"function\",\n    params=None,\n    autouse=False,\n    ids=None,\n    name=None,\n):\n    \"\"\"(Return a) decorator to mark a yield-fixture factory function.\n\n    .. deprecated:: 3.0\n        Use :py:func:`pytest.fixture` directly instead.\n    \"\"\"\n    warnings.warn(YIELD_FIXTURE, stacklevel=2)\n    return fixture(\n        fixture_function,\n        *args,\n        scope=scope,\n        params=params,\n        autouse=autouse,\n        ids=ids,\n        name=name,\n    )\n\n\n@fixture(scope=\"session\")\ndef pytestconfig(request: FixtureRequest) -> Config:\n    \"\"\"Session-scoped fixture that returns the session's :class:`pytest.Config`\n    object.\n\n    Example::\n\n        def test_foo(pytestconfig):\n            if pytestconfig.get_verbosity() > 0:\n                ...\n\n    \"\"\"\n    return request.config\n\n\ndef pytest_addoption(parser: Parser) -> None:\n    parser.addini(\n        \"usefixtures\",\n        type=\"args\",\n        default=[],\n        help=\"List of default fixtures to be used with this project\",\n    )\n    group = parser.getgroup(\"general\")\n    group.addoption(\n        \"--fixtures\",\n        \"--funcargs\",\n        action=\"store_true\",\n        dest=\"showfixtures\",\n        default=False,\n        help=\"Show available f"}, {"start_line": 46000, "end_line": 48000, "belongs_to": {"file_name": "fixtures.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": " request.getfixturevalue(argname)\n\n    fixturefunc = resolve_fixture_function(fixturedef, request)\n    my_cache_key = fixturedef.cache_key(request)\n\n    if inspect.isasyncgenfunction(fixturefunc) or inspect.iscoroutinefunction(\n        fixturefunc\n    ):\n        auto_str = \" with autouse=True\" if fixturedef._autouse else \"\"\n\n        warnings.warn(\n            PytestRemovedIn9Warning(\n                f\"{request.node.name!r} requested an async fixture \"\n                f\"{request.fixturename!r}{auto_str}, with no plugin or hook that \"\n                \"handled it. This is usually an error, as pytest does not natively \"\n                \"support it. \"\n                \"This will turn into an error in pytest 9.\\n\"\n                \"See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture\"\n            ),\n            # no stacklevel will point at users code, so we just point here\n            stacklevel=1,\n        )\n\n    try:\n        result = call_fixture_func(fixturefunc, request, kwargs)\n    except TEST_OUTCOME as e:\n        if isinstance(e, skip.Exception):\n            # The test requested a fixture which caused a skip.\n            # Don't show the fixture as the skip location, as then the user\n            # wouldn't know which test skipped.\n            e._use_item_location = True\n        fixturedef.cached_result = (None, my_cache_key, (e, e.__traceback__))\n        raise\n    fixturedef.cached_result = (result, my_cache_key, None)\n    return result\n\n\n@final\n@dataclasses.dataclass(frozen=True)\nclass FixtureFunctionMarker:\n    scope: _ScopeName | Callable[[str, Config], _ScopeName]\n    params: tuple[object, ...] | None\n    autouse: bool = False\n    ids: tuple[object | None, ...] | Callable[[Any], object | None] | None = None\n    name: str | None = None\n\n    _ispytest: dataclasses.InitVar[bool] = False\n\n    def __post_init__(self, _ispytest: bool) -> None:\n        check_ispytest(_ispytest)\n\n    def __call__(self, function: FixtureFunction) -"}, {"start_line": 60000, "end_line": 62000, "belongs_to": {"file_name": "python.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": ", the object which will be called when the Function is invoked,\n        otherwise the callobj will be obtained from ``parent`` using ``originalname``.\n    :param keywords:\n        Keywords bound to the function object for \"-k\" matching.\n    :param session:\n        The pytest Session object.\n    :param fixtureinfo:\n        Fixture information already resolved at this fixture node..\n    :param originalname:\n        The attribute name to use for accessing the underlying function object.\n        Defaults to ``name``. Set this if name is different from the original name,\n        for example when it contains decorations like those added by parametrization\n        (``my_func[my_param]``).\n    \"\"\"\n\n    # Disable since functions handle it themselves.\n    _ALLOW_MARKERS = False\n\n    def __init__(\n        self,\n        name: str,\n        parent,\n        config: Config | None = None,\n        callspec: CallSpec2 | None = None,\n        callobj=NOTSET,\n        keywords: Mapping[str, Any] | None = None,\n        session: Session | None = None,\n        fixtureinfo: FuncFixtureInfo | None = None,\n        originalname: str | None = None,\n    ) -> None:\n        super().__init__(name, parent, config=config, session=session)\n\n        if callobj is not NOTSET:\n            self._obj = callobj\n            self._instance = getattr(callobj, \"__self__\", None)\n\n        #: Original function name, without any decorations (for example\n        #: parametrization adds a ``\"[...]\"`` suffix to function names), used to access\n        #: the underlying function object from ``parent`` (in case ``callobj`` is not given\n        #: explicitly).\n        #:\n        #: .. versionadded:: 3.0\n        self.originalname = originalname or name\n\n        # Note: when FunctionDefinition is introduced, we should change ``originalname``\n        # to a readonly property that returns FunctionDefinition.name.\n\n        self.own_markers.extend(get_unpacked_marks(self.obj))\n        if callspec:\n            self.callspec = call"}], "retrieved_count": 10, "cost_time": 1.0578980445861816}
{"question": "How does the `from_item_and_call` classmethod implement conditional logic to determine the appropriate outcome and longrepr representation based on exception type and execution phase?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"start_line": 11000, "end_line": 13000, "belongs_to": {"file_name": "reports.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "\n        # Remove \"collect\" from the Literal type -- only for collection calls.\n        assert when != \"collect\"\n        duration = call.duration\n        start = call.start\n        stop = call.stop\n        keywords = {x: 1 for x in item.keywords}\n        excinfo = call.excinfo\n        sections = []\n        if not call.excinfo:\n            outcome: Literal[\"passed\", \"failed\", \"skipped\"] = \"passed\"\n            longrepr: (\n                None\n                | ExceptionInfo[BaseException]\n                | tuple[str, int, str]\n                | str\n                | TerminalRepr\n            ) = None\n        else:\n            if not isinstance(excinfo, ExceptionInfo):\n                outcome = \"failed\"\n                longrepr = excinfo\n            elif isinstance(excinfo.value, skip.Exception):\n                outcome = \"skipped\"\n                r = excinfo._getreprcrash()\n                assert r is not None, (\n                    \"There should always be a traceback entry for skipping a test.\"\n                )\n                if excinfo.value._use_item_location:\n                    path, line = item.reportinfo()[:2]\n                    assert line is not None\n                    longrepr = os.fspath(path), line + 1, r.message\n                else:\n                    longrepr = (str(r.path), r.lineno, r.message)\n            else:\n                outcome = \"failed\"\n                if call.when == \"call\":\n                    longrepr = item.repr_failure(excinfo)\n                else:  # exception in setup or teardown\n                    longrepr = item._repr_failure_py(\n                        excinfo, style=item.config.getoption(\"tbstyle\", \"auto\")\n                    )\n        for rwhen, key, content in item._report_sections:\n            sections.append((f\"Captured {key} {rwhen}\", content))\n        return cls(\n            item.nodeid,\n            item.location,\n            keywords,\n            outcome,\n            longrepr,\n            when,\n            sections,\n  "}, {"start_line": 8000, "end_line": 10000, "belongs_to": {"file_name": "runner.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "pt,)\n    call = CallInfo.from_call(\n        lambda: runtest_hook(item=item, **kwds), when=when, reraise=reraise\n    )\n    report: TestReport = ihook.pytest_runtest_makereport(item=item, call=call)\n    if log:\n        ihook.pytest_runtest_logreport(report=report)\n    if check_interactive_exception(call, report):\n        ihook.pytest_exception_interact(node=item, call=call, report=report)\n    return report\n\n\ndef check_interactive_exception(call: CallInfo[object], report: BaseReport) -> bool:\n    \"\"\"Check whether the call raised an exception that should be reported as\n    interactive.\"\"\"\n    if call.excinfo is None:\n        # Didn't raise.\n        return False\n    if hasattr(report, \"wasxfail\"):\n        # Exception was expected.\n        return False\n    if isinstance(call.excinfo.value, (Skipped, bdb.BdbQuit)):\n        # Special control flow exception.\n        return False\n    return True\n\n\nTResult = TypeVar(\"TResult\", covariant=True)\n\n\n@final\n@dataclasses.dataclass\nclass CallInfo(Generic[TResult]):\n    \"\"\"Result/Exception info of a function invocation.\"\"\"\n\n    _result: TResult | None\n    #: The captured exception of the call, if it raised.\n    excinfo: ExceptionInfo[BaseException] | None\n    #: The system time when the call started, in seconds since the epoch.\n    start: float\n    #: The system time when the call ended, in seconds since the epoch.\n    stop: float\n    #: The call duration, in seconds.\n    duration: float\n    #: The context of invocation: \"collect\", \"setup\", \"call\" or \"teardown\".\n    when: Literal[\"collect\", \"setup\", \"call\", \"teardown\"]\n\n    def __init__(\n        self,\n        result: TResult | None,\n        excinfo: ExceptionInfo[BaseException] | None,\n        start: float,\n        stop: float,\n        duration: float,\n        when: Literal[\"collect\", \"setup\", \"call\", \"teardown\"],\n        *,\n        _ispytest: bool = False,\n    ) -> None:\n        check_ispytest(_ispytest)\n        self._result = result\n        self.excinfo = excinfo\n        self.start ="}, {"start_line": 7000, "end_line": 9000, "belongs_to": {"file_name": "runner.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "ort_teststatus(report: BaseReport) -> tuple[str, str, str] | None:\n    if report.when in (\"setup\", \"teardown\"):\n        if report.failed:\n            #      category, shortletter, verbose-word\n            return \"error\", \"E\", \"ERROR\"\n        elif report.skipped:\n            return \"skipped\", \"s\", \"SKIPPED\"\n        else:\n            return \"\", \"\", \"\"\n    return None\n\n\n#\n# Implementation\n\n\ndef call_and_report(\n    item: Item, when: Literal[\"setup\", \"call\", \"teardown\"], log: bool = True, **kwds\n) -> TestReport:\n    ihook = item.ihook\n    if when == \"setup\":\n        runtest_hook: Callable[..., None] = ihook.pytest_runtest_setup\n    elif when == \"call\":\n        runtest_hook = ihook.pytest_runtest_call\n    elif when == \"teardown\":\n        runtest_hook = ihook.pytest_runtest_teardown\n    else:\n        assert False, f\"Unhandled runtest hook case: {when}\"\n    reraise: tuple[type[BaseException], ...] = (Exit,)\n    if not item.config.getoption(\"usepdb\", False):\n        reraise += (KeyboardInterrupt,)\n    call = CallInfo.from_call(\n        lambda: runtest_hook(item=item, **kwds), when=when, reraise=reraise\n    )\n    report: TestReport = ihook.pytest_runtest_makereport(item=item, call=call)\n    if log:\n        ihook.pytest_runtest_logreport(report=report)\n    if check_interactive_exception(call, report):\n        ihook.pytest_exception_interact(node=item, call=call, report=report)\n    return report\n\n\ndef check_interactive_exception(call: CallInfo[object], report: BaseReport) -> bool:\n    \"\"\"Check whether the call raised an exception that should be reported as\n    interactive.\"\"\"\n    if call.excinfo is None:\n        # Didn't raise.\n        return False\n    if hasattr(report, \"wasxfail\"):\n        # Exception was expected.\n        return False\n    if isinstance(call.excinfo.value, (Skipped, bdb.BdbQuit)):\n        # Special control flow exception.\n        return False\n    return True\n\n\nTResult = TypeVar(\"TResult\", covariant=True)\n\n\n@final\n@dataclasses.dataclass\nclass CallInfo(Generic"}, {"start_line": 12000, "end_line": 14000, "belongs_to": {"file_name": "reports.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": " test.\"\n                )\n                if excinfo.value._use_item_location:\n                    path, line = item.reportinfo()[:2]\n                    assert line is not None\n                    longrepr = os.fspath(path), line + 1, r.message\n                else:\n                    longrepr = (str(r.path), r.lineno, r.message)\n            else:\n                outcome = \"failed\"\n                if call.when == \"call\":\n                    longrepr = item.repr_failure(excinfo)\n                else:  # exception in setup or teardown\n                    longrepr = item._repr_failure_py(\n                        excinfo, style=item.config.getoption(\"tbstyle\", \"auto\")\n                    )\n        for rwhen, key, content in item._report_sections:\n            sections.append((f\"Captured {key} {rwhen}\", content))\n        return cls(\n            item.nodeid,\n            item.location,\n            keywords,\n            outcome,\n            longrepr,\n            when,\n            sections,\n            duration,\n            start,\n            stop,\n            user_properties=item.user_properties,\n        )\n\n\n@final\nclass CollectReport(BaseReport):\n    \"\"\"Collection report object.\n\n    Reports can contain arbitrary extra attributes.\n    \"\"\"\n\n    when = \"collect\"\n\n    def __init__(\n        self,\n        nodeid: str,\n        outcome: Literal[\"passed\", \"failed\", \"skipped\"],\n        longrepr: None\n        | ExceptionInfo[BaseException]\n        | tuple[str, int, str]\n        | str\n        | TerminalRepr,\n        result: list[Item | Collector] | None,\n        sections: Iterable[tuple[str, str]] = (),\n        **extra,\n    ) -> None:\n        #: Normalized collection nodeid.\n        self.nodeid = nodeid\n\n        #: Test outcome, always one of \"passed\", \"failed\", \"skipped\".\n        self.outcome = outcome\n\n        #: None or a failure representation.\n        self.longrepr = longrepr\n\n        #: The collected items and collection nodes.\n        self.result = result or []\n\n        #: Tu"}, {"start_line": 10000, "end_line": 12000, "belongs_to": {"file_name": "runner.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": " start\n        self.stop = stop\n        self.duration = duration\n        self.when = when\n\n    @property\n    def result(self) -> TResult:\n        \"\"\"The return value of the call, if it didn't raise.\n\n        Can only be accessed if excinfo is None.\n        \"\"\"\n        if self.excinfo is not None:\n            raise AttributeError(f\"{self!r} has no valid result\")\n        # The cast is safe because an exception wasn't raised, hence\n        # _result has the expected function return type (which may be\n        #  None, that's why a cast and not an assert).\n        return cast(TResult, self._result)\n\n    @classmethod\n    def from_call(\n        cls,\n        func: Callable[[], TResult],\n        when: Literal[\"collect\", \"setup\", \"call\", \"teardown\"],\n        reraise: type[BaseException] | tuple[type[BaseException], ...] | None = None,\n    ) -> CallInfo[TResult]:\n        \"\"\"Call func, wrapping the result in a CallInfo.\n\n        :param func:\n            The function to call. Called without arguments.\n        :type func: Callable[[], _pytest.runner.TResult]\n        :param when:\n            The phase in which the function is called.\n        :param reraise:\n            Exception or exceptions that shall propagate if raised by the\n            function, instead of being wrapped in the CallInfo.\n        \"\"\"\n        excinfo = None\n        instant = timing.Instant()\n        try:\n            result: TResult | None = func()\n        except BaseException:\n            excinfo = ExceptionInfo.from_current()\n            if reraise is not None and isinstance(excinfo.value, reraise):\n                raise\n            result = None\n        duration = instant.elapsed()\n        return cls(\n            start=duration.start.time,\n            stop=duration.stop.time,\n            duration=duration.seconds,\n            when=when,\n            result=result,\n            excinfo=excinfo,\n            _ispytest=True,\n        )\n\n    def __repr__(self) -> str:\n        if self.excinfo is None:\n            retu"}, {"start_line": 10000, "end_line": 12000, "belongs_to": {"file_name": "reports.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "est report. Used by pytest to add text captured\n        #: from ``stdout``, ``stderr``, and intercepted logging events. May\n        #: be used by other plugins to add arbitrary information to reports.\n        self.sections = list(sections)\n\n        #: Time it took to run just the test.\n        self.duration: float = duration\n\n        #: The system time when the call started, in seconds since the epoch.\n        self.start: float = start\n        #: The system time when the call ended, in seconds since the epoch.\n        self.stop: float = stop\n\n        self.__dict__.update(extra)\n\n    def __repr__(self) -> str:\n        return f\"<{self.__class__.__name__} {self.nodeid!r} when={self.when!r} outcome={self.outcome!r}>\"\n\n    @classmethod\n    def from_item_and_call(cls, item: Item, call: CallInfo[None]) -> TestReport:\n        \"\"\"Create and fill a TestReport with standard item and call info.\n\n        :param item: The item.\n        :param call: The call info.\n        \"\"\"\n        when = call.when\n        # Remove \"collect\" from the Literal type -- only for collection calls.\n        assert when != \"collect\"\n        duration = call.duration\n        start = call.start\n        stop = call.stop\n        keywords = {x: 1 for x in item.keywords}\n        excinfo = call.excinfo\n        sections = []\n        if not call.excinfo:\n            outcome: Literal[\"passed\", \"failed\", \"skipped\"] = \"passed\"\n            longrepr: (\n                None\n                | ExceptionInfo[BaseException]\n                | tuple[str, int, str]\n                | str\n                | TerminalRepr\n            ) = None\n        else:\n            if not isinstance(excinfo, ExceptionInfo):\n                outcome = \"failed\"\n                longrepr = excinfo\n            elif isinstance(excinfo.value, skip.Exception):\n                outcome = \"skipped\"\n                r = excinfo._getreprcrash()\n                assert r is not None, (\n                    \"There should always be a traceback entry for skipping a"}, {"start_line": 9000, "end_line": 11000, "belongs_to": {"file_name": "reports.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "llected one e.g. if a method is inherited from a different module.\n        #: The filesystempath may be relative to ``config.rootdir``.\n        #: The line number is 0-based.\n        self.location: tuple[str, int | None, str] = location\n\n        #: A name -> value dictionary containing all keywords and\n        #: markers associated with a test invocation.\n        self.keywords: Mapping[str, Any] = keywords\n\n        #: Test outcome, always one of \"passed\", \"failed\", \"skipped\".\n        self.outcome = outcome\n\n        #: None or a failure representation.\n        self.longrepr = longrepr\n\n        #: One of 'setup', 'call', 'teardown' to indicate runtest phase.\n        self.when: Literal[\"setup\", \"call\", \"teardown\"] = when\n\n        #: User properties is a list of tuples (name, value) that holds user\n        #: defined properties of the test.\n        self.user_properties = list(user_properties or [])\n\n        #: Tuples of str ``(heading, content)`` with extra information\n        #: for the test report. Used by pytest to add text captured\n        #: from ``stdout``, ``stderr``, and intercepted logging events. May\n        #: be used by other plugins to add arbitrary information to reports.\n        self.sections = list(sections)\n\n        #: Time it took to run just the test.\n        self.duration: float = duration\n\n        #: The system time when the call started, in seconds since the epoch.\n        self.start: float = start\n        #: The system time when the call ended, in seconds since the epoch.\n        self.stop: float = stop\n\n        self.__dict__.update(extra)\n\n    def __repr__(self) -> str:\n        return f\"<{self.__class__.__name__} {self.nodeid!r} when={self.when!r} outcome={self.outcome!r}>\"\n\n    @classmethod\n    def from_item_and_call(cls, item: Item, call: CallInfo[None]) -> TestReport:\n        \"\"\"Create and fill a TestReport with standard item and call info.\n\n        :param item: The item.\n        :param call: The call info.\n        \"\"\"\n        when = call.when"}, {"start_line": 11000, "end_line": 13000, "belongs_to": {"file_name": "runner.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "ts.\n        :type func: Callable[[], _pytest.runner.TResult]\n        :param when:\n            The phase in which the function is called.\n        :param reraise:\n            Exception or exceptions that shall propagate if raised by the\n            function, instead of being wrapped in the CallInfo.\n        \"\"\"\n        excinfo = None\n        instant = timing.Instant()\n        try:\n            result: TResult | None = func()\n        except BaseException:\n            excinfo = ExceptionInfo.from_current()\n            if reraise is not None and isinstance(excinfo.value, reraise):\n                raise\n            result = None\n        duration = instant.elapsed()\n        return cls(\n            start=duration.start.time,\n            stop=duration.stop.time,\n            duration=duration.seconds,\n            when=when,\n            result=result,\n            excinfo=excinfo,\n            _ispytest=True,\n        )\n\n    def __repr__(self) -> str:\n        if self.excinfo is None:\n            return f\"<CallInfo when={self.when!r} result: {self._result!r}>\"\n        return f\"<CallInfo when={self.when!r} excinfo={self.excinfo!r}>\"\n\n\ndef pytest_runtest_makereport(item: Item, call: CallInfo[None]) -> TestReport:\n    return TestReport.from_item_and_call(item, call)\n\n\ndef pytest_make_collect_report(collector: Collector) -> CollectReport:\n    def collect() -> list[Item | Collector]:\n        # Before collecting, if this is a Directory, load the conftests.\n        # If a conftest import fails to load, it is considered a collection\n        # error of the Directory collector. This is why it's done inside of the\n        # CallInfo wrapper.\n        #\n        # Note: initial conftests are loaded early, not here.\n        if isinstance(collector, Directory):\n            collector.config.pluginmanager._loadconftestmodules(\n                collector.path,\n                collector.config.getoption(\"importmode\"),\n                rootpath=collector.config.rootpath,\n                consider_namespac"}, {"start_line": 9000, "end_line": 11000, "belongs_to": {"file_name": "runner.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "[TResult]):\n    \"\"\"Result/Exception info of a function invocation.\"\"\"\n\n    _result: TResult | None\n    #: The captured exception of the call, if it raised.\n    excinfo: ExceptionInfo[BaseException] | None\n    #: The system time when the call started, in seconds since the epoch.\n    start: float\n    #: The system time when the call ended, in seconds since the epoch.\n    stop: float\n    #: The call duration, in seconds.\n    duration: float\n    #: The context of invocation: \"collect\", \"setup\", \"call\" or \"teardown\".\n    when: Literal[\"collect\", \"setup\", \"call\", \"teardown\"]\n\n    def __init__(\n        self,\n        result: TResult | None,\n        excinfo: ExceptionInfo[BaseException] | None,\n        start: float,\n        stop: float,\n        duration: float,\n        when: Literal[\"collect\", \"setup\", \"call\", \"teardown\"],\n        *,\n        _ispytest: bool = False,\n    ) -> None:\n        check_ispytest(_ispytest)\n        self._result = result\n        self.excinfo = excinfo\n        self.start = start\n        self.stop = stop\n        self.duration = duration\n        self.when = when\n\n    @property\n    def result(self) -> TResult:\n        \"\"\"The return value of the call, if it didn't raise.\n\n        Can only be accessed if excinfo is None.\n        \"\"\"\n        if self.excinfo is not None:\n            raise AttributeError(f\"{self!r} has no valid result\")\n        # The cast is safe because an exception wasn't raised, hence\n        # _result has the expected function return type (which may be\n        #  None, that's why a cast and not an assert).\n        return cast(TResult, self._result)\n\n    @classmethod\n    def from_call(\n        cls,\n        func: Callable[[], TResult],\n        when: Literal[\"collect\", \"setup\", \"call\", \"teardown\"],\n        reraise: type[BaseException] | tuple[type[BaseException], ...] | None = None,\n    ) -> CallInfo[TResult]:\n        \"\"\"Call func, wrapping the result in a CallInfo.\n\n        :param func:\n            The function to call. Called without argumen"}, {"start_line": 12000, "end_line": 14000, "belongs_to": {"file_name": "runner.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "rn f\"<CallInfo when={self.when!r} result: {self._result!r}>\"\n        return f\"<CallInfo when={self.when!r} excinfo={self.excinfo!r}>\"\n\n\ndef pytest_runtest_makereport(item: Item, call: CallInfo[None]) -> TestReport:\n    return TestReport.from_item_and_call(item, call)\n\n\ndef pytest_make_collect_report(collector: Collector) -> CollectReport:\n    def collect() -> list[Item | Collector]:\n        # Before collecting, if this is a Directory, load the conftests.\n        # If a conftest import fails to load, it is considered a collection\n        # error of the Directory collector. This is why it's done inside of the\n        # CallInfo wrapper.\n        #\n        # Note: initial conftests are loaded early, not here.\n        if isinstance(collector, Directory):\n            collector.config.pluginmanager._loadconftestmodules(\n                collector.path,\n                collector.config.getoption(\"importmode\"),\n                rootpath=collector.config.rootpath,\n                consider_namespace_packages=collector.config.getini(\n                    \"consider_namespace_packages\"\n                ),\n            )\n\n        return list(collector.collect())\n\n    call = CallInfo.from_call(\n        collect, \"collect\", reraise=(KeyboardInterrupt, SystemExit)\n    )\n    longrepr: None | tuple[str, int, str] | str | TerminalRepr = None\n    if not call.excinfo:\n        outcome: Literal[\"passed\", \"skipped\", \"failed\"] = \"passed\"\n    else:\n        skip_exceptions = [Skipped]\n        unittest = sys.modules.get(\"unittest\")\n        if unittest is not None:\n            skip_exceptions.append(unittest.SkipTest)\n        if isinstance(call.excinfo.value, tuple(skip_exceptions)):\n            outcome = \"skipped\"\n            r_ = collector._repr_failure_py(call.excinfo, \"line\")\n            assert isinstance(r_, ExceptionChainRepr), repr(r_)\n            r = r_.reprcrash\n            assert r\n            longrepr = (str(r.path), r.lineno, r.message)\n        else:\n            outcome = \"failed\"\n         "}], "retrieved_count": 10, "cost_time": 1.0554349422454834}
{"question": "What is the impact of the tmpdir fixture's conversion from Path to LEGACY_PATH through legacy_path() on the fixture's dependency chain, and what would be the cascading impact on test isolation if the conversion were to fail silently?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"start_line": 9000, "end_line": 11000, "belongs_to": {"file_name": "legacypath.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "Testdir:\n        \"\"\"\n        Identical to :fixture:`pytester`, and provides an instance whose methods return\n        legacy ``LEGACY_PATH`` objects instead when applicable.\n\n        New code should avoid using :fixture:`testdir` in favor of :fixture:`pytester`.\n        \"\"\"\n        return Testdir(pytester, _ispytest=True)\n\n\n@final\n@dataclasses.dataclass\nclass TempdirFactory:\n    \"\"\"Backward compatibility wrapper that implements ``py.path.local``\n    for :class:`TempPathFactory`.\n\n    .. note::\n        These days, it is preferred to use ``tmp_path_factory``.\n\n        :ref:`About the tmpdir and tmpdir_factory fixtures<tmpdir and tmpdir_factory>`.\n\n    \"\"\"\n\n    _tmppath_factory: TempPathFactory\n\n    def __init__(\n        self, tmppath_factory: TempPathFactory, *, _ispytest: bool = False\n    ) -> None:\n        check_ispytest(_ispytest)\n        self._tmppath_factory = tmppath_factory\n\n    def mktemp(self, basename: str, numbered: bool = True) -> LEGACY_PATH:\n        \"\"\"Same as :meth:`TempPathFactory.mktemp`, but returns a ``py.path.local`` object.\"\"\"\n        return legacy_path(self._tmppath_factory.mktemp(basename, numbered).resolve())\n\n    def getbasetemp(self) -> LEGACY_PATH:\n        \"\"\"Same as :meth:`TempPathFactory.getbasetemp`, but returns a ``py.path.local`` object.\"\"\"\n        return legacy_path(self._tmppath_factory.getbasetemp().resolve())\n\n\nclass LegacyTmpdirPlugin:\n    @staticmethod\n    @fixture(scope=\"session\")\n    def tmpdir_factory(request: FixtureRequest) -> TempdirFactory:\n        \"\"\"Return a :class:`pytest.TempdirFactory` instance for the test session.\"\"\"\n        # Set dynamically by pytest_configure().\n        return request.config._tmpdirhandler  # type: ignore\n\n    @staticmethod\n    @fixture\n    def tmpdir(tmp_path: Path) -> LEGACY_PATH:\n        \"\"\"Return a temporary directory (as `legacy_path`_ object)\n        which is unique to each test function invocation.\n        The temporary directory is created as a subdirectory\n        of the base temporary dir"}, {"start_line": 10000, "end_line": 12000, "belongs_to": {"file_name": "legacypath.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "hFactory.mktemp`, but returns a ``py.path.local`` object.\"\"\"\n        return legacy_path(self._tmppath_factory.mktemp(basename, numbered).resolve())\n\n    def getbasetemp(self) -> LEGACY_PATH:\n        \"\"\"Same as :meth:`TempPathFactory.getbasetemp`, but returns a ``py.path.local`` object.\"\"\"\n        return legacy_path(self._tmppath_factory.getbasetemp().resolve())\n\n\nclass LegacyTmpdirPlugin:\n    @staticmethod\n    @fixture(scope=\"session\")\n    def tmpdir_factory(request: FixtureRequest) -> TempdirFactory:\n        \"\"\"Return a :class:`pytest.TempdirFactory` instance for the test session.\"\"\"\n        # Set dynamically by pytest_configure().\n        return request.config._tmpdirhandler  # type: ignore\n\n    @staticmethod\n    @fixture\n    def tmpdir(tmp_path: Path) -> LEGACY_PATH:\n        \"\"\"Return a temporary directory (as `legacy_path`_ object)\n        which is unique to each test function invocation.\n        The temporary directory is created as a subdirectory\n        of the base temporary directory, with configurable retention,\n        as discussed in :ref:`temporary directory location and retention`.\n\n        .. note::\n            These days, it is preferred to use ``tmp_path``.\n\n            :ref:`About the tmpdir and tmpdir_factory fixtures<tmpdir and tmpdir_factory>`.\n\n        .. _legacy_path: https://py.readthedocs.io/en/latest/path.html\n        \"\"\"\n        return legacy_path(tmp_path)\n\n\ndef Cache_makedir(self: Cache, name: str) -> LEGACY_PATH:\n    \"\"\"Return a directory path object with the given name.\n\n    Same as :func:`mkdir`, but returns a legacy py path instance.\n    \"\"\"\n    return legacy_path(self.mkdir(name))\n\n\ndef FixtureRequest_fspath(self: FixtureRequest) -> LEGACY_PATH:\n    \"\"\"(deprecated) The file system path of the test module which collected this test.\"\"\"\n    return legacy_path(self.path)\n\n\ndef TerminalReporter_startdir(self: TerminalReporter) -> LEGACY_PATH:\n    \"\"\"The directory from which pytest was invoked.\n\n    Prefer to use ``startpath`` which is a :"}, {"start_line": 15000, "end_line": 16588, "belongs_to": {"file_name": "legacypath.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "i_unknown_type\", Config__getini_unknown_type)\n\n    # Add Node.fspath property.\n    mp.setattr(Node, \"fspath\", property(Node_fspath, Node_fspath_set), raising=False)\n\n\n@hookimpl\ndef pytest_configure(config: Config) -> None:\n    \"\"\"Installs the LegacyTmpdirPlugin if the ``tmpdir`` plugin is also installed.\"\"\"\n    if config.pluginmanager.has_plugin(\"tmpdir\"):\n        mp = MonkeyPatch()\n        config.add_cleanup(mp.undo)\n        # Create TmpdirFactory and attach it to the config object.\n        #\n        # This is to comply with existing plugins which expect the handler to be\n        # available at pytest_configure time, but ideally should be moved entirely\n        # to the tmpdir_factory session fixture.\n        try:\n            tmp_path_factory = config._tmp_path_factory  # type: ignore[attr-defined]\n        except AttributeError:\n            # tmpdir plugin is blocked.\n            pass\n        else:\n            _tmpdirhandler = TempdirFactory(tmp_path_factory, _ispytest=True)\n            mp.setattr(config, \"_tmpdirhandler\", _tmpdirhandler, raising=False)\n\n        config.pluginmanager.register(LegacyTmpdirPlugin, \"legacypath-tmpdir\")\n\n\n@hookimpl\ndef pytest_plugin_registered(plugin: object, manager: PytestPluginManager) -> None:\n    # pytester is not loaded by default and is commonly loaded from a conftest,\n    # so checking for it in `pytest_configure` is not enough.\n    is_pytester = plugin is manager.get_plugin(\"pytester\")\n    if is_pytester and not manager.is_registered(LegacyTestdirPlugin):\n        manager.register(LegacyTestdirPlugin, \"legacypath-pytester\")\n"}, {"start_line": 11000, "end_line": 13000, "belongs_to": {"file_name": "legacypath.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "ectory, with configurable retention,\n        as discussed in :ref:`temporary directory location and retention`.\n\n        .. note::\n            These days, it is preferred to use ``tmp_path``.\n\n            :ref:`About the tmpdir and tmpdir_factory fixtures<tmpdir and tmpdir_factory>`.\n\n        .. _legacy_path: https://py.readthedocs.io/en/latest/path.html\n        \"\"\"\n        return legacy_path(tmp_path)\n\n\ndef Cache_makedir(self: Cache, name: str) -> LEGACY_PATH:\n    \"\"\"Return a directory path object with the given name.\n\n    Same as :func:`mkdir`, but returns a legacy py path instance.\n    \"\"\"\n    return legacy_path(self.mkdir(name))\n\n\ndef FixtureRequest_fspath(self: FixtureRequest) -> LEGACY_PATH:\n    \"\"\"(deprecated) The file system path of the test module which collected this test.\"\"\"\n    return legacy_path(self.path)\n\n\ndef TerminalReporter_startdir(self: TerminalReporter) -> LEGACY_PATH:\n    \"\"\"The directory from which pytest was invoked.\n\n    Prefer to use ``startpath`` which is a :class:`pathlib.Path`.\n\n    :type: LEGACY_PATH\n    \"\"\"\n    return legacy_path(self.startpath)\n\n\ndef Config_invocation_dir(self: Config) -> LEGACY_PATH:\n    \"\"\"The directory from which pytest was invoked.\n\n    Prefer to use :attr:`invocation_params.dir <InvocationParams.dir>`,\n    which is a :class:`pathlib.Path`.\n\n    :type: LEGACY_PATH\n    \"\"\"\n    return legacy_path(str(self.invocation_params.dir))\n\n\ndef Config_rootdir(self: Config) -> LEGACY_PATH:\n    \"\"\"The path to the :ref:`rootdir <rootdir>`.\n\n    Prefer to use :attr:`rootpath`, which is a :class:`pathlib.Path`.\n\n    :type: LEGACY_PATH\n    \"\"\"\n    return legacy_path(str(self.rootpath))\n\n\ndef Config_inifile(self: Config) -> LEGACY_PATH | None:\n    \"\"\"The path to the :ref:`configfile <configfiles>`.\n\n    Prefer to use :attr:`inipath`, which is a :class:`pathlib.Path`.\n\n    :type: Optional[LEGACY_PATH]\n    \"\"\"\n    return legacy_path(str(self.inipath)) if self.inipath else None\n\n\ndef Session_startdir(self: Session) -> LEGACY_PATH:\n    "}, {"start_line": 0, "end_line": 2000, "belongs_to": {"file_name": "test_legacypath.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "# mypy: allow-untyped-defs\nfrom __future__ import annotations\n\nfrom pathlib import Path\n\nfrom _pytest.compat import LEGACY_PATH\nfrom _pytest.fixtures import TopRequest\nfrom _pytest.legacypath import TempdirFactory\nfrom _pytest.legacypath import Testdir\nimport pytest\n\n\ndef test_item_fspath(pytester: pytest.Pytester) -> None:\n    pytester.makepyfile(\"def test_func(): pass\")\n    items, hookrec = pytester.inline_genitems()\n    assert len(items) == 1\n    (item,) = items\n    items2, hookrec = pytester.inline_genitems(item.nodeid)\n    (item2,) = items2\n    assert item2.name == item.name\n    assert item2.fspath == item.fspath\n    assert item2.path == item.path\n\n\ndef test_testdir_testtmproot(testdir: Testdir) -> None:\n    \"\"\"Check test_tmproot is a py.path attribute for backward compatibility.\"\"\"\n    assert testdir.test_tmproot.check(dir=1)\n\n\ndef test_testdir_makefile_dot_prefixes_extension_silently(\n    testdir: Testdir,\n) -> None:\n    \"\"\"For backwards compat #8192\"\"\"\n    p1 = testdir.makefile(\"foo.bar\", \"\")\n    assert \".foo.bar\" in str(p1)\n\n\ndef test_testdir_makefile_ext_none_raises_type_error(testdir: Testdir) -> None:\n    \"\"\"For backwards compat #8192\"\"\"\n    with pytest.raises(TypeError):\n        testdir.makefile(None, \"\")\n\n\ndef test_testdir_makefile_ext_empty_string_makes_file(testdir: Testdir) -> None:\n    \"\"\"For backwards compat #8192\"\"\"\n    p1 = testdir.makefile(\"\", \"\")\n    assert \"test_testdir_makefile\" in str(p1)\n\n\ndef attempt_symlink_to(path: str, to_path: str) -> None:\n    \"\"\"Try to make a symlink from \"path\" to \"to_path\", skipping in case this platform\n    does not support it or we don't have sufficient privileges (common on Windows).\"\"\"\n    try:\n        Path(path).symlink_to(Path(to_path))\n    except OSError:\n        pytest.skip(\"could not create symbolic link\")\n\n\ndef test_tmpdir_factory(\n    tmpdir_factory: TempdirFactory,\n    tmp_path_factory: pytest.TempPathFactory,\n) -> None:\n    assert str(tmpdir_factory.getbasetemp()) == str(tmp_path_factory.getbasetemp()"}, {"start_line": 1000, "end_line": 3000, "belongs_to": {"file_name": "legacypath.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "terminal import TerminalReporter\nfrom _pytest.tmpdir import TempPathFactory\n\n\nif TYPE_CHECKING:\n    import pexpect\n\n\n@final\nclass Testdir:\n    \"\"\"\n    Similar to :class:`Pytester`, but this class works with legacy legacy_path objects instead.\n\n    All methods just forward to an internal :class:`Pytester` instance, converting results\n    to `legacy_path` objects as necessary.\n    \"\"\"\n\n    __test__ = False\n\n    CLOSE_STDIN: Final = Pytester.CLOSE_STDIN\n    TimeoutExpired: Final = Pytester.TimeoutExpired\n\n    def __init__(self, pytester: Pytester, *, _ispytest: bool = False) -> None:\n        check_ispytest(_ispytest)\n        self._pytester = pytester\n\n    @property\n    def tmpdir(self) -> LEGACY_PATH:\n        \"\"\"Temporary directory where tests are executed.\"\"\"\n        return legacy_path(self._pytester.path)\n\n    @property\n    def test_tmproot(self) -> LEGACY_PATH:\n        return legacy_path(self._pytester._test_tmproot)\n\n    @property\n    def request(self):\n        return self._pytester._request\n\n    @property\n    def plugins(self):\n        return self._pytester.plugins\n\n    @plugins.setter\n    def plugins(self, plugins):\n        self._pytester.plugins = plugins\n\n    @property\n    def monkeypatch(self) -> MonkeyPatch:\n        return self._pytester._monkeypatch\n\n    def make_hook_recorder(self, pluginmanager) -> HookRecorder:\n        \"\"\"See :meth:`Pytester.make_hook_recorder`.\"\"\"\n        return self._pytester.make_hook_recorder(pluginmanager)\n\n    def chdir(self) -> None:\n        \"\"\"See :meth:`Pytester.chdir`.\"\"\"\n        return self._pytester.chdir()\n\n    def finalize(self) -> None:\n        return self._pytester._finalize()\n\n    def makefile(self, ext, *args, **kwargs) -> LEGACY_PATH:\n        \"\"\"See :meth:`Pytester.makefile`.\"\"\"\n        if ext and not ext.startswith(\".\"):\n            # pytester.makefile is going to throw a ValueError in a way that\n            # testdir.makefile did not, because\n            # pathlib.Path is stricter suffixes than py.path\n            # T"}, {"start_line": 0, "end_line": 2000, "belongs_to": {"file_name": "legacypath.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "# mypy: allow-untyped-defs\n\"\"\"Add backward compatibility support for the legacy py path type.\"\"\"\n\nfrom __future__ import annotations\n\nimport dataclasses\nfrom pathlib import Path\nimport shlex\nimport subprocess\nfrom typing import Final\nfrom typing import final\nfrom typing import TYPE_CHECKING\n\nfrom iniconfig import SectionWrapper\n\nfrom _pytest.cacheprovider import Cache\nfrom _pytest.compat import LEGACY_PATH\nfrom _pytest.compat import legacy_path\nfrom _pytest.config import Config\nfrom _pytest.config import hookimpl\nfrom _pytest.config import PytestPluginManager\nfrom _pytest.deprecated import check_ispytest\nfrom _pytest.fixtures import fixture\nfrom _pytest.fixtures import FixtureRequest\nfrom _pytest.main import Session\nfrom _pytest.monkeypatch import MonkeyPatch\nfrom _pytest.nodes import Collector\nfrom _pytest.nodes import Item\nfrom _pytest.nodes import Node\nfrom _pytest.pytester import HookRecorder\nfrom _pytest.pytester import Pytester\nfrom _pytest.pytester import RunResult\nfrom _pytest.terminal import TerminalReporter\nfrom _pytest.tmpdir import TempPathFactory\n\n\nif TYPE_CHECKING:\n    import pexpect\n\n\n@final\nclass Testdir:\n    \"\"\"\n    Similar to :class:`Pytester`, but this class works with legacy legacy_path objects instead.\n\n    All methods just forward to an internal :class:`Pytester` instance, converting results\n    to `legacy_path` objects as necessary.\n    \"\"\"\n\n    __test__ = False\n\n    CLOSE_STDIN: Final = Pytester.CLOSE_STDIN\n    TimeoutExpired: Final = Pytester.TimeoutExpired\n\n    def __init__(self, pytester: Pytester, *, _ispytest: bool = False) -> None:\n        check_ispytest(_ispytest)\n        self._pytester = pytester\n\n    @property\n    def tmpdir(self) -> LEGACY_PATH:\n        \"\"\"Temporary directory where tests are executed.\"\"\"\n        return legacy_path(self._pytester.path)\n\n    @property\n    def test_tmproot(self) -> LEGACY_PATH:\n        return legacy_path(self._pytester._test_tmproot)\n\n    @property\n    def request(self):\n        return self._pytester._"}, {"start_line": 2000, "end_line": 4000, "belongs_to": {"file_name": "test_legacypath.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": ")\n    dir = tmpdir_factory.mktemp(\"foo\")\n    assert dir.exists()\n\n\ndef test_tmpdir_equals_tmp_path(tmpdir: LEGACY_PATH, tmp_path: Path) -> None:\n    assert Path(tmpdir) == tmp_path\n\n\ndef test_tmpdir_always_is_realpath(pytester: pytest.Pytester) -> None:\n    # See test_tmp_path_always_is_realpath.\n    realtemp = pytester.mkdir(\"myrealtemp\")\n    linktemp = pytester.path.joinpath(\"symlinktemp\")\n    attempt_symlink_to(str(linktemp), str(realtemp))\n    p = pytester.makepyfile(\n        \"\"\"\n        def test_1(tmpdir):\n            import os\n            assert os.path.realpath(str(tmpdir)) == str(tmpdir)\n    \"\"\"\n    )\n    result = pytester.runpytest(\"-s\", p, f\"--basetemp={linktemp}/bt\")\n    assert not result.ret\n\n\ndef test_cache_makedir(cache: pytest.Cache) -> None:\n    dir = cache.makedir(\"foo\")  # type: ignore[attr-defined]\n    assert dir.exists()\n    dir.remove()\n\n\ndef test_fixturerequest_getmodulepath(pytester: pytest.Pytester) -> None:\n    modcol = pytester.getmodulecol(\"def test_somefunc(): pass\")\n    (item,) = pytester.genitems([modcol])\n    assert isinstance(item, pytest.Function)\n    req = TopRequest(item, _ispytest=True)\n    assert req.path == modcol.path\n    assert req.fspath == modcol.fspath  # type: ignore[attr-defined]\n\n\nclass TestFixtureRequestSessionScoped:\n    @pytest.fixture(scope=\"session\")\n    def session_request(self, request):\n        return request\n\n    def test_session_scoped_unavailable_attributes(self, session_request):\n        with pytest.raises(\n            AttributeError,\n            match=\"path not available in session-scoped context\",\n        ):\n            _ = session_request.fspath\n\n\n@pytest.mark.parametrize(\"config_type\", [\"ini\", \"pyproject\"])\ndef test_addini_paths(pytester: pytest.Pytester, config_type: str) -> None:\n    pytester.makeconftest(\n        \"\"\"\n        def pytest_addoption(parser):\n            parser.addini(\"paths\", \"my new ini value\", type=\"pathlist\")\n            parser.addini(\"abc\", \"abc value\")\n    \"\"\"\n    )\n    if config_type"}, {"start_line": 1000, "end_line": 3000, "belongs_to": {"file_name": "test_legacypath.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "(\"foo.bar\", \"\")\n    assert \".foo.bar\" in str(p1)\n\n\ndef test_testdir_makefile_ext_none_raises_type_error(testdir: Testdir) -> None:\n    \"\"\"For backwards compat #8192\"\"\"\n    with pytest.raises(TypeError):\n        testdir.makefile(None, \"\")\n\n\ndef test_testdir_makefile_ext_empty_string_makes_file(testdir: Testdir) -> None:\n    \"\"\"For backwards compat #8192\"\"\"\n    p1 = testdir.makefile(\"\", \"\")\n    assert \"test_testdir_makefile\" in str(p1)\n\n\ndef attempt_symlink_to(path: str, to_path: str) -> None:\n    \"\"\"Try to make a symlink from \"path\" to \"to_path\", skipping in case this platform\n    does not support it or we don't have sufficient privileges (common on Windows).\"\"\"\n    try:\n        Path(path).symlink_to(Path(to_path))\n    except OSError:\n        pytest.skip(\"could not create symbolic link\")\n\n\ndef test_tmpdir_factory(\n    tmpdir_factory: TempdirFactory,\n    tmp_path_factory: pytest.TempPathFactory,\n) -> None:\n    assert str(tmpdir_factory.getbasetemp()) == str(tmp_path_factory.getbasetemp())\n    dir = tmpdir_factory.mktemp(\"foo\")\n    assert dir.exists()\n\n\ndef test_tmpdir_equals_tmp_path(tmpdir: LEGACY_PATH, tmp_path: Path) -> None:\n    assert Path(tmpdir) == tmp_path\n\n\ndef test_tmpdir_always_is_realpath(pytester: pytest.Pytester) -> None:\n    # See test_tmp_path_always_is_realpath.\n    realtemp = pytester.mkdir(\"myrealtemp\")\n    linktemp = pytester.path.joinpath(\"symlinktemp\")\n    attempt_symlink_to(str(linktemp), str(realtemp))\n    p = pytester.makepyfile(\n        \"\"\"\n        def test_1(tmpdir):\n            import os\n            assert os.path.realpath(str(tmpdir)) == str(tmpdir)\n    \"\"\"\n    )\n    result = pytester.runpytest(\"-s\", p, f\"--basetemp={linktemp}/bt\")\n    assert not result.ret\n\n\ndef test_cache_makedir(cache: pytest.Cache) -> None:\n    dir = cache.makedir(\"foo\")  # type: ignore[attr-defined]\n    assert dir.exists()\n    dir.remove()\n\n\ndef test_fixturerequest_getmodulepath(pytester: pytest.Pytester) -> None:\n    modcol = pytester.getmodulecol(\"def test_somefunc("}, {"start_line": 14000, "end_line": 16000, "belongs_to": {"file_name": "legacypath.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": " legacy path attributes in several classes, as early as possible.\"\"\"\n    mp = MonkeyPatch()\n    early_config.add_cleanup(mp.undo)\n\n    # Add Cache.makedir().\n    mp.setattr(Cache, \"makedir\", Cache_makedir, raising=False)\n\n    # Add FixtureRequest.fspath property.\n    mp.setattr(FixtureRequest, \"fspath\", property(FixtureRequest_fspath), raising=False)\n\n    # Add TerminalReporter.startdir property.\n    mp.setattr(\n        TerminalReporter, \"startdir\", property(TerminalReporter_startdir), raising=False\n    )\n\n    # Add Config.{invocation_dir,rootdir,inifile} properties.\n    mp.setattr(Config, \"invocation_dir\", property(Config_invocation_dir), raising=False)\n    mp.setattr(Config, \"rootdir\", property(Config_rootdir), raising=False)\n    mp.setattr(Config, \"inifile\", property(Config_inifile), raising=False)\n\n    # Add Session.startdir property.\n    mp.setattr(Session, \"startdir\", property(Session_startdir), raising=False)\n\n    # Add pathlist configuration type.\n    mp.setattr(Config, \"_getini_unknown_type\", Config__getini_unknown_type)\n\n    # Add Node.fspath property.\n    mp.setattr(Node, \"fspath\", property(Node_fspath, Node_fspath_set), raising=False)\n\n\n@hookimpl\ndef pytest_configure(config: Config) -> None:\n    \"\"\"Installs the LegacyTmpdirPlugin if the ``tmpdir`` plugin is also installed.\"\"\"\n    if config.pluginmanager.has_plugin(\"tmpdir\"):\n        mp = MonkeyPatch()\n        config.add_cleanup(mp.undo)\n        # Create TmpdirFactory and attach it to the config object.\n        #\n        # This is to comply with existing plugins which expect the handler to be\n        # available at pytest_configure time, but ideally should be moved entirely\n        # to the tmpdir_factory session fixture.\n        try:\n            tmp_path_factory = config._tmp_path_factory  # type: ignore[attr-defined]\n        except AttributeError:\n            # tmpdir plugin is blocked.\n            pass\n        else:\n            _tmpdirhandler = TempdirFactory(tmp_path_factory, _ispytest=True)\n         "}], "retrieved_count": 10, "cost_time": 1.0755257606506348}
{"question": "What external dependencies and context must be available for TestEvaluation test methods to correctly evaluate skipif conditions that reference module attributes like os.sep?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"start_line": 0, "end_line": 2000, "belongs_to": {"file_name": "test_skipping.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "# mypy: allow-untyped-defs\nfrom __future__ import annotations\n\nimport sys\nimport textwrap\n\nfrom _pytest.pytester import Pytester\nfrom _pytest.runner import runtestprotocol\nfrom _pytest.skipping import evaluate_skip_marks\nfrom _pytest.skipping import evaluate_xfail_marks\nfrom _pytest.skipping import pytest_runtest_setup\nimport pytest\n\n\nclass TestEvaluation:\n    def test_no_marker(self, pytester: Pytester) -> None:\n        item = pytester.getitem(\"def test_func(): pass\")\n        skipped = evaluate_skip_marks(item)\n        assert not skipped\n\n    def test_marked_xfail_no_args(self, pytester: Pytester) -> None:\n        item = pytester.getitem(\n            \"\"\"\n            import pytest\n            @pytest.mark.xfail\n            def test_func():\n                pass\n        \"\"\"\n        )\n        xfailed = evaluate_xfail_marks(item)\n        assert xfailed\n        assert xfailed.reason == \"\"\n        assert xfailed.run\n\n    def test_marked_skipif_no_args(self, pytester: Pytester) -> None:\n        item = pytester.getitem(\n            \"\"\"\n            import pytest\n            @pytest.mark.skipif\n            def test_func():\n                pass\n        \"\"\"\n        )\n        skipped = evaluate_skip_marks(item)\n        assert skipped\n        assert skipped.reason == \"\"\n\n    def test_marked_one_arg(self, pytester: Pytester) -> None:\n        item = pytester.getitem(\n            \"\"\"\n            import pytest\n            @pytest.mark.skipif(\"hasattr(os, 'sep')\")\n            def test_func():\n                pass\n        \"\"\"\n        )\n        skipped = evaluate_skip_marks(item)\n        assert skipped\n        assert skipped.reason == \"condition: hasattr(os, 'sep')\"\n\n    def test_marked_one_arg_with_reason(self, pytester: Pytester) -> None:\n        item = pytester.getitem(\n            \"\"\"\n            import pytest\n            @pytest.mark.skipif(\"hasattr(os, 'sep')\", attr=2, reason=\"hello world\")\n            def test_func():\n                pass\n        \"\"\"\n        )\n        skipped = e"}, {"start_line": 3000, "end_line": 5000, "belongs_to": {"file_name": "test_skipping.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": " 'murks')\")\n            def test_func():\n                pass\n        \"\"\"\n        )\n        skipped = evaluate_skip_marks(item)\n        assert skipped\n        assert skipped.reason == \"condition: not hasattr(os, 'murks')\"\n\n    def test_marked_skipif_with_boolean_without_reason(\n        self, pytester: Pytester\n    ) -> None:\n        item = pytester.getitem(\n            \"\"\"\n            import pytest\n            @pytest.mark.skipif(False)\n            def test_func():\n                pass\n        \"\"\"\n        )\n        with pytest.raises(pytest.fail.Exception) as excinfo:\n            evaluate_skip_marks(item)\n        assert excinfo.value.msg is not None\n        assert (\n            \"\"\"Error evaluating 'skipif': you need to specify reason=STRING when using booleans as conditions.\"\"\"\n            in excinfo.value.msg\n        )\n\n    def test_marked_skipif_with_invalid_boolean(self, pytester: Pytester) -> None:\n        item = pytester.getitem(\n            \"\"\"\n            import pytest\n\n            class InvalidBool:\n                def __bool__(self):\n                    raise TypeError(\"INVALID\")\n\n            @pytest.mark.skipif(InvalidBool(), reason=\"xxx\")\n            def test_func():\n                pass\n        \"\"\"\n        )\n        with pytest.raises(pytest.fail.Exception) as excinfo:\n            evaluate_skip_marks(item)\n        assert excinfo.value.msg is not None\n        assert \"Error evaluating 'skipif' condition as a boolean\" in excinfo.value.msg\n        assert \"INVALID\" in excinfo.value.msg\n\n    def test_skipif_class(self, pytester: Pytester) -> None:\n        (item,) = pytester.getitems(\n            \"\"\"\n            import pytest\n            class TestClass(object):\n                pytestmark = pytest.mark.skipif(\"config._hackxyz\")\n                def test_func(self):\n                    pass\n        \"\"\"\n        )\n        item.config._hackxyz = 3  # type: ignore[attr-defined]\n        skipped = evaluate_skip_marks(item)\n        assert skipped\n        assert skipped."}, {"start_line": 1000, "end_line": 3000, "belongs_to": {"file_name": "test_skipping.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "   item = pytester.getitem(\n            \"\"\"\n            import pytest\n            @pytest.mark.skipif\n            def test_func():\n                pass\n        \"\"\"\n        )\n        skipped = evaluate_skip_marks(item)\n        assert skipped\n        assert skipped.reason == \"\"\n\n    def test_marked_one_arg(self, pytester: Pytester) -> None:\n        item = pytester.getitem(\n            \"\"\"\n            import pytest\n            @pytest.mark.skipif(\"hasattr(os, 'sep')\")\n            def test_func():\n                pass\n        \"\"\"\n        )\n        skipped = evaluate_skip_marks(item)\n        assert skipped\n        assert skipped.reason == \"condition: hasattr(os, 'sep')\"\n\n    def test_marked_one_arg_with_reason(self, pytester: Pytester) -> None:\n        item = pytester.getitem(\n            \"\"\"\n            import pytest\n            @pytest.mark.skipif(\"hasattr(os, 'sep')\", attr=2, reason=\"hello world\")\n            def test_func():\n                pass\n        \"\"\"\n        )\n        skipped = evaluate_skip_marks(item)\n        assert skipped\n        assert skipped.reason == \"hello world\"\n\n    def test_marked_one_arg_twice(self, pytester: Pytester) -> None:\n        lines = [\n            \"\"\"@pytest.mark.skipif(\"not hasattr(os, 'murks')\")\"\"\",\n            \"\"\"@pytest.mark.skipif(condition=\"hasattr(os, 'murks')\")\"\"\",\n        ]\n        for i in range(2):\n            item = pytester.getitem(\n                f\"\"\"\n                import pytest\n                {lines[i]}\n                {lines[(i + 1) % 2]}\n                def test_func():\n                    pass\n            \"\"\"\n            )\n            skipped = evaluate_skip_marks(item)\n            assert skipped\n            assert skipped.reason == \"condition: not hasattr(os, 'murks')\"\n\n    def test_marked_one_arg_twice2(self, pytester: Pytester) -> None:\n        item = pytester.getitem(\n            \"\"\"\n            import pytest\n            @pytest.mark.skipif(\"hasattr(os, 'murks')\")\n            @pytest.mark.skipif(\"not hasattr(os,"}, {"start_line": 4000, "end_line": 6000, "belongs_to": {"file_name": "test_skipping.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "    class InvalidBool:\n                def __bool__(self):\n                    raise TypeError(\"INVALID\")\n\n            @pytest.mark.skipif(InvalidBool(), reason=\"xxx\")\n            def test_func():\n                pass\n        \"\"\"\n        )\n        with pytest.raises(pytest.fail.Exception) as excinfo:\n            evaluate_skip_marks(item)\n        assert excinfo.value.msg is not None\n        assert \"Error evaluating 'skipif' condition as a boolean\" in excinfo.value.msg\n        assert \"INVALID\" in excinfo.value.msg\n\n    def test_skipif_class(self, pytester: Pytester) -> None:\n        (item,) = pytester.getitems(\n            \"\"\"\n            import pytest\n            class TestClass(object):\n                pytestmark = pytest.mark.skipif(\"config._hackxyz\")\n                def test_func(self):\n                    pass\n        \"\"\"\n        )\n        item.config._hackxyz = 3  # type: ignore[attr-defined]\n        skipped = evaluate_skip_marks(item)\n        assert skipped\n        assert skipped.reason == \"condition: config._hackxyz\"\n\n    def test_skipif_markeval_namespace(self, pytester: Pytester) -> None:\n        pytester.makeconftest(\n            \"\"\"\n            import pytest\n\n            def pytest_markeval_namespace():\n                return {\"color\": \"green\"}\n            \"\"\"\n        )\n        p = pytester.makepyfile(\n            \"\"\"\n            import pytest\n\n            @pytest.mark.skipif(\"color == 'green'\")\n            def test_1():\n                assert True\n\n            @pytest.mark.skipif(\"color == 'red'\")\n            def test_2():\n                assert True\n        \"\"\"\n        )\n        res = pytester.runpytest(p)\n        assert res.ret == 0\n        res.stdout.fnmatch_lines([\"*1 skipped*\"])\n        res.stdout.fnmatch_lines([\"*1 passed*\"])\n\n    def test_skipif_markeval_namespace_multiple(self, pytester: Pytester) -> None:\n        \"\"\"Keys defined by ``pytest_markeval_namespace()`` in nested plugins override top-level ones.\"\"\"\n        root = pytester.mkdir(\"root\")\n"}, {"start_line": 2000, "end_line": 4000, "belongs_to": {"file_name": "skipping.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "iven test function if any of the conditions evaluate to True. \"\n        \"Example: skipif(sys.platform == 'win32') skips the test if we are on the win32 platform. \"\n        \"See https://docs.pytest.org/en/stable/reference/reference.html#pytest-mark-skipif\",\n    )\n    config.addinivalue_line(\n        \"markers\",\n        \"xfail(condition, ..., *, reason=..., run=True, raises=None, strict=xfail_strict): \"\n        \"mark the test function as an expected failure if any of the conditions \"\n        \"evaluate to True. Optionally specify a reason for better reporting \"\n        \"and run=False if you don't even want to execute the test function. \"\n        \"If only specific exception(s) are expected, you can list them in \"\n        \"raises, and if the test fails in other ways, it will be reported as \"\n        \"a true failure. See https://docs.pytest.org/en/stable/reference/reference.html#pytest-mark-xfail\",\n    )\n\n\ndef evaluate_condition(item: Item, mark: Mark, condition: object) -> tuple[bool, str]:\n    \"\"\"Evaluate a single skipif/xfail condition.\n\n    If an old-style string condition is given, it is eval()'d, otherwise the\n    condition is bool()'d. If this fails, an appropriately formatted pytest.fail\n    is raised.\n\n    Returns (result, reason). The reason is only relevant if the result is True.\n    \"\"\"\n    # String condition.\n    if isinstance(condition, str):\n        globals_ = {\n            \"os\": os,\n            \"sys\": sys,\n            \"platform\": platform,\n            \"config\": item.config,\n        }\n        for dictionary in reversed(\n            item.ihook.pytest_markeval_namespace(config=item.config)\n        ):\n            if not isinstance(dictionary, Mapping):\n                raise ValueError(\n                    f\"pytest_markeval_namespace() needs to return a dict, got {dictionary!r}\"\n                )\n            globals_.update(dictionary)\n        if hasattr(item, \"obj\"):\n            globals_.update(item.obj.__globals__)\n        try:\n            filename = f\"<{mark."}, {"start_line": 2000, "end_line": 4000, "belongs_to": {"file_name": "test_skipping.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "valuate_skip_marks(item)\n        assert skipped\n        assert skipped.reason == \"hello world\"\n\n    def test_marked_one_arg_twice(self, pytester: Pytester) -> None:\n        lines = [\n            \"\"\"@pytest.mark.skipif(\"not hasattr(os, 'murks')\")\"\"\",\n            \"\"\"@pytest.mark.skipif(condition=\"hasattr(os, 'murks')\")\"\"\",\n        ]\n        for i in range(2):\n            item = pytester.getitem(\n                f\"\"\"\n                import pytest\n                {lines[i]}\n                {lines[(i + 1) % 2]}\n                def test_func():\n                    pass\n            \"\"\"\n            )\n            skipped = evaluate_skip_marks(item)\n            assert skipped\n            assert skipped.reason == \"condition: not hasattr(os, 'murks')\"\n\n    def test_marked_one_arg_twice2(self, pytester: Pytester) -> None:\n        item = pytester.getitem(\n            \"\"\"\n            import pytest\n            @pytest.mark.skipif(\"hasattr(os, 'murks')\")\n            @pytest.mark.skipif(\"not hasattr(os, 'murks')\")\n            def test_func():\n                pass\n        \"\"\"\n        )\n        skipped = evaluate_skip_marks(item)\n        assert skipped\n        assert skipped.reason == \"condition: not hasattr(os, 'murks')\"\n\n    def test_marked_skipif_with_boolean_without_reason(\n        self, pytester: Pytester\n    ) -> None:\n        item = pytester.getitem(\n            \"\"\"\n            import pytest\n            @pytest.mark.skipif(False)\n            def test_func():\n                pass\n        \"\"\"\n        )\n        with pytest.raises(pytest.fail.Exception) as excinfo:\n            evaluate_skip_marks(item)\n        assert excinfo.value.msg is not None\n        assert (\n            \"\"\"Error evaluating 'skipif': you need to specify reason=STRING when using booleans as conditions.\"\"\"\n            in excinfo.value.msg\n        )\n\n    def test_marked_skipif_with_invalid_boolean(self, pytester: Pytester) -> None:\n        item = pytester.getitem(\n            \"\"\"\n            import pytest\n\n        "}, {"start_line": 5000, "end_line": 7000, "belongs_to": {"file_name": "test_skipping.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "reason == \"condition: config._hackxyz\"\n\n    def test_skipif_markeval_namespace(self, pytester: Pytester) -> None:\n        pytester.makeconftest(\n            \"\"\"\n            import pytest\n\n            def pytest_markeval_namespace():\n                return {\"color\": \"green\"}\n            \"\"\"\n        )\n        p = pytester.makepyfile(\n            \"\"\"\n            import pytest\n\n            @pytest.mark.skipif(\"color == 'green'\")\n            def test_1():\n                assert True\n\n            @pytest.mark.skipif(\"color == 'red'\")\n            def test_2():\n                assert True\n        \"\"\"\n        )\n        res = pytester.runpytest(p)\n        assert res.ret == 0\n        res.stdout.fnmatch_lines([\"*1 skipped*\"])\n        res.stdout.fnmatch_lines([\"*1 passed*\"])\n\n    def test_skipif_markeval_namespace_multiple(self, pytester: Pytester) -> None:\n        \"\"\"Keys defined by ``pytest_markeval_namespace()`` in nested plugins override top-level ones.\"\"\"\n        root = pytester.mkdir(\"root\")\n        root.joinpath(\"__init__.py\").touch()\n        root.joinpath(\"conftest.py\").write_text(\n            textwrap.dedent(\n                \"\"\"\\\n            import pytest\n\n            def pytest_markeval_namespace():\n                return {\"arg\": \"root\"}\n            \"\"\"\n            ),\n            encoding=\"utf-8\",\n        )\n        root.joinpath(\"test_root.py\").write_text(\n            textwrap.dedent(\n                \"\"\"\\\n            import pytest\n\n            @pytest.mark.skipif(\"arg == 'root'\")\n            def test_root():\n                assert False\n            \"\"\"\n            ),\n            encoding=\"utf-8\",\n        )\n        foo = root.joinpath(\"foo\")\n        foo.mkdir()\n        foo.joinpath(\"__init__.py\").touch()\n        foo.joinpath(\"conftest.py\").write_text(\n            textwrap.dedent(\n                \"\"\"\\\n            import pytest\n\n            def pytest_markeval_namespace():\n                return {\"arg\": \"foo\"}\n            \"\"\"\n            ),\n            encoding=\"utf-8\",\n "}, {"start_line": 7000, "end_line": 9000, "belongs_to": {"file_name": "test_skipping.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "       )\n        foo.joinpath(\"test_foo.py\").write_text(\n            textwrap.dedent(\n                \"\"\"\\\n            import pytest\n\n            @pytest.mark.skipif(\"arg == 'foo'\")\n            def test_foo():\n                assert False\n            \"\"\"\n            ),\n            encoding=\"utf-8\",\n        )\n        bar = root.joinpath(\"bar\")\n        bar.mkdir()\n        bar.joinpath(\"__init__.py\").touch()\n        bar.joinpath(\"conftest.py\").write_text(\n            textwrap.dedent(\n                \"\"\"\\\n            import pytest\n\n            def pytest_markeval_namespace():\n                return {\"arg\": \"bar\"}\n            \"\"\"\n            ),\n            encoding=\"utf-8\",\n        )\n        bar.joinpath(\"test_bar.py\").write_text(\n            textwrap.dedent(\n                \"\"\"\\\n            import pytest\n\n            @pytest.mark.skipif(\"arg == 'bar'\")\n            def test_bar():\n                assert False\n            \"\"\"\n            ),\n            encoding=\"utf-8\",\n        )\n\n        reprec = pytester.inline_run(\"-vs\", \"--capture=no\")\n        reprec.assertoutcome(skipped=3)\n\n    def test_skipif_markeval_namespace_ValueError(self, pytester: Pytester) -> None:\n        pytester.makeconftest(\n            \"\"\"\n            import pytest\n\n            def pytest_markeval_namespace():\n                return True\n            \"\"\"\n        )\n        p = pytester.makepyfile(\n            \"\"\"\n            import pytest\n\n            @pytest.mark.skipif(\"color == 'green'\")\n            def test_1():\n                assert True\n        \"\"\"\n        )\n        res = pytester.runpytest(p)\n        assert res.ret == 1\n        res.stdout.fnmatch_lines(\n            [\n                \"*ValueError: pytest_markeval_namespace() needs to return a dict, got True*\"\n            ]\n        )\n\n\nclass TestXFail:\n    @pytest.mark.parametrize(\"strict\", [True, False])\n    def test_xfail_simple(self, pytester: Pytester, strict: bool) -> None:\n        item = pytester.getitem(\n            f\"\"\"\n            import p"}, {"start_line": 24000, "end_line": 26000, "belongs_to": {"file_name": "test_runner.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "tion == pytest.skip.Exception\n    try:\n        pytest.skip(\"hello\")\n    except pytest.skip.Exception:\n        excinfo = ExceptionInfo.from_current()\n        s = excinfo.exconly(tryshort=True)\n        assert s.startswith(\"Skipped\")\n\n\ndef test_importorskip(monkeypatch) -> None:\n    importorskip = pytest.importorskip\n\n    def f():\n        importorskip(\"asdlkj\")\n\n    try:\n        sysmod = importorskip(\"sys\")\n        assert sysmod is sys\n        # path = pytest.importorskip(\"os.path\")\n        # assert path == os.path\n        excinfo = pytest.raises(pytest.skip.Exception, f)\n        assert excinfo is not None\n        excrepr = excinfo.getrepr()\n        assert excrepr is not None\n        assert excrepr.reprcrash is not None\n        path = Path(excrepr.reprcrash.path)\n        # check that importorskip reports the actual call\n        # in this test the test_runner.py file\n        assert path.stem == \"test_runner\"\n        pytest.raises(SyntaxError, pytest.importorskip, \"x y z\")\n        pytest.raises(SyntaxError, pytest.importorskip, \"x=y\")\n        mod = types.ModuleType(\"hello123\")\n        mod.__version__ = \"1.3\"  # type: ignore\n        monkeypatch.setitem(sys.modules, \"hello123\", mod)\n        with pytest.raises(pytest.skip.Exception):\n            pytest.importorskip(\"hello123\", minversion=\"1.3.1\")\n        mod2 = pytest.importorskip(\"hello123\", minversion=\"1.3\")\n        assert mod2 == mod\n    except pytest.skip.Exception:  # pragma: no cover\n        assert False, f\"spurious skip: {ExceptionInfo.from_current()}\"\n\n\ndef test_importorskip_imports_last_module_part() -> None:\n    ospath = pytest.importorskip(\"os.path\")\n    assert os.path == ospath\n\n\nclass TestImportOrSkipExcType:\n    \"\"\"Tests for #11523.\"\"\"\n\n    def test_no_warning(self) -> None:\n        # An attempt on a module which does not exist will raise ModuleNotFoundError, so it will\n        # be skipped normally and no warning will be issued.\n        with warnings.catch_warnings(record=True) as captured:\n            warnin"}, {"start_line": 16000, "end_line": 18000, "belongs_to": {"file_name": "test_local.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing/_py", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "ecfile.write_text(\"x=42\", encoding=\"utf-8\")\n\n    execfilepy = path.ensure(\"execfile.py\")\n    execfilepy.write_text(\"x=42\", encoding=\"utf-8\")\n\n    d = {1: 2, \"hello\": \"world\", \"answer\": 42}\n    path.ensure(\"samplepickle\").dump(d)\n\n    sampledir = path.ensure(\"sampledir\", dir=1)\n    sampledir.ensure(\"otherfile\")\n\n    otherdir = path.ensure(\"otherdir\", dir=1)\n    otherdir.ensure(\"__init__.py\")\n\n    module_a = otherdir.ensure(\"a.py\")\n    module_a.write_text(\"from .b import stuff as result\\n\", encoding=\"utf-8\")\n    module_b = otherdir.ensure(\"b.py\")\n    module_b.write_text('stuff=\"got it\"\\n', encoding=\"utf-8\")\n    module_c = otherdir.ensure(\"c.py\")\n    module_c.write_text(\n        \"\"\"import py;\nimport otherdir.a\nvalue = otherdir.a.result\n\"\"\",\n        encoding=\"utf-8\",\n    )\n    module_d = otherdir.ensure(\"d.py\")\n    module_d.write_text(\n        \"\"\"import py;\nfrom otherdir import a\nvalue2 = a.result\n\"\"\",\n        encoding=\"utf-8\",\n    )\n\n\nwin32only = pytest.mark.skipif(\n    \"not (sys.platform == 'win32' or getattr(os, '_name', None) == 'nt')\"\n)\nskiponwin32 = pytest.mark.skipif(\n    \"sys.platform == 'win32' or getattr(os, '_name', None) == 'nt'\"\n)\n\nATIME_RESOLUTION = 0.01\n\n\n@pytest.fixture(scope=\"session\")\ndef path1(tmpdir_factory):\n    path = tmpdir_factory.mktemp(\"path\")\n    setuptestfs(path)\n    yield path\n    assert path.join(\"samplefile\").check()\n\n\n@pytest.fixture\ndef fake_fspath_obj(request):\n    class FakeFSPathClass:\n        def __init__(self, path):\n            self._path = path\n\n        def __fspath__(self):\n            return self._path\n\n    return FakeFSPathClass(os.path.join(\"this\", \"is\", \"a\", \"fake\", \"path\"))\n\n\ndef batch_make_numbered_dirs(rootdir, repeats):\n    for i in range(repeats):\n        dir_ = local.make_numbered_dir(prefix=\"repro-\", rootdir=rootdir)\n        file_ = dir_.join(\"foo\")\n        file_.write_text(f\"{i}\", encoding=\"utf-8\")\n        actual = int(file_.read_text(encoding=\"utf-8\"))\n        assert actual == i, (\n            f\"int(file_.read_text(e"}], "retrieved_count": 10, "cost_time": 1.0722243785858154}
{"question": "What is the dependency chain between the TestRequestScopeAccess class, the pytest fixture system, the parametrization mechanism, the Pytester fixture, and the internal request attribute resolution logic that validates request object attributes are correctly scoped?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"start_line": 106000, "end_line": 108000, "belongs_to": {"file_name": "fixtures.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing/python", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": " hash(B) or True\n            \"\"\"\n        )\n        monkeypatch.setenv(\"PYTHONHASHSEED\", \"1\")\n        out1 = pytester.runpytest_subprocess(\"-v\")\n        monkeypatch.setenv(\"PYTHONHASHSEED\", \"2\")\n        out2 = pytester.runpytest_subprocess(\"-v\")\n        output1 = [\n            line\n            for line in out1.outlines\n            if line.startswith(\"test_deterministic_fixture_collection.py::test_foo\")\n        ]\n        output2 = [\n            line\n            for line in out2.outlines\n            if line.startswith(\"test_deterministic_fixture_collection.py::test_foo\")\n        ]\n        assert len(output1) == 12\n        assert output1 == output2\n\n\nclass TestRequestScopeAccess:\n    pytestmark = pytest.mark.parametrize(\n        (\"scope\", \"ok\", \"error\"),\n        [\n            [\"session\", \"\", \"path class function module\"],\n            [\"module\", \"module path\", \"cls function\"],\n            [\"class\", \"module path cls\", \"function\"],\n            [\"function\", \"module path cls function\", \"\"],\n        ],\n    )\n\n    def test_setup(self, pytester: Pytester, scope, ok, error) -> None:\n        pytester.makepyfile(\n            f\"\"\"\n            import pytest\n            @pytest.fixture(scope={scope!r}, autouse=True)\n            def myscoped(request):\n                for x in {ok.split()}:\n                    assert hasattr(request, x)\n                for x in {error.split()}:\n                    pytest.raises(AttributeError, lambda:\n                        getattr(request, x))\n                assert request.session\n                assert request.config\n            def test_func():\n                pass\n        \"\"\"\n        )\n        reprec = pytester.inline_run(\"-l\")\n        reprec.assertoutcome(passed=1)\n\n    def test_funcarg(self, pytester: Pytester, scope, ok, error) -> None:\n        pytester.makepyfile(\n            f\"\"\"\n            import pytest\n            @pytest.fixture(scope={scope!r})\n            def arg(request):\n                for x in {ok.split()!r}:\n                    as"}, {"start_line": 34000, "end_line": 36000, "belongs_to": {"file_name": "fixtures.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing/python", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "d*conftest*\n            *arg1*\n        \"\"\"\n        )\n\n    def test_show_fixtures_color_yes(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\"def test_this(): assert 1\")\n        result = pytester.runpytest(\"--color=yes\", \"--fixtures\")\n        assert \"\\x1b[32mtmp_path\" in result.stdout.str()\n\n    def test_newstyle_with_request(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n            @pytest.fixture()\n            def arg(request):\n                pass\n            def test_1(arg):\n                pass\n        \"\"\"\n        )\n        reprec = pytester.inline_run()\n        reprec.assertoutcome(passed=1)\n\n    def test_setupcontext_no_param(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n            @pytest.fixture(params=[1,2])\n            def arg(request):\n                return request.param\n\n            @pytest.fixture(autouse=True)\n            def mysetup(request, arg):\n                assert not hasattr(request, \"param\")\n            def test_1(arg):\n                assert arg in (1,2)\n        \"\"\"\n        )\n        reprec = pytester.inline_run()\n        reprec.assertoutcome(passed=2)\n\n\nclass TestRequestSessionScoped:\n    @pytest.fixture(scope=\"session\")\n    def session_request(self, request):\n        return request\n\n    @pytest.mark.parametrize(\"name\", [\"path\", \"module\"])\n    def test_session_scoped_unavailable_attributes(self, session_request, name):\n        with pytest.raises(\n            AttributeError,\n            match=f\"{name} not available in session-scoped context\",\n        ):\n            getattr(session_request, name)\n\n\nclass TestRequestMarking:\n    def test_applymarker(self, pytester: Pytester) -> None:\n        item1, item2 = pytester.getitems(\n            \"\"\"\n            import pytest\n\n            @pytest.fixture\n            def something(request):\n                pass\n            class TestClass(object):\n                def test"}, {"start_line": 35000, "end_line": 37000, "belongs_to": {"file_name": "fixtures.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing/python", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "est, arg):\n                assert not hasattr(request, \"param\")\n            def test_1(arg):\n                assert arg in (1,2)\n        \"\"\"\n        )\n        reprec = pytester.inline_run()\n        reprec.assertoutcome(passed=2)\n\n\nclass TestRequestSessionScoped:\n    @pytest.fixture(scope=\"session\")\n    def session_request(self, request):\n        return request\n\n    @pytest.mark.parametrize(\"name\", [\"path\", \"module\"])\n    def test_session_scoped_unavailable_attributes(self, session_request, name):\n        with pytest.raises(\n            AttributeError,\n            match=f\"{name} not available in session-scoped context\",\n        ):\n            getattr(session_request, name)\n\n\nclass TestRequestMarking:\n    def test_applymarker(self, pytester: Pytester) -> None:\n        item1, item2 = pytester.getitems(\n            \"\"\"\n            import pytest\n\n            @pytest.fixture\n            def something(request):\n                pass\n            class TestClass(object):\n                def test_func1(self, something):\n                    pass\n                def test_func2(self, something):\n                    pass\n        \"\"\"\n        )\n        assert isinstance(item1, Function)\n        req1 = TopRequest(item1, _ispytest=True)\n        assert \"xfail\" not in item1.keywords\n        req1.applymarker(pytest.mark.xfail)\n        assert \"xfail\" in item1.keywords\n        assert \"skipif\" not in item1.keywords\n        req1.applymarker(pytest.mark.skipif)\n        assert \"skipif\" in item1.keywords\n        with pytest.raises(ValueError):\n            req1.applymarker(42)  # type: ignore[arg-type]\n\n    def test_accesskeywords(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n            @pytest.fixture()\n            def keywords(request):\n                return request.keywords\n            @pytest.mark.XYZ\n            def test_function(keywords):\n                assert keywords[\"XYZ\"]\n                assert \"abc\" not in keywords\n      "}, {"start_line": 20000, "end_line": 22000, "belongs_to": {"file_name": "fixtures.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing/python", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "      assert result.ret == 0\n\n\nclass TestRequestBasic:\n    def test_request_attributes(self, pytester: Pytester) -> None:\n        item = pytester.getitem(\n            \"\"\"\n            import pytest\n\n            @pytest.fixture\n            def something(request): pass\n            def test_func(something): pass\n        \"\"\"\n        )\n        assert isinstance(item, Function)\n        req = TopRequest(item, _ispytest=True)\n        assert req.function == item.obj\n        assert req.keywords == item.keywords\n        assert hasattr(req.module, \"test_func\")\n        assert req.cls is None\n        assert req.function.__name__ == \"test_func\"\n        assert req.config == item.config\n        assert repr(req).find(req.function.__name__) != -1\n\n    def test_request_attributes_method(self, pytester: Pytester) -> None:\n        (item,) = pytester.getitems(\n            \"\"\"\n            import pytest\n            class TestB(object):\n\n                @pytest.fixture\n                def something(self, request):\n                    return 1\n                def test_func(self, something):\n                    pass\n        \"\"\"\n        )\n        assert isinstance(item, Function)\n        req = item._request\n        assert req.cls.__name__ == \"TestB\"\n        assert req.instance.__class__ == req.cls\n\n    def test_request_contains_funcarg_arg2fixturedefs(self, pytester: Pytester) -> None:\n        modcol = pytester.getmodulecol(\n            \"\"\"\n            import pytest\n            @pytest.fixture\n            def something(request):\n                pass\n            class TestClass(object):\n                def test_method(self, something):\n                    pass\n        \"\"\"\n        )\n        (item1,) = pytester.genitems([modcol])\n        assert isinstance(item1, Function)\n        assert item1.name == \"test_method\"\n        arg2fixturedefs = TopRequest(item1, _ispytest=True)._arg2fixturedefs\n        assert len(arg2fixturedefs) == 1\n        assert arg2fixturedefs[\"something\"][0].argname == \"something\""}, {"start_line": 4000, "end_line": 6000, "belongs_to": {"file_name": "metafunc.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing/python", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "d types are: .*\"\n            ),\n        ):\n            metafunc.parametrize(\"x\", [1, 2, 3], ids=gen())\n\n    def test_parametrize_bad_scope(self) -> None:\n        def func(x):\n            pass\n\n        metafunc = self.Metafunc(func)\n        with pytest.raises(\n            fail.Exception,\n            match=r\"parametrize\\(\\) call in func got an unexpected scope value 'doggy'\",\n        ):\n            metafunc.parametrize(\"x\", [1], scope=\"doggy\")  # type: ignore[arg-type]\n\n    def test_parametrize_request_name(self, pytester: Pytester) -> None:\n        \"\"\"Show proper error  when 'request' is used as a parameter name in parametrize (#6183)\"\"\"\n\n        def func(request):\n            raise NotImplementedError()\n\n        metafunc = self.Metafunc(func)\n        with pytest.raises(\n            fail.Exception,\n            match=r\"'request' is a reserved name and cannot be used in @pytest.mark.parametrize\",\n        ):\n            metafunc.parametrize(\"request\", [1])\n\n    def test_find_parametrized_scope(self) -> None:\n        \"\"\"Unit test for _find_parametrized_scope (#3941).\"\"\"\n        from _pytest.python import _find_parametrized_scope\n\n        @dataclasses.dataclass\n        class DummyFixtureDef:\n            _scope: Scope\n\n        fixtures_defs = cast(\n            dict[str, Sequence[fixtures.FixtureDef[object]]],\n            dict(\n                session_fix=[DummyFixtureDef(Scope.Session)],\n                package_fix=[DummyFixtureDef(Scope.Package)],\n                module_fix=[DummyFixtureDef(Scope.Module)],\n                class_fix=[DummyFixtureDef(Scope.Class)],\n                func_fix=[DummyFixtureDef(Scope.Function)],\n                mixed_fix=[DummyFixtureDef(Scope.Module), DummyFixtureDef(Scope.Class)],\n            ),\n        )\n\n        # use arguments to determine narrow scope; the cause of the bug is that it would look on all\n        # fixture defs given to the method\n        def find_scope(argnames, indirect):\n            return _find_parametrized_scope(argnames,"}, {"start_line": 14000, "end_line": 16000, "belongs_to": {"file_name": "fixtures.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "he fixture is parametrized.\n    \"\"\"\n\n    def __init__(\n        self,\n        pyfuncitem: Function,\n        fixturename: str | None,\n        arg2fixturedefs: dict[str, Sequence[FixtureDef[Any]]],\n        fixture_defs: dict[str, FixtureDef[Any]],\n        *,\n        _ispytest: bool = False,\n    ) -> None:\n        check_ispytest(_ispytest)\n        #: Fixture for which this request is being performed.\n        self.fixturename: Final = fixturename\n        self._pyfuncitem: Final = pyfuncitem\n        # The FixtureDefs for each fixture name requested by this item.\n        # Starts from the statically-known fixturedefs resolved during\n        # collection. Dynamically requested fixtures (using\n        # `request.getfixturevalue(\"foo\")`) are added dynamically.\n        self._arg2fixturedefs: Final = arg2fixturedefs\n        # The evaluated argnames so far, mapping to the FixtureDef they resolved\n        # to.\n        self._fixture_defs: Final = fixture_defs\n        # Notes on the type of `param`:\n        # -`request.param` is only defined in parametrized fixtures, and will raise\n        #   AttributeError otherwise. Python typing has no notion of \"undefined\", so\n        #   this cannot be reflected in the type.\n        # - Technically `param` is only (possibly) defined on SubRequest, not\n        #   FixtureRequest, but the typing of that is still in flux so this cheats.\n        # - In the future we might consider using a generic for the param type, but\n        #   for now just using Any.\n        self.param: Any\n\n    @property\n    def _fixturemanager(self) -> FixtureManager:\n        return self._pyfuncitem.session._fixturemanager\n\n    @property\n    @abc.abstractmethod\n    def _scope(self) -> Scope:\n        raise NotImplementedError()\n\n    @property\n    def scope(self) -> _ScopeName:\n        \"\"\"Scope string, one of \"function\", \"class\", \"module\", \"package\", \"session\".\"\"\"\n        return self._scope.value\n\n    @abc.abstractmethod\n    def _check_scope(\n        self,\n        requested"}, {"start_line": 13000, "end_line": 15000, "belongs_to": {"file_name": "fixtures.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "        working_set = set(self.initialnames)\n        while working_set:\n            argname = working_set.pop()\n            # Argname may be something not included in the original names_closure,\n            # in which case we ignore it. This currently happens with pseudo\n            # FixtureDefs which wrap 'get_direct_param_fixture_func(request)'.\n            # So they introduce the new dependency 'request' which might have\n            # been missing in the original tree (closure).\n            if argname not in closure and argname in self.names_closure:\n                closure.add(argname)\n                if argname in self.name2fixturedefs:\n                    working_set.update(self.name2fixturedefs[argname][-1].argnames)\n\n        self.names_closure[:] = sorted(closure, key=self.names_closure.index)\n\n\nclass FixtureRequest(abc.ABC):\n    \"\"\"The type of the ``request`` fixture.\n\n    A request object gives access to the requesting test context and has a\n    ``param`` attribute in case the fixture is parametrized.\n    \"\"\"\n\n    def __init__(\n        self,\n        pyfuncitem: Function,\n        fixturename: str | None,\n        arg2fixturedefs: dict[str, Sequence[FixtureDef[Any]]],\n        fixture_defs: dict[str, FixtureDef[Any]],\n        *,\n        _ispytest: bool = False,\n    ) -> None:\n        check_ispytest(_ispytest)\n        #: Fixture for which this request is being performed.\n        self.fixturename: Final = fixturename\n        self._pyfuncitem: Final = pyfuncitem\n        # The FixtureDefs for each fixture name requested by this item.\n        # Starts from the statically-known fixturedefs resolved during\n        # collection. Dynamically requested fixtures (using\n        # `request.getfixturevalue(\"foo\")`) are added dynamically.\n        self._arg2fixturedefs: Final = arg2fixturedefs\n        # The evaluated argnames so far, mapping to the FixtureDef they resolved\n        # to.\n        self._fixture_defs: Final = fixture_defs\n        # Notes on the type of `param`:\n"}, {"start_line": 15000, "end_line": 17000, "belongs_to": {"file_name": "fixtures.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "        # -`request.param` is only defined in parametrized fixtures, and will raise\n        #   AttributeError otherwise. Python typing has no notion of \"undefined\", so\n        #   this cannot be reflected in the type.\n        # - Technically `param` is only (possibly) defined on SubRequest, not\n        #   FixtureRequest, but the typing of that is still in flux so this cheats.\n        # - In the future we might consider using a generic for the param type, but\n        #   for now just using Any.\n        self.param: Any\n\n    @property\n    def _fixturemanager(self) -> FixtureManager:\n        return self._pyfuncitem.session._fixturemanager\n\n    @property\n    @abc.abstractmethod\n    def _scope(self) -> Scope:\n        raise NotImplementedError()\n\n    @property\n    def scope(self) -> _ScopeName:\n        \"\"\"Scope string, one of \"function\", \"class\", \"module\", \"package\", \"session\".\"\"\"\n        return self._scope.value\n\n    @abc.abstractmethod\n    def _check_scope(\n        self,\n        requested_fixturedef: FixtureDef[object] | PseudoFixtureDef[object],\n        requested_scope: Scope,\n    ) -> None:\n        raise NotImplementedError()\n\n    @property\n    def fixturenames(self) -> list[str]:\n        \"\"\"Names of all active fixtures in this request.\"\"\"\n        result = list(self._pyfuncitem.fixturenames)\n        result.extend(set(self._fixture_defs).difference(result))\n        return result\n\n    @property\n    @abc.abstractmethod\n    def node(self):\n        \"\"\"Underlying collection node (depends on current request scope).\"\"\"\n        raise NotImplementedError()\n\n    @property\n    def config(self) -> Config:\n        \"\"\"The pytest config object associated with this request.\"\"\"\n        return self._pyfuncitem.config\n\n    @property\n    def function(self):\n        \"\"\"Test function object if the request has a per-function scope.\"\"\"\n        if self.scope != \"function\":\n            raise AttributeError(\n                f\"function not available in {self.scope}-scoped context\"\n            )\n"}, {"start_line": 21000, "end_line": 23000, "belongs_to": {"file_name": "fixtures.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing/python", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "):\n                    return 1\n                def test_func(self, something):\n                    pass\n        \"\"\"\n        )\n        assert isinstance(item, Function)\n        req = item._request\n        assert req.cls.__name__ == \"TestB\"\n        assert req.instance.__class__ == req.cls\n\n    def test_request_contains_funcarg_arg2fixturedefs(self, pytester: Pytester) -> None:\n        modcol = pytester.getmodulecol(\n            \"\"\"\n            import pytest\n            @pytest.fixture\n            def something(request):\n                pass\n            class TestClass(object):\n                def test_method(self, something):\n                    pass\n        \"\"\"\n        )\n        (item1,) = pytester.genitems([modcol])\n        assert isinstance(item1, Function)\n        assert item1.name == \"test_method\"\n        arg2fixturedefs = TopRequest(item1, _ispytest=True)._arg2fixturedefs\n        assert len(arg2fixturedefs) == 1\n        assert arg2fixturedefs[\"something\"][0].argname == \"something\"\n\n    @pytest.mark.skipif(\n        hasattr(sys, \"pypy_version_info\"),\n        reason=\"this method of test doesn't work on pypy\",\n    )\n    def test_request_garbage(self, pytester: Pytester) -> None:\n        try:\n            import xdist  # noqa: F401\n        except ImportError:\n            pass\n        else:\n            pytest.xfail(\"this test is flaky when executed with xdist\")\n        pytester.makepyfile(\n            \"\"\"\n            import sys\n            import pytest\n            from _pytest.fixtures import PseudoFixtureDef\n            import gc\n\n            @pytest.fixture(autouse=True)\n            def something(request):\n                original = gc.get_debug()\n                gc.set_debug(gc.DEBUG_SAVEALL)\n                gc.collect()\n\n                yield\n\n                try:\n                    gc.collect()\n                    leaked = [x for _ in gc.garbage if isinstance(_, PseudoFixtureDef)]\n                    assert leaked == []\n                finally:\n                "}, {"start_line": 144000, "end_line": 146000, "belongs_to": {"file_name": "fixtures.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing/python", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "t(\"-v\")\n    result.assert_outcomes(passed=4)\n    result.stdout.fnmatch_lines([\"*::test_direct[[]1[]]*\"])\n    result.stdout.fnmatch_lines([\"*::test_normal_fixture[[]a[]]*\"])\n    result.stdout.fnmatch_lines([\"*::test_normal_fixture[[]b[]]*\"])\n    result.stdout.fnmatch_lines([\"*::test_indirect[[]1[]]*\"])\n\n\ndef test_fixture_named_request(pytester: Pytester) -> None:\n    pytester.copy_example(\"fixtures/test_fixture_named_request.py\")\n    result = pytester.runpytest()\n    result.stdout.fnmatch_lines(\n        [\n            \"*'request' is a reserved word for fixtures, use another name:\",\n            \"  *test_fixture_named_request.py:8\",\n        ]\n    )\n\n\ndef test_indirect_fixture_does_not_break_scope(pytester: Pytester) -> None:\n    \"\"\"Ensure that fixture scope is respected when using indirect fixtures (#570)\"\"\"\n    pytester.makepyfile(\n        \"\"\"\n        import pytest\n        instantiated  = []\n\n        @pytest.fixture(scope=\"session\")\n        def fixture_1(request):\n            instantiated.append((\"fixture_1\", request.param))\n\n\n        @pytest.fixture(scope=\"session\")\n        def fixture_2(request):\n            instantiated.append((\"fixture_2\", request.param))\n\n\n        scenarios = [\n            (\"A\", \"a1\"),\n            (\"A\", \"a2\"),\n            (\"B\", \"b1\"),\n            (\"B\", \"b2\"),\n            (\"C\", \"c1\"),\n            (\"C\", \"c2\"),\n        ]\n\n        @pytest.mark.parametrize(\n            \"fixture_1,fixture_2\", scenarios, indirect=[\"fixture_1\", \"fixture_2\"]\n        )\n        def test_create_fixtures(fixture_1, fixture_2):\n            pass\n\n\n        def test_check_fixture_instantiations():\n            assert instantiated == [\n                ('fixture_1', 'A'),\n                ('fixture_2', 'a1'),\n                ('fixture_2', 'a2'),\n                ('fixture_1', 'B'),\n                ('fixture_2', 'b1'),\n                ('fixture_2', 'b2'),\n                ('fixture_1', 'C'),\n                ('fixture_2', 'c1'),\n                ('fixture_2', 'c2'),\n            ]\n    \"\"\"\n "}], "retrieved_count": 10, "cost_time": 1.0893619060516357}
{"question": "What is the architectural separation in the pytest fixture resolution system that decouples fixture discovery and validation to enable the error reporting mechanism that distinguishes between missing fixtures and internal failures?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"start_line": 52000, "end_line": 54000, "belongs_to": {"file_name": "fixtures.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing/python", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "               return request._fixturemanager\n\n            @pytest.fixture\n            def item(request):\n                return request._pyfuncitem\n        \"\"\"\n        )\n        return pytester\n\n    def test_parsefactories_evil_objects_issue214(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            class A(object):\n                def __call__(self):\n                    pass\n                def __getattr__(self, name):\n                    raise RuntimeError()\n            a = A()\n            def test_hello():\n                pass\n        \"\"\"\n        )\n        reprec = pytester.inline_run()\n        reprec.assertoutcome(passed=1, failed=0)\n\n    def test_parsefactories_conftest(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            def test_hello(item, fm):\n                for name in (\"fm\", \"hello\", \"item\"):\n                    faclist = fm.getfixturedefs(name, item)\n                    assert len(faclist) == 1\n                    fac = faclist[0]\n                    assert fac.func.__name__ == name\n        \"\"\"\n        )\n        reprec = pytester.inline_run(\"-s\")\n        reprec.assertoutcome(passed=1)\n\n    def test_parsefactories_conftest_and_module_and_class(\n        self, pytester: Pytester\n    ) -> None:\n        pytester.makepyfile(\n            \"\"\"\\\n            import pytest\n\n            @pytest.fixture\n            def hello(request):\n                return \"module\"\n            class TestClass(object):\n                @pytest.fixture\n                def hello(self, request):\n                    return \"class\"\n                def test_hello(self, item, fm):\n                    faclist = fm.getfixturedefs(\"hello\", item)\n                    print(faclist)\n                    assert len(faclist) == 3\n\n                    assert faclist[0].func(item._request) == \"conftest\"\n                    assert faclist[1].func(item._request) == \"module\"\n                    assert faclist[2].func(item._request"}, {"start_line": 18000, "end_line": 20000, "belongs_to": {"file_name": "fixtures.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing/python", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "\n                assert request.function.foo == 7\n        \"\"\"\n        )\n        result = pytester.runpytest()\n        assert result.ret == 0\n\n    def test_funcarg_lookup_error(self, pytester: Pytester) -> None:\n        pytester.makeconftest(\n            \"\"\"\n            import pytest\n\n            @pytest.fixture\n            def a_fixture(): pass\n\n            @pytest.fixture\n            def b_fixture(): pass\n\n            @pytest.fixture\n            def c_fixture(): pass\n\n            @pytest.fixture\n            def d_fixture(): pass\n        \"\"\"\n        )\n        pytester.makepyfile(\n            \"\"\"\n            def test_lookup_error(unknown):\n                pass\n        \"\"\"\n        )\n        result = pytester.runpytest()\n        result.stdout.fnmatch_lines(\n            [\n                \"*ERROR at setup of test_lookup_error*\",\n                \"  def test_lookup_error(unknown):*\",\n                \"E       fixture 'unknown' not found\",\n                \">       available fixtures:*a_fixture,*b_fixture,*c_fixture,*d_fixture*monkeypatch,*\",\n                # sorted\n                \">       use 'py*test --fixtures *' for help on them.\",\n                \"*1 error*\",\n            ]\n        )\n        result.stdout.no_fnmatch_line(\"*INTERNAL*\")\n\n    def test_fixture_excinfo_leak(self, pytester: Pytester) -> None:\n        # on python2 sys.excinfo would leak into fixture executions\n        pytester.makepyfile(\n            \"\"\"\n            import sys\n            import traceback\n            import pytest\n\n            @pytest.fixture\n            def leak():\n                if sys.exc_info()[0]:  # python3 bug :)\n                    traceback.print_exc()\n                #fails\n                assert sys.exc_info() == (None, None, None)\n\n            def test_leak(leak):\n                if sys.exc_info()[0]:  # python3 bug :)\n                    traceback.print_exc()\n                assert sys.exc_info() == (None, None, None)\n        \"\"\"\n        )\n        result = pytester.runpytest()\n  "}, {"start_line": 47000, "end_line": 49000, "belongs_to": {"file_name": "fixtures.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "(fixturefunc, request, kwargs)\n    except TEST_OUTCOME as e:\n        if isinstance(e, skip.Exception):\n            # The test requested a fixture which caused a skip.\n            # Don't show the fixture as the skip location, as then the user\n            # wouldn't know which test skipped.\n            e._use_item_location = True\n        fixturedef.cached_result = (None, my_cache_key, (e, e.__traceback__))\n        raise\n    fixturedef.cached_result = (result, my_cache_key, None)\n    return result\n\n\n@final\n@dataclasses.dataclass(frozen=True)\nclass FixtureFunctionMarker:\n    scope: _ScopeName | Callable[[str, Config], _ScopeName]\n    params: tuple[object, ...] | None\n    autouse: bool = False\n    ids: tuple[object | None, ...] | Callable[[Any], object | None] | None = None\n    name: str | None = None\n\n    _ispytest: dataclasses.InitVar[bool] = False\n\n    def __post_init__(self, _ispytest: bool) -> None:\n        check_ispytest(_ispytest)\n\n    def __call__(self, function: FixtureFunction) -> FixtureFunctionDefinition:\n        if inspect.isclass(function):\n            raise ValueError(\"class fixtures not supported (maybe in the future)\")\n\n        if isinstance(function, FixtureFunctionDefinition):\n            raise ValueError(\n                f\"@pytest.fixture is being applied more than once to the same function {function.__name__!r}\"\n            )\n\n        if hasattr(function, \"pytestmark\"):\n            warnings.warn(MARKED_FIXTURE, stacklevel=2)\n\n        fixture_definition = FixtureFunctionDefinition(\n            function=function, fixture_function_marker=self, _ispytest=True\n        )\n\n        name = self.name or function.__name__\n        if name == \"request\":\n            location = getlocation(function)\n            fail(\n                f\"'request' is a reserved word for fixtures, use another name:\\n  {location}\",\n                pytrace=False,\n            )\n\n        return fixture_definition\n\n\n# TODO: paramspec/return type annotation tracking and storing\nclass Fixtur"}, {"start_line": 110000, "end_line": 112000, "belongs_to": {"file_name": "fixtures.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing/python", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "\n                return 1\n            def test_something():\n                pass\n        \"\"\"\n        )\n        result = pytester.runpytest()\n        assert result.ret != 0\n        result.stdout.fnmatch_lines(\n            [\"*def gen(qwe123):*\", \"*fixture*qwe123*not found*\", \"*1 error*\"]\n        )\n\n    def test_cached_exception_doesnt_get_longer(self, pytester: Pytester) -> None:\n        \"\"\"Regression test for #12204.\"\"\"\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n            @pytest.fixture(scope=\"session\")\n            def bad(): 1 / 0\n\n            def test_1(bad): pass\n            def test_2(bad): pass\n            def test_3(bad): pass\n            \"\"\"\n        )\n\n        result = pytester.runpytest_inprocess(\"--tb=native\")\n        assert result.ret == ExitCode.TESTS_FAILED\n        failures = result.reprec.getfailures()  # type: ignore[attr-defined]\n        assert len(failures) == 3\n        lines1 = failures[1].longrepr.reprtraceback.reprentries[0].lines\n        lines2 = failures[2].longrepr.reprtraceback.reprentries[0].lines\n        assert len(lines1) == len(lines2)\n\n\nclass TestShowFixtures:\n    def test_funcarg_compat(self, pytester: Pytester) -> None:\n        config = pytester.parseconfigure(\"--funcargs\")\n        assert config.option.showfixtures\n\n    def test_show_help(self, pytester: Pytester) -> None:\n        result = pytester.runpytest(\"--fixtures\", \"--help\")\n        assert not result.ret\n\n    def test_show_fixtures(self, pytester: Pytester) -> None:\n        result = pytester.runpytest(\"--fixtures\")\n        result.stdout.fnmatch_lines(\n            [\n                \"tmp_path_factory [[]session scope[]] -- .../_pytest/tmpdir.py:*\",\n                \"*for the test session*\",\n                \"tmp_path -- .../_pytest/tmpdir.py:*\",\n                \"*temporary directory*\",\n            ]\n        )\n\n    def test_show_fixtures_verbose(self, pytester: Pytester) -> None:\n        result = pytester.runpytest(\"--fixtures\", \"-v\")\n        result.stdou"}, {"start_line": 44000, "end_line": 46000, "belongs_to": {"file_name": "fixtures.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "t=request)\n        for parent_fixture in requested_fixtures_that_should_finalize_us:\n            parent_fixture.addfinalizer(finalizer)\n\n        ihook = request.node.ihook\n        try:\n            # Setup the fixture, run the code in it, and cache the value\n            # in self.cached_result.\n            result: FixtureValue = ihook.pytest_fixture_setup(\n                fixturedef=self, request=request\n            )\n        finally:\n            # Schedule our finalizer, even if the setup failed.\n            request.node.addfinalizer(finalizer)\n\n        return result\n\n    def cache_key(self, request: SubRequest) -> object:\n        return getattr(request, \"param\", None)\n\n    def __repr__(self) -> str:\n        return f\"<FixtureDef argname={self.argname!r} scope={self.scope!r} baseid={self.baseid!r}>\"\n\n\ndef resolve_fixture_function(\n    fixturedef: FixtureDef[FixtureValue], request: FixtureRequest\n) -> _FixtureFunc[FixtureValue]:\n    \"\"\"Get the actual callable that can be called to obtain the fixture\n    value.\"\"\"\n    fixturefunc = fixturedef.func\n    # The fixture function needs to be bound to the actual\n    # request.instance so that code working with \"fixturedef\" behaves\n    # as expected.\n    instance = request.instance\n    if instance is not None:\n        # Handle the case where fixture is defined not in a test class, but some other class\n        # (for example a plugin class with a fixture), see #2270.\n        if hasattr(fixturefunc, \"__self__\") and not isinstance(\n            instance,\n            fixturefunc.__self__.__class__,\n        ):\n            return fixturefunc\n        fixturefunc = getimfunc(fixturedef.func)\n        if fixturefunc != fixturedef.func:\n            fixturefunc = fixturefunc.__get__(instance)\n    return fixturefunc\n\n\ndef pytest_fixture_setup(\n    fixturedef: FixtureDef[FixtureValue], request: SubRequest\n) -> FixtureValue:\n    \"\"\"Execution of fixture setup.\"\"\"\n    kwargs = {}\n    for argname in fixturedef.argnames:\n        kwargs[argname] ="}, {"start_line": 43000, "end_line": 45000, "belongs_to": {"file_name": "fixtures.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "y arrays -- #6497).\n                cache_hit = bool(request_cache_key == cache_key)\n            except (ValueError, RuntimeError):\n                # If the comparison raises, use 'is' as fallback.\n                cache_hit = request_cache_key is cache_key\n\n            if cache_hit:\n                if self.cached_result[2] is not None:\n                    exc, exc_tb = self.cached_result[2]\n                    raise exc.with_traceback(exc_tb)\n                else:\n                    return self.cached_result[0]\n            # We have a previous but differently parametrized fixture instance\n            # so we need to tear it down before creating a new one.\n            self.finish(request)\n            assert self.cached_result is None\n\n        # Add finalizer to requested fixtures we saved previously.\n        # We make sure to do this after checking for cached value to avoid\n        # adding our finalizer multiple times. (#12135)\n        finalizer = functools.partial(self.finish, request=request)\n        for parent_fixture in requested_fixtures_that_should_finalize_us:\n            parent_fixture.addfinalizer(finalizer)\n\n        ihook = request.node.ihook\n        try:\n            # Setup the fixture, run the code in it, and cache the value\n            # in self.cached_result.\n            result: FixtureValue = ihook.pytest_fixture_setup(\n                fixturedef=self, request=request\n            )\n        finally:\n            # Schedule our finalizer, even if the setup failed.\n            request.node.addfinalizer(finalizer)\n\n        return result\n\n    def cache_key(self, request: SubRequest) -> object:\n        return getattr(request, \"param\", None)\n\n    def __repr__(self) -> str:\n        return f\"<FixtureDef argname={self.argname!r} scope={self.scope!r} baseid={self.baseid!r}>\"\n\n\ndef resolve_fixture_function(\n    fixturedef: FixtureDef[FixtureValue], request: FixtureRequest\n) -> _FixtureFunc[FixtureValue]:\n    \"\"\"Get the actual callable that can be called to obtain"}, {"start_line": 53000, "end_line": 55000, "belongs_to": {"file_name": "fixtures.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing/python", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "                 fac = faclist[0]\n                    assert fac.func.__name__ == name\n        \"\"\"\n        )\n        reprec = pytester.inline_run(\"-s\")\n        reprec.assertoutcome(passed=1)\n\n    def test_parsefactories_conftest_and_module_and_class(\n        self, pytester: Pytester\n    ) -> None:\n        pytester.makepyfile(\n            \"\"\"\\\n            import pytest\n\n            @pytest.fixture\n            def hello(request):\n                return \"module\"\n            class TestClass(object):\n                @pytest.fixture\n                def hello(self, request):\n                    return \"class\"\n                def test_hello(self, item, fm):\n                    faclist = fm.getfixturedefs(\"hello\", item)\n                    print(faclist)\n                    assert len(faclist) == 3\n\n                    assert faclist[0].func(item._request) == \"conftest\"\n                    assert faclist[1].func(item._request) == \"module\"\n                    assert faclist[2].func(item._request) == \"class\"\n            \"\"\"\n        )\n        reprec = pytester.inline_run(\"-s\")\n        reprec.assertoutcome(passed=1)\n\n    def test_parsefactories_relative_node_ids(\n        self, pytester: Pytester, monkeypatch: MonkeyPatch\n    ) -> None:\n        # example mostly taken from:\n        # https://mail.python.org/pipermail/pytest-dev/2014-September/002617.html\n        runner = pytester.mkdir(\"runner\")\n        package = pytester.mkdir(\"package\")\n        package.joinpath(\"conftest.py\").write_text(\n            textwrap.dedent(\n                \"\"\"\\\n            import pytest\n            @pytest.fixture\n            def one():\n                return 1\n            \"\"\"\n            ),\n            encoding=\"utf-8\",\n        )\n        package.joinpath(\"test_x.py\").write_text(\n            textwrap.dedent(\n                \"\"\"\\\n                def test_x(one):\n                    assert one == 1\n                \"\"\"\n            ),\n            encoding=\"utf-8\",\n        )\n        sub = package.joinpath(\"s"}, {"start_line": 19000, "end_line": 21000, "belongs_to": {"file_name": "fixtures.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing/python", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "*b_fixture,*c_fixture,*d_fixture*monkeypatch,*\",\n                # sorted\n                \">       use 'py*test --fixtures *' for help on them.\",\n                \"*1 error*\",\n            ]\n        )\n        result.stdout.no_fnmatch_line(\"*INTERNAL*\")\n\n    def test_fixture_excinfo_leak(self, pytester: Pytester) -> None:\n        # on python2 sys.excinfo would leak into fixture executions\n        pytester.makepyfile(\n            \"\"\"\n            import sys\n            import traceback\n            import pytest\n\n            @pytest.fixture\n            def leak():\n                if sys.exc_info()[0]:  # python3 bug :)\n                    traceback.print_exc()\n                #fails\n                assert sys.exc_info() == (None, None, None)\n\n            def test_leak(leak):\n                if sys.exc_info()[0]:  # python3 bug :)\n                    traceback.print_exc()\n                assert sys.exc_info() == (None, None, None)\n        \"\"\"\n        )\n        result = pytester.runpytest()\n        assert result.ret == 0\n\n\nclass TestRequestBasic:\n    def test_request_attributes(self, pytester: Pytester) -> None:\n        item = pytester.getitem(\n            \"\"\"\n            import pytest\n\n            @pytest.fixture\n            def something(request): pass\n            def test_func(something): pass\n        \"\"\"\n        )\n        assert isinstance(item, Function)\n        req = TopRequest(item, _ispytest=True)\n        assert req.function == item.obj\n        assert req.keywords == item.keywords\n        assert hasattr(req.module, \"test_func\")\n        assert req.cls is None\n        assert req.function.__name__ == \"test_func\"\n        assert req.config == item.config\n        assert repr(req).find(req.function.__name__) != -1\n\n    def test_request_attributes_method(self, pytester: Pytester) -> None:\n        (item,) = pytester.getitems(\n            \"\"\"\n            import pytest\n            class TestB(object):\n\n                @pytest.fixture\n                def something(self, request"}, {"start_line": 31000, "end_line": 33000, "belongs_to": {"file_name": "fixtures.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "finalizer(finalizer)\n\n\n@final\nclass FixtureLookupError(LookupError):\n    \"\"\"Could not return a requested fixture (missing or invalid).\"\"\"\n\n    def __init__(\n        self, argname: str | None, request: FixtureRequest, msg: str | None = None\n    ) -> None:\n        self.argname = argname\n        self.request = request\n        self.fixturestack = request._get_fixturestack()\n        self.msg = msg\n\n    def formatrepr(self) -> FixtureLookupErrorRepr:\n        tblines: list[str] = []\n        addline = tblines.append\n        stack = [self.request._pyfuncitem.obj]\n        stack.extend(map(lambda x: x.func, self.fixturestack))\n        msg = self.msg\n        # This function currently makes an assumption that a non-None msg means we\n        # have a non-empty `self.fixturestack`. This is currently true, but if\n        # somebody at some point want to extend the use of FixtureLookupError to\n        # new cases it might break.\n        # Add the assert to make it clearer to developer that this will fail, otherwise\n        # it crashes because `fspath` does not get set due to `stack` being empty.\n        assert self.msg is None or self.fixturestack, (\n            \"formatrepr assumptions broken, rewrite it to handle it\"\n        )\n        if msg is not None:\n            # The last fixture raise an error, let's present\n            # it at the requesting side.\n            stack = stack[:-1]\n        for function in stack:\n            fspath, lineno = getfslineno(function)\n            try:\n                lines, _ = inspect.getsourcelines(get_real_func(function))\n            except (OSError, IndexError, TypeError):\n                error_msg = \"file %s, line %s: source code not available\"\n                addline(error_msg % (fspath, lineno + 1))\n            else:\n                addline(f\"file {fspath}, line {lineno + 1}\")\n                for i, line in enumerate(lines):\n                    line = line.rstrip()\n                    addline(\"  \" + line)\n                    if line.lstrip().s"}, {"start_line": 108000, "end_line": 110000, "belongs_to": {"file_name": "fixtures.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing/python", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "sert hasattr(request, x)\n                for x in {error.split()!r}:\n                    pytest.raises(AttributeError, lambda:\n                        getattr(request, x))\n                assert request.session\n                assert request.config\n            def test_func(arg):\n                pass\n        \"\"\"\n        )\n        reprec = pytester.inline_run()\n        reprec.assertoutcome(passed=1)\n\n\nclass TestErrors:\n    def test_subfactory_missing_funcarg(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n            @pytest.fixture()\n            def gen(qwe123):\n                return 1\n            def test_something(gen):\n                pass\n        \"\"\"\n        )\n        result = pytester.runpytest()\n        assert result.ret != 0\n        result.stdout.fnmatch_lines(\n            [\"*def gen(qwe123):*\", \"*fixture*qwe123*not found*\", \"*1 error*\"]\n        )\n\n    def test_issue498_fixture_finalizer_failing(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n            @pytest.fixture\n            def fix1(request):\n                def f():\n                    raise KeyError\n                request.addfinalizer(f)\n                return object()\n\n            values = []\n            def test_1(fix1):\n                values.append(fix1)\n            def test_2(fix1):\n                values.append(fix1)\n            def test_3():\n                assert values[0] != values[1]\n        \"\"\"\n        )\n        result = pytester.runpytest()\n        result.stdout.fnmatch_lines(\n            \"\"\"\n            *ERROR*teardown*test_1*\n            *KeyError*\n            *ERROR*teardown*test_2*\n            *KeyError*\n            *3 pass*2 errors*\n        \"\"\"\n        )\n\n    def test_setupfunc_missing_funcarg(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n            @pytest.fixture(autouse=True)\n            def gen(qwe123):"}], "retrieved_count": 10, "cost_time": 1.0950002670288086}
{"question": "What is the defensive layering pattern established by the exception handling architecture in _format_repr_exception to prevent cascading failures when repr() operations fail during error reporting?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"start_line": 2000, "end_line": 4000, "belongs_to": {"file_name": "saferepr.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest/_io", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "      except BaseException as exc:\n            s = _format_repr_exception(exc, x)\n        if self.maxsize is not None:\n            s = _ellipsize(s, self.maxsize)\n        return s\n\n    def repr_instance(self, x: object, level: int) -> str:\n        try:\n            s = repr(x)\n        except (KeyboardInterrupt, SystemExit):\n            raise\n        except BaseException as exc:\n            s = _format_repr_exception(exc, x)\n        if self.maxsize is not None:\n            s = _ellipsize(s, self.maxsize)\n        return s\n\n\ndef safeformat(obj: object) -> str:\n    \"\"\"Return a pretty printed string for the given object.\n\n    Failing __repr__ functions of user instances will be represented\n    with a short exception info.\n    \"\"\"\n    try:\n        return pprint.pformat(obj)\n    except Exception as exc:\n        return _format_repr_exception(exc, obj)\n\n\n# Maximum size of overall repr of objects to display during assertion errors.\nDEFAULT_REPR_MAX_SIZE = 240\n\n\ndef saferepr(\n    obj: object, maxsize: int | None = DEFAULT_REPR_MAX_SIZE, use_ascii: bool = False\n) -> str:\n    \"\"\"Return a size-limited safe repr-string for the given object.\n\n    Failing __repr__ functions of user instances will be represented\n    with a short exception info and 'saferepr' generally takes\n    care to never raise exceptions itself.\n\n    This function is a wrapper around the Repr/reprlib functionality of the\n    stdlib.\n    \"\"\"\n    return SafeRepr(maxsize, use_ascii).repr(obj)\n\n\ndef saferepr_unlimited(obj: object, use_ascii: bool = True) -> str:\n    \"\"\"Return an unlimited-size safe repr-string for the given object.\n\n    As with saferepr, failing __repr__ functions of user instances\n    will be represented with a short exception info.\n\n    This function is a wrapper around simple repr.\n\n    Note: a cleaner solution would be to alter ``saferepr``this way\n    when maxsize=None, but that might affect some other code.\n    \"\"\"\n    try:\n        if use_ascii:\n            return ascii(obj)\n        return repr("}, {"start_line": 1000, "end_line": 3000, "belongs_to": {"file_name": "saferepr.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest/_io", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "rmation on exceptions raised during the call.\n    \"\"\"\n\n    def __init__(self, maxsize: int | None, use_ascii: bool = False) -> None:\n        \"\"\"\n        :param maxsize:\n            If not None, will truncate the resulting repr to that specific size, using ellipsis\n            somewhere in the middle to hide the extra text.\n            If None, will not impose any size limits on the returning repr.\n        \"\"\"\n        super().__init__()\n        # ``maxstring`` is used by the superclass, and needs to be an int; using a\n        # very large number in case maxsize is None, meaning we want to disable\n        # truncation.\n        self.maxstring = maxsize if maxsize is not None else 1_000_000_000\n        self.maxsize = maxsize\n        self.use_ascii = use_ascii\n\n    def repr(self, x: object) -> str:\n        try:\n            if self.use_ascii:\n                s = ascii(x)\n            else:\n                s = super().repr(x)\n        except (KeyboardInterrupt, SystemExit):\n            raise\n        except BaseException as exc:\n            s = _format_repr_exception(exc, x)\n        if self.maxsize is not None:\n            s = _ellipsize(s, self.maxsize)\n        return s\n\n    def repr_instance(self, x: object, level: int) -> str:\n        try:\n            s = repr(x)\n        except (KeyboardInterrupt, SystemExit):\n            raise\n        except BaseException as exc:\n            s = _format_repr_exception(exc, x)\n        if self.maxsize is not None:\n            s = _ellipsize(s, self.maxsize)\n        return s\n\n\ndef safeformat(obj: object) -> str:\n    \"\"\"Return a pretty printed string for the given object.\n\n    Failing __repr__ functions of user instances will be represented\n    with a short exception info.\n    \"\"\"\n    try:\n        return pprint.pformat(obj)\n    except Exception as exc:\n        return _format_repr_exception(exc, obj)\n\n\n# Maximum size of overall repr of objects to display during assertion errors.\nDEFAULT_REPR_MAX_SIZE = 240\n\n\ndef saferepr(\n    obj: object, maxs"}, {"start_line": 2000, "end_line": 4000, "belongs_to": {"file_name": "test_saferepr.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing/io", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "ry:\n                self.exc_type = self.exc_types.pop(0)\n            except IndexError:\n                pass\n            if hasattr(self.exc_type, \"__call__\"):\n                raise self.exc_type(*args)\n            raise self.exc_type\n\n        def __str__(self):  # noqa: PLE0307\n            self.raise_exc(\"__str__\")\n\n        def __repr__(self):\n            self.raise_exc(\"__repr__\")\n\n    class BrokenObj:\n        def __init__(self, exc):\n            self.exc = exc\n\n        def __repr__(self):\n            raise self.exc\n\n        __str__ = __repr__\n\n    baseexc_str = BaseException(\"__str__\")\n    obj = BrokenObj(RaisingOnStrRepr([BaseException]))\n    assert saferepr(obj) == (\n        f\"<[unpresentable exception ({baseexc_str!r}) \"\n        f\"raised in repr()] BrokenObj object at 0x{id(obj):x}>\"\n    )\n    obj = BrokenObj(RaisingOnStrRepr([RaisingOnStrRepr([BaseException])]))\n    assert saferepr(obj) == (\n        f\"<[{baseexc_str!r} raised in repr()] BrokenObj object at 0x{id(obj):x}>\"\n    )\n\n    with pytest.raises(KeyboardInterrupt):\n        saferepr(BrokenObj(KeyboardInterrupt()))\n\n    with pytest.raises(SystemExit):\n        saferepr(BrokenObj(SystemExit()))\n\n    with pytest.raises(KeyboardInterrupt):\n        saferepr(BrokenObj(RaisingOnStrRepr([KeyboardInterrupt])))\n\n    with pytest.raises(SystemExit):\n        saferepr(BrokenObj(RaisingOnStrRepr([SystemExit])))\n\n    with pytest.raises(KeyboardInterrupt):\n        print(saferepr(BrokenObj(RaisingOnStrRepr([BaseException, KeyboardInterrupt]))))\n\n    with pytest.raises(SystemExit):\n        saferepr(BrokenObj(RaisingOnStrRepr([BaseException, SystemExit])))\n\n\ndef test_buggy_builtin_repr():\n    # Simulate a case where a repr for a builtin raises.\n    # reprlib dispatches by type name, so use \"int\".\n\n    class int:\n        def __repr__(self):\n            raise ValueError(\"Buggy repr!\")\n\n    assert \"Buggy\" in saferepr(int())\n\n\ndef test_big_repr():\n    from _pytest._io.saferepr import SafeRepr\n\n    assert len(saferepr(range(1000"}, {"start_line": 0, "end_line": 2000, "belongs_to": {"file_name": "saferepr.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest/_io", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "from __future__ import annotations\n\nimport pprint\nimport reprlib\n\n\ndef _try_repr_or_str(obj: object) -> str:\n    try:\n        return repr(obj)\n    except (KeyboardInterrupt, SystemExit):\n        raise\n    except BaseException:\n        return f'{type(obj).__name__}(\"{obj}\")'\n\n\ndef _format_repr_exception(exc: BaseException, obj: object) -> str:\n    try:\n        exc_info = _try_repr_or_str(exc)\n    except (KeyboardInterrupt, SystemExit):\n        raise\n    except BaseException as inner_exc:\n        exc_info = f\"unpresentable exception ({_try_repr_or_str(inner_exc)})\"\n    return (\n        f\"<[{exc_info} raised in repr()] {type(obj).__name__} object at 0x{id(obj):x}>\"\n    )\n\n\ndef _ellipsize(s: str, maxsize: int) -> str:\n    if len(s) > maxsize:\n        i = max(0, (maxsize - 3) // 2)\n        j = max(0, maxsize - 3 - i)\n        return s[:i] + \"...\" + s[len(s) - j :]\n    return s\n\n\nclass SafeRepr(reprlib.Repr):\n    \"\"\"\n    repr.Repr that limits the resulting size of repr() and includes\n    information on exceptions raised during the call.\n    \"\"\"\n\n    def __init__(self, maxsize: int | None, use_ascii: bool = False) -> None:\n        \"\"\"\n        :param maxsize:\n            If not None, will truncate the resulting repr to that specific size, using ellipsis\n            somewhere in the middle to hide the extra text.\n            If None, will not impose any size limits on the returning repr.\n        \"\"\"\n        super().__init__()\n        # ``maxstring`` is used by the superclass, and needs to be an int; using a\n        # very large number in case maxsize is None, meaning we want to disable\n        # truncation.\n        self.maxstring = maxsize if maxsize is not None else 1_000_000_000\n        self.maxsize = maxsize\n        self.use_ascii = use_ascii\n\n    def repr(self, x: object) -> str:\n        try:\n            if self.use_ascii:\n                s = ascii(x)\n            else:\n                s = super().repr(x)\n        except (KeyboardInterrupt, SystemExit):\n            raise\n  "}, {"start_line": 0, "end_line": 2000, "belongs_to": {"file_name": "test_saferepr.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing/io", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "# mypy: allow-untyped-defs\nfrom __future__ import annotations\n\nfrom _pytest._io.saferepr import DEFAULT_REPR_MAX_SIZE\nfrom _pytest._io.saferepr import saferepr\nfrom _pytest._io.saferepr import saferepr_unlimited\nimport pytest\n\n\ndef test_simple_repr():\n    assert saferepr(1) == \"1\"\n    assert saferepr(None) == \"None\"\n\n\ndef test_maxsize():\n    s = saferepr(\"x\" * 50, maxsize=25)\n    assert len(s) == 25\n    expected = repr(\"x\" * 10 + \"...\" + \"x\" * 10)\n    assert s == expected\n\n\ndef test_no_maxsize():\n    text = \"x\" * DEFAULT_REPR_MAX_SIZE * 10\n    s = saferepr(text, maxsize=None)\n    expected = repr(text)\n    assert s == expected\n\n\ndef test_maxsize_error_on_instance():\n    class A:\n        def __repr__(self):\n            raise ValueError(\"...\")\n\n    s = saferepr((\"*\" * 50, A()), maxsize=25)\n    assert len(s) == 25\n    assert s[0] == \"(\" and s[-1] == \")\"\n\n\ndef test_exceptions() -> None:\n    class BrokenRepr:\n        def __init__(self, ex):\n            self.ex = ex\n\n        def __repr__(self):\n            raise self.ex\n\n    class BrokenReprException(Exception):\n        __str__ = None  # type: ignore[assignment]\n        __repr__ = None  # type: ignore[assignment]\n\n    assert \"Exception\" in saferepr(BrokenRepr(Exception(\"broken\")))\n    s = saferepr(BrokenReprException(\"really broken\"))\n    assert \"TypeError\" in s\n    assert \"TypeError\" in saferepr(BrokenRepr(\"string\"))\n\n    none = None\n    try:\n        none()  # type: ignore[misc]\n    except BaseException as exc:\n        exp_exc = repr(exc)\n    obj = BrokenRepr(BrokenReprException(\"omg even worse\"))\n    s2 = saferepr(obj)\n    assert s2 == (\n        f\"<[unpresentable exception ({exp_exc!s}) raised in repr()] BrokenRepr object at 0x{id(obj):x}>\"\n    )\n\n\ndef test_baseexception():\n    \"\"\"Test saferepr() with BaseExceptions, which includes pytest outcomes.\"\"\"\n\n    class RaisingOnStrRepr(BaseException):\n        def __init__(self, exc_types):\n            self.exc_types = exc_types\n\n        def raise_exc(self, *args):\n            t"}, {"start_line": 3000, "end_line": 5000, "belongs_to": {"file_name": "test_saferepr.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing/io", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "\n\n    with pytest.raises(KeyboardInterrupt):\n        saferepr(BrokenObj(KeyboardInterrupt()))\n\n    with pytest.raises(SystemExit):\n        saferepr(BrokenObj(SystemExit()))\n\n    with pytest.raises(KeyboardInterrupt):\n        saferepr(BrokenObj(RaisingOnStrRepr([KeyboardInterrupt])))\n\n    with pytest.raises(SystemExit):\n        saferepr(BrokenObj(RaisingOnStrRepr([SystemExit])))\n\n    with pytest.raises(KeyboardInterrupt):\n        print(saferepr(BrokenObj(RaisingOnStrRepr([BaseException, KeyboardInterrupt]))))\n\n    with pytest.raises(SystemExit):\n        saferepr(BrokenObj(RaisingOnStrRepr([BaseException, SystemExit])))\n\n\ndef test_buggy_builtin_repr():\n    # Simulate a case where a repr for a builtin raises.\n    # reprlib dispatches by type name, so use \"int\".\n\n    class int:\n        def __repr__(self):\n            raise ValueError(\"Buggy repr!\")\n\n    assert \"Buggy\" in saferepr(int())\n\n\ndef test_big_repr():\n    from _pytest._io.saferepr import SafeRepr\n\n    assert len(saferepr(range(1000))) <= len(\"[\" + SafeRepr(0).maxlist * \"1000\" + \"]\")\n\n\ndef test_repr_on_newstyle() -> None:\n    class Function:\n        def __repr__(self):\n            return f\"<{self.name}>\"  # type: ignore[attr-defined]\n\n    assert saferepr(Function())\n\n\ndef test_unicode():\n    val = \"\"\n    reprval = \"''\"\n    assert saferepr(val) == reprval\n\n\ndef test_broken_getattribute():\n    \"\"\"saferepr() can create proper representations of classes with\n    broken __getattribute__ (#7145)\n    \"\"\"\n\n    class SomeClass:\n        def __getattribute__(self, attr):\n            raise RuntimeError\n\n        def __repr__(self):\n            raise RuntimeError\n\n    assert saferepr(SomeClass()).startswith(\n        \"<[RuntimeError() raised in repr()] SomeClass object at 0x\"\n    )\n\n\ndef test_saferepr_unlimited():\n    dict5 = {f\"v{i}\": i for i in range(5)}\n    assert saferepr_unlimited(dict5) == \"{'v0': 0, 'v1': 1, 'v2': 2, 'v3': 3, 'v4': 4}\"\n\n    dict_long = {f\"v{i}\": i for i in range(1_000)}\n    r = saferepr_unlimited(dic"}, {"start_line": 4000, "end_line": 5284, "belongs_to": {"file_name": "test_saferepr.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing/io", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "))) <= len(\"[\" + SafeRepr(0).maxlist * \"1000\" + \"]\")\n\n\ndef test_repr_on_newstyle() -> None:\n    class Function:\n        def __repr__(self):\n            return f\"<{self.name}>\"  # type: ignore[attr-defined]\n\n    assert saferepr(Function())\n\n\ndef test_unicode():\n    val = \"\"\n    reprval = \"''\"\n    assert saferepr(val) == reprval\n\n\ndef test_broken_getattribute():\n    \"\"\"saferepr() can create proper representations of classes with\n    broken __getattribute__ (#7145)\n    \"\"\"\n\n    class SomeClass:\n        def __getattribute__(self, attr):\n            raise RuntimeError\n\n        def __repr__(self):\n            raise RuntimeError\n\n    assert saferepr(SomeClass()).startswith(\n        \"<[RuntimeError() raised in repr()] SomeClass object at 0x\"\n    )\n\n\ndef test_saferepr_unlimited():\n    dict5 = {f\"v{i}\": i for i in range(5)}\n    assert saferepr_unlimited(dict5) == \"{'v0': 0, 'v1': 1, 'v2': 2, 'v3': 3, 'v4': 4}\"\n\n    dict_long = {f\"v{i}\": i for i in range(1_000)}\n    r = saferepr_unlimited(dict_long)\n    assert \"...\" not in r\n    assert \"\\n\" not in r\n\n\ndef test_saferepr_unlimited_exc():\n    class A:\n        def __repr__(self):\n            raise ValueError(42)\n\n    assert saferepr_unlimited(A()).startswith(\n        \"<[ValueError(42) raised in repr()] A object at 0x\"\n    )\n"}, {"start_line": 44000, "end_line": 46000, "belongs_to": {"file_name": "code.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest/_code", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "       reprcrash = None\n            repr_chain += [(reprtraceback, reprcrash, descr)]\n\n            if e.__cause__ is not None and self.chain:\n                e = e.__cause__\n                excinfo_ = ExceptionInfo.from_exception(e) if e.__traceback__ else None\n                descr = \"The above exception was the direct cause of the following exception:\"\n            elif (\n                e.__context__ is not None and not e.__suppress_context__ and self.chain\n            ):\n                e = e.__context__\n                excinfo_ = ExceptionInfo.from_exception(e) if e.__traceback__ else None\n                descr = \"During handling of the above exception, another exception occurred:\"\n            else:\n                e = None\n        repr_chain.reverse()\n        return ExceptionChainRepr(repr_chain)\n\n\n@dataclasses.dataclass(eq=False)\nclass TerminalRepr:\n    def __str__(self) -> str:\n        # FYI this is called from pytest-xdist's serialization of exception\n        # information.\n        io = StringIO()\n        tw = TerminalWriter(file=io)\n        self.toterminal(tw)\n        return io.getvalue().strip()\n\n    def __repr__(self) -> str:\n        return f\"<{self.__class__} instance at {id(self):0x}>\"\n\n    def toterminal(self, tw: TerminalWriter) -> None:\n        raise NotImplementedError()\n\n\n# This class is abstract -- only subclasses are instantiated.\n@dataclasses.dataclass(eq=False)\nclass ExceptionRepr(TerminalRepr):\n    # Provided by subclasses.\n    reprtraceback: ReprTraceback\n    reprcrash: ReprFileLocation | None\n    sections: list[tuple[str, str, str]] = dataclasses.field(\n        init=False, default_factory=list\n    )\n\n    def addsection(self, name: str, content: str, sep: str = \"-\") -> None:\n        self.sections.append((name, content, sep))\n\n    def toterminal(self, tw: TerminalWriter) -> None:\n        for name, content, sep in self.sections:\n            tw.sep(sep, name)\n            tw.line(content)\n\n\n@dataclasses.dataclass(eq=False)\nclass ExceptionChainRep"}, {"start_line": 42000, "end_line": 44000, "belongs_to": {"file_name": "code.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest/_code", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "ack[-max_frames:]  # type: ignore\n        else:\n            if recursionindex is not None:\n                extraline = \"!!! Recursion detected (same locals & position)\"\n                traceback = traceback[: recursionindex + 1]\n            else:\n                extraline = None\n\n        return traceback, extraline\n\n    def repr_excinfo(self, excinfo: ExceptionInfo[BaseException]) -> ExceptionChainRepr:\n        repr_chain: list[tuple[ReprTraceback, ReprFileLocation | None, str | None]] = []\n        e: BaseException | None = excinfo.value\n        excinfo_: ExceptionInfo[BaseException] | None = excinfo\n        descr = None\n        seen: set[int] = set()\n        while e is not None and id(e) not in seen:\n            seen.add(id(e))\n\n            if excinfo_:\n                # Fall back to native traceback as a temporary workaround until\n                # full support for exception groups added to ExceptionInfo.\n                # See https://github.com/pytest-dev/pytest/issues/9159\n                reprtraceback: ReprTraceback | ReprTracebackNative\n                if isinstance(e, BaseExceptionGroup):\n                    # don't filter any sub-exceptions since they shouldn't have any internal frames\n                    traceback = filter_excinfo_traceback(self.tbfilter, excinfo)\n                    reprtraceback = ReprTracebackNative(\n                        format_exception(\n                            type(excinfo.value),\n                            excinfo.value,\n                            traceback[0]._rawentry,\n                        )\n                    )\n                else:\n                    reprtraceback = self.repr_traceback(excinfo_)\n                reprcrash = excinfo_._getreprcrash()\n            else:\n                # Fallback to native repr if the exception doesn't have a traceback:\n                # ExceptionInfo objects require a full traceback to work.\n                reprtraceback = ReprTracebackNative(format_exception(type(e), e, None))\n         "}, {"start_line": 43000, "end_line": 45000, "belongs_to": {"file_name": "code.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest/_code", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "        reprtraceback: ReprTraceback | ReprTracebackNative\n                if isinstance(e, BaseExceptionGroup):\n                    # don't filter any sub-exceptions since they shouldn't have any internal frames\n                    traceback = filter_excinfo_traceback(self.tbfilter, excinfo)\n                    reprtraceback = ReprTracebackNative(\n                        format_exception(\n                            type(excinfo.value),\n                            excinfo.value,\n                            traceback[0]._rawentry,\n                        )\n                    )\n                else:\n                    reprtraceback = self.repr_traceback(excinfo_)\n                reprcrash = excinfo_._getreprcrash()\n            else:\n                # Fallback to native repr if the exception doesn't have a traceback:\n                # ExceptionInfo objects require a full traceback to work.\n                reprtraceback = ReprTracebackNative(format_exception(type(e), e, None))\n                reprcrash = None\n            repr_chain += [(reprtraceback, reprcrash, descr)]\n\n            if e.__cause__ is not None and self.chain:\n                e = e.__cause__\n                excinfo_ = ExceptionInfo.from_exception(e) if e.__traceback__ else None\n                descr = \"The above exception was the direct cause of the following exception:\"\n            elif (\n                e.__context__ is not None and not e.__suppress_context__ and self.chain\n            ):\n                e = e.__context__\n                excinfo_ = ExceptionInfo.from_exception(e) if e.__traceback__ else None\n                descr = \"During handling of the above exception, another exception occurred:\"\n            else:\n                e = None\n        repr_chain.reverse()\n        return ExceptionChainRepr(repr_chain)\n\n\n@dataclasses.dataclass(eq=False)\nclass TerminalRepr:\n    def __str__(self) -> str:\n        # FYI this is called from pytest-xdist's serialization of exception\n        # information.\n   "}], "retrieved_count": 10, "cost_time": 1.0862343311309814}
{"question": "What is the architectural pattern in the TestArgComplete class that decouples the comparison logic between FastFilesCompleter and FilesCompleter implementations to enable independent evolution of bash completion strategies?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"start_line": 2000, "end_line": 3241, "belongs_to": {"file_name": "test_argcomplete.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "[\"bash\", \"-c\", f\"compgen -A directory -- '{prefix}'\"])\n\n            completion = list(set(completion) - set(anticomp))\n\n            if self.directories:\n                completion += [f + \"/\" for f in anticomp]\n        return completion\n\n\nclass TestArgComplete:\n    @pytest.mark.skipif(\"sys.platform in ('win32', 'darwin')\")\n    def test_compare_with_compgen(\n        self, tmp_path: Path, monkeypatch: MonkeyPatch\n    ) -> None:\n        from _pytest._argcomplete import FastFilesCompleter\n\n        ffc = FastFilesCompleter()\n        fc = FilesCompleter()\n\n        monkeypatch.chdir(tmp_path)\n\n        assert equal_with_bash(\"\", ffc, fc, out=sys.stdout)\n\n        tmp_path.cwd().joinpath(\"data\").touch()\n\n        for x in [\"d\", \"data\", \"doesnotexist\", \"\"]:\n            assert equal_with_bash(x, ffc, fc, out=sys.stdout)\n\n    @pytest.mark.skipif(\"sys.platform in ('win32', 'darwin')\")\n    def test_remove_dir_prefix(self):\n        \"\"\"This is not compatible with compgen but it is with bash itself: ls /usr/<TAB>.\"\"\"\n        from _pytest._argcomplete import FastFilesCompleter\n\n        ffc = FastFilesCompleter()\n        fc = FilesCompleter()\n        for x in \"/usr/\".split():\n            assert not equal_with_bash(x, ffc, fc, out=sys.stdout)\n"}, {"start_line": 1000, "end_line": 3000, "belongs_to": {"file_name": "test_argcomplete.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "esCompleter:\n    \"\"\"File completer class, optionally takes a list of allowed extensions.\"\"\"\n\n    def __init__(self, allowednames=(), directories=True):\n        # Fix if someone passes in a string instead of a list\n        if type(allowednames) is str:\n            allowednames = [allowednames]\n\n        self.allowednames = [x.lstrip(\"*\").lstrip(\".\") for x in allowednames]\n        self.directories = directories\n\n    def __call__(self, prefix, **kwargs):\n        completion = []\n        if self.allowednames:\n            if self.directories:\n                files = _wrapcall([\"bash\", \"-c\", f\"compgen -A directory -- '{prefix}'\"])\n                completion += [f + \"/\" for f in files]\n            for x in self.allowednames:\n                completion += _wrapcall(\n                    [\"bash\", \"-c\", f\"compgen -A file -X '!*.{x}' -- '{prefix}'\"]\n                )\n        else:\n            completion += _wrapcall([\"bash\", \"-c\", f\"compgen -A file -- '{prefix}'\"])\n\n            anticomp = _wrapcall([\"bash\", \"-c\", f\"compgen -A directory -- '{prefix}'\"])\n\n            completion = list(set(completion) - set(anticomp))\n\n            if self.directories:\n                completion += [f + \"/\" for f in anticomp]\n        return completion\n\n\nclass TestArgComplete:\n    @pytest.mark.skipif(\"sys.platform in ('win32', 'darwin')\")\n    def test_compare_with_compgen(\n        self, tmp_path: Path, monkeypatch: MonkeyPatch\n    ) -> None:\n        from _pytest._argcomplete import FastFilesCompleter\n\n        ffc = FastFilesCompleter()\n        fc = FilesCompleter()\n\n        monkeypatch.chdir(tmp_path)\n\n        assert equal_with_bash(\"\", ffc, fc, out=sys.stdout)\n\n        tmp_path.cwd().joinpath(\"data\").touch()\n\n        for x in [\"d\", \"data\", \"doesnotexist\", \"\"]:\n            assert equal_with_bash(x, ffc, fc, out=sys.stdout)\n\n    @pytest.mark.skipif(\"sys.platform in ('win32', 'darwin')\")\n    def test_remove_dir_prefix(self):\n        \"\"\"This is not compatible with compgen but it is with bash itself: ls /"}, {"start_line": 0, "end_line": 2000, "belongs_to": {"file_name": "test_argcomplete.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "# mypy: allow-untyped-defs\nfrom __future__ import annotations\n\nfrom pathlib import Path\nimport subprocess\nimport sys\n\nfrom _pytest.monkeypatch import MonkeyPatch\nimport pytest\n\n\n# Test for _argcomplete but not specific for any application.\n\n\ndef equal_with_bash(prefix, ffc, fc, out=None):\n    res = ffc(prefix)\n    res_bash = set(fc(prefix))\n    retval = set(res) == res_bash\n    if out:\n        out.write(f\"equal_with_bash({prefix}) {retval} {res}\\n\")\n        if not retval:\n            out.write(\" python - bash: %s\\n\" % (set(res) - res_bash))\n            out.write(\" bash - python: %s\\n\" % (res_bash - set(res)))\n    return retval\n\n\n# Copied from argcomplete.completers as import from there.\n# Also pulls in argcomplete.__init__ which opens filedescriptor 9.\n# This gives an OSError at the end of testrun.\n\n\ndef _wrapcall(*args, **kargs):\n    try:\n        return subprocess.check_output(*args, **kargs).decode().splitlines()\n    except subprocess.CalledProcessError:\n        return []\n\n\nclass FilesCompleter:\n    \"\"\"File completer class, optionally takes a list of allowed extensions.\"\"\"\n\n    def __init__(self, allowednames=(), directories=True):\n        # Fix if someone passes in a string instead of a list\n        if type(allowednames) is str:\n            allowednames = [allowednames]\n\n        self.allowednames = [x.lstrip(\"*\").lstrip(\".\") for x in allowednames]\n        self.directories = directories\n\n    def __call__(self, prefix, **kwargs):\n        completion = []\n        if self.allowednames:\n            if self.directories:\n                files = _wrapcall([\"bash\", \"-c\", f\"compgen -A directory -- '{prefix}'\"])\n                completion += [f + \"/\" for f in files]\n            for x in self.allowednames:\n                completion += _wrapcall(\n                    [\"bash\", \"-c\", f\"compgen -A file -X '!*.{x}' -- '{prefix}'\"]\n                )\n        else:\n            completion += _wrapcall([\"bash\", \"-c\", f\"compgen -A file -- '{prefix}'\"])\n\n            anticomp = _wrapcall("}, {"start_line": 0, "end_line": 631, "belongs_to": {"file_name": "bench_argcomplete.py", "upper_path": "/data2/raymone/swebench-repos/pytest/bench", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "# 10000 iterations, just for relative comparison\n#                      2.7.5     3.3.2\n# FilesCompleter       75.1109   69.2116\n# FastFilesCompleter    0.7383    1.0760\nfrom __future__ import annotations\n\nimport timeit\n\n\nimports = [\n    \"from argcomplete.completers import FilesCompleter as completer\",\n    \"from _pytest._argcomplete import FastFilesCompleter as completer\",\n]\n\ncount = 1000  # only a few seconds\nsetup = \"%s\\nfc = completer()\"\nrun = 'fc(\"/d\")'\n\n\nif __name__ == \"__main__\":\n    print(timeit.timeit(run, setup=setup % imports[0], number=count))\n    print(timeit.timeit(run, setup=setup % imports[1], number=count))\n"}, {"start_line": 2000, "end_line": 3776, "belongs_to": {"file_name": "_argcomplete.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "the magic line has been found, 1 if not.\n\n- Sometimes it helps to find early on errors using:\n    _ARGCOMPLETE=1 _ARC_DEBUG=1 appname\n  which should throw a KeyError: 'COMPLINE' (which is properly set by the\n  global argcomplete script).\n\"\"\"\n\nfrom __future__ import annotations\n\nimport argparse\nfrom glob import glob\nimport os\nimport sys\nfrom typing import Any\n\n\nclass FastFilesCompleter:\n    \"\"\"Fast file completer class.\"\"\"\n\n    def __init__(self, directories: bool = True) -> None:\n        self.directories = directories\n\n    def __call__(self, prefix: str, **kwargs: Any) -> list[str]:\n        # Only called on non option completions.\n        if os.sep in prefix[1:]:\n            prefix_dir = len(os.path.dirname(prefix) + os.sep)\n        else:\n            prefix_dir = 0\n        completion = []\n        globbed = []\n        if \"*\" not in prefix and \"?\" not in prefix:\n            # We are on unix, otherwise no bash.\n            if not prefix or prefix[-1] == os.sep:\n                globbed.extend(glob(prefix + \".*\"))\n            prefix += \"*\"\n        globbed.extend(glob(prefix))\n        for x in sorted(globbed):\n            if os.path.isdir(x):\n                x += \"/\"\n            # Append stripping the prefix (like bash, not like compgen).\n            completion.append(x[prefix_dir:])\n        return completion\n\n\nif os.environ.get(\"_ARGCOMPLETE\"):\n    try:\n        import argcomplete.completers\n    except ImportError:\n        sys.exit(-1)\n    filescompleter: FastFilesCompleter | None = FastFilesCompleter()\n\n    def try_argcomplete(parser: argparse.ArgumentParser) -> None:\n        argcomplete.autocomplete(parser, always_complete_options=False)\n\nelse:\n\n    def try_argcomplete(parser: argparse.ArgumentParser) -> None:\n        pass\n\n    filescompleter = None\n"}, {"start_line": 1000, "end_line": 3000, "belongs_to": {"file_name": "_argcomplete.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "startup script generated by pip.\nYou can speed up completion somewhat by changing this script to include\n  # PYTHON_ARGCOMPLETE_OK\nso the python-argcomplete-check-easy-install-script does not\nneed to be called to find the entry point of the code and see if that is\nmarked  with PYTHON_ARGCOMPLETE_OK.\n\nINSTALL/DEBUGGING\n=================\n\nTo include this support in another application that has setup.py generated\nscripts:\n\n- Add the line:\n    # PYTHON_ARGCOMPLETE_OK\n  near the top of the main python entry point.\n\n- Include in the file calling parse_args():\n    from _argcomplete import try_argcomplete, filescompleter\n  Call try_argcomplete just before parse_args(), and optionally add\n  filescompleter to the positional arguments' add_argument().\n\nIf things do not work right away:\n\n- Switch on argcomplete debugging with (also helpful when doing custom\n  completers):\n    export _ARC_DEBUG=1\n\n- Run:\n    python-argcomplete-check-easy-install-script $(which appname)\n    echo $?\n  will echo 0 if the magic line has been found, 1 if not.\n\n- Sometimes it helps to find early on errors using:\n    _ARGCOMPLETE=1 _ARC_DEBUG=1 appname\n  which should throw a KeyError: 'COMPLINE' (which is properly set by the\n  global argcomplete script).\n\"\"\"\n\nfrom __future__ import annotations\n\nimport argparse\nfrom glob import glob\nimport os\nimport sys\nfrom typing import Any\n\n\nclass FastFilesCompleter:\n    \"\"\"Fast file completer class.\"\"\"\n\n    def __init__(self, directories: bool = True) -> None:\n        self.directories = directories\n\n    def __call__(self, prefix: str, **kwargs: Any) -> list[str]:\n        # Only called on non option completions.\n        if os.sep in prefix[1:]:\n            prefix_dir = len(os.path.dirname(prefix) + os.sep)\n        else:\n            prefix_dir = 0\n        completion = []\n        globbed = []\n        if \"*\" not in prefix and \"?\" not in prefix:\n            # We are on unix, otherwise no bash.\n            if not prefix or prefix[-1] == os.sep:\n                globbed.ext"}, {"start_line": 13000, "end_line": 14867, "belongs_to": {"file_name": "test_parseopt.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": " encoding=encoding,\n        ).stdout\n    except (OSError, subprocess.CalledProcessError):\n        pytest.skip(\"bash is not available\")\n    if \"GNU bash\" not in bash_version:\n        # See #7518.\n        pytest.skip(\"not a real bash\")\n\n    script = str(pytester.path.joinpath(\"test_argcomplete\"))\n\n    with open(str(script), \"w\", encoding=\"utf-8\") as fp:\n        # redirect output from argcomplete to stdin and stderr is not trivial\n        # http://stackoverflow.com/q/12589419/1307905\n        # so we use bash\n        fp.write(\n            f'COMP_WORDBREAKS=\"$COMP_WORDBREAKS\" {shlex.quote(sys.executable)} -m pytest 8>&1 9>&2'\n        )\n    # alternative would be extended Pytester.{run(),_run(),popen()} to be able\n    # to handle a keyword argument env that replaces os.environ in popen or\n    # extends the copy, advantage: could not forget to restore\n    monkeypatch.setenv(\"_ARGCOMPLETE\", \"1\")\n    monkeypatch.setenv(\"_ARGCOMPLETE_IFS\", \"\\x0b\")\n    monkeypatch.setenv(\"COMP_WORDBREAKS\", \" \\\\t\\\\n\\\"\\\\'><=;|&(:\")\n\n    arg = \"--fu\"\n    monkeypatch.setenv(\"COMP_LINE\", \"pytest \" + arg)\n    monkeypatch.setenv(\"COMP_POINT\", str(len(\"pytest \" + arg)))\n    result = pytester.run(\"bash\", str(script), arg)\n    if result.ret == 255:\n        # argcomplete not found\n        pytest.skip(\"argcomplete not available\")\n    elif not result.stdout.str():\n        pytest.skip(\n            f\"bash provided no output on stdout, argcomplete not available? (stderr={result.stderr.str()!r})\"\n        )\n    else:\n        result.stdout.fnmatch_lines([\"--funcargs\", \"--fulltrace\"])\n    os.mkdir(\"test_argcomplete.d\")\n    arg = \"test_argc\"\n    monkeypatch.setenv(\"COMP_LINE\", \"pytest \" + arg)\n    monkeypatch.setenv(\"COMP_POINT\", str(len(\"pytest \" + arg)))\n    result = pytester.run(\"bash\", str(script), arg)\n    result.stdout.fnmatch_lines([\"test_argcomplete\", \"test_argcomplete.d/\"])\n"}, {"start_line": 0, "end_line": 2000, "belongs_to": {"file_name": "_argcomplete.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "\"\"\"Allow bash-completion for argparse with argcomplete if installed.\n\nNeeds argcomplete>=0.5.6 for python 3.2/3.3 (older versions fail\nto find the magic string, so _ARGCOMPLETE env. var is never set, and\nthis does not need special code).\n\nFunction try_argcomplete(parser) should be called directly before\nthe call to ArgumentParser.parse_args().\n\nThe filescompleter is what you normally would use on the positional\narguments specification, in order to get \"dirname/\" after \"dirn<TAB>\"\ninstead of the default \"dirname \":\n\n   optparser.add_argument(Config._file_or_dir, nargs='*').completer=filescompleter\n\nOther, application specific, completers should go in the file\ndoing the add_argument calls as they need to be specified as .completer\nattributes as well. (If argcomplete is not installed, the function the\nattribute points to will not be used).\n\nSPEEDUP\n=======\n\nThe generic argcomplete script for bash-completion\n(/etc/bash_completion.d/python-argcomplete.sh)\nuses a python program to determine startup script generated by pip.\nYou can speed up completion somewhat by changing this script to include\n  # PYTHON_ARGCOMPLETE_OK\nso the python-argcomplete-check-easy-install-script does not\nneed to be called to find the entry point of the code and see if that is\nmarked  with PYTHON_ARGCOMPLETE_OK.\n\nINSTALL/DEBUGGING\n=================\n\nTo include this support in another application that has setup.py generated\nscripts:\n\n- Add the line:\n    # PYTHON_ARGCOMPLETE_OK\n  near the top of the main python entry point.\n\n- Include in the file calling parse_args():\n    from _argcomplete import try_argcomplete, filescompleter\n  Call try_argcomplete just before parse_args(), and optionally add\n  filescompleter to the positional arguments' add_argument().\n\nIf things do not work right away:\n\n- Switch on argcomplete debugging with (also helpful when doing custom\n  completers):\n    export _ARC_DEBUG=1\n\n- Run:\n    python-argcomplete-check-easy-install-script $(which appname)\n    echo $?\n  will echo 0 if "}, {"start_line": 12000, "end_line": 14000, "belongs_to": {"file_name": "test_parseopt.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "\"\"\n        Help text for options with a metavar tuple should display help\n        in the form \"--preferences=value1 value2 value3\" (#2004).\n        \"\"\"\n        group = parser.getgroup(\"general\")\n        group.addoption(\n            \"--preferences\", metavar=(\"value1\", \"value2\", \"value3\"), nargs=3\n        )\n        group._addoption(\"-h\", \"--help\", action=\"store_true\", dest=\"help\")\n        parser.parse([\"-h\"])\n        help = parser.optparser.format_help()\n        assert \"--preferences=value1 value2 value3\" in help\n\n\ndef test_argcomplete(pytester: Pytester, monkeypatch: MonkeyPatch) -> None:\n    if sys.version_info >= (3, 11):\n        # New in Python 3.11, ignores utf-8 mode\n        encoding = locale.getencoding()\n    else:\n        encoding = locale.getpreferredencoding(False)\n    try:\n        bash_version = subprocess.run(\n            [\"bash\", \"--version\"],\n            stdout=subprocess.PIPE,\n            stderr=subprocess.DEVNULL,\n            check=True,\n            text=True,\n            encoding=encoding,\n        ).stdout\n    except (OSError, subprocess.CalledProcessError):\n        pytest.skip(\"bash is not available\")\n    if \"GNU bash\" not in bash_version:\n        # See #7518.\n        pytest.skip(\"not a real bash\")\n\n    script = str(pytester.path.joinpath(\"test_argcomplete\"))\n\n    with open(str(script), \"w\", encoding=\"utf-8\") as fp:\n        # redirect output from argcomplete to stdin and stderr is not trivial\n        # http://stackoverflow.com/q/12589419/1307905\n        # so we use bash\n        fp.write(\n            f'COMP_WORDBREAKS=\"$COMP_WORDBREAKS\" {shlex.quote(sys.executable)} -m pytest 8>&1 9>&2'\n        )\n    # alternative would be extended Pytester.{run(),_run(),popen()} to be able\n    # to handle a keyword argument env that replaces os.environ in popen or\n    # extends the copy, advantage: could not forget to restore\n    monkeypatch.setenv(\"_ARGCOMPLETE\", \"1\")\n    monkeypatch.setenv(\"_ARGCOMPLETE_IFS\", \"\\x0b\")\n    monkeypatch.setenv(\"COMP_WORDBREAKS\", \" \\\\t\\"}, {"start_line": 11000, "end_line": 13000, "belongs_to": {"file_name": "test_parseopt.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "gs.func_arg is False\n        assert args.file_or_dir == [\"abcd\"]\n\n    def test_drop_short_help0(self, parser: parseopt.Parser) -> None:\n        parser.addoption(\"--func-args\", \"--doit\", help=\"foo\", action=\"store_true\")\n        parser.parse([])\n        help = parser.optparser.format_help()\n        assert \"--func-args, --doit  foo\" in help\n\n    # testing would be more helpful with all help generated\n    def test_drop_short_help1(self, parser: parseopt.Parser) -> None:\n        group = parser.getgroup(\"general\")\n        group.addoption(\"--doit\", \"--func-args\", action=\"store_true\", help=\"foo\")\n        group._addoption(\n            \"-h\",\n            \"--help\",\n            action=\"store_true\",\n            dest=\"help\",\n            help=\"show help message and configuration info\",\n        )\n        parser.parse([\"-h\"])\n        help = parser.optparser.format_help()\n        assert \"-doit, --func-args  foo\" in help\n\n    def test_multiple_metavar_help(self, parser: parseopt.Parser) -> None:\n        \"\"\"\n        Help text for options with a metavar tuple should display help\n        in the form \"--preferences=value1 value2 value3\" (#2004).\n        \"\"\"\n        group = parser.getgroup(\"general\")\n        group.addoption(\n            \"--preferences\", metavar=(\"value1\", \"value2\", \"value3\"), nargs=3\n        )\n        group._addoption(\"-h\", \"--help\", action=\"store_true\", dest=\"help\")\n        parser.parse([\"-h\"])\n        help = parser.optparser.format_help()\n        assert \"--preferences=value1 value2 value3\" in help\n\n\ndef test_argcomplete(pytester: Pytester, monkeypatch: MonkeyPatch) -> None:\n    if sys.version_info >= (3, 11):\n        # New in Python 3.11, ignores utf-8 mode\n        encoding = locale.getencoding()\n    else:\n        encoding = locale.getpreferredencoding(False)\n    try:\n        bash_version = subprocess.run(\n            [\"bash\", \"--version\"],\n            stdout=subprocess.PIPE,\n            stderr=subprocess.DEVNULL,\n            check=True,\n            text=True,\n           "}], "retrieved_count": 10, "cost_time": 1.1090195178985596}
{"question": "What is the dependency relationship between evaluate_skip_marks function and the pytester fixture's getitem method in terms of test item creation and mark evaluation?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"start_line": 2000, "end_line": 4000, "belongs_to": {"file_name": "test_skipping.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "valuate_skip_marks(item)\n        assert skipped\n        assert skipped.reason == \"hello world\"\n\n    def test_marked_one_arg_twice(self, pytester: Pytester) -> None:\n        lines = [\n            \"\"\"@pytest.mark.skipif(\"not hasattr(os, 'murks')\")\"\"\",\n            \"\"\"@pytest.mark.skipif(condition=\"hasattr(os, 'murks')\")\"\"\",\n        ]\n        for i in range(2):\n            item = pytester.getitem(\n                f\"\"\"\n                import pytest\n                {lines[i]}\n                {lines[(i + 1) % 2]}\n                def test_func():\n                    pass\n            \"\"\"\n            )\n            skipped = evaluate_skip_marks(item)\n            assert skipped\n            assert skipped.reason == \"condition: not hasattr(os, 'murks')\"\n\n    def test_marked_one_arg_twice2(self, pytester: Pytester) -> None:\n        item = pytester.getitem(\n            \"\"\"\n            import pytest\n            @pytest.mark.skipif(\"hasattr(os, 'murks')\")\n            @pytest.mark.skipif(\"not hasattr(os, 'murks')\")\n            def test_func():\n                pass\n        \"\"\"\n        )\n        skipped = evaluate_skip_marks(item)\n        assert skipped\n        assert skipped.reason == \"condition: not hasattr(os, 'murks')\"\n\n    def test_marked_skipif_with_boolean_without_reason(\n        self, pytester: Pytester\n    ) -> None:\n        item = pytester.getitem(\n            \"\"\"\n            import pytest\n            @pytest.mark.skipif(False)\n            def test_func():\n                pass\n        \"\"\"\n        )\n        with pytest.raises(pytest.fail.Exception) as excinfo:\n            evaluate_skip_marks(item)\n        assert excinfo.value.msg is not None\n        assert (\n            \"\"\"Error evaluating 'skipif': you need to specify reason=STRING when using booleans as conditions.\"\"\"\n            in excinfo.value.msg\n        )\n\n    def test_marked_skipif_with_invalid_boolean(self, pytester: Pytester) -> None:\n        item = pytester.getitem(\n            \"\"\"\n            import pytest\n\n        "}, {"start_line": 1000, "end_line": 3000, "belongs_to": {"file_name": "test_skipping.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "   item = pytester.getitem(\n            \"\"\"\n            import pytest\n            @pytest.mark.skipif\n            def test_func():\n                pass\n        \"\"\"\n        )\n        skipped = evaluate_skip_marks(item)\n        assert skipped\n        assert skipped.reason == \"\"\n\n    def test_marked_one_arg(self, pytester: Pytester) -> None:\n        item = pytester.getitem(\n            \"\"\"\n            import pytest\n            @pytest.mark.skipif(\"hasattr(os, 'sep')\")\n            def test_func():\n                pass\n        \"\"\"\n        )\n        skipped = evaluate_skip_marks(item)\n        assert skipped\n        assert skipped.reason == \"condition: hasattr(os, 'sep')\"\n\n    def test_marked_one_arg_with_reason(self, pytester: Pytester) -> None:\n        item = pytester.getitem(\n            \"\"\"\n            import pytest\n            @pytest.mark.skipif(\"hasattr(os, 'sep')\", attr=2, reason=\"hello world\")\n            def test_func():\n                pass\n        \"\"\"\n        )\n        skipped = evaluate_skip_marks(item)\n        assert skipped\n        assert skipped.reason == \"hello world\"\n\n    def test_marked_one_arg_twice(self, pytester: Pytester) -> None:\n        lines = [\n            \"\"\"@pytest.mark.skipif(\"not hasattr(os, 'murks')\")\"\"\",\n            \"\"\"@pytest.mark.skipif(condition=\"hasattr(os, 'murks')\")\"\"\",\n        ]\n        for i in range(2):\n            item = pytester.getitem(\n                f\"\"\"\n                import pytest\n                {lines[i]}\n                {lines[(i + 1) % 2]}\n                def test_func():\n                    pass\n            \"\"\"\n            )\n            skipped = evaluate_skip_marks(item)\n            assert skipped\n            assert skipped.reason == \"condition: not hasattr(os, 'murks')\"\n\n    def test_marked_one_arg_twice2(self, pytester: Pytester) -> None:\n        item = pytester.getitem(\n            \"\"\"\n            import pytest\n            @pytest.mark.skipif(\"hasattr(os, 'murks')\")\n            @pytest.mark.skipif(\"not hasattr(os,"}, {"start_line": 3000, "end_line": 5000, "belongs_to": {"file_name": "test_skipping.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": " 'murks')\")\n            def test_func():\n                pass\n        \"\"\"\n        )\n        skipped = evaluate_skip_marks(item)\n        assert skipped\n        assert skipped.reason == \"condition: not hasattr(os, 'murks')\"\n\n    def test_marked_skipif_with_boolean_without_reason(\n        self, pytester: Pytester\n    ) -> None:\n        item = pytester.getitem(\n            \"\"\"\n            import pytest\n            @pytest.mark.skipif(False)\n            def test_func():\n                pass\n        \"\"\"\n        )\n        with pytest.raises(pytest.fail.Exception) as excinfo:\n            evaluate_skip_marks(item)\n        assert excinfo.value.msg is not None\n        assert (\n            \"\"\"Error evaluating 'skipif': you need to specify reason=STRING when using booleans as conditions.\"\"\"\n            in excinfo.value.msg\n        )\n\n    def test_marked_skipif_with_invalid_boolean(self, pytester: Pytester) -> None:\n        item = pytester.getitem(\n            \"\"\"\n            import pytest\n\n            class InvalidBool:\n                def __bool__(self):\n                    raise TypeError(\"INVALID\")\n\n            @pytest.mark.skipif(InvalidBool(), reason=\"xxx\")\n            def test_func():\n                pass\n        \"\"\"\n        )\n        with pytest.raises(pytest.fail.Exception) as excinfo:\n            evaluate_skip_marks(item)\n        assert excinfo.value.msg is not None\n        assert \"Error evaluating 'skipif' condition as a boolean\" in excinfo.value.msg\n        assert \"INVALID\" in excinfo.value.msg\n\n    def test_skipif_class(self, pytester: Pytester) -> None:\n        (item,) = pytester.getitems(\n            \"\"\"\n            import pytest\n            class TestClass(object):\n                pytestmark = pytest.mark.skipif(\"config._hackxyz\")\n                def test_func(self):\n                    pass\n        \"\"\"\n        )\n        item.config._hackxyz = 3  # type: ignore[attr-defined]\n        skipped = evaluate_skip_marks(item)\n        assert skipped\n        assert skipped."}, {"start_line": 0, "end_line": 2000, "belongs_to": {"file_name": "test_skipping.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "# mypy: allow-untyped-defs\nfrom __future__ import annotations\n\nimport sys\nimport textwrap\n\nfrom _pytest.pytester import Pytester\nfrom _pytest.runner import runtestprotocol\nfrom _pytest.skipping import evaluate_skip_marks\nfrom _pytest.skipping import evaluate_xfail_marks\nfrom _pytest.skipping import pytest_runtest_setup\nimport pytest\n\n\nclass TestEvaluation:\n    def test_no_marker(self, pytester: Pytester) -> None:\n        item = pytester.getitem(\"def test_func(): pass\")\n        skipped = evaluate_skip_marks(item)\n        assert not skipped\n\n    def test_marked_xfail_no_args(self, pytester: Pytester) -> None:\n        item = pytester.getitem(\n            \"\"\"\n            import pytest\n            @pytest.mark.xfail\n            def test_func():\n                pass\n        \"\"\"\n        )\n        xfailed = evaluate_xfail_marks(item)\n        assert xfailed\n        assert xfailed.reason == \"\"\n        assert xfailed.run\n\n    def test_marked_skipif_no_args(self, pytester: Pytester) -> None:\n        item = pytester.getitem(\n            \"\"\"\n            import pytest\n            @pytest.mark.skipif\n            def test_func():\n                pass\n        \"\"\"\n        )\n        skipped = evaluate_skip_marks(item)\n        assert skipped\n        assert skipped.reason == \"\"\n\n    def test_marked_one_arg(self, pytester: Pytester) -> None:\n        item = pytester.getitem(\n            \"\"\"\n            import pytest\n            @pytest.mark.skipif(\"hasattr(os, 'sep')\")\n            def test_func():\n                pass\n        \"\"\"\n        )\n        skipped = evaluate_skip_marks(item)\n        assert skipped\n        assert skipped.reason == \"condition: hasattr(os, 'sep')\"\n\n    def test_marked_one_arg_with_reason(self, pytester: Pytester) -> None:\n        item = pytester.getitem(\n            \"\"\"\n            import pytest\n            @pytest.mark.skipif(\"hasattr(os, 'sep')\", attr=2, reason=\"hello world\")\n            def test_func():\n                pass\n        \"\"\"\n        )\n        skipped = e"}, {"start_line": 4000, "end_line": 6000, "belongs_to": {"file_name": "test_skipping.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "    class InvalidBool:\n                def __bool__(self):\n                    raise TypeError(\"INVALID\")\n\n            @pytest.mark.skipif(InvalidBool(), reason=\"xxx\")\n            def test_func():\n                pass\n        \"\"\"\n        )\n        with pytest.raises(pytest.fail.Exception) as excinfo:\n            evaluate_skip_marks(item)\n        assert excinfo.value.msg is not None\n        assert \"Error evaluating 'skipif' condition as a boolean\" in excinfo.value.msg\n        assert \"INVALID\" in excinfo.value.msg\n\n    def test_skipif_class(self, pytester: Pytester) -> None:\n        (item,) = pytester.getitems(\n            \"\"\"\n            import pytest\n            class TestClass(object):\n                pytestmark = pytest.mark.skipif(\"config._hackxyz\")\n                def test_func(self):\n                    pass\n        \"\"\"\n        )\n        item.config._hackxyz = 3  # type: ignore[attr-defined]\n        skipped = evaluate_skip_marks(item)\n        assert skipped\n        assert skipped.reason == \"condition: config._hackxyz\"\n\n    def test_skipif_markeval_namespace(self, pytester: Pytester) -> None:\n        pytester.makeconftest(\n            \"\"\"\n            import pytest\n\n            def pytest_markeval_namespace():\n                return {\"color\": \"green\"}\n            \"\"\"\n        )\n        p = pytester.makepyfile(\n            \"\"\"\n            import pytest\n\n            @pytest.mark.skipif(\"color == 'green'\")\n            def test_1():\n                assert True\n\n            @pytest.mark.skipif(\"color == 'red'\")\n            def test_2():\n                assert True\n        \"\"\"\n        )\n        res = pytester.runpytest(p)\n        assert res.ret == 0\n        res.stdout.fnmatch_lines([\"*1 skipped*\"])\n        res.stdout.fnmatch_lines([\"*1 passed*\"])\n\n    def test_skipif_markeval_namespace_multiple(self, pytester: Pytester) -> None:\n        \"\"\"Keys defined by ``pytest_markeval_namespace()`` in nested plugins override top-level ones.\"\"\"\n        root = pytester.mkdir(\"root\")\n"}, {"start_line": 22000, "end_line": 24000, "belongs_to": {"file_name": "test_mark.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "x.name: x for x in items}\n        for name, expected_markers in expected.items():\n            markers = {m.name for m in items[name].iter_markers()}\n            assert markers == set(expected_markers)\n\n    @pytest.mark.filterwarnings(\"ignore\")\n    def test_mark_from_parameters(self, pytester: Pytester) -> None:\n        \"\"\"#1540\"\"\"\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n\n            pytestmark = pytest.mark.skipif(True, reason='skip all')\n\n            # skipifs inside fixture params\n            params = [pytest.mark.skipif(False, reason='dont skip')('parameter')]\n\n\n            @pytest.fixture(params=params)\n            def parameter(request):\n                return request.param\n\n\n            def test_1(parameter):\n                assert True\n        \"\"\"\n        )\n        reprec = pytester.inline_run()\n        reprec.assertoutcome(skipped=1)\n\n    def test_reevaluate_dynamic_expr(self, pytester: Pytester) -> None:\n        \"\"\"#7360\"\"\"\n        py_file1 = pytester.makepyfile(\n            test_reevaluate_dynamic_expr1=\"\"\"\n            import pytest\n\n            skip = True\n\n            @pytest.mark.skipif(\"skip\")\n            def test_should_skip():\n                assert True\n        \"\"\"\n        )\n        py_file2 = pytester.makepyfile(\n            test_reevaluate_dynamic_expr2=\"\"\"\n            import pytest\n\n            skip = False\n\n            @pytest.mark.skipif(\"skip\")\n            def test_should_not_skip():\n                assert True\n        \"\"\"\n        )\n\n        file_name1 = os.path.basename(py_file1)\n        file_name2 = os.path.basename(py_file2)\n        reprec = pytester.inline_run(file_name1, file_name2)\n        reprec.assertoutcome(passed=1, skipped=1)\n\n\nclass TestKeywordSelection:\n    def test_select_simple(self, pytester: Pytester) -> None:\n        file_test = pytester.makepyfile(\n            \"\"\"\n            def test_one():\n                assert 0\n            class TestClass(object):\n                def test_method_one(self):"}, {"start_line": 21000, "end_line": 23000, "belongs_to": {"file_name": "test_mark.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "             session.add_marker(10))\n        \"\"\"\n        )\n        pytester.makepyfile(\n            \"\"\"\n            def test_some(request):\n                assert \"mark1\" in request.keywords\n                assert \"mark2\" in request.keywords\n                assert \"mark3\" in request.keywords\n                assert 10 not in request.keywords\n                marker = request.node.get_closest_marker(\"mark1\")\n                assert marker.name == \"mark1\"\n                assert marker.args == ()\n                assert marker.kwargs == {}\n        \"\"\"\n        )\n        reprec = pytester.inline_run(\"-m\", \"mark1\")\n        reprec.assertoutcome(passed=1)\n\n    def assert_markers(self, items, **expected) -> None:\n        \"\"\"Assert that given items have expected marker names applied to them.\n        expected should be a dict of (item name -> seq of expected marker names).\n\n        Note: this could be moved to ``pytester`` if proven to be useful\n        to other modules.\n        \"\"\"\n        items = {x.name: x for x in items}\n        for name, expected_markers in expected.items():\n            markers = {m.name for m in items[name].iter_markers()}\n            assert markers == set(expected_markers)\n\n    @pytest.mark.filterwarnings(\"ignore\")\n    def test_mark_from_parameters(self, pytester: Pytester) -> None:\n        \"\"\"#1540\"\"\"\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n\n            pytestmark = pytest.mark.skipif(True, reason='skip all')\n\n            # skipifs inside fixture params\n            params = [pytest.mark.skipif(False, reason='dont skip')('parameter')]\n\n\n            @pytest.fixture(params=params)\n            def parameter(request):\n                return request.param\n\n\n            def test_1(parameter):\n                assert True\n        \"\"\"\n        )\n        reprec = pytester.inline_run()\n        reprec.assertoutcome(skipped=1)\n\n    def test_reevaluate_dynamic_expr(self, pytester: Pytester) -> None:\n        \"\"\"#7360\"\"\"\n        py_file1 = pyt"}, {"start_line": 5000, "end_line": 7000, "belongs_to": {"file_name": "skipping.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "at_exception_only(type(exc), exc),\n            ]\n            fail(\"\\n\".join(msglines), pytrace=False)\n\n    reason = mark.kwargs.get(\"reason\", None)\n    if reason is None:\n        if isinstance(condition, str):\n            reason = \"condition: \" + condition\n        else:\n            # XXX better be checked at collection time\n            msg = (\n                f\"Error evaluating {mark.name!r}: \"\n                + \"you need to specify reason=STRING when using booleans as conditions.\"\n            )\n            fail(msg, pytrace=False)\n\n    return result, reason\n\n\n@dataclasses.dataclass(frozen=True)\nclass Skip:\n    \"\"\"The result of evaluate_skip_marks().\"\"\"\n\n    reason: str = \"unconditional skip\"\n\n\ndef evaluate_skip_marks(item: Item) -> Skip | None:\n    \"\"\"Evaluate skip and skipif marks on item, returning Skip if triggered.\"\"\"\n    for mark in item.iter_markers(name=\"skipif\"):\n        if \"condition\" not in mark.kwargs:\n            conditions = mark.args\n        else:\n            conditions = (mark.kwargs[\"condition\"],)\n\n        # Unconditional.\n        if not conditions:\n            reason = mark.kwargs.get(\"reason\", \"\")\n            return Skip(reason)\n\n        # If any of the conditions are true.\n        for condition in conditions:\n            result, reason = evaluate_condition(item, mark, condition)\n            if result:\n                return Skip(reason)\n\n    for mark in item.iter_markers(name=\"skip\"):\n        try:\n            return Skip(*mark.args, **mark.kwargs)\n        except TypeError as e:\n            raise TypeError(str(e) + \" - maybe you meant pytest.mark.skipif?\") from None\n\n    return None\n\n\n@dataclasses.dataclass(frozen=True)\nclass Xfail:\n    \"\"\"The result of evaluate_xfail_marks().\"\"\"\n\n    __slots__ = (\"raises\", \"reason\", \"run\", \"strict\")\n\n    reason: str\n    run: bool\n    strict: bool\n    raises: (\n        type[BaseException]\n        | tuple[type[BaseException], ...]\n        | AbstractRaises[BaseException]\n        | None\n    )\n\n\ndef evaluate_xfail_mar"}, {"start_line": 7000, "end_line": 9000, "belongs_to": {"file_name": "test_skipping.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "       )\n        foo.joinpath(\"test_foo.py\").write_text(\n            textwrap.dedent(\n                \"\"\"\\\n            import pytest\n\n            @pytest.mark.skipif(\"arg == 'foo'\")\n            def test_foo():\n                assert False\n            \"\"\"\n            ),\n            encoding=\"utf-8\",\n        )\n        bar = root.joinpath(\"bar\")\n        bar.mkdir()\n        bar.joinpath(\"__init__.py\").touch()\n        bar.joinpath(\"conftest.py\").write_text(\n            textwrap.dedent(\n                \"\"\"\\\n            import pytest\n\n            def pytest_markeval_namespace():\n                return {\"arg\": \"bar\"}\n            \"\"\"\n            ),\n            encoding=\"utf-8\",\n        )\n        bar.joinpath(\"test_bar.py\").write_text(\n            textwrap.dedent(\n                \"\"\"\\\n            import pytest\n\n            @pytest.mark.skipif(\"arg == 'bar'\")\n            def test_bar():\n                assert False\n            \"\"\"\n            ),\n            encoding=\"utf-8\",\n        )\n\n        reprec = pytester.inline_run(\"-vs\", \"--capture=no\")\n        reprec.assertoutcome(skipped=3)\n\n    def test_skipif_markeval_namespace_ValueError(self, pytester: Pytester) -> None:\n        pytester.makeconftest(\n            \"\"\"\n            import pytest\n\n            def pytest_markeval_namespace():\n                return True\n            \"\"\"\n        )\n        p = pytester.makepyfile(\n            \"\"\"\n            import pytest\n\n            @pytest.mark.skipif(\"color == 'green'\")\n            def test_1():\n                assert True\n        \"\"\"\n        )\n        res = pytester.runpytest(p)\n        assert res.ret == 1\n        res.stdout.fnmatch_lines(\n            [\n                \"*ValueError: pytest_markeval_namespace() needs to return a dict, got True*\"\n            ]\n        )\n\n\nclass TestXFail:\n    @pytest.mark.parametrize(\"strict\", [True, False])\n    def test_xfail_simple(self, pytester: Pytester, strict: bool) -> None:\n        item = pytester.getitem(\n            f\"\"\"\n            import p"}, {"start_line": 6000, "end_line": 8000, "belongs_to": {"file_name": "skipping.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "= (mark.kwargs[\"condition\"],)\n\n        # Unconditional.\n        if not conditions:\n            reason = mark.kwargs.get(\"reason\", \"\")\n            return Skip(reason)\n\n        # If any of the conditions are true.\n        for condition in conditions:\n            result, reason = evaluate_condition(item, mark, condition)\n            if result:\n                return Skip(reason)\n\n    for mark in item.iter_markers(name=\"skip\"):\n        try:\n            return Skip(*mark.args, **mark.kwargs)\n        except TypeError as e:\n            raise TypeError(str(e) + \" - maybe you meant pytest.mark.skipif?\") from None\n\n    return None\n\n\n@dataclasses.dataclass(frozen=True)\nclass Xfail:\n    \"\"\"The result of evaluate_xfail_marks().\"\"\"\n\n    __slots__ = (\"raises\", \"reason\", \"run\", \"strict\")\n\n    reason: str\n    run: bool\n    strict: bool\n    raises: (\n        type[BaseException]\n        | tuple[type[BaseException], ...]\n        | AbstractRaises[BaseException]\n        | None\n    )\n\n\ndef evaluate_xfail_marks(item: Item) -> Xfail | None:\n    \"\"\"Evaluate xfail marks on item, returning Xfail if triggered.\"\"\"\n    for mark in item.iter_markers(name=\"xfail\"):\n        run = mark.kwargs.get(\"run\", True)\n        strict = mark.kwargs.get(\"strict\", item.config.getini(\"xfail_strict\"))\n        raises = mark.kwargs.get(\"raises\", None)\n        if \"condition\" not in mark.kwargs:\n            conditions = mark.args\n        else:\n            conditions = (mark.kwargs[\"condition\"],)\n\n        # Unconditional.\n        if not conditions:\n            reason = mark.kwargs.get(\"reason\", \"\")\n            return Xfail(reason, run, strict, raises)\n\n        # If any of the conditions are true.\n        for condition in conditions:\n            result, reason = evaluate_condition(item, mark, condition)\n            if result:\n                return Xfail(reason, run, strict, raises)\n\n    return None\n\n\n# Saves the xfail mark evaluation. Can be refreshed during call if None.\nxfailed_key = StashKey[Optional[Xfail]]()\n\n\n@hoo"}], "retrieved_count": 10, "cost_time": 1.1082687377929688}
{"question": "How does the Skip class integrate with pytest's mark evaluation framework to determine when a test should be skipped, and what is the relationship between the reason attribute and the evaluate_skip_marks() function that produces Skip instances?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"start_line": 3000, "end_line": 5000, "belongs_to": {"file_name": "test_skipping.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": " 'murks')\")\n            def test_func():\n                pass\n        \"\"\"\n        )\n        skipped = evaluate_skip_marks(item)\n        assert skipped\n        assert skipped.reason == \"condition: not hasattr(os, 'murks')\"\n\n    def test_marked_skipif_with_boolean_without_reason(\n        self, pytester: Pytester\n    ) -> None:\n        item = pytester.getitem(\n            \"\"\"\n            import pytest\n            @pytest.mark.skipif(False)\n            def test_func():\n                pass\n        \"\"\"\n        )\n        with pytest.raises(pytest.fail.Exception) as excinfo:\n            evaluate_skip_marks(item)\n        assert excinfo.value.msg is not None\n        assert (\n            \"\"\"Error evaluating 'skipif': you need to specify reason=STRING when using booleans as conditions.\"\"\"\n            in excinfo.value.msg\n        )\n\n    def test_marked_skipif_with_invalid_boolean(self, pytester: Pytester) -> None:\n        item = pytester.getitem(\n            \"\"\"\n            import pytest\n\n            class InvalidBool:\n                def __bool__(self):\n                    raise TypeError(\"INVALID\")\n\n            @pytest.mark.skipif(InvalidBool(), reason=\"xxx\")\n            def test_func():\n                pass\n        \"\"\"\n        )\n        with pytest.raises(pytest.fail.Exception) as excinfo:\n            evaluate_skip_marks(item)\n        assert excinfo.value.msg is not None\n        assert \"Error evaluating 'skipif' condition as a boolean\" in excinfo.value.msg\n        assert \"INVALID\" in excinfo.value.msg\n\n    def test_skipif_class(self, pytester: Pytester) -> None:\n        (item,) = pytester.getitems(\n            \"\"\"\n            import pytest\n            class TestClass(object):\n                pytestmark = pytest.mark.skipif(\"config._hackxyz\")\n                def test_func(self):\n                    pass\n        \"\"\"\n        )\n        item.config._hackxyz = 3  # type: ignore[attr-defined]\n        skipped = evaluate_skip_marks(item)\n        assert skipped\n        assert skipped."}, {"start_line": 5000, "end_line": 7000, "belongs_to": {"file_name": "skipping.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "at_exception_only(type(exc), exc),\n            ]\n            fail(\"\\n\".join(msglines), pytrace=False)\n\n    reason = mark.kwargs.get(\"reason\", None)\n    if reason is None:\n        if isinstance(condition, str):\n            reason = \"condition: \" + condition\n        else:\n            # XXX better be checked at collection time\n            msg = (\n                f\"Error evaluating {mark.name!r}: \"\n                + \"you need to specify reason=STRING when using booleans as conditions.\"\n            )\n            fail(msg, pytrace=False)\n\n    return result, reason\n\n\n@dataclasses.dataclass(frozen=True)\nclass Skip:\n    \"\"\"The result of evaluate_skip_marks().\"\"\"\n\n    reason: str = \"unconditional skip\"\n\n\ndef evaluate_skip_marks(item: Item) -> Skip | None:\n    \"\"\"Evaluate skip and skipif marks on item, returning Skip if triggered.\"\"\"\n    for mark in item.iter_markers(name=\"skipif\"):\n        if \"condition\" not in mark.kwargs:\n            conditions = mark.args\n        else:\n            conditions = (mark.kwargs[\"condition\"],)\n\n        # Unconditional.\n        if not conditions:\n            reason = mark.kwargs.get(\"reason\", \"\")\n            return Skip(reason)\n\n        # If any of the conditions are true.\n        for condition in conditions:\n            result, reason = evaluate_condition(item, mark, condition)\n            if result:\n                return Skip(reason)\n\n    for mark in item.iter_markers(name=\"skip\"):\n        try:\n            return Skip(*mark.args, **mark.kwargs)\n        except TypeError as e:\n            raise TypeError(str(e) + \" - maybe you meant pytest.mark.skipif?\") from None\n\n    return None\n\n\n@dataclasses.dataclass(frozen=True)\nclass Xfail:\n    \"\"\"The result of evaluate_xfail_marks().\"\"\"\n\n    __slots__ = (\"raises\", \"reason\", \"run\", \"strict\")\n\n    reason: str\n    run: bool\n    strict: bool\n    raises: (\n        type[BaseException]\n        | tuple[type[BaseException], ...]\n        | AbstractRaises[BaseException]\n        | None\n    )\n\n\ndef evaluate_xfail_mar"}, {"start_line": 4000, "end_line": 6000, "belongs_to": {"file_name": "skipping.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "name} condition>\"\n            condition_code = compile(condition, filename, \"eval\")\n            result = eval(condition_code, globals_)\n        except SyntaxError as exc:\n            msglines = [\n                f\"Error evaluating {mark.name!r} condition\",\n                \"    \" + condition,\n                \"    \" + \" \" * (exc.offset or 0) + \"^\",\n                \"SyntaxError: invalid syntax\",\n            ]\n            fail(\"\\n\".join(msglines), pytrace=False)\n        except Exception as exc:\n            msglines = [\n                f\"Error evaluating {mark.name!r} condition\",\n                \"    \" + condition,\n                *traceback.format_exception_only(type(exc), exc),\n            ]\n            fail(\"\\n\".join(msglines), pytrace=False)\n\n    # Boolean condition.\n    else:\n        try:\n            result = bool(condition)\n        except Exception as exc:\n            msglines = [\n                f\"Error evaluating {mark.name!r} condition as a boolean\",\n                *traceback.format_exception_only(type(exc), exc),\n            ]\n            fail(\"\\n\".join(msglines), pytrace=False)\n\n    reason = mark.kwargs.get(\"reason\", None)\n    if reason is None:\n        if isinstance(condition, str):\n            reason = \"condition: \" + condition\n        else:\n            # XXX better be checked at collection time\n            msg = (\n                f\"Error evaluating {mark.name!r}: \"\n                + \"you need to specify reason=STRING when using booleans as conditions.\"\n            )\n            fail(msg, pytrace=False)\n\n    return result, reason\n\n\n@dataclasses.dataclass(frozen=True)\nclass Skip:\n    \"\"\"The result of evaluate_skip_marks().\"\"\"\n\n    reason: str = \"unconditional skip\"\n\n\ndef evaluate_skip_marks(item: Item) -> Skip | None:\n    \"\"\"Evaluate skip and skipif marks on item, returning Skip if triggered.\"\"\"\n    for mark in item.iter_markers(name=\"skipif\"):\n        if \"condition\" not in mark.kwargs:\n            conditions = mark.args\n        else:\n            conditions "}, {"start_line": 0, "end_line": 2000, "belongs_to": {"file_name": "test_skipping.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "# mypy: allow-untyped-defs\nfrom __future__ import annotations\n\nimport sys\nimport textwrap\n\nfrom _pytest.pytester import Pytester\nfrom _pytest.runner import runtestprotocol\nfrom _pytest.skipping import evaluate_skip_marks\nfrom _pytest.skipping import evaluate_xfail_marks\nfrom _pytest.skipping import pytest_runtest_setup\nimport pytest\n\n\nclass TestEvaluation:\n    def test_no_marker(self, pytester: Pytester) -> None:\n        item = pytester.getitem(\"def test_func(): pass\")\n        skipped = evaluate_skip_marks(item)\n        assert not skipped\n\n    def test_marked_xfail_no_args(self, pytester: Pytester) -> None:\n        item = pytester.getitem(\n            \"\"\"\n            import pytest\n            @pytest.mark.xfail\n            def test_func():\n                pass\n        \"\"\"\n        )\n        xfailed = evaluate_xfail_marks(item)\n        assert xfailed\n        assert xfailed.reason == \"\"\n        assert xfailed.run\n\n    def test_marked_skipif_no_args(self, pytester: Pytester) -> None:\n        item = pytester.getitem(\n            \"\"\"\n            import pytest\n            @pytest.mark.skipif\n            def test_func():\n                pass\n        \"\"\"\n        )\n        skipped = evaluate_skip_marks(item)\n        assert skipped\n        assert skipped.reason == \"\"\n\n    def test_marked_one_arg(self, pytester: Pytester) -> None:\n        item = pytester.getitem(\n            \"\"\"\n            import pytest\n            @pytest.mark.skipif(\"hasattr(os, 'sep')\")\n            def test_func():\n                pass\n        \"\"\"\n        )\n        skipped = evaluate_skip_marks(item)\n        assert skipped\n        assert skipped.reason == \"condition: hasattr(os, 'sep')\"\n\n    def test_marked_one_arg_with_reason(self, pytester: Pytester) -> None:\n        item = pytester.getitem(\n            \"\"\"\n            import pytest\n            @pytest.mark.skipif(\"hasattr(os, 'sep')\", attr=2, reason=\"hello world\")\n            def test_func():\n                pass\n        \"\"\"\n        )\n        skipped = e"}, {"start_line": 2000, "end_line": 4000, "belongs_to": {"file_name": "test_skipping.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "valuate_skip_marks(item)\n        assert skipped\n        assert skipped.reason == \"hello world\"\n\n    def test_marked_one_arg_twice(self, pytester: Pytester) -> None:\n        lines = [\n            \"\"\"@pytest.mark.skipif(\"not hasattr(os, 'murks')\")\"\"\",\n            \"\"\"@pytest.mark.skipif(condition=\"hasattr(os, 'murks')\")\"\"\",\n        ]\n        for i in range(2):\n            item = pytester.getitem(\n                f\"\"\"\n                import pytest\n                {lines[i]}\n                {lines[(i + 1) % 2]}\n                def test_func():\n                    pass\n            \"\"\"\n            )\n            skipped = evaluate_skip_marks(item)\n            assert skipped\n            assert skipped.reason == \"condition: not hasattr(os, 'murks')\"\n\n    def test_marked_one_arg_twice2(self, pytester: Pytester) -> None:\n        item = pytester.getitem(\n            \"\"\"\n            import pytest\n            @pytest.mark.skipif(\"hasattr(os, 'murks')\")\n            @pytest.mark.skipif(\"not hasattr(os, 'murks')\")\n            def test_func():\n                pass\n        \"\"\"\n        )\n        skipped = evaluate_skip_marks(item)\n        assert skipped\n        assert skipped.reason == \"condition: not hasattr(os, 'murks')\"\n\n    def test_marked_skipif_with_boolean_without_reason(\n        self, pytester: Pytester\n    ) -> None:\n        item = pytester.getitem(\n            \"\"\"\n            import pytest\n            @pytest.mark.skipif(False)\n            def test_func():\n                pass\n        \"\"\"\n        )\n        with pytest.raises(pytest.fail.Exception) as excinfo:\n            evaluate_skip_marks(item)\n        assert excinfo.value.msg is not None\n        assert (\n            \"\"\"Error evaluating 'skipif': you need to specify reason=STRING when using booleans as conditions.\"\"\"\n            in excinfo.value.msg\n        )\n\n    def test_marked_skipif_with_invalid_boolean(self, pytester: Pytester) -> None:\n        item = pytester.getitem(\n            \"\"\"\n            import pytest\n\n        "}, {"start_line": 4000, "end_line": 6000, "belongs_to": {"file_name": "test_skipping.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "    class InvalidBool:\n                def __bool__(self):\n                    raise TypeError(\"INVALID\")\n\n            @pytest.mark.skipif(InvalidBool(), reason=\"xxx\")\n            def test_func():\n                pass\n        \"\"\"\n        )\n        with pytest.raises(pytest.fail.Exception) as excinfo:\n            evaluate_skip_marks(item)\n        assert excinfo.value.msg is not None\n        assert \"Error evaluating 'skipif' condition as a boolean\" in excinfo.value.msg\n        assert \"INVALID\" in excinfo.value.msg\n\n    def test_skipif_class(self, pytester: Pytester) -> None:\n        (item,) = pytester.getitems(\n            \"\"\"\n            import pytest\n            class TestClass(object):\n                pytestmark = pytest.mark.skipif(\"config._hackxyz\")\n                def test_func(self):\n                    pass\n        \"\"\"\n        )\n        item.config._hackxyz = 3  # type: ignore[attr-defined]\n        skipped = evaluate_skip_marks(item)\n        assert skipped\n        assert skipped.reason == \"condition: config._hackxyz\"\n\n    def test_skipif_markeval_namespace(self, pytester: Pytester) -> None:\n        pytester.makeconftest(\n            \"\"\"\n            import pytest\n\n            def pytest_markeval_namespace():\n                return {\"color\": \"green\"}\n            \"\"\"\n        )\n        p = pytester.makepyfile(\n            \"\"\"\n            import pytest\n\n            @pytest.mark.skipif(\"color == 'green'\")\n            def test_1():\n                assert True\n\n            @pytest.mark.skipif(\"color == 'red'\")\n            def test_2():\n                assert True\n        \"\"\"\n        )\n        res = pytester.runpytest(p)\n        assert res.ret == 0\n        res.stdout.fnmatch_lines([\"*1 skipped*\"])\n        res.stdout.fnmatch_lines([\"*1 passed*\"])\n\n    def test_skipif_markeval_namespace_multiple(self, pytester: Pytester) -> None:\n        \"\"\"Keys defined by ``pytest_markeval_namespace()`` in nested plugins override top-level ones.\"\"\"\n        root = pytester.mkdir(\"root\")\n"}, {"start_line": 1000, "end_line": 3000, "belongs_to": {"file_name": "test_skipping.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "   item = pytester.getitem(\n            \"\"\"\n            import pytest\n            @pytest.mark.skipif\n            def test_func():\n                pass\n        \"\"\"\n        )\n        skipped = evaluate_skip_marks(item)\n        assert skipped\n        assert skipped.reason == \"\"\n\n    def test_marked_one_arg(self, pytester: Pytester) -> None:\n        item = pytester.getitem(\n            \"\"\"\n            import pytest\n            @pytest.mark.skipif(\"hasattr(os, 'sep')\")\n            def test_func():\n                pass\n        \"\"\"\n        )\n        skipped = evaluate_skip_marks(item)\n        assert skipped\n        assert skipped.reason == \"condition: hasattr(os, 'sep')\"\n\n    def test_marked_one_arg_with_reason(self, pytester: Pytester) -> None:\n        item = pytester.getitem(\n            \"\"\"\n            import pytest\n            @pytest.mark.skipif(\"hasattr(os, 'sep')\", attr=2, reason=\"hello world\")\n            def test_func():\n                pass\n        \"\"\"\n        )\n        skipped = evaluate_skip_marks(item)\n        assert skipped\n        assert skipped.reason == \"hello world\"\n\n    def test_marked_one_arg_twice(self, pytester: Pytester) -> None:\n        lines = [\n            \"\"\"@pytest.mark.skipif(\"not hasattr(os, 'murks')\")\"\"\",\n            \"\"\"@pytest.mark.skipif(condition=\"hasattr(os, 'murks')\")\"\"\",\n        ]\n        for i in range(2):\n            item = pytester.getitem(\n                f\"\"\"\n                import pytest\n                {lines[i]}\n                {lines[(i + 1) % 2]}\n                def test_func():\n                    pass\n            \"\"\"\n            )\n            skipped = evaluate_skip_marks(item)\n            assert skipped\n            assert skipped.reason == \"condition: not hasattr(os, 'murks')\"\n\n    def test_marked_one_arg_twice2(self, pytester: Pytester) -> None:\n        item = pytester.getitem(\n            \"\"\"\n            import pytest\n            @pytest.mark.skipif(\"hasattr(os, 'murks')\")\n            @pytest.mark.skipif(\"not hasattr(os,"}, {"start_line": 6000, "end_line": 8000, "belongs_to": {"file_name": "skipping.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "= (mark.kwargs[\"condition\"],)\n\n        # Unconditional.\n        if not conditions:\n            reason = mark.kwargs.get(\"reason\", \"\")\n            return Skip(reason)\n\n        # If any of the conditions are true.\n        for condition in conditions:\n            result, reason = evaluate_condition(item, mark, condition)\n            if result:\n                return Skip(reason)\n\n    for mark in item.iter_markers(name=\"skip\"):\n        try:\n            return Skip(*mark.args, **mark.kwargs)\n        except TypeError as e:\n            raise TypeError(str(e) + \" - maybe you meant pytest.mark.skipif?\") from None\n\n    return None\n\n\n@dataclasses.dataclass(frozen=True)\nclass Xfail:\n    \"\"\"The result of evaluate_xfail_marks().\"\"\"\n\n    __slots__ = (\"raises\", \"reason\", \"run\", \"strict\")\n\n    reason: str\n    run: bool\n    strict: bool\n    raises: (\n        type[BaseException]\n        | tuple[type[BaseException], ...]\n        | AbstractRaises[BaseException]\n        | None\n    )\n\n\ndef evaluate_xfail_marks(item: Item) -> Xfail | None:\n    \"\"\"Evaluate xfail marks on item, returning Xfail if triggered.\"\"\"\n    for mark in item.iter_markers(name=\"xfail\"):\n        run = mark.kwargs.get(\"run\", True)\n        strict = mark.kwargs.get(\"strict\", item.config.getini(\"xfail_strict\"))\n        raises = mark.kwargs.get(\"raises\", None)\n        if \"condition\" not in mark.kwargs:\n            conditions = mark.args\n        else:\n            conditions = (mark.kwargs[\"condition\"],)\n\n        # Unconditional.\n        if not conditions:\n            reason = mark.kwargs.get(\"reason\", \"\")\n            return Xfail(reason, run, strict, raises)\n\n        # If any of the conditions are true.\n        for condition in conditions:\n            result, reason = evaluate_condition(item, mark, condition)\n            if result:\n                return Xfail(reason, run, strict, raises)\n\n    return None\n\n\n# Saves the xfail mark evaluation. Can be refreshed during call if None.\nxfailed_key = StashKey[Optional[Xfail]]()\n\n\n@hoo"}, {"start_line": 25000, "end_line": 27000, "belongs_to": {"file_name": "test_skipping.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "ef test_skip_no_reason(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n            @pytest.mark.skip\n            def test_foo():\n                pass\n        \"\"\"\n        )\n        result = pytester.runpytest(\"-rs\")\n        result.stdout.fnmatch_lines([\"*unconditional skip*\", \"*1 skipped*\"])\n\n    def test_skip_with_reason(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n            @pytest.mark.skip(reason=\"for lolz\")\n            def test_bar():\n                pass\n        \"\"\"\n        )\n        result = pytester.runpytest(\"-rs\")\n        result.stdout.fnmatch_lines([\"*for lolz*\", \"*1 skipped*\"])\n\n    def test_only_skips_marked_test(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n            @pytest.mark.skip\n            def test_foo():\n                pass\n            @pytest.mark.skip(reason=\"nothing in particular\")\n            def test_bar():\n                pass\n            def test_baz():\n                assert True\n        \"\"\"\n        )\n        result = pytester.runpytest(\"-rs\")\n        result.stdout.fnmatch_lines([\"*nothing in particular*\", \"*1 passed*2 skipped*\"])\n\n    def test_strict_and_skip(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n            @pytest.mark.skip\n            def test_hello():\n                pass\n        \"\"\"\n        )\n        result = pytester.runpytest(\"-rs\", \"--strict-markers\")\n        result.stdout.fnmatch_lines([\"*unconditional skip*\", \"*1 skipped*\"])\n\n    def test_wrong_skip_usage(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n            @pytest.mark.skip(False, reason=\"I thought this was skipif\")\n            def test_hello():\n                pass\n        \"\"\"\n        )\n        result = pytester.runpytest()\n        result.stdout.fnmatch_lines(\n   "}, {"start_line": 5000, "end_line": 7000, "belongs_to": {"file_name": "test_skipping.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "reason == \"condition: config._hackxyz\"\n\n    def test_skipif_markeval_namespace(self, pytester: Pytester) -> None:\n        pytester.makeconftest(\n            \"\"\"\n            import pytest\n\n            def pytest_markeval_namespace():\n                return {\"color\": \"green\"}\n            \"\"\"\n        )\n        p = pytester.makepyfile(\n            \"\"\"\n            import pytest\n\n            @pytest.mark.skipif(\"color == 'green'\")\n            def test_1():\n                assert True\n\n            @pytest.mark.skipif(\"color == 'red'\")\n            def test_2():\n                assert True\n        \"\"\"\n        )\n        res = pytester.runpytest(p)\n        assert res.ret == 0\n        res.stdout.fnmatch_lines([\"*1 skipped*\"])\n        res.stdout.fnmatch_lines([\"*1 passed*\"])\n\n    def test_skipif_markeval_namespace_multiple(self, pytester: Pytester) -> None:\n        \"\"\"Keys defined by ``pytest_markeval_namespace()`` in nested plugins override top-level ones.\"\"\"\n        root = pytester.mkdir(\"root\")\n        root.joinpath(\"__init__.py\").touch()\n        root.joinpath(\"conftest.py\").write_text(\n            textwrap.dedent(\n                \"\"\"\\\n            import pytest\n\n            def pytest_markeval_namespace():\n                return {\"arg\": \"root\"}\n            \"\"\"\n            ),\n            encoding=\"utf-8\",\n        )\n        root.joinpath(\"test_root.py\").write_text(\n            textwrap.dedent(\n                \"\"\"\\\n            import pytest\n\n            @pytest.mark.skipif(\"arg == 'root'\")\n            def test_root():\n                assert False\n            \"\"\"\n            ),\n            encoding=\"utf-8\",\n        )\n        foo = root.joinpath(\"foo\")\n        foo.mkdir()\n        foo.joinpath(\"__init__.py\").touch()\n        foo.joinpath(\"conftest.py\").write_text(\n            textwrap.dedent(\n                \"\"\"\\\n            import pytest\n\n            def pytest_markeval_namespace():\n                return {\"arg\": \"foo\"}\n            \"\"\"\n            ),\n            encoding=\"utf-8\",\n "}], "retrieved_count": 10, "cost_time": 1.1098482608795166}
{"question": "What is the execution semantics encoded by the return value from `pytester.runpytest_subprocess()`, and what specific exit code semantics does the `.ret` attribute represent in the context of pytest's test execution model?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"start_line": 39000, "end_line": 41000, "belongs_to": {"file_name": "pytester.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "sult of running pytest in-process, providing a similar\n        interface to what self.runpytest() provides.\"\"\"\n        syspathinsert = kwargs.pop(\"syspathinsert\", False)\n\n        if syspathinsert:\n            self.syspathinsert()\n        instant = timing.Instant()\n        capture = _get_multicapture(\"sys\")\n        capture.start_capturing()\n        try:\n            try:\n                reprec = self.inline_run(*args, **kwargs)\n            except SystemExit as e:\n                ret = e.args[0]\n                try:\n                    ret = ExitCode(e.args[0])\n                except ValueError:\n                    pass\n\n                class reprec:  # type: ignore\n                    ret = ret\n\n            except Exception:\n                traceback.print_exc()\n\n                class reprec:  # type: ignore\n                    ret = ExitCode(3)\n\n        finally:\n            out, err = capture.readouterr()\n            capture.stop_capturing()\n            sys.stdout.write(out)\n            sys.stderr.write(err)\n\n        assert reprec.ret is not None\n        res = RunResult(\n            reprec.ret, out.splitlines(), err.splitlines(), instant.elapsed().seconds\n        )\n        res.reprec = reprec  # type: ignore\n        return res\n\n    def runpytest(self, *args: str | os.PathLike[str], **kwargs: Any) -> RunResult:\n        \"\"\"Run pytest inline or in a subprocess, depending on the command line\n        option \"--runpytest\" and return a :py:class:`~pytest.RunResult`.\"\"\"\n        new_args = self._ensure_basetemp(args)\n        if self._method == \"inprocess\":\n            return self.runpytest_inprocess(*new_args, **kwargs)\n        elif self._method == \"subprocess\":\n            return self.runpytest_subprocess(*new_args, **kwargs)\n        raise RuntimeError(f\"Unrecognized runpytest option: {self._method}\")\n\n    def _ensure_basetemp(\n        self, args: Sequence[str | os.PathLike[str]]\n    ) -> list[str | os.PathLike[str]]:\n        new_args = list(args)\n        for x in new_args:\n"}, {"start_line": 24000, "end_line": 26000, "belongs_to": {"file_name": "test_pytester.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": " child = pytester.spawn_pytest(str(p1))\n    out = child.read()\n    assert child.wait() == 0, out.decode(\"utf8\")\n\n\ndef test_run_result_repr() -> None:\n    outlines = [\"some\", \"normal\", \"output\"]\n    errlines = [\"some\", \"nasty\", \"errors\", \"happened\"]\n\n    # known exit code\n    r = pytester_mod.RunResult(1, outlines, errlines, duration=0.5)\n    assert repr(r) == (\n        f\"<RunResult ret={pytest.ExitCode.TESTS_FAILED!s} len(stdout.lines)=3\"\n        \" len(stderr.lines)=4 duration=0.50s>\"\n    )\n\n    # unknown exit code: just the number\n    r = pytester_mod.RunResult(99, outlines, errlines, duration=0.5)\n    assert (\n        repr(r) == \"<RunResult ret=99 len(stdout.lines)=3\"\n        \" len(stderr.lines)=4 duration=0.50s>\"\n    )\n\n\ndef test_pytester_outcomes_with_multiple_errors(pytester: Pytester) -> None:\n    p1 = pytester.makepyfile(\n        \"\"\"\n        import pytest\n\n        @pytest.fixture\n        def bad_fixture():\n            raise Exception(\"bad\")\n\n        def test_error1(bad_fixture):\n            pass\n\n        def test_error2(bad_fixture):\n            pass\n    \"\"\"\n    )\n    result = pytester.runpytest(str(p1))\n    result.assert_outcomes(errors=2)\n\n    assert result.parseoutcomes() == {\"errors\": 2}\n\n\ndef test_parse_summary_line_always_plural() -> None:\n    \"\"\"Parsing summaries always returns plural nouns (#6505)\"\"\"\n    lines = [\n        \"some output 1\",\n        \"some output 2\",\n        \"======= 1 failed, 1 passed, 1 warning, 1 error in 0.13s ====\",\n        \"done.\",\n    ]\n    assert pytester_mod.RunResult.parse_summary_nouns(lines) == {\n        \"errors\": 1,\n        \"failed\": 1,\n        \"passed\": 1,\n        \"warnings\": 1,\n    }\n\n    lines = [\n        \"some output 1\",\n        \"some output 2\",\n        \"======= 1 failed, 1 passed, 2 warnings, 2 errors in 0.13s ====\",\n        \"done.\",\n    ]\n    assert pytester_mod.RunResult.parse_summary_nouns(lines) == {\n        \"errors\": 2,\n        \"failed\": 1,\n        \"passed\": 1,\n        \"warnings\": 2,\n    }\n\n\ndef test_makefile_joins_"}, {"start_line": 23000, "end_line": 25000, "belongs_to": {"file_name": "test_pytester.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "epyfile(\n                \"\"\"\n                import sys\n                print(sys.stdin.read())  # empty\n                print('stdout')\n                sys.stderr.write('stderr')\n                \"\"\"\n            )\n            proc = pytester.popen([sys.executable, str(p1)], stdin=None)\n            stdout, stderr = proc.communicate(b\"ignored\")\n            assert stdout.splitlines() == [b\"\", b\"stdout\"]\n            assert stderr.splitlines() == [b\"stderr\"]\n            assert proc.returncode == 0\n        '''\n    )\n    result = pytester.runpytest(\"-p\", \"pytester\", str(p1))\n    assert result.ret == 0\n\n\ndef test_spawn_uses_tmphome(pytester: Pytester) -> None:\n    tmphome = str(pytester.path)\n    assert os.environ.get(\"HOME\") == tmphome\n\n    pytester._monkeypatch.setenv(\"CUSTOMENV\", \"42\")\n\n    p1 = pytester.makepyfile(\n        f\"\"\"\n        import os\n\n        def test():\n            assert os.environ[\"HOME\"] == {tmphome!r}\n            assert os.environ[\"CUSTOMENV\"] == \"42\"\n        \"\"\"\n    )\n    child = pytester.spawn_pytest(str(p1))\n    out = child.read()\n    assert child.wait() == 0, out.decode(\"utf8\")\n\n\ndef test_run_result_repr() -> None:\n    outlines = [\"some\", \"normal\", \"output\"]\n    errlines = [\"some\", \"nasty\", \"errors\", \"happened\"]\n\n    # known exit code\n    r = pytester_mod.RunResult(1, outlines, errlines, duration=0.5)\n    assert repr(r) == (\n        f\"<RunResult ret={pytest.ExitCode.TESTS_FAILED!s} len(stdout.lines)=3\"\n        \" len(stderr.lines)=4 duration=0.50s>\"\n    )\n\n    # unknown exit code: just the number\n    r = pytester_mod.RunResult(99, outlines, errlines, duration=0.5)\n    assert (\n        repr(r) == \"<RunResult ret=99 len(stdout.lines)=3\"\n        \" len(stderr.lines)=4 duration=0.50s>\"\n    )\n\n\ndef test_pytester_outcomes_with_multiple_errors(pytester: Pytester) -> None:\n    p1 = pytester.makepyfile(\n        \"\"\"\n        import pytest\n\n        @pytest.fixture\n        def bad_fixture():\n            raise Exception(\"bad\")\n\n        def test_error1(bad_fixture):"}, {"start_line": 40000, "end_line": 42000, "belongs_to": {"file_name": "pytester.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": " sys.stderr.write(err)\n\n        assert reprec.ret is not None\n        res = RunResult(\n            reprec.ret, out.splitlines(), err.splitlines(), instant.elapsed().seconds\n        )\n        res.reprec = reprec  # type: ignore\n        return res\n\n    def runpytest(self, *args: str | os.PathLike[str], **kwargs: Any) -> RunResult:\n        \"\"\"Run pytest inline or in a subprocess, depending on the command line\n        option \"--runpytest\" and return a :py:class:`~pytest.RunResult`.\"\"\"\n        new_args = self._ensure_basetemp(args)\n        if self._method == \"inprocess\":\n            return self.runpytest_inprocess(*new_args, **kwargs)\n        elif self._method == \"subprocess\":\n            return self.runpytest_subprocess(*new_args, **kwargs)\n        raise RuntimeError(f\"Unrecognized runpytest option: {self._method}\")\n\n    def _ensure_basetemp(\n        self, args: Sequence[str | os.PathLike[str]]\n    ) -> list[str | os.PathLike[str]]:\n        new_args = list(args)\n        for x in new_args:\n            if str(x).startswith(\"--basetemp\"):\n                break\n        else:\n            new_args.append(\n                \"--basetemp={}\".format(self.path.parent.joinpath(\"basetemp\"))\n            )\n        return new_args\n\n    def parseconfig(self, *args: str | os.PathLike[str]) -> Config:\n        \"\"\"Return a new pytest :class:`pytest.Config` instance from given\n        commandline args.\n\n        This invokes the pytest bootstrapping code in _pytest.config to create a\n        new :py:class:`pytest.PytestPluginManager` and call the\n        :hook:`pytest_cmdline_parse` hook to create a new :class:`pytest.Config`\n        instance.\n\n        If :attr:`plugins` has been populated they should be plugin modules\n        to be registered with the plugin manager.\n        \"\"\"\n        import _pytest.config\n\n        new_args = [str(x) for x in self._ensure_basetemp(args)]\n\n        config = _pytest.config._prepareconfig(new_args, self.plugins)\n        # we don't know what the test will do with"}, {"start_line": 26000, "end_line": 28000, "belongs_to": {"file_name": "test_pytester.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "absolute_path(pytester: Pytester) -> None:\n    absfile = pytester.path / \"absfile\"\n    p1 = pytester.makepyfile(**{str(absfile): \"\"})\n    assert str(p1) == str(pytester.path / \"absfile.py\")\n\n\ndef test_pytester_makefile_dot_prefixes_extension_with_warning(\n    pytester: Pytester,\n) -> None:\n    with pytest.raises(\n        ValueError,\n        match=\"pytester.makefile expects a file extension, try .foo.bar instead of foo.bar\",\n    ):\n        pytester.makefile(\"foo.bar\", \"\")\n\n\n@pytest.mark.filterwarnings(\"default\")\ndef test_pytester_assert_outcomes_warnings(pytester: Pytester) -> None:\n    pytester.makepyfile(\n        \"\"\"\n        import warnings\n\n        def test_with_warning():\n            warnings.warn(UserWarning(\"some custom warning\"))\n        \"\"\"\n    )\n    result = pytester.runpytest()\n    result.assert_outcomes(passed=1, warnings=1)\n    # If warnings is not passed, it is not checked at all.\n    result.assert_outcomes(passed=1)\n\n\ndef test_pytester_outcomes_deselected(pytester: Pytester) -> None:\n    pytester.makepyfile(\n        \"\"\"\n        def test_one():\n            pass\n\n        def test_two():\n            pass\n        \"\"\"\n    )\n    result = pytester.runpytest(\"-k\", \"test_one\")\n    result.assert_outcomes(passed=1, deselected=1)\n    # If deselected is not passed, it is not checked at all.\n    result.assert_outcomes(passed=1)\n\n\ndef test_pytester_subprocess_with_string_plugins(pytester: Pytester) -> None:\n    \"\"\"Test that pytester.runpytest_subprocess is OK with named (string)\n    `.plugins`.\"\"\"\n    pytester.plugins = [\"pytester\"]\n\n    result = pytester.runpytest_subprocess()\n    assert result.ret == ExitCode.NO_TESTS_COLLECTED\n\n\ndef test_pytester_subprocess_with_non_string_plugins(pytester: Pytester) -> None:\n    \"\"\"Test that pytester.runpytest_subprocess fails with a proper error given\n    non-string `.plugins`.\"\"\"\n\n    class MyPlugin:\n        pass\n\n    pytester.plugins = [MyPlugin()]\n\n    with pytest.raises(ValueError, match=\"plugins as objects is not supported\")"}, {"start_line": 16000, "end_line": 18000, "belongs_to": {"file_name": "pytester.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "test.Pytester`.\"\"\"\n\n    def __init__(\n        self,\n        ret: int | ExitCode,\n        outlines: list[str],\n        errlines: list[str],\n        duration: float,\n    ) -> None:\n        try:\n            self.ret: int | ExitCode = ExitCode(ret)\n            \"\"\"The return value.\"\"\"\n        except ValueError:\n            self.ret = ret\n        self.outlines = outlines\n        \"\"\"List of lines captured from stdout.\"\"\"\n        self.errlines = errlines\n        \"\"\"List of lines captured from stderr.\"\"\"\n        self.stdout = LineMatcher(outlines)\n        \"\"\":class:`~pytest.LineMatcher` of stdout.\n\n        Use e.g. :func:`str(stdout) <pytest.LineMatcher.__str__()>` to reconstruct stdout, or the commonly used\n        :func:`stdout.fnmatch_lines() <pytest.LineMatcher.fnmatch_lines()>` method.\n        \"\"\"\n        self.stderr = LineMatcher(errlines)\n        \"\"\":class:`~pytest.LineMatcher` of stderr.\"\"\"\n        self.duration = duration\n        \"\"\"Duration in seconds.\"\"\"\n\n    def __repr__(self) -> str:\n        return (\n            f\"<RunResult ret={self.ret!s} \"\n            f\"len(stdout.lines)={len(self.stdout.lines)} \"\n            f\"len(stderr.lines)={len(self.stderr.lines)} \"\n            f\"duration={self.duration:.2f}s>\"\n        )\n\n    def parseoutcomes(self) -> dict[str, int]:\n        \"\"\"Return a dictionary of outcome noun -> count from parsing the terminal\n        output that the test process produced.\n\n        The returned nouns will always be in plural form::\n\n            ======= 1 failed, 1 passed, 1 warning, 1 error in 0.13s ====\n\n        Will return ``{\"failed\": 1, \"passed\": 1, \"warnings\": 1, \"errors\": 1}``.\n        \"\"\"\n        return self.parse_summary_nouns(self.outlines)\n\n    @classmethod\n    def parse_summary_nouns(cls, lines) -> dict[str, int]:\n        \"\"\"Extract the nouns from a pytest terminal summary line.\n\n        It always returns the plural noun for consistency::\n\n            ======= 1 failed, 1 passed, 1 warning, 1 error in 0.13s ====\n\n        Will return ``{\""}, {"start_line": 54000, "end_line": 56000, "belongs_to": {"file_name": "acceptance_test.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "ent directory to PYTHONPATH which avoids\n        # the bug. We also use pytest rather than python -m pytest for the same\n        # PYTHONPATH reason.\n        subprocess.run(\n            [\"pytest\", \"my_package\"],\n            capture_output=True,\n            check=True,\n            encoding=\"utf-8\",\n            text=True,\n        )\n    except subprocess.CalledProcessError as exc:\n        raise AssertionError(\n            f\"pytest command failed:\\n{exc.stdout=!s}\\n{exc.stderr=!s}\"\n        ) from exc\n\n\ndef test_no_terminal_plugin(pytester: Pytester) -> None:\n    \"\"\"Smoke test to ensure pytest can execute without the terminal plugin (#9422).\"\"\"\n    pytester.makepyfile(\"def test(): assert 1 == 2\")\n    result = pytester.runpytest(\"-pno:terminal\", \"-s\")\n    assert result.ret == ExitCode.TESTS_FAILED\n\n\ndef test_stop_iteration_from_collect(pytester: Pytester) -> None:\n    pytester.makepyfile(test_it=\"raise StopIteration('hello')\")\n    result = pytester.runpytest()\n    assert result.ret == ExitCode.INTERRUPTED\n    result.assert_outcomes(failed=0, passed=0, errors=1)\n    result.stdout.fnmatch_lines(\n        [\n            \"=* short test summary info =*\",\n            \"ERROR test_it.py - StopIteration: hello\",\n            \"!* Interrupted: 1 error during collection !*\",\n            \"=* 1 error in * =*\",\n        ]\n    )\n\n\ndef test_stop_iteration_runtest_protocol(pytester: Pytester) -> None:\n    pytester.makepyfile(\n        test_it=\"\"\"\n        import pytest\n        @pytest.fixture\n        def fail_setup():\n            raise StopIteration(1)\n        def test_fail_setup(fail_setup):\n            pass\n        def test_fail_teardown(request):\n            def stop_iteration():\n                raise StopIteration(2)\n            request.addfinalizer(stop_iteration)\n        def test_fail_call():\n            raise StopIteration(3)\n        \"\"\"\n    )\n    result = pytester.runpytest()\n    assert result.ret == ExitCode.TESTS_FAILED\n    result.assert_outcomes(failed=1, passed=1, errors=2)\n    resul"}, {"start_line": 50000, "end_line": 52000, "belongs_to": {"file_name": "pytester.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "r:\n            print(f\"couldn't print to {fp} because of encoding\")\n\n    def _getpytestargs(self) -> tuple[str, ...]:\n        return sys.executable, \"-mpytest\"\n\n    def runpython(self, script: os.PathLike[str]) -> RunResult:\n        \"\"\"Run a python script using sys.executable as interpreter.\"\"\"\n        return self.run(sys.executable, script)\n\n    def runpython_c(self, command: str) -> RunResult:\n        \"\"\"Run ``python -c \"command\"``.\"\"\"\n        return self.run(sys.executable, \"-c\", command)\n\n    def runpytest_subprocess(\n        self, *args: str | os.PathLike[str], timeout: float | None = None\n    ) -> RunResult:\n        \"\"\"Run pytest as a subprocess with given arguments.\n\n        Any plugins added to the :py:attr:`plugins` list will be added using the\n        ``-p`` command line option.  Additionally ``--basetemp`` is used to put\n        any temporary files and directories in a numbered directory prefixed\n        with \"runpytest-\" to not conflict with the normal numbered pytest\n        location for temporary files and directories.\n\n        :param args:\n            The sequence of arguments to pass to the pytest subprocess.\n        :param timeout:\n            The period in seconds after which to timeout and raise\n            :py:class:`Pytester.TimeoutExpired`.\n        :returns:\n            The result.\n        \"\"\"\n        __tracebackhide__ = True\n        p = make_numbered_dir(root=self.path, prefix=\"runpytest-\", mode=0o700)\n        args = (f\"--basetemp={p}\", *args)\n        for plugin in self.plugins:\n            if not isinstance(plugin, str):\n                raise ValueError(\n                    f\"Specifying plugins as objects is not supported in pytester subprocess mode; \"\n                    f\"specify by name instead: {plugin}\"\n                )\n            args = (\"-p\", plugin, *args)\n        args = self._getpytestargs() + args\n        return self.run(*args, timeout=timeout)\n\n    def spawn_pytest(self, string: str, expect_timeout: float = 10.0) -> pexpect.spawn"}, {"start_line": 43000, "end_line": 45000, "belongs_to": {"file_name": "acceptance_test.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "       assert 0\n\n        def test2():\n            gc.collect()\n            assert ref() is None\n    \"\"\"\n    )\n    result = pytester.runpytest_subprocess()\n    result.stdout.fnmatch_lines([\"*1 failed, 1 passed in*\"])\n\n\ndef test_fixture_mock_integration(pytester: Pytester) -> None:\n    \"\"\"Test that decorators applied to fixture are left working (#3774)\"\"\"\n    p = pytester.copy_example(\"acceptance/fixture_mock_integration.py\")\n    result = pytester.runpytest(p)\n    result.stdout.fnmatch_lines([\"*1 passed*\"])\n\n\ndef test_usage_error_code(pytester: Pytester) -> None:\n    result = pytester.runpytest(\"-unknown-option-\")\n    assert result.ret == ExitCode.USAGE_ERROR\n\n\ndef test_error_on_async_function(pytester: Pytester) -> None:\n    # In the below we .close() the coroutine only to avoid\n    # \"RuntimeWarning: coroutine 'test_2' was never awaited\"\n    # which messes with other tests.\n    pytester.makepyfile(\n        test_async=\"\"\"\n        async def test_1():\n            pass\n        async def test_2():\n            pass\n        def test_3():\n            coro = test_2()\n            coro.close()\n            return coro\n    \"\"\"\n    )\n    result = pytester.runpytest()\n    result.stdout.fnmatch_lines(\n        [\n            \"*async def functions are not natively supported*\",\n            \"*test_async.py::test_1*\",\n            \"*test_async.py::test_2*\",\n            \"*test_async.py::test_3*\",\n        ]\n    )\n    result.assert_outcomes(failed=3)\n\n\ndef test_error_on_async_gen_function(pytester: Pytester) -> None:\n    pytester.makepyfile(\n        test_async=\"\"\"\n        async def test_1():\n            yield\n        async def test_2():\n            yield\n        def test_3():\n            return test_2()\n    \"\"\"\n    )\n    result = pytester.runpytest()\n    result.stdout.fnmatch_lines(\n        [\n            \"*async def functions are not natively supported*\",\n            \"*test_async.py::test_1*\",\n            \"*test_async.py::test_2*\",\n            \"*test_async.py::test_3*\",\n        ]\n    )\n    r"}, {"start_line": 10000, "end_line": 12000, "belongs_to": {"file_name": "test_runner.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "eturncode(self, pytester: Pytester) -> None:\n        rec = pytester.inline_runsource(\n            \"\"\"\n            def test_func():\n                pass\n            def teardown_function(func):\n                raise ValueError(42)\n        \"\"\"\n        )\n        assert rec.ret == 1\n\n    def test_logstart_logfinish_hooks(self, pytester: Pytester) -> None:\n        rec = pytester.inline_runsource(\n            \"\"\"\n            import pytest\n            def test_func():\n                pass\n        \"\"\"\n        )\n        reps = rec.getcalls(\"pytest_runtest_logstart pytest_runtest_logfinish\")\n        assert [x._name for x in reps] == [\n            \"pytest_runtest_logstart\",\n            \"pytest_runtest_logfinish\",\n        ]\n        for rep in reps:\n            assert rep.nodeid == \"test_logstart_logfinish_hooks.py::test_func\"\n            assert rep.location == (\"test_logstart_logfinish_hooks.py\", 1, \"test_func\")\n\n    def test_exact_teardown_issue90(self, pytester: Pytester) -> None:\n        rec = pytester.inline_runsource(\n            \"\"\"\n            import pytest\n\n            class TestClass(object):\n                def test_method(self):\n                    pass\n                def teardown_class(cls):\n                    raise Exception()\n\n            def test_func():\n                import sys\n                # on python2 exc_info is kept till a function exits\n                # so we would end up calling test functions while\n                # sys.exc_info would return the indexerror\n                # from guessing the lastitem\n                excinfo = sys.exc_info()\n                import traceback\n                assert excinfo[0] is None, \\\n                       traceback.format_exception(*excinfo)\n            def teardown_function(func):\n                raise ValueError(42)\n        \"\"\"\n        )\n        reps = rec.getreports(\"pytest_runtest_logreport\")\n        print(reps)\n        for i in range(2):\n            assert reps[i].nodeid.endswith(\"test_method\")\n            a"}], "retrieved_count": 10, "cost_time": 1.1384108066558838}
{"question": "What is the sentinel value abstraction pattern that NotSetType implements within the pytest compatibility layer to decouple internal state representation from external API contracts?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"start_line": 0, "end_line": 2000, "belongs_to": {"file_name": "compat.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "# mypy: allow-untyped-defs\n\"\"\"Python version compatibility code.\"\"\"\n\nfrom __future__ import annotations\n\nfrom collections.abc import Callable\nimport enum\nimport functools\nimport inspect\nfrom inspect import Parameter\nfrom inspect import Signature\nimport os\nfrom pathlib import Path\nimport sys\nfrom typing import Any\nfrom typing import Final\nfrom typing import NoReturn\n\nimport py\n\n\nif sys.version_info >= (3, 14):\n    from annotationlib import Format\n\n\n#: constant to prepare valuing pylib path replacements/lazy proxies later on\n#  intended for removal in pytest 8.0 or 9.0\n\n# fmt: off\n# intentional space to create a fake difference for the verification\nLEGACY_PATH = py.path. local\n# fmt: on\n\n\ndef legacy_path(path: str | os.PathLike[str]) -> LEGACY_PATH:\n    \"\"\"Internal wrapper to prepare lazy proxies for legacy_path instances\"\"\"\n    return LEGACY_PATH(path)\n\n\n# fmt: off\n# Singleton type for NOTSET, as described in:\n# https://www.python.org/dev/peps/pep-0484/#support-for-singleton-types-in-unions\nclass NotSetType(enum.Enum):\n    token = 0\nNOTSET: Final = NotSetType.token\n# fmt: on\n\n\ndef iscoroutinefunction(func: object) -> bool:\n    \"\"\"Return True if func is a coroutine function (a function defined with async\n    def syntax, and doesn't contain yield), or a function decorated with\n    @asyncio.coroutine.\n\n    Note: copied and modified from Python 3.5's builtin coroutines.py to avoid\n    importing asyncio directly, which in turns also initializes the \"logging\"\n    module as a side-effect (see issue #8).\n    \"\"\"\n    return inspect.iscoroutinefunction(func) or getattr(func, \"_is_coroutine\", False)\n\n\ndef is_async_function(func: object) -> bool:\n    \"\"\"Return True if the given function seems to be an async function or\n    an async generator.\"\"\"\n    return iscoroutinefunction(func) or inspect.isasyncgenfunction(func)\n\n\ndef signature(obj: Callable[..., Any]) -> Signature:\n    \"\"\"Return signature without evaluating annotations.\"\"\"\n    if sys.version_info >= (3, 14):\n        return"}, {"start_line": 7000, "end_line": 9000, "belongs_to": {"file_name": "structures.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest/mark", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "\n                    fail(\n                        msg.format(\n                            nodeid=nodeid,\n                            values=param.values,\n                            names=argnames,\n                            names_len=len(argnames),\n                            values_len=len(param.values),\n                        ),\n                        pytrace=False,\n                    )\n        else:\n            # Empty parameter set (likely computed at runtime): create a single\n            # parameter set with NOTSET values, with the \"empty parameter set\" mark applied to it.\n            mark = get_empty_parameterset_mark(config, argnames, func)\n            parameters.append(\n                ParameterSet(\n                    values=(NOTSET,) * len(argnames), marks=[mark], id=\"NOTSET\"\n                )\n            )\n        return argnames, parameters\n\n\n@final\n@dataclasses.dataclass(frozen=True)\nclass Mark:\n    \"\"\"A pytest mark.\"\"\"\n\n    #: Name of the mark.\n    name: str\n    #: Positional arguments of the mark decorator.\n    args: tuple[Any, ...]\n    #: Keyword arguments of the mark decorator.\n    kwargs: Mapping[str, Any]\n\n    #: Source Mark for ids with parametrize Marks.\n    _param_ids_from: Mark | None = dataclasses.field(default=None, repr=False)\n    #: Resolved/generated ids with parametrize Marks.\n    _param_ids_generated: Sequence[str] | None = dataclasses.field(\n        default=None, repr=False\n    )\n\n    def __init__(\n        self,\n        name: str,\n        args: tuple[Any, ...],\n        kwargs: Mapping[str, Any],\n        param_ids_from: Mark | None = None,\n        param_ids_generated: Sequence[str] | None = None,\n        *,\n        _ispytest: bool = False,\n    ) -> None:\n        \"\"\":meta private:\"\"\"\n        check_ispytest(_ispytest)\n        # Weirdness to bypass frozen=True.\n        object.__setattr__(self, \"name\", name)\n        object.__setattr__(self, \"args\", args)\n        object.__setattr__(self, \"kwargs\", kwargs)\n        object.__setattr__(sel"}, {"start_line": 3000, "end_line": 5000, "belongs_to": {"file_name": "structures.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest/mark", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": ", 2, 42, id=\"everything\"),\n            ],\n        )\n        # ParameterSet(values=(1, 2, 3), marks=(), id=None)\n        # ParameterSet(values=(2, 2, 3), marks=(), id=\"everything\")\n    \"\"\"\n\n    values: Sequence[object | NotSetType]\n    marks: Collection[MarkDecorator | Mark]\n    id: str | _HiddenParam | None\n\n    @classmethod\n    def param(\n        cls,\n        *values: object,\n        marks: MarkDecorator | Collection[MarkDecorator | Mark] = (),\n        id: str | _HiddenParam | None = None,\n    ) -> ParameterSet:\n        if isinstance(marks, MarkDecorator):\n            marks = (marks,)\n        else:\n            assert isinstance(marks, collections.abc.Collection)\n        if any(i.name == \"usefixtures\" for i in marks):\n            raise ValueError(\n                \"pytest.param cannot add pytest.mark.usefixtures; see \"\n                \"https://docs.pytest.org/en/stable/reference/reference.html#pytest-param\"\n            )\n\n        if id is not None:\n            if not isinstance(id, str) and id is not HIDDEN_PARAM:\n                raise TypeError(\n                    \"Expected id to be a string or a `pytest.HIDDEN_PARAM` sentinel, \"\n                    f\"got {type(id)}: {id!r}\",\n                )\n        return cls(values, marks, id)\n\n    @classmethod\n    def extract_from(\n        cls,\n        parameterset: ParameterSet | Sequence[object] | object,\n        force_tuple: bool = False,\n    ) -> ParameterSet:\n        \"\"\"Extract from an object or objects.\n\n        :param parameterset:\n            A legacy style parameterset that may or may not be a tuple,\n            and may or may not be wrapped into a mess of mark objects.\n\n        :param force_tuple:\n            Enforce tuple wrapping so single argument tuple values\n            don't get decomposed and break tests.\n        \"\"\"\n        if isinstance(parameterset, cls):\n            return parameterset\n        if force_tuple:\n            return cls.param(parameterset)\n        else:\n            # TODO: Refactor to fix this "}, {"start_line": 0, "end_line": 2000, "belongs_to": {"file_name": "structures.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest/mark", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "# mypy: allow-untyped-defs\nfrom __future__ import annotations\n\nimport collections.abc\nfrom collections.abc import Callable\nfrom collections.abc import Collection\nfrom collections.abc import Iterable\nfrom collections.abc import Iterator\nfrom collections.abc import Mapping\nfrom collections.abc import MutableMapping\nfrom collections.abc import Sequence\nimport dataclasses\nimport enum\nimport inspect\nfrom typing import Any\nfrom typing import final\nfrom typing import NamedTuple\nfrom typing import overload\nfrom typing import TYPE_CHECKING\nfrom typing import TypeVar\nfrom typing import Union\nimport warnings\n\nfrom .._code import getfslineno\nfrom ..compat import NOTSET\nfrom ..compat import NotSetType\nfrom _pytest.config import Config\nfrom _pytest.deprecated import check_ispytest\nfrom _pytest.deprecated import MARKED_FIXTURE\nfrom _pytest.outcomes import fail\nfrom _pytest.raises import AbstractRaises\nfrom _pytest.scope import _ScopeName\nfrom _pytest.warning_types import PytestUnknownMarkWarning\n\n\nif TYPE_CHECKING:\n    from ..nodes import Node\n\n\nEMPTY_PARAMETERSET_OPTION = \"empty_parameter_set_mark\"\n\n\n# Singleton type for HIDDEN_PARAM, as described in:\n# https://www.python.org/dev/peps/pep-0484/#support-for-singleton-types-in-unions\nclass _HiddenParam(enum.Enum):\n    token = 0\n\n\n#: Can be used as a parameter set id to hide it from the test name.\nHIDDEN_PARAM = _HiddenParam.token\n\n\ndef istestfunc(func) -> bool:\n    return callable(func) and getattr(func, \"__name__\", \"<lambda>\") != \"<lambda>\"\n\n\ndef get_empty_parameterset_mark(\n    config: Config, argnames: Sequence[str], func\n) -> MarkDecorator:\n    from ..nodes import Collector\n\n    argslisting = \", \".join(argnames)\n\n    fs, lineno = getfslineno(func)\n    reason = f\"got empty parameter set for ({argslisting})\"\n    requested_mark = config.getini(EMPTY_PARAMETERSET_OPTION)\n    if requested_mark in (\"\", None, \"skip\"):\n        mark = MARK_GEN.skip(reason=reason)\n    elif requested_mark == \"xfail\":\n        mark = MARK_GEN.xfail(reason=r"}, {"start_line": 1000, "end_line": 3000, "belongs_to": {"file_name": "structures.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest/mark", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": " TYPE_CHECKING:\n    from ..nodes import Node\n\n\nEMPTY_PARAMETERSET_OPTION = \"empty_parameter_set_mark\"\n\n\n# Singleton type for HIDDEN_PARAM, as described in:\n# https://www.python.org/dev/peps/pep-0484/#support-for-singleton-types-in-unions\nclass _HiddenParam(enum.Enum):\n    token = 0\n\n\n#: Can be used as a parameter set id to hide it from the test name.\nHIDDEN_PARAM = _HiddenParam.token\n\n\ndef istestfunc(func) -> bool:\n    return callable(func) and getattr(func, \"__name__\", \"<lambda>\") != \"<lambda>\"\n\n\ndef get_empty_parameterset_mark(\n    config: Config, argnames: Sequence[str], func\n) -> MarkDecorator:\n    from ..nodes import Collector\n\n    argslisting = \", \".join(argnames)\n\n    fs, lineno = getfslineno(func)\n    reason = f\"got empty parameter set for ({argslisting})\"\n    requested_mark = config.getini(EMPTY_PARAMETERSET_OPTION)\n    if requested_mark in (\"\", None, \"skip\"):\n        mark = MARK_GEN.skip(reason=reason)\n    elif requested_mark == \"xfail\":\n        mark = MARK_GEN.xfail(reason=reason, run=False)\n    elif requested_mark == \"fail_at_collect\":\n        raise Collector.CollectError(\n            f\"Empty parameter set in '{func.__name__}' at line {lineno + 1}\"\n        )\n    else:\n        raise LookupError(requested_mark)\n    return mark\n\n\nclass ParameterSet(NamedTuple):\n    \"\"\"A set of values for a set of parameters along with associated marks and\n    an optional ID for the set.\n\n    Examples::\n\n        pytest.param(1, 2, 3)\n        # ParameterSet(values=(1, 2, 3), marks=(), id=None)\n\n        pytest.param(\"hello\", id=\"greeting\")\n        # ParameterSet(values=(\"hello\",), marks=(), id=\"greeting\")\n\n        # Parameter set with marks\n        pytest.param(42, marks=pytest.mark.xfail)\n        # ParameterSet(values=(42,), marks=(MarkDecorator(...),), id=None)\n\n        # From parametrize mark (parameter names + list of parameter sets)\n        pytest.mark.parametrize(\n            (\"a\", \"b\", \"expected\"),\n            [\n                (1, 2, 3),\n                pytest.param(40"}, {"start_line": 0, "end_line": 2000, "belongs_to": {"file_name": "fixtures.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "# mypy: allow-untyped-defs\nfrom __future__ import annotations\n\nimport abc\nfrom collections import defaultdict\nfrom collections import deque\nfrom collections import OrderedDict\nfrom collections.abc import Callable\nfrom collections.abc import Generator\nfrom collections.abc import Iterable\nfrom collections.abc import Iterator\nfrom collections.abc import Mapping\nfrom collections.abc import MutableMapping\nfrom collections.abc import Sequence\nfrom collections.abc import Set as AbstractSet\nimport dataclasses\nimport functools\nimport inspect\nimport os\nfrom pathlib import Path\nimport sys\nimport types\nfrom typing import Any\nfrom typing import cast\nfrom typing import Final\nfrom typing import final\nfrom typing import Generic\nfrom typing import NoReturn\nfrom typing import Optional\nfrom typing import overload\nfrom typing import TYPE_CHECKING\nfrom typing import TypeVar\nfrom typing import Union\nimport warnings\n\nimport _pytest\nfrom _pytest import nodes\nfrom _pytest._code import getfslineno\nfrom _pytest._code import Source\nfrom _pytest._code.code import FormattedExcinfo\nfrom _pytest._code.code import TerminalRepr\nfrom _pytest._io import TerminalWriter\nfrom _pytest.compat import assert_never\nfrom _pytest.compat import get_real_func\nfrom _pytest.compat import getfuncargnames\nfrom _pytest.compat import getimfunc\nfrom _pytest.compat import getlocation\nfrom _pytest.compat import NOTSET\nfrom _pytest.compat import NotSetType\nfrom _pytest.compat import safe_getattr\nfrom _pytest.compat import safe_isclass\nfrom _pytest.compat import signature\nfrom _pytest.config import _PluggyPlugin\nfrom _pytest.config import Config\nfrom _pytest.config import ExitCode\nfrom _pytest.config.argparsing import Parser\nfrom _pytest.deprecated import check_ispytest\nfrom _pytest.deprecated import MARKED_FIXTURE\nfrom _pytest.deprecated import YIELD_FIXTURE\nfrom _pytest.main import Session\nfrom _pytest.mark import Mark\nfrom _pytest.mark import ParameterSet\nfrom _pytest.mark.structures import MarkDecorator\nfrom _pytest.out"}, {"start_line": 1000, "end_line": 3000, "belongs_to": {"file_name": "__init__.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest/config", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "ager\n\nfrom .compat import PathAwareHookProxy\nfrom .exceptions import PrintHelp as PrintHelp\nfrom .exceptions import UsageError as UsageError\nfrom .findpaths import determine_setup\nfrom _pytest import __version__\nimport _pytest._code\nfrom _pytest._code import ExceptionInfo\nfrom _pytest._code import filter_traceback\nfrom _pytest._code.code import TracebackStyle\nfrom _pytest._io import TerminalWriter\nfrom _pytest.config.argparsing import Argument\nfrom _pytest.config.argparsing import Parser\nimport _pytest.deprecated\nimport _pytest.hookspec\nfrom _pytest.outcomes import fail\nfrom _pytest.outcomes import Skipped\nfrom _pytest.pathlib import absolutepath\nfrom _pytest.pathlib import bestrelpath\nfrom _pytest.pathlib import import_path\nfrom _pytest.pathlib import ImportMode\nfrom _pytest.pathlib import resolve_package_path\nfrom _pytest.pathlib import safe_exists\nfrom _pytest.stash import Stash\nfrom _pytest.warning_types import PytestConfigWarning\nfrom _pytest.warning_types import warn_explicit_for\n\n\nif TYPE_CHECKING:\n    from _pytest.assertion.rewrite import AssertionRewritingHook\n    from _pytest.cacheprovider import Cache\n    from _pytest.terminal import TerminalReporter\n\n_PluggyPlugin = object\n\"\"\"A type to represent plugin objects.\n\nPlugins can be any namespace, so we can't narrow it down much, but we use an\nalias to make the intent clear.\n\nIdeally this type would be provided by pluggy itself.\n\"\"\"\n\n\nhookimpl = HookimplMarker(\"pytest\")\nhookspec = HookspecMarker(\"pytest\")\n\n\n@final\nclass ExitCode(enum.IntEnum):\n    \"\"\"Encodes the valid exit codes by pytest.\n\n    Currently users and plugins may supply other exit codes as well.\n\n    .. versionadded:: 5.0\n    \"\"\"\n\n    #: Tests passed.\n    OK = 0\n    #: Tests failed.\n    TESTS_FAILED = 1\n    #: pytest was interrupted.\n    INTERRUPTED = 2\n    #: An internal error got in the way.\n    INTERNAL_ERROR = 3\n    #: pytest was misused.\n    USAGE_ERROR = 4\n    #: pytest couldn't find tests.\n    NO_TESTS_COLLECTED = 5\n\n\nclass ConftestImportFa"}, {"start_line": 1000, "end_line": 3000, "belongs_to": {"file_name": "fixtures.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "_code import Source\nfrom _pytest._code.code import FormattedExcinfo\nfrom _pytest._code.code import TerminalRepr\nfrom _pytest._io import TerminalWriter\nfrom _pytest.compat import assert_never\nfrom _pytest.compat import get_real_func\nfrom _pytest.compat import getfuncargnames\nfrom _pytest.compat import getimfunc\nfrom _pytest.compat import getlocation\nfrom _pytest.compat import NOTSET\nfrom _pytest.compat import NotSetType\nfrom _pytest.compat import safe_getattr\nfrom _pytest.compat import safe_isclass\nfrom _pytest.compat import signature\nfrom _pytest.config import _PluggyPlugin\nfrom _pytest.config import Config\nfrom _pytest.config import ExitCode\nfrom _pytest.config.argparsing import Parser\nfrom _pytest.deprecated import check_ispytest\nfrom _pytest.deprecated import MARKED_FIXTURE\nfrom _pytest.deprecated import YIELD_FIXTURE\nfrom _pytest.main import Session\nfrom _pytest.mark import Mark\nfrom _pytest.mark import ParameterSet\nfrom _pytest.mark.structures import MarkDecorator\nfrom _pytest.outcomes import fail\nfrom _pytest.outcomes import skip\nfrom _pytest.outcomes import TEST_OUTCOME\nfrom _pytest.pathlib import absolutepath\nfrom _pytest.pathlib import bestrelpath\nfrom _pytest.scope import _ScopeName\nfrom _pytest.scope import HIGH_SCOPES\nfrom _pytest.scope import Scope\nfrom _pytest.warning_types import PytestRemovedIn9Warning\nfrom _pytest.warning_types import PytestWarning\n\n\nif sys.version_info < (3, 11):\n    from exceptiongroup import BaseExceptionGroup\n\n\nif TYPE_CHECKING:\n    from _pytest.python import CallSpec2\n    from _pytest.python import Function\n    from _pytest.python import Metafunc\n\n\n# The value of the fixture -- return/yield of the fixture function (type variable).\nFixtureValue = TypeVar(\"FixtureValue\")\n# The type of the fixture function (type variable).\nFixtureFunction = TypeVar(\"FixtureFunction\", bound=Callable[..., object])\n# The type of a fixture function (type alias generic in fixture value).\n_FixtureFunc = Union[\n    Callable[..., FixtureValue], Callable[."}, {"start_line": 2000, "end_line": 4000, "belongs_to": {"file_name": "structures.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest/mark", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "eason, run=False)\n    elif requested_mark == \"fail_at_collect\":\n        raise Collector.CollectError(\n            f\"Empty parameter set in '{func.__name__}' at line {lineno + 1}\"\n        )\n    else:\n        raise LookupError(requested_mark)\n    return mark\n\n\nclass ParameterSet(NamedTuple):\n    \"\"\"A set of values for a set of parameters along with associated marks and\n    an optional ID for the set.\n\n    Examples::\n\n        pytest.param(1, 2, 3)\n        # ParameterSet(values=(1, 2, 3), marks=(), id=None)\n\n        pytest.param(\"hello\", id=\"greeting\")\n        # ParameterSet(values=(\"hello\",), marks=(), id=\"greeting\")\n\n        # Parameter set with marks\n        pytest.param(42, marks=pytest.mark.xfail)\n        # ParameterSet(values=(42,), marks=(MarkDecorator(...),), id=None)\n\n        # From parametrize mark (parameter names + list of parameter sets)\n        pytest.mark.parametrize(\n            (\"a\", \"b\", \"expected\"),\n            [\n                (1, 2, 3),\n                pytest.param(40, 2, 42, id=\"everything\"),\n            ],\n        )\n        # ParameterSet(values=(1, 2, 3), marks=(), id=None)\n        # ParameterSet(values=(2, 2, 3), marks=(), id=\"everything\")\n    \"\"\"\n\n    values: Sequence[object | NotSetType]\n    marks: Collection[MarkDecorator | Mark]\n    id: str | _HiddenParam | None\n\n    @classmethod\n    def param(\n        cls,\n        *values: object,\n        marks: MarkDecorator | Collection[MarkDecorator | Mark] = (),\n        id: str | _HiddenParam | None = None,\n    ) -> ParameterSet:\n        if isinstance(marks, MarkDecorator):\n            marks = (marks,)\n        else:\n            assert isinstance(marks, collections.abc.Collection)\n        if any(i.name == \"usefixtures\" for i in marks):\n            raise ValueError(\n                \"pytest.param cannot add pytest.mark.usefixtures; see \"\n                \"https://docs.pytest.org/en/stable/reference/reference.html#pytest-param\"\n            )\n\n        if id is not None:\n            if not isinstance(id, str)"}, {"start_line": 0, "end_line": 2000, "belongs_to": {"file_name": "test_conftest.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "# mypy: allow-untyped-defs\nfrom __future__ import annotations\n\nfrom collections.abc import Generator\nfrom collections.abc import Sequence\nimport os\nfrom pathlib import Path\nimport textwrap\nfrom typing import cast\n\nfrom _pytest.config import ExitCode\nfrom _pytest.config import PytestPluginManager\nfrom _pytest.monkeypatch import MonkeyPatch\nfrom _pytest.pathlib import symlink_or_skip\nfrom _pytest.pytester import Pytester\nfrom _pytest.tmpdir import TempPathFactory\nimport pytest\n\n\ndef ConftestWithSetinitial(path) -> PytestPluginManager:\n    conftest = PytestPluginManager()\n    conftest_setinitial(conftest, [path])\n    return conftest\n\n\ndef conftest_setinitial(\n    conftest: PytestPluginManager,\n    args: Sequence[str | Path],\n    confcutdir: Path | None = None,\n) -> None:\n    conftest._set_initial_conftests(\n        args=args,\n        pyargs=False,\n        noconftest=False,\n        rootpath=Path(args[0]),\n        confcutdir=confcutdir,\n        invocation_dir=Path.cwd(),\n        importmode=\"prepend\",\n        consider_namespace_packages=False,\n    )\n\n\n@pytest.mark.usefixtures(\"_sys_snapshot\")\nclass TestConftestValueAccessGlobal:\n    @pytest.fixture(scope=\"module\", params=[\"global\", \"inpackage\"])\n    def basedir(self, request, tmp_path_factory: TempPathFactory) -> Generator[Path]:\n        tmp_path = tmp_path_factory.mktemp(\"basedir\", numbered=True)\n        tmp_path.joinpath(\"adir/b\").mkdir(parents=True)\n        tmp_path.joinpath(\"adir/conftest.py\").write_text(\n            \"a=1 ; Directory = 3\", encoding=\"utf-8\"\n        )\n        tmp_path.joinpath(\"adir/b/conftest.py\").write_text(\n            \"b=2 ; a = 1.5\", encoding=\"utf-8\"\n        )\n        if request.param == \"inpackage\":\n            tmp_path.joinpath(\"adir/__init__.py\").touch()\n            tmp_path.joinpath(\"adir/b/__init__.py\").touch()\n\n        yield tmp_path\n\n    def test_basic_init(self, basedir: Path) -> None:\n        conftest = PytestPluginManager()\n        p = basedir / \"adir\"\n        conftest._loadconftestmodule"}], "retrieved_count": 10, "cost_time": 1.1201999187469482}
{"question": "How does the FastFilesCompleter.__call__ method reconcile the dual glob expansion strategies for handling hidden files versus wildcard patterns, and what is the algorithmic consequence of applying prefix_dir stripping after sorting?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"start_line": 1000, "end_line": 3000, "belongs_to": {"file_name": "test_argcomplete.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "esCompleter:\n    \"\"\"File completer class, optionally takes a list of allowed extensions.\"\"\"\n\n    def __init__(self, allowednames=(), directories=True):\n        # Fix if someone passes in a string instead of a list\n        if type(allowednames) is str:\n            allowednames = [allowednames]\n\n        self.allowednames = [x.lstrip(\"*\").lstrip(\".\") for x in allowednames]\n        self.directories = directories\n\n    def __call__(self, prefix, **kwargs):\n        completion = []\n        if self.allowednames:\n            if self.directories:\n                files = _wrapcall([\"bash\", \"-c\", f\"compgen -A directory -- '{prefix}'\"])\n                completion += [f + \"/\" for f in files]\n            for x in self.allowednames:\n                completion += _wrapcall(\n                    [\"bash\", \"-c\", f\"compgen -A file -X '!*.{x}' -- '{prefix}'\"]\n                )\n        else:\n            completion += _wrapcall([\"bash\", \"-c\", f\"compgen -A file -- '{prefix}'\"])\n\n            anticomp = _wrapcall([\"bash\", \"-c\", f\"compgen -A directory -- '{prefix}'\"])\n\n            completion = list(set(completion) - set(anticomp))\n\n            if self.directories:\n                completion += [f + \"/\" for f in anticomp]\n        return completion\n\n\nclass TestArgComplete:\n    @pytest.mark.skipif(\"sys.platform in ('win32', 'darwin')\")\n    def test_compare_with_compgen(\n        self, tmp_path: Path, monkeypatch: MonkeyPatch\n    ) -> None:\n        from _pytest._argcomplete import FastFilesCompleter\n\n        ffc = FastFilesCompleter()\n        fc = FilesCompleter()\n\n        monkeypatch.chdir(tmp_path)\n\n        assert equal_with_bash(\"\", ffc, fc, out=sys.stdout)\n\n        tmp_path.cwd().joinpath(\"data\").touch()\n\n        for x in [\"d\", \"data\", \"doesnotexist\", \"\"]:\n            assert equal_with_bash(x, ffc, fc, out=sys.stdout)\n\n    @pytest.mark.skipif(\"sys.platform in ('win32', 'darwin')\")\n    def test_remove_dir_prefix(self):\n        \"\"\"This is not compatible with compgen but it is with bash itself: ls /"}, {"start_line": 2000, "end_line": 3241, "belongs_to": {"file_name": "test_argcomplete.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "[\"bash\", \"-c\", f\"compgen -A directory -- '{prefix}'\"])\n\n            completion = list(set(completion) - set(anticomp))\n\n            if self.directories:\n                completion += [f + \"/\" for f in anticomp]\n        return completion\n\n\nclass TestArgComplete:\n    @pytest.mark.skipif(\"sys.platform in ('win32', 'darwin')\")\n    def test_compare_with_compgen(\n        self, tmp_path: Path, monkeypatch: MonkeyPatch\n    ) -> None:\n        from _pytest._argcomplete import FastFilesCompleter\n\n        ffc = FastFilesCompleter()\n        fc = FilesCompleter()\n\n        monkeypatch.chdir(tmp_path)\n\n        assert equal_with_bash(\"\", ffc, fc, out=sys.stdout)\n\n        tmp_path.cwd().joinpath(\"data\").touch()\n\n        for x in [\"d\", \"data\", \"doesnotexist\", \"\"]:\n            assert equal_with_bash(x, ffc, fc, out=sys.stdout)\n\n    @pytest.mark.skipif(\"sys.platform in ('win32', 'darwin')\")\n    def test_remove_dir_prefix(self):\n        \"\"\"This is not compatible with compgen but it is with bash itself: ls /usr/<TAB>.\"\"\"\n        from _pytest._argcomplete import FastFilesCompleter\n\n        ffc = FastFilesCompleter()\n        fc = FilesCompleter()\n        for x in \"/usr/\".split():\n            assert not equal_with_bash(x, ffc, fc, out=sys.stdout)\n"}, {"start_line": 2000, "end_line": 3776, "belongs_to": {"file_name": "_argcomplete.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "the magic line has been found, 1 if not.\n\n- Sometimes it helps to find early on errors using:\n    _ARGCOMPLETE=1 _ARC_DEBUG=1 appname\n  which should throw a KeyError: 'COMPLINE' (which is properly set by the\n  global argcomplete script).\n\"\"\"\n\nfrom __future__ import annotations\n\nimport argparse\nfrom glob import glob\nimport os\nimport sys\nfrom typing import Any\n\n\nclass FastFilesCompleter:\n    \"\"\"Fast file completer class.\"\"\"\n\n    def __init__(self, directories: bool = True) -> None:\n        self.directories = directories\n\n    def __call__(self, prefix: str, **kwargs: Any) -> list[str]:\n        # Only called on non option completions.\n        if os.sep in prefix[1:]:\n            prefix_dir = len(os.path.dirname(prefix) + os.sep)\n        else:\n            prefix_dir = 0\n        completion = []\n        globbed = []\n        if \"*\" not in prefix and \"?\" not in prefix:\n            # We are on unix, otherwise no bash.\n            if not prefix or prefix[-1] == os.sep:\n                globbed.extend(glob(prefix + \".*\"))\n            prefix += \"*\"\n        globbed.extend(glob(prefix))\n        for x in sorted(globbed):\n            if os.path.isdir(x):\n                x += \"/\"\n            # Append stripping the prefix (like bash, not like compgen).\n            completion.append(x[prefix_dir:])\n        return completion\n\n\nif os.environ.get(\"_ARGCOMPLETE\"):\n    try:\n        import argcomplete.completers\n    except ImportError:\n        sys.exit(-1)\n    filescompleter: FastFilesCompleter | None = FastFilesCompleter()\n\n    def try_argcomplete(parser: argparse.ArgumentParser) -> None:\n        argcomplete.autocomplete(parser, always_complete_options=False)\n\nelse:\n\n    def try_argcomplete(parser: argparse.ArgumentParser) -> None:\n        pass\n\n    filescompleter = None\n"}, {"start_line": 1000, "end_line": 3000, "belongs_to": {"file_name": "_argcomplete.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "startup script generated by pip.\nYou can speed up completion somewhat by changing this script to include\n  # PYTHON_ARGCOMPLETE_OK\nso the python-argcomplete-check-easy-install-script does not\nneed to be called to find the entry point of the code and see if that is\nmarked  with PYTHON_ARGCOMPLETE_OK.\n\nINSTALL/DEBUGGING\n=================\n\nTo include this support in another application that has setup.py generated\nscripts:\n\n- Add the line:\n    # PYTHON_ARGCOMPLETE_OK\n  near the top of the main python entry point.\n\n- Include in the file calling parse_args():\n    from _argcomplete import try_argcomplete, filescompleter\n  Call try_argcomplete just before parse_args(), and optionally add\n  filescompleter to the positional arguments' add_argument().\n\nIf things do not work right away:\n\n- Switch on argcomplete debugging with (also helpful when doing custom\n  completers):\n    export _ARC_DEBUG=1\n\n- Run:\n    python-argcomplete-check-easy-install-script $(which appname)\n    echo $?\n  will echo 0 if the magic line has been found, 1 if not.\n\n- Sometimes it helps to find early on errors using:\n    _ARGCOMPLETE=1 _ARC_DEBUG=1 appname\n  which should throw a KeyError: 'COMPLINE' (which is properly set by the\n  global argcomplete script).\n\"\"\"\n\nfrom __future__ import annotations\n\nimport argparse\nfrom glob import glob\nimport os\nimport sys\nfrom typing import Any\n\n\nclass FastFilesCompleter:\n    \"\"\"Fast file completer class.\"\"\"\n\n    def __init__(self, directories: bool = True) -> None:\n        self.directories = directories\n\n    def __call__(self, prefix: str, **kwargs: Any) -> list[str]:\n        # Only called on non option completions.\n        if os.sep in prefix[1:]:\n            prefix_dir = len(os.path.dirname(prefix) + os.sep)\n        else:\n            prefix_dir = 0\n        completion = []\n        globbed = []\n        if \"*\" not in prefix and \"?\" not in prefix:\n            # We are on unix, otherwise no bash.\n            if not prefix or prefix[-1] == os.sep:\n                globbed.ext"}, {"start_line": 0, "end_line": 2000, "belongs_to": {"file_name": "test_argcomplete.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "# mypy: allow-untyped-defs\nfrom __future__ import annotations\n\nfrom pathlib import Path\nimport subprocess\nimport sys\n\nfrom _pytest.monkeypatch import MonkeyPatch\nimport pytest\n\n\n# Test for _argcomplete but not specific for any application.\n\n\ndef equal_with_bash(prefix, ffc, fc, out=None):\n    res = ffc(prefix)\n    res_bash = set(fc(prefix))\n    retval = set(res) == res_bash\n    if out:\n        out.write(f\"equal_with_bash({prefix}) {retval} {res}\\n\")\n        if not retval:\n            out.write(\" python - bash: %s\\n\" % (set(res) - res_bash))\n            out.write(\" bash - python: %s\\n\" % (res_bash - set(res)))\n    return retval\n\n\n# Copied from argcomplete.completers as import from there.\n# Also pulls in argcomplete.__init__ which opens filedescriptor 9.\n# This gives an OSError at the end of testrun.\n\n\ndef _wrapcall(*args, **kargs):\n    try:\n        return subprocess.check_output(*args, **kargs).decode().splitlines()\n    except subprocess.CalledProcessError:\n        return []\n\n\nclass FilesCompleter:\n    \"\"\"File completer class, optionally takes a list of allowed extensions.\"\"\"\n\n    def __init__(self, allowednames=(), directories=True):\n        # Fix if someone passes in a string instead of a list\n        if type(allowednames) is str:\n            allowednames = [allowednames]\n\n        self.allowednames = [x.lstrip(\"*\").lstrip(\".\") for x in allowednames]\n        self.directories = directories\n\n    def __call__(self, prefix, **kwargs):\n        completion = []\n        if self.allowednames:\n            if self.directories:\n                files = _wrapcall([\"bash\", \"-c\", f\"compgen -A directory -- '{prefix}'\"])\n                completion += [f + \"/\" for f in files]\n            for x in self.allowednames:\n                completion += _wrapcall(\n                    [\"bash\", \"-c\", f\"compgen -A file -X '!*.{x}' -- '{prefix}'\"]\n                )\n        else:\n            completion += _wrapcall([\"bash\", \"-c\", f\"compgen -A file -- '{prefix}'\"])\n\n            anticomp = _wrapcall("}, {"start_line": 4000, "end_line": 6000, "belongs_to": {"file_name": "path.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest/_py", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "     self.ignore = ignore\n        self.breadthfirst = bf\n        self.optsort = cast(Callable[[Any], Any], sorted) if sort else (lambda x: x)\n\n    def gen(self, path):\n        try:\n            entries = path.listdir()\n        except self.ignore:\n            return\n        rec = self.rec\n        dirs = self.optsort(\n            [p for p in entries if p.check(dir=1) and (rec is None or rec(p))]\n        )\n        if not self.breadthfirst:\n            for subdir in dirs:\n                yield from self.gen(subdir)\n        for p in self.optsort(entries):\n            if self.fil is None or self.fil(p):\n                yield p\n        if self.breadthfirst:\n            for subdir in dirs:\n                yield from self.gen(subdir)\n\n\nclass FNMatcher:\n    def __init__(self, pattern):\n        self.pattern = pattern\n\n    def __call__(self, path):\n        pattern = self.pattern\n\n        if (\n            pattern.find(path.sep) == -1\n            and iswin32\n            and pattern.find(posixpath.sep) != -1\n        ):\n            # Running on Windows, the pattern has no Windows path separators,\n            # and the pattern has one or more Posix path separators. Replace\n            # the Posix path separators with the Windows path separator.\n            pattern = pattern.replace(posixpath.sep, path.sep)\n\n        if pattern.find(path.sep) == -1:\n            name = path.basename\n        else:\n            name = str(path)  # path.strpath # XXX svn?\n            if not os.path.isabs(pattern):\n                pattern = \"*\" + path.sep + pattern\n        return fnmatch.fnmatch(name, pattern)\n\n\ndef map_as_list(func, iter):\n    return list(map(func, iter))\n\n\nclass Stat:\n    if TYPE_CHECKING:\n\n        @property\n        def size(self) -> int: ...\n\n        @property\n        def mtime(self) -> float: ...\n\n    def __getattr__(self, name: str) -> Any:\n        return getattr(self._osstatresult, \"st_\" + name)\n\n    def __init__(self, path, osstatresult):\n        self.path = path\n        self._osstatr"}, {"start_line": 3000, "end_line": 5000, "belongs_to": {"file_name": "path.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest/_py", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "he: Stat\n\n    def _stat(self) -> Stat:\n        try:\n            return self._statcache\n        except AttributeError:\n            try:\n                self._statcache = self.path.stat()\n            except error.ELOOP:\n                self._statcache = self.path.lstat()\n            return self._statcache\n\n    def dir(self):\n        return S_ISDIR(self._stat().mode)\n\n    def file(self):\n        return S_ISREG(self._stat().mode)\n\n    def exists(self):\n        return self._stat()\n\n    def link(self):\n        st = self.path.lstat()\n        return S_ISLNK(st.mode)\n\n\nclass NeverRaised(Exception):\n    pass\n\n\nclass Visitor:\n    def __init__(self, fil, rec, ignore, bf, sort):\n        if isinstance(fil, str):\n            fil = FNMatcher(fil)\n        if isinstance(rec, str):\n            self.rec: Callable[[LocalPath], bool] = FNMatcher(rec)\n        elif not hasattr(rec, \"__call__\") and rec:\n            self.rec = lambda path: True\n        else:\n            self.rec = rec\n        self.fil = fil\n        self.ignore = ignore\n        self.breadthfirst = bf\n        self.optsort = cast(Callable[[Any], Any], sorted) if sort else (lambda x: x)\n\n    def gen(self, path):\n        try:\n            entries = path.listdir()\n        except self.ignore:\n            return\n        rec = self.rec\n        dirs = self.optsort(\n            [p for p in entries if p.check(dir=1) and (rec is None or rec(p))]\n        )\n        if not self.breadthfirst:\n            for subdir in dirs:\n                yield from self.gen(subdir)\n        for p in self.optsort(entries):\n            if self.fil is None or self.fil(p):\n                yield p\n        if self.breadthfirst:\n            for subdir in dirs:\n                yield from self.gen(subdir)\n\n\nclass FNMatcher:\n    def __init__(self, pattern):\n        self.pattern = pattern\n\n    def __call__(self, path):\n        pattern = self.pattern\n\n        if (\n            pattern.find(path.sep) == -1\n            and iswin32\n            and pattern.find(posixpath.sep"}, {"start_line": 0, "end_line": 631, "belongs_to": {"file_name": "bench_argcomplete.py", "upper_path": "/data2/raymone/swebench-repos/pytest/bench", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "# 10000 iterations, just for relative comparison\n#                      2.7.5     3.3.2\n# FilesCompleter       75.1109   69.2116\n# FastFilesCompleter    0.7383    1.0760\nfrom __future__ import annotations\n\nimport timeit\n\n\nimports = [\n    \"from argcomplete.completers import FilesCompleter as completer\",\n    \"from _pytest._argcomplete import FastFilesCompleter as completer\",\n]\n\ncount = 1000  # only a few seconds\nsetup = \"%s\\nfc = completer()\"\nrun = 'fc(\"/d\")'\n\n\nif __name__ == \"__main__\":\n    print(timeit.timeit(run, setup=setup % imports[0], number=count))\n    print(timeit.timeit(run, setup=setup % imports[1], number=count))\n"}, {"start_line": 16000, "end_line": 18000, "belongs_to": {"file_name": "path.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest/_py", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "ot matching the\n        path will not be yielded, defaulting to None (everything is\n        returned)\n\n        rec is a filter (glob pattern or callable) that controls whether\n        a node is descended, defaulting to None\n\n        ignore is an Exception class that is ignoredwhen calling dirlist()\n        on any of the paths (by default, all exceptions are reported)\n\n        bf if True will cause a breadthfirst search instead of the\n        default depthfirst. Default: False\n\n        sort if True will sort entries within each directory level.\n        \"\"\"\n        yield from Visitor(fil, rec, ignore, bf, sort).gen(self)\n\n    def _sortlist(self, res, sort):\n        if sort:\n            if hasattr(sort, \"__call__\"):\n                warnings.warn(\n                    DeprecationWarning(\n                        \"listdir(sort=callable) is deprecated and breaks on python3\"\n                    ),\n                    stacklevel=3,\n                )\n                res.sort(sort)\n            else:\n                res.sort()\n\n    def __fspath__(self):\n        return self.strpath\n\n    def __hash__(self):\n        s = self.strpath\n        if iswin32:\n            s = s.lower()\n        return hash(s)\n\n    def __eq__(self, other):\n        s1 = os.fspath(self)\n        try:\n            s2 = os.fspath(other)\n        except TypeError:\n            return False\n        if iswin32:\n            s1 = s1.lower()\n            try:\n                s2 = s2.lower()\n            except AttributeError:\n                return False\n        return s1 == s2\n\n    def __ne__(self, other):\n        return not (self == other)\n\n    def __lt__(self, other):\n        return os.fspath(self) < os.fspath(other)\n\n    def __gt__(self, other):\n        return os.fspath(self) > os.fspath(other)\n\n    def samefile(self, other):\n        \"\"\"Return True if 'other' references the same file as 'self'.\"\"\"\n        other = os.fspath(other)\n        if not isabs(other):\n            other = abspath(other)\n        if self == other:\n "}, {"start_line": 2000, "end_line": 4000, "belongs_to": {"file_name": "path.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest/_py", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "                  pass\n            if meth is None:\n                raise TypeError(f\"no {name!r} checker available for {self.path!r}\")\n            try:\n                if getrawcode(meth).co_argcount > 1:\n                    if (not meth(value)) ^ invert:\n                        return False\n                else:\n                    if bool(value) ^ bool(meth()) ^ invert:\n                        return False\n            except (error.ENOENT, error.ENOTDIR, error.EBUSY):\n                # EBUSY feels not entirely correct,\n                # but its kind of necessary since ENOMEDIUM\n                # is not accessible in python\n                for name in self._depend_on_existence:\n                    if name in kw:\n                        if kw.get(name):\n                            return False\n                    name = \"not\" + name\n                    if name in kw:\n                        if not kw.get(name):\n                            return False\n        return True\n\n    _statcache: Stat\n\n    def _stat(self) -> Stat:\n        try:\n            return self._statcache\n        except AttributeError:\n            try:\n                self._statcache = self.path.stat()\n            except error.ELOOP:\n                self._statcache = self.path.lstat()\n            return self._statcache\n\n    def dir(self):\n        return S_ISDIR(self._stat().mode)\n\n    def file(self):\n        return S_ISREG(self._stat().mode)\n\n    def exists(self):\n        return self._stat()\n\n    def link(self):\n        st = self.path.lstat()\n        return S_ISLNK(st.mode)\n\n\nclass NeverRaised(Exception):\n    pass\n\n\nclass Visitor:\n    def __init__(self, fil, rec, ignore, bf, sort):\n        if isinstance(fil, str):\n            fil = FNMatcher(fil)\n        if isinstance(rec, str):\n            self.rec: Callable[[LocalPath], bool] = FNMatcher(rec)\n        elif not hasattr(rec, \"__call__\") and rec:\n            self.rec = lambda path: True\n        else:\n            self.rec = rec\n        self.fil = fil\n   "}], "retrieved_count": 10, "cost_time": 1.1132566928863525}
{"question": "Why does the repeated fixture instantiation and teardown cycle in test_package_fixture_complex impact performance when scaling to hundreds of package-scoped fixtures with autouse dependencies?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"start_line": 57000, "end_line": 59000, "belongs_to": {"file_name": "fixtures.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing/python", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "def teardown_module():\n                    values[:] = []\n                \"\"\"\n            ),\n            encoding=\"utf-8\",\n        )\n        package.joinpath(\"test_x.py\").write_text(\n            textwrap.dedent(\n                \"\"\"\\\n                from .. import values\n                def test_x():\n                    assert values == [\"package2\"]\n                \"\"\"\n            ),\n            encoding=\"utf-8\",\n        )\n        reprec = pytester.inline_run()\n        reprec.assertoutcome(passed=2)\n\n    def test_package_fixture_complex(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            __init__=\"\"\"\\\n            values = []\n        \"\"\"\n        )\n        pytester.syspathinsert(pytester.path.name)\n        package = pytester.mkdir(\"package\")\n        package.joinpath(\"__init__.py\").write_text(\"\", encoding=\"utf-8\")\n        package.joinpath(\"conftest.py\").write_text(\n            textwrap.dedent(\n                \"\"\"\\\n                import pytest\n                from .. import values\n                @pytest.fixture(scope=\"package\")\n                def one():\n                    values.append(\"package\")\n                    yield values\n                    values.pop()\n                @pytest.fixture(scope=\"package\", autouse=True)\n                def two():\n                    values.append(\"package-auto\")\n                    yield values\n                    values.pop()\n                \"\"\"\n            ),\n            encoding=\"utf-8\",\n        )\n        package.joinpath(\"test_x.py\").write_text(\n            textwrap.dedent(\n                \"\"\"\\\n                from .. import values\n                def test_package_autouse():\n                    assert values == [\"package-auto\"]\n                def test_package(one):\n                    assert values == [\"package-auto\", \"package\"]\n                \"\"\"\n            ),\n            encoding=\"utf-8\",\n        )\n        reprec = pytester.inline_run()\n        reprec.assertoutcome(passed=2)\n\n    def test_collect_c"}, {"start_line": 136000, "end_line": 138000, "belongs_to": {"file_name": "fixtures.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing/python", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "turenames == \"p_sub m_conf m_sub m_test f1\".split()\n\n    def test_func_closure_all_scopes_complex(self, pytester: Pytester) -> None:\n        \"\"\"Complex test involving all scopes and mixing autouse with normal fixtures\"\"\"\n        pytester.makeconftest(\n            \"\"\"\n            import pytest\n\n            @pytest.fixture(scope='session')\n            def s1(): pass\n\n            @pytest.fixture(scope='package', autouse=True)\n            def p1(): pass\n        \"\"\"\n        )\n        pytester.makepyfile(**{\"__init__.py\": \"\"})\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n\n            @pytest.fixture(scope='module', autouse=True)\n            def m1(): pass\n\n            @pytest.fixture(scope='module')\n            def m2(s1): pass\n\n            @pytest.fixture(scope='function')\n            def f1(): pass\n\n            @pytest.fixture(scope='function')\n            def f2(): pass\n\n            class Test:\n\n                @pytest.fixture(scope='class', autouse=True)\n                def c1(self):\n                    pass\n\n                def test_func(self, f2, f1, m2):\n                    pass\n        \"\"\"\n        )\n        items, _ = pytester.inline_genitems()\n        assert isinstance(items[0], Function)\n        request = TopRequest(items[0], _ispytest=True)\n        assert request.fixturenames == \"s1 p1 m1 m2 c1 f2 f1\".split()\n\n    def test_parametrized_package_scope_reordering(self, pytester: Pytester) -> None:\n        \"\"\"A parameterized package-scoped fixture correctly reorders items to\n        minimize setups & teardowns.\n\n        Regression test for #12328.\n        \"\"\"\n        pytester.makepyfile(\n            __init__=\"\",\n            conftest=\"\"\"\n                import pytest\n                @pytest.fixture(scope=\"package\", params=[\"a\", \"b\"])\n                def fix(request):\n                    return request.param\n            \"\"\",\n            test_1=\"def test1(fix): pass\",\n            test_2=\"def test2(fix): pass\",\n        )\n\n        result = pyte"}, {"start_line": 56000, "end_line": 58000, "belongs_to": {"file_name": "fixtures.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing/python", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "\n        )\n        package = pytester.mkdir(\"package\")\n        package.joinpath(\"__init__.py\").write_text(\n            textwrap.dedent(\n                \"\"\"\\\n                from .. import values\n                def setup_module():\n                    values.append(\"package\")\n                def teardown_module():\n                    values[:] = []\n                \"\"\"\n            ),\n            encoding=\"utf-8\",\n        )\n        package.joinpath(\"test_x.py\").write_text(\n            textwrap.dedent(\n                \"\"\"\\\n                from .. import values\n                def test_x():\n                    assert values == [\"package\"]\n                \"\"\"\n            ),\n            encoding=\"utf-8\",\n        )\n        package = pytester.mkdir(\"package2\")\n        package.joinpath(\"__init__.py\").write_text(\n            textwrap.dedent(\n                \"\"\"\\\n                from .. import values\n                def setup_module():\n                    values.append(\"package2\")\n                def teardown_module():\n                    values[:] = []\n                \"\"\"\n            ),\n            encoding=\"utf-8\",\n        )\n        package.joinpath(\"test_x.py\").write_text(\n            textwrap.dedent(\n                \"\"\"\\\n                from .. import values\n                def test_x():\n                    assert values == [\"package2\"]\n                \"\"\"\n            ),\n            encoding=\"utf-8\",\n        )\n        reprec = pytester.inline_run()\n        reprec.assertoutcome(passed=2)\n\n    def test_package_fixture_complex(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            __init__=\"\"\"\\\n            values = []\n        \"\"\"\n        )\n        pytester.syspathinsert(pytester.path.name)\n        package = pytester.mkdir(\"package\")\n        package.joinpath(\"__init__.py\").write_text(\"\", encoding=\"utf-8\")\n        package.joinpath(\"conftest.py\").write_text(\n            textwrap.dedent(\n                \"\"\"\\\n                import pytest\n                from ."}, {"start_line": 137000, "end_line": 139000, "belongs_to": {"file_name": "fixtures.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing/python", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "         def c1(self):\n                    pass\n\n                def test_func(self, f2, f1, m2):\n                    pass\n        \"\"\"\n        )\n        items, _ = pytester.inline_genitems()\n        assert isinstance(items[0], Function)\n        request = TopRequest(items[0], _ispytest=True)\n        assert request.fixturenames == \"s1 p1 m1 m2 c1 f2 f1\".split()\n\n    def test_parametrized_package_scope_reordering(self, pytester: Pytester) -> None:\n        \"\"\"A parameterized package-scoped fixture correctly reorders items to\n        minimize setups & teardowns.\n\n        Regression test for #12328.\n        \"\"\"\n        pytester.makepyfile(\n            __init__=\"\",\n            conftest=\"\"\"\n                import pytest\n                @pytest.fixture(scope=\"package\", params=[\"a\", \"b\"])\n                def fix(request):\n                    return request.param\n            \"\"\",\n            test_1=\"def test1(fix): pass\",\n            test_2=\"def test2(fix): pass\",\n        )\n\n        result = pytester.runpytest(\"--setup-plan\")\n        assert result.ret == ExitCode.OK\n        result.stdout.fnmatch_lines(\n            [\n                \"  SETUP    P fix['a']\",\n                \"        test_1.py::test1[a] (fixtures used: fix, request)\",\n                \"        test_2.py::test2[a] (fixtures used: fix, request)\",\n                \"  TEARDOWN P fix['a']\",\n                \"  SETUP    P fix['b']\",\n                \"        test_1.py::test1[b] (fixtures used: fix, request)\",\n                \"        test_2.py::test2[b] (fixtures used: fix, request)\",\n                \"  TEARDOWN P fix['b']\",\n            ],\n        )\n\n    def test_multiple_packages(self, pytester: Pytester) -> None:\n        \"\"\"Complex test involving multiple package fixtures. Make sure teardowns\n        are executed in order.\n        .\n         root\n             __init__.py\n             sub1\n                __init__.py\n                conftest.py\n                test_1.py\n             sub2\n          "}, {"start_line": 138000, "end_line": 140000, "belongs_to": {"file_name": "fixtures.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing/python", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "ster.runpytest(\"--setup-plan\")\n        assert result.ret == ExitCode.OK\n        result.stdout.fnmatch_lines(\n            [\n                \"  SETUP    P fix['a']\",\n                \"        test_1.py::test1[a] (fixtures used: fix, request)\",\n                \"        test_2.py::test2[a] (fixtures used: fix, request)\",\n                \"  TEARDOWN P fix['a']\",\n                \"  SETUP    P fix['b']\",\n                \"        test_1.py::test1[b] (fixtures used: fix, request)\",\n                \"        test_2.py::test2[b] (fixtures used: fix, request)\",\n                \"  TEARDOWN P fix['b']\",\n            ],\n        )\n\n    def test_multiple_packages(self, pytester: Pytester) -> None:\n        \"\"\"Complex test involving multiple package fixtures. Make sure teardowns\n        are executed in order.\n        .\n         root\n             __init__.py\n             sub1\n                __init__.py\n                conftest.py\n                test_1.py\n             sub2\n                 __init__.py\n                 conftest.py\n                 test_2.py\n        \"\"\"\n        root = pytester.mkdir(\"root\")\n        root.joinpath(\"__init__.py\").write_text(\"values = []\", encoding=\"utf-8\")\n        sub1 = root.joinpath(\"sub1\")\n        sub1.mkdir()\n        sub1.joinpath(\"__init__.py\").touch()\n        sub1.joinpath(\"conftest.py\").write_text(\n            textwrap.dedent(\n                \"\"\"\\\n            import pytest\n            from .. import values\n            @pytest.fixture(scope=\"package\")\n            def fix():\n                values.append(\"pre-sub1\")\n                yield values\n                assert values.pop() == \"pre-sub1\"\n        \"\"\"\n            ),\n            encoding=\"utf-8\",\n        )\n        sub1.joinpath(\"test_1.py\").write_text(\n            textwrap.dedent(\n                \"\"\"\\\n            from .. import values\n            def test_1(fix):\n                assert values == [\"pre-sub1\"]\n        \"\"\"\n            ),\n            encoding=\"utf-8\",\n    "}, {"start_line": 139000, "end_line": 141000, "belongs_to": {"file_name": "fixtures.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing/python", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "       __init__.py\n                 conftest.py\n                 test_2.py\n        \"\"\"\n        root = pytester.mkdir(\"root\")\n        root.joinpath(\"__init__.py\").write_text(\"values = []\", encoding=\"utf-8\")\n        sub1 = root.joinpath(\"sub1\")\n        sub1.mkdir()\n        sub1.joinpath(\"__init__.py\").touch()\n        sub1.joinpath(\"conftest.py\").write_text(\n            textwrap.dedent(\n                \"\"\"\\\n            import pytest\n            from .. import values\n            @pytest.fixture(scope=\"package\")\n            def fix():\n                values.append(\"pre-sub1\")\n                yield values\n                assert values.pop() == \"pre-sub1\"\n        \"\"\"\n            ),\n            encoding=\"utf-8\",\n        )\n        sub1.joinpath(\"test_1.py\").write_text(\n            textwrap.dedent(\n                \"\"\"\\\n            from .. import values\n            def test_1(fix):\n                assert values == [\"pre-sub1\"]\n        \"\"\"\n            ),\n            encoding=\"utf-8\",\n        )\n        sub2 = root.joinpath(\"sub2\")\n        sub2.mkdir()\n        sub2.joinpath(\"__init__.py\").touch()\n        sub2.joinpath(\"conftest.py\").write_text(\n            textwrap.dedent(\n                \"\"\"\\\n            import pytest\n            from .. import values\n            @pytest.fixture(scope=\"package\")\n            def fix():\n                values.append(\"pre-sub2\")\n                yield values\n                assert values.pop() == \"pre-sub2\"\n        \"\"\"\n            ),\n            encoding=\"utf-8\",\n        )\n        sub2.joinpath(\"test_2.py\").write_text(\n            textwrap.dedent(\n                \"\"\"\\\n            from .. import values\n            def test_2(fix):\n                assert values == [\"pre-sub2\"]\n        \"\"\"\n            ),\n            encoding=\"utf-8\",\n        )\n        reprec = pytester.inline_run()\n        reprec.assertoutcome(passed=2)\n\n    def test_class_fixture_self_instance(self, pytester: Pytester) -> None:\n        \"\"\"Check that plugin classes which imple"}, {"start_line": 135000, "end_line": 137000, "belongs_to": {"file_name": "fixtures.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing/python", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "       @pytest.fixture(scope='module', autouse=True)\n            def m_conf(): pass\n        \"\"\"\n        )\n        pytester.makepyfile(\n            **{\n                \"sub/conftest.py\": \"\"\"\n                import pytest\n\n                @pytest.fixture(scope='package', autouse=True)\n                def p_sub(): pass\n\n                @pytest.fixture(scope='module', autouse=True)\n                def m_sub(): pass\n            \"\"\",\n                \"sub/__init__.py\": \"\",\n                \"sub/test_func.py\": \"\"\"\n                import pytest\n\n                @pytest.fixture(scope='module', autouse=True)\n                def m_test(): pass\n\n                @pytest.fixture(scope='function')\n                def f1(): pass\n\n                def test_func(m_test, f1):\n                    pass\n        \"\"\",\n            }\n        )\n        items, _ = pytester.inline_genitems()\n        assert isinstance(items[0], Function)\n        request = TopRequest(items[0], _ispytest=True)\n        assert request.fixturenames == \"p_sub m_conf m_sub m_test f1\".split()\n\n    def test_func_closure_all_scopes_complex(self, pytester: Pytester) -> None:\n        \"\"\"Complex test involving all scopes and mixing autouse with normal fixtures\"\"\"\n        pytester.makeconftest(\n            \"\"\"\n            import pytest\n\n            @pytest.fixture(scope='session')\n            def s1(): pass\n\n            @pytest.fixture(scope='package', autouse=True)\n            def p1(): pass\n        \"\"\"\n        )\n        pytester.makepyfile(**{\"__init__.py\": \"\"})\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n\n            @pytest.fixture(scope='module', autouse=True)\n            def m1(): pass\n\n            @pytest.fixture(scope='module')\n            def m2(s1): pass\n\n            @pytest.fixture(scope='function')\n            def f1(): pass\n\n            @pytest.fixture(scope='function')\n            def f2(): pass\n\n            class Test:\n\n                @pytest.fixture(scope='class', autouse=True)\n       "}, {"start_line": 58000, "end_line": 60000, "belongs_to": {"file_name": "fixtures.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing/python", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": ". import values\n                @pytest.fixture(scope=\"package\")\n                def one():\n                    values.append(\"package\")\n                    yield values\n                    values.pop()\n                @pytest.fixture(scope=\"package\", autouse=True)\n                def two():\n                    values.append(\"package-auto\")\n                    yield values\n                    values.pop()\n                \"\"\"\n            ),\n            encoding=\"utf-8\",\n        )\n        package.joinpath(\"test_x.py\").write_text(\n            textwrap.dedent(\n                \"\"\"\\\n                from .. import values\n                def test_package_autouse():\n                    assert values == [\"package-auto\"]\n                def test_package(one):\n                    assert values == [\"package-auto\", \"package\"]\n                \"\"\"\n            ),\n            encoding=\"utf-8\",\n        )\n        reprec = pytester.inline_run()\n        reprec.assertoutcome(passed=2)\n\n    def test_collect_custom_items(self, pytester: Pytester) -> None:\n        pytester.copy_example(\"fixtures/custom_item\")\n        result = pytester.runpytest(\"foo\")\n        result.stdout.fnmatch_lines([\"*passed*\"])\n\n\nclass TestAutouseDiscovery:\n    @pytest.fixture\n    def pytester(self, pytester: Pytester) -> Pytester:\n        pytester.makeconftest(\n            \"\"\"\n            import pytest\n            @pytest.fixture(autouse=True)\n            def perfunction(request, tmp_path):\n                pass\n\n            @pytest.fixture()\n            def arg1(tmp_path):\n                pass\n            @pytest.fixture(autouse=True)\n            def perfunction2(arg1):\n                pass\n\n            @pytest.fixture\n            def fm(request):\n                return request._fixturemanager\n\n            @pytest.fixture\n            def item(request):\n                return request._pyfuncitem\n        \"\"\"\n        )\n        return pytester\n\n    def test_parsefactories_conftest(self, pytester: Pytester) -> None:\n      "}, {"start_line": 18000, "end_line": 20000, "belongs_to": {"file_name": "test_conftest.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "\n                def fxtr():\n                    return \"from-package\"\n                \"\"\"\n            ),\n            encoding=\"utf-8\",\n        )\n        package.joinpath(\"test_pkgroot.py\").write_text(\n            textwrap.dedent(\n                \"\"\"\\\n                def test_pkgroot(fxtr):\n                    assert fxtr == \"from-package\"\n                \"\"\"\n            ),\n            encoding=\"utf-8\",\n        )\n\n        swc = package.joinpath(\"swc\")\n        swc.mkdir()\n        swc.joinpath(\"__init__.py\").touch()\n        swc.joinpath(\"conftest.py\").write_text(\n            textwrap.dedent(\n                \"\"\"\\\n                import pytest\n                @pytest.fixture\n                def fxtr():\n                    return \"from-swc\"\n                \"\"\"\n            ),\n            encoding=\"utf-8\",\n        )\n        swc.joinpath(\"test_with_conftest.py\").write_text(\n            textwrap.dedent(\n                \"\"\"\\\n                def test_with_conftest(fxtr):\n                    assert fxtr == \"from-swc\"\n                \"\"\"\n            ),\n            encoding=\"utf-8\",\n        )\n\n        snc = package.joinpath(\"snc\")\n        snc.mkdir()\n        snc.joinpath(\"__init__.py\").touch()\n        snc.joinpath(\"test_no_conftest.py\").write_text(\n            textwrap.dedent(\n                \"\"\"\\\n                def test_no_conftest(fxtr):\n                    assert fxtr == \"from-package\"   # No local conftest.py, so should\n                                                    # use value from parent dir's\n                \"\"\"\n            ),\n            encoding=\"utf-8\",\n        )\n        print(\"created directory structure:\")\n        for x in pytester.path.glob(\"**/\"):\n            print(\"   \" + str(x.relative_to(pytester.path)))\n\n        return {\"runner\": runner, \"package\": package, \"swc\": swc, \"snc\": snc}\n\n    # N.B.: \"swc\" stands for \"subdir with conftest.py\"\n    #       \"snc\" stands for \"subdir no [i.e. without] conftest.py\"\n    @pytest.mark.parametrize(\n        \"chdir,testarg,e"}, {"start_line": 73000, "end_line": 75000, "belongs_to": {"file_name": "fixtures.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing/python", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "\"new1\", \"new2\", \"fin2\", \"fin1\"]\n        \"\"\"\n        )\n        reprec = pytester.inline_run(\"-s\")\n        reprec.assertoutcome(passed=2)\n\n    def test_reordering_catastrophic_performance(self, pytester: Pytester) -> None:\n        \"\"\"Check that a certain high-scope parametrization pattern doesn't cause\n        a catasrophic slowdown.\n\n        Regression test for #12355.\n        \"\"\"\n        pytester.makepyfile(\"\"\"\n            import pytest\n\n            params = tuple(\"abcdefghijklmnopqrstuvwxyz\")\n            @pytest.mark.parametrize(params, [range(len(params))] * 3, scope=\"module\")\n            def test_parametrize(a, b, c, d, e, f, g, h, i, j, k, l, m, n, o, p, q, r, s, t, u, v, w, x, y, z):\n                pass\n        \"\"\")\n\n        result = pytester.runpytest()\n\n        result.assert_outcomes(passed=3)\n\n\nclass TestFixtureMarker:\n    def test_parametrize(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n            @pytest.fixture(params=[\"a\", \"b\", \"c\"])\n            def arg(request):\n                return request.param\n            values = []\n            def test_param(arg):\n                values.append(arg)\n            def test_result():\n                assert values == list(\"abc\")\n        \"\"\"\n        )\n        reprec = pytester.inline_run()\n        reprec.assertoutcome(passed=4)\n\n    def test_multiple_parametrization_issue_736(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n\n            @pytest.fixture(params=[1,2,3])\n            def foo(request):\n                return request.param\n\n            @pytest.mark.parametrize('foobar', [4,5,6])\n            def test_issue(foo, foobar):\n                assert foo in [1,2,3]\n                assert foobar in [4,5,6]\n        \"\"\"\n        )\n        reprec = pytester.inline_run()\n        reprec.assertoutcome(passed=9)\n\n    @pytest.mark.parametrize(\n        \"param_args\",\n        [\"'fixt, val'\", \"'fixt,val'\", \"['fixt"}], "retrieved_count": 10, "cost_time": 1.0930027961730957}
{"question": "Why does test_rewrite_ast employ pytest.register_assert_rewrite() in the package's __init__.py rather than relying solely on the automatic conftest-based rewriting mechanism, and what does this reveal about the design architecture?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"start_line": 11000, "end_line": 13000, "belongs_to": {"file_name": "test_assertion.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": ":\n            result.assert_outcomes(failed=2)\n            result.stdout.fnmatch_lines([expected, expected])\n        else:\n            result.assert_outcomes(errors=2)\n            result.stdout.fnmatch_lines(\n                [\n                    \"E       fixture 'check_first' not found\",\n                    \"E       fixture 'check_first2' not found\",\n                ]\n            )\n\n    def test_rewrite_ast(self, pytester: Pytester) -> None:\n        pytester.mkdir(\"pkg\")\n        contents = {\n            \"pkg/__init__.py\": \"\"\"\n                import pytest\n                pytest.register_assert_rewrite('pkg.helper')\n            \"\"\",\n            \"pkg/helper.py\": \"\"\"\n                def tool():\n                    a, b = 2, 3\n                    assert a == b\n            \"\"\",\n            \"pkg/plugin.py\": \"\"\"\n                import pytest, pkg.helper\n                @pytest.fixture\n                def tool():\n                    return pkg.helper.tool\n            \"\"\",\n            \"pkg/other.py\": \"\"\"\n                values = [3, 2]\n                def tool():\n                    assert values.pop() == 3\n            \"\"\",\n            \"conftest.py\": \"\"\"\n                pytest_plugins = ['pkg.plugin']\n            \"\"\",\n            \"test_pkg.py\": \"\"\"\n                import pkg.other\n                def test_tool(tool):\n                    tool()\n                def test_other():\n                    pkg.other.tool()\n            \"\"\",\n        }\n        pytester.makepyfile(**contents)\n        result = pytester.runpytest_subprocess(\"--assert=rewrite\")\n        result.stdout.fnmatch_lines(\n            [\n                \">*assert a == b*\",\n                \"E*assert 2 == 3*\",\n                \">*assert values.pop() == 3*\",\n                \"E*AssertionError\",\n            ]\n        )\n\n    def test_register_assert_rewrite_checks_types(self) -> None:\n        with pytest.raises(TypeError):\n            pytest.register_assert_rewrite([\"pytest_tests_internal_non_existing\"])  # type: ignore\n   "}, {"start_line": 10000, "end_line": 12000, "belongs_to": {"file_name": "test_assertion.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "             return spamplugin\n\n            class DummyDistInfo(object):\n                version = '1.0'\n                files = ('spamplugin.py', 'hampkg/__init__.py')\n                entry_points = (DummyEntryPoint(),)\n                metadata = {'name': 'foo'}\n\n            def distributions():\n                return (DummyDistInfo(),)\n\n            importlib.metadata.distributions = distributions\n            pytest.main()\n            \"\"\",\n            \"test_foo.py\": \"\"\"\\\n            def test(check_first):\n                check_first([10, 30], 30)\n\n            def test2(check_first2):\n                check_first2([10, 30], 30)\n            \"\"\",\n        }\n        pytester.makepyfile(**contents)\n        result = pytester.run(sys.executable, *args)\n        if mode == \"plain\":\n            expected = \"E       AssertionError\"\n        elif mode == \"rewrite\":\n            expected = \"*assert 10 == 30*\"\n        else:\n            assert 0\n\n        if not disable_plugin_autoload or explicit_specify:\n            result.assert_outcomes(failed=2)\n            result.stdout.fnmatch_lines([expected, expected])\n        else:\n            result.assert_outcomes(errors=2)\n            result.stdout.fnmatch_lines(\n                [\n                    \"E       fixture 'check_first' not found\",\n                    \"E       fixture 'check_first2' not found\",\n                ]\n            )\n\n    def test_rewrite_ast(self, pytester: Pytester) -> None:\n        pytester.mkdir(\"pkg\")\n        contents = {\n            \"pkg/__init__.py\": \"\"\"\n                import pytest\n                pytest.register_assert_rewrite('pkg.helper')\n            \"\"\",\n            \"pkg/helper.py\": \"\"\"\n                def tool():\n                    a, b = 2, 3\n                    assert a == b\n            \"\"\",\n            \"pkg/plugin.py\": \"\"\"\n                import pytest, pkg.helper\n                @pytest.fixture\n                def tool():\n                    return pkg.helper.tool\n            \"\"\",\n            \"pkg/oth"}, {"start_line": 9000, "end_line": 11000, "belongs_to": {"file_name": "test_assertrewrite.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "     class T:\n                    def __{name}__(self,other):\n                        loc()\n                        return True\n\n                assert  5 {op} T()\n                assert  (5\n                         {op}\n                         T\n                         ())\n        \"\"\")\n\n        preserved(\"\"\"\n            def func(value):\n                loc(\"func\")\n                return value\n\n            class T:\n                def __iter__(self):\n                    loc(\"iter\")\n                    return iter([5])\n\n            assert  func(*T()) == 5\n        \"\"\")\n\n        preserved(\"\"\"\n            class T:\n                def __getattr__(self,name):\n                    loc()\n                    return name\n\n            assert  T().attr == \"attr\"\n        \"\"\")\n\n    def test_dont_rewrite(self) -> None:\n        s = \"\"\"'PYTEST_DONT_REWRITE'\\nassert 14\"\"\"\n        m = rewrite(s)\n        assert len(m.body) == 2\n        assert isinstance(m.body[1], ast.Assert)\n        assert m.body[1].msg is None\n\n    def test_dont_rewrite_plugin(self, pytester: Pytester) -> None:\n        contents = {\n            \"conftest.py\": \"pytest_plugins = 'plugin'; import plugin\",\n            \"plugin.py\": \"'PYTEST_DONT_REWRITE'\",\n            \"test_foo.py\": \"def test_foo(): pass\",\n        }\n        pytester.makepyfile(**contents)\n        result = pytester.runpytest_subprocess()\n        assert \"warning\" not in \"\".join(result.outlines)\n\n    def test_rewrites_plugin_as_a_package(self, pytester: Pytester) -> None:\n        pkgdir = pytester.mkpydir(\"plugin\")\n        pkgdir.joinpath(\"__init__.py\").write_text(\n            \"import pytest\\n\"\n            \"@pytest.fixture\\n\"\n            \"def special_asserter():\\n\"\n            \"    def special_assert(x, y):\\n\"\n            \"        assert x == y\\n\"\n            \"    return special_assert\\n\",\n            encoding=\"utf-8\",\n        )\n        pytester.makeconftest('pytest_plugins = [\"plugin\"]')\n        pytester.makepyfile(\"def test(special_asserter): special_asser"}, {"start_line": 34000, "end_line": 36000, "belongs_to": {"file_name": "test_assertrewrite.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "one:\n        pkg = pytester.path.joinpath(\"pkg\")\n        pkg.mkdir()\n        pkg.joinpath(\"__init__.py\")\n        pkg.joinpath(\"test_blah.py\").write_text(\n            \"\"\"\ndef test_rewritten():\n    assert \"@py_builtins\" in globals()\"\"\",\n            encoding=\"utf-8\",\n        )\n        assert pytester.runpytest().ret == 0\n\n    def test_translate_newlines(self, pytester: Pytester) -> None:\n        content = \"def test_rewritten():\\r\\n assert '@py_builtins' in globals()\"\n        b = content.encode(\"utf-8\")\n        pytester.path.joinpath(\"test_newlines.py\").write_bytes(b)\n        assert pytester.runpytest().ret == 0\n\n    def test_package_without__init__py(self, pytester: Pytester) -> None:\n        pkg = pytester.mkdir(\"a_package_without_init_py\")\n        pkg.joinpath(\"module.py\").touch()\n        pytester.makepyfile(\"import a_package_without_init_py.module\")\n        assert pytester.runpytest().ret == ExitCode.NO_TESTS_COLLECTED\n\n    def test_rewrite_warning(self, pytester: Pytester) -> None:\n        pytester.makeconftest(\n            \"\"\"\n            import pytest\n            pytest.register_assert_rewrite(\"_pytest\")\n        \"\"\"\n        )\n        # needs to be a subprocess because pytester explicitly disables this warning\n        result = pytester.runpytest_subprocess()\n        result.stdout.fnmatch_lines([\"*Module already imported*; _pytest\"])\n\n    def test_rewrite_warning_ignore(self, pytester: Pytester) -> None:\n        pytester.makeconftest(\n            \"\"\"\n            import pytest\n            pytest.register_assert_rewrite(\"_pytest\")\n        \"\"\"\n        )\n        # needs to be a subprocess because pytester explicitly disables this warning\n        result = pytester.runpytest_subprocess(\n            \"-W\",\n            \"ignore:Module already imported so cannot be rewritten; _pytest:pytest.PytestAssertRewriteWarning\",\n        )\n        # Previously, when the message pattern used to contain an extra `:`, an error was raised.\n        assert not result.stderr.str().strip()\n    "}, {"start_line": 10000, "end_line": 12000, "belongs_to": {"file_name": "test_assertrewrite.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": " is None\n\n    def test_dont_rewrite_plugin(self, pytester: Pytester) -> None:\n        contents = {\n            \"conftest.py\": \"pytest_plugins = 'plugin'; import plugin\",\n            \"plugin.py\": \"'PYTEST_DONT_REWRITE'\",\n            \"test_foo.py\": \"def test_foo(): pass\",\n        }\n        pytester.makepyfile(**contents)\n        result = pytester.runpytest_subprocess()\n        assert \"warning\" not in \"\".join(result.outlines)\n\n    def test_rewrites_plugin_as_a_package(self, pytester: Pytester) -> None:\n        pkgdir = pytester.mkpydir(\"plugin\")\n        pkgdir.joinpath(\"__init__.py\").write_text(\n            \"import pytest\\n\"\n            \"@pytest.fixture\\n\"\n            \"def special_asserter():\\n\"\n            \"    def special_assert(x, y):\\n\"\n            \"        assert x == y\\n\"\n            \"    return special_assert\\n\",\n            encoding=\"utf-8\",\n        )\n        pytester.makeconftest('pytest_plugins = [\"plugin\"]')\n        pytester.makepyfile(\"def test(special_asserter): special_asserter(1, 2)\\n\")\n        result = pytester.runpytest()\n        result.stdout.fnmatch_lines([\"*assert 1 == 2*\"])\n\n    def test_honors_pep_235(self, pytester: Pytester, monkeypatch) -> None:\n        # note: couldn't make it fail on macos with a single `sys.path` entry\n        # note: these modules are named `test_*` to trigger rewriting\n        pytester.makepyfile(test_y=\"x = 1\")\n        xdir = pytester.mkdir(\"x\")\n        pytester.mkpydir(str(xdir.joinpath(\"test_Y\")))\n        xdir.joinpath(\"test_Y\").joinpath(\"__init__.py\").write_text(\n            \"x = 2\", encoding=\"utf-8\"\n        )\n        pytester.makepyfile(\n            \"import test_y\\n\"\n            \"import test_Y\\n\"\n            \"def test():\\n\"\n            \"    assert test_y.x == 1\\n\"\n            \"    assert test_Y.x == 2\\n\"\n        )\n        monkeypatch.syspath_prepend(str(xdir))\n        pytester.runpytest().assert_outcomes(passed=1)\n\n    def test_name(self, request) -> None:\n        def f1() -> None:\n            assert False\n\n        as"}, {"start_line": 1000, "end_line": 3000, "belongs_to": {"file_name": "test_assertrewrite.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": " Config\nfrom _pytest.config import ExitCode\nfrom _pytest.pathlib import make_numbered_dir\nfrom _pytest.pytester import Pytester\nimport pytest\n\n\ndef rewrite(src: str) -> ast.Module:\n    tree = ast.parse(src)\n    rewrite_asserts(tree, src.encode())\n    return tree\n\n\ndef getmsg(\n    f, extra_ns: Mapping[str, object] | None = None, *, must_pass: bool = False\n) -> str | None:\n    \"\"\"Rewrite the assertions in f, run it, and get the failure message.\"\"\"\n    src = \"\\n\".join(_pytest._code.Code.from_function(f).source().lines)\n    mod = rewrite(src)\n    code = compile(mod, \"<test>\", \"exec\")\n    ns: dict[str, object] = {}\n    if extra_ns is not None:\n        ns.update(extra_ns)\n    exec(code, ns)\n    func = ns[f.__name__]\n    try:\n        func()  # type: ignore[operator]\n    except AssertionError:\n        if must_pass:\n            pytest.fail(\"shouldn't have raised\")\n        s = str(sys.exc_info()[1])\n        if not s.startswith(\"assert\"):\n            return \"AssertionError: \" + s\n        return s\n    else:\n        if not must_pass:\n            pytest.fail(\"function didn't raise at all\")\n        return None\n\n\nclass TestAssertionRewrite:\n    def test_place_initial_imports(self) -> None:\n        s = \"\"\"'Doc string'\\nother = stuff\"\"\"\n        m = rewrite(s)\n        assert isinstance(m.body[0], ast.Expr)\n        for imp in m.body[1:3]:\n            assert isinstance(imp, ast.Import)\n            assert imp.lineno == 2\n            assert imp.col_offset == 0\n        assert isinstance(m.body[3], ast.Assign)\n        s = \"\"\"from __future__ import division\\nother_stuff\"\"\"\n        m = rewrite(s)\n        assert isinstance(m.body[0], ast.ImportFrom)\n        for imp in m.body[1:3]:\n            assert isinstance(imp, ast.Import)\n            assert imp.lineno == 2\n            assert imp.col_offset == 0\n        assert isinstance(m.body[3], ast.Expr)\n        s = \"\"\"'doc string'\\nfrom __future__ import division\"\"\"\n        m = rewrite(s)\n        assert isinstance(m.body[0], ast.Expr)\n        assert i"}, {"start_line": 12000, "end_line": 14000, "belongs_to": {"file_name": "test_assertion.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "er.py\": \"\"\"\n                values = [3, 2]\n                def tool():\n                    assert values.pop() == 3\n            \"\"\",\n            \"conftest.py\": \"\"\"\n                pytest_plugins = ['pkg.plugin']\n            \"\"\",\n            \"test_pkg.py\": \"\"\"\n                import pkg.other\n                def test_tool(tool):\n                    tool()\n                def test_other():\n                    pkg.other.tool()\n            \"\"\",\n        }\n        pytester.makepyfile(**contents)\n        result = pytester.runpytest_subprocess(\"--assert=rewrite\")\n        result.stdout.fnmatch_lines(\n            [\n                \">*assert a == b*\",\n                \"E*assert 2 == 3*\",\n                \">*assert values.pop() == 3*\",\n                \"E*AssertionError\",\n            ]\n        )\n\n    def test_register_assert_rewrite_checks_types(self) -> None:\n        with pytest.raises(TypeError):\n            pytest.register_assert_rewrite([\"pytest_tests_internal_non_existing\"])  # type: ignore\n        pytest.register_assert_rewrite(\n            \"pytest_tests_internal_non_existing\", \"pytest_tests_internal_non_existing2\"\n        )\n\n\nclass TestBinReprIntegration:\n    def test_pytest_assertrepr_compare_called(self, pytester: Pytester) -> None:\n        pytester.makeconftest(\n            \"\"\"\n            import pytest\n            values = []\n            def pytest_assertrepr_compare(op, left, right):\n                values.append((op, left, right))\n\n            @pytest.fixture\n            def list(request):\n                return values\n        \"\"\"\n        )\n        pytester.makepyfile(\n            \"\"\"\n            def test_hello():\n                assert 0 == 1\n            def test_check(list):\n                assert list == [(\"==\", 0, 1)]\n        \"\"\"\n        )\n        result = pytester.runpytest(\"-v\")\n        result.stdout.fnmatch_lines([\"*test_hello*FAIL*\", \"*test_check*PASS*\"])\n\n\ndef callop(op: str, left: Any, right: Any, verbose: int = 0) -> list[str] | None:\n    config = mock_con"}, {"start_line": 35000, "end_line": 37000, "belongs_to": {"file_name": "test_assertrewrite.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "      pytester.makeconftest(\n            \"\"\"\n            import pytest\n            pytest.register_assert_rewrite(\"_pytest\")\n        \"\"\"\n        )\n        # needs to be a subprocess because pytester explicitly disables this warning\n        result = pytester.runpytest_subprocess()\n        result.stdout.fnmatch_lines([\"*Module already imported*; _pytest\"])\n\n    def test_rewrite_warning_ignore(self, pytester: Pytester) -> None:\n        pytester.makeconftest(\n            \"\"\"\n            import pytest\n            pytest.register_assert_rewrite(\"_pytest\")\n        \"\"\"\n        )\n        # needs to be a subprocess because pytester explicitly disables this warning\n        result = pytester.runpytest_subprocess(\n            \"-W\",\n            \"ignore:Module already imported so cannot be rewritten; _pytest:pytest.PytestAssertRewriteWarning\",\n        )\n        # Previously, when the message pattern used to contain an extra `:`, an error was raised.\n        assert not result.stderr.str().strip()\n        result.stdout.no_fnmatch_line(\"*Module already imported*; _pytest\")\n\n    def test_rewrite_module_imported_from_conftest(self, pytester: Pytester) -> None:\n        pytester.makeconftest(\n            \"\"\"\n            import test_rewrite_module_imported\n        \"\"\"\n        )\n        pytester.makepyfile(\n            test_rewrite_module_imported=\"\"\"\n            def test_rewritten():\n                assert \"@py_builtins\" in globals()\n        \"\"\"\n        )\n        assert pytester.runpytest_subprocess().ret == 0\n\n    def test_remember_rewritten_modules(\n        self, pytestconfig, pytester: Pytester, monkeypatch\n    ) -> None:\n        \"\"\"`AssertionRewriteHook` should remember rewritten modules so it\n        doesn't give false positives (#2005).\"\"\"\n        monkeypatch.syspath_prepend(pytester.path)\n        pytester.makepyfile(test_remember_rewritten_modules=\"\")\n        warnings = []\n        hook = AssertionRewritingHook(pytestconfig)\n        monkeypatch.setattr(\n            hook, \"_warn_alre"}, {"start_line": 2000, "end_line": 4000, "belongs_to": {"file_name": "test_assertion.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "       config.get_verbosity(_Config.VERBOSITY_ASSERTIONS)\n            == TestMockConfig.SOME_OTHER_VERBOSITY_LEVEL\n        )\n\n    def test_get_unsupported_type_error(self):\n        config = mock_config(verbose=TestMockConfig.SOME_VERBOSITY_LEVEL)\n\n        with pytest.raises(KeyError):\n            config.get_verbosity(\"--- NOT A VERBOSITY LEVEL ---\")\n\n\nclass TestImportHookInstallation:\n    @pytest.mark.parametrize(\"initial_conftest\", [True, False])\n    @pytest.mark.parametrize(\"mode\", [\"plain\", \"rewrite\"])\n    def test_conftest_assertion_rewrite(\n        self, pytester: Pytester, initial_conftest, mode\n    ) -> None:\n        \"\"\"Test that conftest files are using assertion rewrite on import (#1619).\"\"\"\n        pytester.mkdir(\"foo\")\n        pytester.mkdir(\"foo/tests\")\n        conftest_path = \"conftest.py\" if initial_conftest else \"foo/conftest.py\"\n        contents = {\n            conftest_path: \"\"\"\n                import pytest\n                @pytest.fixture\n                def check_first():\n                    def check(values, value):\n                        assert values.pop(0) == value\n                    return check\n            \"\"\",\n            \"foo/tests/test_foo.py\": \"\"\"\n                def test(check_first):\n                    check_first([10, 30], 30)\n            \"\"\",\n        }\n        pytester.makepyfile(**contents)\n        result = pytester.runpytest_subprocess(f\"--assert={mode}\")\n        if mode == \"plain\":\n            expected = \"E       AssertionError\"\n        elif mode == \"rewrite\":\n            expected = \"*assert 10 == 30*\"\n        else:\n            assert 0\n        result.stdout.fnmatch_lines([expected])\n\n    def test_rewrite_assertions_pytester_plugin(self, pytester: Pytester) -> None:\n        \"\"\"\n        Assertions in the pytester plugin must also benefit from assertion\n        rewriting (#1920).\n        \"\"\"\n        pytester.makepyfile(\n            \"\"\"\n            pytest_plugins = ['pytester']\n            def test_dummy_failure(pytester):  # how "}, {"start_line": 1000, "end_line": 3000, "belongs_to": {"file_name": "__init__.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest/assertion", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "erforms no assertion debugging.\\n\"\n            \"'rewrite' (the default) rewrites assert statements in test modules\"\n            \" on import to provide assert expression information.\"\n        ),\n    )\n    parser.addini(\n        \"enable_assertion_pass_hook\",\n        type=\"bool\",\n        default=False,\n        help=\"Enables the pytest_assertion_pass hook. \"\n        \"Make sure to delete any previously generated pyc cache files.\",\n    )\n\n    parser.addini(\n        \"truncation_limit_lines\",\n        default=None,\n        help=\"Set threshold of LINES after which truncation will take effect\",\n    )\n    parser.addini(\n        \"truncation_limit_chars\",\n        default=None,\n        help=(\"Set threshold of CHARS after which truncation will take effect\"),\n    )\n\n    Config._add_verbosity_ini(\n        parser,\n        Config.VERBOSITY_ASSERTIONS,\n        help=(\n            \"Specify a verbosity level for assertions, overriding the main level. \"\n            \"Higher levels will provide more detailed explanation when an assertion fails.\"\n        ),\n    )\n\n\ndef register_assert_rewrite(*names: str) -> None:\n    \"\"\"Register one or more module names to be rewritten on import.\n\n    This function will make sure that this module or all modules inside\n    the package will get their assert statements rewritten.\n    Thus you should make sure to call this before the module is\n    actually imported, usually in your __init__.py if you are a plugin\n    using a package.\n\n    :param names: The module names to register.\n    \"\"\"\n    for name in names:\n        if not isinstance(name, str):\n            msg = \"expected module names as *args, got {0} instead\"  # type: ignore[unreachable]\n            raise TypeError(msg.format(repr(names)))\n    rewrite_hook: RewriteHook\n    for hook in sys.meta_path:\n        if isinstance(hook, rewrite.AssertionRewritingHook):\n            rewrite_hook = hook\n            break\n    else:\n        rewrite_hook = DummyRewriteHook()\n    rewrite_hook.mark_rewrite(*names)\n\n\nclass R"}], "retrieved_count": 10, "cost_time": 1.097707986831665}
{"question": "Why does the TestImportHookInstallation class employ subprocess-based testing through pytester.runpytest_subprocess() rather than inline test execution, and what design constraints does this impose on the assertion rewrite hook installation verification?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"start_line": 37000, "end_line": 39000, "belongs_to": {"file_name": "test_assertrewrite.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "ady_imported\", lambda code, msg: warnings.append(msg)\n        )\n        spec = hook.find_spec(\"test_remember_rewritten_modules\")\n        assert spec is not None\n        module = importlib.util.module_from_spec(spec)\n        hook.exec_module(module)\n        hook.mark_rewrite(\"test_remember_rewritten_modules\")\n        hook.mark_rewrite(\"test_remember_rewritten_modules\")\n        assert warnings == []\n\n    def test_rewrite_warning_using_pytest_plugins(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            **{\n                \"conftest.py\": \"pytest_plugins = ['core', 'gui', 'sci']\",\n                \"core.py\": \"\",\n                \"gui.py\": \"pytest_plugins = ['core', 'sci']\",\n                \"sci.py\": \"pytest_plugins = ['core']\",\n                \"test_rewrite_warning_pytest_plugins.py\": \"def test(): pass\",\n            }\n        )\n        pytester.chdir()\n        result = pytester.runpytest_subprocess()\n        result.stdout.fnmatch_lines([\"*= 1 passed in *=*\"])\n        result.stdout.no_fnmatch_line(\"*pytest-warning summary*\")\n\n    def test_rewrite_warning_using_pytest_plugins_env_var(\n        self, pytester: Pytester, monkeypatch\n    ) -> None:\n        monkeypatch.setenv(\"PYTEST_PLUGINS\", \"plugin\")\n        pytester.makepyfile(\n            **{\n                \"plugin.py\": \"\",\n                \"test_rewrite_warning_using_pytest_plugins_env_var.py\": \"\"\"\n                import plugin\n                pytest_plugins = ['plugin']\n                def test():\n                    pass\n            \"\"\",\n            }\n        )\n        pytester.chdir()\n        result = pytester.runpytest_subprocess()\n        result.stdout.fnmatch_lines([\"*= 1 passed in *=*\"])\n        result.stdout.no_fnmatch_line(\"*pytest-warning summary*\")\n\n\nclass TestAssertionRewriteHookDetails:\n    def test_sys_meta_path_munged(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            def test_meta_path():\n                import sys; sys.meta_path = []\"\"\"\n       "}, {"start_line": 2000, "end_line": 4000, "belongs_to": {"file_name": "test_assertion.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "       config.get_verbosity(_Config.VERBOSITY_ASSERTIONS)\n            == TestMockConfig.SOME_OTHER_VERBOSITY_LEVEL\n        )\n\n    def test_get_unsupported_type_error(self):\n        config = mock_config(verbose=TestMockConfig.SOME_VERBOSITY_LEVEL)\n\n        with pytest.raises(KeyError):\n            config.get_verbosity(\"--- NOT A VERBOSITY LEVEL ---\")\n\n\nclass TestImportHookInstallation:\n    @pytest.mark.parametrize(\"initial_conftest\", [True, False])\n    @pytest.mark.parametrize(\"mode\", [\"plain\", \"rewrite\"])\n    def test_conftest_assertion_rewrite(\n        self, pytester: Pytester, initial_conftest, mode\n    ) -> None:\n        \"\"\"Test that conftest files are using assertion rewrite on import (#1619).\"\"\"\n        pytester.mkdir(\"foo\")\n        pytester.mkdir(\"foo/tests\")\n        conftest_path = \"conftest.py\" if initial_conftest else \"foo/conftest.py\"\n        contents = {\n            conftest_path: \"\"\"\n                import pytest\n                @pytest.fixture\n                def check_first():\n                    def check(values, value):\n                        assert values.pop(0) == value\n                    return check\n            \"\"\",\n            \"foo/tests/test_foo.py\": \"\"\"\n                def test(check_first):\n                    check_first([10, 30], 30)\n            \"\"\",\n        }\n        pytester.makepyfile(**contents)\n        result = pytester.runpytest_subprocess(f\"--assert={mode}\")\n        if mode == \"plain\":\n            expected = \"E       AssertionError\"\n        elif mode == \"rewrite\":\n            expected = \"*assert 10 == 30*\"\n        else:\n            assert 0\n        result.stdout.fnmatch_lines([expected])\n\n    def test_rewrite_assertions_pytester_plugin(self, pytester: Pytester) -> None:\n        \"\"\"\n        Assertions in the pytester plugin must also benefit from assertion\n        rewriting (#1920).\n        \"\"\"\n        pytester.makepyfile(\n            \"\"\"\n            pytest_plugins = ['pytester']\n            def test_dummy_failure(pytester):  # how "}, {"start_line": 35000, "end_line": 37000, "belongs_to": {"file_name": "test_assertrewrite.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "      pytester.makeconftest(\n            \"\"\"\n            import pytest\n            pytest.register_assert_rewrite(\"_pytest\")\n        \"\"\"\n        )\n        # needs to be a subprocess because pytester explicitly disables this warning\n        result = pytester.runpytest_subprocess()\n        result.stdout.fnmatch_lines([\"*Module already imported*; _pytest\"])\n\n    def test_rewrite_warning_ignore(self, pytester: Pytester) -> None:\n        pytester.makeconftest(\n            \"\"\"\n            import pytest\n            pytest.register_assert_rewrite(\"_pytest\")\n        \"\"\"\n        )\n        # needs to be a subprocess because pytester explicitly disables this warning\n        result = pytester.runpytest_subprocess(\n            \"-W\",\n            \"ignore:Module already imported so cannot be rewritten; _pytest:pytest.PytestAssertRewriteWarning\",\n        )\n        # Previously, when the message pattern used to contain an extra `:`, an error was raised.\n        assert not result.stderr.str().strip()\n        result.stdout.no_fnmatch_line(\"*Module already imported*; _pytest\")\n\n    def test_rewrite_module_imported_from_conftest(self, pytester: Pytester) -> None:\n        pytester.makeconftest(\n            \"\"\"\n            import test_rewrite_module_imported\n        \"\"\"\n        )\n        pytester.makepyfile(\n            test_rewrite_module_imported=\"\"\"\n            def test_rewritten():\n                assert \"@py_builtins\" in globals()\n        \"\"\"\n        )\n        assert pytester.runpytest_subprocess().ret == 0\n\n    def test_remember_rewritten_modules(\n        self, pytestconfig, pytester: Pytester, monkeypatch\n    ) -> None:\n        \"\"\"`AssertionRewriteHook` should remember rewritten modules so it\n        doesn't give false positives (#2005).\"\"\"\n        monkeypatch.syspath_prepend(pytester.path)\n        pytester.makepyfile(test_remember_rewritten_modules=\"\")\n        warnings = []\n        hook = AssertionRewritingHook(pytestconfig)\n        monkeypatch.setattr(\n            hook, \"_warn_alre"}, {"start_line": 36000, "end_line": 38000, "belongs_to": {"file_name": "test_assertrewrite.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "    result.stdout.no_fnmatch_line(\"*Module already imported*; _pytest\")\n\n    def test_rewrite_module_imported_from_conftest(self, pytester: Pytester) -> None:\n        pytester.makeconftest(\n            \"\"\"\n            import test_rewrite_module_imported\n        \"\"\"\n        )\n        pytester.makepyfile(\n            test_rewrite_module_imported=\"\"\"\n            def test_rewritten():\n                assert \"@py_builtins\" in globals()\n        \"\"\"\n        )\n        assert pytester.runpytest_subprocess().ret == 0\n\n    def test_remember_rewritten_modules(\n        self, pytestconfig, pytester: Pytester, monkeypatch\n    ) -> None:\n        \"\"\"`AssertionRewriteHook` should remember rewritten modules so it\n        doesn't give false positives (#2005).\"\"\"\n        monkeypatch.syspath_prepend(pytester.path)\n        pytester.makepyfile(test_remember_rewritten_modules=\"\")\n        warnings = []\n        hook = AssertionRewritingHook(pytestconfig)\n        monkeypatch.setattr(\n            hook, \"_warn_already_imported\", lambda code, msg: warnings.append(msg)\n        )\n        spec = hook.find_spec(\"test_remember_rewritten_modules\")\n        assert spec is not None\n        module = importlib.util.module_from_spec(spec)\n        hook.exec_module(module)\n        hook.mark_rewrite(\"test_remember_rewritten_modules\")\n        hook.mark_rewrite(\"test_remember_rewritten_modules\")\n        assert warnings == []\n\n    def test_rewrite_warning_using_pytest_plugins(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            **{\n                \"conftest.py\": \"pytest_plugins = ['core', 'gui', 'sci']\",\n                \"core.py\": \"\",\n                \"gui.py\": \"pytest_plugins = ['core', 'sci']\",\n                \"sci.py\": \"pytest_plugins = ['core']\",\n                \"test_rewrite_warning_pytest_plugins.py\": \"def test(): pass\",\n            }\n        )\n        pytester.chdir()\n        result = pytester.runpytest_subprocess()\n        result.stdout.fnmatch_lines([\"*= 1 passed in *=*\"])\n        re"}, {"start_line": 57000, "end_line": 59000, "belongs_to": {"file_name": "test_assertrewrite.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": " writing pyc files: if an import happens to be triggered when writing the pyc\n    file, this would cause another call to the hook, which would trigger another pyc writing, which could\n    trigger another import, and so on. (#3506)\"\"\"\n    from _pytest.assertion import rewrite as rewritemod\n\n    pytester.syspathinsert()\n    pytester.makepyfile(test_foo=\"def test_foo(): pass\")\n    pytester.makepyfile(test_bar=\"def test_bar(): pass\")\n\n    original_write_pyc = rewritemod._write_pyc\n\n    write_pyc_called = []\n\n    def spy_write_pyc(*args, **kwargs):\n        # make a note that we have called _write_pyc\n        write_pyc_called.append(True)\n        # try to import a module at this point: we should not try to rewrite this module\n        assert hook.find_spec(\"test_bar\") is None\n        return original_write_pyc(*args, **kwargs)\n\n    monkeypatch.setattr(rewritemod, \"_write_pyc\", spy_write_pyc)\n    monkeypatch.setattr(sys, \"dont_write_bytecode\", False)\n\n    hook = AssertionRewritingHook(pytestconfig)\n    spec = hook.find_spec(\"test_foo\")\n    assert spec is not None\n    module = importlib.util.module_from_spec(spec)\n    hook.exec_module(module)\n    assert len(write_pyc_called) == 1\n\n\nclass TestEarlyRewriteBailout:\n    @pytest.fixture\n    def hook(\n        self, pytestconfig, monkeypatch, pytester: Pytester\n    ) -> Generator[AssertionRewritingHook]:\n        \"\"\"Returns a patched AssertionRewritingHook instance so we can configure its initial paths and track\n        if PathFinder.find_spec has been called.\n        \"\"\"\n        import importlib.machinery\n\n        self.find_spec_calls: list[str] = []\n        self.initial_paths: set[Path] = set()\n\n        class StubSession:\n            _initialpaths = self.initial_paths\n\n            def isinitpath(self, p):\n                return p in self._initialpaths\n\n        def spy_find_spec(name, path):\n            self.find_spec_calls.append(name)\n            return importlib.machinery.PathFinder.find_spec(name, path)\n\n        hook = Assertion"}, {"start_line": 3000, "end_line": 5000, "belongs_to": {"file_name": "__init__.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest/assertion", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "ewriteHook(Protocol):\n    def mark_rewrite(self, *names: str) -> None: ...\n\n\nclass DummyRewriteHook:\n    \"\"\"A no-op import hook for when rewriting is disabled.\"\"\"\n\n    def mark_rewrite(self, *names: str) -> None:\n        pass\n\n\nclass AssertionState:\n    \"\"\"State for the assertion plugin.\"\"\"\n\n    def __init__(self, config: Config, mode) -> None:\n        self.mode = mode\n        self.trace = config.trace.root.get(\"assertion\")\n        self.hook: rewrite.AssertionRewritingHook | None = None\n\n\ndef install_importhook(config: Config) -> rewrite.AssertionRewritingHook:\n    \"\"\"Try to install the rewrite hook, raise SystemError if it fails.\"\"\"\n    config.stash[assertstate_key] = AssertionState(config, \"rewrite\")\n    config.stash[assertstate_key].hook = hook = rewrite.AssertionRewritingHook(config)\n    sys.meta_path.insert(0, hook)\n    config.stash[assertstate_key].trace(\"installed rewrite import hook\")\n\n    def undo() -> None:\n        hook = config.stash[assertstate_key].hook\n        if hook is not None and hook in sys.meta_path:\n            sys.meta_path.remove(hook)\n\n    config.add_cleanup(undo)\n    return hook\n\n\ndef pytest_collection(session: Session) -> None:\n    # This hook is only called when test modules are collected\n    # so for example not in the managing process of pytest-xdist\n    # (which does not collect test modules).\n    assertstate = session.config.stash.get(assertstate_key, None)\n    if assertstate:\n        if assertstate.hook is not None:\n            assertstate.hook.set_session(session)\n\n\n@hookimpl(wrapper=True, tryfirst=True)\ndef pytest_runtest_protocol(item: Item) -> Generator[None, object, object]:\n    \"\"\"Setup the pytest_assertrepr_compare and pytest_assertion_pass hooks.\n\n    The rewrite module will use util._reprcompare if it exists to use custom\n    reporting via the pytest_assertrepr_compare hook.  This sets up this custom\n    comparison for the test.\n    \"\"\"\n    ihook = item.ihook\n\n    def callbinrepr(op, left: object, right: object) -> str | None"}, {"start_line": 38000, "end_line": 40000, "belongs_to": {"file_name": "test_assertrewrite.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "sult.stdout.no_fnmatch_line(\"*pytest-warning summary*\")\n\n    def test_rewrite_warning_using_pytest_plugins_env_var(\n        self, pytester: Pytester, monkeypatch\n    ) -> None:\n        monkeypatch.setenv(\"PYTEST_PLUGINS\", \"plugin\")\n        pytester.makepyfile(\n            **{\n                \"plugin.py\": \"\",\n                \"test_rewrite_warning_using_pytest_plugins_env_var.py\": \"\"\"\n                import plugin\n                pytest_plugins = ['plugin']\n                def test():\n                    pass\n            \"\"\",\n            }\n        )\n        pytester.chdir()\n        result = pytester.runpytest_subprocess()\n        result.stdout.fnmatch_lines([\"*= 1 passed in *=*\"])\n        result.stdout.no_fnmatch_line(\"*pytest-warning summary*\")\n\n\nclass TestAssertionRewriteHookDetails:\n    def test_sys_meta_path_munged(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            def test_meta_path():\n                import sys; sys.meta_path = []\"\"\"\n        )\n        assert pytester.runpytest().ret == 0\n\n    def test_write_pyc(self, pytester: Pytester, tmp_path) -> None:\n        from _pytest.assertion import AssertionState\n        from _pytest.assertion.rewrite import _write_pyc\n\n        config = pytester.parseconfig()\n        state = AssertionState(config, \"rewrite\")\n        tmp_path.joinpath(\"source.py\").touch()\n        source_path = str(tmp_path)\n        pycpath = tmp_path.joinpath(\"pyc\")\n        co = compile(\"1\", \"f.py\", \"single\")\n        assert _write_pyc(state, co, os.stat(source_path), pycpath)\n\n        with mock.patch.object(os, \"replace\", side_effect=OSError):\n            assert not _write_pyc(state, co, os.stat(source_path), pycpath)\n\n    def test_resources_provider_for_loader(self, pytester: Pytester) -> None:\n        \"\"\"\n        Attempts to load resources from a package should succeed normally,\n        even when the AssertionRewriteHook is used to load the modules.\n\n        See #366 for details.\n        \"\"\"\n        pytest.imp"}, {"start_line": 60000, "end_line": 62000, "belongs_to": {"file_name": "test_assertrewrite.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": ".initial_paths.add(foobar_path)\n\n        # conftest files should always be rewritten\n        assert hook.find_spec(\"conftest\") is not None\n        assert self.find_spec_calls == [\"conftest\"]\n\n        # files matching \"python_files\" mask should always be rewritten\n        assert hook.find_spec(\"test_foo\") is not None\n        assert self.find_spec_calls == [\"conftest\", \"test_foo\"]\n\n        # file does not match \"python_files\": early bailout\n        assert hook.find_spec(\"bar\") is None\n        assert self.find_spec_calls == [\"conftest\", \"test_foo\"]\n\n        # file is an initial path (passed on the command-line): should be rewritten\n        assert hook.find_spec(\"foobar\") is not None\n        assert self.find_spec_calls == [\"conftest\", \"test_foo\", \"foobar\"]\n\n    def test_pattern_contains_subdirectories(\n        self, pytester: Pytester, hook: AssertionRewritingHook\n    ) -> None:\n        \"\"\"If one of the python_files patterns contain subdirectories (\"tests/**.py\") we can't bailout early\n        because we need to match with the full path, which can only be found by calling PathFinder.find_spec\n        \"\"\"\n        pytester.makepyfile(\n            **{\n                \"tests/file.py\": \"\"\"\\\n                    def test_simple_failure():\n                        assert 1 + 1 == 3\n                \"\"\"\n            }\n        )\n        pytester.syspathinsert(\"tests\")\n        with mock.patch.object(hook, \"fnpats\", [\"tests/**.py\"]):\n            assert hook.find_spec(\"file\") is not None\n            assert self.find_spec_calls == [\"file\"]\n\n    @pytest.mark.skipif(\n        sys.platform.startswith(\"win32\"), reason=\"cannot remove cwd on Windows\"\n    )\n    @pytest.mark.skipif(\n        sys.platform.startswith(\"sunos5\"), reason=\"cannot remove cwd on Solaris\"\n    )\n    def test_cwd_changed(self, pytester: Pytester, monkeypatch) -> None:\n        # Setup conditions for py's fspath trying to import pathlib on py34\n        # always (previously triggered via xdist only).\n        # Ref: https://git"}, {"start_line": 58000, "end_line": 60000, "belongs_to": {"file_name": "test_assertrewrite.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "fig)\n    spec = hook.find_spec(\"test_foo\")\n    assert spec is not None\n    module = importlib.util.module_from_spec(spec)\n    hook.exec_module(module)\n    assert len(write_pyc_called) == 1\n\n\nclass TestEarlyRewriteBailout:\n    @pytest.fixture\n    def hook(\n        self, pytestconfig, monkeypatch, pytester: Pytester\n    ) -> Generator[AssertionRewritingHook]:\n        \"\"\"Returns a patched AssertionRewritingHook instance so we can configure its initial paths and track\n        if PathFinder.find_spec has been called.\n        \"\"\"\n        import importlib.machinery\n\n        self.find_spec_calls: list[str] = []\n        self.initial_paths: set[Path] = set()\n\n        class StubSession:\n            _initialpaths = self.initial_paths\n\n            def isinitpath(self, p):\n                return p in self._initialpaths\n\n        def spy_find_spec(name, path):\n            self.find_spec_calls.append(name)\n            return importlib.machinery.PathFinder.find_spec(name, path)\n\n        hook = AssertionRewritingHook(pytestconfig)\n        # use default patterns, otherwise we inherit pytest's testing config\n        with mock.patch.object(hook, \"fnpats\", [\"test_*.py\", \"*_test.py\"]):\n            monkeypatch.setattr(hook, \"_find_spec\", spy_find_spec)\n            hook.set_session(StubSession())  # type: ignore[arg-type]\n            pytester.syspathinsert()\n            yield hook\n\n    def test_basic(self, pytester: Pytester, hook: AssertionRewritingHook) -> None:\n        \"\"\"\n        Ensure we avoid calling PathFinder.find_spec when we know for sure a certain\n        module will not be rewritten to optimize assertion rewriting (#3918).\n        \"\"\"\n        pytester.makeconftest(\n            \"\"\"\n            import pytest\n            @pytest.fixture\n            def fix(): return 1\n        \"\"\"\n        )\n        pytester.makepyfile(test_foo=\"def test_foo(): pass\")\n        pytester.makepyfile(bar=\"def bar(): pass\")\n        foobar_path = pytester.makepyfile(foobar=\"def foobar(): pass\")\n        self"}, {"start_line": 7000, "end_line": 9000, "belongs_to": {"file_name": "test_assertion.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "e match files correctly when they are marked for rewriting (#2939).\"\"\"\n        contents = {\n            \"conftest.py\": \"\"\"\\\n                pytest_plugins = \"ham\"\n            \"\"\",\n            \"ham.py\": \"\",\n            \"hamster.py\": \"\",\n            \"test_foo.py\": \"\"\"\\\n                def test_foo(pytestconfig):\n                    assert pytestconfig.pluginmanager.rewrite_hook.find_spec('ham') is not None\n                    assert pytestconfig.pluginmanager.rewrite_hook.find_spec('hamster') is None\n            \"\"\",\n        }\n        pytester.makepyfile(**contents)\n        result = pytester.runpytest_subprocess(\"--assert=rewrite\")\n        assert result.ret == 0\n\n    @pytest.mark.parametrize(\"mode\", [\"plain\", \"rewrite\"])\n    @pytest.mark.parametrize(\"disable_plugin_autoload\", [\"env_var\", \"cli\", \"\"])\n    @pytest.mark.parametrize(\"explicit_specify\", [\"env_var\", \"cli\", \"\"])\n    def test_installed_plugin_rewrite(\n        self,\n        pytester: Pytester,\n        mode: str,\n        monkeypatch: pytest.MonkeyPatch,\n        disable_plugin_autoload: str,\n        explicit_specify: str,\n    ) -> None:\n        args = [\"mainwrapper.py\", \"-s\", f\"--assert={mode}\"]\n        if disable_plugin_autoload == \"env_var\":\n            monkeypatch.setenv(\"PYTEST_DISABLE_PLUGIN_AUTOLOAD\", \"1\")\n        elif disable_plugin_autoload == \"cli\":\n            monkeypatch.delenv(\"PYTEST_DISABLE_PLUGIN_AUTOLOAD\", raising=False)\n            args.append(\"--disable-plugin-autoload\")\n        else:\n            assert disable_plugin_autoload == \"\"\n            monkeypatch.delenv(\"PYTEST_DISABLE_PLUGIN_AUTOLOAD\", raising=False)\n\n        name = \"spamplugin\"\n\n        if explicit_specify == \"env_var\":\n            monkeypatch.setenv(\"PYTEST_PLUGINS\", name)\n        elif explicit_specify == \"cli\":\n            args.append(\"-p\")\n            args.append(name)\n        else:\n            assert explicit_specify == \"\"\n\n        # Make sure the hook is installed early enough so that plugins\n        # installed via distribution"}], "retrieved_count": 10, "cost_time": 1.1069893836975098}
{"question": "How does pytest's indirect parametrization mechanism resolve non-hashable dictionary items through fixture request parameters, and what internal transformations occur when parametrize decorators process mutable objects that cannot be used as cache keys?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"start_line": 14000, "end_line": 16000, "belongs_to": {"file_name": "collect.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing/python", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "values.\"\"\"\n        pytester.makepyfile(\n            \"\"\"\n            archival_mapping = {\n                '1.0': {'tag': '1.0'},\n                '1.2.2a1': {'tag': 'release-1.2.2a1'},\n            }\n\n            import pytest\n            @pytest.mark.parametrize('key value'.split(),\n                                     archival_mapping.items())\n            def test_archival_to_version(key, value):\n                assert key in archival_mapping\n                assert value == archival_mapping[key]\n        \"\"\"\n        )\n        rec = pytester.inline_run()\n        rec.assertoutcome(passed=2)\n\n    def test_parametrize_with_non_hashable_values_indirect(\n        self, pytester: Pytester\n    ) -> None:\n        \"\"\"Test parametrization with non-hashable values with indirect parametrization.\"\"\"\n        pytester.makepyfile(\n            \"\"\"\n            archival_mapping = {\n                '1.0': {'tag': '1.0'},\n                '1.2.2a1': {'tag': 'release-1.2.2a1'},\n            }\n\n            import pytest\n\n            @pytest.fixture\n            def key(request):\n                return request.param\n\n            @pytest.fixture\n            def value(request):\n                return request.param\n\n            @pytest.mark.parametrize('key value'.split(),\n                                     archival_mapping.items(), indirect=True)\n            def test_archival_to_version(key, value):\n                assert key in archival_mapping\n                assert value == archival_mapping[key]\n        \"\"\"\n        )\n        rec = pytester.inline_run()\n        rec.assertoutcome(passed=2)\n\n    def test_parametrize_overrides_fixture(self, pytester: Pytester) -> None:\n        \"\"\"Test parametrization when parameter overrides existing fixture with same name.\"\"\"\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n\n            @pytest.fixture\n            def value():\n                return 'value'\n\n            @pytest.mark.parametrize('value',\n                                     ["}, {"start_line": 12000, "end_line": 14000, "belongs_to": {"file_name": "collect.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing/python", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "elf, pytester: Pytester) -> None:\n        def func1():\n            pass\n\n        def func2():\n            pass\n\n        f1 = self.make_function(pytester, name=\"name\", callobj=func1)\n        assert f1 == f1\n        f2 = self.make_function(\n            pytester, name=\"name\", callobj=func2, originalname=\"foobar\"\n        )\n        assert f1 != f2\n\n    def test_repr_produces_actual_test_id(self, pytester: Pytester) -> None:\n        f = self.make_function(\n            pytester, name=r\"test[\\xe5]\", callobj=self.test_repr_produces_actual_test_id\n        )\n        assert repr(f) == r\"<Function test[\\xe5]>\"\n\n    def test_issue197_parametrize_emptyset(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n            @pytest.mark.parametrize('arg', [])\n            def test_function(arg):\n                pass\n        \"\"\"\n        )\n        reprec = pytester.inline_run()\n        reprec.assertoutcome(skipped=1)\n\n    def test_single_tuple_unwraps_values(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n            @pytest.mark.parametrize(('arg',), [(1,)])\n            def test_function(arg):\n                assert arg == 1\n        \"\"\"\n        )\n        reprec = pytester.inline_run()\n        reprec.assertoutcome(passed=1)\n\n    def test_issue213_parametrize_value_no_equal(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n            class A(object):\n                def __eq__(self, other):\n                    raise ValueError(\"not possible\")\n            @pytest.mark.parametrize('arg', [A()])\n            def test_function(arg):\n                assert arg.__class__.__name__ == \"A\"\n        \"\"\"\n        )\n        reprec = pytester.inline_run(\"--fulltrace\")\n        reprec.assertoutcome(passed=1)\n\n    def test_parametrize_with_non_hashable_values(self, pytester: Pytester) -> None:\n        \"\"\"Test parametrization with non-hashable "}, {"start_line": 13000, "end_line": 15000, "belongs_to": {"file_name": "collect.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing/python", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "es(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n            @pytest.mark.parametrize(('arg',), [(1,)])\n            def test_function(arg):\n                assert arg == 1\n        \"\"\"\n        )\n        reprec = pytester.inline_run()\n        reprec.assertoutcome(passed=1)\n\n    def test_issue213_parametrize_value_no_equal(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n            class A(object):\n                def __eq__(self, other):\n                    raise ValueError(\"not possible\")\n            @pytest.mark.parametrize('arg', [A()])\n            def test_function(arg):\n                assert arg.__class__.__name__ == \"A\"\n        \"\"\"\n        )\n        reprec = pytester.inline_run(\"--fulltrace\")\n        reprec.assertoutcome(passed=1)\n\n    def test_parametrize_with_non_hashable_values(self, pytester: Pytester) -> None:\n        \"\"\"Test parametrization with non-hashable values.\"\"\"\n        pytester.makepyfile(\n            \"\"\"\n            archival_mapping = {\n                '1.0': {'tag': '1.0'},\n                '1.2.2a1': {'tag': 'release-1.2.2a1'},\n            }\n\n            import pytest\n            @pytest.mark.parametrize('key value'.split(),\n                                     archival_mapping.items())\n            def test_archival_to_version(key, value):\n                assert key in archival_mapping\n                assert value == archival_mapping[key]\n        \"\"\"\n        )\n        rec = pytester.inline_run()\n        rec.assertoutcome(passed=2)\n\n    def test_parametrize_with_non_hashable_values_indirect(\n        self, pytester: Pytester\n    ) -> None:\n        \"\"\"Test parametrization with non-hashable values with indirect parametrization.\"\"\"\n        pytester.makepyfile(\n            \"\"\"\n            archival_mapping = {\n                '1.0': {'tag': '1.0'},\n                '1.2.2a1': {'tag': 'release-1.2.2a1'},\n            }\n\n            import "}, {"start_line": 25000, "end_line": 27000, "belongs_to": {"file_name": "metafunc.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing/python", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "       (\"a\"),\n            list(map(pytest.param, [1, 2, 3, 4, 5])),\n            None,\n            [\"a\", \"a\", \"b\", \"c\", \"b\"],\n            None,\n            None,\n            None,\n        ).make_unique_parameterset_ids()\n        assert result == [\"a0\", \"a1\", \"b0\", \"c\", \"b1\"]\n\n    def test_parametrize_indirect(self) -> None:\n        \"\"\"#714\"\"\"\n\n        def func(x, y):\n            pass\n\n        metafunc = self.Metafunc(func)\n        metafunc.parametrize(\"x\", [1], indirect=True)\n        metafunc.parametrize(\"y\", [2, 3], indirect=True)\n        assert len(metafunc._calls) == 2\n        assert metafunc._calls[0].params == dict(x=1, y=2)\n        assert metafunc._calls[1].params == dict(x=1, y=3)\n\n    def test_parametrize_indirect_list(self) -> None:\n        \"\"\"#714\"\"\"\n\n        def func(x, y):\n            pass\n\n        metafunc = self.Metafunc(func)\n        metafunc.parametrize(\"x, y\", [(\"a\", \"b\")], indirect=[\"x\"])\n        assert metafunc._calls[0].params == dict(x=\"a\", y=\"b\")\n        # Since `y` is a direct parameter, its pseudo-fixture would\n        # be registered.\n        assert list(metafunc._arg2fixturedefs.keys()) == [\"y\"]\n\n    def test_parametrize_indirect_list_all(self) -> None:\n        \"\"\"#714\"\"\"\n\n        def func(x, y):\n            pass\n\n        metafunc = self.Metafunc(func)\n        metafunc.parametrize(\"x, y\", [(\"a\", \"b\")], indirect=[\"x\", \"y\"])\n        assert metafunc._calls[0].params == dict(x=\"a\", y=\"b\")\n        assert list(metafunc._arg2fixturedefs.keys()) == []\n\n    def test_parametrize_indirect_list_empty(self) -> None:\n        \"\"\"#714\"\"\"\n\n        def func(x, y):\n            pass\n\n        metafunc = self.Metafunc(func)\n        metafunc.parametrize(\"x, y\", [(\"a\", \"b\")], indirect=[])\n        assert metafunc._calls[0].params == dict(x=\"a\", y=\"b\")\n        assert list(metafunc._arg2fixturedefs.keys()) == [\"x\", \"y\"]\n\n    def test_parametrize_indirect_wrong_type(self) -> None:\n        def func(x, y):\n            pass\n\n        metafunc = self.Metafunc(func)\n        "}, {"start_line": 24000, "end_line": 26000, "belongs_to": {"file_name": "metafunc.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing/python", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "_non_string.py::test_int[1] PASSED\",\n                \"test_parametrize_ids_returns_non_string.py::test_int[2.0] PASSED\",\n                \"test_parametrize_ids_returns_non_string.py::test_int[True] PASSED\",\n            ]\n        )\n\n    def test_idmaker_with_ids(self) -> None:\n        result = IdMaker(\n            (\"a\", \"b\"),\n            [pytest.param(1, 2), pytest.param(3, 4)],\n            None,\n            [\"a\", None],\n            None,\n            None,\n            None,\n        ).make_unique_parameterset_ids()\n        assert result == [\"a\", \"3-4\"]\n\n    def test_idmaker_with_paramset_id(self) -> None:\n        result = IdMaker(\n            (\"a\", \"b\"),\n            [pytest.param(1, 2, id=\"me\"), pytest.param(3, 4, id=\"you\")],\n            None,\n            [\"a\", None],\n            None,\n            None,\n            None,\n        ).make_unique_parameterset_ids()\n        assert result == [\"me\", \"you\"]\n\n    def test_idmaker_with_ids_unique_names(self) -> None:\n        result = IdMaker(\n            (\"a\"),\n            list(map(pytest.param, [1, 2, 3, 4, 5])),\n            None,\n            [\"a\", \"a\", \"b\", \"c\", \"b\"],\n            None,\n            None,\n            None,\n        ).make_unique_parameterset_ids()\n        assert result == [\"a0\", \"a1\", \"b0\", \"c\", \"b1\"]\n\n    def test_parametrize_indirect(self) -> None:\n        \"\"\"#714\"\"\"\n\n        def func(x, y):\n            pass\n\n        metafunc = self.Metafunc(func)\n        metafunc.parametrize(\"x\", [1], indirect=True)\n        metafunc.parametrize(\"y\", [2, 3], indirect=True)\n        assert len(metafunc._calls) == 2\n        assert metafunc._calls[0].params == dict(x=1, y=2)\n        assert metafunc._calls[1].params == dict(x=1, y=3)\n\n    def test_parametrize_indirect_list(self) -> None:\n        \"\"\"#714\"\"\"\n\n        def func(x, y):\n            pass\n\n        metafunc = self.Metafunc(func)\n        metafunc.parametrize(\"x, y\", [(\"a\", \"b\")], indirect=[\"x\"])\n        assert metafunc._calls[0].params == dict(x=\"a\", y=\"b\")\n        # Since `y"}, {"start_line": 57000, "end_line": 59000, "belongs_to": {"file_name": "metafunc.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing/python", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "ct=['echo'])\n            def test_1(animal, echo):\n                assert animal in ('dog', 'cat')\n                assert echo in (1, 2, 3)\n\n            @pytest.mark.parametrize('animal, echo', [('fish', 3)], indirect=['echo'])\n            def test_2(animal, echo):\n                assert animal == 'fish'\n                assert echo in (1, 2, 3)\n        \"\"\"\n        )\n        result = pytester.runpytest()\n        result.stdout.fnmatch_lines([\"* 3 passed *\"])\n\n    def test_parametrize_auto_scope_override_fixture(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n\n            @pytest.fixture(scope='session', autouse=True)\n            def animal():\n                return 'fox'\n\n            @pytest.mark.parametrize('animal', [\"dog\", \"cat\"])\n            def test_1(animal):\n                assert animal in ('dog', 'cat')\n        \"\"\"\n        )\n        result = pytester.runpytest()\n        result.stdout.fnmatch_lines([\"* 2 passed *\"])\n\n    def test_parametrize_all_indirects(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n\n            @pytest.fixture()\n            def animal(request):\n                return request.param\n\n            @pytest.fixture(scope='session')\n            def echo(request):\n                return request.param\n\n            @pytest.mark.parametrize('animal, echo', [(\"dog\", 1), (\"cat\", 2)], indirect=True)\n            def test_1(animal, echo):\n                assert animal in ('dog', 'cat')\n                assert echo in (1, 2, 3)\n\n            @pytest.mark.parametrize('animal, echo', [(\"fish\", 3)], indirect=True)\n            def test_2(animal, echo):\n                assert animal == 'fish'\n                assert echo in (1, 2, 3)\n        \"\"\"\n        )\n        result = pytester.runpytest()\n        result.stdout.fnmatch_lines([\"* 3 passed *\"])\n\n    def test_parametrize_some_arguments_auto_scope(\n        self, pytester: Pytester, monkeypatch\n    ) -"}, {"start_line": 143000, "end_line": 145000, "belongs_to": {"file_name": "fixtures.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing/python", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "ytester: Pytester) -> None:\n    \"\"\"Parametrized arguments would be shadowed if a fixture with the same name also exists (#5036)\"\"\"\n    pytester.makepyfile(\n        \"\"\"\n        import pytest\n\n        @pytest.fixture(params=['a', 'b'])\n        def argroot(request):\n            return request.param\n\n        @pytest.fixture\n        def arg(argroot):\n            return argroot\n\n        # This should only be parametrized directly\n        @pytest.mark.parametrize(\"arg\", [1])\n        def test_direct(arg):\n            assert arg == 1\n\n        # This should be parametrized based on the fixtures\n        def test_normal_fixture(arg):\n            assert isinstance(arg, str)\n\n        # Indirect should still work:\n\n        @pytest.fixture\n        def arg2(request):\n            return 2*request.param\n\n        @pytest.mark.parametrize(\"arg2\", [1], indirect=True)\n        def test_indirect(arg2):\n            assert arg2 == 2\n    \"\"\"\n    )\n    # Only one test should have run\n    result = pytester.runpytest(\"-v\")\n    result.assert_outcomes(passed=4)\n    result.stdout.fnmatch_lines([\"*::test_direct[[]1[]]*\"])\n    result.stdout.fnmatch_lines([\"*::test_normal_fixture[[]a[]]*\"])\n    result.stdout.fnmatch_lines([\"*::test_normal_fixture[[]b[]]*\"])\n    result.stdout.fnmatch_lines([\"*::test_indirect[[]1[]]*\"])\n\n\ndef test_fixture_named_request(pytester: Pytester) -> None:\n    pytester.copy_example(\"fixtures/test_fixture_named_request.py\")\n    result = pytester.runpytest()\n    result.stdout.fnmatch_lines(\n        [\n            \"*'request' is a reserved word for fixtures, use another name:\",\n            \"  *test_fixture_named_request.py:8\",\n        ]\n    )\n\n\ndef test_indirect_fixture_does_not_break_scope(pytester: Pytester) -> None:\n    \"\"\"Ensure that fixture scope is respected when using indirect fixtures (#570)\"\"\"\n    pytester.makepyfile(\n        \"\"\"\n        import pytest\n        instantiated  = []\n\n        @pytest.fixture(scope=\"session\")\n        def fixture_1(request):\n            instantiated"}, {"start_line": 26000, "end_line": 28000, "belongs_to": {"file_name": "metafunc.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing/python", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "` is a direct parameter, its pseudo-fixture would\n        # be registered.\n        assert list(metafunc._arg2fixturedefs.keys()) == [\"y\"]\n\n    def test_parametrize_indirect_list_all(self) -> None:\n        \"\"\"#714\"\"\"\n\n        def func(x, y):\n            pass\n\n        metafunc = self.Metafunc(func)\n        metafunc.parametrize(\"x, y\", [(\"a\", \"b\")], indirect=[\"x\", \"y\"])\n        assert metafunc._calls[0].params == dict(x=\"a\", y=\"b\")\n        assert list(metafunc._arg2fixturedefs.keys()) == []\n\n    def test_parametrize_indirect_list_empty(self) -> None:\n        \"\"\"#714\"\"\"\n\n        def func(x, y):\n            pass\n\n        metafunc = self.Metafunc(func)\n        metafunc.parametrize(\"x, y\", [(\"a\", \"b\")], indirect=[])\n        assert metafunc._calls[0].params == dict(x=\"a\", y=\"b\")\n        assert list(metafunc._arg2fixturedefs.keys()) == [\"x\", \"y\"]\n\n    def test_parametrize_indirect_wrong_type(self) -> None:\n        def func(x, y):\n            pass\n\n        metafunc = self.Metafunc(func)\n        with pytest.raises(\n            fail.Exception,\n            match=\"In func: expected Sequence or boolean for indirect, got dict\",\n        ):\n            metafunc.parametrize(\"x, y\", [(\"a\", \"b\")], indirect={})  # type: ignore[arg-type]\n\n    def test_parametrize_indirect_list_functional(self, pytester: Pytester) -> None:\n        \"\"\"\n        #714\n        Test parametrization with 'indirect' parameter applied on\n        particular arguments. As y is direct, its value should\n        be used directly rather than being passed to the fixture y.\n\n        :param pytester: the instance of Pytester class, a temporary\n        test directory.\n        \"\"\"\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n            @pytest.fixture(scope='function')\n            def x(request):\n                return request.param * 3\n            @pytest.fixture(scope='function')\n            def y(request):\n                return request.param * 2\n            @pytest.mark.parametrize('x, y', [('a'"}, {"start_line": 41000, "end_line": 43000, "belongs_to": {"file_name": "python.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "s which will be added to the item's name in `[..]` separated by \"-\".\n    _idlist: Sequence[str] = dataclasses.field(default_factory=tuple)\n    # Marks which will be applied to the item.\n    marks: list[Mark] = dataclasses.field(default_factory=list)\n\n    def setmulti(\n        self,\n        *,\n        argnames: Iterable[str],\n        valset: Iterable[object],\n        id: str | _HiddenParam,\n        marks: Iterable[Mark | MarkDecorator],\n        scope: Scope,\n        param_index: int,\n        nodeid: str,\n    ) -> CallSpec2:\n        params = self.params.copy()\n        indices = self.indices.copy()\n        arg2scope = dict(self._arg2scope)\n        for arg, val in zip(argnames, valset):\n            if arg in params:\n                raise nodes.Collector.CollectError(\n                    f\"{nodeid}: duplicate parametrization of {arg!r}\"\n                )\n            params[arg] = val\n            indices[arg] = param_index\n            arg2scope[arg] = scope\n        return CallSpec2(\n            params=params,\n            indices=indices,\n            _arg2scope=arg2scope,\n            _idlist=self._idlist if id is HIDDEN_PARAM else [*self._idlist, id],\n            marks=[*self.marks, *normalize_mark_list(marks)],\n        )\n\n    def getparam(self, name: str) -> object:\n        try:\n            return self.params[name]\n        except KeyError as e:\n            raise ValueError(name) from e\n\n    @property\n    def id(self) -> str:\n        return \"-\".join(self._idlist)\n\n\ndef get_direct_param_fixture_func(request: FixtureRequest) -> Any:\n    return request.param\n\n\n# Used for storing pseudo fixturedefs for direct parametrization.\nname2pseudofixturedef_key = StashKey[dict[str, FixtureDef[Any]]]()\n\n\n@final\nclass Metafunc:\n    \"\"\"Objects passed to the :hook:`pytest_generate_tests` hook.\n\n    They help to inspect a test function and to generate tests according to\n    test configuration or values specified in the class or module where a\n    test function is defined.\n    \"\"\"\n\n    def __"}, {"start_line": 41000, "end_line": 43000, "belongs_to": {"file_name": "fixtures.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing/python", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "id_scope.py got an unexpected scope value 'functions'\"\n        )\n\n    @pytest.mark.parametrize(\"scope\", [\"function\", \"session\"])\n    def test_parameters_without_eq_semantics(self, scope, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            f\"\"\"\n            class NoEq1:  # fails on `a == b` statement\n                def __eq__(self, _):\n                    raise RuntimeError\n\n            class NoEq2:  # fails on `if a == b:` statement\n                def __eq__(self, _):\n                    class NoBool:\n                        def __bool__(self):\n                            raise RuntimeError\n                    return NoBool()\n\n            import pytest\n            @pytest.fixture(params=[NoEq1(), NoEq2()], scope={scope!r})\n            def no_eq(request):\n                return request.param\n\n            def test1(no_eq):\n                pass\n\n            def test2(no_eq):\n                pass\n        \"\"\"\n        )\n        result = pytester.runpytest()\n        result.stdout.fnmatch_lines([\"*4 passed*\"])\n\n    def test_funcarg_parametrized_and_used_twice(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n            values = []\n            @pytest.fixture(params=[1,2])\n            def arg1(request):\n                values.append(1)\n                return request.param\n\n            @pytest.fixture()\n            def arg2(arg1):\n                return arg1 + 1\n\n            def test_add(arg1, arg2):\n                assert arg2 == arg1 + 1\n                assert len(values) == arg1\n        \"\"\"\n        )\n        result = pytester.runpytest()\n        result.stdout.fnmatch_lines([\"*2 passed*\"])\n\n    def test_factory_uses_unknown_funcarg_as_dependency_error(\n        self, pytester: Pytester\n    ) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n\n            @pytest.fixture()\n            def fail(missing):\n                return\n\n            @pytest.fixture()\n            def "}], "retrieved_count": 10, "cost_time": 1.1392920017242432}
{"question": "Why would caching the Source object initialization in setup_class impact the performance characteristics of the TestAccesses test suite when executed repeatedly across multiple test runs?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"start_line": 1000, "end_line": 3000, "belongs_to": {"file_name": "test_source.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing/code", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": " None:\n    lines = [\"a \\n\", \"b\\n\", \"c\"]\n    source = Source(lines)\n    assert source.lines == [\"a \", \"b\", \"c\"]\n\n\ndef test_source_from_inner_function() -> None:\n    def f():\n        raise NotImplementedError()\n\n    source = Source(f)\n    assert str(source).startswith(\"def f():\")\n\n\ndef test_source_strips() -> None:\n    source = Source(\"\")\n    assert source == Source()\n    assert str(source) == \"\"\n    assert source.strip() == source\n\n\ndef test_source_strip_multiline() -> None:\n    source = Source()\n    source.lines = [\"\", \" hello\", \"  \"]\n    source2 = source.strip()\n    assert source2.lines == [\" hello\"]\n\n\nclass TestAccesses:\n    def setup_class(self) -> None:\n        self.source = Source(\n            \"\"\"\\\n            def f(x):\n                pass\n            def g(x):\n                pass\n        \"\"\"\n        )\n\n    def test_getrange(self) -> None:\n        x = self.source[0:2]\n        assert len(x.lines) == 2\n        assert str(x) == \"def f(x):\\n    pass\"\n\n    def test_getrange_step_not_supported(self) -> None:\n        with pytest.raises(IndexError, match=r\"step\"):\n            self.source[::2]\n\n    def test_getline(self) -> None:\n        x = self.source[0]\n        assert x == \"def f(x):\"\n\n    def test_len(self) -> None:\n        assert len(self.source) == 4\n\n    def test_iter(self) -> None:\n        values = [x for x in self.source]\n        assert len(values) == 4\n\n\nclass TestSourceParsing:\n    def setup_class(self) -> None:\n        self.source = Source(\n            \"\"\"\\\n            def f(x):\n                assert (x ==\n                        3 +\n                        4)\n        \"\"\"\n        ).strip()\n\n    def test_getstatement(self) -> None:\n        # print str(self.source)\n        ass = str(self.source[1:])\n        for i in range(1, 4):\n            # print \"trying start in line %r\" % self.source[i]\n            s = self.source.getstatement(i)\n            # x = s.deindent()\n            assert str(s) == ass\n\n    def test_getstatementrange_triple_quoted(self) -> None:\n"}, {"start_line": 149000, "end_line": 151000, "belongs_to": {"file_name": "fixtures.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing/python", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "           @pytest.fixture(autouse=True)\n            def fixture(self):\n                assert not self.ran_fixture\n                self.ran_fixture = True\n\n            def test_method(self):\n                assert self.ran_setup_method\n                assert self.ran_fixture\n\n            @staticmethod\n            def test_1(request):\n                assert request.instance.ran_setup_method\n                assert request.instance.ran_fixture\n\n            @classmethod\n            def test_2(cls, request):\n                assert request.instance.ran_setup_method\n                assert request.instance.ran_fixture\n        \"\"\"\n    )\n    result = pytester.runpytest()\n    assert result.ret == ExitCode.OK\n    result.assert_outcomes(passed=3)\n\n\ndef test_scoped_fixture_caching(pytester: Pytester) -> None:\n    \"\"\"Make sure setup and finalization is only run once when using scoped fixture\n    multiple times.\"\"\"\n    pytester.makepyfile(\n        \"\"\"\n        from __future__ import annotations\n\n        from typing import Generator\n\n        import pytest\n        executed: list[str] = []\n        @pytest.fixture(scope=\"class\")\n        def fixture_1() -> Generator[None, None, None]:\n            executed.append(\"fix setup\")\n            yield\n            executed.append(\"fix teardown\")\n\n\n        class TestFixtureCaching:\n            def test_1(self, fixture_1: None) -> None:\n                assert executed == [\"fix setup\"]\n\n            def test_2(self, fixture_1: None) -> None:\n                assert executed == [\"fix setup\"]\n\n\n        def test_expected_setup_and_teardown() -> None:\n            assert executed == [\"fix setup\", \"fix teardown\"]\n        \"\"\"\n    )\n    result = pytester.runpytest()\n    assert result.ret == 0\n\n\ndef test_scoped_fixture_caching_exception(pytester: Pytester) -> None:\n    \"\"\"Make sure setup & finalization is only run once for scoped fixture, with a cached exception.\"\"\"\n    pytester.makepyfile(\n        \"\"\"\n        from __future__ import annotations\n\n        import"}, {"start_line": 0, "end_line": 2000, "belongs_to": {"file_name": "test_source.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing/code", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "# mypy: allow-untyped-defs\nfrom __future__ import annotations\n\nimport inspect\nimport linecache\nfrom pathlib import Path\nimport sys\nimport textwrap\nfrom typing import Any\n\nfrom _pytest._code import Code\nfrom _pytest._code import Frame\nfrom _pytest._code import getfslineno\nfrom _pytest._code import Source\nfrom _pytest.pathlib import import_path\nimport pytest\n\n\ndef test_source_str_function() -> None:\n    x = Source(\"3\")\n    assert str(x) == \"3\"\n\n    x = Source(\"   3\")\n    assert str(x) == \"3\"\n\n    x = Source(\n        \"\"\"\n        3\n        \"\"\"\n    )\n    assert str(x) == \"\\n3\"\n\n\ndef test_source_from_function() -> None:\n    source = Source(test_source_str_function)\n    assert str(source).startswith(\"def test_source_str_function() -> None:\")\n\n\ndef test_source_from_method() -> None:\n    class TestClass:\n        def test_method(self):\n            pass\n\n    source = Source(TestClass().test_method)\n    assert source.lines == [\"def test_method(self):\", \"    pass\"]\n\n\ndef test_source_from_lines() -> None:\n    lines = [\"a \\n\", \"b\\n\", \"c\"]\n    source = Source(lines)\n    assert source.lines == [\"a \", \"b\", \"c\"]\n\n\ndef test_source_from_inner_function() -> None:\n    def f():\n        raise NotImplementedError()\n\n    source = Source(f)\n    assert str(source).startswith(\"def f():\")\n\n\ndef test_source_strips() -> None:\n    source = Source(\"\")\n    assert source == Source()\n    assert str(source) == \"\"\n    assert source.strip() == source\n\n\ndef test_source_strip_multiline() -> None:\n    source = Source()\n    source.lines = [\"\", \" hello\", \"  \"]\n    source2 = source.strip()\n    assert source2.lines == [\" hello\"]\n\n\nclass TestAccesses:\n    def setup_class(self) -> None:\n        self.source = Source(\n            \"\"\"\\\n            def f(x):\n                pass\n            def g(x):\n                pass\n        \"\"\"\n        )\n\n    def test_getrange(self) -> None:\n        x = self.source[0:2]\n        assert len(x.lines) == 2\n        assert str(x) == \"def f(x):\\n    pass\"\n\n    def test_getrange_step_not_"}, {"start_line": 7000, "end_line": 9000, "belongs_to": {"file_name": "test_source.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing/code", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "(source.splitlines())\n    assert lines == [\"def f():\", \"    def g():\", \"        pass\"]\n\n\ndef test_source_of_class_at_eof_without_newline(_sys_snapshot, tmp_path: Path) -> None:\n    # this test fails because the implicit inspect.getsource(A) below\n    # does not return the \"x = 1\" last line.\n    source = Source(\n        \"\"\"\n        class A:\n            def method(self):\n                x = 1\n    \"\"\"\n    )\n    path = tmp_path.joinpath(\"a.py\")\n    path.write_text(str(source), encoding=\"utf-8\")\n    mod: Any = import_path(path, root=tmp_path, consider_namespace_packages=False)\n    s2 = Source(mod.A)\n    assert str(source).strip() == str(s2).strip()\n\n\nif True:\n\n    def x():\n        pass\n\n\ndef test_source_fallback() -> None:\n    src = Source(x)\n    expected = \"\"\"def x():\n    pass\"\"\"\n    assert str(src) == expected\n\n\ndef test_findsource_fallback() -> None:\n    from _pytest._code.source import findsource\n\n    src, lineno = findsource(x)\n    assert src is not None\n    assert \"test_findsource_simple\" in str(src)\n    assert src[lineno] == \"    def x():\"\n\n\ndef test_findsource(monkeypatch) -> None:\n    from _pytest._code.source import findsource\n\n    filename = \"<pytest-test_findsource>\"\n    lines = [\"if 1:\\n\", \"    def x():\\n\", \"          pass\\n\"]\n    co = compile(\"\".join(lines), filename, \"exec\")\n\n    monkeypatch.setitem(linecache.cache, filename, (1, None, lines, filename))\n\n    src, lineno = findsource(co)\n    assert src is not None\n    assert \"if 1:\" in str(src)\n\n    d: dict[str, Any] = {}\n    eval(co, d)\n    src, lineno = findsource(d[\"x\"])\n    assert src is not None\n    assert \"if 1:\" in str(src)\n    assert src[lineno] == \"    def x():\"\n\n\ndef test_getfslineno() -> None:\n    def f(x) -> None:\n        raise NotImplementedError()\n\n    fspath, lineno = getfslineno(f)\n\n    assert isinstance(fspath, Path)\n    assert fspath.name == \"test_source.py\"\n    assert lineno == f.__code__.co_firstlineno - 1  # see findsource\n\n    class A:\n        pass\n\n    fspath, lineno = getfslineno(A)\n"}, {"start_line": 150000, "end_line": 152000, "belongs_to": {"file_name": "fixtures.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing/python", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "   from typing import Generator\n\n        import pytest\n        executed: list[str] = []\n        @pytest.fixture(scope=\"class\")\n        def fixture_1() -> Generator[None, None, None]:\n            executed.append(\"fix setup\")\n            yield\n            executed.append(\"fix teardown\")\n\n\n        class TestFixtureCaching:\n            def test_1(self, fixture_1: None) -> None:\n                assert executed == [\"fix setup\"]\n\n            def test_2(self, fixture_1: None) -> None:\n                assert executed == [\"fix setup\"]\n\n\n        def test_expected_setup_and_teardown() -> None:\n            assert executed == [\"fix setup\", \"fix teardown\"]\n        \"\"\"\n    )\n    result = pytester.runpytest()\n    assert result.ret == 0\n\n\ndef test_scoped_fixture_caching_exception(pytester: Pytester) -> None:\n    \"\"\"Make sure setup & finalization is only run once for scoped fixture, with a cached exception.\"\"\"\n    pytester.makepyfile(\n        \"\"\"\n        from __future__ import annotations\n\n        import pytest\n        executed_crash: list[str] = []\n\n\n        @pytest.fixture(scope=\"class\")\n        def fixture_crash(request: pytest.FixtureRequest) -> None:\n            executed_crash.append(\"fix_crash setup\")\n\n            def my_finalizer() -> None:\n                executed_crash.append(\"fix_crash teardown\")\n\n            request.addfinalizer(my_finalizer)\n\n            raise Exception(\"foo\")\n\n\n        class TestFixtureCachingException:\n            @pytest.mark.xfail\n            def test_crash_1(self, fixture_crash: None) -> None:\n                ...\n\n            @pytest.mark.xfail\n            def test_crash_2(self, fixture_crash: None) -> None:\n                ...\n\n\n        def test_crash_expected_setup_and_teardown() -> None:\n            assert executed_crash == [\"fix_crash setup\", \"fix_crash teardown\"]\n        \"\"\"\n    )\n    result = pytester.runpytest()\n    assert result.ret == 0\n\n\ndef test_scoped_fixture_teardown_order(pytester: Pytester) -> None:\n    \"\"\"\n    Make sure teardowns happe"}, {"start_line": 48000, "end_line": 50000, "belongs_to": {"file_name": "fixtures.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing/python", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "        DB_INITIALIZED = False\n\n            def setup_module():\n                assert DB_INITIALIZED\n\n            def teardown_module():\n                assert DB_INITIALIZED\n\n            class TestClass(object):\n\n                def setup_method(self, method):\n                    assert DB_INITIALIZED\n\n                def teardown_method(self, method):\n                    assert DB_INITIALIZED\n\n                def test_printer_1(self):\n                    pass\n\n                def test_printer_2(self):\n                    pass\n        \"\"\"\n        )\n        result = pytester.runpytest()\n        result.stdout.fnmatch_lines([\"* 2 passed in *\"])\n\n    def test_parameterized_fixture_caching(self, pytester: Pytester) -> None:\n        \"\"\"Regression test for #12600.\"\"\"\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n            from itertools import count\n\n            CACHE_MISSES = count(0)\n\n            def pytest_generate_tests(metafunc):\n                if \"my_fixture\" in metafunc.fixturenames:\n                    # Use unique objects for parametrization (as opposed to small strings\n                    # and small integers which are singletons).\n                    metafunc.parametrize(\"my_fixture\", [[1], [2]], indirect=True)\n\n            @pytest.fixture(scope='session')\n            def my_fixture(request):\n                next(CACHE_MISSES)\n\n            def test1(my_fixture):\n                pass\n\n            def test2(my_fixture):\n                pass\n\n            def teardown_module():\n                assert next(CACHE_MISSES) == 2\n            \"\"\"\n        )\n        result = pytester.runpytest()\n        result.stdout.no_fnmatch_line(\"* ERROR at teardown *\")\n\n    def test_unwrapping_pytest_fixture(self, pytester: Pytester) -> None:\n        \"\"\"Ensure the unwrap method on `FixtureFunctionDefinition` correctly wraps and unwraps methods and functions\"\"\"\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n            import inspect\n"}, {"start_line": 2000, "end_line": 4000, "belongs_to": {"file_name": "test_source.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing/code", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "supported(self) -> None:\n        with pytest.raises(IndexError, match=r\"step\"):\n            self.source[::2]\n\n    def test_getline(self) -> None:\n        x = self.source[0]\n        assert x == \"def f(x):\"\n\n    def test_len(self) -> None:\n        assert len(self.source) == 4\n\n    def test_iter(self) -> None:\n        values = [x for x in self.source]\n        assert len(values) == 4\n\n\nclass TestSourceParsing:\n    def setup_class(self) -> None:\n        self.source = Source(\n            \"\"\"\\\n            def f(x):\n                assert (x ==\n                        3 +\n                        4)\n        \"\"\"\n        ).strip()\n\n    def test_getstatement(self) -> None:\n        # print str(self.source)\n        ass = str(self.source[1:])\n        for i in range(1, 4):\n            # print \"trying start in line %r\" % self.source[i]\n            s = self.source.getstatement(i)\n            # x = s.deindent()\n            assert str(s) == ass\n\n    def test_getstatementrange_triple_quoted(self) -> None:\n        # print str(self.source)\n        source = Source(\n            \"\"\"hello('''\n        ''')\"\"\"\n        )\n        s = source.getstatement(0)\n        assert s == source\n        s = source.getstatement(1)\n        assert s == source\n\n    def test_getstatementrange_within_constructs(self) -> None:\n        source = Source(\n            \"\"\"\\\n            try:\n                try:\n                    raise ValueError\n                except SomeThing:\n                    pass\n            finally:\n                42\n        \"\"\"\n        )\n        assert len(source) == 7\n        # check all lineno's that could occur in a traceback\n        # assert source.getstatementrange(0) == (0, 7)\n        # assert source.getstatementrange(1) == (1, 5)\n        assert source.getstatementrange(2) == (2, 3)\n        assert source.getstatementrange(3) == (3, 4)\n        assert source.getstatementrange(4) == (4, 5)\n        # assert source.getstatementrange(5) == (0, 7)\n        assert source.getstatementrange(6) == ("}, {"start_line": 6000, "end_line": 8000, "belongs_to": {"file_name": "test_source.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing/code", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "wn:\n                teardown()  # type: ignore[unreachable]\n    source = excinfo.traceback[-1].statement\n    assert str(source).strip() == \"c(1)  # type: ignore\"\n\n\ndef test_getfuncsource_dynamic() -> None:\n    def f():\n        raise NotImplementedError()\n\n    def g():\n        pass  # pragma: no cover\n\n    f_source = Source(f)\n    g_source = Source(g)\n    assert str(f_source).strip() == \"def f():\\n    raise NotImplementedError()\"\n    assert str(g_source).strip() == \"def g():\\n    pass  # pragma: no cover\"\n\n\ndef test_getfuncsource_with_multiline_string() -> None:\n    def f():\n        c = \"\"\"while True:\n    pass\n\"\"\"\n\n    expected = '''\\\n    def f():\n        c = \"\"\"while True:\n    pass\n\"\"\"\n'''\n    assert str(Source(f)) == expected.rstrip()\n\n\ndef test_deindent() -> None:\n    from _pytest._code.source import deindent as deindent\n\n    assert deindent([\"\\tfoo\", \"\\tbar\"]) == [\"foo\", \"bar\"]\n\n    source = \"\"\"\\\n        def f():\n            def g():\n                pass\n    \"\"\"\n    lines = deindent(source.splitlines())\n    assert lines == [\"def f():\", \"    def g():\", \"        pass\"]\n\n\ndef test_source_of_class_at_eof_without_newline(_sys_snapshot, tmp_path: Path) -> None:\n    # this test fails because the implicit inspect.getsource(A) below\n    # does not return the \"x = 1\" last line.\n    source = Source(\n        \"\"\"\n        class A:\n            def method(self):\n                x = 1\n    \"\"\"\n    )\n    path = tmp_path.joinpath(\"a.py\")\n    path.write_text(str(source), encoding=\"utf-8\")\n    mod: Any = import_path(path, root=tmp_path, consider_namespace_packages=False)\n    s2 = Source(mod.A)\n    assert str(source).strip() == str(s2).strip()\n\n\nif True:\n\n    def x():\n        pass\n\n\ndef test_source_fallback() -> None:\n    src = Source(x)\n    expected = \"\"\"def x():\n    pass\"\"\"\n    assert str(src) == expected\n\n\ndef test_findsource_fallback() -> None:\n    from _pytest._code.source import findsource\n\n    src, lineno = findsource(x)\n    assert src is not None\n    assert \"test_findsource_sim"}, {"start_line": 33000, "end_line": 35000, "belongs_to": {"file_name": "collect.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing/python", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "   This tests a performance optimization, not correctness, really,\n        although it tests PytestCollectionWarning is not raised, while\n        it would have been raised otherwise.\n        \"\"\"\n        pytester.makeini(\n            \"\"\"\n            [pytest]\n            python_classes=*\n            python_functions=*\n        \"\"\"\n        )\n        pytester.makepyfile(\n            \"\"\"\n            class TestEmpty:\n                pass\n            test_empty = TestEmpty()\n            def test_real():\n                pass\n        \"\"\"\n        )\n        items, rec = pytester.inline_genitems()\n        assert rec.ret == 0\n        assert len(items) == 1\n\n\ndef test_setup_only_available_in_subdir(pytester: Pytester) -> None:\n    sub1 = pytester.mkpydir(\"sub1\")\n    sub2 = pytester.mkpydir(\"sub2\")\n    sub1.joinpath(\"conftest.py\").write_text(\n        textwrap.dedent(\n            \"\"\"\\\n            import pytest\n            def pytest_runtest_setup(item):\n                assert item.path.stem == \"test_in_sub1\"\n            def pytest_runtest_call(item):\n                assert item.path.stem == \"test_in_sub1\"\n            def pytest_runtest_teardown(item):\n                assert item.path.stem == \"test_in_sub1\"\n            \"\"\"\n        ),\n        encoding=\"utf-8\",\n    )\n    sub2.joinpath(\"conftest.py\").write_text(\n        textwrap.dedent(\n            \"\"\"\\\n            import pytest\n            def pytest_runtest_setup(item):\n                assert item.path.stem == \"test_in_sub2\"\n            def pytest_runtest_call(item):\n                assert item.path.stem == \"test_in_sub2\"\n            def pytest_runtest_teardown(item):\n                assert item.path.stem == \"test_in_sub2\"\n            \"\"\"\n        ),\n        encoding=\"utf-8\",\n    )\n    sub1.joinpath(\"test_in_sub1.py\").write_text(\"def test_1(): pass\", encoding=\"utf-8\")\n    sub2.joinpath(\"test_in_sub2.py\").write_text(\"def test_2(): pass\", encoding=\"utf-8\")\n    result = pytester.runpytest(\"-v\", \"-s\")\n    result.assert_outcomes(passed=2)\n\n"}, {"start_line": 106000, "end_line": 108000, "belongs_to": {"file_name": "fixtures.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing/python", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": " hash(B) or True\n            \"\"\"\n        )\n        monkeypatch.setenv(\"PYTHONHASHSEED\", \"1\")\n        out1 = pytester.runpytest_subprocess(\"-v\")\n        monkeypatch.setenv(\"PYTHONHASHSEED\", \"2\")\n        out2 = pytester.runpytest_subprocess(\"-v\")\n        output1 = [\n            line\n            for line in out1.outlines\n            if line.startswith(\"test_deterministic_fixture_collection.py::test_foo\")\n        ]\n        output2 = [\n            line\n            for line in out2.outlines\n            if line.startswith(\"test_deterministic_fixture_collection.py::test_foo\")\n        ]\n        assert len(output1) == 12\n        assert output1 == output2\n\n\nclass TestRequestScopeAccess:\n    pytestmark = pytest.mark.parametrize(\n        (\"scope\", \"ok\", \"error\"),\n        [\n            [\"session\", \"\", \"path class function module\"],\n            [\"module\", \"module path\", \"cls function\"],\n            [\"class\", \"module path cls\", \"function\"],\n            [\"function\", \"module path cls function\", \"\"],\n        ],\n    )\n\n    def test_setup(self, pytester: Pytester, scope, ok, error) -> None:\n        pytester.makepyfile(\n            f\"\"\"\n            import pytest\n            @pytest.fixture(scope={scope!r}, autouse=True)\n            def myscoped(request):\n                for x in {ok.split()}:\n                    assert hasattr(request, x)\n                for x in {error.split()}:\n                    pytest.raises(AttributeError, lambda:\n                        getattr(request, x))\n                assert request.session\n                assert request.config\n            def test_func():\n                pass\n        \"\"\"\n        )\n        reprec = pytester.inline_run(\"-l\")\n        reprec.assertoutcome(passed=1)\n\n    def test_funcarg(self, pytester: Pytester, scope, ok, error) -> None:\n        pytester.makepyfile(\n            f\"\"\"\n            import pytest\n            @pytest.fixture(scope={scope!r})\n            def arg(request):\n                for x in {ok.split()!r}:\n                    as"}], "retrieved_count": 10, "cost_time": 1.1368036270141602}
{"question": "How does the pytest capture framework ensure that stdout and stderr captured during setup and teardown phases are correctly isolated and reported separately from the test execution phase, particularly when multiple fixtures at different scopes are involved?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"start_line": 24000, "end_line": 26000, "belongs_to": {"file_name": "test_capture.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "eadouterr()\n                assert out == 'stdout contents end\\\\n'\n                assert err == 'stderr contents end\\\\n'\n\n            def test_captured_print(captured_print):\n                out, err = captured_print\n                assert out == 'stdout contents begin\\\\n'\n                assert err == 'stderr contents begin\\\\n'\n        \"\"\"\n        )\n        result = pytester.runpytest_subprocess()\n        result.stdout.fnmatch_lines([\"*1 passed*\"])\n        result.stdout.no_fnmatch_line(\"*stdout contents begin*\")\n        result.stdout.no_fnmatch_line(\"*stderr contents begin*\")\n\n    @pytest.mark.parametrize(\"cap\", [\"capsys\", \"capfd\"])\n    def test_fixture_use_by_other_fixtures_teardown(\n        self, pytester: Pytester, cap\n    ) -> None:\n        \"\"\"Ensure we can access setup and teardown buffers from teardown when using capsys/capfd (##3033)\"\"\"\n        pytester.makepyfile(\n            f\"\"\"\\\n            import sys\n            import pytest\n            import os\n\n            @pytest.fixture()\n            def fix({cap}):\n                print(\"setup out\")\n                sys.stderr.write(\"setup err\\\\n\")\n                yield\n                out, err = {cap}.readouterr()\n                assert out == 'setup out\\\\ncall out\\\\n'\n                assert err == 'setup err\\\\ncall err\\\\n'\n\n            def test_a(fix):\n                print(\"call out\")\n                sys.stderr.write(\"call err\\\\n\")\n        \"\"\"\n        )\n        reprec = pytester.inline_run()\n        reprec.assertoutcome(passed=1)\n\n\ndef test_setup_failure_does_not_kill_capturing(pytester: Pytester) -> None:\n    sub1 = pytester.mkpydir(\"sub1\")\n    sub1.joinpath(\"conftest.py\").write_text(\n        textwrap.dedent(\n            \"\"\"\\\n            def pytest_runtest_setup(item):\n                raise ValueError(42)\n            \"\"\"\n        ),\n        encoding=\"utf-8\",\n    )\n    sub1.joinpath(\"test_mod.py\").write_text(\"def test_func1(): pass\", encoding=\"utf-8\")\n    result = pytester.runpytest(pytester.path, \"--traceconfi"}, {"start_line": 25000, "end_line": 27000, "belongs_to": {"file_name": "test_capture.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "ture()\n            def fix({cap}):\n                print(\"setup out\")\n                sys.stderr.write(\"setup err\\\\n\")\n                yield\n                out, err = {cap}.readouterr()\n                assert out == 'setup out\\\\ncall out\\\\n'\n                assert err == 'setup err\\\\ncall err\\\\n'\n\n            def test_a(fix):\n                print(\"call out\")\n                sys.stderr.write(\"call err\\\\n\")\n        \"\"\"\n        )\n        reprec = pytester.inline_run()\n        reprec.assertoutcome(passed=1)\n\n\ndef test_setup_failure_does_not_kill_capturing(pytester: Pytester) -> None:\n    sub1 = pytester.mkpydir(\"sub1\")\n    sub1.joinpath(\"conftest.py\").write_text(\n        textwrap.dedent(\n            \"\"\"\\\n            def pytest_runtest_setup(item):\n                raise ValueError(42)\n            \"\"\"\n        ),\n        encoding=\"utf-8\",\n    )\n    sub1.joinpath(\"test_mod.py\").write_text(\"def test_func1(): pass\", encoding=\"utf-8\")\n    result = pytester.runpytest(pytester.path, \"--traceconfig\")\n    result.stdout.fnmatch_lines([\"*ValueError(42)*\", \"*1 error*\"])\n\n\ndef test_capture_conftest_runtest_setup(pytester: Pytester) -> None:\n    pytester.makeconftest(\n        \"\"\"\n        def pytest_runtest_setup():\n            print(\"hello19\")\n    \"\"\"\n    )\n    pytester.makepyfile(\"def test_func(): pass\")\n    result = pytester.runpytest()\n    assert result.ret == 0\n    result.stdout.no_fnmatch_line(\"*hello19*\")\n\n\ndef test_capture_badoutput_issue412(pytester: Pytester) -> None:\n    pytester.makepyfile(\n        \"\"\"\n        import os\n\n        def test_func():\n            omg = bytearray([1,129,1])\n            os.write(1, omg)\n            assert 0\n        \"\"\"\n    )\n    result = pytester.runpytest(\"--capture=fd\")\n    result.stdout.fnmatch_lines(\n        \"\"\"\n        *def test_func*\n        *assert 0*\n        *Captured*\n        *1 failed*\n    \"\"\"\n    )\n\n\ndef test_capture_early_option_parsing(pytester: Pytester) -> None:\n    pytester.makeconftest(\n        \"\"\"\n        def pytest_runtest_setup"}, {"start_line": 5000, "end_line": 7000, "belongs_to": {"file_name": "test_capture.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "      assert 0\n        \"\"\"\n        )\n        result = pytester.runpytest(p)\n        result.stdout.fnmatch_lines(\n            [\n                \"setup module*\",\n                \"setup test_func1*\",\n                \"in func1*\",\n                \"setup test_func2*\",\n                \"in func2*\",\n            ]\n        )\n\n    @pytest.mark.xfail(reason=\"unimplemented feature\")\n    def test_capture_scope_cache(self, pytester: Pytester) -> None:\n        p = pytester.makepyfile(\n            \"\"\"\n            import sys\n            def setup_module(func):\n                print(\"module-setup\")\n            def setup_function(func):\n                print(\"function-setup\")\n            def test_func():\n                print(\"in function\")\n                assert 0\n            def teardown_function(func):\n                print(\"in teardown\")\n        \"\"\"\n        )\n        result = pytester.runpytest(p)\n        result.stdout.fnmatch_lines(\n            [\n                \"*test_func():*\",\n                \"*Captured stdout during setup*\",\n                \"module-setup*\",\n                \"function-setup*\",\n                \"*Captured stdout*\",\n                \"in teardown*\",\n            ]\n        )\n\n    def test_no_carry_over(self, pytester: Pytester) -> None:\n        p = pytester.makepyfile(\n            \"\"\"\n            def test_func1():\n                print(\"in func1\")\n            def test_func2():\n                print(\"in func2\")\n                assert 0\n        \"\"\"\n        )\n        result = pytester.runpytest(p)\n        s = result.stdout.str()\n        assert \"in func1\" not in s\n        assert \"in func2\" in s\n\n    def test_teardown_capturing(self, pytester: Pytester) -> None:\n        p = pytester.makepyfile(\n            \"\"\"\n            def setup_function(function):\n                print(\"setup func1\")\n            def teardown_function(function):\n                print(\"teardown func1\")\n                assert 0\n            def test_func1():\n                print(\"in func1\")\n                "}, {"start_line": 56000, "end_line": 58000, "belongs_to": {"file_name": "test_terminal.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "\n            \"\"\"\n            import logging\n            import sys\n            import pytest\n\n            @pytest.fixture(scope=\"function\", autouse=\"True\")\n            def hook_each_test(request):\n                yield\n                sys.stdout.write(\"!stdout!\")\n                sys.stderr.write(\"!stderr!\")\n                logging.warning(\"!log!\")\n\n            def test_func():\n                assert False\n        \"\"\"\n        )\n\n        result = pytester.runpytest(\"--show-capture=stdout\", \"--tb=short\").stdout.str()\n        assert \"!stdout!\" in result\n        assert \"!stderr!\" not in result\n        assert \"!log!\" not in result\n\n        result = pytester.runpytest(\"--show-capture=stderr\", \"--tb=short\").stdout.str()\n        assert \"!stdout!\" not in result\n        assert \"!stderr!\" in result\n        assert \"!log!\" not in result\n\n        result = pytester.runpytest(\"--show-capture=log\", \"--tb=short\").stdout.str()\n        assert \"!stdout!\" not in result\n        assert \"!stderr!\" not in result\n        assert \"!log!\" in result\n\n        result = pytester.runpytest(\"--show-capture=no\", \"--tb=short\").stdout.str()\n        assert \"!stdout!\" not in result\n        assert \"!stderr!\" not in result\n        assert \"!log!\" not in result\n\n\n@pytest.mark.xfail(\"not hasattr(os, 'dup')\")\ndef test_fdopen_kept_alive_issue124(pytester: Pytester) -> None:\n    pytester.makepyfile(\n        \"\"\"\n        import os, sys\n        k = []\n        def test_open_file_and_keep_alive(capfd):\n            stdout = os.fdopen(1, 'w', buffering=1, encoding='utf-8')\n            k.append(stdout)\n\n        def test_close_kept_alive_file():\n            stdout = k.pop()\n            stdout.close()\n    \"\"\"\n    )\n    result = pytester.runpytest()\n    result.stdout.fnmatch_lines([\"*2 passed*\"])\n\n\ndef test_tbstyle_native_setup_error(pytester: Pytester) -> None:\n    pytester.makepyfile(\n        \"\"\"\n        import pytest\n        @pytest.fixture\n        def setup_error_fixture():\n            raise Exception(\"error in exception\""}, {"start_line": 4000, "end_line": 6000, "belongs_to": {"file_name": "test_capture.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "fnmatch_lines([\"*1 passed*\"])\n\n\ndef test_collect_capturing(pytester: Pytester) -> None:\n    p = pytester.makepyfile(\n        \"\"\"\n        import sys\n\n        print(\"collect %s failure\" % 13)\n        sys.stderr.write(\"collect %s_stderr failure\" % 13)\n        import xyz42123\n    \"\"\"\n    )\n    result = pytester.runpytest(p)\n    result.stdout.fnmatch_lines(\n        [\n            \"*Captured stdout*\",\n            \"collect 13 failure\",\n            \"*Captured stderr*\",\n            \"collect 13_stderr failure\",\n        ]\n    )\n\n\nclass TestPerTestCapturing:\n    def test_capture_and_fixtures(self, pytester: Pytester) -> None:\n        p = pytester.makepyfile(\n            \"\"\"\n            def setup_module(mod):\n                print(\"setup module\")\n            def setup_function(function):\n                print(\"setup \" + function.__name__)\n            def test_func1():\n                print(\"in func1\")\n                assert 0\n            def test_func2():\n                print(\"in func2\")\n                assert 0\n        \"\"\"\n        )\n        result = pytester.runpytest(p)\n        result.stdout.fnmatch_lines(\n            [\n                \"setup module*\",\n                \"setup test_func1*\",\n                \"in func1*\",\n                \"setup test_func2*\",\n                \"in func2*\",\n            ]\n        )\n\n    @pytest.mark.xfail(reason=\"unimplemented feature\")\n    def test_capture_scope_cache(self, pytester: Pytester) -> None:\n        p = pytester.makepyfile(\n            \"\"\"\n            import sys\n            def setup_module(func):\n                print(\"module-setup\")\n            def setup_function(func):\n                print(\"function-setup\")\n            def test_func():\n                print(\"in function\")\n                assert 0\n            def teardown_function(func):\n                print(\"in teardown\")\n        \"\"\"\n        )\n        result = pytester.runpytest(p)\n        result.stdout.fnmatch_lines(\n            [\n                \"*test_func():*\",\n                \"*Cap"}, {"start_line": 6000, "end_line": 8000, "belongs_to": {"file_name": "test_capture.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "tured stdout during setup*\",\n                \"module-setup*\",\n                \"function-setup*\",\n                \"*Captured stdout*\",\n                \"in teardown*\",\n            ]\n        )\n\n    def test_no_carry_over(self, pytester: Pytester) -> None:\n        p = pytester.makepyfile(\n            \"\"\"\n            def test_func1():\n                print(\"in func1\")\n            def test_func2():\n                print(\"in func2\")\n                assert 0\n        \"\"\"\n        )\n        result = pytester.runpytest(p)\n        s = result.stdout.str()\n        assert \"in func1\" not in s\n        assert \"in func2\" in s\n\n    def test_teardown_capturing(self, pytester: Pytester) -> None:\n        p = pytester.makepyfile(\n            \"\"\"\n            def setup_function(function):\n                print(\"setup func1\")\n            def teardown_function(function):\n                print(\"teardown func1\")\n                assert 0\n            def test_func1():\n                print(\"in func1\")\n                pass\n        \"\"\"\n        )\n        result = pytester.runpytest(p)\n        result.stdout.fnmatch_lines(\n            [\n                \"*teardown_function*\",\n                \"*Captured stdout*\",\n                \"setup func1*\",\n                \"in func1*\",\n                \"teardown func1*\",\n                # \"*1 fixture failure*\"\n            ]\n        )\n\n    def test_teardown_capturing_final(self, pytester: Pytester) -> None:\n        p = pytester.makepyfile(\n            \"\"\"\n            def teardown_module(mod):\n                print(\"teardown module\")\n                assert 0\n            def test_func():\n                pass\n        \"\"\"\n        )\n        result = pytester.runpytest(p)\n        result.stdout.fnmatch_lines(\n            [\n                \"*def teardown_module(mod):*\",\n                \"*Captured stdout*\",\n                \"*teardown module*\",\n                \"*1 error*\",\n            ]\n        )\n\n    def test_capturing_outerr(self, pytester: Pytester) -> None:\n        p1 = pytes"}, {"start_line": 22000, "end_line": 24000, "belongs_to": {"file_name": "test_capture.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "tch_line(\"*captured after*\")\n        if no_capture:\n            assert \"test_normal executed\" in result.stdout.str()\n        else:\n            result.stdout.no_fnmatch_line(\"*test_normal executed*\")\n\n    def test_disabled_capture_fixture_twice(self, pytester: Pytester) -> None:\n        \"\"\"Test that an inner disabled() exit doesn't undo an outer disabled().\n\n        Issue #7148.\n        \"\"\"\n        pytester.makepyfile(\n            \"\"\"\n            def test_disabled(capfd):\n                print('captured before')\n                with capfd.disabled():\n                    print('while capture is disabled 1')\n                    with capfd.disabled():\n                        print('while capture is disabled 2')\n                    print('while capture is disabled 1 after')\n                print('captured after')\n                assert capfd.readouterr() == ('captured before\\\\ncaptured after\\\\n', '')\n        \"\"\"\n        )\n        result = pytester.runpytest_subprocess()\n        result.stdout.fnmatch_lines(\n            [\n                \"*while capture is disabled 1\",\n                \"*while capture is disabled 2\",\n                \"*while capture is disabled 1 after\",\n            ],\n            consecutive=True,\n        )\n\n    @pytest.mark.parametrize(\"fixture\", [\"capsys\", \"capfd\"])\n    def test_fixture_use_by_other_fixtures(self, pytester: Pytester, fixture) -> None:\n        \"\"\"Ensure that capsys and capfd can be used by other fixtures during\n        setup and teardown.\"\"\"\n        pytester.makepyfile(\n            f\"\"\"\\\n            import sys\n            import pytest\n\n            @pytest.fixture\n            def captured_print({fixture}):\n                print('stdout contents begin')\n                print('stderr contents begin', file=sys.stderr)\n                out, err = {fixture}.readouterr()\n\n                yield out, err\n\n                print('stdout contents end')\n                print('stderr contents end', file=sys.stderr)\n                out, err = {fixture}.r"}, {"start_line": 27000, "end_line": 29000, "belongs_to": {"file_name": "capture.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "ture:\n                self.resume_fixture()\n\n    @contextlib.contextmanager\n    def item_capture(self, when: str, item: Item) -> Generator[None]:\n        self.resume_global_capture()\n        self.activate_fixture()\n        try:\n            yield\n        finally:\n            self.deactivate_fixture()\n            self.suspend_global_capture(in_=False)\n\n            out, err = self.read_global_capture()\n            item.add_report_section(when, \"stdout\", out)\n            item.add_report_section(when, \"stderr\", err)\n\n    # Hooks\n\n    @hookimpl(wrapper=True)\n    def pytest_make_collect_report(\n        self, collector: Collector\n    ) -> Generator[None, CollectReport, CollectReport]:\n        if isinstance(collector, File):\n            self.resume_global_capture()\n            try:\n                rep = yield\n            finally:\n                self.suspend_global_capture()\n            out, err = self.read_global_capture()\n            if out:\n                rep.sections.append((\"Captured stdout\", out))\n            if err:\n                rep.sections.append((\"Captured stderr\", err))\n        else:\n            rep = yield\n        return rep\n\n    @hookimpl(wrapper=True)\n    def pytest_runtest_setup(self, item: Item) -> Generator[None]:\n        with self.item_capture(\"setup\", item):\n            return (yield)\n\n    @hookimpl(wrapper=True)\n    def pytest_runtest_call(self, item: Item) -> Generator[None]:\n        with self.item_capture(\"call\", item):\n            return (yield)\n\n    @hookimpl(wrapper=True)\n    def pytest_runtest_teardown(self, item: Item) -> Generator[None]:\n        with self.item_capture(\"teardown\", item):\n            return (yield)\n\n    @hookimpl(tryfirst=True)\n    def pytest_keyboard_interrupt(self) -> None:\n        self.stop_global_capturing()\n\n    @hookimpl(tryfirst=True)\n    def pytest_internalerror(self) -> None:\n        self.stop_global_capturing()\n\n\nclass CaptureFixture(Generic[AnyStr]):\n    \"\"\"Object returned by the :fixture:`capsys`, :fixture:`capsysbin"}, {"start_line": 9000, "end_line": 11000, "belongs_to": {"file_name": "test_capture.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "               stream = capture.CaptureIO()\n                logging.basicConfig(stream=stream)\n                stream.close() # to free memory/release resources\n            \"\"\"\n        )\n        result = pytester.runpytest_subprocess(p)\n        assert result.stderr.str().find(\"atexit\") == -1\n\n    def test_logging_and_immediate_setupteardown(self, pytester: Pytester) -> None:\n        p = pytester.makepyfile(\n            \"\"\"\\\n            import logging\n            def setup_function(function):\n                logging.warning(\"hello1\")\n\n            def test_logging():\n                logging.warning(\"hello2\")\n                assert 0\n\n            def teardown_function(function):\n                logging.warning(\"hello3\")\n                assert 0\n            \"\"\"\n        )\n        for optargs in ((\"--capture=sys\",), (\"--capture=fd\",)):\n            print(optargs)\n            result = pytester.runpytest_subprocess(p, *optargs)\n            s = result.stdout.str()\n            result.stdout.fnmatch_lines(\n                [\"*WARN*hello3\", \"*WARN*hello1\", \"*WARN*hello2\"]  # errors show first!\n            )\n            # verify proper termination\n            assert \"closed\" not in s\n\n    def test_logging_and_crossscope_fixtures(self, pytester: Pytester) -> None:\n        p = pytester.makepyfile(\n            \"\"\"\\\n            import logging\n            def setup_module(function):\n                logging.warning(\"hello1\")\n\n            def test_logging():\n                logging.warning(\"hello2\")\n                assert 0\n\n            def teardown_module(function):\n                logging.warning(\"hello3\")\n                assert 0\n            \"\"\"\n        )\n        for optargs in ((\"--capture=sys\",), (\"--capture=fd\",)):\n            print(optargs)\n            result = pytester.runpytest_subprocess(p, *optargs)\n            s = result.stdout.str()\n            result.stdout.fnmatch_lines(\n                [\"*WARN*hello3\", \"*WARN*hello1\", \"*WARN*hello2\"]  # errors come first\n            )\n   "}, {"start_line": 6000, "end_line": 8000, "belongs_to": {"file_name": "test_setuponly.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "capturing(pytester: Pytester) -> None:\n    p = pytester.makepyfile(\n        \"\"\"\n        import pytest, sys\n        @pytest.fixture()\n        def one():\n            sys.stdout.write('this should be captured')\n            sys.stderr.write('this should also be captured')\n        @pytest.fixture()\n        def two(one):\n            assert 0\n        def test_capturing(two):\n            pass\n    \"\"\"\n    )\n\n    result = pytester.runpytest(\"--setup-only\", p)\n    result.stdout.fnmatch_lines(\n        [\"this should be captured\", \"this should also be captured\"]\n    )\n\n\ndef test_show_fixtures_and_execute_test(pytester: Pytester) -> None:\n    \"\"\"Verify that setups are shown and tests are executed.\"\"\"\n    p = pytester.makepyfile(\n        \"\"\"\n        import pytest\n        @pytest.fixture\n        def arg():\n            assert True\n        def test_arg(arg):\n            assert False\n    \"\"\"\n    )\n\n    result = pytester.runpytest(\"--setup-show\", p)\n    assert result.ret == 1\n\n    result.stdout.fnmatch_lines(\n        [\"*SETUP    F arg*\", \"*test_arg (fixtures used: arg)F*\", \"*TEARDOWN F arg*\"]\n    )\n\n\ndef test_setup_show_with_KeyboardInterrupt_in_test(pytester: Pytester) -> None:\n    p = pytester.makepyfile(\n        \"\"\"\n        import pytest\n        @pytest.fixture\n        def arg():\n            pass\n        def test_arg(arg):\n            raise KeyboardInterrupt()\n    \"\"\"\n    )\n    result = pytester.runpytest(\"--setup-show\", p, no_reraise_ctrlc=True)\n    result.stdout.fnmatch_lines(\n        [\n            \"*SETUP    F arg*\",\n            \"*test_arg (fixtures used: arg)*\",\n            \"*TEARDOWN F arg*\",\n            \"*! KeyboardInterrupt !*\",\n            \"*= no tests ran in *\",\n        ]\n    )\n    assert result.ret == ExitCode.INTERRUPTED\n\n\ndef test_show_fixture_action_with_bytes(pytester: Pytester) -> None:\n    # Issue 7126, BytesWarning when using --setup-show with bytes parameter\n    test_file = pytester.makepyfile(\n        \"\"\"\n        import pytest\n\n        @pytest.mark.parametrize('dat"}], "retrieved_count": 10, "cost_time": 1.1560614109039307}
{"question": "What is the failure mechanism when the parametrize method's validation of indirect parameter names detects that an indirect parameter references a non-existent function argument, and how does this depend on the function signature?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"start_line": 55000, "end_line": 57000, "belongs_to": {"file_name": "python.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "`` parameter of the\n        parametrized() call.\n\n        :param argnames:\n            List of argument names passed to ``parametrize()``.\n        :param indirect:\n            Same as the ``indirect`` parameter of ``parametrize()``.\n        :returns\n            A dict mapping each arg name to either \"indirect\" or \"direct\".\n        \"\"\"\n        arg_directness: dict[str, Literal[\"indirect\", \"direct\"]]\n        if isinstance(indirect, bool):\n            arg_directness = dict.fromkeys(\n                argnames, \"indirect\" if indirect else \"direct\"\n            )\n        elif isinstance(indirect, Sequence):\n            arg_directness = dict.fromkeys(argnames, \"direct\")\n            for arg in indirect:\n                if arg not in argnames:\n                    fail(\n                        f\"In {self.function.__name__}: indirect fixture '{arg}' doesn't exist\",\n                        pytrace=False,\n                    )\n                arg_directness[arg] = \"indirect\"\n        else:\n            fail(\n                f\"In {self.function.__name__}: expected Sequence or boolean\"\n                f\" for indirect, got {type(indirect).__name__}\",\n                pytrace=False,\n            )\n        return arg_directness\n\n    def _validate_if_using_arg_names(\n        self,\n        argnames: Sequence[str],\n        indirect: bool | Sequence[str],\n    ) -> None:\n        \"\"\"Check if all argnames are being used, by default values, or directly/indirectly.\n\n        :param List[str] argnames: List of argument names passed to ``parametrize()``.\n        :param indirect: Same as the ``indirect`` parameter of ``parametrize()``.\n        :raises ValueError: If validation fails.\n        \"\"\"\n        default_arg_names = set(get_default_arg_names(self.function))\n        func_name = self.function.__name__\n        for arg in argnames:\n            if arg not in self.fixturenames:\n                if arg in default_arg_names:\n                    fail(\n                        f\"In {func_name}: function alr"}, {"start_line": 56000, "end_line": 58000, "belongs_to": {"file_name": "python.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": " fail(\n                f\"In {self.function.__name__}: expected Sequence or boolean\"\n                f\" for indirect, got {type(indirect).__name__}\",\n                pytrace=False,\n            )\n        return arg_directness\n\n    def _validate_if_using_arg_names(\n        self,\n        argnames: Sequence[str],\n        indirect: bool | Sequence[str],\n    ) -> None:\n        \"\"\"Check if all argnames are being used, by default values, or directly/indirectly.\n\n        :param List[str] argnames: List of argument names passed to ``parametrize()``.\n        :param indirect: Same as the ``indirect`` parameter of ``parametrize()``.\n        :raises ValueError: If validation fails.\n        \"\"\"\n        default_arg_names = set(get_default_arg_names(self.function))\n        func_name = self.function.__name__\n        for arg in argnames:\n            if arg not in self.fixturenames:\n                if arg in default_arg_names:\n                    fail(\n                        f\"In {func_name}: function already takes an argument '{arg}' with a default value\",\n                        pytrace=False,\n                    )\n                else:\n                    if isinstance(indirect, Sequence):\n                        name = \"fixture\" if arg in indirect else \"argument\"\n                    else:\n                        name = \"fixture\" if indirect else \"argument\"\n                    fail(\n                        f\"In {func_name}: function uses no {name} '{arg}'\",\n                        pytrace=False,\n                    )\n\n    def _recompute_direct_params_indices(self) -> None:\n        for argname, param_type in self._params_directness.items():\n            if param_type == \"direct\":\n                for i, callspec in enumerate(self._calls):\n                    callspec.indices[argname] = i\n\n\ndef _find_parametrized_scope(\n    argnames: Sequence[str],\n    arg2fixturedefs: Mapping[str, Sequence[fixtures.FixtureDef[object]]],\n    indirect: bool | Sequence[str],\n) -> Scope:\n    \"\"\"Find the mo"}, {"start_line": 32000, "end_line": 34000, "belongs_to": {"file_name": "metafunc.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing/python", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "   \"\"\"\n            import pytest\n\n            @pytest.mark.parametrize('x, y', [('a', 'b')])\n            def test_simple(x, y=1):\n                assert len(x) == 1\n        \"\"\"\n        )\n        result = pytester.runpytest(\"--collect-only\")\n        result.stdout.fnmatch_lines(\n            [\"*already takes an argument 'y' with a default value\"]\n        )\n\n    def test_parametrize_functional(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n            def pytest_generate_tests(metafunc):\n                metafunc.parametrize('x', [1,2], indirect=True)\n                metafunc.parametrize('y', [2])\n            @pytest.fixture\n            def x(request):\n                return request.param * 10\n\n            def test_simple(x,y):\n                assert x in (10,20)\n                assert y == 2\n        \"\"\"\n        )\n        result = pytester.runpytest(\"-v\")\n        result.stdout.fnmatch_lines(\n            [\"*test_simple*1-2*\", \"*test_simple*2-2*\", \"*2 passed*\"]\n        )\n\n    def test_parametrize_onearg(self) -> None:\n        metafunc = self.Metafunc(lambda x: None)\n        metafunc.parametrize(\"x\", [1, 2])\n        assert len(metafunc._calls) == 2\n        assert metafunc._calls[0].params == dict(x=1)\n        assert metafunc._calls[0].id == \"1\"\n        assert metafunc._calls[1].params == dict(x=2)\n        assert metafunc._calls[1].id == \"2\"\n\n    def test_parametrize_onearg_indirect(self) -> None:\n        metafunc = self.Metafunc(lambda x: None)\n        metafunc.parametrize(\"x\", [1, 2], indirect=True)\n        assert metafunc._calls[0].params == dict(x=1)\n        assert metafunc._calls[0].id == \"1\"\n        assert metafunc._calls[1].params == dict(x=2)\n        assert metafunc._calls[1].id == \"2\"\n\n    def test_parametrize_twoargs(self) -> None:\n        metafunc = self.Metafunc(lambda x, y: None)\n        metafunc.parametrize((\"x\", \"y\"), [(1, 2), (3, 4)])\n        assert len(metafunc._calls) == 2\n        assert metafunc._c"}, {"start_line": 45000, "end_line": 47000, "belongs_to": {"file_name": "python.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "            unparametrized:         t\n            parametrize [\"x\", \"y\"]: t[x], t[y]\n            parametrize [1, 2]:     t[x-1], t[x-2], t[y-1], t[y-2]\n\n        :param argnames:\n            A comma-separated string denoting one or more argument names, or\n            a list/tuple of argument strings.\n\n        :param argvalues:\n            The list of argvalues determines how often a test is invoked with\n            different argument values.\n\n            If only one argname was specified argvalues is a list of values.\n            If N argnames were specified, argvalues must be a list of\n            N-tuples, where each tuple-element specifies a value for its\n            respective argname.\n\n        :param indirect:\n            A list of arguments' names (subset of argnames) or a boolean.\n            If True the list contains all names from the argnames. Each\n            argvalue corresponding to an argname in this list will\n            be passed as request.param to its respective argname fixture\n            function so that it can perform more expensive setups during the\n            setup phase of a test rather than at collection time.\n\n        :param ids:\n            Sequence of (or generator for) ids for ``argvalues``,\n            or a callable to return part of the id for each argvalue.\n\n            With sequences (and generators like ``itertools.count()``) the\n            returned ids should be of type ``string``, ``int``, ``float``,\n            ``bool``, or ``None``.\n            They are mapped to the corresponding index in ``argvalues``.\n            ``None`` means to use the auto-generated id.\n\n            .. versionadded:: 8.4\n                :ref:`hidden-param` means to hide the parameter set\n                from the test name. Can only be used at most 1 time, as\n                test names need to be unique.\n\n            If it is a callable it will be called for each entry in\n            ``argvalues``, and the return value is used as part of the\n            a"}, {"start_line": 31000, "end_line": 33000, "belongs_to": {"file_name": "metafunc.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing/python", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": " [('a', 'b')], indirect=['y'])\n            def test_simple(x):\n                assert len(x) == 3\n        \"\"\"\n        )\n        result = pytester.runpytest(\"--collect-only\")\n        result.stdout.fnmatch_lines([\"*uses no fixture 'y'*\"])\n\n    def test_parametrize_argument_not_in_indirect_list(\n        self, pytester: Pytester\n    ) -> None:\n        \"\"\"#714\"\"\"\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n            @pytest.fixture(scope='function')\n            def x(request):\n                return request.param * 3\n\n            @pytest.mark.parametrize('x, y', [('a', 'b')], indirect=['x'])\n            def test_simple(x):\n                assert len(x) == 3\n        \"\"\"\n        )\n        result = pytester.runpytest(\"--collect-only\")\n        result.stdout.fnmatch_lines([\"*uses no argument 'y'*\"])\n\n    def test_parametrize_gives_indicative_error_on_function_with_default_argument(\n        self, pytester: Pytester\n    ) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n\n            @pytest.mark.parametrize('x, y', [('a', 'b')])\n            def test_simple(x, y=1):\n                assert len(x) == 1\n        \"\"\"\n        )\n        result = pytester.runpytest(\"--collect-only\")\n        result.stdout.fnmatch_lines(\n            [\"*already takes an argument 'y' with a default value\"]\n        )\n\n    def test_parametrize_functional(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n            def pytest_generate_tests(metafunc):\n                metafunc.parametrize('x', [1,2], indirect=True)\n                metafunc.parametrize('y', [2])\n            @pytest.fixture\n            def x(request):\n                return request.param * 10\n\n            def test_simple(x,y):\n                assert x in (10,20)\n                assert y == 2\n        \"\"\"\n        )\n        result = pytester.runpytest(\"-v\")\n        result.stdout.fnmatch_lines(\n            [\"*test_simple*1-2*\", \"*test_"}, {"start_line": 54000, "end_line": 56000, "belongs_to": {"file_name": "python.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "re[arg-type]\n        except TypeError:\n            try:\n                iter(ids)\n            except TypeError as e:\n                raise TypeError(\"ids must be a callable or an iterable\") from e\n            num_ids = len(parametersets)\n\n        # num_ids == 0 is a special case: https://github.com/pytest-dev/pytest/issues/1849\n        if num_ids != len(parametersets) and num_ids != 0:\n            msg = \"In {}: {} parameter sets specified, with different number of ids: {}\"\n            fail(msg.format(func_name, len(parametersets), num_ids), pytrace=False)\n\n        return list(itertools.islice(ids, num_ids))\n\n    def _resolve_args_directness(\n        self,\n        argnames: Sequence[str],\n        indirect: bool | Sequence[str],\n    ) -> dict[str, Literal[\"indirect\", \"direct\"]]:\n        \"\"\"Resolve if each parametrized argument must be considered an indirect\n        parameter to a fixture of the same name, or a direct parameter to the\n        parametrized function, based on the ``indirect`` parameter of the\n        parametrized() call.\n\n        :param argnames:\n            List of argument names passed to ``parametrize()``.\n        :param indirect:\n            Same as the ``indirect`` parameter of ``parametrize()``.\n        :returns\n            A dict mapping each arg name to either \"indirect\" or \"direct\".\n        \"\"\"\n        arg_directness: dict[str, Literal[\"indirect\", \"direct\"]]\n        if isinstance(indirect, bool):\n            arg_directness = dict.fromkeys(\n                argnames, \"indirect\" if indirect else \"direct\"\n            )\n        elif isinstance(indirect, Sequence):\n            arg_directness = dict.fromkeys(argnames, \"direct\")\n            for arg in indirect:\n                if arg not in argnames:\n                    fail(\n                        f\"In {self.function.__name__}: indirect fixture '{arg}' doesn't exist\",\n                        pytrace=False,\n                    )\n                arg_directness[arg] = \"indirect\"\n        else:\n           "}, {"start_line": 44000, "end_line": 46000, "belongs_to": {"file_name": "python.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "_calls: list[CallSpec2] = []\n\n        self._params_directness: dict[str, Literal[\"indirect\", \"direct\"]] = {}\n\n    def parametrize(\n        self,\n        argnames: str | Sequence[str],\n        argvalues: Iterable[ParameterSet | Sequence[object] | object],\n        indirect: bool | Sequence[str] = False,\n        ids: Iterable[object | None] | Callable[[Any], object | None] | None = None,\n        scope: _ScopeName | None = None,\n        *,\n        _param_mark: Mark | None = None,\n    ) -> None:\n        \"\"\"Add new invocations to the underlying test function using the list\n        of argvalues for the given argnames. Parametrization is performed\n        during the collection phase. If you need to setup expensive resources\n        see about setting ``indirect`` to do it at test setup time instead.\n\n        Can be called multiple times per test function (but only on different\n        argument names), in which case each call parametrizes all previous\n        parametrizations, e.g.\n\n        ::\n\n            unparametrized:         t\n            parametrize [\"x\", \"y\"]: t[x], t[y]\n            parametrize [1, 2]:     t[x-1], t[x-2], t[y-1], t[y-2]\n\n        :param argnames:\n            A comma-separated string denoting one or more argument names, or\n            a list/tuple of argument strings.\n\n        :param argvalues:\n            The list of argvalues determines how often a test is invoked with\n            different argument values.\n\n            If only one argname was specified argvalues is a list of values.\n            If N argnames were specified, argvalues must be a list of\n            N-tuples, where each tuple-element specifies a value for its\n            respective argname.\n\n        :param indirect:\n            A list of arguments' names (subset of argnames) or a boolean.\n            If True the list contains all names from the argnames. Each\n            argvalue corresponding to an argname in this list will\n            be passed as request.param to its respective argnam"}, {"start_line": 3000, "end_line": 5000, "belongs_to": {"file_name": "metafunc.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing/python", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "ust be a callable or an iterable$\"):\n            metafunc.parametrize(\"y\", [5, 6], ids=42)  # type: ignore[arg-type]\n\n    def test_parametrize_error_iterator(self) -> None:\n        def func(x):\n            raise NotImplementedError()\n\n        class Exc(Exception):\n            def __repr__(self):\n                return \"Exc(from_gen)\"\n\n        def gen() -> Iterator[int | None | Exc]:\n            yield 0\n            yield None\n            yield Exc()\n\n        metafunc = self.Metafunc(func)\n        # When the input is an iterator, only len(args) are taken,\n        # so the bad Exc isn't reached.\n        metafunc.parametrize(\"x\", [1, 2], ids=gen())\n        assert [(x.params, x.id) for x in metafunc._calls] == [\n            ({\"x\": 1}, \"0\"),\n            ({\"x\": 2}, \"2\"),\n        ]\n        with pytest.raises(\n            fail.Exception,\n            match=(\n                r\"In func: ids contains unsupported value Exc\\(from_gen\\) \\(type: <class .*Exc'>\\) at index 2. \"\n                r\"Supported types are: .*\"\n            ),\n        ):\n            metafunc.parametrize(\"x\", [1, 2, 3], ids=gen())\n\n    def test_parametrize_bad_scope(self) -> None:\n        def func(x):\n            pass\n\n        metafunc = self.Metafunc(func)\n        with pytest.raises(\n            fail.Exception,\n            match=r\"parametrize\\(\\) call in func got an unexpected scope value 'doggy'\",\n        ):\n            metafunc.parametrize(\"x\", [1], scope=\"doggy\")  # type: ignore[arg-type]\n\n    def test_parametrize_request_name(self, pytester: Pytester) -> None:\n        \"\"\"Show proper error  when 'request' is used as a parameter name in parametrize (#6183)\"\"\"\n\n        def func(request):\n            raise NotImplementedError()\n\n        metafunc = self.Metafunc(func)\n        with pytest.raises(\n            fail.Exception,\n            match=r\"'request' is a reserved name and cannot be used in @pytest.mark.parametrize\",\n        ):\n            metafunc.parametrize(\"request\", [1])\n\n    def test_find_parametrized_s"}, {"start_line": 4000, "end_line": 6000, "belongs_to": {"file_name": "metafunc.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing/python", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "d types are: .*\"\n            ),\n        ):\n            metafunc.parametrize(\"x\", [1, 2, 3], ids=gen())\n\n    def test_parametrize_bad_scope(self) -> None:\n        def func(x):\n            pass\n\n        metafunc = self.Metafunc(func)\n        with pytest.raises(\n            fail.Exception,\n            match=r\"parametrize\\(\\) call in func got an unexpected scope value 'doggy'\",\n        ):\n            metafunc.parametrize(\"x\", [1], scope=\"doggy\")  # type: ignore[arg-type]\n\n    def test_parametrize_request_name(self, pytester: Pytester) -> None:\n        \"\"\"Show proper error  when 'request' is used as a parameter name in parametrize (#6183)\"\"\"\n\n        def func(request):\n            raise NotImplementedError()\n\n        metafunc = self.Metafunc(func)\n        with pytest.raises(\n            fail.Exception,\n            match=r\"'request' is a reserved name and cannot be used in @pytest.mark.parametrize\",\n        ):\n            metafunc.parametrize(\"request\", [1])\n\n    def test_find_parametrized_scope(self) -> None:\n        \"\"\"Unit test for _find_parametrized_scope (#3941).\"\"\"\n        from _pytest.python import _find_parametrized_scope\n\n        @dataclasses.dataclass\n        class DummyFixtureDef:\n            _scope: Scope\n\n        fixtures_defs = cast(\n            dict[str, Sequence[fixtures.FixtureDef[object]]],\n            dict(\n                session_fix=[DummyFixtureDef(Scope.Session)],\n                package_fix=[DummyFixtureDef(Scope.Package)],\n                module_fix=[DummyFixtureDef(Scope.Module)],\n                class_fix=[DummyFixtureDef(Scope.Class)],\n                func_fix=[DummyFixtureDef(Scope.Function)],\n                mixed_fix=[DummyFixtureDef(Scope.Module), DummyFixtureDef(Scope.Class)],\n            ),\n        )\n\n        # use arguments to determine narrow scope; the cause of the bug is that it would look on all\n        # fixture defs given to the method\n        def find_scope(argnames, indirect):\n            return _find_parametrized_scope(argnames,"}, {"start_line": 48000, "end_line": 50000, "belongs_to": {"file_name": "python.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "\n                f\"{nodeid}: 'request' is a reserved name and cannot be used in @pytest.mark.parametrize\",\n                pytrace=False,\n            )\n\n        if scope is not None:\n            scope_ = Scope.from_user(\n                scope, descr=f\"parametrize() call in {self.function.__name__}\"\n            )\n        else:\n            scope_ = _find_parametrized_scope(argnames, self._arg2fixturedefs, indirect)\n\n        self._validate_if_using_arg_names(argnames, indirect)\n\n        # Use any already (possibly) generated ids with parametrize Marks.\n        if _param_mark and _param_mark._param_ids_from:\n            generated_ids = _param_mark._param_ids_from._param_ids_generated\n            if generated_ids is not None:\n                ids = generated_ids\n\n        ids = self._resolve_parameter_set_ids(\n            argnames, ids, parametersets, nodeid=self.definition.nodeid\n        )\n\n        # Store used (possibly generated) ids with parametrize Marks.\n        if _param_mark and _param_mark._param_ids_from and generated_ids is None:\n            object.__setattr__(_param_mark._param_ids_from, \"_param_ids_generated\", ids)\n\n        # Calculate directness.\n        arg_directness = self._resolve_args_directness(argnames, indirect)\n        self._params_directness.update(arg_directness)\n\n        # Add direct parametrizations as fixturedefs to arg2fixturedefs by\n        # registering artificial \"pseudo\" FixtureDef's such that later at test\n        # setup time we can rely on FixtureDefs to exist for all argnames.\n        node = None\n        # For scopes higher than function, a \"pseudo\" FixtureDef might have\n        # already been created for the scope. We thus store and cache the\n        # FixtureDef on the node related to the scope.\n        if scope_ is Scope.Function:\n            name2pseudofixturedef = None\n        else:\n            collector = self.definition.parent\n            assert collector is not None\n            node = get_scope_node(collector, scope_)\n          "}], "retrieved_count": 10, "cost_time": 1.1707038879394531}
{"question": "How does the import_path API framework resolve module identity and ensure module caching consistency when the same file path is imported multiple times through different sys.path configurations?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"start_line": 10000, "end_line": 12000, "belongs_to": {"file_name": "test_pathlib.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": " it\"\n\n    def test_import_after(self, tmp_path: Path, ns_param: bool) -> None:\n        tmp_path.joinpath(\"xxxpackage\").mkdir()\n        tmp_path.joinpath(\"xxxpackage\", \"__init__.py\").touch()\n        mod1path = tmp_path.joinpath(\"xxxpackage\", \"module1.py\")\n        mod1path.touch()\n        mod1 = import_path(\n            mod1path, root=tmp_path, consider_namespace_packages=ns_param\n        )\n        assert mod1.__name__ == \"xxxpackage.module1\"\n        from xxxpackage import module1\n\n        assert module1 is mod1\n\n    def test_check_filepath_consistency(\n        self, monkeypatch: MonkeyPatch, tmp_path: Path, ns_param: bool\n    ) -> None:\n        name = \"pointsback123\"\n        p = tmp_path.joinpath(name + \".py\")\n        p.touch()\n        with monkeypatch.context() as mp:\n            for ending in (\".pyc\", \".pyo\"):\n                mod = ModuleType(name)\n                pseudopath = tmp_path.joinpath(name + ending)\n                pseudopath.touch()\n                mod.__file__ = str(pseudopath)\n                mp.setitem(sys.modules, name, mod)\n                newmod = import_path(\n                    p, root=tmp_path, consider_namespace_packages=ns_param\n                )\n                assert mod == newmod\n        mod = ModuleType(name)\n        pseudopath = tmp_path.joinpath(name + \"123.py\")\n        pseudopath.touch()\n        mod.__file__ = str(pseudopath)\n        monkeypatch.setitem(sys.modules, name, mod)\n        with pytest.raises(ImportPathMismatchError) as excinfo:\n            import_path(p, root=tmp_path, consider_namespace_packages=ns_param)\n        modname, modfile, orig = excinfo.value.args\n        assert modname == name\n        assert modfile == str(pseudopath)\n        assert orig == p\n        assert issubclass(ImportPathMismatchError, ImportError)\n\n    def test_ensuresyspath_append(self, tmp_path: Path, ns_param: bool) -> None:\n        root1 = tmp_path / \"root1\"\n        root1.mkdir()\n        file1 = root1 / \"x123.py\"\n        file1.touch()\n        assert st"}, {"start_line": 11000, "end_line": 13000, "belongs_to": {"file_name": "test_pathlib.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "path)\n                mp.setitem(sys.modules, name, mod)\n                newmod = import_path(\n                    p, root=tmp_path, consider_namespace_packages=ns_param\n                )\n                assert mod == newmod\n        mod = ModuleType(name)\n        pseudopath = tmp_path.joinpath(name + \"123.py\")\n        pseudopath.touch()\n        mod.__file__ = str(pseudopath)\n        monkeypatch.setitem(sys.modules, name, mod)\n        with pytest.raises(ImportPathMismatchError) as excinfo:\n            import_path(p, root=tmp_path, consider_namespace_packages=ns_param)\n        modname, modfile, orig = excinfo.value.args\n        assert modname == name\n        assert modfile == str(pseudopath)\n        assert orig == p\n        assert issubclass(ImportPathMismatchError, ImportError)\n\n    def test_ensuresyspath_append(self, tmp_path: Path, ns_param: bool) -> None:\n        root1 = tmp_path / \"root1\"\n        root1.mkdir()\n        file1 = root1 / \"x123.py\"\n        file1.touch()\n        assert str(root1) not in sys.path\n        import_path(\n            file1, mode=\"append\", root=tmp_path, consider_namespace_packages=ns_param\n        )\n        assert str(root1) == sys.path[-1]\n        assert str(root1) not in sys.path[:-1]\n\n    def test_invalid_path(self, tmp_path: Path, ns_param: bool) -> None:\n        with pytest.raises(ImportError):\n            import_path(\n                tmp_path / \"invalid.py\",\n                root=tmp_path,\n                consider_namespace_packages=ns_param,\n            )\n\n    @pytest.fixture\n    def simple_module(\n        self, tmp_path: Path, request: pytest.FixtureRequest\n    ) -> Iterator[Path]:\n        name = f\"mymod_{request.node.name}\"\n        fn = tmp_path / f\"_src/tests/{name}.py\"\n        fn.parent.mkdir(parents=True)\n        fn.write_text(\"def foo(x): return 40 + x\", encoding=\"utf-8\")\n        module_name = module_name_from_path(fn, root=tmp_path)\n        yield fn\n        sys.modules.pop(module_name, None)\n\n    def test_importmode_importlib(\n "}, {"start_line": 41000, "end_line": 43000, "belongs_to": {"file_name": "test_pathlib.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "  \"./.tests\",\n        )\n        result.stdout.fnmatch_lines(\n            [\n                f\"{core_py.relative_to(pytester.path)} . *\",\n                f\"{test_path1.relative_to(pytester.path)} . *\",\n                f\"{test_path2.relative_to(pytester.path)} . *\",\n                \"* 3 passed*\",\n            ]\n        )\n\n    def test_import_path_imports_correct_file(\n        self, pytester: Pytester, ns_param: bool\n    ) -> None:\n        \"\"\"\n        Import the module by the given path, even if other module with the same name\n        is reachable from sys.path.\n        \"\"\"\n        pytester.syspathinsert()\n        # Create a 'x.py' module reachable from sys.path that raises AssertionError\n        # if imported.\n        x_at_root = pytester.path / \"x.py\"\n        x_at_root.write_text(\"raise AssertionError('x at root')\", encoding=\"ascii\")\n\n        # Create another x.py module, but in some subdirectories to ensure it is not\n        # accessible from sys.path.\n        x_in_sub_folder = pytester.path / \"a/b/x.py\"\n        x_in_sub_folder.parent.mkdir(parents=True)\n        x_in_sub_folder.write_text(\"X = 'a/b/x'\", encoding=\"ascii\")\n\n        # Import our x.py module from the subdirectories.\n        # The 'x.py' module from sys.path was not imported for sure because\n        # otherwise we would get an AssertionError.\n        mod = import_path(\n            x_in_sub_folder,\n            mode=ImportMode.importlib,\n            root=pytester.path,\n            consider_namespace_packages=ns_param,\n        )\n        assert mod.__file__ and Path(mod.__file__) == x_in_sub_folder\n        assert mod.X == \"a/b/x\"\n\n        mod2 = import_path(\n            x_in_sub_folder,\n            mode=ImportMode.importlib,\n            root=pytester.path,\n            consider_namespace_packages=ns_param,\n        )\n        assert mod is mod2\n\n        # Attempt to import root 'x.py'.\n        with pytest.raises(AssertionError, match=\"x at root\"):\n            _ = import_path(\n                x_at_root,\n          "}, {"start_line": 40000, "end_line": 42000, "belongs_to": {"file_name": "test_pathlib.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "t the same module again (#11475).\n        mod2 = import_path(\n            test_path2,\n            mode=\"importlib\",\n            root=pytester.path,\n            consider_namespace_packages=ns_param,\n        )\n        assert mod is mod2\n\n    def test_import_using_normal_mechanism_first_integration(\n        self, monkeypatch: MonkeyPatch, pytester: Pytester, ns_param: bool\n    ) -> None:\n        \"\"\"\n        Same test as above, but verify the behavior calling pytest.\n\n        We should not make this call in the same test as above, as the modules have already\n        been imported by separate import_path() calls.\n        \"\"\"\n        core_py, test_path1, test_path2 = self.create_installed_doctests_and_tests_dir(\n            pytester.path, monkeypatch\n        )\n        result = pytester.runpytest(\n            \"--import-mode=importlib\",\n            \"-o\",\n            f\"consider_namespace_packages={ns_param}\",\n            \"--doctest-modules\",\n            \"--pyargs\",\n            \"app\",\n            \"./.tests\",\n        )\n        result.stdout.fnmatch_lines(\n            [\n                f\"{core_py.relative_to(pytester.path)} . *\",\n                f\"{test_path1.relative_to(pytester.path)} . *\",\n                f\"{test_path2.relative_to(pytester.path)} . *\",\n                \"* 3 passed*\",\n            ]\n        )\n\n    def test_import_path_imports_correct_file(\n        self, pytester: Pytester, ns_param: bool\n    ) -> None:\n        \"\"\"\n        Import the module by the given path, even if other module with the same name\n        is reachable from sys.path.\n        \"\"\"\n        pytester.syspathinsert()\n        # Create a 'x.py' module reachable from sys.path that raises AssertionError\n        # if imported.\n        x_at_root = pytester.path / \"x.py\"\n        x_at_root.write_text(\"raise AssertionError('x at root')\", encoding=\"ascii\")\n\n        # Create another x.py module, but in some subdirectories to ensure it is not\n        # accessible from sys.path.\n        x_in_sub_folder = pytester."}, {"start_line": 36000, "end_line": 38000, "belongs_to": {"file_name": "test_local.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing/_py", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "e(name + \".py\")\n        with monkeypatch.context() as mp:\n            for ending in (\".pyc\", \"$py.class\", \".pyo\"):\n                mod = ModuleType(name)\n                pseudopath = tmpdir.ensure(name + ending)\n                mod.__file__ = str(pseudopath)\n                mp.setitem(sys.modules, name, mod)\n                newmod = p.pyimport()\n                assert mod == newmod\n        mod = ModuleType(name)\n        pseudopath = tmpdir.ensure(name + \"123.py\")\n        mod.__file__ = str(pseudopath)\n        monkeypatch.setitem(sys.modules, name, mod)\n        excinfo = pytest.raises(pseudopath.ImportMismatchError, p.pyimport)\n        modname, modfile, orig = excinfo.value.args\n        assert modname == name\n        assert modfile == pseudopath\n        assert orig == p\n        assert issubclass(pseudopath.ImportMismatchError, ImportError)\n\n    def test_issue131_pyimport_on__init__(self, tmpdir):\n        # __init__.py files may be namespace packages, and thus the\n        # __file__ of an imported module may not be ourselves\n        # see issue\n        p1 = tmpdir.ensure(\"proja\", \"__init__.py\")\n        p2 = tmpdir.ensure(\"sub\", \"proja\", \"__init__.py\")\n        m1 = p1.pyimport()\n        m2 = p2.pyimport()\n        assert m1 == m2\n\n    def test_ensuresyspath_append(self, tmpdir):\n        root1 = tmpdir.mkdir(\"root1\")\n        file1 = root1.ensure(\"x123.py\")\n        assert str(root1) not in sys.path\n        file1.pyimport(ensuresyspath=\"append\")\n        assert str(root1) == sys.path[-1]\n        assert str(root1) not in sys.path[:-1]\n\n\nclass TestImportlibImport:\n    OPTS = {\"ensuresyspath\": \"importlib\"}\n\n    def test_pyimport(self, path1):\n        obj = path1.join(\"execfile.py\").pyimport(**self.OPTS)\n        assert obj.x == 42\n        assert obj.__name__ == \"execfile\"\n\n    def test_pyimport_dir_fails(self, tmpdir):\n        p = tmpdir.join(\"hello_123\")\n        p.ensure(\"__init__.py\")\n        with pytest.raises(ImportError):\n            p.pyimport(**self.OPTS)\n\n    def test_p"}, {"start_line": 38000, "end_line": 40000, "belongs_to": {"file_name": "test_pathlib.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": " -> None:\n        \"\"\"\n        Test import_path imports from the canonical location when possible first, only\n        falling back to its normal flow when the module being imported is not reachable via sys.path (#11475).\n        \"\"\"\n        core_py, test_path1, test_path2 = self.create_installed_doctests_and_tests_dir(\n            pytester.path, monkeypatch\n        )\n\n        # core_py is reached from sys.path, so should be imported normally.\n        mod = import_path(\n            core_py,\n            mode=\"importlib\",\n            root=pytester.path,\n            consider_namespace_packages=ns_param,\n        )\n        assert mod.__name__ == \"app.core\"\n        assert mod.__file__ and Path(mod.__file__) == core_py\n\n        # Ensure we do not import the same module again (#11475).\n        mod2 = import_path(\n            core_py,\n            mode=\"importlib\",\n            root=pytester.path,\n            consider_namespace_packages=ns_param,\n        )\n        assert mod is mod2\n\n        # tests are not reachable from sys.path, so they are imported as a standalone modules.\n        # Instead of '.tests.a.test_core', we import as \"_tests.a.test_core\" because\n        # importlib considers module names starting with '.' to be local imports.\n        mod = import_path(\n            test_path1,\n            mode=\"importlib\",\n            root=pytester.path,\n            consider_namespace_packages=ns_param,\n        )\n        assert mod.__name__ == \"_tests.a.test_core\"\n\n        # Ensure we do not import the same module again (#11475).\n        mod2 = import_path(\n            test_path1,\n            mode=\"importlib\",\n            root=pytester.path,\n            consider_namespace_packages=ns_param,\n        )\n        assert mod is mod2\n\n        mod = import_path(\n            test_path2,\n            mode=\"importlib\",\n            root=pytester.path,\n            consider_namespace_packages=ns_param,\n        )\n        assert mod.__name__ == \"_tests.b.test_core\"\n\n        # Ensure we do not impor"}, {"start_line": 37000, "end_line": 39000, "belongs_to": {"file_name": "test_pathlib.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "  def test(a_fix):\n                    assert a_fix == \"a\"\n                \"\"\",\n            ),\n            encoding=\"ascii\",\n        )\n\n        conftest_path2 = path / \".tests/b/conftest.py\"\n        conftest_path2.parent.mkdir(parents=True)\n        conftest_path2.write_text(\n            dedent(\n                \"\"\"\n                import pytest\n                @pytest.fixture\n                def b_fix(): return \"b\"\n                \"\"\"\n            ),\n            encoding=\"ascii\",\n        )\n\n        test_path2 = path / \".tests/b/test_core.py\"\n        test_path2.write_text(\n            dedent(\n                \"\"\"\n                import app.core\n                def test(b_fix):\n                    assert b_fix == \"b\"\n                \"\"\",\n            ),\n            encoding=\"ascii\",\n        )\n        return (site_packages / \"app/core.py\"), test_path1, test_path2\n\n    def test_import_using_normal_mechanism_first(\n        self, monkeypatch: MonkeyPatch, pytester: Pytester, ns_param: bool\n    ) -> None:\n        \"\"\"\n        Test import_path imports from the canonical location when possible first, only\n        falling back to its normal flow when the module being imported is not reachable via sys.path (#11475).\n        \"\"\"\n        core_py, test_path1, test_path2 = self.create_installed_doctests_and_tests_dir(\n            pytester.path, monkeypatch\n        )\n\n        # core_py is reached from sys.path, so should be imported normally.\n        mod = import_path(\n            core_py,\n            mode=\"importlib\",\n            root=pytester.path,\n            consider_namespace_packages=ns_param,\n        )\n        assert mod.__name__ == \"app.core\"\n        assert mod.__file__ and Path(mod.__file__) == core_py\n\n        # Ensure we do not import the same module again (#11475).\n        mod2 = import_path(\n            core_py,\n            mode=\"importlib\",\n            root=pytester.path,\n            consider_namespace_packages=ns_param,\n        )\n        assert mod is mod2\n\n        # test"}, {"start_line": 19000, "end_line": 21000, "belongs_to": {"file_name": "pathlib.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "ample, a conftest.py file imported by this function\n    # might have local imports, which would fail at runtime if we restored sys.path.\n    if mode is ImportMode.append:\n        if str(pkg_root) not in sys.path:\n            sys.path.append(str(pkg_root))\n    elif mode is ImportMode.prepend:\n        if str(pkg_root) != sys.path[0]:\n            sys.path.insert(0, str(pkg_root))\n    else:\n        assert_never(mode)\n\n    importlib.import_module(module_name)\n\n    mod = sys.modules[module_name]\n    if path.name == \"__init__.py\":\n        return mod\n\n    ignore = os.environ.get(\"PY_IGNORE_IMPORTMISMATCH\", \"\")\n    if ignore != \"1\":\n        module_file = mod.__file__\n        if module_file is None:\n            raise ImportPathMismatchError(module_name, module_file, path)\n\n        if module_file.endswith((\".pyc\", \".pyo\")):\n            module_file = module_file[:-1]\n        if module_file.endswith(os.sep + \"__init__.py\"):\n            module_file = module_file[: -(len(os.sep + \"__init__.py\"))]\n\n        try:\n            is_same = _is_same(str(path), module_file)\n        except FileNotFoundError:\n            is_same = False\n\n        if not is_same:\n            raise ImportPathMismatchError(module_name, module_file, path)\n\n    return mod\n\n\ndef _import_module_using_spec(\n    module_name: str, module_path: Path, module_location: Path, *, insert_modules: bool\n) -> ModuleType | None:\n    \"\"\"\n    Tries to import a module by its canonical name, path, and its parent location.\n\n    :param module_name:\n        The expected module name, will become the key of `sys.modules`.\n\n    :param module_path:\n        The file path of the module, for example `/foo/bar/test_demo.py`.\n        If module is a package, pass the path to the  `__init__.py` of the package.\n        If module is a namespace package, pass directory path.\n\n    :param module_location:\n        The parent location of the module.\n        If module is a package, pass the directory containing the `__init__.py` file.\n\n    :param insert_m"}, {"start_line": 9000, "end_line": 11000, "belongs_to": {"file_name": "test_pathlib.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "dir\"\n        mod = import_path(\n            otherdir / \"a.py\", root=path1, consider_namespace_packages=ns_param\n        )\n        assert mod.result == \"got it\"\n        assert mod.__name__ == \"otherdir.a\"\n\n    def test_b(self, path1: Path, ns_param: bool) -> None:\n        otherdir = path1 / \"otherdir\"\n        mod = import_path(\n            otherdir / \"b.py\", root=path1, consider_namespace_packages=ns_param\n        )\n        assert mod.stuff == \"got it\"\n        assert mod.__name__ == \"otherdir.b\"\n\n    def test_c(self, path1: Path, ns_param: bool) -> None:\n        otherdir = path1 / \"otherdir\"\n        mod = import_path(\n            otherdir / \"c.py\", root=path1, consider_namespace_packages=ns_param\n        )\n        assert mod.value == \"got it\"\n\n    def test_d(self, path1: Path, ns_param: bool) -> None:\n        otherdir = path1 / \"otherdir\"\n        mod = import_path(\n            otherdir / \"d.py\", root=path1, consider_namespace_packages=ns_param\n        )\n        assert mod.value2 == \"got it\"\n\n    def test_import_after(self, tmp_path: Path, ns_param: bool) -> None:\n        tmp_path.joinpath(\"xxxpackage\").mkdir()\n        tmp_path.joinpath(\"xxxpackage\", \"__init__.py\").touch()\n        mod1path = tmp_path.joinpath(\"xxxpackage\", \"module1.py\")\n        mod1path.touch()\n        mod1 = import_path(\n            mod1path, root=tmp_path, consider_namespace_packages=ns_param\n        )\n        assert mod1.__name__ == \"xxxpackage.module1\"\n        from xxxpackage import module1\n\n        assert module1 is mod1\n\n    def test_check_filepath_consistency(\n        self, monkeypatch: MonkeyPatch, tmp_path: Path, ns_param: bool\n    ) -> None:\n        name = \"pointsback123\"\n        p = tmp_path.joinpath(name + \".py\")\n        p.touch()\n        with monkeypatch.context() as mp:\n            for ending in (\".pyc\", \".pyo\"):\n                mod = ModuleType(name)\n                pseudopath = tmp_path.joinpath(name + ending)\n                pseudopath.touch()\n                mod.__file__ = str(pseudo"}, {"start_line": 18000, "end_line": 20000, "belongs_to": {"file_name": "pathlib.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "f mod is not None:\n                return mod\n\n        # Could not import the module with the current sys.path, so we fall back\n        # to importing the file as a single module, not being a part of a package.\n        module_name = module_name_from_path(path, root)\n        with contextlib.suppress(KeyError):\n            return sys.modules[module_name]\n\n        mod = _import_module_using_spec(\n            module_name, path, path.parent, insert_modules=True\n        )\n        if mod is None:\n            raise ImportError(f\"Can't find module {module_name} at location {path}\")\n        return mod\n\n    try:\n        pkg_root, module_name = resolve_pkg_root_and_module_name(\n            path, consider_namespace_packages=consider_namespace_packages\n        )\n    except CouldNotResolvePathError:\n        pkg_root, module_name = path.parent, path.stem\n\n    # Change sys.path permanently: restoring it at the end of this function would cause surprising\n    # problems because of delayed imports: for example, a conftest.py file imported by this function\n    # might have local imports, which would fail at runtime if we restored sys.path.\n    if mode is ImportMode.append:\n        if str(pkg_root) not in sys.path:\n            sys.path.append(str(pkg_root))\n    elif mode is ImportMode.prepend:\n        if str(pkg_root) != sys.path[0]:\n            sys.path.insert(0, str(pkg_root))\n    else:\n        assert_never(mode)\n\n    importlib.import_module(module_name)\n\n    mod = sys.modules[module_name]\n    if path.name == \"__init__.py\":\n        return mod\n\n    ignore = os.environ.get(\"PY_IGNORE_IMPORTMISMATCH\", \"\")\n    if ignore != \"1\":\n        module_file = mod.__file__\n        if module_file is None:\n            raise ImportPathMismatchError(module_name, module_file, path)\n\n        if module_file.endswith((\".pyc\", \".pyo\")):\n            module_file = module_file[:-1]\n        if module_file.endswith(os.sep + \"__init__.py\"):\n            module_file = module_file[: -(len(os.sep + \"__init__.py\"))]\n\n  "}], "retrieved_count": 10, "cost_time": 1.1608319282531738}
{"question": "How should the plugin manager architecture be redesigned to enforce plugin registration policies at the system level rather than relying on runtime assertion checks in individual test cases?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"start_line": 9000, "end_line": 11000, "belongs_to": {"file_name": "test_pluginmanager.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "register, mod)\n        pytest.raises(ValueError, lambda: pm.register(mod))\n        # assert not pm.is_registered(mod2)\n        assert pm.get_plugins() == values\n\n    def test_canonical_import(self, monkeypatch):\n        mod = types.ModuleType(\"pytest_xyz\")\n        monkeypatch.setitem(sys.modules, \"pytest_xyz\", mod)\n        pm = PytestPluginManager()\n        pm.import_plugin(\"pytest_xyz\")\n        assert pm.get_plugin(\"pytest_xyz\") == mod\n        assert pm.is_registered(mod)\n\n    def test_consider_module(\n        self, pytester: Pytester, pytestpm: PytestPluginManager\n    ) -> None:\n        pytester.syspathinsert()\n        pytester.makepyfile(pytest_p1=\"#\")\n        pytester.makepyfile(pytest_p2=\"#\")\n        mod = types.ModuleType(\"temp\")\n        mod.__dict__[\"pytest_plugins\"] = [\"pytest_p1\", \"pytest_p2\"]\n        pytestpm.consider_module(mod)\n        p1 = pytestpm.get_plugin(\"pytest_p1\")\n        assert p1 is not None\n        assert p1.__name__ == \"pytest_p1\"\n        p2 = pytestpm.get_plugin(\"pytest_p2\")\n        assert p2 is not None\n        assert p2.__name__ == \"pytest_p2\"\n\n    def test_consider_module_import_module(\n        self, pytester: Pytester, _config_for_test: Config\n    ) -> None:\n        pytestpm = _config_for_test.pluginmanager\n        mod = types.ModuleType(\"x\")\n        mod.__dict__[\"pytest_plugins\"] = \"pytest_a\"\n        aplugin = pytester.makepyfile(pytest_a=\"#\")\n        reprec = pytester.make_hook_recorder(pytestpm)\n        pytester.syspathinsert(aplugin.parent)\n        pytestpm.consider_module(mod)\n        call = reprec.getcall(pytestpm.hook.pytest_plugin_registered.name)\n        assert call.plugin.__name__ == \"pytest_a\"\n\n        # check that it is not registered twice\n        pytestpm.consider_module(mod)\n        values = reprec.getcalls(\"pytest_plugin_registered\")\n        assert len(values) == 1\n\n    def test_consider_env_fails_to_import(\n        self, monkeypatch: MonkeyPatch, pytestpm: PytestPluginManager\n    ) -> None:\n        monkeypatch.setenv(\"P"}, {"start_line": 15000, "end_line": 17000, "belongs_to": {"file_name": "test_pluginmanager.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "portError, lambda: pytestpm.consider_preparse([\"xyz\", \"-p\", \"hello123\"])\n        )\n\n        # Handles -p without space (#3532).\n        with pytest.raises(ImportError) as excinfo:\n            pytestpm.consider_preparse([\"-phello123\"])\n        assert '\"hello123\"' in excinfo.value.args[0]\n        pytestpm.consider_preparse([\"-pno:hello123\"])\n\n        # Handles -p without following arg (when used without argparse).\n        pytestpm.consider_preparse([\"-p\"])\n\n        with pytest.raises(UsageError, match=\"^plugin main cannot be disabled$\"):\n            pytestpm.consider_preparse([\"-p\", \"no:main\"])\n\n    def test_plugin_prevent_register(self, pytestpm: PytestPluginManager) -> None:\n        pytestpm.consider_preparse([\"xyz\", \"-p\", \"no:abc\"])\n        l1 = pytestpm.get_plugins()\n        pytestpm.register(42, name=\"abc\")\n        l2 = pytestpm.get_plugins()\n        assert len(l2) == len(l1)\n        assert 42 not in l2\n\n    def test_plugin_prevent_register_unregistered_already_registered(\n        self, pytestpm: PytestPluginManager\n    ) -> None:\n        pytestpm.register(42, name=\"abc\")\n        l1 = pytestpm.get_plugins()\n        assert 42 in l1\n        pytestpm.consider_preparse([\"xyz\", \"-p\", \"no:abc\"])\n        l2 = pytestpm.get_plugins()\n        assert 42 not in l2\n\n    def test_plugin_prevent_register_stepwise_on_cacheprovider_unregister(\n        self, pytestpm: PytestPluginManager\n    ) -> None:\n        \"\"\"From PR #4304: The only way to unregister a module is documented at\n        the end of https://docs.pytest.org/en/stable/how-to/plugins.html.\n\n        When unregister cacheprovider, then unregister stepwise too.\n        \"\"\"\n        pytestpm.register(42, name=\"cacheprovider\")\n        pytestpm.register(43, name=\"stepwise\")\n        l1 = pytestpm.get_plugins()\n        assert 42 in l1\n        assert 43 in l1\n        pytestpm.consider_preparse([\"xyz\", \"-p\", \"no:cacheprovider\"])\n        l2 = pytestpm.get_plugins()\n        assert 42 not in l2\n        assert 43 not in l2\n\n    def "}, {"start_line": 14000, "end_line": 16000, "belongs_to": {"file_name": "test_pluginmanager.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "tError, pytestpm.import_plugin, \"qweqwex.y\")\n        pytest.raises(ImportError, pytestpm.import_plugin, \"pytest_qweqwex.y\")\n\n        pytester.syspathinsert()\n        pytester.mkpydir(\"pkg\").joinpath(\"plug.py\").write_text(\"x=3\", encoding=\"utf-8\")\n        pluginname = \"pkg.plug\"\n        pytestpm.import_plugin(pluginname)\n        mod = pytestpm.get_plugin(\"pkg.plug\")\n        assert mod is not None\n        assert mod.x == 3\n\n    def test_consider_conftest_deps(\n        self,\n        pytester: Pytester,\n        pytestpm: PytestPluginManager,\n    ) -> None:\n        mod = import_path(\n            pytester.makepyfile(\"pytest_plugins='xyz'\"),\n            root=pytester.path,\n            consider_namespace_packages=False,\n        )\n        with pytest.raises(ImportError):\n            pytestpm.consider_conftest(mod, registration_name=\"unused\")\n\n\nclass TestPytestPluginManagerBootstrapping:\n    def test_preparse_args(self, pytestpm: PytestPluginManager) -> None:\n        pytest.raises(\n            ImportError, lambda: pytestpm.consider_preparse([\"xyz\", \"-p\", \"hello123\"])\n        )\n\n        # Handles -p without space (#3532).\n        with pytest.raises(ImportError) as excinfo:\n            pytestpm.consider_preparse([\"-phello123\"])\n        assert '\"hello123\"' in excinfo.value.args[0]\n        pytestpm.consider_preparse([\"-pno:hello123\"])\n\n        # Handles -p without following arg (when used without argparse).\n        pytestpm.consider_preparse([\"-p\"])\n\n        with pytest.raises(UsageError, match=\"^plugin main cannot be disabled$\"):\n            pytestpm.consider_preparse([\"-p\", \"no:main\"])\n\n    def test_plugin_prevent_register(self, pytestpm: PytestPluginManager) -> None:\n        pytestpm.consider_preparse([\"xyz\", \"-p\", \"no:abc\"])\n        l1 = pytestpm.get_plugins()\n        pytestpm.register(42, name=\"abc\")\n        l2 = pytestpm.get_plugins()\n        assert len(l2) == len(l1)\n        assert 42 not in l2\n\n    def test_plugin_prevent_register_unregistered_already_registered(\n        s"}, {"start_line": 16000, "end_line": 17293, "belongs_to": {"file_name": "test_pluginmanager.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "elf, pytestpm: PytestPluginManager\n    ) -> None:\n        pytestpm.register(42, name=\"abc\")\n        l1 = pytestpm.get_plugins()\n        assert 42 in l1\n        pytestpm.consider_preparse([\"xyz\", \"-p\", \"no:abc\"])\n        l2 = pytestpm.get_plugins()\n        assert 42 not in l2\n\n    def test_plugin_prevent_register_stepwise_on_cacheprovider_unregister(\n        self, pytestpm: PytestPluginManager\n    ) -> None:\n        \"\"\"From PR #4304: The only way to unregister a module is documented at\n        the end of https://docs.pytest.org/en/stable/how-to/plugins.html.\n\n        When unregister cacheprovider, then unregister stepwise too.\n        \"\"\"\n        pytestpm.register(42, name=\"cacheprovider\")\n        pytestpm.register(43, name=\"stepwise\")\n        l1 = pytestpm.get_plugins()\n        assert 42 in l1\n        assert 43 in l1\n        pytestpm.consider_preparse([\"xyz\", \"-p\", \"no:cacheprovider\"])\n        l2 = pytestpm.get_plugins()\n        assert 42 not in l2\n        assert 43 not in l2\n\n    def test_blocked_plugin_can_be_used(self, pytestpm: PytestPluginManager) -> None:\n        pytestpm.consider_preparse([\"xyz\", \"-p\", \"no:abc\", \"-p\", \"abc\"])\n\n        assert pytestpm.has_plugin(\"abc\")\n        assert not pytestpm.is_blocked(\"abc\")\n        assert not pytestpm.is_blocked(\"pytest_abc\")\n"}, {"start_line": 10000, "end_line": 12000, "belongs_to": {"file_name": "test_pluginmanager.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "in(\"pytest_p2\")\n        assert p2 is not None\n        assert p2.__name__ == \"pytest_p2\"\n\n    def test_consider_module_import_module(\n        self, pytester: Pytester, _config_for_test: Config\n    ) -> None:\n        pytestpm = _config_for_test.pluginmanager\n        mod = types.ModuleType(\"x\")\n        mod.__dict__[\"pytest_plugins\"] = \"pytest_a\"\n        aplugin = pytester.makepyfile(pytest_a=\"#\")\n        reprec = pytester.make_hook_recorder(pytestpm)\n        pytester.syspathinsert(aplugin.parent)\n        pytestpm.consider_module(mod)\n        call = reprec.getcall(pytestpm.hook.pytest_plugin_registered.name)\n        assert call.plugin.__name__ == \"pytest_a\"\n\n        # check that it is not registered twice\n        pytestpm.consider_module(mod)\n        values = reprec.getcalls(\"pytest_plugin_registered\")\n        assert len(values) == 1\n\n    def test_consider_env_fails_to_import(\n        self, monkeypatch: MonkeyPatch, pytestpm: PytestPluginManager\n    ) -> None:\n        monkeypatch.setenv(\"PYTEST_PLUGINS\", \"nonexisting\", prepend=\",\")\n        with pytest.raises(ImportError):\n            pytestpm.consider_env()\n\n    @pytest.mark.filterwarnings(\"always\")\n    def test_plugin_skip(self, pytester: Pytester, monkeypatch: MonkeyPatch) -> None:\n        p = pytester.makepyfile(\n            skipping1=\"\"\"\n            import pytest\n            pytest.skip(\"hello\", allow_module_level=True)\n        \"\"\"\n        )\n        shutil.copy(p, p.with_name(\"skipping2.py\"))\n        monkeypatch.setenv(\"PYTEST_PLUGINS\", \"skipping2\")\n        result = pytester.runpytest(\"-p\", \"skipping1\", syspathinsert=True)\n        assert result.ret == ExitCode.NO_TESTS_COLLECTED\n        result.stdout.fnmatch_lines(\n            [\"*skipped plugin*skipping1*hello*\", \"*skipped plugin*skipping2*hello*\"]\n        )\n\n    def test_consider_env_plugin_instantiation(\n        self,\n        pytester: Pytester,\n        monkeypatch: MonkeyPatch,\n        pytestpm: PytestPluginManager,\n    ) -> None:\n        pytester.syspathinsert()"}, {"start_line": 13000, "end_line": 15000, "belongs_to": {"file_name": "test_pluginmanager.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "h_lines([\"*1 passed*\"])\n\n    def test_import_plugin_importname(\n        self, pytester: Pytester, pytestpm: PytestPluginManager\n    ) -> None:\n        pytest.raises(ImportError, pytestpm.import_plugin, \"qweqwex.y\")\n        pytest.raises(ImportError, pytestpm.import_plugin, \"pytest_qweqwx.y\")\n\n        pytester.syspathinsert()\n        pluginname = \"pytest_hello\"\n        pytester.makepyfile(**{pluginname: \"\"})\n        pytestpm.import_plugin(\"pytest_hello\")\n        len1 = len(pytestpm.get_plugins())\n        pytestpm.import_plugin(\"pytest_hello\")\n        len2 = len(pytestpm.get_plugins())\n        assert len1 == len2\n        plugin1 = pytestpm.get_plugin(\"pytest_hello\")\n        assert plugin1 is not None\n        assert plugin1.__name__.endswith(\"pytest_hello\")\n        plugin2 = pytestpm.get_plugin(\"pytest_hello\")\n        assert plugin2 is plugin1\n\n    def test_import_plugin_dotted_name(\n        self, pytester: Pytester, pytestpm: PytestPluginManager\n    ) -> None:\n        pytest.raises(ImportError, pytestpm.import_plugin, \"qweqwex.y\")\n        pytest.raises(ImportError, pytestpm.import_plugin, \"pytest_qweqwex.y\")\n\n        pytester.syspathinsert()\n        pytester.mkpydir(\"pkg\").joinpath(\"plug.py\").write_text(\"x=3\", encoding=\"utf-8\")\n        pluginname = \"pkg.plug\"\n        pytestpm.import_plugin(pluginname)\n        mod = pytestpm.get_plugin(\"pkg.plug\")\n        assert mod is not None\n        assert mod.x == 3\n\n    def test_consider_conftest_deps(\n        self,\n        pytester: Pytester,\n        pytestpm: PytestPluginManager,\n    ) -> None:\n        mod = import_path(\n            pytester.makepyfile(\"pytest_plugins='xyz'\"),\n            root=pytester.path,\n            consider_namespace_packages=False,\n        )\n        with pytest.raises(ImportError):\n            pytestpm.consider_conftest(mod, registration_name=\"unused\")\n\n\nclass TestPytestPluginManagerBootstrapping:\n    def test_preparse_args(self, pytestpm: PytestPluginManager) -> None:\n        pytest.raises(\n            Im"}, {"start_line": 12000, "end_line": 14000, "belongs_to": {"file_name": "test_pluginmanager.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "\n        pytester.makepyfile(xy123=\"#\")\n        monkeypatch.setitem(os.environ, \"PYTEST_PLUGINS\", \"xy123\")\n        l1 = len(pytestpm.get_plugins())\n        pytestpm.consider_env()\n        l2 = len(pytestpm.get_plugins())\n        assert l2 == l1 + 1\n        assert pytestpm.get_plugin(\"xy123\")\n        pytestpm.consider_env()\n        l3 = len(pytestpm.get_plugins())\n        assert l2 == l3\n\n    def test_pluginmanager_ENV_startup(\n        self, pytester: Pytester, monkeypatch: MonkeyPatch\n    ) -> None:\n        pytester.makepyfile(pytest_x500=\"#\")\n        p = pytester.makepyfile(\n            \"\"\"\n            import pytest\n            def test_hello(pytestconfig):\n                plugin = pytestconfig.pluginmanager.get_plugin('pytest_x500')\n                assert plugin is not None\n        \"\"\"\n        )\n        monkeypatch.setenv(\"PYTEST_PLUGINS\", \"pytest_x500\", prepend=\",\")\n        result = pytester.runpytest(p, syspathinsert=True)\n        assert result.ret == 0\n        result.stdout.fnmatch_lines([\"*1 passed*\"])\n\n    def test_import_plugin_importname(\n        self, pytester: Pytester, pytestpm: PytestPluginManager\n    ) -> None:\n        pytest.raises(ImportError, pytestpm.import_plugin, \"qweqwex.y\")\n        pytest.raises(ImportError, pytestpm.import_plugin, \"pytest_qweqwx.y\")\n\n        pytester.syspathinsert()\n        pluginname = \"pytest_hello\"\n        pytester.makepyfile(**{pluginname: \"\"})\n        pytestpm.import_plugin(\"pytest_hello\")\n        len1 = len(pytestpm.get_plugins())\n        pytestpm.import_plugin(\"pytest_hello\")\n        len2 = len(pytestpm.get_plugins())\n        assert len1 == len2\n        plugin1 = pytestpm.get_plugin(\"pytest_hello\")\n        assert plugin1 is not None\n        assert plugin1.__name__.endswith(\"pytest_hello\")\n        plugin2 = pytestpm.get_plugin(\"pytest_hello\")\n        assert plugin2 is plugin1\n\n    def test_import_plugin_dotted_name(\n        self, pytester: Pytester, pytestpm: PytestPluginManager\n    ) -> None:\n        pytest.raises(Impor"}, {"start_line": 15000, "end_line": 17000, "belongs_to": {"file_name": "__init__.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest/config", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "ts(module_or_class, name)\n        if opts is None:\n            method = getattr(module_or_class, name)\n            if name.startswith(\"pytest_\"):\n                legacy = _get_legacy_hook_marks(\n                    method, \"spec\", (\"firstresult\", \"historic\")\n                )\n                opts = cast(HookspecOpts, legacy)\n        return opts\n\n    def register(self, plugin: _PluggyPlugin, name: str | None = None) -> str | None:\n        if name in _pytest.deprecated.DEPRECATED_EXTERNAL_PLUGINS:\n            warnings.warn(\n                PytestConfigWarning(\n                    \"{} plugin has been merged into the core, \"\n                    \"please remove it from your requirements.\".format(\n                        name.replace(\"_\", \"-\")\n                    )\n                )\n            )\n            return None\n        plugin_name = super().register(plugin, name)\n        if plugin_name is not None:\n            self.hook.pytest_plugin_registered.call_historic(\n                kwargs=dict(\n                    plugin=plugin,\n                    plugin_name=plugin_name,\n                    manager=self,\n                )\n            )\n\n            if isinstance(plugin, types.ModuleType):\n                self.consider_module(plugin)\n        return plugin_name\n\n    def getplugin(self, name: str):\n        # Support deprecated naming because plugins (xdist e.g.) use it.\n        plugin: _PluggyPlugin | None = self.get_plugin(name)\n        return plugin\n\n    def hasplugin(self, name: str) -> bool:\n        \"\"\"Return whether a plugin with the given name is registered.\"\"\"\n        return bool(self.get_plugin(name))\n\n    def pytest_configure(self, config: Config) -> None:\n        \"\"\":meta private:\"\"\"\n        # XXX now that the pluginmanager exposes hookimpl(tryfirst...)\n        # we should remove tryfirst/trylast as markers.\n        config.addinivalue_line(\n            \"markers\",\n            \"tryfirst: mark a hook implementation function such that the \"\n            \"plugin machi"}, {"start_line": 11000, "end_line": 13000, "belongs_to": {"file_name": "test_pluginmanager.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "YTEST_PLUGINS\", \"nonexisting\", prepend=\",\")\n        with pytest.raises(ImportError):\n            pytestpm.consider_env()\n\n    @pytest.mark.filterwarnings(\"always\")\n    def test_plugin_skip(self, pytester: Pytester, monkeypatch: MonkeyPatch) -> None:\n        p = pytester.makepyfile(\n            skipping1=\"\"\"\n            import pytest\n            pytest.skip(\"hello\", allow_module_level=True)\n        \"\"\"\n        )\n        shutil.copy(p, p.with_name(\"skipping2.py\"))\n        monkeypatch.setenv(\"PYTEST_PLUGINS\", \"skipping2\")\n        result = pytester.runpytest(\"-p\", \"skipping1\", syspathinsert=True)\n        assert result.ret == ExitCode.NO_TESTS_COLLECTED\n        result.stdout.fnmatch_lines(\n            [\"*skipped plugin*skipping1*hello*\", \"*skipped plugin*skipping2*hello*\"]\n        )\n\n    def test_consider_env_plugin_instantiation(\n        self,\n        pytester: Pytester,\n        monkeypatch: MonkeyPatch,\n        pytestpm: PytestPluginManager,\n    ) -> None:\n        pytester.syspathinsert()\n        pytester.makepyfile(xy123=\"#\")\n        monkeypatch.setitem(os.environ, \"PYTEST_PLUGINS\", \"xy123\")\n        l1 = len(pytestpm.get_plugins())\n        pytestpm.consider_env()\n        l2 = len(pytestpm.get_plugins())\n        assert l2 == l1 + 1\n        assert pytestpm.get_plugin(\"xy123\")\n        pytestpm.consider_env()\n        l3 = len(pytestpm.get_plugins())\n        assert l2 == l3\n\n    def test_pluginmanager_ENV_startup(\n        self, pytester: Pytester, monkeypatch: MonkeyPatch\n    ) -> None:\n        pytester.makepyfile(pytest_x500=\"#\")\n        p = pytester.makepyfile(\n            \"\"\"\n            import pytest\n            def test_hello(pytestconfig):\n                plugin = pytestconfig.pluginmanager.get_plugin('pytest_x500')\n                assert plugin is not None\n        \"\"\"\n        )\n        monkeypatch.setenv(\"PYTEST_PLUGINS\", \"pytest_x500\", prepend=\",\")\n        result = pytester.runpytest(p, syspathinsert=True)\n        assert result.ret == 0\n        result.stdout.fnmatc"}, {"start_line": 16000, "end_line": 18000, "belongs_to": {"file_name": "__init__.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest/config", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "ict(\n                    plugin=plugin,\n                    plugin_name=plugin_name,\n                    manager=self,\n                )\n            )\n\n            if isinstance(plugin, types.ModuleType):\n                self.consider_module(plugin)\n        return plugin_name\n\n    def getplugin(self, name: str):\n        # Support deprecated naming because plugins (xdist e.g.) use it.\n        plugin: _PluggyPlugin | None = self.get_plugin(name)\n        return plugin\n\n    def hasplugin(self, name: str) -> bool:\n        \"\"\"Return whether a plugin with the given name is registered.\"\"\"\n        return bool(self.get_plugin(name))\n\n    def pytest_configure(self, config: Config) -> None:\n        \"\"\":meta private:\"\"\"\n        # XXX now that the pluginmanager exposes hookimpl(tryfirst...)\n        # we should remove tryfirst/trylast as markers.\n        config.addinivalue_line(\n            \"markers\",\n            \"tryfirst: mark a hook implementation function such that the \"\n            \"plugin machinery will try to call it first/as early as possible. \"\n            \"DEPRECATED, use @pytest.hookimpl(tryfirst=True) instead.\",\n        )\n        config.addinivalue_line(\n            \"markers\",\n            \"trylast: mark a hook implementation function such that the \"\n            \"plugin machinery will try to call it last/as late as possible. \"\n            \"DEPRECATED, use @pytest.hookimpl(trylast=True) instead.\",\n        )\n        self._configured = True\n\n    #\n    # Internal API for local conftest plugin handling.\n    #\n    def _set_initial_conftests(\n        self,\n        args: Sequence[str | pathlib.Path],\n        pyargs: bool,\n        noconftest: bool,\n        rootpath: pathlib.Path,\n        confcutdir: pathlib.Path | None,\n        invocation_dir: pathlib.Path,\n        importmode: ImportMode | str,\n        *,\n        consider_namespace_packages: bool,\n    ) -> None:\n        \"\"\"Load initial conftest files given a preparsed \"namespace\".\n\n        As conftest files may add their own com"}], "retrieved_count": 10, "cost_time": 1.1675944328308105}
{"question": "How does the TestReadme class separate the concerns of cache directory verification from test execution orchestration to maintain architectural layering between test setup, execution, and assertion phases?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"start_line": 43000, "end_line": 45000, "belongs_to": {"file_name": "test_cacheprovider.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "                \"*test_2/test_2.py::test_1[1*\",\n                \"*test_2/test_2.py::test_1[2*\",\n                \"*test_1/test_1.py::test_1[1*\",\n                \"*test_1/test_1.py::test_1[2*\",\n            ]\n        )\n\n\nclass TestReadme:\n    def check_readme(self, pytester: Pytester) -> bool:\n        config = pytester.parseconfigure()\n        assert config.cache is not None\n        readme = config.cache._cachedir.joinpath(\"README.md\")\n        return readme.is_file()\n\n    def test_readme_passed(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\"def test_always_passes(): pass\")\n        pytester.runpytest()\n        assert self.check_readme(pytester) is True\n\n    def test_readme_failed(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\"def test_always_fails(): assert 0\")\n        pytester.runpytest()\n        assert self.check_readme(pytester) is True\n\n\nclass Action(Enum):\n    \"\"\"Action to perform on the cache directory.\"\"\"\n\n    MKDIR = auto()\n    SET = auto()\n\n\n@pytest.mark.parametrize(\"action\", list(Action))\ndef test_gitignore(\n    pytester: Pytester,\n    action: Action,\n) -> None:\n    \"\"\"Ensure we automatically create .gitignore file in the pytest_cache directory (#3286).\"\"\"\n    from _pytest.cacheprovider import Cache\n\n    config = pytester.parseconfig()\n    cache = Cache.for_config(config, _ispytest=True)\n    if action == Action.MKDIR:\n        cache.mkdir(\"foo\")\n    elif action == Action.SET:\n        cache.set(\"foo\", \"bar\")\n    else:\n        assert_never(action)\n    msg = \"# Created by pytest automatically.\\n*\\n\"\n    gitignore_path = cache._cachedir.joinpath(\".gitignore\")\n    assert gitignore_path.read_text(encoding=\"UTF-8\") == msg\n\n    # Does not overwrite existing/custom one.\n    gitignore_path.write_text(\"custom\", encoding=\"utf-8\")\n    if action == Action.MKDIR:\n        cache.mkdir(\"something\")\n    elif action == Action.SET:\n        cache.set(\"something\", \"else\")\n    else:\n        assert_never(action)\n    assert gitignore_path.read_text(enco"}, {"start_line": 42000, "end_line": 44000, "belongs_to": {"file_name": "test_cacheprovider.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "\n        )\n\n        result = pytester.runpytest(\"-v\", \"--nf\")\n        result.stdout.fnmatch_lines(\n            [\n                \"*test_2/test_2.py::test_1[1*\",\n                \"*test_2/test_2.py::test_1[2*\",\n                \"*test_1/test_1.py::test_1[1*\",\n                \"*test_1/test_1.py::test_1[2*\",\n            ]\n        )\n\n        p1.write_text(\n            \"import pytest\\n\"\n            \"@pytest.mark.parametrize('num', [1, 2, 3])\\n\"\n            \"def test_1(num): assert num\\n\",\n            encoding=\"utf-8\",\n        )\n        os.utime(p1, ns=(p1.stat().st_atime_ns, int(1e9)))\n\n        # Running only a subset does not forget about existing ones.\n        result = pytester.runpytest(\"-v\", \"--nf\", \"test_2/test_2.py\")\n        result.stdout.fnmatch_lines(\n            [\"*test_2/test_2.py::test_1[1*\", \"*test_2/test_2.py::test_1[2*\"]\n        )\n\n        result = pytester.runpytest(\"-v\", \"--nf\")\n        result.stdout.fnmatch_lines(\n            [\n                \"*test_1/test_1.py::test_1[3*\",\n                \"*test_2/test_2.py::test_1[1*\",\n                \"*test_2/test_2.py::test_1[2*\",\n                \"*test_1/test_1.py::test_1[1*\",\n                \"*test_1/test_1.py::test_1[2*\",\n            ]\n        )\n\n\nclass TestReadme:\n    def check_readme(self, pytester: Pytester) -> bool:\n        config = pytester.parseconfigure()\n        assert config.cache is not None\n        readme = config.cache._cachedir.joinpath(\"README.md\")\n        return readme.is_file()\n\n    def test_readme_passed(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\"def test_always_passes(): pass\")\n        pytester.runpytest()\n        assert self.check_readme(pytester) is True\n\n    def test_readme_failed(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\"def test_always_fails(): assert 0\")\n        pytester.runpytest()\n        assert self.check_readme(pytester) is True\n\n\nclass Action(Enum):\n    \"\"\"Action to perform on the cache directory.\"\"\"\n\n    MKDIR = auto()\n    SET = auto()\n\n\n@pyte"}, {"start_line": 5000, "end_line": 7000, "belongs_to": {"file_name": "test_cacheprovider.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "               cache.set(\"some/thing\", [1])\n                pytest.raises(TypeError, lambda: cache.get(\"some/thing\"))\n                val = cache.get(\"some/thing\", [])\n                assert val == [1]\n        \"\"\"\n        )\n        result = pytester.runpytest()\n        assert result.ret == 0\n        result.stdout.fnmatch_lines([\"*1 passed*\"])\n\n    def test_custom_rel_cache_dir(self, pytester: Pytester) -> None:\n        rel_cache_dir = os.path.join(\"custom_cache_dir\", \"subdir\")\n        pytester.makeini(\n            f\"\"\"\n            [pytest]\n            cache_dir = {rel_cache_dir}\n        \"\"\"\n        )\n        pytester.makepyfile(test_errored=\"def test_error():\\n    assert False\")\n        pytester.runpytest()\n        assert pytester.path.joinpath(rel_cache_dir).is_dir()\n\n    def test_custom_abs_cache_dir(\n        self, pytester: Pytester, tmp_path_factory: TempPathFactory\n    ) -> None:\n        tmp = tmp_path_factory.mktemp(\"tmp\")\n        abs_cache_dir = tmp / \"custom_cache_dir\"\n        pytester.makeini(\n            f\"\"\"\n            [pytest]\n            cache_dir = {abs_cache_dir}\n        \"\"\"\n        )\n        pytester.makepyfile(test_errored=\"def test_error():\\n    assert False\")\n        pytester.runpytest()\n        assert abs_cache_dir.is_dir()\n\n    def test_custom_cache_dir_with_env_var(\n        self, pytester: Pytester, monkeypatch: MonkeyPatch\n    ) -> None:\n        monkeypatch.setenv(\"env_var\", \"custom_cache_dir\")\n        pytester.makeini(\n            \"\"\"\n            [pytest]\n            cache_dir = {cache_dir}\n        \"\"\".format(cache_dir=\"$env_var\")\n        )\n        pytester.makepyfile(test_errored=\"def test_error():\\n    assert False\")\n        pytester.runpytest()\n        assert pytester.path.joinpath(\"custom_cache_dir\").is_dir()\n\n\n@pytest.mark.parametrize(\"env\", ((), (\"TOX_ENV_DIR\", \"mydir/tox-env\")))\ndef test_cache_reportheader(\n    env: Sequence[str], pytester: Pytester, monkeypatch: MonkeyPatch\n) -> None:\n    pytester.makepyfile(\"\"\"def test_foo(): pass\"\""}, {"start_line": 6000, "end_line": 8000, "belongs_to": {"file_name": "test_cacheprovider.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "pytester.makeini(\n            f\"\"\"\n            [pytest]\n            cache_dir = {abs_cache_dir}\n        \"\"\"\n        )\n        pytester.makepyfile(test_errored=\"def test_error():\\n    assert False\")\n        pytester.runpytest()\n        assert abs_cache_dir.is_dir()\n\n    def test_custom_cache_dir_with_env_var(\n        self, pytester: Pytester, monkeypatch: MonkeyPatch\n    ) -> None:\n        monkeypatch.setenv(\"env_var\", \"custom_cache_dir\")\n        pytester.makeini(\n            \"\"\"\n            [pytest]\n            cache_dir = {cache_dir}\n        \"\"\".format(cache_dir=\"$env_var\")\n        )\n        pytester.makepyfile(test_errored=\"def test_error():\\n    assert False\")\n        pytester.runpytest()\n        assert pytester.path.joinpath(\"custom_cache_dir\").is_dir()\n\n\n@pytest.mark.parametrize(\"env\", ((), (\"TOX_ENV_DIR\", \"mydir/tox-env\")))\ndef test_cache_reportheader(\n    env: Sequence[str], pytester: Pytester, monkeypatch: MonkeyPatch\n) -> None:\n    pytester.makepyfile(\"\"\"def test_foo(): pass\"\"\")\n    if env:\n        monkeypatch.setenv(*env)\n        expected = os.path.join(env[1], \".pytest_cache\")\n    else:\n        monkeypatch.delenv(\"TOX_ENV_DIR\", raising=False)\n        expected = \".pytest_cache\"\n    result = pytester.runpytest(\"-v\")\n    result.stdout.fnmatch_lines([f\"cachedir: {expected}\"])\n\n\ndef test_cache_reportheader_external_abspath(\n    pytester: Pytester, tmp_path_factory: TempPathFactory\n) -> None:\n    external_cache = tmp_path_factory.mktemp(\n        \"test_cache_reportheader_external_abspath_abs\"\n    )\n\n    pytester.makepyfile(\"def test_hello(): pass\")\n    pytester.makeini(\n        f\"\"\"\n    [pytest]\n    cache_dir = {external_cache}\n    \"\"\"\n    )\n    result = pytester.runpytest(\"-v\")\n    result.stdout.fnmatch_lines([f\"cachedir: {external_cache}\"])\n\n\ndef test_cache_show(pytester: Pytester) -> None:\n    result = pytester.runpytest(\"--cache-show\")\n    assert result.ret == 0\n    result.stdout.fnmatch_lines([\"*cache is empty*\"])\n    pytester.makeconftest(\n        \"\"\"\n    "}, {"start_line": 7000, "end_line": 9000, "belongs_to": {"file_name": "test_cacheprovider.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "\")\n    if env:\n        monkeypatch.setenv(*env)\n        expected = os.path.join(env[1], \".pytest_cache\")\n    else:\n        monkeypatch.delenv(\"TOX_ENV_DIR\", raising=False)\n        expected = \".pytest_cache\"\n    result = pytester.runpytest(\"-v\")\n    result.stdout.fnmatch_lines([f\"cachedir: {expected}\"])\n\n\ndef test_cache_reportheader_external_abspath(\n    pytester: Pytester, tmp_path_factory: TempPathFactory\n) -> None:\n    external_cache = tmp_path_factory.mktemp(\n        \"test_cache_reportheader_external_abspath_abs\"\n    )\n\n    pytester.makepyfile(\"def test_hello(): pass\")\n    pytester.makeini(\n        f\"\"\"\n    [pytest]\n    cache_dir = {external_cache}\n    \"\"\"\n    )\n    result = pytester.runpytest(\"-v\")\n    result.stdout.fnmatch_lines([f\"cachedir: {external_cache}\"])\n\n\ndef test_cache_show(pytester: Pytester) -> None:\n    result = pytester.runpytest(\"--cache-show\")\n    assert result.ret == 0\n    result.stdout.fnmatch_lines([\"*cache is empty*\"])\n    pytester.makeconftest(\n        \"\"\"\n        def pytest_configure(config):\n            config.cache.set(\"my/name\", [1,2,3])\n            config.cache.set(\"my/hello\", \"world\")\n            config.cache.set(\"other/some\", {1:2})\n            dp = config.cache.mkdir(\"mydb\")\n            dp.joinpath(\"hello\").touch()\n            dp.joinpath(\"world\").touch()\n    \"\"\"\n    )\n    result = pytester.runpytest()\n    assert result.ret == 5  # no tests executed\n\n    result = pytester.runpytest(\"--cache-show\")\n    result.stdout.fnmatch_lines(\n        [\n            \"*cachedir:*\",\n            \"*- cache values for '[*]' -*\",\n            \"cache/nodeids contains:\",\n            \"my/name contains:\",\n            \"  [1, 2, 3]\",\n            \"other/some contains:\",\n            \"  {*'1': 2}\",\n            \"*- cache directories for '[*]' -*\",\n            \"*mydb/hello*length 0*\",\n            \"*mydb/world*length 0*\",\n        ]\n    )\n    assert result.ret == 0\n\n    result = pytester.runpytest(\"--cache-show\", \"*/hello\")\n    result.stdout.fnmatch_lines(\n        [\n "}, {"start_line": 45000, "end_line": 46599, "belongs_to": {"file_name": "test_cacheprovider.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "ding=\"UTF-8\") == \"custom\"\n\n\ndef test_preserve_keys_order(pytester: Pytester) -> None:\n    \"\"\"Ensure keys order is preserved when saving dicts (#9205).\"\"\"\n    from _pytest.cacheprovider import Cache\n\n    config = pytester.parseconfig()\n    cache = Cache.for_config(config, _ispytest=True)\n    cache.set(\"foo\", {\"z\": 1, \"b\": 2, \"a\": 3, \"d\": 10})\n    read_back = cache.get(\"foo\", None)\n    assert list(read_back.items()) == [(\"z\", 1), (\"b\", 2), (\"a\", 3), (\"d\", 10)]\n\n\ndef test_does_not_create_boilerplate_in_existing_dirs(pytester: Pytester) -> None:\n    from _pytest.cacheprovider import Cache\n\n    pytester.makeini(\n        \"\"\"\n        [pytest]\n        cache_dir = .\n        \"\"\"\n    )\n    config = pytester.parseconfig()\n    cache = Cache.for_config(config, _ispytest=True)\n    cache.set(\"foo\", \"bar\")\n\n    assert os.path.isdir(\"v\")  # cache contents\n    assert not os.path.exists(\".gitignore\")\n    assert not os.path.exists(\"README.md\")\n\n\ndef test_cachedir_tag(pytester: Pytester) -> None:\n    \"\"\"Ensure we automatically create CACHEDIR.TAG file in the pytest_cache directory (#4278).\"\"\"\n    from _pytest.cacheprovider import Cache\n    from _pytest.cacheprovider import CACHEDIR_TAG_CONTENT\n\n    config = pytester.parseconfig()\n    cache = Cache.for_config(config, _ispytest=True)\n    cache.set(\"foo\", \"bar\")\n    cachedir_tag_path = cache._cachedir.joinpath(\"CACHEDIR.TAG\")\n    assert cachedir_tag_path.read_bytes() == CACHEDIR_TAG_CONTENT\n\n\ndef test_clioption_with_cacheshow_and_help(pytester: Pytester) -> None:\n    result = pytester.runpytest(\"--cache-show\", \"--help\")\n    assert result.ret == 0\n"}, {"start_line": 6000, "end_line": 8000, "belongs_to": {"file_name": "cacheprovider.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "            self.warn(\n                f\"could not create cache path {path}: {exc}\",\n                _ispytest=True,\n            )\n            return\n        data = json.dumps(value, ensure_ascii=False, indent=2)\n        try:\n            f = path.open(\"w\", encoding=\"UTF-8\")\n        except OSError as exc:\n            self.warn(\n                f\"cache could not write path {path}: {exc}\",\n                _ispytest=True,\n            )\n        else:\n            with f:\n                f.write(data)\n\n    def _ensure_cache_dir_and_supporting_files(self) -> None:\n        \"\"\"Create the cache dir and its supporting files.\"\"\"\n        if self._cachedir.is_dir():\n            return\n\n        self._cachedir.parent.mkdir(parents=True, exist_ok=True)\n        with tempfile.TemporaryDirectory(\n            prefix=\"pytest-cache-files-\",\n            dir=self._cachedir.parent,\n        ) as newpath:\n            path = Path(newpath)\n\n            # Reset permissions to the default, see #12308.\n            # Note: there's no way to get the current umask atomically, eek.\n            umask = os.umask(0o022)\n            os.umask(umask)\n            path.chmod(0o777 - umask)\n\n            with open(path.joinpath(\"README.md\"), \"x\", encoding=\"UTF-8\") as f:\n                f.write(README_CONTENT)\n            with open(path.joinpath(\".gitignore\"), \"x\", encoding=\"UTF-8\") as f:\n                f.write(\"# Created by pytest automatically.\\n*\\n\")\n            with open(path.joinpath(\"CACHEDIR.TAG\"), \"xb\") as f:\n                f.write(CACHEDIR_TAG_CONTENT)\n\n            try:\n                path.rename(self._cachedir)\n            except OSError as e:\n                # If 2 concurrent pytests both race to the rename, the loser\n                # gets \"Directory not empty\" from the rename. In this case,\n                # everything is handled so just continue (while letting the\n                # temporary directory be cleaned up).\n                # On Windows, the error is a FileExistsError which translates to "}, {"start_line": 44000, "end_line": 46000, "belongs_to": {"file_name": "test_cacheprovider.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "st.mark.parametrize(\"action\", list(Action))\ndef test_gitignore(\n    pytester: Pytester,\n    action: Action,\n) -> None:\n    \"\"\"Ensure we automatically create .gitignore file in the pytest_cache directory (#3286).\"\"\"\n    from _pytest.cacheprovider import Cache\n\n    config = pytester.parseconfig()\n    cache = Cache.for_config(config, _ispytest=True)\n    if action == Action.MKDIR:\n        cache.mkdir(\"foo\")\n    elif action == Action.SET:\n        cache.set(\"foo\", \"bar\")\n    else:\n        assert_never(action)\n    msg = \"# Created by pytest automatically.\\n*\\n\"\n    gitignore_path = cache._cachedir.joinpath(\".gitignore\")\n    assert gitignore_path.read_text(encoding=\"UTF-8\") == msg\n\n    # Does not overwrite existing/custom one.\n    gitignore_path.write_text(\"custom\", encoding=\"utf-8\")\n    if action == Action.MKDIR:\n        cache.mkdir(\"something\")\n    elif action == Action.SET:\n        cache.set(\"something\", \"else\")\n    else:\n        assert_never(action)\n    assert gitignore_path.read_text(encoding=\"UTF-8\") == \"custom\"\n\n\ndef test_preserve_keys_order(pytester: Pytester) -> None:\n    \"\"\"Ensure keys order is preserved when saving dicts (#9205).\"\"\"\n    from _pytest.cacheprovider import Cache\n\n    config = pytester.parseconfig()\n    cache = Cache.for_config(config, _ispytest=True)\n    cache.set(\"foo\", {\"z\": 1, \"b\": 2, \"a\": 3, \"d\": 10})\n    read_back = cache.get(\"foo\", None)\n    assert list(read_back.items()) == [(\"z\", 1), (\"b\", 2), (\"a\", 3), (\"d\", 10)]\n\n\ndef test_does_not_create_boilerplate_in_existing_dirs(pytester: Pytester) -> None:\n    from _pytest.cacheprovider import Cache\n\n    pytester.makeini(\n        \"\"\"\n        [pytest]\n        cache_dir = .\n        \"\"\"\n    )\n    config = pytester.parseconfig()\n    cache = Cache.for_config(config, _ispytest=True)\n    cache.set(\"foo\", \"bar\")\n\n    assert os.path.isdir(\"v\")  # cache contents\n    assert not os.path.exists(\".gitignore\")\n    assert not os.path.exists(\"README.md\")\n\n\ndef test_cachedir_tag(pytester: Pytester) -> None:\n    \"\"\"Ens"}, {"start_line": 4000, "end_line": 6000, "belongs_to": {"file_name": "test_cacheprovider.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "/nodeids: *\",\n                '    config.cache.set(\"cache/nodeids\", sorted(self.cached_nodeids))',\n                \"*1 failed, 2 warnings in*\",\n            ]\n        )\n\n    def test_config_cache(self, pytester: Pytester) -> None:\n        pytester.makeconftest(\n            \"\"\"\n            def pytest_configure(config):\n                # see that we get cache information early on\n                assert hasattr(config, \"cache\")\n        \"\"\"\n        )\n        pytester.makepyfile(\n            \"\"\"\n            def test_session(pytestconfig):\n                assert hasattr(pytestconfig, \"cache\")\n        \"\"\"\n        )\n        result = pytester.runpytest()\n        assert result.ret == 0\n        result.stdout.fnmatch_lines([\"*1 passed*\"])\n\n    def test_cachefuncarg(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n            def test_cachefuncarg(cache):\n                val = cache.get(\"some/thing\", None)\n                assert val is None\n                cache.set(\"some/thing\", [1])\n                pytest.raises(TypeError, lambda: cache.get(\"some/thing\"))\n                val = cache.get(\"some/thing\", [])\n                assert val == [1]\n        \"\"\"\n        )\n        result = pytester.runpytest()\n        assert result.ret == 0\n        result.stdout.fnmatch_lines([\"*1 passed*\"])\n\n    def test_custom_rel_cache_dir(self, pytester: Pytester) -> None:\n        rel_cache_dir = os.path.join(\"custom_cache_dir\", \"subdir\")\n        pytester.makeini(\n            f\"\"\"\n            [pytest]\n            cache_dir = {rel_cache_dir}\n        \"\"\"\n        )\n        pytester.makepyfile(test_errored=\"def test_error():\\n    assert False\")\n        pytester.runpytest()\n        assert pytester.path.joinpath(rel_cache_dir).is_dir()\n\n    def test_custom_abs_cache_dir(\n        self, pytester: Pytester, tmp_path_factory: TempPathFactory\n    ) -> None:\n        tmp = tmp_path_factory.mktemp(\"tmp\")\n        abs_cache_dir = tmp / \"custom_cache_dir\"\n        "}, {"start_line": 8000, "end_line": 10000, "belongs_to": {"file_name": "test_cacheprovider.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "    def pytest_configure(config):\n            config.cache.set(\"my/name\", [1,2,3])\n            config.cache.set(\"my/hello\", \"world\")\n            config.cache.set(\"other/some\", {1:2})\n            dp = config.cache.mkdir(\"mydb\")\n            dp.joinpath(\"hello\").touch()\n            dp.joinpath(\"world\").touch()\n    \"\"\"\n    )\n    result = pytester.runpytest()\n    assert result.ret == 5  # no tests executed\n\n    result = pytester.runpytest(\"--cache-show\")\n    result.stdout.fnmatch_lines(\n        [\n            \"*cachedir:*\",\n            \"*- cache values for '[*]' -*\",\n            \"cache/nodeids contains:\",\n            \"my/name contains:\",\n            \"  [1, 2, 3]\",\n            \"other/some contains:\",\n            \"  {*'1': 2}\",\n            \"*- cache directories for '[*]' -*\",\n            \"*mydb/hello*length 0*\",\n            \"*mydb/world*length 0*\",\n        ]\n    )\n    assert result.ret == 0\n\n    result = pytester.runpytest(\"--cache-show\", \"*/hello\")\n    result.stdout.fnmatch_lines(\n        [\n            \"*cachedir:*\",\n            \"*- cache values for '[*]/hello' -*\",\n            \"my/hello contains:\",\n            \"  *'world'\",\n            \"*- cache directories for '[*]/hello' -*\",\n            \"d/mydb/hello*length 0*\",\n        ]\n    )\n    stdout = result.stdout.str()\n    assert \"other/some\" not in stdout\n    assert \"d/mydb/world\" not in stdout\n    assert result.ret == 0\n\n\nclass TestLastFailed:\n    def test_lastfailed_usecase(\n        self, pytester: Pytester, monkeypatch: MonkeyPatch\n    ) -> None:\n        monkeypatch.setattr(\"sys.dont_write_bytecode\", True)\n        p = pytester.makepyfile(\n            \"\"\"\n            def test_1(): assert 0\n            def test_2(): assert 0\n            def test_3(): assert 1\n            \"\"\"\n        )\n        result = pytester.runpytest(str(p))\n        result.stdout.fnmatch_lines([\"*2 failed*\"])\n        p = pytester.makepyfile(\n            \"\"\"\n            def test_1(): assert 1\n            def test_2(): assert 1\n            def test_3(): asse"}], "retrieved_count": 10, "cost_time": 1.184800386428833}
{"question": "How would you refactor a minimal test function like test_1 to implement a parameterized testing strategy that maintains backward compatibility while enabling data-driven test execution across multiple input scenarios?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"start_line": 12000, "end_line": 14000, "belongs_to": {"file_name": "collect.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing/python", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "elf, pytester: Pytester) -> None:\n        def func1():\n            pass\n\n        def func2():\n            pass\n\n        f1 = self.make_function(pytester, name=\"name\", callobj=func1)\n        assert f1 == f1\n        f2 = self.make_function(\n            pytester, name=\"name\", callobj=func2, originalname=\"foobar\"\n        )\n        assert f1 != f2\n\n    def test_repr_produces_actual_test_id(self, pytester: Pytester) -> None:\n        f = self.make_function(\n            pytester, name=r\"test[\\xe5]\", callobj=self.test_repr_produces_actual_test_id\n        )\n        assert repr(f) == r\"<Function test[\\xe5]>\"\n\n    def test_issue197_parametrize_emptyset(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n            @pytest.mark.parametrize('arg', [])\n            def test_function(arg):\n                pass\n        \"\"\"\n        )\n        reprec = pytester.inline_run()\n        reprec.assertoutcome(skipped=1)\n\n    def test_single_tuple_unwraps_values(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n            @pytest.mark.parametrize(('arg',), [(1,)])\n            def test_function(arg):\n                assert arg == 1\n        \"\"\"\n        )\n        reprec = pytester.inline_run()\n        reprec.assertoutcome(passed=1)\n\n    def test_issue213_parametrize_value_no_equal(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n            class A(object):\n                def __eq__(self, other):\n                    raise ValueError(\"not possible\")\n            @pytest.mark.parametrize('arg', [A()])\n            def test_function(arg):\n                assert arg.__class__.__name__ == \"A\"\n        \"\"\"\n        )\n        reprec = pytester.inline_run(\"--fulltrace\")\n        reprec.assertoutcome(passed=1)\n\n    def test_parametrize_with_non_hashable_values(self, pytester: Pytester) -> None:\n        \"\"\"Test parametrization with non-hashable "}, {"start_line": 32000, "end_line": 34000, "belongs_to": {"file_name": "metafunc.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing/python", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "   \"\"\"\n            import pytest\n\n            @pytest.mark.parametrize('x, y', [('a', 'b')])\n            def test_simple(x, y=1):\n                assert len(x) == 1\n        \"\"\"\n        )\n        result = pytester.runpytest(\"--collect-only\")\n        result.stdout.fnmatch_lines(\n            [\"*already takes an argument 'y' with a default value\"]\n        )\n\n    def test_parametrize_functional(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n            def pytest_generate_tests(metafunc):\n                metafunc.parametrize('x', [1,2], indirect=True)\n                metafunc.parametrize('y', [2])\n            @pytest.fixture\n            def x(request):\n                return request.param * 10\n\n            def test_simple(x,y):\n                assert x in (10,20)\n                assert y == 2\n        \"\"\"\n        )\n        result = pytester.runpytest(\"-v\")\n        result.stdout.fnmatch_lines(\n            [\"*test_simple*1-2*\", \"*test_simple*2-2*\", \"*2 passed*\"]\n        )\n\n    def test_parametrize_onearg(self) -> None:\n        metafunc = self.Metafunc(lambda x: None)\n        metafunc.parametrize(\"x\", [1, 2])\n        assert len(metafunc._calls) == 2\n        assert metafunc._calls[0].params == dict(x=1)\n        assert metafunc._calls[0].id == \"1\"\n        assert metafunc._calls[1].params == dict(x=2)\n        assert metafunc._calls[1].id == \"2\"\n\n    def test_parametrize_onearg_indirect(self) -> None:\n        metafunc = self.Metafunc(lambda x: None)\n        metafunc.parametrize(\"x\", [1, 2], indirect=True)\n        assert metafunc._calls[0].params == dict(x=1)\n        assert metafunc._calls[0].id == \"1\"\n        assert metafunc._calls[1].params == dict(x=2)\n        assert metafunc._calls[1].id == \"2\"\n\n    def test_parametrize_twoargs(self) -> None:\n        metafunc = self.Metafunc(lambda x, y: None)\n        metafunc.parametrize((\"x\", \"y\"), [(1, 2), (3, 4)])\n        assert len(metafunc._calls) == 2\n        assert metafunc._c"}, {"start_line": 68000, "end_line": 70000, "belongs_to": {"file_name": "metafunc.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing/python", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "else (2, 0)\n        reprec.assertoutcome(passed=passed, failed=failed)\n\n    def test_pytest_make_parametrize_id(self, pytester: Pytester) -> None:\n        pytester.makeconftest(\n            \"\"\"\n            def pytest_make_parametrize_id(config, val):\n                return str(val * 2)\n        \"\"\"\n        )\n        pytester.makepyfile(\n            \"\"\"\n                import pytest\n\n                @pytest.mark.parametrize(\"x\", range(2))\n                def test_func(x):\n                    pass\n                \"\"\"\n        )\n        result = pytester.runpytest(\"-v\")\n        result.stdout.fnmatch_lines([\"*test_func*0*PASS*\", \"*test_func*2*PASS*\"])\n\n    def test_pytest_make_parametrize_id_with_argname(self, pytester: Pytester) -> None:\n        pytester.makeconftest(\n            \"\"\"\n            def pytest_make_parametrize_id(config, val, argname):\n                return str(val * 2 if argname == 'x' else val * 10)\n        \"\"\"\n        )\n        pytester.makepyfile(\n            \"\"\"\n                import pytest\n\n                @pytest.mark.parametrize(\"x\", range(2))\n                def test_func_a(x):\n                    pass\n\n                @pytest.mark.parametrize(\"y\", [1])\n                def test_func_b(y):\n                    pass\n                \"\"\"\n        )\n        result = pytester.runpytest(\"-v\")\n        result.stdout.fnmatch_lines(\n            [\"*test_func_a*0*PASS*\", \"*test_func_a*2*PASS*\", \"*test_func_b*10*PASS*\"]\n        )\n\n    def test_parametrize_positional_args(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n\n            @pytest.mark.parametrize(\"a\", [1], False)\n            def test_foo(a):\n                pass\n        \"\"\"\n        )\n        result = pytester.runpytest()\n        result.assert_outcomes(passed=1)\n\n    def test_parametrize_iterator(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            import itertools\n            import pytest\n\n            id_par"}, {"start_line": 24000, "end_line": 26000, "belongs_to": {"file_name": "metafunc.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing/python", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "_non_string.py::test_int[1] PASSED\",\n                \"test_parametrize_ids_returns_non_string.py::test_int[2.0] PASSED\",\n                \"test_parametrize_ids_returns_non_string.py::test_int[True] PASSED\",\n            ]\n        )\n\n    def test_idmaker_with_ids(self) -> None:\n        result = IdMaker(\n            (\"a\", \"b\"),\n            [pytest.param(1, 2), pytest.param(3, 4)],\n            None,\n            [\"a\", None],\n            None,\n            None,\n            None,\n        ).make_unique_parameterset_ids()\n        assert result == [\"a\", \"3-4\"]\n\n    def test_idmaker_with_paramset_id(self) -> None:\n        result = IdMaker(\n            (\"a\", \"b\"),\n            [pytest.param(1, 2, id=\"me\"), pytest.param(3, 4, id=\"you\")],\n            None,\n            [\"a\", None],\n            None,\n            None,\n            None,\n        ).make_unique_parameterset_ids()\n        assert result == [\"me\", \"you\"]\n\n    def test_idmaker_with_ids_unique_names(self) -> None:\n        result = IdMaker(\n            (\"a\"),\n            list(map(pytest.param, [1, 2, 3, 4, 5])),\n            None,\n            [\"a\", \"a\", \"b\", \"c\", \"b\"],\n            None,\n            None,\n            None,\n        ).make_unique_parameterset_ids()\n        assert result == [\"a0\", \"a1\", \"b0\", \"c\", \"b1\"]\n\n    def test_parametrize_indirect(self) -> None:\n        \"\"\"#714\"\"\"\n\n        def func(x, y):\n            pass\n\n        metafunc = self.Metafunc(func)\n        metafunc.parametrize(\"x\", [1], indirect=True)\n        metafunc.parametrize(\"y\", [2, 3], indirect=True)\n        assert len(metafunc._calls) == 2\n        assert metafunc._calls[0].params == dict(x=1, y=2)\n        assert metafunc._calls[1].params == dict(x=1, y=3)\n\n    def test_parametrize_indirect_list(self) -> None:\n        \"\"\"#714\"\"\"\n\n        def func(x, y):\n            pass\n\n        metafunc = self.Metafunc(func)\n        metafunc.parametrize(\"x, y\", [(\"a\", \"b\")], indirect=[\"x\"])\n        assert metafunc._calls[0].params == dict(x=\"a\", y=\"b\")\n        # Since `y"}, {"start_line": 37000, "end_line": 39000, "belongs_to": {"file_name": "metafunc.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing/python", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "e2', \"arg2\": \"value2\"}]]\n\n               def test_1(self, arg, arg2):\n                  pass\n\n               def test_2(self, arg2, arg):\n                  pass\n\n               def test_3(self, arg, arg2):\n                  pass\n        \"\"\"\n        )\n        result = pytester.runpytest(\"-v\")\n        assert result.ret == 0\n        result.stdout.fnmatch_lines(\n            \"\"\"\n            *test_1*1*\n            *test_2*1*\n            *test_3*1*\n            *test_1*2*\n            *test_2*2*\n            *test_3*2*\n            *6 passed*\n        \"\"\"\n        )\n\n\nclass TestMetafuncFunctional:\n    def test_attributes(self, pytester: Pytester) -> None:\n        p = pytester.makepyfile(\n            \"\"\"\n            # assumes that generate/provide runs in the same process\n            import sys, pytest\n            def pytest_generate_tests(metafunc):\n                metafunc.parametrize('metafunc', [metafunc])\n\n            @pytest.fixture\n            def metafunc(request):\n                return request.param\n\n            def test_function(metafunc, pytestconfig):\n                assert metafunc.config == pytestconfig\n                assert metafunc.module.__name__ == __name__\n                assert metafunc.function == test_function\n                assert metafunc.cls is None\n\n            class TestClass(object):\n                def test_method(self, metafunc, pytestconfig):\n                    assert metafunc.config == pytestconfig\n                    assert metafunc.module.__name__ == __name__\n                    unbound = TestClass.test_method\n                    assert metafunc.function == unbound\n                    assert metafunc.cls == TestClass\n        \"\"\"\n        )\n        result = pytester.runpytest(p, \"-v\")\n        result.assert_outcomes(passed=2)\n\n    def test_two_functions(self, pytester: Pytester) -> None:\n        p = pytester.makepyfile(\n            \"\"\"\n            def pytest_generate_tests(metafunc):\n                metafunc.parametrize('arg1', [10, 20], ids=['0"}, {"start_line": 45000, "end_line": 47000, "belongs_to": {"file_name": "python.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "            unparametrized:         t\n            parametrize [\"x\", \"y\"]: t[x], t[y]\n            parametrize [1, 2]:     t[x-1], t[x-2], t[y-1], t[y-2]\n\n        :param argnames:\n            A comma-separated string denoting one or more argument names, or\n            a list/tuple of argument strings.\n\n        :param argvalues:\n            The list of argvalues determines how often a test is invoked with\n            different argument values.\n\n            If only one argname was specified argvalues is a list of values.\n            If N argnames were specified, argvalues must be a list of\n            N-tuples, where each tuple-element specifies a value for its\n            respective argname.\n\n        :param indirect:\n            A list of arguments' names (subset of argnames) or a boolean.\n            If True the list contains all names from the argnames. Each\n            argvalue corresponding to an argname in this list will\n            be passed as request.param to its respective argname fixture\n            function so that it can perform more expensive setups during the\n            setup phase of a test rather than at collection time.\n\n        :param ids:\n            Sequence of (or generator for) ids for ``argvalues``,\n            or a callable to return part of the id for each argvalue.\n\n            With sequences (and generators like ``itertools.count()``) the\n            returned ids should be of type ``string``, ``int``, ``float``,\n            ``bool``, or ``None``.\n            They are mapped to the corresponding index in ``argvalues``.\n            ``None`` means to use the auto-generated id.\n\n            .. versionadded:: 8.4\n                :ref:`hidden-param` means to hide the parameter set\n                from the test name. Can only be used at most 1 time, as\n                test names need to be unique.\n\n            If it is a callable it will be called for each entry in\n            ``argvalues``, and the return value is used as part of the\n            a"}, {"start_line": 18000, "end_line": 20000, "belongs_to": {"file_name": "acceptance_test.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "eType(\"myplugin\")\n        monkeypatch.setitem(sys.modules, \"myplugin\", mod)\n        assert pytest.main(args=[str(pytester.path)], plugins=[\"myplugin\"]) == 0\n\n    def test_parametrized_with_bytes_regex(self, pytester: Pytester) -> None:\n        p = pytester.makepyfile(\n            \"\"\"\n            import re\n            import pytest\n            @pytest.mark.parametrize('r', [re.compile(b'foo')])\n            def test_stuff(r):\n                pass\n        \"\"\"\n        )\n        res = pytester.runpytest(p)\n        res.stdout.fnmatch_lines([\"*1 passed*\"])\n\n    def test_parametrized_with_null_bytes(self, pytester: Pytester) -> None:\n        \"\"\"Test parametrization with values that contain null bytes and unicode characters (#2644, #2957)\"\"\"\n        p = pytester.makepyfile(\n            \"\"\"\\\n            import pytest\n\n            @pytest.mark.parametrize(\"data\", [b\"\\\\x00\", \"\\\\x00\", 'ao'])\n            def test_foo(data):\n                assert data\n            \"\"\"\n        )\n        res = pytester.runpytest(p)\n        res.assert_outcomes(passed=3)\n\n    # Warning ignore because of:\n    # https://github.com/python/cpython/issues/85308\n    # Can be removed once Python<3.12 support is dropped.\n    @pytest.mark.filterwarnings(\"ignore:'encoding' argument not specified\")\n    def test_command_line_args_from_file(\n        self, pytester: Pytester, tmp_path: Path\n    ) -> None:\n        pytester.makepyfile(\n            test_file=\"\"\"\n            import pytest\n\n            class TestClass:\n                @pytest.mark.parametrize(\"a\", [\"x\",\"y\"])\n                def test_func(self, a):\n                    pass\n            \"\"\"\n        )\n        tests = [\n            \"test_file.py::TestClass::test_func[x]\",\n            \"test_file.py::TestClass::test_func[y]\",\n            \"-q\",\n        ]\n        args_file = pytester.maketxtfile(tests=\"\\n\".join(tests))\n        result = pytester.runpytest(f\"@{args_file}\")\n        result.assert_outcomes(failed=0, passed=2)\n\n\nclass TestInvocationVariants:\n    def"}, {"start_line": 40000, "end_line": 42000, "belongs_to": {"file_name": "metafunc.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing/python", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "ster.makepyfile(\n            \"\"\"\n            class TestClass(object):\n                def pytest_generate_tests(self, metafunc):\n                    metafunc.parametrize('hello', ['world'], ids=['hellow'])\n\n                def test_myfunc(self, hello):\n                    assert hello == \"world\"\n        \"\"\"\n        )\n        result = pytester.runpytest(\"-v\", p)\n        result.stdout.fnmatch_lines([\"*test_myfunc*hello*PASS*\", \"*1 passed*\"])\n\n    def test_two_functions_not_same_instance(self, pytester: Pytester) -> None:\n        p = pytester.makepyfile(\n            \"\"\"\n            def pytest_generate_tests(metafunc):\n                metafunc.parametrize('arg1', [10, 20], ids=[\"0\", \"1\"])\n\n            class TestClass(object):\n                def test_func(self, arg1):\n                    assert not hasattr(self, 'x')\n                    self.x = 1\n        \"\"\"\n        )\n        result = pytester.runpytest(\"-v\", p)\n        result.stdout.fnmatch_lines(\n            [\"*test_func*0*PASS*\", \"*test_func*1*PASS*\", \"*2 pass*\"]\n        )\n\n    def test_issue28_setup_method_in_generate_tests(self, pytester: Pytester) -> None:\n        p = pytester.makepyfile(\n            \"\"\"\n            def pytest_generate_tests(metafunc):\n                metafunc.parametrize('arg1', [1])\n\n            class TestClass(object):\n                def test_method(self, arg1):\n                    assert arg1 == self.val\n                def setup_method(self, func):\n                    self.val = 1\n            \"\"\"\n        )\n        result = pytester.runpytest(p)\n        result.assert_outcomes(passed=1)\n\n    def test_parametrize_functional2(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            def pytest_generate_tests(metafunc):\n                metafunc.parametrize(\"arg1\", [1,2])\n                metafunc.parametrize(\"arg2\", [4,5])\n            def test_hello(arg1, arg2):\n                assert 0, (arg1, arg2)\n        \"\"\"\n        )\n        result = pytester.runpytest()\n   "}, {"start_line": 31000, "end_line": 33000, "belongs_to": {"file_name": "metafunc.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing/python", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": " [('a', 'b')], indirect=['y'])\n            def test_simple(x):\n                assert len(x) == 3\n        \"\"\"\n        )\n        result = pytester.runpytest(\"--collect-only\")\n        result.stdout.fnmatch_lines([\"*uses no fixture 'y'*\"])\n\n    def test_parametrize_argument_not_in_indirect_list(\n        self, pytester: Pytester\n    ) -> None:\n        \"\"\"#714\"\"\"\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n            @pytest.fixture(scope='function')\n            def x(request):\n                return request.param * 3\n\n            @pytest.mark.parametrize('x, y', [('a', 'b')], indirect=['x'])\n            def test_simple(x):\n                assert len(x) == 3\n        \"\"\"\n        )\n        result = pytester.runpytest(\"--collect-only\")\n        result.stdout.fnmatch_lines([\"*uses no argument 'y'*\"])\n\n    def test_parametrize_gives_indicative_error_on_function_with_default_argument(\n        self, pytester: Pytester\n    ) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n\n            @pytest.mark.parametrize('x, y', [('a', 'b')])\n            def test_simple(x, y=1):\n                assert len(x) == 1\n        \"\"\"\n        )\n        result = pytester.runpytest(\"--collect-only\")\n        result.stdout.fnmatch_lines(\n            [\"*already takes an argument 'y' with a default value\"]\n        )\n\n    def test_parametrize_functional(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n            def pytest_generate_tests(metafunc):\n                metafunc.parametrize('x', [1,2], indirect=True)\n                metafunc.parametrize('y', [2])\n            @pytest.fixture\n            def x(request):\n                return request.param * 10\n\n            def test_simple(x,y):\n                assert x in (10,20)\n                assert y == 2\n        \"\"\"\n        )\n        result = pytester.runpytest(\"-v\")\n        result.stdout.fnmatch_lines(\n            [\"*test_simple*1-2*\", \"*test_"}, {"start_line": 33000, "end_line": 35000, "belongs_to": {"file_name": "metafunc.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing/python", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "simple*2-2*\", \"*2 passed*\"]\n        )\n\n    def test_parametrize_onearg(self) -> None:\n        metafunc = self.Metafunc(lambda x: None)\n        metafunc.parametrize(\"x\", [1, 2])\n        assert len(metafunc._calls) == 2\n        assert metafunc._calls[0].params == dict(x=1)\n        assert metafunc._calls[0].id == \"1\"\n        assert metafunc._calls[1].params == dict(x=2)\n        assert metafunc._calls[1].id == \"2\"\n\n    def test_parametrize_onearg_indirect(self) -> None:\n        metafunc = self.Metafunc(lambda x: None)\n        metafunc.parametrize(\"x\", [1, 2], indirect=True)\n        assert metafunc._calls[0].params == dict(x=1)\n        assert metafunc._calls[0].id == \"1\"\n        assert metafunc._calls[1].params == dict(x=2)\n        assert metafunc._calls[1].id == \"2\"\n\n    def test_parametrize_twoargs(self) -> None:\n        metafunc = self.Metafunc(lambda x, y: None)\n        metafunc.parametrize((\"x\", \"y\"), [(1, 2), (3, 4)])\n        assert len(metafunc._calls) == 2\n        assert metafunc._calls[0].params == dict(x=1, y=2)\n        assert metafunc._calls[0].id == \"1-2\"\n        assert metafunc._calls[1].params == dict(x=3, y=4)\n        assert metafunc._calls[1].id == \"3-4\"\n\n    def test_high_scoped_parametrize_reordering(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n\n            @pytest.mark.parametrize(\"arg2\", [3, 4])\n            @pytest.mark.parametrize(\"arg1\", [0, 1, 2], scope='module')\n            def test1(arg1, arg2):\n                pass\n\n            def test2():\n                pass\n\n            @pytest.mark.parametrize(\"arg1\", [0, 1, 2], scope='module')\n            def test3(arg1):\n                pass\n        \"\"\"\n        )\n        result = pytester.runpytest(\"--collect-only\")\n        result.stdout.re_match_lines(\n            [\n                r\"    <Function test1\\[0-3\\]>\",\n                r\"    <Function test3\\[0\\]>\",\n                r\"    <Function test1\\[0-4\\]>\",\n                r\"    <Function test3\\["}], "retrieved_count": 10, "cost_time": 1.188828945159912}
{"question": "How does the pytest_internalerror method iterate through split lines instead of directly passing the exception representation to write_line, and what control flow optimization could be applied if the exception representation format were guaranteed to be single-line?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"start_line": 49000, "end_line": 51000, "belongs_to": {"file_name": "code.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest/_code", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "      character, as doing so might break line continuations.\n        \"\"\"\n        if not self.lines:\n            return\n\n        if self.style == \"value\":\n            # Using tw.write instead of tw.line for testing purposes due to TWMock implementation;\n            # lines written with TWMock.line and TWMock._write_source cannot be distinguished\n            # from each other, whereas lines written with TWMock.write are marked with TWMock.WRITE\n            for line in self.lines:\n                tw.write(line)\n                tw.write(\"\\n\")\n            return\n\n        # separate indents and source lines that are not failures: we want to\n        # highlight the code but not the indentation, which may contain markers\n        # such as \">   assert 0\"\n        fail_marker = f\"{FormattedExcinfo.fail_marker}   \"\n        indent_size = len(fail_marker)\n        indents: list[str] = []\n        source_lines: list[str] = []\n        failure_lines: list[str] = []\n        for index, line in enumerate(self.lines):\n            is_failure_line = line.startswith(fail_marker)\n            if is_failure_line:\n                # from this point on all lines are considered part of the failure\n                failure_lines.extend(self.lines[index:])\n                break\n            else:\n                indents.append(line[:indent_size])\n                source_lines.append(line[indent_size:])\n\n        tw._write_source(source_lines, indents)\n\n        # failure lines are always completely red and bold\n        for line in failure_lines:\n            tw.line(line, bold=True, red=True)\n\n    def toterminal(self, tw: TerminalWriter) -> None:\n        if self.style == \"short\":\n            if self.reprfileloc:\n                self.reprfileloc.toterminal(tw)\n            self._write_entry_lines(tw)\n            if self.reprlocals:\n                self.reprlocals.toterminal(tw, indent=\" \" * 8)\n            return\n\n        if self.reprfuncargs:\n            self.reprfuncargs.toterminal(tw)\n\n        self._write_"}, {"start_line": 44000, "end_line": 46000, "belongs_to": {"file_name": "code.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest/_code", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "       reprcrash = None\n            repr_chain += [(reprtraceback, reprcrash, descr)]\n\n            if e.__cause__ is not None and self.chain:\n                e = e.__cause__\n                excinfo_ = ExceptionInfo.from_exception(e) if e.__traceback__ else None\n                descr = \"The above exception was the direct cause of the following exception:\"\n            elif (\n                e.__context__ is not None and not e.__suppress_context__ and self.chain\n            ):\n                e = e.__context__\n                excinfo_ = ExceptionInfo.from_exception(e) if e.__traceback__ else None\n                descr = \"During handling of the above exception, another exception occurred:\"\n            else:\n                e = None\n        repr_chain.reverse()\n        return ExceptionChainRepr(repr_chain)\n\n\n@dataclasses.dataclass(eq=False)\nclass TerminalRepr:\n    def __str__(self) -> str:\n        # FYI this is called from pytest-xdist's serialization of exception\n        # information.\n        io = StringIO()\n        tw = TerminalWriter(file=io)\n        self.toterminal(tw)\n        return io.getvalue().strip()\n\n    def __repr__(self) -> str:\n        return f\"<{self.__class__} instance at {id(self):0x}>\"\n\n    def toterminal(self, tw: TerminalWriter) -> None:\n        raise NotImplementedError()\n\n\n# This class is abstract -- only subclasses are instantiated.\n@dataclasses.dataclass(eq=False)\nclass ExceptionRepr(TerminalRepr):\n    # Provided by subclasses.\n    reprtraceback: ReprTraceback\n    reprcrash: ReprFileLocation | None\n    sections: list[tuple[str, str, str]] = dataclasses.field(\n        init=False, default_factory=list\n    )\n\n    def addsection(self, name: str, content: str, sep: str = \"-\") -> None:\n        self.sections.append((name, content, sep))\n\n    def toterminal(self, tw: TerminalWriter) -> None:\n        for name, content, sep in self.sections:\n            tw.sep(sep, name)\n            tw.line(content)\n\n\n@dataclasses.dataclass(eq=False)\nclass ExceptionChainRep"}, {"start_line": 17000, "end_line": 19000, "belongs_to": {"file_name": "terminal.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "   self._tw.write(\"\\r\" + line + fill, **markup)\n\n    def write_sep(\n        self,\n        sep: str,\n        title: str | None = None,\n        fullwidth: int | None = None,\n        **markup: bool,\n    ) -> None:\n        self.ensure_newline()\n        self._tw.sep(sep, title, fullwidth, **markup)\n\n    def section(self, title: str, sep: str = \"=\", **kw: bool) -> None:\n        self._tw.sep(sep, title, **kw)\n\n    def line(self, msg: str, **kw: bool) -> None:\n        self._tw.line(msg, **kw)\n\n    def _add_stats(self, category: str, items: Sequence[Any]) -> None:\n        set_main_color = category not in self.stats\n        self.stats.setdefault(category, []).extend(items)\n        if set_main_color:\n            self._set_main_color()\n\n    def pytest_internalerror(self, excrepr: ExceptionRepr) -> bool:\n        for line in str(excrepr).split(\"\\n\"):\n            self.write_line(\"INTERNALERROR> \" + line)\n        return True\n\n    def pytest_warning_recorded(\n        self,\n        warning_message: warnings.WarningMessage,\n        nodeid: str,\n    ) -> None:\n        from _pytest.warnings import warning_record_to_str\n\n        fslocation = warning_message.filename, warning_message.lineno\n        message = warning_record_to_str(warning_message)\n\n        warning_report = WarningReport(\n            fslocation=fslocation, message=message, nodeid=nodeid\n        )\n        self._add_stats(\"warnings\", [warning_report])\n\n    def pytest_plugin_registered(self, plugin: _PluggyPlugin) -> None:\n        if self.config.option.traceconfig:\n            msg = f\"PLUGIN registered: {plugin}\"\n            # XXX This event may happen during setup/teardown time\n            #     which unfortunately captures our output here\n            #     which garbles our output if we use self.write_line.\n            self.write_line(msg)\n\n    def pytest_deselected(self, items: Sequence[Item]) -> None:\n        self._add_stats(\"deselected\", items)\n\n    def pytest_runtest_logstart(\n        self, nodeid: str, location: tuple[s"}, {"start_line": 43000, "end_line": 45000, "belongs_to": {"file_name": "code.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest/_code", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "        reprtraceback: ReprTraceback | ReprTracebackNative\n                if isinstance(e, BaseExceptionGroup):\n                    # don't filter any sub-exceptions since they shouldn't have any internal frames\n                    traceback = filter_excinfo_traceback(self.tbfilter, excinfo)\n                    reprtraceback = ReprTracebackNative(\n                        format_exception(\n                            type(excinfo.value),\n                            excinfo.value,\n                            traceback[0]._rawentry,\n                        )\n                    )\n                else:\n                    reprtraceback = self.repr_traceback(excinfo_)\n                reprcrash = excinfo_._getreprcrash()\n            else:\n                # Fallback to native repr if the exception doesn't have a traceback:\n                # ExceptionInfo objects require a full traceback to work.\n                reprtraceback = ReprTracebackNative(format_exception(type(e), e, None))\n                reprcrash = None\n            repr_chain += [(reprtraceback, reprcrash, descr)]\n\n            if e.__cause__ is not None and self.chain:\n                e = e.__cause__\n                excinfo_ = ExceptionInfo.from_exception(e) if e.__traceback__ else None\n                descr = \"The above exception was the direct cause of the following exception:\"\n            elif (\n                e.__context__ is not None and not e.__suppress_context__ and self.chain\n            ):\n                e = e.__context__\n                excinfo_ = ExceptionInfo.from_exception(e) if e.__traceback__ else None\n                descr = \"During handling of the above exception, another exception occurred:\"\n            else:\n                e = None\n        repr_chain.reverse()\n        return ExceptionChainRepr(repr_chain)\n\n\n@dataclasses.dataclass(eq=False)\nclass TerminalRepr:\n    def __str__(self) -> str:\n        # FYI this is called from pytest-xdist's serialization of exception\n        # information.\n   "}, {"start_line": 3000, "end_line": 5000, "belongs_to": {"file_name": "test_terminal.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "\n            result.stdout.fnmatch_lines([\".sF*\"])\n        result.stdout.fnmatch_lines(\n            [\"    def test_func():\", \">       assert 0\", \"E       assert 0\"]\n        )\n\n    def test_console_output_style_times_with_skipped_and_passed(\n        self, pytester: Pytester\n    ) -> None:\n        pytester.makepyfile(\n            test_repro=\"\"\"\n                def test_hello():\n                    pass\n            \"\"\",\n            test_repro_skip=\"\"\"\n                import pytest\n                pytest.importorskip(\"fakepackage_does_not_exist\")\n            \"\"\",\n        )\n        result = pytester.runpytest(\n            \"test_repro.py\",\n            \"test_repro_skip.py\",\n            \"-o\",\n            \"console_output_style=times\",\n        )\n\n        result.stdout.fnmatch_lines(\"* 1 passed, 1 skipped in *\")\n\n        combined = \"\\n\".join(result.stdout.lines + result.stderr.lines)\n        assert \"INTERNALERROR\" not in combined\n\n    def test_internalerror(self, pytester: Pytester, linecomp) -> None:\n        modcol = pytester.getmodulecol(\"def test_one(): pass\")\n        rep = TerminalReporter(modcol.config, file=linecomp.stringio)\n        with pytest.raises(ValueError) as excinfo:\n            raise ValueError(\"hello\")\n        rep.pytest_internalerror(excinfo.getrepr())\n        linecomp.assert_contains_lines([\"INTERNALERROR> *ValueError*hello*\"])\n\n    def test_writeline(self, pytester: Pytester, linecomp) -> None:\n        modcol = pytester.getmodulecol(\"def test_one(): pass\")\n        rep = TerminalReporter(modcol.config, file=linecomp.stringio)\n        rep.write_fspath_result(modcol.nodeid, \".\")\n        rep.write_line(\"hello world\")\n        lines = linecomp.stringio.getvalue().split(\"\\n\")\n        assert not lines[0]\n        assert lines[1].endswith(modcol.name + \" .\")\n        assert lines[2] == \"hello world\"\n\n    def test_show_runtest_logstart(self, pytester: Pytester, linecomp) -> None:\n        item = pytester.getitem(\"def test_func(): pass\")\n        tr = TerminalReporter(ite"}, {"start_line": 4000, "end_line": 6000, "belongs_to": {"file_name": "test_terminal.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "None:\n        modcol = pytester.getmodulecol(\"def test_one(): pass\")\n        rep = TerminalReporter(modcol.config, file=linecomp.stringio)\n        with pytest.raises(ValueError) as excinfo:\n            raise ValueError(\"hello\")\n        rep.pytest_internalerror(excinfo.getrepr())\n        linecomp.assert_contains_lines([\"INTERNALERROR> *ValueError*hello*\"])\n\n    def test_writeline(self, pytester: Pytester, linecomp) -> None:\n        modcol = pytester.getmodulecol(\"def test_one(): pass\")\n        rep = TerminalReporter(modcol.config, file=linecomp.stringio)\n        rep.write_fspath_result(modcol.nodeid, \".\")\n        rep.write_line(\"hello world\")\n        lines = linecomp.stringio.getvalue().split(\"\\n\")\n        assert not lines[0]\n        assert lines[1].endswith(modcol.name + \" .\")\n        assert lines[2] == \"hello world\"\n\n    def test_show_runtest_logstart(self, pytester: Pytester, linecomp) -> None:\n        item = pytester.getitem(\"def test_func(): pass\")\n        tr = TerminalReporter(item.config, file=linecomp.stringio)\n        item.config.pluginmanager.register(tr)\n        location = item.reportinfo()\n        tr.config.hook.pytest_runtest_logstart(\n            nodeid=item.nodeid, location=location, fspath=str(item.path)\n        )\n        linecomp.assert_contains_lines([\"*test_show_runtest_logstart.py*\"])\n\n    def test_runtest_location_shown_before_test_starts(\n        self, pytester: Pytester\n    ) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            def test_1():\n                import time\n                time.sleep(20)\n        \"\"\"\n        )\n        child = pytester.spawn_pytest(\"\")\n        child.expect(\".*test_runtest_location.*py\")\n        child.sendeof()\n        child.kill(15)\n\n    def test_report_collect_after_half_a_second(\n        self, pytester: Pytester, monkeypatch: MonkeyPatch\n    ) -> None:\n        \"\"\"Test for \"collecting\" being updated after 0.5s\"\"\"\n        pytester.makepyfile(\n            **{\n                \"test1.py\": \"\"\"\n               "}, {"start_line": 42000, "end_line": 44000, "belongs_to": {"file_name": "code.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest/_code", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "ack[-max_frames:]  # type: ignore\n        else:\n            if recursionindex is not None:\n                extraline = \"!!! Recursion detected (same locals & position)\"\n                traceback = traceback[: recursionindex + 1]\n            else:\n                extraline = None\n\n        return traceback, extraline\n\n    def repr_excinfo(self, excinfo: ExceptionInfo[BaseException]) -> ExceptionChainRepr:\n        repr_chain: list[tuple[ReprTraceback, ReprFileLocation | None, str | None]] = []\n        e: BaseException | None = excinfo.value\n        excinfo_: ExceptionInfo[BaseException] | None = excinfo\n        descr = None\n        seen: set[int] = set()\n        while e is not None and id(e) not in seen:\n            seen.add(id(e))\n\n            if excinfo_:\n                # Fall back to native traceback as a temporary workaround until\n                # full support for exception groups added to ExceptionInfo.\n                # See https://github.com/pytest-dev/pytest/issues/9159\n                reprtraceback: ReprTraceback | ReprTracebackNative\n                if isinstance(e, BaseExceptionGroup):\n                    # don't filter any sub-exceptions since they shouldn't have any internal frames\n                    traceback = filter_excinfo_traceback(self.tbfilter, excinfo)\n                    reprtraceback = ReprTracebackNative(\n                        format_exception(\n                            type(excinfo.value),\n                            excinfo.value,\n                            traceback[0]._rawentry,\n                        )\n                    )\n                else:\n                    reprtraceback = self.repr_traceback(excinfo_)\n                reprcrash = excinfo_._getreprcrash()\n            else:\n                # Fallback to native repr if the exception doesn't have a traceback:\n                # ExceptionInfo objects require a full traceback to work.\n                reprtraceback = ReprTracebackNative(format_exception(type(e), e, None))\n         "}, {"start_line": 35000, "end_line": 37000, "belongs_to": {"file_name": "terminal.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "xcrepr is not None\n        assert excrepr.reprcrash is not None\n        msg = excrepr.reprcrash.message\n        self.write_sep(\"!\", msg)\n        if \"KeyboardInterrupt\" in msg:\n            if self.config.option.fulltrace:\n                excrepr.toterminal(self._tw)\n            else:\n                excrepr.reprcrash.toterminal(self._tw)\n                self._tw.line(\n                    \"(to show a full traceback on KeyboardInterrupt use --full-trace)\",\n                    yellow=True,\n                )\n\n    def _locationline(\n        self, nodeid: str, fspath: str, lineno: int | None, domain: str\n    ) -> str:\n        def mkrel(nodeid: str) -> str:\n            line = self.config.cwd_relative_nodeid(nodeid)\n            if domain and line.endswith(domain):\n                line = line[: -len(domain)]\n                values = domain.split(\"[\")\n                values[0] = values[0].replace(\".\", \"::\")  # don't replace '.' in params\n                line += \"[\".join(values)\n            return line\n\n        # fspath comes from testid which has a \"/\"-normalized path.\n        if fspath:\n            res = mkrel(nodeid)\n            if self.verbosity >= 2 and nodeid.split(\"::\")[0] != fspath.replace(\n                \"\\\\\", nodes.SEP\n            ):\n                res += \" <- \" + bestrelpath(self.startpath, Path(fspath))\n        else:\n            res = \"[location]\"\n        return res + \" \"\n\n    def _getfailureheadline(self, rep):\n        head_line = rep.head_line\n        if head_line:\n            return head_line\n        return \"test session\"  # XXX?\n\n    def _getcrashline(self, rep):\n        try:\n            return str(rep.longrepr.reprcrash)\n        except AttributeError:\n            try:\n                return str(rep.longrepr)[:50]\n            except AttributeError:\n                return \"\"\n\n    #\n    # Summaries for sessionfinish.\n    #\n    def getreports(self, name: str):\n        return [x for x in self.stats.get(name, ()) if not hasattr(x, \"_pdbshown\")]\n\n    def summary_war"}, {"start_line": 53000, "end_line": 55000, "belongs_to": {"file_name": "test_excinfo.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing/code", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "IO()\n        tw = TerminalWriter(file=file)\n        tw.hasmarkup = False\n        r.toterminal(tw)\n\n        matcher = LineMatcher(file.getvalue().splitlines())\n        matcher.fnmatch_lines(\n            [\n                \"ValueError: invalid value\",\n                description,\n                \"* except Exception as e:\",\n                \"> * raise RuntimeError('runtime problem')\" + exc_handling_code,\n                \"E *RuntimeError: runtime problem\",\n            ]\n        )\n\n    def test_exc_chain_repr_cycle(self, importasmod, tw_mock):\n        mod = importasmod(\n            \"\"\"\n            class Err(Exception):\n                pass\n            def fail():\n                return 0 / 0\n            def reraise():\n                try:\n                    fail()\n                except ZeroDivisionError as e:\n                    raise Err() from e\n            def unreraise():\n                try:\n                    reraise()\n                except Err as e:\n                    raise e.__cause__\n        \"\"\"\n        )\n        excinfo = pytest.raises(ZeroDivisionError, mod.unreraise)\n        r = excinfo.getrepr(style=\"short\")\n        r.toterminal(tw_mock)\n        out = \"\\n\".join(line for line in tw_mock.lines if isinstance(line, str))\n        # Assert highlighting carets in python3.11+\n        if sys.version_info >= (3, 11):\n            expected_out = textwrap.dedent(\n                \"\"\"\\\n                :13: in unreraise\n                    reraise()\n                :10: in reraise\n                    raise Err() from e\n                E   test_exc_chain_repr_cycle0.mod.Err\n\n                During handling of the above exception, another exception occurred:\n                :15: in unreraise\n                    raise e.__cause__\n                :8: in reraise\n                    fail()\n                :5: in fail\n                    return 0 / 0\n                           ^^^^^\n                E   ZeroDivisionError: division by zero\"\"\"\n            )\n        else:\n         "}, {"start_line": 8000, "end_line": 10000, "belongs_to": {"file_name": "test_excinfo.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing/code", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "y testable version\n        decorator = pytest.importorskip(\"decorator\").decorator\n\n        def log(f, *k, **kw):\n            print(f\"{k} {kw}\")\n            f(*k, **kw)\n\n        log = decorator(log)\n\n        def fail():\n            raise ValueError(\"\")\n\n        fail = log(log(fail))\n\n        excinfo = pytest.raises(ValueError, fail)\n        assert excinfo.traceback.recursionindex() is None\n\n    def test_getreprcrash(self):\n        def i():\n            __tracebackhide__ = True\n            raise ValueError\n\n        def h():\n            i()\n\n        def g():\n            __tracebackhide__ = True\n            h()\n\n        def f():\n            g()\n\n        excinfo = pytest.raises(ValueError, f)\n        reprcrash = excinfo._getreprcrash()\n        assert reprcrash is not None\n        co = _pytest._code.Code.from_function(h)\n        assert reprcrash.path == str(co.path)\n        assert reprcrash.lineno == co.firstlineno + 1 + 1\n\n    def test_getreprcrash_empty(self):\n        def g():\n            __tracebackhide__ = True\n            raise ValueError\n\n        def f():\n            __tracebackhide__ = True\n            g()\n\n        excinfo = pytest.raises(ValueError, f)\n        assert excinfo._getreprcrash() is None\n\n\ndef test_excinfo_exconly():\n    excinfo = pytest.raises(ValueError, h)\n    assert excinfo.exconly().startswith(\"ValueError\")\n    with pytest.raises(ValueError) as excinfo:\n        raise ValueError(\"hello\\nworld\")\n    msg = excinfo.exconly(tryshort=True)\n    assert msg.startswith(\"ValueError\")\n    assert msg.endswith(\"world\")\n\n\ndef test_excinfo_repr_str() -> None:\n    excinfo1 = pytest.raises(ValueError, h)\n    assert repr(excinfo1) == \"<ExceptionInfo ValueError() tblen=4>\"\n    assert str(excinfo1) == \"<ExceptionInfo ValueError() tblen=4>\"\n\n    class CustomException(Exception):\n        def __repr__(self):\n            return \"custom_repr\"\n\n    def raises() -> None:\n        raise CustomException()\n\n    excinfo2 = pytest.raises(CustomException, raises)\n    assert repr(exci"}], "retrieved_count": 10, "cost_time": 1.1881179809570312}
{"question": "What is the conditional logic in write_captured_output that determines which captured output streams are written to the XML report, and what is the semantic difference between the 'all' logging mode and the combination of 'system-out' and 'system-err' modes in terms of content aggregation?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"start_line": 5000, "end_line": 7000, "belongs_to": {"file_name": "junitxml.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "s not None:\n            testcase.append(properties)\n        testcase.extend(self.nodes)\n        return testcase\n\n    def _add_simple(self, tag: str, message: str, data: str | None = None) -> None:\n        node = ET.Element(tag, message=message)\n        node.text = bin_xml_escape(data)\n        self.append(node)\n\n    def write_captured_output(self, report: TestReport) -> None:\n        if not self.xml.log_passing_tests and report.passed:\n            return\n\n        content_out = report.capstdout\n        content_log = report.caplog\n        content_err = report.capstderr\n        if self.xml.logging == \"no\":\n            return\n        content_all = \"\"\n        if self.xml.logging in [\"log\", \"all\"]:\n            content_all = self._prepare_content(content_log, \" Captured Log \")\n        if self.xml.logging in [\"system-out\", \"out-err\", \"all\"]:\n            content_all += self._prepare_content(content_out, \" Captured Out \")\n            self._write_content(report, content_all, \"system-out\")\n            content_all = \"\"\n        if self.xml.logging in [\"system-err\", \"out-err\", \"all\"]:\n            content_all += self._prepare_content(content_err, \" Captured Err \")\n            self._write_content(report, content_all, \"system-err\")\n            content_all = \"\"\n        if content_all:\n            self._write_content(report, content_all, \"system-out\")\n\n    def _prepare_content(self, content: str, header: str) -> str:\n        return \"\\n\".join([header.center(80, \"-\"), content, \"\"])\n\n    def _write_content(self, report: TestReport, content: str, jheader: str) -> None:\n        tag = ET.Element(jheader)\n        tag.text = bin_xml_escape(content)\n        self.append(tag)\n\n    def append_pass(self, report: TestReport) -> None:\n        self.add_stats(\"passed\")\n\n    def append_failure(self, report: TestReport) -> None:\n        # msg = str(report.longrepr.reprtraceback.extraline)\n        if hasattr(report, \"wasxfail\"):\n            self._add_simple(\"skipped\", \"xfail-marked test passes unexpectedly"}, {"start_line": 6000, "end_line": 8000, "belongs_to": {"file_name": "junitxml.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "    content_all = \"\"\n        if self.xml.logging in [\"system-err\", \"out-err\", \"all\"]:\n            content_all += self._prepare_content(content_err, \" Captured Err \")\n            self._write_content(report, content_all, \"system-err\")\n            content_all = \"\"\n        if content_all:\n            self._write_content(report, content_all, \"system-out\")\n\n    def _prepare_content(self, content: str, header: str) -> str:\n        return \"\\n\".join([header.center(80, \"-\"), content, \"\"])\n\n    def _write_content(self, report: TestReport, content: str, jheader: str) -> None:\n        tag = ET.Element(jheader)\n        tag.text = bin_xml_escape(content)\n        self.append(tag)\n\n    def append_pass(self, report: TestReport) -> None:\n        self.add_stats(\"passed\")\n\n    def append_failure(self, report: TestReport) -> None:\n        # msg = str(report.longrepr.reprtraceback.extraline)\n        if hasattr(report, \"wasxfail\"):\n            self._add_simple(\"skipped\", \"xfail-marked test passes unexpectedly\")\n        else:\n            assert report.longrepr is not None\n            reprcrash: ReprFileLocation | None = getattr(\n                report.longrepr, \"reprcrash\", None\n            )\n            if reprcrash is not None:\n                message = reprcrash.message\n            else:\n                message = str(report.longrepr)\n            message = bin_xml_escape(message)\n            self._add_simple(\"failure\", message, str(report.longrepr))\n\n    def append_collect_error(self, report: TestReport) -> None:\n        # msg = str(report.longrepr.reprtraceback.extraline)\n        assert report.longrepr is not None\n        self._add_simple(\"error\", \"collection failure\", str(report.longrepr))\n\n    def append_collect_skipped(self, report: TestReport) -> None:\n        self._add_simple(\"skipped\", \"collection skipped\", str(report.longrepr))\n\n    def append_error(self, report: TestReport) -> None:\n        assert report.longrepr is not None\n        reprcrash: ReprFileLocation | None = getattr(re"}, {"start_line": 30000, "end_line": 32000, "belongs_to": {"file_name": "test_junitxml.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": " node.find_by_tag(\"system-out\"), (\n                \"system-out should not be generated\"\n            )\n        if junit_logging == \"system-out\":\n            systemout = pnode.get_first_by_tag(\"system-out\")\n            assert \"hello-stdout\" in systemout.toxml(), (\n                \"'hello-stdout' should be in system-out\"\n            )\n\n    @pytest.mark.parametrize(\"junit_logging\", [\"no\", \"system-err\"])\n    def test_pass_captures_stderr(\n        self, pytester: Pytester, run_and_parse: RunAndParse, junit_logging: str\n    ) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            import sys\n            def test_pass():\n                sys.stderr.write('hello-stderr')\n        \"\"\"\n        )\n        result, dom = run_and_parse(\"-o\", f\"junit_logging={junit_logging}\")\n        node = dom.get_first_by_tag(\"testsuite\")\n        pnode = node.get_first_by_tag(\"testcase\")\n        if junit_logging == \"no\":\n            assert not node.find_by_tag(\"system-err\"), (\n                \"system-err should not be generated\"\n            )\n        if junit_logging == \"system-err\":\n            systemerr = pnode.get_first_by_tag(\"system-err\")\n            assert \"hello-stderr\" in systemerr.toxml(), (\n                \"'hello-stderr' should be in system-err\"\n            )\n\n    @pytest.mark.parametrize(\"junit_logging\", [\"no\", \"system-out\"])\n    def test_setup_error_captures_stdout(\n        self, pytester: Pytester, run_and_parse: RunAndParse, junit_logging: str\n    ) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n\n            @pytest.fixture\n            def arg(request):\n                print('hello-stdout')\n                raise ValueError()\n            def test_function(arg):\n                pass\n        \"\"\"\n        )\n        result, dom = run_and_parse(\"-o\", f\"junit_logging={junit_logging}\")\n        node = dom.get_first_by_tag(\"testsuite\")\n        pnode = node.get_first_by_tag(\"testcase\")\n        if junit_logging == \"no\":\n            assert not node.find_by"}, {"start_line": 32000, "end_line": 34000, "belongs_to": {"file_name": "test_junitxml.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "_tag(\"system-out\"), (\n                \"system-out should not be generated\"\n            )\n        if junit_logging == \"system-out\":\n            systemout = pnode.get_first_by_tag(\"system-out\")\n            assert \"hello-stdout\" in systemout.toxml(), (\n                \"'hello-stdout' should be in system-out\"\n            )\n\n    @pytest.mark.parametrize(\"junit_logging\", [\"no\", \"system-err\"])\n    def test_setup_error_captures_stderr(\n        self, pytester: Pytester, run_and_parse: RunAndParse, junit_logging: str\n    ) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            import sys\n            import pytest\n\n            @pytest.fixture\n            def arg(request):\n                sys.stderr.write('hello-stderr')\n                raise ValueError()\n            def test_function(arg):\n                pass\n        \"\"\"\n        )\n        result, dom = run_and_parse(\"-o\", f\"junit_logging={junit_logging}\")\n        node = dom.get_first_by_tag(\"testsuite\")\n        pnode = node.get_first_by_tag(\"testcase\")\n        if junit_logging == \"no\":\n            assert not node.find_by_tag(\"system-err\"), (\n                \"system-err should not be generated\"\n            )\n        if junit_logging == \"system-err\":\n            systemerr = pnode.get_first_by_tag(\"system-err\")\n            assert \"hello-stderr\" in systemerr.toxml(), (\n                \"'hello-stderr' should be in system-err\"\n            )\n\n    @pytest.mark.parametrize(\"junit_logging\", [\"no\", \"system-out\"])\n    def test_avoid_double_stdout(\n        self, pytester: Pytester, run_and_parse: RunAndParse, junit_logging: str\n    ) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            import sys\n            import pytest\n\n            @pytest.fixture\n            def arg(request):\n                yield\n                sys.stdout.write('hello-stdout teardown')\n                raise ValueError()\n            def test_function(arg):\n                sys.stdout.write('hello-stdout call')\n        \"\"\"\n        )\n        resu"}, {"start_line": 31000, "end_line": 33000, "belongs_to": {"file_name": "test_junitxml.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "ld not be generated\"\n            )\n        if junit_logging == \"system-err\":\n            systemerr = pnode.get_first_by_tag(\"system-err\")\n            assert \"hello-stderr\" in systemerr.toxml(), (\n                \"'hello-stderr' should be in system-err\"\n            )\n\n    @pytest.mark.parametrize(\"junit_logging\", [\"no\", \"system-out\"])\n    def test_setup_error_captures_stdout(\n        self, pytester: Pytester, run_and_parse: RunAndParse, junit_logging: str\n    ) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n\n            @pytest.fixture\n            def arg(request):\n                print('hello-stdout')\n                raise ValueError()\n            def test_function(arg):\n                pass\n        \"\"\"\n        )\n        result, dom = run_and_parse(\"-o\", f\"junit_logging={junit_logging}\")\n        node = dom.get_first_by_tag(\"testsuite\")\n        pnode = node.get_first_by_tag(\"testcase\")\n        if junit_logging == \"no\":\n            assert not node.find_by_tag(\"system-out\"), (\n                \"system-out should not be generated\"\n            )\n        if junit_logging == \"system-out\":\n            systemout = pnode.get_first_by_tag(\"system-out\")\n            assert \"hello-stdout\" in systemout.toxml(), (\n                \"'hello-stdout' should be in system-out\"\n            )\n\n    @pytest.mark.parametrize(\"junit_logging\", [\"no\", \"system-err\"])\n    def test_setup_error_captures_stderr(\n        self, pytester: Pytester, run_and_parse: RunAndParse, junit_logging: str\n    ) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            import sys\n            import pytest\n\n            @pytest.fixture\n            def arg(request):\n                sys.stderr.write('hello-stderr')\n                raise ValueError()\n            def test_function(arg):\n                pass\n        \"\"\"\n        )\n        result, dom = run_and_parse(\"-o\", f\"junit_logging={junit_logging}\")\n        node = dom.get_first_by_tag(\"testsuite\")\n        pnode = node.get_first_"}, {"start_line": 20000, "end_line": 22000, "belongs_to": {"file_name": "test_junitxml.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "ut\")\n            systemout_xml = systemout.toxml()\n            assert systemout.tag == \"system-out\", \"Expected tag: system-out\"\n            assert \"info msg\" not in systemout_xml, \"INFO message found in system-out\"\n            assert \"hello-stdout\" in systemout_xml, (\n                \"Missing 'hello-stdout' in system-out\"\n            )\n        if junit_logging in [\"system-err\", \"out-err\", \"all\"]:\n            systemerr = tnode.get_first_by_tag(\"system-err\")\n            systemerr_xml = systemerr.toxml()\n            assert systemerr.tag == \"system-err\", \"Expected tag: system-err\"\n            assert \"info msg\" not in systemerr_xml, \"INFO message found in system-err\"\n            assert \"hello-stderr\" in systemerr_xml, (\n                \"Missing 'hello-stderr' in system-err\"\n            )\n            assert \"warning msg\" not in systemerr_xml, (\n                \"WARN message found in system-err\"\n            )\n        if junit_logging == \"no\":\n            assert not tnode.find_by_tag(\"log\"), \"Found unexpected content: log\"\n            assert not tnode.find_by_tag(\"system-out\"), (\n                \"Found unexpected content: system-out\"\n            )\n            assert not tnode.find_by_tag(\"system-err\"), (\n                \"Found unexpected content: system-err\"\n            )\n\n    @parametrize_families\n    def test_failure_verbose_message(\n        self, pytester: Pytester, run_and_parse: RunAndParse, xunit_family: str\n    ) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            import sys\n            def test_fail():\n                assert 0, \"An error\"\n        \"\"\"\n        )\n        result, dom = run_and_parse(family=xunit_family)\n        node = dom.get_first_by_tag(\"testsuite\")\n        tnode = node.get_first_by_tag(\"testcase\")\n        fnode = tnode.get_first_by_tag(\"failure\")\n        fnode.assert_attr(message=\"AssertionError: An error\\nassert 0\")\n\n    @parametrize_families\n    def test_failure_escape(\n        self, pytester: Pytester, run_and_parse: RunAndParse, xun"}, {"start_line": 4000, "end_line": 6000, "belongs_to": {"file_name": "junitxml.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "bin_xml_escape(names[-1]),\n            \"file\": testreport.location[0],\n        }\n        if testreport.location[1] is not None:\n            attrs[\"line\"] = str(testreport.location[1])\n        if hasattr(testreport, \"url\"):\n            attrs[\"url\"] = testreport.url\n        self.attrs = attrs\n        self.attrs.update(existing_attrs)  # Restore any user-defined attributes.\n\n        # Preserve legacy testcase behavior.\n        if self.family == \"xunit1\":\n            return\n\n        # Filter out attributes not permitted by this test family.\n        # Including custom attributes because they are not valid here.\n        temp_attrs = {}\n        for key in self.attrs:\n            if key in families[self.family][\"testcase\"]:\n                temp_attrs[key] = self.attrs[key]\n        self.attrs = temp_attrs\n\n    def to_xml(self) -> ET.Element:\n        testcase = ET.Element(\"testcase\", self.attrs, time=f\"{self.duration:.3f}\")\n        properties = self.make_properties_node()\n        if properties is not None:\n            testcase.append(properties)\n        testcase.extend(self.nodes)\n        return testcase\n\n    def _add_simple(self, tag: str, message: str, data: str | None = None) -> None:\n        node = ET.Element(tag, message=message)\n        node.text = bin_xml_escape(data)\n        self.append(node)\n\n    def write_captured_output(self, report: TestReport) -> None:\n        if not self.xml.log_passing_tests and report.passed:\n            return\n\n        content_out = report.capstdout\n        content_log = report.caplog\n        content_err = report.capstderr\n        if self.xml.logging == \"no\":\n            return\n        content_all = \"\"\n        if self.xml.logging in [\"log\", \"all\"]:\n            content_all = self._prepare_content(content_log, \" Captured Log \")\n        if self.xml.logging in [\"system-out\", \"out-err\", \"all\"]:\n            content_all += self._prepare_content(content_out, \" Captured Out \")\n            self._write_content(report, content_all, \"system-out\")\n        "}, {"start_line": 29000, "end_line": 31000, "belongs_to": {"file_name": "test_junitxml.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "tion_binchars(\n        self, pytester: Pytester, run_and_parse: RunAndParse\n    ) -> None:\n        \"\"\"This test did fail when the escaping wasn't strict.\"\"\"\n        pytester.makepyfile(\n            \"\"\"\n\n            M1 = '\\x01\\x02\\x03\\x04'\n            M2 = '\\x01\\x02\\x03\\x05'\n\n            def test_str_compare():\n                assert M1 == M2\n            \"\"\"\n        )\n        result, dom = run_and_parse()\n        print(dom.toxml())\n\n    @pytest.mark.parametrize(\"junit_logging\", [\"no\", \"system-out\"])\n    def test_pass_captures_stdout(\n        self, pytester: Pytester, run_and_parse: RunAndParse, junit_logging: str\n    ) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            def test_pass():\n                print('hello-stdout')\n        \"\"\"\n        )\n        result, dom = run_and_parse(\"-o\", f\"junit_logging={junit_logging}\")\n        node = dom.get_first_by_tag(\"testsuite\")\n        pnode = node.get_first_by_tag(\"testcase\")\n        if junit_logging == \"no\":\n            assert not node.find_by_tag(\"system-out\"), (\n                \"system-out should not be generated\"\n            )\n        if junit_logging == \"system-out\":\n            systemout = pnode.get_first_by_tag(\"system-out\")\n            assert \"hello-stdout\" in systemout.toxml(), (\n                \"'hello-stdout' should be in system-out\"\n            )\n\n    @pytest.mark.parametrize(\"junit_logging\", [\"no\", \"system-err\"])\n    def test_pass_captures_stderr(\n        self, pytester: Pytester, run_and_parse: RunAndParse, junit_logging: str\n    ) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            import sys\n            def test_pass():\n                sys.stderr.write('hello-stderr')\n        \"\"\"\n        )\n        result, dom = run_and_parse(\"-o\", f\"junit_logging={junit_logging}\")\n        node = dom.get_first_by_tag(\"testsuite\")\n        pnode = node.get_first_by_tag(\"testcase\")\n        if junit_logging == \"no\":\n            assert not node.find_by_tag(\"system-err\"), (\n                \"system-err shou"}, {"start_line": 51000, "end_line": 53000, "belongs_to": {"file_name": "test_capture.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "ert captured.out == \"hello\\\\n\"\n            assert captured.err == \"world\\\\n\"\n\n            logging.info(\"something\")\n            print(\"next\")\n            logging.info(\"something\")\n\n            captured = {capture_fixture}.readouterr()\n            assert captured.out == \"next\\\\n\"\n        \"\"\"\n    )\n\n    result = pytester.runpytest_subprocess(\"--log-cli-level=INFO\")\n    assert result.ret == 0\n\n\ndef test_typeerror_encodedfile_write(pytester: Pytester) -> None:\n    \"\"\"It should behave the same with and without output capturing (#4861).\"\"\"\n    p = pytester.makepyfile(\n        \"\"\"\n        def test_fails():\n            import sys\n            sys.stdout.write(b\"foo\")\n    \"\"\"\n    )\n    result_without_capture = pytester.runpytest(\"-s\", str(p))\n    result_with_capture = pytester.runpytest(str(p))\n\n    assert result_with_capture.ret == result_without_capture.ret\n    out = result_with_capture.stdout.str()\n    assert (\"TypeError: write() argument must be str, not bytes\" in out) or (\n        \"TypeError: unicode argument expected, got 'bytes'\" in out\n    )\n\n\ndef test_stderr_write_returns_len(capsys: CaptureFixture[str]) -> None:\n    \"\"\"Write on Encoded files, namely captured stderr, should return number of characters written.\"\"\"\n    assert sys.stderr.write(\"Foo\") == 3\n\n\ndef test_encodedfile_writelines(tmpfile: BinaryIO) -> None:\n    ef = capture.EncodedFile(tmpfile, encoding=\"utf-8\")\n    with pytest.raises(TypeError):\n        ef.writelines([b\"line1\", b\"line2\"])  # type: ignore[list-item]\n    assert ef.writelines([\"line3\", \"line4\"]) is None  # type: ignore[func-returns-value]\n    ef.flush()\n    tmpfile.seek(0)\n    assert tmpfile.read() == b\"line3line4\"\n    tmpfile.close()\n    with pytest.raises(ValueError):\n        ef.read()\n\n\ndef test__get_multicapture() -> None:\n    assert isinstance(_get_multicapture(\"no\"), MultiCapture)\n    pytest.raises(ValueError, _get_multicapture, \"unknown\").match(\n        r\"^unknown capturing method: 'unknown'\"\n    )\n\n\ndef test_logging_while_collecting(pytes"}, {"start_line": 33000, "end_line": 35000, "belongs_to": {"file_name": "test_junitxml.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "by_tag(\"testcase\")\n        if junit_logging == \"no\":\n            assert not node.find_by_tag(\"system-err\"), (\n                \"system-err should not be generated\"\n            )\n        if junit_logging == \"system-err\":\n            systemerr = pnode.get_first_by_tag(\"system-err\")\n            assert \"hello-stderr\" in systemerr.toxml(), (\n                \"'hello-stderr' should be in system-err\"\n            )\n\n    @pytest.mark.parametrize(\"junit_logging\", [\"no\", \"system-out\"])\n    def test_avoid_double_stdout(\n        self, pytester: Pytester, run_and_parse: RunAndParse, junit_logging: str\n    ) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            import sys\n            import pytest\n\n            @pytest.fixture\n            def arg(request):\n                yield\n                sys.stdout.write('hello-stdout teardown')\n                raise ValueError()\n            def test_function(arg):\n                sys.stdout.write('hello-stdout call')\n        \"\"\"\n        )\n        result, dom = run_and_parse(\"-o\", f\"junit_logging={junit_logging}\")\n        node = dom.get_first_by_tag(\"testsuite\")\n        pnode = node.get_first_by_tag(\"testcase\")\n        if junit_logging == \"no\":\n            assert not node.find_by_tag(\"system-out\"), (\n                \"system-out should not be generated\"\n            )\n        if junit_logging == \"system-out\":\n            systemout = pnode.get_first_by_tag(\"system-out\")\n            assert \"hello-stdout call\" in systemout.toxml()\n            assert \"hello-stdout teardown\" in systemout.toxml()\n\n\ndef test_mangle_test_address() -> None:\n    from _pytest.junitxml import mangle_test_address\n\n    address = \"::\".join([\"a/my.py.thing.py\", \"Class\", \"method\", \"[a-1-::]\"])\n    newnames = mangle_test_address(address)\n    assert newnames == [\"a.my.py.thing\", \"Class\", \"method\", \"[a-1-::]\"]\n\n\ndef test_dont_configure_on_workers(tmp_path: Path) -> None:\n    gotten: list[object] = []\n\n    class FakeConfig:\n        if TYPE_CHECKING:\n            workerinpu"}], "retrieved_count": 10, "cost_time": 1.210763692855835}
{"question": "How should the `isnosetest` method be refactored to separate the concern of attribute validation from test detection logic, and what design pattern would enable this separation while maintaining backward compatibility with nose-style test markers across the PyCollector hierarchy?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"start_line": 11000, "end_line": 13000, "belongs_to": {"file_name": "python.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "    parts = []\n        for node in self.iter_parents():\n            name = node.name\n            if isinstance(node, Module):\n                name = os.path.splitext(name)[0]\n                if stopatmodule:\n                    if includemodule:\n                        parts.append(name)\n                    break\n            parts.append(name)\n        parts.reverse()\n        return \".\".join(parts)\n\n    def reportinfo(self) -> tuple[os.PathLike[str] | str, int | None, str]:\n        # XXX caching?\n        path, lineno = getfslineno(self.obj)\n        modpath = self.getmodpath()\n        return path, lineno, modpath\n\n\n# As an optimization, these builtin attribute names are pre-ignored when\n# iterating over an object during collection -- the pytest_pycollect_makeitem\n# hook is not called for them.\n# fmt: off\nclass _EmptyClass: pass  # noqa: E701\nIGNORED_ATTRIBUTES = frozenset.union(\n    frozenset(),\n    # Module.\n    dir(types.ModuleType(\"empty_module\")),\n    # Some extra module attributes the above doesn't catch.\n    {\"__builtins__\", \"__file__\", \"__cached__\"},\n    # Class.\n    dir(_EmptyClass),\n    # Instance.\n    dir(_EmptyClass()),\n)\ndel _EmptyClass\n# fmt: on\n\n\nclass PyCollector(PyobjMixin, nodes.Collector, abc.ABC):\n    def funcnamefilter(self, name: str) -> bool:\n        return self._matches_prefix_or_glob_option(\"python_functions\", name)\n\n    def isnosetest(self, obj: object) -> bool:\n        \"\"\"Look for the __test__ attribute, which is applied by the\n        @nose.tools.istest decorator.\n        \"\"\"\n        # We explicitly check for \"is True\" here to not mistakenly treat\n        # classes with a custom __getattr__ returning something truthy (like a\n        # function) as test classes.\n        return safe_getattr(obj, \"__test__\", False) is True\n\n    def classnamefilter(self, name: str) -> bool:\n        return self._matches_prefix_or_glob_option(\"python_classes\", name)\n\n    def istestfunction(self, obj: object, name: str) -> bool:\n        if self.funcnamefilter(name)"}, {"start_line": 12000, "end_line": 14000, "belongs_to": {"file_name": "python.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "he above doesn't catch.\n    {\"__builtins__\", \"__file__\", \"__cached__\"},\n    # Class.\n    dir(_EmptyClass),\n    # Instance.\n    dir(_EmptyClass()),\n)\ndel _EmptyClass\n# fmt: on\n\n\nclass PyCollector(PyobjMixin, nodes.Collector, abc.ABC):\n    def funcnamefilter(self, name: str) -> bool:\n        return self._matches_prefix_or_glob_option(\"python_functions\", name)\n\n    def isnosetest(self, obj: object) -> bool:\n        \"\"\"Look for the __test__ attribute, which is applied by the\n        @nose.tools.istest decorator.\n        \"\"\"\n        # We explicitly check for \"is True\" here to not mistakenly treat\n        # classes with a custom __getattr__ returning something truthy (like a\n        # function) as test classes.\n        return safe_getattr(obj, \"__test__\", False) is True\n\n    def classnamefilter(self, name: str) -> bool:\n        return self._matches_prefix_or_glob_option(\"python_classes\", name)\n\n    def istestfunction(self, obj: object, name: str) -> bool:\n        if self.funcnamefilter(name) or self.isnosetest(obj):\n            if isinstance(obj, (staticmethod, classmethod)):\n                # staticmethods and classmethods need to be unwrapped.\n                obj = safe_getattr(obj, \"__func__\", False)\n            return callable(obj) and fixtures.getfixturemarker(obj) is None\n        else:\n            return False\n\n    def istestclass(self, obj: object, name: str) -> bool:\n        if not (self.classnamefilter(name) or self.isnosetest(obj)):\n            return False\n        if inspect.isabstract(obj):\n            return False\n        return True\n\n    def _matches_prefix_or_glob_option(self, option_name: str, name: str) -> bool:\n        \"\"\"Check if the given name matches the prefix or glob-pattern defined\n        in ini configuration.\"\"\"\n        for option in self.config.getini(option_name):\n            if name.startswith(option):\n                return True\n            # Check that name looks like a glob-string before calling fnmatch\n            # because this is called "}, {"start_line": 8000, "end_line": 10000, "belongs_to": {"file_name": "integration.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing/python", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "\"\"\"\n            *fix count 0*\n            *fix count 1*\n        \"\"\"\n        )\n        result.stdout.fnmatch_lines(\n            \"\"\"\n            *2 passed*\n        \"\"\"\n        )\n\n\ndef test_pytestconfig_is_session_scoped() -> None:\n    from _pytest.fixtures import pytestconfig\n\n    marker = getfixturemarker(pytestconfig)\n    assert marker is not None\n    assert marker.scope == \"session\"\n\n\nclass TestNoselikeTestAttribute:\n    def test_module_with_global_test(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            __test__ = False\n            def test_hello():\n                pass\n        \"\"\"\n        )\n        reprec = pytester.inline_run()\n        assert not reprec.getfailedcollections()\n        calls = reprec.getreports(\"pytest_runtest_logreport\")\n        assert not calls\n\n    def test_class_and_method(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            __test__ = True\n            def test_func():\n                pass\n            test_func.__test__ = False\n\n            class TestSome(object):\n                __test__ = False\n                def test_method(self):\n                    pass\n        \"\"\"\n        )\n        reprec = pytester.inline_run()\n        assert not reprec.getfailedcollections()\n        calls = reprec.getreports(\"pytest_runtest_logreport\")\n        assert not calls\n\n    def test_unittest_class(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            import unittest\n            class TC(unittest.TestCase):\n                def test_1(self):\n                    pass\n            class TC2(unittest.TestCase):\n                __test__ = False\n                def test_2(self):\n                    pass\n        \"\"\"\n        )\n        reprec = pytester.inline_run()\n        assert not reprec.getfailedcollections()\n        call = reprec.getcalls(\"pytest_collection_modifyitems\")[0]\n        assert len(call.items) == 1\n        assert call.items[0].cls.__name__"}, {"start_line": 3000, "end_line": 5000, "belongs_to": {"file_name": "test_collection.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "dule is not None\n        assert fn.cls is not None\n        assert fn.instance is not None\n        assert fn.function is not None\n\n    def test_getcustomfile_roundtrip(self, pytester: Pytester) -> None:\n        hello = pytester.makefile(\".xxx\", hello=\"world\")\n        pytester.makepyfile(\n            conftest=\"\"\"\n            import pytest\n            class CustomFile(pytest.File):\n                def collect(self):\n                    return []\n            def pytest_collect_file(file_path, parent):\n                if file_path.suffix == \".xxx\":\n                    return CustomFile.from_parent(path=file_path, parent=parent)\n        \"\"\"\n        )\n        node = pytester.getpathnode(hello)\n        assert isinstance(node, pytest.File)\n        assert node.name == \"hello.xxx\"\n        nodes = node.session.perform_collect([node.nodeid], genitems=False)\n        assert len(nodes) == 1\n        assert isinstance(nodes[0], pytest.File)\n\n    def test_can_skip_class_with_test_attr(self, pytester: Pytester) -> None:\n        \"\"\"Assure test class is skipped when using `__test__=False` (See #2007).\"\"\"\n        pytester.makepyfile(\n            \"\"\"\n            class TestFoo(object):\n                __test__ = False\n                def __init__(self):\n                    pass\n                def test_foo():\n                    assert True\n        \"\"\"\n        )\n        result = pytester.runpytest()\n        result.stdout.fnmatch_lines([\"collected 0 items\", \"*no tests ran in*\"])\n\n\nclass TestCollectFS:\n    def test_ignored_certain_directories(self, pytester: Pytester) -> None:\n        tmp_path = pytester.path\n        ensure_file(tmp_path / \"build\" / \"test_notfound.py\")\n        ensure_file(tmp_path / \"dist\" / \"test_notfound.py\")\n        ensure_file(tmp_path / \"_darcs\" / \"test_notfound.py\")\n        ensure_file(tmp_path / \"CVS\" / \"test_notfound.py\")\n        ensure_file(tmp_path / \"{arch}\" / \"test_notfound.py\")\n        ensure_file(tmp_path / \".whatever\" / \"test_notfound.py\")\n        ensure_file(t"}, {"start_line": 31000, "end_line": 33000, "belongs_to": {"file_name": "collect.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing/python", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "           if name == \"some\":\n                    return MyFunction.from_parent(name=name, parent=collector)\n        \"\"\"\n        )\n        pytester.makepyfile(\"def some(): pass\")\n        result = pytester.runpytest(\"--collect-only\")\n        result.stdout.fnmatch_lines([\"*MyFunction*some*\"])\n\n    def test_issue2369_collect_module_fileext(self, pytester: Pytester) -> None:\n        \"\"\"Ensure we can collect files with weird file extensions as Python\n        modules (#2369)\"\"\"\n        # Implement a little meta path finder to import files containing\n        # Python source code whose file extension is \".narf\".\n        pytester.makeconftest(\n            \"\"\"\n            import sys\n            import os.path\n            from importlib.util import spec_from_loader\n            from importlib.machinery import SourceFileLoader\n            from _pytest.python import Module\n\n            class MetaPathFinder:\n                def find_spec(self, fullname, path, target=None):\n                    if os.path.exists(fullname + \".narf\"):\n                        return spec_from_loader(\n                            fullname,\n                            SourceFileLoader(fullname, fullname + \".narf\"),\n                        )\n            sys.meta_path.append(MetaPathFinder())\n\n            def pytest_collect_file(file_path, parent):\n                if file_path.suffix == \".narf\":\n                    return Module.from_parent(path=file_path, parent=parent)\n            \"\"\"\n        )\n        pytester.makefile(\n            \".narf\",\n            \"\"\"\\\n            def test_something():\n                assert 1 + 1 == 2\"\"\",\n        )\n        # Use runpytest_subprocess, since we're futzing with sys.meta_path.\n        result = pytester.runpytest_subprocess()\n        result.stdout.fnmatch_lines([\"*1 passed*\"])\n\n    def test_early_ignored_attributes(self, pytester: Pytester) -> None:\n        \"\"\"Builtin attributes should be ignored early on, even if\n        configuration would otherwise allow them.\n\n     "}, {"start_line": 32000, "end_line": 34000, "belongs_to": {"file_name": "collect.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing/python", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "ath.exists(fullname + \".narf\"):\n                        return spec_from_loader(\n                            fullname,\n                            SourceFileLoader(fullname, fullname + \".narf\"),\n                        )\n            sys.meta_path.append(MetaPathFinder())\n\n            def pytest_collect_file(file_path, parent):\n                if file_path.suffix == \".narf\":\n                    return Module.from_parent(path=file_path, parent=parent)\n            \"\"\"\n        )\n        pytester.makefile(\n            \".narf\",\n            \"\"\"\\\n            def test_something():\n                assert 1 + 1 == 2\"\"\",\n        )\n        # Use runpytest_subprocess, since we're futzing with sys.meta_path.\n        result = pytester.runpytest_subprocess()\n        result.stdout.fnmatch_lines([\"*1 passed*\"])\n\n    def test_early_ignored_attributes(self, pytester: Pytester) -> None:\n        \"\"\"Builtin attributes should be ignored early on, even if\n        configuration would otherwise allow them.\n\n        This tests a performance optimization, not correctness, really,\n        although it tests PytestCollectionWarning is not raised, while\n        it would have been raised otherwise.\n        \"\"\"\n        pytester.makeini(\n            \"\"\"\n            [pytest]\n            python_classes=*\n            python_functions=*\n        \"\"\"\n        )\n        pytester.makepyfile(\n            \"\"\"\n            class TestEmpty:\n                pass\n            test_empty = TestEmpty()\n            def test_real():\n                pass\n        \"\"\"\n        )\n        items, rec = pytester.inline_genitems()\n        assert rec.ret == 0\n        assert len(items) == 1\n\n\ndef test_setup_only_available_in_subdir(pytester: Pytester) -> None:\n    sub1 = pytester.mkpydir(\"sub1\")\n    sub2 = pytester.mkpydir(\"sub2\")\n    sub1.joinpath(\"conftest.py\").write_text(\n        textwrap.dedent(\n            \"\"\"\\\n            import pytest\n            def pytest_runtest_setup(item):\n                assert item.path.stem == \"test_in"}, {"start_line": 9000, "end_line": 11000, "belongs_to": {"file_name": "collect.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing/python", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "ert result.ret == ExitCode.NO_TESTS_COLLECTED\n\n    def test_does_not_discover_instance_descriptors(self, pytester: Pytester) -> None:\n        \"\"\"Regression test for #12446.\"\"\"\n        pytester.makepyfile(\n            \"\"\"\\\n            # not `@property`, but it acts like one\n            # this should cover the case of things like `@cached_property` / etc.\n            class MyProperty:\n                def __init__(self, func):\n                    self._func = func\n                def __get__(self, inst, owner):\n                    if inst is None:\n                        return self\n                    else:\n                        return self._func.__get__(inst, owner)()\n\n            class TestCase:\n                @MyProperty\n                def oops(self):\n                    raise SystemExit('do not call me!')\n            \"\"\"\n        )\n        result = pytester.runpytest()\n        assert result.ret == ExitCode.NO_TESTS_COLLECTED\n\n    def test_abstract_class_is_not_collected(self, pytester: Pytester) -> None:\n        \"\"\"Regression test for #12275 (non-unittest version).\"\"\"\n        pytester.makepyfile(\n            \"\"\"\n            import abc\n\n            class TestBase(abc.ABC):\n                @abc.abstractmethod\n                def abstract1(self): pass\n\n                @abc.abstractmethod\n                def abstract2(self): pass\n\n                def test_it(self): pass\n\n            class TestPartial(TestBase):\n                def abstract1(self): pass\n\n            class TestConcrete(TestPartial):\n                def abstract2(self): pass\n            \"\"\"\n        )\n        result = pytester.runpytest()\n        assert result.ret == ExitCode.OK\n        result.assert_outcomes(passed=1)\n\n\nclass TestFunction:\n    def test_getmodulecollector(self, pytester: Pytester) -> None:\n        item = pytester.getitem(\"def test_func(): pass\")\n        modcol = item.getparent(pytest.Module)\n        assert isinstance(modcol, pytest.Module)\n        assert hasattr(modcol.obj, \"test_func\""}, {"start_line": 7000, "end_line": 9000, "belongs_to": {"file_name": "collect.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing/python", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "pytester.makepyfile(\n            test_mod1=\"\"\"\n            class TestClassMethod(object):\n                @classmethod\n                def setup_class(cls):\n                    pass\n                def test_1(self):\n                    pass\n                @classmethod\n                def teardown_class(cls):\n                    pass\n        \"\"\"\n        )\n        result = pytester.runpytest()\n        result.stdout.fnmatch_lines([\"*1 passed*\"])\n\n    def test_issue1035_obj_has_getattr(self, pytester: Pytester) -> None:\n        modcol = pytester.getmodulecol(\n            \"\"\"\n            class Chameleon(object):\n                def __getattr__(self, name):\n                    return True\n            chameleon = Chameleon()\n        \"\"\"\n        )\n        colitems = modcol.collect()\n        assert len(colitems) == 0\n\n    def test_issue1579_namedtuple(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            import collections\n\n            TestCase = collections.namedtuple('TestCase', ['a'])\n        \"\"\"\n        )\n        result = pytester.runpytest()\n        result.stdout.fnmatch_lines(\n            \"*cannot collect test class 'TestCase' \"\n            \"because it has a __new__ constructor*\"\n        )\n\n    def test_issue2234_property(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            class TestCase(object):\n                @property\n                def prop(self):\n                    raise NotImplementedError()\n        \"\"\"\n        )\n        result = pytester.runpytest()\n        assert result.ret == ExitCode.NO_TESTS_COLLECTED\n\n    def test_does_not_discover_properties(self, pytester: Pytester) -> None:\n        \"\"\"Regression test for #12446.\"\"\"\n        pytester.makepyfile(\n            \"\"\"\\\n            class TestCase:\n                @property\n                def oops(self):\n                    raise SystemExit('do not call me!')\n            \"\"\"\n        )\n        result = pytester.runpytest()\n        ass"}, {"start_line": 27000, "end_line": 29000, "belongs_to": {"file_name": "python.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "t_file(file_path=path, parent=self)\n                yield from cols\n\n\ndef _call_with_optional_argument(func, arg) -> None:\n    \"\"\"Call the given function with the given argument if func accepts one argument, otherwise\n    calls func without arguments.\"\"\"\n    arg_count = func.__code__.co_argcount\n    if inspect.ismethod(func):\n        arg_count -= 1\n    if arg_count:\n        func(arg)\n    else:\n        func()\n\n\ndef _get_first_non_fixture_func(obj: object, names: Iterable[str]) -> object | None:\n    \"\"\"Return the attribute from the given object to be used as a setup/teardown\n    xunit-style function, but only if not marked as a fixture to avoid calling it twice.\n    \"\"\"\n    for name in names:\n        meth: object | None = getattr(obj, name, None)\n        if meth is not None and fixtures.getfixturemarker(meth) is None:\n            return meth\n    return None\n\n\nclass Class(PyCollector):\n    \"\"\"Collector for test methods (and nested classes) in a Python class.\"\"\"\n\n    @classmethod\n    def from_parent(cls, parent, *, name, obj=None, **kw) -> Self:  # type: ignore[override]\n        \"\"\"The public constructor.\"\"\"\n        return super().from_parent(name=name, parent=parent, **kw)\n\n    def newinstance(self):\n        return self.obj()\n\n    def collect(self) -> Iterable[nodes.Item | nodes.Collector]:\n        if not safe_getattr(self.obj, \"__test__\", True):\n            return []\n        if hasinit(self.obj):\n            assert self.parent is not None\n            self.warn(\n                PytestCollectionWarning(\n                    f\"cannot collect test class {self.obj.__name__!r} because it has a \"\n                    f\"__init__ constructor (from: {self.parent.nodeid})\"\n                )\n            )\n            return []\n        elif hasnew(self.obj):\n            assert self.parent is not None\n            self.warn(\n                PytestCollectionWarning(\n                    f\"cannot collect test class {self.obj.__name__!r} because it has a \"\n                    f\"__new__ co"}, {"start_line": 13000, "end_line": 15000, "belongs_to": {"file_name": "python.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": " or self.isnosetest(obj):\n            if isinstance(obj, (staticmethod, classmethod)):\n                # staticmethods and classmethods need to be unwrapped.\n                obj = safe_getattr(obj, \"__func__\", False)\n            return callable(obj) and fixtures.getfixturemarker(obj) is None\n        else:\n            return False\n\n    def istestclass(self, obj: object, name: str) -> bool:\n        if not (self.classnamefilter(name) or self.isnosetest(obj)):\n            return False\n        if inspect.isabstract(obj):\n            return False\n        return True\n\n    def _matches_prefix_or_glob_option(self, option_name: str, name: str) -> bool:\n        \"\"\"Check if the given name matches the prefix or glob-pattern defined\n        in ini configuration.\"\"\"\n        for option in self.config.getini(option_name):\n            if name.startswith(option):\n                return True\n            # Check that name looks like a glob-string before calling fnmatch\n            # because this is called for every name in each collected module,\n            # and fnmatch is somewhat expensive to call.\n            elif (\"*\" in option or \"?\" in option or \"[\" in option) and fnmatch.fnmatch(\n                name, option\n            ):\n                return True\n        return False\n\n    def collect(self) -> Iterable[nodes.Item | nodes.Collector]:\n        if not getattr(self.obj, \"__test__\", True):\n            return []\n\n        # Avoid random getattrs and peek in the __dict__ instead.\n        dicts = [getattr(self.obj, \"__dict__\", {})]\n        if isinstance(self.obj, type):\n            for basecls in self.obj.__mro__:\n                dicts.append(basecls.__dict__)\n\n        # In each class, nodes should be definition ordered.\n        # __dict__ is definition ordered.\n        seen: set[str] = set()\n        dict_values: list[list[nodes.Item | nodes.Collector]] = []\n        collect_imported_tests = self.session.config.getini(\"collect_imported_tests\")\n        ihook = self.ihook\n        for dic "}], "retrieved_count": 10, "cost_time": 1.195340871810913}
{"question": "Why does the TestShowFixtures class employ separate test methods for validating fixture documentation formatting across different contexts (trimmed docs, indented docs, first-line unindented, class-level fixtures) rather than consolidating these variations into parameterized tests?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"start_line": 115000, "end_line": 117000, "belongs_to": {"file_name": "fixtures.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing/python", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "\n                        indented line\n                    \"\"\"\n                '''\n            )\n        )\n        result = pytester.runpytest(\"--fixtures\", p)\n        result.stdout.fnmatch_lines(\n            textwrap.dedent(\n                \"\"\"\\\n                * fixtures defined from test_show_fixtures_indented_doc *\n                fixture1 -- test_show_fixtures_indented_doc.py:3\n                    line1\n                        indented line\n                \"\"\"\n            )\n        )\n\n    def test_show_fixtures_indented_doc_first_line_unindented(\n        self, pytester: Pytester\n    ) -> None:\n        p = pytester.makepyfile(\n            textwrap.dedent(\n                '''\\\n                import pytest\n                @pytest.fixture\n                def fixture1():\n                    \"\"\"line1\n                    line2\n                        indented line\n                    \"\"\"\n                '''\n            )\n        )\n        result = pytester.runpytest(\"--fixtures\", p)\n        result.stdout.fnmatch_lines(\n            textwrap.dedent(\n                \"\"\"\\\n                * fixtures defined from test_show_fixtures_indented_doc_first_line_unindented *\n                fixture1 -- test_show_fixtures_indented_doc_first_line_unindented.py:3\n                    line1\n                    line2\n                        indented line\n                \"\"\"\n            )\n        )\n\n    def test_show_fixtures_indented_in_class(self, pytester: Pytester) -> None:\n        p = pytester.makepyfile(\n            textwrap.dedent(\n                '''\\\n                import pytest\n                class TestClass(object):\n                    @pytest.fixture\n                    def fixture1(self):\n                        \"\"\"line1\n                        line2\n                            indented line\n                        \"\"\"\n                '''\n            )\n        )\n        result = pytester.runpytest(\"--fixtures\", p)\n        result.stdout.fnmatch_lines(\n            textwrap."}, {"start_line": 114000, "end_line": 116000, "belongs_to": {"file_name": "fixtures.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing/python", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "       \"\"\"\n                @pytest.fixture\n                def arg2():\n                    \"\"\"\n                    line1\n                    line2\n\n                    \"\"\"\n                '''\n            )\n        )\n        result = pytester.runpytest(\"--fixtures\", p)\n        result.stdout.fnmatch_lines(\n            textwrap.dedent(\n                \"\"\"\\\n                * fixtures defined from test_show_fixtures_trimmed_doc *\n                arg2 -- test_show_fixtures_trimmed_doc.py:10\n                    line1\n                    line2\n                arg1 -- test_show_fixtures_trimmed_doc.py:3\n                    line1\n                    line2\n                \"\"\"\n            )\n        )\n\n    def test_show_fixtures_indented_doc(self, pytester: Pytester) -> None:\n        p = pytester.makepyfile(\n            textwrap.dedent(\n                '''\\\n                import pytest\n                @pytest.fixture\n                def fixture1():\n                    \"\"\"\n                    line1\n                        indented line\n                    \"\"\"\n                '''\n            )\n        )\n        result = pytester.runpytest(\"--fixtures\", p)\n        result.stdout.fnmatch_lines(\n            textwrap.dedent(\n                \"\"\"\\\n                * fixtures defined from test_show_fixtures_indented_doc *\n                fixture1 -- test_show_fixtures_indented_doc.py:3\n                    line1\n                        indented line\n                \"\"\"\n            )\n        )\n\n    def test_show_fixtures_indented_doc_first_line_unindented(\n        self, pytester: Pytester\n    ) -> None:\n        p = pytester.makepyfile(\n            textwrap.dedent(\n                '''\\\n                import pytest\n                @pytest.fixture\n                def fixture1():\n                    \"\"\"line1\n                    line2\n                        indented line\n                    \"\"\"\n                '''\n            )\n        )\n        result = pytester.runpytest(\"--fixtures\", p)\n   "}, {"start_line": 116000, "end_line": 118000, "belongs_to": {"file_name": "fixtures.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing/python", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "     result.stdout.fnmatch_lines(\n            textwrap.dedent(\n                \"\"\"\\\n                * fixtures defined from test_show_fixtures_indented_doc_first_line_unindented *\n                fixture1 -- test_show_fixtures_indented_doc_first_line_unindented.py:3\n                    line1\n                    line2\n                        indented line\n                \"\"\"\n            )\n        )\n\n    def test_show_fixtures_indented_in_class(self, pytester: Pytester) -> None:\n        p = pytester.makepyfile(\n            textwrap.dedent(\n                '''\\\n                import pytest\n                class TestClass(object):\n                    @pytest.fixture\n                    def fixture1(self):\n                        \"\"\"line1\n                        line2\n                            indented line\n                        \"\"\"\n                '''\n            )\n        )\n        result = pytester.runpytest(\"--fixtures\", p)\n        result.stdout.fnmatch_lines(\n            textwrap.dedent(\n                \"\"\"\\\n                * fixtures defined from test_show_fixtures_indented_in_class *\n                fixture1 -- test_show_fixtures_indented_in_class.py:4\n                    line1\n                    line2\n                        indented line\n                \"\"\"\n            )\n        )\n\n    def test_show_fixtures_different_files(self, pytester: Pytester) -> None:\n        \"\"\"`--fixtures` only shows fixtures from first file (#833).\"\"\"\n        pytester.makepyfile(\n            test_a='''\n            import pytest\n\n            @pytest.fixture\n            def fix_a():\n                \"\"\"Fixture A\"\"\"\n                pass\n\n            def test_a(fix_a):\n                pass\n        '''\n        )\n        pytester.makepyfile(\n            test_b='''\n            import pytest\n\n            @pytest.fixture\n            def fix_b():\n                \"\"\"Fixture B\"\"\"\n                pass\n\n            def test_b(fix_b):\n                pass\n        '''\n        )\n        result = p"}, {"start_line": 113000, "end_line": 115000, "belongs_to": {"file_name": "fixtures.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing/python", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "  def test_show_fixtures_conftest(self, pytester: Pytester, testmod) -> None:\n        pytester.makeconftest(\n            '''\n            import pytest\n            @pytest.fixture\n            def arg1():\n                \"\"\"  hello world \"\"\"\n        '''\n        )\n        if testmod:\n            pytester.makepyfile(\n                \"\"\"\n                def test_hello():\n                    pass\n            \"\"\"\n            )\n        result = pytester.runpytest(\"--fixtures\")\n        result.stdout.fnmatch_lines(\n            \"\"\"\n            *tmp_path*\n            *fixtures defined from*conftest*\n            *arg1*\n            *hello world*\n        \"\"\"\n        )\n\n    def test_show_fixtures_trimmed_doc(self, pytester: Pytester) -> None:\n        p = pytester.makepyfile(\n            textwrap.dedent(\n                '''\\\n                import pytest\n                @pytest.fixture\n                def arg1():\n                    \"\"\"\n                    line1\n                    line2\n\n                    \"\"\"\n                @pytest.fixture\n                def arg2():\n                    \"\"\"\n                    line1\n                    line2\n\n                    \"\"\"\n                '''\n            )\n        )\n        result = pytester.runpytest(\"--fixtures\", p)\n        result.stdout.fnmatch_lines(\n            textwrap.dedent(\n                \"\"\"\\\n                * fixtures defined from test_show_fixtures_trimmed_doc *\n                arg2 -- test_show_fixtures_trimmed_doc.py:10\n                    line1\n                    line2\n                arg1 -- test_show_fixtures_trimmed_doc.py:3\n                    line1\n                    line2\n                \"\"\"\n            )\n        )\n\n    def test_show_fixtures_indented_doc(self, pytester: Pytester) -> None:\n        p = pytester.makepyfile(\n            textwrap.dedent(\n                '''\\\n                import pytest\n                @pytest.fixture\n                def fixture1():\n                    \"\"\"\n                    line1"}, {"start_line": 117000, "end_line": 119000, "belongs_to": {"file_name": "fixtures.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing/python", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "dedent(\n                \"\"\"\\\n                * fixtures defined from test_show_fixtures_indented_in_class *\n                fixture1 -- test_show_fixtures_indented_in_class.py:4\n                    line1\n                    line2\n                        indented line\n                \"\"\"\n            )\n        )\n\n    def test_show_fixtures_different_files(self, pytester: Pytester) -> None:\n        \"\"\"`--fixtures` only shows fixtures from first file (#833).\"\"\"\n        pytester.makepyfile(\n            test_a='''\n            import pytest\n\n            @pytest.fixture\n            def fix_a():\n                \"\"\"Fixture A\"\"\"\n                pass\n\n            def test_a(fix_a):\n                pass\n        '''\n        )\n        pytester.makepyfile(\n            test_b='''\n            import pytest\n\n            @pytest.fixture\n            def fix_b():\n                \"\"\"Fixture B\"\"\"\n                pass\n\n            def test_b(fix_b):\n                pass\n        '''\n        )\n        result = pytester.runpytest(\"--fixtures\")\n        result.stdout.fnmatch_lines(\n            \"\"\"\n            * fixtures defined from test_a *\n            fix_a -- test_a.py:4\n                Fixture A\n\n            * fixtures defined from test_b *\n            fix_b -- test_b.py:4\n                Fixture B\n        \"\"\"\n        )\n\n    def test_show_fixtures_with_same_name(self, pytester: Pytester) -> None:\n        pytester.makeconftest(\n            '''\n            import pytest\n            @pytest.fixture\n            def arg1():\n                \"\"\"Hello World in conftest.py\"\"\"\n                return \"Hello World\"\n        '''\n        )\n        pytester.makepyfile(\n            \"\"\"\n            def test_foo(arg1):\n                assert arg1 == \"Hello World\"\n        \"\"\"\n        )\n        pytester.makepyfile(\n            '''\n            import pytest\n            @pytest.fixture\n            def arg1():\n                \"\"\"Hi from test module\"\"\"\n                return \"Hi\"\n            def test_bar(arg1):\n    "}, {"start_line": 112000, "end_line": 114000, "belongs_to": {"file_name": "fixtures.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing/python", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "t.fnmatch_lines(\n            [\n                \"tmp_path_factory [[]session scope[]] -- .../_pytest/tmpdir.py:*\",\n                \"*for the test session*\",\n                \"tmp_path -- .../_pytest/tmpdir.py:*\",\n                \"*temporary directory*\",\n            ]\n        )\n\n    def test_show_fixtures_testmodule(self, pytester: Pytester) -> None:\n        p = pytester.makepyfile(\n            '''\n            import pytest\n            @pytest.fixture\n            def _arg0():\n                \"\"\" hidden \"\"\"\n            @pytest.fixture\n            def arg1():\n                \"\"\"  hello world \"\"\"\n        '''\n        )\n        result = pytester.runpytest(\"--fixtures\", p)\n        result.stdout.fnmatch_lines(\n            \"\"\"\n            *tmp_path -- *\n            *fixtures defined from*\n            *arg1 -- test_show_fixtures_testmodule.py:6*\n            *hello world*\n        \"\"\"\n        )\n        result.stdout.no_fnmatch_line(\"*arg0*\")\n\n    @pytest.mark.parametrize(\"testmod\", [True, False])\n    def test_show_fixtures_conftest(self, pytester: Pytester, testmod) -> None:\n        pytester.makeconftest(\n            '''\n            import pytest\n            @pytest.fixture\n            def arg1():\n                \"\"\"  hello world \"\"\"\n        '''\n        )\n        if testmod:\n            pytester.makepyfile(\n                \"\"\"\n                def test_hello():\n                    pass\n            \"\"\"\n            )\n        result = pytester.runpytest(\"--fixtures\")\n        result.stdout.fnmatch_lines(\n            \"\"\"\n            *tmp_path*\n            *fixtures defined from*conftest*\n            *arg1*\n            *hello world*\n        \"\"\"\n        )\n\n    def test_show_fixtures_trimmed_doc(self, pytester: Pytester) -> None:\n        p = pytester.makepyfile(\n            textwrap.dedent(\n                '''\\\n                import pytest\n                @pytest.fixture\n                def arg1():\n                    \"\"\"\n                    line1\n                    line2\n\n             "}, {"start_line": 3000, "end_line": 5000, "belongs_to": {"file_name": "show_fixtures_per_test.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing/python", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "rom testmodule\",\n            \"arg2 -- conftest.py:6\",\n            \"    arg2 from conftest\",\n        ]\n    )\n\n\ndef test_verbose_include_private_fixtures_and_loc(pytester: Pytester) -> None:\n    pytester.makeconftest(\n        '''\n        import pytest\n        @pytest.fixture\n        def _arg1():\n            \"\"\"_arg1 from conftest\"\"\"\n        @pytest.fixture\n        def arg2(_arg1):\n            \"\"\"arg2 from conftest\"\"\"\n    '''\n    )\n    p = pytester.makepyfile(\n        '''\n        import pytest\n        @pytest.fixture\n        def arg3():\n            \"\"\"arg3 from testmodule\"\"\"\n        def test_args(arg2, arg3):\n            pass\n    '''\n    )\n    result = pytester.runpytest(\"--fixtures-per-test\", \"-v\", p)\n    assert result.ret == 0\n\n    result.stdout.fnmatch_lines(\n        [\n            \"*fixtures used by test_args*\",\n            \"*(test_verbose_include_private_fixtures_and_loc.py:6)*\",\n            \"_arg1 -- conftest.py:3\",\n            \"    _arg1 from conftest\",\n            \"arg2 -- conftest.py:6\",\n            \"    arg2 from conftest\",\n            \"arg3 -- test_verbose_include_private_fixtures_and_loc.py:3\",\n            \"    arg3 from testmodule\",\n        ]\n    )\n\n\ndef test_doctest_items(pytester: Pytester) -> None:\n    pytester.makepyfile(\n        '''\n        def foo():\n            \"\"\"\n            >>> 1 + 1\n            2\n            \"\"\"\n    '''\n    )\n    pytester.maketxtfile(\n        \"\"\"\n        >>> 1 + 1\n        2\n    \"\"\"\n    )\n    result = pytester.runpytest(\n        \"--fixtures-per-test\", \"--doctest-modules\", \"--doctest-glob=*.txt\", \"-v\"\n    )\n    assert result.ret == 0\n\n    result.stdout.fnmatch_lines([\"*collected 2 items*\"])\n\n\ndef test_multiline_docstring_in_module(pytester: Pytester) -> None:\n    p = pytester.makepyfile(\n        '''\n        import pytest\n        @pytest.fixture\n        def arg1():\n            \"\"\"Docstring content that spans across multiple lines,\n            through second line,\n            and through third line.\n\n            Docstring content tha"}, {"start_line": 4000, "end_line": 6000, "belongs_to": {"file_name": "show_fixtures_per_test.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing/python", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": ".py:6\",\n            \"    arg2 from conftest\",\n            \"arg3 -- test_verbose_include_private_fixtures_and_loc.py:3\",\n            \"    arg3 from testmodule\",\n        ]\n    )\n\n\ndef test_doctest_items(pytester: Pytester) -> None:\n    pytester.makepyfile(\n        '''\n        def foo():\n            \"\"\"\n            >>> 1 + 1\n            2\n            \"\"\"\n    '''\n    )\n    pytester.maketxtfile(\n        \"\"\"\n        >>> 1 + 1\n        2\n    \"\"\"\n    )\n    result = pytester.runpytest(\n        \"--fixtures-per-test\", \"--doctest-modules\", \"--doctest-glob=*.txt\", \"-v\"\n    )\n    assert result.ret == 0\n\n    result.stdout.fnmatch_lines([\"*collected 2 items*\"])\n\n\ndef test_multiline_docstring_in_module(pytester: Pytester) -> None:\n    p = pytester.makepyfile(\n        '''\n        import pytest\n        @pytest.fixture\n        def arg1():\n            \"\"\"Docstring content that spans across multiple lines,\n            through second line,\n            and through third line.\n\n            Docstring content that extends into a second paragraph.\n\n            Docstring content that extends into a third paragraph.\n            \"\"\"\n        def test_arg1(arg1):\n            pass\n    '''\n    )\n\n    result = pytester.runpytest(\"--fixtures-per-test\", p)\n    assert result.ret == 0\n\n    result.stdout.fnmatch_lines(\n        [\n            \"*fixtures used by test_arg1*\",\n            \"*(test_multiline_docstring_in_module.py:13)*\",\n            \"arg1 -- test_multiline_docstring_in_module.py:3\",\n            \"    Docstring content that spans across multiple lines,\",\n            \"    through second line,\",\n            \"    and through third line.\",\n        ]\n    )\n\n\ndef test_verbose_include_multiline_docstring(pytester: Pytester) -> None:\n    p = pytester.makepyfile(\n        '''\n        import pytest\n        @pytest.fixture\n        def arg1():\n            \"\"\"Docstring content that spans across multiple lines,\n            through second line,\n            and through third line.\n\n            Docstring content that"}, {"start_line": 111000, "end_line": 113000, "belongs_to": {"file_name": "fixtures.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing/python", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "  lines2 = failures[2].longrepr.reprtraceback.reprentries[0].lines\n        assert len(lines1) == len(lines2)\n\n\nclass TestShowFixtures:\n    def test_funcarg_compat(self, pytester: Pytester) -> None:\n        config = pytester.parseconfigure(\"--funcargs\")\n        assert config.option.showfixtures\n\n    def test_show_help(self, pytester: Pytester) -> None:\n        result = pytester.runpytest(\"--fixtures\", \"--help\")\n        assert not result.ret\n\n    def test_show_fixtures(self, pytester: Pytester) -> None:\n        result = pytester.runpytest(\"--fixtures\")\n        result.stdout.fnmatch_lines(\n            [\n                \"tmp_path_factory [[]session scope[]] -- .../_pytest/tmpdir.py:*\",\n                \"*for the test session*\",\n                \"tmp_path -- .../_pytest/tmpdir.py:*\",\n                \"*temporary directory*\",\n            ]\n        )\n\n    def test_show_fixtures_verbose(self, pytester: Pytester) -> None:\n        result = pytester.runpytest(\"--fixtures\", \"-v\")\n        result.stdout.fnmatch_lines(\n            [\n                \"tmp_path_factory [[]session scope[]] -- .../_pytest/tmpdir.py:*\",\n                \"*for the test session*\",\n                \"tmp_path -- .../_pytest/tmpdir.py:*\",\n                \"*temporary directory*\",\n            ]\n        )\n\n    def test_show_fixtures_testmodule(self, pytester: Pytester) -> None:\n        p = pytester.makepyfile(\n            '''\n            import pytest\n            @pytest.fixture\n            def _arg0():\n                \"\"\" hidden \"\"\"\n            @pytest.fixture\n            def arg1():\n                \"\"\"  hello world \"\"\"\n        '''\n        )\n        result = pytester.runpytest(\"--fixtures\", p)\n        result.stdout.fnmatch_lines(\n            \"\"\"\n            *tmp_path -- *\n            *fixtures defined from*\n            *arg1 -- test_show_fixtures_testmodule.py:6*\n            *hello world*\n        \"\"\"\n        )\n        result.stdout.no_fnmatch_line(\"*arg0*\")\n\n    @pytest.mark.parametrize(\"testmod\", [True, False])\n  "}, {"start_line": 0, "end_line": 2000, "belongs_to": {"file_name": "show_fixtures_per_test.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing/python", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "from __future__ import annotations\n\nfrom _pytest.pytester import Pytester\n\n\ndef test_no_items_should_not_show_output(pytester: Pytester) -> None:\n    result = pytester.runpytest(\"--fixtures-per-test\")\n    result.stdout.no_fnmatch_line(\"*fixtures used by*\")\n    assert result.ret == 0\n\n\ndef test_fixtures_in_module(pytester: Pytester) -> None:\n    p = pytester.makepyfile(\n        '''\n        import pytest\n        @pytest.fixture\n        def _arg0():\n            \"\"\"hidden arg0 fixture\"\"\"\n        @pytest.fixture\n        def arg1():\n            \"\"\"arg1 docstring\"\"\"\n        def test_arg1(arg1):\n            pass\n    '''\n    )\n\n    result = pytester.runpytest(\"--fixtures-per-test\", p)\n    assert result.ret == 0\n\n    result.stdout.fnmatch_lines(\n        [\n            \"*fixtures used by test_arg1*\",\n            \"*(test_fixtures_in_module.py:9)*\",\n            \"arg1 -- test_fixtures_in_module.py:6\",\n            \"    arg1 docstring\",\n        ]\n    )\n    result.stdout.no_fnmatch_line(\"*_arg0*\")\n\n\ndef test_fixtures_in_conftest(pytester: Pytester) -> None:\n    pytester.makeconftest(\n        '''\n        import pytest\n        @pytest.fixture\n        def arg1():\n            \"\"\"arg1 docstring\"\"\"\n        @pytest.fixture\n        def arg2():\n            \"\"\"arg2 docstring\"\"\"\n        @pytest.fixture\n        def arg3(arg1, arg2):\n            \"\"\"arg3\n            docstring\n            \"\"\"\n    '''\n    )\n    p = pytester.makepyfile(\n        \"\"\"\n        def test_arg2(arg2):\n            pass\n        def test_arg3(arg3):\n            pass\n    \"\"\"\n    )\n    result = pytester.runpytest(\"--fixtures-per-test\", p)\n    assert result.ret == 0\n\n    result.stdout.fnmatch_lines(\n        [\n            \"*fixtures used by test_arg2*\",\n            \"*(test_fixtures_in_conftest.py:2)*\",\n            \"arg2 -- conftest.py:6\",\n            \"    arg2 docstring\",\n            \"*fixtures used by test_arg3*\",\n            \"*(test_fixtures_in_conftest.py:4)*\",\n            \"arg1 -- conftest.py:3\",\n            \"    arg1 docstring"}], "retrieved_count": 10, "cost_time": 1.1962409019470215}
{"question": "Why does the repeated instantiation of FNMatcher objects in the Visitor.__init__ method impact memory consumption and traversal performance when processing large directory trees with complex filtering patterns?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"start_line": 3000, "end_line": 5000, "belongs_to": {"file_name": "path.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest/_py", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "he: Stat\n\n    def _stat(self) -> Stat:\n        try:\n            return self._statcache\n        except AttributeError:\n            try:\n                self._statcache = self.path.stat()\n            except error.ELOOP:\n                self._statcache = self.path.lstat()\n            return self._statcache\n\n    def dir(self):\n        return S_ISDIR(self._stat().mode)\n\n    def file(self):\n        return S_ISREG(self._stat().mode)\n\n    def exists(self):\n        return self._stat()\n\n    def link(self):\n        st = self.path.lstat()\n        return S_ISLNK(st.mode)\n\n\nclass NeverRaised(Exception):\n    pass\n\n\nclass Visitor:\n    def __init__(self, fil, rec, ignore, bf, sort):\n        if isinstance(fil, str):\n            fil = FNMatcher(fil)\n        if isinstance(rec, str):\n            self.rec: Callable[[LocalPath], bool] = FNMatcher(rec)\n        elif not hasattr(rec, \"__call__\") and rec:\n            self.rec = lambda path: True\n        else:\n            self.rec = rec\n        self.fil = fil\n        self.ignore = ignore\n        self.breadthfirst = bf\n        self.optsort = cast(Callable[[Any], Any], sorted) if sort else (lambda x: x)\n\n    def gen(self, path):\n        try:\n            entries = path.listdir()\n        except self.ignore:\n            return\n        rec = self.rec\n        dirs = self.optsort(\n            [p for p in entries if p.check(dir=1) and (rec is None or rec(p))]\n        )\n        if not self.breadthfirst:\n            for subdir in dirs:\n                yield from self.gen(subdir)\n        for p in self.optsort(entries):\n            if self.fil is None or self.fil(p):\n                yield p\n        if self.breadthfirst:\n            for subdir in dirs:\n                yield from self.gen(subdir)\n\n\nclass FNMatcher:\n    def __init__(self, pattern):\n        self.pattern = pattern\n\n    def __call__(self, path):\n        pattern = self.pattern\n\n        if (\n            pattern.find(path.sep) == -1\n            and iswin32\n            and pattern.find(posixpath.sep"}, {"start_line": 4000, "end_line": 6000, "belongs_to": {"file_name": "path.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest/_py", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "     self.ignore = ignore\n        self.breadthfirst = bf\n        self.optsort = cast(Callable[[Any], Any], sorted) if sort else (lambda x: x)\n\n    def gen(self, path):\n        try:\n            entries = path.listdir()\n        except self.ignore:\n            return\n        rec = self.rec\n        dirs = self.optsort(\n            [p for p in entries if p.check(dir=1) and (rec is None or rec(p))]\n        )\n        if not self.breadthfirst:\n            for subdir in dirs:\n                yield from self.gen(subdir)\n        for p in self.optsort(entries):\n            if self.fil is None or self.fil(p):\n                yield p\n        if self.breadthfirst:\n            for subdir in dirs:\n                yield from self.gen(subdir)\n\n\nclass FNMatcher:\n    def __init__(self, pattern):\n        self.pattern = pattern\n\n    def __call__(self, path):\n        pattern = self.pattern\n\n        if (\n            pattern.find(path.sep) == -1\n            and iswin32\n            and pattern.find(posixpath.sep) != -1\n        ):\n            # Running on Windows, the pattern has no Windows path separators,\n            # and the pattern has one or more Posix path separators. Replace\n            # the Posix path separators with the Windows path separator.\n            pattern = pattern.replace(posixpath.sep, path.sep)\n\n        if pattern.find(path.sep) == -1:\n            name = path.basename\n        else:\n            name = str(path)  # path.strpath # XXX svn?\n            if not os.path.isabs(pattern):\n                pattern = \"*\" + path.sep + pattern\n        return fnmatch.fnmatch(name, pattern)\n\n\ndef map_as_list(func, iter):\n    return list(map(func, iter))\n\n\nclass Stat:\n    if TYPE_CHECKING:\n\n        @property\n        def size(self) -> int: ...\n\n        @property\n        def mtime(self) -> float: ...\n\n    def __getattr__(self, name: str) -> Any:\n        return getattr(self._osstatresult, \"st_\" + name)\n\n    def __init__(self, path, osstatresult):\n        self.path = path\n        self._osstatr"}, {"start_line": 2000, "end_line": 4000, "belongs_to": {"file_name": "path.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest/_py", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "                  pass\n            if meth is None:\n                raise TypeError(f\"no {name!r} checker available for {self.path!r}\")\n            try:\n                if getrawcode(meth).co_argcount > 1:\n                    if (not meth(value)) ^ invert:\n                        return False\n                else:\n                    if bool(value) ^ bool(meth()) ^ invert:\n                        return False\n            except (error.ENOENT, error.ENOTDIR, error.EBUSY):\n                # EBUSY feels not entirely correct,\n                # but its kind of necessary since ENOMEDIUM\n                # is not accessible in python\n                for name in self._depend_on_existence:\n                    if name in kw:\n                        if kw.get(name):\n                            return False\n                    name = \"not\" + name\n                    if name in kw:\n                        if not kw.get(name):\n                            return False\n        return True\n\n    _statcache: Stat\n\n    def _stat(self) -> Stat:\n        try:\n            return self._statcache\n        except AttributeError:\n            try:\n                self._statcache = self.path.stat()\n            except error.ELOOP:\n                self._statcache = self.path.lstat()\n            return self._statcache\n\n    def dir(self):\n        return S_ISDIR(self._stat().mode)\n\n    def file(self):\n        return S_ISREG(self._stat().mode)\n\n    def exists(self):\n        return self._stat()\n\n    def link(self):\n        st = self.path.lstat()\n        return S_ISLNK(st.mode)\n\n\nclass NeverRaised(Exception):\n    pass\n\n\nclass Visitor:\n    def __init__(self, fil, rec, ignore, bf, sort):\n        if isinstance(fil, str):\n            fil = FNMatcher(fil)\n        if isinstance(rec, str):\n            self.rec: Callable[[LocalPath], bool] = FNMatcher(rec)\n        elif not hasattr(rec, \"__call__\") and rec:\n            self.rec = lambda path: True\n        else:\n            self.rec = rec\n        self.fil = fil\n   "}, {"start_line": 2000, "end_line": 4000, "belongs_to": {"file_name": "test_pathlib.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "ause of that, so common module names such as \"test\" or \"test.conftest\"\n    end up leaking to tests in other modules.\n\n    Note: we might consider extracting the sys.path restoration aspect into its own fixture, and apply it\n    to the entire test suite always.\n    \"\"\"\n\n\nclass TestFNMatcherPort:\n    \"\"\"Test our port of py.common.FNMatcher (fnmatch_ex).\"\"\"\n\n    if sys.platform == \"win32\":\n        drv1 = \"c:\"\n        drv2 = \"d:\"\n    else:\n        drv1 = \"/c\"\n        drv2 = \"/d\"\n\n    @pytest.mark.parametrize(\n        \"pattern, path\",\n        [\n            (\"*.py\", \"foo.py\"),\n            (\"*.py\", \"bar/foo.py\"),\n            (\"test_*.py\", \"foo/test_foo.py\"),\n            (\"tests/*.py\", \"tests/foo.py\"),\n            (f\"{drv1}/*.py\", f\"{drv1}/foo.py\"),\n            (f\"{drv1}/foo/*.py\", f\"{drv1}/foo/foo.py\"),\n            (\"tests/**/test*.py\", \"tests/foo/test_foo.py\"),\n            (\"tests/**/doc/test*.py\", \"tests/foo/bar/doc/test_foo.py\"),\n            (\"tests/**/doc/**/test*.py\", \"tests/foo/doc/bar/test_foo.py\"),\n        ],\n    )\n    def test_matching(self, pattern: str, path: str) -> None:\n        assert fnmatch_ex(pattern, path)\n\n    def test_matching_abspath(self) -> None:\n        abspath = os.path.abspath(os.path.join(\"tests/foo.py\"))\n        assert fnmatch_ex(\"tests/foo.py\", abspath)\n\n    @pytest.mark.parametrize(\n        \"pattern, path\",\n        [\n            (\"*.py\", \"foo.pyc\"),\n            (\"*.py\", \"foo/foo.pyc\"),\n            (\"tests/*.py\", \"foo/foo.py\"),\n            (f\"{drv1}/*.py\", f\"{drv2}/foo.py\"),\n            (f\"{drv1}/foo/*.py\", f\"{drv2}/foo/foo.py\"),\n            (\"tests/**/test*.py\", \"tests/foo.py\"),\n            (\"tests/**/test*.py\", \"foo/test_foo.py\"),\n            (\"tests/**/doc/test*.py\", \"tests/foo/bar/doc/foo.py\"),\n            (\"tests/**/doc/test*.py\", \"tests/foo/bar/test_foo.py\"),\n        ],\n    )\n    def test_not_matching(self, pattern: str, path: str) -> None:\n        assert not fnmatch_ex(pattern, path)\n\n\n@pytest.fixture(params=[True, False])\ndef ns_param(r"}, {"start_line": 32000, "end_line": 34000, "belongs_to": {"file_name": "main.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "          if isinstance(matchparts[0], Path):\n                        is_match = node.path == matchparts[0]\n                        if sys.platform == \"win32\" and not is_match:\n                            # In case the file paths do not match, fallback to samefile() to\n                            # account for short-paths on Windows (#11895).\n                            same_file = os.path.samefile(node.path, matchparts[0])\n                            # We don't want to match links to the current node,\n                            # otherwise we would match the same file more than once (#12039).\n                            is_match = same_file and (\n                                os.path.islink(node.path)\n                                == os.path.islink(matchparts[0])\n                            )\n\n                    # Name part e.g. `TestIt` in `/a/b/test_file.py::TestIt::test_it`.\n                    else:\n                        # TODO: Remove parametrized workaround once collection structure contains\n                        # parametrization.\n                        is_match = (\n                            node.name == matchparts[0]\n                            or node.name.split(\"[\")[0] == matchparts[0]\n                        )\n                    if is_match:\n                        work.append((node, matchparts[1:]))\n                        any_matched_in_collector = True\n\n                if not any_matched_in_collector:\n                    notfound_collectors.append(matchnode)\n\n            if not any_matched_in_initial_part:\n                report_arg = \"::\".join((str(argpath), *names))\n                self._notfound.append((report_arg, notfound_collectors))\n\n            self.trace.root.indent -= 1\n\n    def genitems(self, node: nodes.Item | nodes.Collector) -> Iterator[nodes.Item]:\n        self.trace(\"genitems\", node)\n        if isinstance(node, nodes.Item):\n            node.ihook.pytest_itemcollected(item=node)\n            yield node\n        else:\n       "}, {"start_line": 16000, "end_line": 18000, "belongs_to": {"file_name": "path.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest/_py", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "ot matching the\n        path will not be yielded, defaulting to None (everything is\n        returned)\n\n        rec is a filter (glob pattern or callable) that controls whether\n        a node is descended, defaulting to None\n\n        ignore is an Exception class that is ignoredwhen calling dirlist()\n        on any of the paths (by default, all exceptions are reported)\n\n        bf if True will cause a breadthfirst search instead of the\n        default depthfirst. Default: False\n\n        sort if True will sort entries within each directory level.\n        \"\"\"\n        yield from Visitor(fil, rec, ignore, bf, sort).gen(self)\n\n    def _sortlist(self, res, sort):\n        if sort:\n            if hasattr(sort, \"__call__\"):\n                warnings.warn(\n                    DeprecationWarning(\n                        \"listdir(sort=callable) is deprecated and breaks on python3\"\n                    ),\n                    stacklevel=3,\n                )\n                res.sort(sort)\n            else:\n                res.sort()\n\n    def __fspath__(self):\n        return self.strpath\n\n    def __hash__(self):\n        s = self.strpath\n        if iswin32:\n            s = s.lower()\n        return hash(s)\n\n    def __eq__(self, other):\n        s1 = os.fspath(self)\n        try:\n            s2 = os.fspath(other)\n        except TypeError:\n            return False\n        if iswin32:\n            s1 = s1.lower()\n            try:\n                s2 = s2.lower()\n            except AttributeError:\n                return False\n        return s1 == s2\n\n    def __ne__(self, other):\n        return not (self == other)\n\n    def __lt__(self, other):\n        return os.fspath(self) < os.fspath(other)\n\n    def __gt__(self, other):\n        return os.fspath(self) > os.fspath(other)\n\n    def samefile(self, other):\n        \"\"\"Return True if 'other' references the same file as 'self'.\"\"\"\n        other = os.fspath(other)\n        if not isabs(other):\n            other = abspath(other)\n        if self == other:\n "}, {"start_line": 29000, "end_line": 31000, "belongs_to": {"file_name": "main.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "          if not pm._is_in_confcutdir(path):\n                        break\n                    paths.insert(0, path)\n            else:\n                # For --pyargs arguments, only consider paths matching the module\n                # name. Paths beyond the package hierarchy are not included.\n                module_name_parts = module_name.split(\".\")\n                for i, path in enumerate(argpath.parents, 2):\n                    if i > len(module_name_parts) or path.stem != module_name_parts[-i]:\n                        break\n                    paths.insert(0, path)\n\n            # Start going over the parts from the root, collecting each level\n            # and discarding all nodes which don't match the level's part.\n            any_matched_in_initial_part = False\n            notfound_collectors = []\n            work: list[tuple[nodes.Collector | nodes.Item, list[Path | str]]] = [\n                (self, [*paths, *names])\n            ]\n            while work:\n                matchnode, matchparts = work.pop()\n\n                # Pop'd all of the parts, this is a match.\n                if not matchparts:\n                    yield matchnode\n                    any_matched_in_initial_part = True\n                    continue\n\n                # Should have been matched by now, discard.\n                if not isinstance(matchnode, nodes.Collector):\n                    continue\n\n                # Collect this level of matching.\n                # Collecting Session (self) is done directly to avoid endless\n                # recursion to this function.\n                subnodes: Sequence[nodes.Collector | nodes.Item]\n                if isinstance(matchnode, Session):\n                    assert isinstance(matchparts[0], Path)\n                    subnodes = matchnode._collect_path(matchparts[0], path_cache)\n                else:\n                    # For backward compat, files given directly multiple\n                    # times on the command line should not be deduplicated.\n  "}, {"start_line": 27000, "end_line": 29000, "belongs_to": {"file_name": "test_local.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing/_py", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "test_visit_depth_first(self, tmpdir):\n        tmpdir.ensure(\"a\", \"1\")\n        tmpdir.ensure(\"b\", \"2\")\n        p3 = tmpdir.ensure(\"breadth\")\n        lst = list(tmpdir.visit(lambda x: x.check(file=1)))\n        assert len(lst) == 3\n        # check that breadth comes last\n        assert lst[2] == p3\n\n    def test_visit_rec_fnmatch(self, tmpdir):\n        p1 = tmpdir.ensure(\"a\", \"123\")\n        tmpdir.ensure(\".b\", \"345\")\n        lst = list(tmpdir.visit(\"???\", rec=\"[!.]*\"))\n        assert len(lst) == 1\n        # check that breadth comes last\n        assert lst[0] == p1\n\n    def test_fnmatch_file_abspath(self, tmpdir):\n        b = tmpdir.join(\"a\", \"b\")\n        assert b.fnmatch(os.sep.join(\"ab\"))\n        pattern = os.sep.join([str(tmpdir), \"*\", \"b\"])\n        assert b.fnmatch(pattern)\n\n    def test_sysfind(self):\n        name = (sys.platform == \"win32\" and \"cmd\") or \"test\"\n        x = local.sysfind(name)\n        assert x.check(file=1)\n        assert local.sysfind(\"jaksdkasldqwe\") is None\n        assert local.sysfind(name, paths=[]) is None\n        x2 = local.sysfind(name, paths=[x.dirpath()])\n        assert x2 == x\n\n    def test_fspath_protocol_other_class(self, fake_fspath_obj):\n        # py.path is always absolute\n        py_path = local(fake_fspath_obj)\n        str_path = fake_fspath_obj.__fspath__()\n        assert py_path.check(endswith=str_path)\n        assert py_path.join(fake_fspath_obj).strpath == os.path.join(\n            py_path.strpath, str_path\n        )\n\n    @pytest.mark.xfail(\n        reason=\"#11603\", raises=(error.EEXIST, error.ENOENT), strict=False\n    )\n    def test_make_numbered_dir_multiprocess_safe(self, tmpdir):\n        # https://github.com/pytest-dev/py/issues/30\n        with multiprocessing.Pool() as pool:\n            results = [\n                pool.apply_async(batch_make_numbered_dirs, [tmpdir, 100])\n                for _ in range(20)\n            ]\n            for r in results:\n                assert r.get()\n\n\nclass TestExecutionOnWindows:\n    pytestma"}, {"start_line": 31000, "end_line": 33000, "belongs_to": {"file_name": "main.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "                  handle_dupes = not (\n                        len(matchparts) == 1\n                        and isinstance(matchparts[0], Path)\n                        and matchparts[0].is_file()\n                    )\n                    rep, duplicate = self._collect_one_node(matchnode, handle_dupes)\n                    if not duplicate and not rep.passed:\n                        # Report collection failures here to avoid failing to\n                        # run some test specified in the command line because\n                        # the module could not be imported (#134).\n                        matchnode.ihook.pytest_collectreport(report=rep)\n                    if not rep.passed:\n                        continue\n                    subnodes = rep.result\n\n                # Prune this level.\n                any_matched_in_collector = False\n                for node in reversed(subnodes):\n                    # Path part e.g. `/a/b/` in `/a/b/test_file.py::TestIt::test_it`.\n                    if isinstance(matchparts[0], Path):\n                        is_match = node.path == matchparts[0]\n                        if sys.platform == \"win32\" and not is_match:\n                            # In case the file paths do not match, fallback to samefile() to\n                            # account for short-paths on Windows (#11895).\n                            same_file = os.path.samefile(node.path, matchparts[0])\n                            # We don't want to match links to the current node,\n                            # otherwise we would match the same file more than once (#12039).\n                            is_match = same_file and (\n                                os.path.islink(node.path)\n                                == os.path.islink(matchparts[0])\n                            )\n\n                    # Name part e.g. `TestIt` in `/a/b/test_file.py::TestIt::test_it`.\n                    else:\n                        # TODO: Remove parametrized workaround once collecti"}, {"start_line": 30000, "end_line": 32000, "belongs_to": {"file_name": "main.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "e, matchparts = work.pop()\n\n                # Pop'd all of the parts, this is a match.\n                if not matchparts:\n                    yield matchnode\n                    any_matched_in_initial_part = True\n                    continue\n\n                # Should have been matched by now, discard.\n                if not isinstance(matchnode, nodes.Collector):\n                    continue\n\n                # Collect this level of matching.\n                # Collecting Session (self) is done directly to avoid endless\n                # recursion to this function.\n                subnodes: Sequence[nodes.Collector | nodes.Item]\n                if isinstance(matchnode, Session):\n                    assert isinstance(matchparts[0], Path)\n                    subnodes = matchnode._collect_path(matchparts[0], path_cache)\n                else:\n                    # For backward compat, files given directly multiple\n                    # times on the command line should not be deduplicated.\n                    handle_dupes = not (\n                        len(matchparts) == 1\n                        and isinstance(matchparts[0], Path)\n                        and matchparts[0].is_file()\n                    )\n                    rep, duplicate = self._collect_one_node(matchnode, handle_dupes)\n                    if not duplicate and not rep.passed:\n                        # Report collection failures here to avoid failing to\n                        # run some test specified in the command line because\n                        # the module could not be imported (#134).\n                        matchnode.ihook.pytest_collectreport(report=rep)\n                    if not rep.passed:\n                        continue\n                    subnodes = rep.result\n\n                # Prune this level.\n                any_matched_in_collector = False\n                for node in reversed(subnodes):\n                    # Path part e.g. `/a/b/` in `/a/b/test_file.py::TestIt::test_it`.\n          "}], "retrieved_count": 10, "cost_time": 1.1955132484436035}
{"question": "Why does the test design rely on injecting the TerminalReporter through a fixture request rather than directly instantiating it, and what architectural principle does this reflect about pytest's plugin system?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"start_line": 4000, "end_line": 6000, "belongs_to": {"file_name": "test_terminal.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "None:\n        modcol = pytester.getmodulecol(\"def test_one(): pass\")\n        rep = TerminalReporter(modcol.config, file=linecomp.stringio)\n        with pytest.raises(ValueError) as excinfo:\n            raise ValueError(\"hello\")\n        rep.pytest_internalerror(excinfo.getrepr())\n        linecomp.assert_contains_lines([\"INTERNALERROR> *ValueError*hello*\"])\n\n    def test_writeline(self, pytester: Pytester, linecomp) -> None:\n        modcol = pytester.getmodulecol(\"def test_one(): pass\")\n        rep = TerminalReporter(modcol.config, file=linecomp.stringio)\n        rep.write_fspath_result(modcol.nodeid, \".\")\n        rep.write_line(\"hello world\")\n        lines = linecomp.stringio.getvalue().split(\"\\n\")\n        assert not lines[0]\n        assert lines[1].endswith(modcol.name + \" .\")\n        assert lines[2] == \"hello world\"\n\n    def test_show_runtest_logstart(self, pytester: Pytester, linecomp) -> None:\n        item = pytester.getitem(\"def test_func(): pass\")\n        tr = TerminalReporter(item.config, file=linecomp.stringio)\n        item.config.pluginmanager.register(tr)\n        location = item.reportinfo()\n        tr.config.hook.pytest_runtest_logstart(\n            nodeid=item.nodeid, location=location, fspath=str(item.path)\n        )\n        linecomp.assert_contains_lines([\"*test_show_runtest_logstart.py*\"])\n\n    def test_runtest_location_shown_before_test_starts(\n        self, pytester: Pytester\n    ) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            def test_1():\n                import time\n                time.sleep(20)\n        \"\"\"\n        )\n        child = pytester.spawn_pytest(\"\")\n        child.expect(\".*test_runtest_location.*py\")\n        child.sendeof()\n        child.kill(15)\n\n    def test_report_collect_after_half_a_second(\n        self, pytester: Pytester, monkeypatch: MonkeyPatch\n    ) -> None:\n        \"\"\"Test for \"collecting\" being updated after 0.5s\"\"\"\n        pytester.makepyfile(\n            **{\n                \"test1.py\": \"\"\"\n               "}, {"start_line": 61000, "end_line": 63000, "belongs_to": {"file_name": "test_terminal.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "o_fnmatch_line(\"*= warnings summary =*\")\n    result.stdout.no_fnmatch_line(\"*= short test summary info =*\")\n\n\n@pytest.fixture(scope=\"session\")\ndef tr() -> TerminalReporter:\n    config = _pytest.config._prepareconfig([])\n    return TerminalReporter(config)\n\n\n@pytest.mark.parametrize(\n    \"exp_color, exp_line, stats_arg\",\n    [\n        # The method under test only cares about the length of each\n        # dict value, not the actual contents, so tuples of anything\n        # suffice\n        # Important statuses -- the highest priority of these always wins\n        (\"red\", [(\"1 failed\", {\"bold\": True, \"red\": True})], {\"failed\": [1]}),\n        (\n            \"red\",\n            [\n                (\"1 failed\", {\"bold\": True, \"red\": True}),\n                (\"1 passed\", {\"bold\": False, \"green\": True}),\n            ],\n            {\"failed\": [1], \"passed\": [1]},\n        ),\n        (\"red\", [(\"1 error\", {\"bold\": True, \"red\": True})], {\"error\": [1]}),\n        (\"red\", [(\"2 errors\", {\"bold\": True, \"red\": True})], {\"error\": [1, 2]}),\n        (\n            \"red\",\n            [\n                (\"1 passed\", {\"bold\": False, \"green\": True}),\n                (\"1 error\", {\"bold\": True, \"red\": True}),\n            ],\n            {\"error\": [1], \"passed\": [1]},\n        ),\n        # (a status that's not known to the code)\n        (\"yellow\", [(\"1 weird\", {\"bold\": True, \"yellow\": True})], {\"weird\": [1]}),\n        (\n            \"yellow\",\n            [\n                (\"1 passed\", {\"bold\": False, \"green\": True}),\n                (\"1 weird\", {\"bold\": True, \"yellow\": True}),\n            ],\n            {\"weird\": [1], \"passed\": [1]},\n        ),\n        (\"yellow\", [(\"1 warning\", {\"bold\": True, \"yellow\": True})], {\"warnings\": [1]}),\n        (\n            \"yellow\",\n            [\n                (\"1 passed\", {\"bold\": False, \"green\": True}),\n                (\"1 warning\", {\"bold\": True, \"yellow\": True}),\n            ],\n            {\"warnings\": [1], \"passed\": [1]},\n        ),\n        (\n            \"green\",\n       "}, {"start_line": 11000, "end_line": 13000, "belongs_to": {"file_name": "test_terminal.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "st_foobar():\n                pass\n        \"\"\"\n        )\n        result = pytester.runpytest()\n        result.stdout.fnmatch_lines([\"collected 1 item\"])\n\n    def test_rewrite(self, pytester: Pytester, monkeypatch) -> None:\n        config = pytester.parseconfig()\n        f = StringIO()\n        monkeypatch.setattr(f, \"isatty\", lambda *args: True)\n        tr = TerminalReporter(config, f)\n        tr._tw.fullwidth = 10\n        tr.write(\"hello\")\n        tr.rewrite(\"hey\", erase=True)\n        assert f.getvalue() == \"hello\" + \"\\r\" + \"hey\" + (6 * \" \")\n\n    @pytest.mark.parametrize(\"category\", [\"foo\", \"failed\", \"error\", \"passed\"])\n    def test_report_teststatus_explicit_markup(\n        self, monkeypatch: MonkeyPatch, pytester: Pytester, color_mapping, category: str\n    ) -> None:\n        \"\"\"Test that TerminalReporter handles markup explicitly provided by\n        a pytest_report_teststatus hook.\"\"\"\n        monkeypatch.setenv(\"PY_COLORS\", \"1\")\n        pytester.makeconftest(\n            f\"\"\"\n            def pytest_report_teststatus(report):\n                return {category!r}, 'F', ('FOO', {{'red': True}})\n        \"\"\"\n        )\n        pytester.makepyfile(\n            \"\"\"\n            def test_foobar():\n                pass\n        \"\"\"\n        )\n\n        result = pytester.runpytest(\"-v\")\n        assert not result.stderr.lines\n        result.stdout.fnmatch_lines(\n            color_mapping.format_for_fnmatch([\"*{red}FOO{reset}*\"])\n        )\n\n    def test_verbose_skip_reason(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n\n            @pytest.mark.skip(reason=\"123\")\n            def test_1():\n                pass\n\n            @pytest.mark.xfail(reason=\"456\")\n            def test_2():\n                pass\n\n            @pytest.mark.xfail(reason=\"789\")\n            def test_3():\n                assert False\n\n            @pytest.mark.xfail(reason=\"\")\n            def test_4():\n                assert False\n\n            @pytest.mark.ski"}, {"start_line": 3000, "end_line": 5000, "belongs_to": {"file_name": "test_terminal.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "\n            result.stdout.fnmatch_lines([\".sF*\"])\n        result.stdout.fnmatch_lines(\n            [\"    def test_func():\", \">       assert 0\", \"E       assert 0\"]\n        )\n\n    def test_console_output_style_times_with_skipped_and_passed(\n        self, pytester: Pytester\n    ) -> None:\n        pytester.makepyfile(\n            test_repro=\"\"\"\n                def test_hello():\n                    pass\n            \"\"\",\n            test_repro_skip=\"\"\"\n                import pytest\n                pytest.importorskip(\"fakepackage_does_not_exist\")\n            \"\"\",\n        )\n        result = pytester.runpytest(\n            \"test_repro.py\",\n            \"test_repro_skip.py\",\n            \"-o\",\n            \"console_output_style=times\",\n        )\n\n        result.stdout.fnmatch_lines(\"* 1 passed, 1 skipped in *\")\n\n        combined = \"\\n\".join(result.stdout.lines + result.stderr.lines)\n        assert \"INTERNALERROR\" not in combined\n\n    def test_internalerror(self, pytester: Pytester, linecomp) -> None:\n        modcol = pytester.getmodulecol(\"def test_one(): pass\")\n        rep = TerminalReporter(modcol.config, file=linecomp.stringio)\n        with pytest.raises(ValueError) as excinfo:\n            raise ValueError(\"hello\")\n        rep.pytest_internalerror(excinfo.getrepr())\n        linecomp.assert_contains_lines([\"INTERNALERROR> *ValueError*hello*\"])\n\n    def test_writeline(self, pytester: Pytester, linecomp) -> None:\n        modcol = pytester.getmodulecol(\"def test_one(): pass\")\n        rep = TerminalReporter(modcol.config, file=linecomp.stringio)\n        rep.write_fspath_result(modcol.nodeid, \".\")\n        rep.write_line(\"hello world\")\n        lines = linecomp.stringio.getvalue().split(\"\\n\")\n        assert not lines[0]\n        assert lines[1].endswith(modcol.name + \" .\")\n        assert lines[2] == \"hello world\"\n\n    def test_show_runtest_logstart(self, pytester: Pytester, linecomp) -> None:\n        item = pytester.getitem(\"def test_func(): pass\")\n        tr = TerminalReporter(ite"}, {"start_line": 48000, "end_line": 50000, "belongs_to": {"file_name": "test_terminal.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "a\"\n    assert getreportopt(config) == \"sxXEf\"\n\n    config.option.reportchars = \"A\"\n    assert getreportopt(config) == \"PpsxXEf\"\n\n    config.option.reportchars = \"AN\"\n    assert getreportopt(config) == \"\"\n\n    config.option.reportchars = \"NwfE\"\n    assert getreportopt(config) == \"fE\"\n\n\ndef test_terminalreporter_reportopt_addopts(pytester: Pytester) -> None:\n    pytester.makeini(\"[pytest]\\naddopts=-rs\")\n    pytester.makepyfile(\n        \"\"\"\n        import pytest\n\n        @pytest.fixture\n        def tr(request):\n            tr = request.config.pluginmanager.getplugin(\"terminalreporter\")\n            return tr\n        def test_opt(tr):\n            assert tr.hasopt('skipped')\n            assert not tr.hasopt('qwe')\n    \"\"\"\n    )\n    result = pytester.runpytest()\n    result.stdout.fnmatch_lines([\"*1 passed*\"])\n\n\ndef test_tbstyle_short(pytester: Pytester) -> None:\n    p = pytester.makepyfile(\n        \"\"\"\n        import pytest\n\n        @pytest.fixture\n        def arg(request):\n            return 42\n        def test_opt(arg):\n            x = 0\n            assert x\n    \"\"\"\n    )\n    result = pytester.runpytest(\"--tb=short\")\n    s = result.stdout.str()\n    assert \"arg = 42\" not in s\n    assert \"x = 0\" not in s\n    result.stdout.fnmatch_lines([f\"*{p.name}:8*\", \"    assert x\", \"E   assert*\"])\n    result = pytester.runpytest()\n    s = result.stdout.str()\n    assert \"x = 0\" in s\n    assert \"assert x\" in s\n\n\ndef test_traceconfig(pytester: Pytester) -> None:\n    result = pytester.runpytest(\"--traceconfig\")\n    result.stdout.fnmatch_lines([\"*active plugins*\"])\n    assert result.ret == ExitCode.NO_TESTS_COLLECTED\n\n\nclass TestGenericReporting:\n    \"\"\"Test class which can be subclassed with a different option provider to\n    run e.g. distributed tests.\"\"\"\n\n    def test_collect_fail(self, pytester: Pytester, option) -> None:\n        pytester.makepyfile(\"import xyz\\n\")\n        result = pytester.runpytest(*option.args)\n        result.stdout.fnmatch_lines(\n            [\"ImportError while impo"}, {"start_line": 0, "end_line": 2000, "belongs_to": {"file_name": "test_terminal.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "# mypy: allow-untyped-defs\n\"\"\"Terminal reporting of the full testing process.\"\"\"\n\nfrom __future__ import annotations\n\nfrom io import StringIO\nimport os\nfrom pathlib import Path\nimport sys\nimport textwrap\nfrom types import SimpleNamespace\nfrom typing import cast\nfrom typing import NamedTuple\n\nimport pluggy\n\nfrom _pytest._io.wcwidth import wcswidth\nimport _pytest.config\nfrom _pytest.config import Config\nfrom _pytest.config import ExitCode\nfrom _pytest.monkeypatch import MonkeyPatch\nfrom _pytest.pytester import Pytester\nfrom _pytest.reports import BaseReport\nfrom _pytest.reports import CollectReport\nfrom _pytest.reports import TestReport\nimport _pytest.terminal\nfrom _pytest.terminal import _folded_skips\nfrom _pytest.terminal import _format_trimmed\nfrom _pytest.terminal import _get_line_with_reprcrash_message\nfrom _pytest.terminal import _get_raw_skip_reason\nfrom _pytest.terminal import _plugin_nameversions\nfrom _pytest.terminal import getreportopt\nfrom _pytest.terminal import TerminalReporter\nimport pytest\n\n\nclass DistInfo(NamedTuple):\n    project_name: str\n    version: int\n\n\nTRANS_FNMATCH = str.maketrans({\"[\": \"[[]\", \"]\": \"[]]\"})\n\n\nclass Option:\n    def __init__(self, verbosity=0):\n        self.verbosity = verbosity\n\n    @property\n    def args(self):\n        values = []\n        values.append(f\"--verbosity={self.verbosity}\")\n        return values\n\n\n@pytest.fixture(\n    params=[Option(verbosity=0), Option(verbosity=1), Option(verbosity=-1)],\n    ids=[\"default\", \"verbose\", \"quiet\"],\n)\ndef option(request):\n    return request.param\n\n\n@pytest.mark.parametrize(\n    \"input,expected\",\n    [\n        ([DistInfo(project_name=\"test\", version=1)], [\"test-1\"]),\n        ([DistInfo(project_name=\"pytest-test\", version=1)], [\"test-1\"]),\n        (\n            [\n                DistInfo(project_name=\"test\", version=1),\n                DistInfo(project_name=\"test\", version=1),\n            ],\n            [\"test-1\"],\n        ),\n    ],\n    ids=[\"normal\", \"prefix-strip\", \"deduplicate\"],\n)\ndef "}, {"start_line": 10000, "end_line": 12000, "belongs_to": {"file_name": "test_terminal.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "_lines(\n                [\"*raise KeyboardInterrupt   # simulating the user*\"]\n            )\n        else:\n            result.stdout.fnmatch_lines(\n                [\"(to show a full traceback on KeyboardInterrupt use --full-trace)\"]\n            )\n        result.stdout.fnmatch_lines([\"*KeyboardInterrupt*\"])\n\n    def test_keyboard_in_sessionstart(self, pytester: Pytester) -> None:\n        pytester.makeconftest(\n            \"\"\"\n            def pytest_sessionstart():\n                raise KeyboardInterrupt\n        \"\"\"\n        )\n        pytester.makepyfile(\n            \"\"\"\n            def test_foobar():\n                pass\n        \"\"\"\n        )\n\n        result = pytester.runpytest(no_reraise_ctrlc=True)\n        assert result.ret == 2\n        result.stdout.fnmatch_lines([\"*KeyboardInterrupt*\"])\n\n    def test_collect_single_item(self, pytester: Pytester) -> None:\n        \"\"\"Use singular 'item' when reporting a single test item\"\"\"\n        pytester.makepyfile(\n            \"\"\"\n            def test_foobar():\n                pass\n        \"\"\"\n        )\n        result = pytester.runpytest()\n        result.stdout.fnmatch_lines([\"collected 1 item\"])\n\n    def test_rewrite(self, pytester: Pytester, monkeypatch) -> None:\n        config = pytester.parseconfig()\n        f = StringIO()\n        monkeypatch.setattr(f, \"isatty\", lambda *args: True)\n        tr = TerminalReporter(config, f)\n        tr._tw.fullwidth = 10\n        tr.write(\"hello\")\n        tr.rewrite(\"hey\", erase=True)\n        assert f.getvalue() == \"hello\" + \"\\r\" + \"hey\" + (6 * \" \")\n\n    @pytest.mark.parametrize(\"category\", [\"foo\", \"failed\", \"error\", \"passed\"])\n    def test_report_teststatus_explicit_markup(\n        self, monkeypatch: MonkeyPatch, pytester: Pytester, color_mapping, category: str\n    ) -> None:\n        \"\"\"Test that TerminalReporter handles markup explicitly provided by\n        a pytest_report_teststatus hook.\"\"\"\n        monkeypatch.setenv(\"PY_COLORS\", \"1\")\n        pytester.makeconftest(\n            f\"\"\"\n        "}, {"start_line": 47000, "end_line": 49000, "belongs_to": {"file_name": "test_terminal.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "e\n\n        option = Option()\n\n    config = cast(Config, FakeConfig())\n\n    assert _REPORTCHARS_DEFAULT == \"fE\"\n\n    # Default.\n    assert getreportopt(config) == \"wfE\"\n\n    config.option.reportchars = \"sf\"\n    assert getreportopt(config) == \"wsf\"\n\n    config.option.reportchars = \"sfxw\"\n    assert getreportopt(config) == \"sfxw\"\n\n    config.option.reportchars = \"a\"\n    assert getreportopt(config) == \"wsxXEf\"\n\n    config.option.reportchars = \"N\"\n    assert getreportopt(config) == \"w\"\n\n    config.option.reportchars = \"NwfE\"\n    assert getreportopt(config) == \"wfE\"\n\n    config.option.reportchars = \"NfENx\"\n    assert getreportopt(config) == \"wx\"\n\n    # Now with --disable-warnings.\n    config.option.disable_warnings = True\n    config.option.reportchars = \"a\"\n    assert getreportopt(config) == \"sxXEf\"\n\n    config.option.reportchars = \"sfx\"\n    assert getreportopt(config) == \"sfx\"\n\n    config.option.reportchars = \"sfxw\"\n    assert getreportopt(config) == \"sfx\"\n\n    config.option.reportchars = \"a\"\n    assert getreportopt(config) == \"sxXEf\"\n\n    config.option.reportchars = \"A\"\n    assert getreportopt(config) == \"PpsxXEf\"\n\n    config.option.reportchars = \"AN\"\n    assert getreportopt(config) == \"\"\n\n    config.option.reportchars = \"NwfE\"\n    assert getreportopt(config) == \"fE\"\n\n\ndef test_terminalreporter_reportopt_addopts(pytester: Pytester) -> None:\n    pytester.makeini(\"[pytest]\\naddopts=-rs\")\n    pytester.makepyfile(\n        \"\"\"\n        import pytest\n\n        @pytest.fixture\n        def tr(request):\n            tr = request.config.pluginmanager.getplugin(\"terminalreporter\")\n            return tr\n        def test_opt(tr):\n            assert tr.hasopt('skipped')\n            assert not tr.hasopt('qwe')\n    \"\"\"\n    )\n    result = pytester.runpytest()\n    result.stdout.fnmatch_lines([\"*1 passed*\"])\n\n\ndef test_tbstyle_short(pytester: Pytester) -> None:\n    p = pytester.makepyfile(\n        \"\"\"\n        import pytest\n\n        @pytest.fixture\n        def arg(request):\n            return"}, {"start_line": 0, "end_line": 2000, "belongs_to": {"file_name": "test_pytester.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "# mypy: allow-untyped-defs\nfrom __future__ import annotations\n\nimport os\nimport subprocess\nimport sys\nfrom types import ModuleType\n\nfrom _pytest.config import ExitCode\nfrom _pytest.config import PytestPluginManager\nfrom _pytest.monkeypatch import MonkeyPatch\nimport _pytest.pytester as pytester_mod\nfrom _pytest.pytester import HookRecorder\nfrom _pytest.pytester import LineMatcher\nfrom _pytest.pytester import Pytester\nfrom _pytest.pytester import SysModulesSnapshot\nfrom _pytest.pytester import SysPathsSnapshot\nimport _pytest.timing\nimport pytest\n\n\ndef test_make_hook_recorder(pytester: Pytester) -> None:\n    item = pytester.getitem(\"def test_func(): pass\")\n    recorder = pytester.make_hook_recorder(item.config.pluginmanager)\n    assert not recorder.getfailures()\n\n    # (The silly condition is to fool mypy that the code below this is reachable)\n    if 1 + 1 == 2:\n        pytest.xfail(\"internal reportrecorder tests need refactoring\")\n\n    class rep:\n        excinfo = None\n        passed = False\n        failed = True\n        skipped = False\n        when = \"call\"\n\n    recorder.hook.pytest_runtest_logreport(report=rep)  # type: ignore[attr-defined]\n    failures = recorder.getfailures()\n    assert failures == [rep]  # type: ignore[comparison-overlap]\n    failures = recorder.getfailures()\n    assert failures == [rep]  # type: ignore[comparison-overlap]\n\n    class rep2:\n        excinfo = None\n        passed = False\n        failed = False\n        skipped = True\n        when = \"call\"\n\n    rep2.passed = False\n    rep2.skipped = True\n    recorder.hook.pytest_runtest_logreport(report=rep2)  # type: ignore[attr-defined]\n\n    modcol = pytester.getmodulecol(\"\")\n    rep3 = modcol.config.hook.pytest_make_collect_report(collector=modcol)\n    rep3.passed = False\n    rep3.failed = True\n    rep3.skipped = False\n    recorder.hook.pytest_collectreport(report=rep3)  # type: ignore[attr-defined]\n\n    passed, skipped, failed = recorder.listoutcomes()\n    assert not passed and skipped and failed\n"}, {"start_line": 1000, "end_line": 3000, "belongs_to": {"file_name": "test_pytester.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "alse\n        failed = True\n        skipped = False\n        when = \"call\"\n\n    recorder.hook.pytest_runtest_logreport(report=rep)  # type: ignore[attr-defined]\n    failures = recorder.getfailures()\n    assert failures == [rep]  # type: ignore[comparison-overlap]\n    failures = recorder.getfailures()\n    assert failures == [rep]  # type: ignore[comparison-overlap]\n\n    class rep2:\n        excinfo = None\n        passed = False\n        failed = False\n        skipped = True\n        when = \"call\"\n\n    rep2.passed = False\n    rep2.skipped = True\n    recorder.hook.pytest_runtest_logreport(report=rep2)  # type: ignore[attr-defined]\n\n    modcol = pytester.getmodulecol(\"\")\n    rep3 = modcol.config.hook.pytest_make_collect_report(collector=modcol)\n    rep3.passed = False\n    rep3.failed = True\n    rep3.skipped = False\n    recorder.hook.pytest_collectreport(report=rep3)  # type: ignore[attr-defined]\n\n    passed, skipped, failed = recorder.listoutcomes()\n    assert not passed and skipped and failed\n\n    numpassed, numskipped, numfailed = recorder.countoutcomes()\n    assert numpassed == 0\n    assert numskipped == 1\n    assert numfailed == 1\n    assert len(recorder.getfailedcollections()) == 1\n\n    recorder.unregister()  # type: ignore[attr-defined]\n    recorder.clear()\n    recorder.hook.pytest_runtest_logreport(report=rep3)  # type: ignore[attr-defined]\n    pytest.raises(ValueError, recorder.getfailures)\n\n\ndef test_parseconfig(pytester: Pytester) -> None:\n    config1 = pytester.parseconfig()\n    config2 = pytester.parseconfig()\n    assert config2 is not config1\n\n\ndef test_pytester_runs_with_plugin(pytester: Pytester) -> None:\n    pytester.makepyfile(\n        \"\"\"\n        pytest_plugins = \"pytester\"\n        def test_hello(pytester):\n            assert 1\n    \"\"\"\n    )\n    result = pytester.runpytest()\n    result.assert_outcomes(passed=1)\n\n\ndef test_pytester_with_doctest(pytester: Pytester) -> None:\n    \"\"\"Check that pytester can be used within doctests.\n\n    It used to use `request.f"}], "retrieved_count": 10, "cost_time": 1.2091829776763916}
{"question": "Why does the _bestrelpath_cache class leverage Python's dictionary protocol to implement lazy computation and caching of relative path transformations?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"start_line": 14000, "end_line": 16000, "belongs_to": {"file_name": "path.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest/_py", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": " dest such that\n        self.join(bestrelpath) == dest and if not such\n        path can be determined return dest.\n        \"\"\"\n        try:\n            if self == dest:\n                return os.curdir\n            base = self.common(dest)\n            if not base:  # can be the case on windows\n                return str(dest)\n            self2base = self.relto(base)\n            reldest = dest.relto(base)\n            if self2base:\n                n = self2base.count(self.sep) + 1\n            else:\n                n = 0\n            lst = [os.pardir] * n\n            if reldest:\n                lst.append(reldest)\n            target = dest.sep.join(lst)\n            return target\n        except AttributeError:\n            return str(dest)\n\n    def exists(self):\n        return self.check()\n\n    def isdir(self):\n        return self.check(dir=1)\n\n    def isfile(self):\n        return self.check(file=1)\n\n    def parts(self, reverse=False):\n        \"\"\"Return a root-first list of all ancestor directories\n        plus the path itself.\n        \"\"\"\n        current = self\n        lst = [self]\n        while 1:\n            last = current\n            current = current.dirpath()\n            if last == current:\n                break\n            lst.append(current)\n        if not reverse:\n            lst.reverse()\n        return lst\n\n    def common(self, other):\n        \"\"\"Return the common part shared with the other path\n        or None if there is no common part.\n        \"\"\"\n        last = None\n        for x, y in zip(self.parts(), other.parts()):\n            if x != y:\n                return last\n            last = x\n        return last\n\n    def __add__(self, other):\n        \"\"\"Return new path object with 'other' added to the basename\"\"\"\n        return self.new(basename=self.basename + str(other))\n\n    def visit(self, fil=None, rec=None, ignore=NeverRaised, bf=False, sort=False):\n        \"\"\"Yields all paths below the current one\n\n        fil is a filter (glob pattern or callable), if n"}, {"start_line": 13000, "end_line": 15000, "belongs_to": {"file_name": "path.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest/_py", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "    to the given 'relpath'.\n        \"\"\"\n        if not isinstance(relpath, (str, LocalPath)):\n            raise TypeError(f\"{relpath!r}: not a string or path object\")\n        strrelpath = str(relpath)\n        if strrelpath and strrelpath[-1] != self.sep:\n            strrelpath += self.sep\n        # assert strrelpath[-1] == self.sep\n        # assert strrelpath[-2] != self.sep\n        strself = self.strpath\n        if sys.platform == \"win32\" or getattr(os, \"_name\", None) == \"nt\":\n            if os.path.normcase(strself).startswith(os.path.normcase(strrelpath)):\n                return strself[len(strrelpath) :]\n        elif strself.startswith(strrelpath):\n            return strself[len(strrelpath) :]\n        return \"\"\n\n    def ensure_dir(self, *args):\n        \"\"\"Ensure the path joined with args is a directory.\"\"\"\n        return self.ensure(*args, dir=True)\n\n    def bestrelpath(self, dest):\n        \"\"\"Return a string which is a relative path from self\n        (assumed to be a directory) to dest such that\n        self.join(bestrelpath) == dest and if not such\n        path can be determined return dest.\n        \"\"\"\n        try:\n            if self == dest:\n                return os.curdir\n            base = self.common(dest)\n            if not base:  # can be the case on windows\n                return str(dest)\n            self2base = self.relto(base)\n            reldest = dest.relto(base)\n            if self2base:\n                n = self2base.count(self.sep) + 1\n            else:\n                n = 0\n            lst = [os.pardir] * n\n            if reldest:\n                lst.append(reldest)\n            target = dest.sep.join(lst)\n            return target\n        except AttributeError:\n            return str(dest)\n\n    def exists(self):\n        return self.check()\n\n    def isdir(self):\n        return self.check(dir=1)\n\n    def isfile(self):\n        return self.check(file=1)\n\n    def parts(self, reverse=False):\n        \"\"\"Return a root-first list of all ancestor direc"}, {"start_line": 12000, "end_line": 14000, "belongs_to": {"file_name": "path.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest/_py", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "\n            raise error.EINVAL(target, \"cannot move path into a subdirectory of itself\")\n        try:\n            self.rename(target)\n        except error.EXDEV:  # invalid cross-device link\n            self.copy(target)\n            self.remove()\n\n    def fnmatch(self, pattern):\n        \"\"\"Return true if the basename/fullname matches the glob-'pattern'.\n\n        valid pattern characters::\n\n            *       matches everything\n            ?       matches any single character\n            [seq]   matches any character in seq\n            [!seq]  matches any char not in seq\n\n        If the pattern contains a path-separator then the full path\n        is used for pattern matching and a '*' is prepended to the\n        pattern.\n\n        if the pattern doesn't contain a path-separator the pattern\n        is only matched against the basename.\n        \"\"\"\n        return FNMatcher(pattern)(self)\n\n    def relto(self, relpath):\n        \"\"\"Return a string which is the relative part of the path\n        to the given 'relpath'.\n        \"\"\"\n        if not isinstance(relpath, (str, LocalPath)):\n            raise TypeError(f\"{relpath!r}: not a string or path object\")\n        strrelpath = str(relpath)\n        if strrelpath and strrelpath[-1] != self.sep:\n            strrelpath += self.sep\n        # assert strrelpath[-1] == self.sep\n        # assert strrelpath[-2] != self.sep\n        strself = self.strpath\n        if sys.platform == \"win32\" or getattr(os, \"_name\", None) == \"nt\":\n            if os.path.normcase(strself).startswith(os.path.normcase(strrelpath)):\n                return strself[len(strrelpath) :]\n        elif strself.startswith(strrelpath):\n            return strself[len(strrelpath) :]\n        return \"\"\n\n    def ensure_dir(self, *args):\n        \"\"\"Ensure the path joined with args is a directory.\"\"\"\n        return self.ensure(*args, dir=True)\n\n    def bestrelpath(self, dest):\n        \"\"\"Return a string which is a relative path from self\n        (assumed to be a directory) to"}, {"start_line": 36000, "end_line": 37622, "belongs_to": {"file_name": "pathlib.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": ", or None if there is\n    no common part.\n\n    If one path is relative and one is absolute, returns None.\n    \"\"\"\n    try:\n        return Path(os.path.commonpath((str(path1), str(path2))))\n    except ValueError:\n        return None\n\n\ndef bestrelpath(directory: Path, dest: Path) -> str:\n    \"\"\"Return a string which is a relative path from directory to dest such\n    that directory/bestrelpath == dest.\n\n    The paths must be either both absolute or both relative.\n\n    If no such path can be determined, returns dest.\n    \"\"\"\n    assert isinstance(directory, Path)\n    assert isinstance(dest, Path)\n    if dest == directory:\n        return os.curdir\n    # Find the longest common directory.\n    base = commonpath(directory, dest)\n    # Can be the case on Windows for two absolute paths on different drives.\n    # Can be the case for two relative paths without common prefix.\n    # Can be the case for a relative path and an absolute path.\n    if not base:\n        return str(dest)\n    reldirectory = directory.relative_to(base)\n    reldest = dest.relative_to(base)\n    return os.path.join(\n        # Back from directory to base.\n        *([os.pardir] * len(reldirectory.parts)),\n        # Forward from base to dest.\n        *reldest.parts,\n    )\n\n\ndef safe_exists(p: Path) -> bool:\n    \"\"\"Like Path.exists(), but account for input arguments that might be too long (#11394).\"\"\"\n    try:\n        return p.exists()\n    except (ValueError, OSError):\n        # ValueError: stat: path too long for Windows\n        # OSError: [WinError 123] The filename, directory name, or volume label syntax is incorrect\n        return False\n"}, {"start_line": 1000, "end_line": 2947, "belongs_to": {"file_name": "compat.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest/config", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "orts fixingcalls, this one will do\n\n    it currently doesn't return full hook caller proxies for fixed hooks,\n    this may have to be changed later depending on bugs\n    \"\"\"\n\n    def __init__(self, hook_relay: pluggy.HookRelay) -> None:\n        self._hook_relay = hook_relay\n\n    def __dir__(self) -> list[str]:\n        return dir(self._hook_relay)\n\n    def __getattr__(self, key: str) -> pluggy.HookCaller:\n        hook: pluggy.HookCaller = getattr(self._hook_relay, key)\n        if key not in imply_paths_hooks:\n            self.__dict__[key] = hook\n            return hook\n        else:\n            path_var, fspath_var = imply_paths_hooks[key]\n\n            @functools.wraps(hook)\n            def fixed_hook(**kw: Any) -> Any:\n                path_value: Path | None = kw.pop(path_var, None)\n                fspath_value: LEGACY_PATH | None = kw.pop(fspath_var, None)\n                if fspath_value is not None:\n                    warnings.warn(\n                        HOOK_LEGACY_PATH_ARG.format(\n                            pylib_path_arg=fspath_var, pathlib_path_arg=path_var\n                        ),\n                        stacklevel=2,\n                    )\n                if path_value is not None:\n                    if fspath_value is not None:\n                        _check_path(path_value, fspath_value)\n                    else:\n                        fspath_value = legacy_path(path_value)\n                else:\n                    assert fspath_value is not None\n                    path_value = Path(fspath_value)\n\n                kw[path_var] = path_value\n                kw[fspath_var] = fspath_value\n                return hook(**kw)\n\n            fixed_hook.name = hook.name  # type: ignore[attr-defined]\n            fixed_hook.spec = hook.spec  # type: ignore[attr-defined]\n            fixed_hook.__name__ = key\n            self.__dict__[key] = fixed_hook\n            return fixed_hook  # type: ignore[return-value]\n"}, {"start_line": 0, "end_line": 2000, "belongs_to": {"file_name": "cacheprovider.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "# mypy: allow-untyped-defs\n\"\"\"Implementation of the cache provider.\"\"\"\n\n# This plugin was not named \"cache\" to avoid conflicts with the external\n# pytest-cache version.\nfrom __future__ import annotations\n\nfrom collections.abc import Generator\nfrom collections.abc import Iterable\nimport dataclasses\nimport errno\nimport json\nimport os\nfrom pathlib import Path\nimport tempfile\nfrom typing import final\n\nfrom .pathlib import resolve_from_str\nfrom .pathlib import rm_rf\nfrom .reports import CollectReport\nfrom _pytest import nodes\nfrom _pytest._io import TerminalWriter\nfrom _pytest.config import Config\nfrom _pytest.config import ExitCode\nfrom _pytest.config import hookimpl\nfrom _pytest.config.argparsing import Parser\nfrom _pytest.deprecated import check_ispytest\nfrom _pytest.fixtures import fixture\nfrom _pytest.fixtures import FixtureRequest\nfrom _pytest.main import Session\nfrom _pytest.nodes import Directory\nfrom _pytest.nodes import File\nfrom _pytest.reports import TestReport\n\n\nREADME_CONTENT = \"\"\"\\\n# pytest cache directory #\n\nThis directory contains data from the pytest's cache plugin,\nwhich provides the `--lf` and `--ff` options, as well as the `cache` fixture.\n\n**Do not** commit this to version control.\n\nSee [the docs](https://docs.pytest.org/en/stable/how-to/cache.html) for more information.\n\"\"\"\n\nCACHEDIR_TAG_CONTENT = b\"\"\"\\\nSignature: 8a477f597d28d172789f06886806bc55\n# This file is a cache directory tag created by pytest.\n# For information about cache directory tags, see:\n#\thttps://bford.info/cachedir/spec.html\n\"\"\"\n\n\n@final\n@dataclasses.dataclass\nclass Cache:\n    \"\"\"Instance of the `cache` fixture.\"\"\"\n\n    _cachedir: Path = dataclasses.field(repr=False)\n    _config: Config = dataclasses.field(repr=False)\n\n    # Sub-directory under cache-dir for directories created by `mkdir()`.\n    _CACHE_PREFIX_DIRS = \"d\"\n\n    # Sub-directory under cache-dir for values created by `set()`.\n    _CACHE_PREFIX_VALUES = \"v\"\n\n    def __init__(\n        self, cachedir: Path, config: Config, *"}, {"start_line": 35000, "end_line": 37000, "belongs_to": {"file_name": "pathlib.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "         entries.append(entry)\n    entries.sort(key=sort_key)  # type: ignore[arg-type]\n    return entries\n\n\ndef visit(\n    path: str | os.PathLike[str], recurse: Callable[[os.DirEntry[str]], bool]\n) -> Iterator[os.DirEntry[str]]:\n    \"\"\"Walk a directory recursively, in breadth-first order.\n\n    The `recurse` predicate determines whether a directory is recursed.\n\n    Entries at each directory level are sorted.\n    \"\"\"\n    entries = scandir(path)\n    yield from entries\n    for entry in entries:\n        if entry.is_dir() and recurse(entry):\n            yield from visit(entry.path, recurse)\n\n\ndef absolutepath(path: str | os.PathLike[str]) -> Path:\n    \"\"\"Convert a path to an absolute path using os.path.abspath.\n\n    Prefer this over Path.resolve() (see #6523).\n    Prefer this over Path.absolute() (not public, doesn't normalize).\n    \"\"\"\n    return Path(os.path.abspath(path))\n\n\ndef commonpath(path1: Path, path2: Path) -> Path | None:\n    \"\"\"Return the common part shared with the other path, or None if there is\n    no common part.\n\n    If one path is relative and one is absolute, returns None.\n    \"\"\"\n    try:\n        return Path(os.path.commonpath((str(path1), str(path2))))\n    except ValueError:\n        return None\n\n\ndef bestrelpath(directory: Path, dest: Path) -> str:\n    \"\"\"Return a string which is a relative path from directory to dest such\n    that directory/bestrelpath == dest.\n\n    The paths must be either both absolute or both relative.\n\n    If no such path can be determined, returns dest.\n    \"\"\"\n    assert isinstance(directory, Path)\n    assert isinstance(dest, Path)\n    if dest == directory:\n        return os.curdir\n    # Find the longest common directory.\n    base = commonpath(directory, dest)\n    # Can be the case on Windows for two absolute paths on different drives.\n    # Can be the case for two relative paths without common prefix.\n    # Can be the case for a relative path and an absolute path.\n    if not base:\n        return str(dest)\n    reldirectory ="}, {"start_line": 2000, "end_line": 4000, "belongs_to": {"file_name": "cacheprovider.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": ", _ispytest: bool = False\n    ) -> None:\n        check_ispytest(_ispytest)\n        self._cachedir = cachedir\n        self._config = config\n\n    @classmethod\n    def for_config(cls, config: Config, *, _ispytest: bool = False) -> Cache:\n        \"\"\"Create the Cache instance for a Config.\n\n        :meta private:\n        \"\"\"\n        check_ispytest(_ispytest)\n        cachedir = cls.cache_dir_from_config(config, _ispytest=True)\n        if config.getoption(\"cacheclear\") and cachedir.is_dir():\n            cls.clear_cache(cachedir, _ispytest=True)\n        return cls(cachedir, config, _ispytest=True)\n\n    @classmethod\n    def clear_cache(cls, cachedir: Path, _ispytest: bool = False) -> None:\n        \"\"\"Clear the sub-directories used to hold cached directories and values.\n\n        :meta private:\n        \"\"\"\n        check_ispytest(_ispytest)\n        for prefix in (cls._CACHE_PREFIX_DIRS, cls._CACHE_PREFIX_VALUES):\n            d = cachedir / prefix\n            if d.is_dir():\n                rm_rf(d)\n\n    @staticmethod\n    def cache_dir_from_config(config: Config, *, _ispytest: bool = False) -> Path:\n        \"\"\"Get the path to the cache directory for a Config.\n\n        :meta private:\n        \"\"\"\n        check_ispytest(_ispytest)\n        return resolve_from_str(config.getini(\"cache_dir\"), config.rootpath)\n\n    def warn(self, fmt: str, *, _ispytest: bool = False, **args: object) -> None:\n        \"\"\"Issue a cache warning.\n\n        :meta private:\n        \"\"\"\n        check_ispytest(_ispytest)\n        import warnings\n\n        from _pytest.warning_types import PytestCacheWarning\n\n        warnings.warn(\n            PytestCacheWarning(fmt.format(**args) if args else fmt),\n            self._config.hook,\n            stacklevel=3,\n        )\n\n    def _mkdir(self, path: Path) -> None:\n        self._ensure_cache_dir_and_supporting_files()\n        path.mkdir(exist_ok=True, parents=True)\n\n    def mkdir(self, name: str) -> Path:\n        \"\"\"Return a directory path object with the given name.\n\n      "}, {"start_line": 5000, "end_line": 7000, "belongs_to": {"file_name": "test_local.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing/_py", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "sep = curdir.sep\n        s = curdir.bestrelpath(curdir)\n        assert s == \".\"\n        s = curdir.bestrelpath(curdir.join(\"hello\", \"world\"))\n        assert s == \"hello\" + sep + \"world\"\n\n        s = curdir.bestrelpath(curdir.dirpath().join(\"sister\"))\n        assert s == \"..\" + sep + \"sister\"\n        assert curdir.bestrelpath(curdir.dirpath()) == \"..\"\n\n        assert curdir.bestrelpath(\"hello\") == \"hello\"\n\n    def test_relto_not_relative(self, path1):\n        l1 = path1.join(\"bcde\")\n        l2 = path1.join(\"b\")\n        assert not l1.relto(l2)\n        assert not l2.relto(l1)\n\n    def test_listdir(self, path1):\n        p = path1.listdir()\n        assert path1.join(\"sampledir\") in p\n        assert path1.join(\"samplefile\") in p\n        with pytest.raises(error.ENOTDIR):\n            path1.join(\"samplefile\").listdir()\n\n    def test_listdir_fnmatchstring(self, path1):\n        p = path1.listdir(\"s*dir\")\n        assert len(p)\n        assert p[0], path1.join(\"sampledir\")\n\n    def test_listdir_filter(self, path1):\n        p = path1.listdir(lambda x: x.check(dir=1))\n        assert path1.join(\"sampledir\") in p\n        assert path1.join(\"samplefile\") not in p\n\n    def test_listdir_sorted(self, path1):\n        p = path1.listdir(lambda x: x.check(basestarts=\"sample\"), sort=True)\n        assert path1.join(\"sampledir\") == p[0]\n        assert path1.join(\"samplefile\") == p[1]\n        assert path1.join(\"samplepickle\") == p[2]\n\n    def test_visit_nofilter(self, path1):\n        lst = []\n        for i in path1.visit():\n            lst.append(i.relto(path1))\n        assert \"sampledir\" in lst\n        assert path1.sep.join([\"sampledir\", \"otherfile\"]) in lst\n\n    def test_visit_norecurse(self, path1):\n        lst = []\n        for i in path1.visit(None, lambda x: x.basename != \"sampledir\"):\n            lst.append(i.relto(path1))\n        assert \"sampledir\" in lst\n        assert path1.sep.join([\"sampledir\", \"otherfile\"]) not in lst\n\n    @pytest.mark.parametrize(\n        \"fil\",\n        [\"*dir\", \"*d"}, {"start_line": 0, "end_line": 2000, "belongs_to": {"file_name": "path.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest/_py", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "# mypy: allow-untyped-defs\n\"\"\"local path implementation.\"\"\"\n\nfrom __future__ import annotations\n\nimport atexit\nfrom collections.abc import Callable\nfrom contextlib import contextmanager\nimport fnmatch\nimport importlib.util\nimport io\nimport os\nfrom os.path import abspath\nfrom os.path import dirname\nfrom os.path import exists\nfrom os.path import isabs\nfrom os.path import isdir\nfrom os.path import isfile\nfrom os.path import islink\nfrom os.path import normpath\nimport posixpath\nfrom stat import S_ISDIR\nfrom stat import S_ISLNK\nfrom stat import S_ISREG\nimport sys\nfrom typing import Any\nfrom typing import cast\nfrom typing import Literal\nfrom typing import overload\nfrom typing import TYPE_CHECKING\nimport uuid\nimport warnings\n\nfrom . import error\n\n\n# Moved from local.py.\niswin32 = sys.platform == \"win32\" or (getattr(os, \"_name\", False) == \"nt\")\n\n\nclass Checkers:\n    _depend_on_existence = \"exists\", \"link\", \"dir\", \"file\"\n\n    def __init__(self, path):\n        self.path = path\n\n    def dotfile(self):\n        return self.path.basename.startswith(\".\")\n\n    def ext(self, arg):\n        if not arg.startswith(\".\"):\n            arg = \".\" + arg\n        return self.path.ext == arg\n\n    def basename(self, arg):\n        return self.path.basename == arg\n\n    def basestarts(self, arg):\n        return self.path.basename.startswith(arg)\n\n    def relto(self, arg):\n        return self.path.relto(arg)\n\n    def fnmatch(self, arg):\n        return self.path.fnmatch(arg)\n\n    def endswith(self, arg):\n        return str(self.path).endswith(arg)\n\n    def _evaluate(self, kw):\n        from .._code.source import getrawcode\n\n        for name, value in kw.items():\n            invert = False\n            meth = None\n            try:\n                meth = getattr(self, name)\n            except AttributeError:\n                if name[:3] == \"not\":\n                    invert = True\n                    try:\n                        meth = getattr(self, name[3:])\n                    except AttributeError:\n      "}], "retrieved_count": 10, "cost_time": 1.2081477642059326}
{"question": "How does the RunAndParse class decouple the concerns of test execution orchestration from XML schema validation and document parsing to maintain separation of responsibilities?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"start_line": 2000, "end_line": 4000, "belongs_to": {"file_name": "test_junitxml.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "   \"xunit2\" is also automatically validated against the schema.\n    \"\"\"\n    return RunAndParse(pytester, schema)\n\n\ndef assert_attr(node: minidom.Element, **kwargs: object) -> None:\n    __tracebackhide__ = True\n\n    def nodeval(node: minidom.Element, name: str) -> str | None:\n        anode = node.getAttributeNode(name)\n        return anode.value if anode is not None else None\n\n    expected = {name: str(value) for name, value in kwargs.items()}\n    on_node = {name: nodeval(node, name) for name in expected}\n    assert on_node == expected\n\n\nclass DomDocument:\n    _node: minidom.Document | minidom.Element\n\n    def __init__(self, dom: minidom.Document) -> None:\n        self._node = dom\n\n    def find_first_by_tag(self, tag: str) -> DomNode | None:\n        return self.find_nth_by_tag(tag, 0)\n\n    def get_first_by_tag(self, tag: str) -> DomNode:\n        maybe = self.find_first_by_tag(tag)\n        if maybe is None:\n            raise LookupError(tag)\n        else:\n            return maybe\n\n    def find_nth_by_tag(self, tag: str, n: int) -> DomNode | None:\n        items = self._node.getElementsByTagName(tag)\n        try:\n            nth = items[n]\n        except IndexError:\n            return None\n        else:\n            return DomNode(nth)\n\n    def find_by_tag(self, tag: str) -> list[DomNode]:\n        return [DomNode(x) for x in self._node.getElementsByTagName(tag)]\n\n    @property\n    def children(self) -> list[DomNode]:\n        return [\n            DomNode(x) for x in self._node.childNodes if isinstance(x, minidom.Element)\n        ]\n\n    @property\n    def get_unique_child(self) -> DomNode:\n        children = self.children\n        assert len(children) == 1\n        return children[0]\n\n    def toxml(self) -> str:\n        return self._node.toxml()\n\n\nclass DomNode(DomDocument):\n    _node: minidom.Element\n\n    def __init__(self, dom: minidom.Element) -> None:\n        self._node = dom\n\n    def __repr__(self) -> str:\n        return self.toxml()\n\n    def __getitem__(self, key: str) "}, {"start_line": 1000, "end_line": 3000, "belongs_to": {"file_name": "test_junitxml.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "tester, schema: xmlschema.XMLSchema) -> None:\n        self.pytester = pytester\n        self.schema = schema\n\n    def __call__(\n        self, *args: str | os.PathLike[str], family: str | None = \"xunit1\"\n    ) -> tuple[RunResult, DomDocument]:\n        if family:\n            args = (\"-o\", \"junit_family=\" + family, *args)\n        xml_path = self.pytester.path.joinpath(\"junit.xml\")\n        result = self.pytester.runpytest(f\"--junitxml={xml_path}\", *args)\n        if family == \"xunit2\":\n            with xml_path.open(encoding=\"utf-8\") as f:\n                self.schema.validate(f)\n        xmldoc = minidom.parse(str(xml_path))\n        return result, DomDocument(xmldoc)\n\n\n@pytest.fixture\ndef run_and_parse(pytester: Pytester, schema: xmlschema.XMLSchema) -> RunAndParse:\n    \"\"\"Fixture that returns a function that can be used to execute pytest and\n    return the parsed ``DomNode`` of the root xml node.\n\n    The ``family`` parameter is used to configure the ``junit_family`` of the written report.\n    \"xunit2\" is also automatically validated against the schema.\n    \"\"\"\n    return RunAndParse(pytester, schema)\n\n\ndef assert_attr(node: minidom.Element, **kwargs: object) -> None:\n    __tracebackhide__ = True\n\n    def nodeval(node: minidom.Element, name: str) -> str | None:\n        anode = node.getAttributeNode(name)\n        return anode.value if anode is not None else None\n\n    expected = {name: str(value) for name, value in kwargs.items()}\n    on_node = {name: nodeval(node, name) for name in expected}\n    assert on_node == expected\n\n\nclass DomDocument:\n    _node: minidom.Document | minidom.Element\n\n    def __init__(self, dom: minidom.Document) -> None:\n        self._node = dom\n\n    def find_first_by_tag(self, tag: str) -> DomNode | None:\n        return self.find_nth_by_tag(tag, 0)\n\n    def get_first_by_tag(self, tag: str) -> DomNode:\n        maybe = self.find_first_by_tag(tag)\n        if maybe is None:\n            raise LookupError(tag)\n        else:\n            return maybe\n\n    de"}, {"start_line": 49000, "end_line": 51000, "belongs_to": {"file_name": "test_junitxml.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "d == [\"test_x[22]\"]\n\n\n@parametrize_families\ndef test_root_testsuites_tag(\n    pytester: Pytester, run_and_parse: RunAndParse, xunit_family: str\n) -> None:\n    pytester.makepyfile(\n        \"\"\"\n        def test_x():\n            pass\n    \"\"\"\n    )\n    _, dom = run_and_parse(family=xunit_family)\n    root = dom.get_unique_child\n    assert root.tag == \"testsuites\"\n    root.assert_attr(name=\"pytest tests\")\n    suite_node = root.get_unique_child\n    assert suite_node.tag == \"testsuite\"\n\n\ndef test_runs_twice(pytester: Pytester, run_and_parse: RunAndParse) -> None:\n    f = pytester.makepyfile(\n        \"\"\"\n        def test_pass():\n            pass\n    \"\"\"\n    )\n\n    result, dom = run_and_parse(f, f)\n    result.stdout.no_fnmatch_line(\"*INTERNALERROR*\")\n    first, second = (x[\"classname\"] for x in dom.find_by_tag(\"testcase\"))\n    assert first == second\n\n\ndef test_runs_twice_xdist(\n    pytester: Pytester, monkeypatch: MonkeyPatch, run_and_parse: RunAndParse\n) -> None:\n    pytest.importorskip(\"xdist\")\n    monkeypatch.delenv(\"PYTEST_DISABLE_PLUGIN_AUTOLOAD\")\n    f = pytester.makepyfile(\n        \"\"\"\n        def test_pass():\n            pass\n    \"\"\"\n    )\n\n    result, dom = run_and_parse(f, \"--dist\", \"each\", \"--tx\", \"2*popen\")\n    result.stdout.no_fnmatch_line(\"*INTERNALERROR*\")\n    first, second = (x[\"classname\"] for x in dom.find_by_tag(\"testcase\"))\n    assert first == second\n\n\ndef test_fancy_items_regression(pytester: Pytester, run_and_parse: RunAndParse) -> None:\n    # issue 1259\n    pytester.makeconftest(\n        \"\"\"\n        import pytest\n        class FunItem(pytest.Item):\n            def runtest(self):\n                pass\n        class NoFunItem(pytest.Item):\n            def runtest(self):\n                pass\n\n        class FunCollector(pytest.File):\n            def collect(self):\n                return [\n                    FunItem.from_parent(name='a', parent=self),\n                    NoFunItem.from_parent(name='a', parent=self),\n                    NoFunItem.from_parent("}, {"start_line": 6000, "end_line": 8000, "belongs_to": {"file_name": "test_junitxml.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "_simple(\n        self, pytester: Pytester, run_and_parse: RunAndParse, xunit_family: str\n    ) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n            def test_pass():\n                pass\n            def test_fail():\n                assert 0\n            def test_skip():\n                pytest.skip(\"\")\n            @pytest.mark.xfail\n            def test_xfail():\n                assert 0\n            @pytest.mark.xfail\n            def test_xpass():\n                assert 1\n        \"\"\"\n        )\n        result, dom = run_and_parse(family=xunit_family)\n        assert result.ret\n        node = dom.get_first_by_tag(\"testsuite\")\n        node.assert_attr(name=\"pytest\", errors=0, failures=1, skipped=2, tests=5)\n\n    @parametrize_families\n    def test_summing_simple_with_errors(\n        self, pytester: Pytester, run_and_parse: RunAndParse, xunit_family: str\n    ) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n            @pytest.fixture\n            def fixture():\n                raise Exception()\n            def test_pass():\n                pass\n            def test_fail():\n                assert 0\n            def test_error(fixture):\n                pass\n            @pytest.mark.xfail\n            def test_xfail():\n                assert False\n            @pytest.mark.xfail(strict=True)\n            def test_xpass():\n                assert True\n        \"\"\"\n        )\n        result, dom = run_and_parse(family=xunit_family)\n        assert result.ret\n        node = dom.get_first_by_tag(\"testsuite\")\n        node.assert_attr(name=\"pytest\", errors=1, failures=2, skipped=1, tests=5)\n\n    @parametrize_families\n    def test_hostname_in_xml(\n        self, pytester: Pytester, run_and_parse: RunAndParse, xunit_family: str\n    ) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            def test_pass():\n                pass\n        \"\"\"\n        )\n        result, dom = run_and_parse(family=xunit_family)\n        node "}, {"start_line": 7000, "end_line": 9000, "belongs_to": {"file_name": "test_junitxml.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "t.fixture\n            def fixture():\n                raise Exception()\n            def test_pass():\n                pass\n            def test_fail():\n                assert 0\n            def test_error(fixture):\n                pass\n            @pytest.mark.xfail\n            def test_xfail():\n                assert False\n            @pytest.mark.xfail(strict=True)\n            def test_xpass():\n                assert True\n        \"\"\"\n        )\n        result, dom = run_and_parse(family=xunit_family)\n        assert result.ret\n        node = dom.get_first_by_tag(\"testsuite\")\n        node.assert_attr(name=\"pytest\", errors=1, failures=2, skipped=1, tests=5)\n\n    @parametrize_families\n    def test_hostname_in_xml(\n        self, pytester: Pytester, run_and_parse: RunAndParse, xunit_family: str\n    ) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            def test_pass():\n                pass\n        \"\"\"\n        )\n        result, dom = run_and_parse(family=xunit_family)\n        node = dom.get_first_by_tag(\"testsuite\")\n        node.assert_attr(hostname=platform.node())\n\n    @parametrize_families\n    def test_timestamp_in_xml(\n        self, pytester: Pytester, run_and_parse: RunAndParse, xunit_family: str\n    ) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            def test_pass():\n                pass\n        \"\"\"\n        )\n        start_time = datetime.now(timezone.utc)\n        result, dom = run_and_parse(family=xunit_family)\n        node = dom.get_first_by_tag(\"testsuite\")\n        timestamp = datetime.fromisoformat(node[\"timestamp\"])\n        assert start_time <= timestamp < datetime.now(timezone.utc)\n\n    def test_timing_function(\n        self,\n        pytester: Pytester,\n        run_and_parse: RunAndParse,\n        mock_timing: _pytest.timing.MockTiming,\n    ) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            from _pytest import timing\n            def setup_module():\n                timing.sleep(1)\n            def teardown_module():\n    "}, {"start_line": 26000, "end_line": 28000, "belongs_to": {"file_name": "test_junitxml.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": ")\n\n        has_err_logging = junit_logging in [\"system-err\", \"out-err\", \"all\"]\n        expected_err_output_len = 1 if has_err_logging else 0\n        assert len(tnode.find_by_tag(\"system-err\")) == expected_err_output_len\n\n        has_out_logigng = junit_logging in (\"log\", \"system-out\", \"out-err\", \"all\")\n        expected_out_output_len = 1 if has_out_logigng else 0\n\n        assert len(tnode.find_by_tag(\"system-out\")) == expected_out_output_len\n\n    @parametrize_families\n    def test_xfailure_xpass(\n        self, pytester: Pytester, run_and_parse: RunAndParse, xunit_family: str\n    ) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n            @pytest.mark.xfail\n            def test_xpass():\n                pass\n        \"\"\"\n        )\n        result, dom = run_and_parse(family=xunit_family)\n        # assert result.ret\n        node = dom.get_first_by_tag(\"testsuite\")\n        node.assert_attr(skipped=0, tests=1)\n        tnode = node.get_first_by_tag(\"testcase\")\n        tnode.assert_attr(classname=\"test_xfailure_xpass\", name=\"test_xpass\")\n\n    @parametrize_families\n    def test_xfailure_xpass_strict(\n        self, pytester: Pytester, run_and_parse: RunAndParse, xunit_family: str\n    ) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n            @pytest.mark.xfail(strict=True, reason=\"This needs to fail!\")\n            def test_xpass():\n                pass\n        \"\"\"\n        )\n        result, dom = run_and_parse(family=xunit_family)\n        # assert result.ret\n        node = dom.get_first_by_tag(\"testsuite\")\n        node.assert_attr(skipped=0, tests=1)\n        tnode = node.get_first_by_tag(\"testcase\")\n        tnode.assert_attr(classname=\"test_xfailure_xpass_strict\", name=\"test_xpass\")\n        fnode = tnode.get_first_by_tag(\"failure\")\n        fnode.assert_attr(message=\"[XPASS(strict)] This needs to fail!\")\n\n    @parametrize_families\n    def test_collect_error(\n        self, pytester: Pytester, run_and_parse: RunA"}, {"start_line": 8000, "end_line": 10000, "belongs_to": {"file_name": "test_junitxml.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "= dom.get_first_by_tag(\"testsuite\")\n        node.assert_attr(hostname=platform.node())\n\n    @parametrize_families\n    def test_timestamp_in_xml(\n        self, pytester: Pytester, run_and_parse: RunAndParse, xunit_family: str\n    ) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            def test_pass():\n                pass\n        \"\"\"\n        )\n        start_time = datetime.now(timezone.utc)\n        result, dom = run_and_parse(family=xunit_family)\n        node = dom.get_first_by_tag(\"testsuite\")\n        timestamp = datetime.fromisoformat(node[\"timestamp\"])\n        assert start_time <= timestamp < datetime.now(timezone.utc)\n\n    def test_timing_function(\n        self,\n        pytester: Pytester,\n        run_and_parse: RunAndParse,\n        mock_timing: _pytest.timing.MockTiming,\n    ) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            from _pytest import timing\n            def setup_module():\n                timing.sleep(1)\n            def teardown_module():\n                timing.sleep(2)\n            def test_sleep():\n                timing.sleep(4)\n        \"\"\"\n        )\n        result, dom = run_and_parse()\n        node = dom.get_first_by_tag(\"testsuite\")\n        tnode = node.get_first_by_tag(\"testcase\")\n        val = tnode[\"time\"]\n        assert val is not None\n        assert float(val) == 7.0\n\n    @pytest.mark.parametrize(\"duration_report\", [\"call\", \"total\"])\n    def test_junit_duration_report(\n        self,\n        pytester: Pytester,\n        monkeypatch: MonkeyPatch,\n        duration_report: str,\n        run_and_parse: RunAndParse,\n    ) -> None:\n        # mock LogXML.node_reporter so it always sets a known duration to each test report object\n        original_node_reporter = LogXML.node_reporter\n\n        def node_reporter_wrapper(s: Any, report: TestReport) -> Any:\n            report.duration = 1.0\n            reporter = original_node_reporter(s, report)\n            return reporter\n\n        monkeypatch.setattr(LogXML, \"node_reporter\", no"}, {"start_line": 48000, "end_line": 50000, "belongs_to": {"file_name": "test_junitxml.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": " \"with junit_family 'xunit2' (use 'legacy' or 'xunit1')\"\n    ]\n    result.stdout.fnmatch_lines(expected_lines)\n\n\ndef test_random_report_log_xdist(\n    pytester: Pytester, monkeypatch: MonkeyPatch, run_and_parse: RunAndParse\n) -> None:\n    \"\"\"`xdist` calls pytest_runtest_logreport as they are executed by the workers,\n    with nodes from several nodes overlapping, so junitxml must cope with that\n    to produce correct reports (#1064).\"\"\"\n    pytest.importorskip(\"xdist\")\n    monkeypatch.delenv(\"PYTEST_DISABLE_PLUGIN_AUTOLOAD\", raising=False)\n    pytester.makepyfile(\n        \"\"\"\n        import pytest, time\n        @pytest.mark.parametrize('i', list(range(30)))\n        def test_x(i):\n            assert i != 22\n    \"\"\"\n    )\n    _, dom = run_and_parse(\"-n2\")\n    suite_node = dom.get_first_by_tag(\"testsuite\")\n    failed = []\n    for case_node in suite_node.find_by_tag(\"testcase\"):\n        if case_node.find_first_by_tag(\"failure\"):\n            failed.append(case_node[\"name\"])\n\n    assert failed == [\"test_x[22]\"]\n\n\n@parametrize_families\ndef test_root_testsuites_tag(\n    pytester: Pytester, run_and_parse: RunAndParse, xunit_family: str\n) -> None:\n    pytester.makepyfile(\n        \"\"\"\n        def test_x():\n            pass\n    \"\"\"\n    )\n    _, dom = run_and_parse(family=xunit_family)\n    root = dom.get_unique_child\n    assert root.tag == \"testsuites\"\n    root.assert_attr(name=\"pytest tests\")\n    suite_node = root.get_unique_child\n    assert suite_node.tag == \"testsuite\"\n\n\ndef test_runs_twice(pytester: Pytester, run_and_parse: RunAndParse) -> None:\n    f = pytester.makepyfile(\n        \"\"\"\n        def test_pass():\n            pass\n    \"\"\"\n    )\n\n    result, dom = run_and_parse(f, f)\n    result.stdout.no_fnmatch_line(\"*INTERNALERROR*\")\n    first, second = (x[\"classname\"] for x in dom.find_by_tag(\"testcase\"))\n    assert first == second\n\n\ndef test_runs_twice_xdist(\n    pytester: Pytester, monkeypatch: MonkeyPatch, run_and_parse: RunAndParse\n) -> None:\n    pytest.importorskip(\"xdist\""}, {"start_line": 34000, "end_line": 36000, "belongs_to": {"file_name": "test_junitxml.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "lt, dom = run_and_parse(\"-o\", f\"junit_logging={junit_logging}\")\n        node = dom.get_first_by_tag(\"testsuite\")\n        pnode = node.get_first_by_tag(\"testcase\")\n        if junit_logging == \"no\":\n            assert not node.find_by_tag(\"system-out\"), (\n                \"system-out should not be generated\"\n            )\n        if junit_logging == \"system-out\":\n            systemout = pnode.get_first_by_tag(\"system-out\")\n            assert \"hello-stdout call\" in systemout.toxml()\n            assert \"hello-stdout teardown\" in systemout.toxml()\n\n\ndef test_mangle_test_address() -> None:\n    from _pytest.junitxml import mangle_test_address\n\n    address = \"::\".join([\"a/my.py.thing.py\", \"Class\", \"method\", \"[a-1-::]\"])\n    newnames = mangle_test_address(address)\n    assert newnames == [\"a.my.py.thing\", \"Class\", \"method\", \"[a-1-::]\"]\n\n\ndef test_dont_configure_on_workers(tmp_path: Path) -> None:\n    gotten: list[object] = []\n\n    class FakeConfig:\n        if TYPE_CHECKING:\n            workerinput = None\n\n        def __init__(self) -> None:\n            self.pluginmanager = self\n            self.option = self\n            self.stash = Stash()\n\n        def getini(self, name: str) -> str:\n            return \"pytest\"\n\n        junitprefix = None\n        # XXX: shouldn't need tmp_path ?\n        xmlpath = str(tmp_path.joinpath(\"junix.xml\"))\n        register = gotten.append\n\n    fake_config = cast(Config, FakeConfig())\n    from _pytest import junitxml\n\n    junitxml.pytest_configure(fake_config)\n    assert len(gotten) == 1\n    FakeConfig.workerinput = None\n    junitxml.pytest_configure(fake_config)\n    assert len(gotten) == 1\n\n\nclass TestNonPython:\n    @parametrize_families\n    def test_summing_simple(\n        self, pytester: Pytester, run_and_parse: RunAndParse, xunit_family: str\n    ) -> None:\n        pytester.makeconftest(\n            \"\"\"\n            import pytest\n            def pytest_collect_file(file_path, parent):\n                if file_path.suffix == \".xyz\":\n                  "}, {"start_line": 0, "end_line": 2000, "belongs_to": {"file_name": "test_junitxml.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "from __future__ import annotations\n\nfrom datetime import datetime\nfrom datetime import timezone\nimport os\nfrom pathlib import Path\nimport platform\nfrom typing import Any\nfrom typing import cast\nfrom typing import TYPE_CHECKING\nfrom xml.dom import minidom\n\nimport xmlschema\n\nfrom _pytest.config import Config\nfrom _pytest.junitxml import bin_xml_escape\nfrom _pytest.junitxml import LogXML\nfrom _pytest.monkeypatch import MonkeyPatch\nfrom _pytest.pytester import Pytester\nfrom _pytest.pytester import RunResult\nfrom _pytest.reports import BaseReport\nfrom _pytest.reports import TestReport\nfrom _pytest.stash import Stash\nimport _pytest.timing\nimport pytest\n\n\n@pytest.fixture(scope=\"session\")\ndef schema() -> xmlschema.XMLSchema:\n    \"\"\"Return an xmlschema.XMLSchema object for the junit-10.xsd file.\"\"\"\n    fn = Path(__file__).parent / \"example_scripts/junit-10.xsd\"\n    with fn.open(encoding=\"utf-8\") as f:\n        return xmlschema.XMLSchema(f)\n\n\nclass RunAndParse:\n    def __init__(self, pytester: Pytester, schema: xmlschema.XMLSchema) -> None:\n        self.pytester = pytester\n        self.schema = schema\n\n    def __call__(\n        self, *args: str | os.PathLike[str], family: str | None = \"xunit1\"\n    ) -> tuple[RunResult, DomDocument]:\n        if family:\n            args = (\"-o\", \"junit_family=\" + family, *args)\n        xml_path = self.pytester.path.joinpath(\"junit.xml\")\n        result = self.pytester.runpytest(f\"--junitxml={xml_path}\", *args)\n        if family == \"xunit2\":\n            with xml_path.open(encoding=\"utf-8\") as f:\n                self.schema.validate(f)\n        xmldoc = minidom.parse(str(xml_path))\n        return result, DomDocument(xmldoc)\n\n\n@pytest.fixture\ndef run_and_parse(pytester: Pytester, schema: xmlschema.XMLSchema) -> RunAndParse:\n    \"\"\"Fixture that returns a function that can be used to execute pytest and\n    return the parsed ``DomNode`` of the root xml node.\n\n    The ``family`` parameter is used to configure the ``junit_family`` of the written report.\n "}], "retrieved_count": 10, "cost_time": 1.2847867012023926}
{"question": "Why would repeated invocations of pytester.getitem() followed by evaluate_xfail_marks() impact test suite performance, and what internal caching mechanisms could mitigate redundant AST parsing and mark evaluation across multiple test evaluations?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"start_line": 0, "end_line": 2000, "belongs_to": {"file_name": "test_skipping.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "# mypy: allow-untyped-defs\nfrom __future__ import annotations\n\nimport sys\nimport textwrap\n\nfrom _pytest.pytester import Pytester\nfrom _pytest.runner import runtestprotocol\nfrom _pytest.skipping import evaluate_skip_marks\nfrom _pytest.skipping import evaluate_xfail_marks\nfrom _pytest.skipping import pytest_runtest_setup\nimport pytest\n\n\nclass TestEvaluation:\n    def test_no_marker(self, pytester: Pytester) -> None:\n        item = pytester.getitem(\"def test_func(): pass\")\n        skipped = evaluate_skip_marks(item)\n        assert not skipped\n\n    def test_marked_xfail_no_args(self, pytester: Pytester) -> None:\n        item = pytester.getitem(\n            \"\"\"\n            import pytest\n            @pytest.mark.xfail\n            def test_func():\n                pass\n        \"\"\"\n        )\n        xfailed = evaluate_xfail_marks(item)\n        assert xfailed\n        assert xfailed.reason == \"\"\n        assert xfailed.run\n\n    def test_marked_skipif_no_args(self, pytester: Pytester) -> None:\n        item = pytester.getitem(\n            \"\"\"\n            import pytest\n            @pytest.mark.skipif\n            def test_func():\n                pass\n        \"\"\"\n        )\n        skipped = evaluate_skip_marks(item)\n        assert skipped\n        assert skipped.reason == \"\"\n\n    def test_marked_one_arg(self, pytester: Pytester) -> None:\n        item = pytester.getitem(\n            \"\"\"\n            import pytest\n            @pytest.mark.skipif(\"hasattr(os, 'sep')\")\n            def test_func():\n                pass\n        \"\"\"\n        )\n        skipped = evaluate_skip_marks(item)\n        assert skipped\n        assert skipped.reason == \"condition: hasattr(os, 'sep')\"\n\n    def test_marked_one_arg_with_reason(self, pytester: Pytester) -> None:\n        item = pytester.getitem(\n            \"\"\"\n            import pytest\n            @pytest.mark.skipif(\"hasattr(os, 'sep')\", attr=2, reason=\"hello world\")\n            def test_func():\n                pass\n        \"\"\"\n        )\n        skipped = e"}, {"start_line": 5000, "end_line": 7000, "belongs_to": {"file_name": "skipping.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "at_exception_only(type(exc), exc),\n            ]\n            fail(\"\\n\".join(msglines), pytrace=False)\n\n    reason = mark.kwargs.get(\"reason\", None)\n    if reason is None:\n        if isinstance(condition, str):\n            reason = \"condition: \" + condition\n        else:\n            # XXX better be checked at collection time\n            msg = (\n                f\"Error evaluating {mark.name!r}: \"\n                + \"you need to specify reason=STRING when using booleans as conditions.\"\n            )\n            fail(msg, pytrace=False)\n\n    return result, reason\n\n\n@dataclasses.dataclass(frozen=True)\nclass Skip:\n    \"\"\"The result of evaluate_skip_marks().\"\"\"\n\n    reason: str = \"unconditional skip\"\n\n\ndef evaluate_skip_marks(item: Item) -> Skip | None:\n    \"\"\"Evaluate skip and skipif marks on item, returning Skip if triggered.\"\"\"\n    for mark in item.iter_markers(name=\"skipif\"):\n        if \"condition\" not in mark.kwargs:\n            conditions = mark.args\n        else:\n            conditions = (mark.kwargs[\"condition\"],)\n\n        # Unconditional.\n        if not conditions:\n            reason = mark.kwargs.get(\"reason\", \"\")\n            return Skip(reason)\n\n        # If any of the conditions are true.\n        for condition in conditions:\n            result, reason = evaluate_condition(item, mark, condition)\n            if result:\n                return Skip(reason)\n\n    for mark in item.iter_markers(name=\"skip\"):\n        try:\n            return Skip(*mark.args, **mark.kwargs)\n        except TypeError as e:\n            raise TypeError(str(e) + \" - maybe you meant pytest.mark.skipif?\") from None\n\n    return None\n\n\n@dataclasses.dataclass(frozen=True)\nclass Xfail:\n    \"\"\"The result of evaluate_xfail_marks().\"\"\"\n\n    __slots__ = (\"raises\", \"reason\", \"run\", \"strict\")\n\n    reason: str\n    run: bool\n    strict: bool\n    raises: (\n        type[BaseException]\n        | tuple[type[BaseException], ...]\n        | AbstractRaises[BaseException]\n        | None\n    )\n\n\ndef evaluate_xfail_mar"}, {"start_line": 6000, "end_line": 8000, "belongs_to": {"file_name": "skipping.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "= (mark.kwargs[\"condition\"],)\n\n        # Unconditional.\n        if not conditions:\n            reason = mark.kwargs.get(\"reason\", \"\")\n            return Skip(reason)\n\n        # If any of the conditions are true.\n        for condition in conditions:\n            result, reason = evaluate_condition(item, mark, condition)\n            if result:\n                return Skip(reason)\n\n    for mark in item.iter_markers(name=\"skip\"):\n        try:\n            return Skip(*mark.args, **mark.kwargs)\n        except TypeError as e:\n            raise TypeError(str(e) + \" - maybe you meant pytest.mark.skipif?\") from None\n\n    return None\n\n\n@dataclasses.dataclass(frozen=True)\nclass Xfail:\n    \"\"\"The result of evaluate_xfail_marks().\"\"\"\n\n    __slots__ = (\"raises\", \"reason\", \"run\", \"strict\")\n\n    reason: str\n    run: bool\n    strict: bool\n    raises: (\n        type[BaseException]\n        | tuple[type[BaseException], ...]\n        | AbstractRaises[BaseException]\n        | None\n    )\n\n\ndef evaluate_xfail_marks(item: Item) -> Xfail | None:\n    \"\"\"Evaluate xfail marks on item, returning Xfail if triggered.\"\"\"\n    for mark in item.iter_markers(name=\"xfail\"):\n        run = mark.kwargs.get(\"run\", True)\n        strict = mark.kwargs.get(\"strict\", item.config.getini(\"xfail_strict\"))\n        raises = mark.kwargs.get(\"raises\", None)\n        if \"condition\" not in mark.kwargs:\n            conditions = mark.args\n        else:\n            conditions = (mark.kwargs[\"condition\"],)\n\n        # Unconditional.\n        if not conditions:\n            reason = mark.kwargs.get(\"reason\", \"\")\n            return Xfail(reason, run, strict, raises)\n\n        # If any of the conditions are true.\n        for condition in conditions:\n            result, reason = evaluate_condition(item, mark, condition)\n            if result:\n                return Xfail(reason, run, strict, raises)\n\n    return None\n\n\n# Saves the xfail mark evaluation. Can be refreshed during call if None.\nxfailed_key = StashKey[Optional[Xfail]]()\n\n\n@hoo"}, {"start_line": 7000, "end_line": 9000, "belongs_to": {"file_name": "test_skipping.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "       )\n        foo.joinpath(\"test_foo.py\").write_text(\n            textwrap.dedent(\n                \"\"\"\\\n            import pytest\n\n            @pytest.mark.skipif(\"arg == 'foo'\")\n            def test_foo():\n                assert False\n            \"\"\"\n            ),\n            encoding=\"utf-8\",\n        )\n        bar = root.joinpath(\"bar\")\n        bar.mkdir()\n        bar.joinpath(\"__init__.py\").touch()\n        bar.joinpath(\"conftest.py\").write_text(\n            textwrap.dedent(\n                \"\"\"\\\n            import pytest\n\n            def pytest_markeval_namespace():\n                return {\"arg\": \"bar\"}\n            \"\"\"\n            ),\n            encoding=\"utf-8\",\n        )\n        bar.joinpath(\"test_bar.py\").write_text(\n            textwrap.dedent(\n                \"\"\"\\\n            import pytest\n\n            @pytest.mark.skipif(\"arg == 'bar'\")\n            def test_bar():\n                assert False\n            \"\"\"\n            ),\n            encoding=\"utf-8\",\n        )\n\n        reprec = pytester.inline_run(\"-vs\", \"--capture=no\")\n        reprec.assertoutcome(skipped=3)\n\n    def test_skipif_markeval_namespace_ValueError(self, pytester: Pytester) -> None:\n        pytester.makeconftest(\n            \"\"\"\n            import pytest\n\n            def pytest_markeval_namespace():\n                return True\n            \"\"\"\n        )\n        p = pytester.makepyfile(\n            \"\"\"\n            import pytest\n\n            @pytest.mark.skipif(\"color == 'green'\")\n            def test_1():\n                assert True\n        \"\"\"\n        )\n        res = pytester.runpytest(p)\n        assert res.ret == 1\n        res.stdout.fnmatch_lines(\n            [\n                \"*ValueError: pytest_markeval_namespace() needs to return a dict, got True*\"\n            ]\n        )\n\n\nclass TestXFail:\n    @pytest.mark.parametrize(\"strict\", [True, False])\n    def test_xfail_simple(self, pytester: Pytester, strict: bool) -> None:\n        item = pytester.getitem(\n            f\"\"\"\n            import p"}, {"start_line": 22000, "end_line": 24000, "belongs_to": {"file_name": "test_mark.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "x.name: x for x in items}\n        for name, expected_markers in expected.items():\n            markers = {m.name for m in items[name].iter_markers()}\n            assert markers == set(expected_markers)\n\n    @pytest.mark.filterwarnings(\"ignore\")\n    def test_mark_from_parameters(self, pytester: Pytester) -> None:\n        \"\"\"#1540\"\"\"\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n\n            pytestmark = pytest.mark.skipif(True, reason='skip all')\n\n            # skipifs inside fixture params\n            params = [pytest.mark.skipif(False, reason='dont skip')('parameter')]\n\n\n            @pytest.fixture(params=params)\n            def parameter(request):\n                return request.param\n\n\n            def test_1(parameter):\n                assert True\n        \"\"\"\n        )\n        reprec = pytester.inline_run()\n        reprec.assertoutcome(skipped=1)\n\n    def test_reevaluate_dynamic_expr(self, pytester: Pytester) -> None:\n        \"\"\"#7360\"\"\"\n        py_file1 = pytester.makepyfile(\n            test_reevaluate_dynamic_expr1=\"\"\"\n            import pytest\n\n            skip = True\n\n            @pytest.mark.skipif(\"skip\")\n            def test_should_skip():\n                assert True\n        \"\"\"\n        )\n        py_file2 = pytester.makepyfile(\n            test_reevaluate_dynamic_expr2=\"\"\"\n            import pytest\n\n            skip = False\n\n            @pytest.mark.skipif(\"skip\")\n            def test_should_not_skip():\n                assert True\n        \"\"\"\n        )\n\n        file_name1 = os.path.basename(py_file1)\n        file_name2 = os.path.basename(py_file2)\n        reprec = pytester.inline_run(file_name1, file_name2)\n        reprec.assertoutcome(passed=1, skipped=1)\n\n\nclass TestKeywordSelection:\n    def test_select_simple(self, pytester: Pytester) -> None:\n        file_test = pytester.makepyfile(\n            \"\"\"\n            def test_one():\n                assert 0\n            class TestClass(object):\n                def test_method_one(self):"}, {"start_line": 2000, "end_line": 4000, "belongs_to": {"file_name": "test_skipping.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "valuate_skip_marks(item)\n        assert skipped\n        assert skipped.reason == \"hello world\"\n\n    def test_marked_one_arg_twice(self, pytester: Pytester) -> None:\n        lines = [\n            \"\"\"@pytest.mark.skipif(\"not hasattr(os, 'murks')\")\"\"\",\n            \"\"\"@pytest.mark.skipif(condition=\"hasattr(os, 'murks')\")\"\"\",\n        ]\n        for i in range(2):\n            item = pytester.getitem(\n                f\"\"\"\n                import pytest\n                {lines[i]}\n                {lines[(i + 1) % 2]}\n                def test_func():\n                    pass\n            \"\"\"\n            )\n            skipped = evaluate_skip_marks(item)\n            assert skipped\n            assert skipped.reason == \"condition: not hasattr(os, 'murks')\"\n\n    def test_marked_one_arg_twice2(self, pytester: Pytester) -> None:\n        item = pytester.getitem(\n            \"\"\"\n            import pytest\n            @pytest.mark.skipif(\"hasattr(os, 'murks')\")\n            @pytest.mark.skipif(\"not hasattr(os, 'murks')\")\n            def test_func():\n                pass\n        \"\"\"\n        )\n        skipped = evaluate_skip_marks(item)\n        assert skipped\n        assert skipped.reason == \"condition: not hasattr(os, 'murks')\"\n\n    def test_marked_skipif_with_boolean_without_reason(\n        self, pytester: Pytester\n    ) -> None:\n        item = pytester.getitem(\n            \"\"\"\n            import pytest\n            @pytest.mark.skipif(False)\n            def test_func():\n                pass\n        \"\"\"\n        )\n        with pytest.raises(pytest.fail.Exception) as excinfo:\n            evaluate_skip_marks(item)\n        assert excinfo.value.msg is not None\n        assert (\n            \"\"\"Error evaluating 'skipif': you need to specify reason=STRING when using booleans as conditions.\"\"\"\n            in excinfo.value.msg\n        )\n\n    def test_marked_skipif_with_invalid_boolean(self, pytester: Pytester) -> None:\n        item = pytester.getitem(\n            \"\"\"\n            import pytest\n\n        "}, {"start_line": 7000, "end_line": 9000, "belongs_to": {"file_name": "skipping.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "ks(item: Item) -> Xfail | None:\n    \"\"\"Evaluate xfail marks on item, returning Xfail if triggered.\"\"\"\n    for mark in item.iter_markers(name=\"xfail\"):\n        run = mark.kwargs.get(\"run\", True)\n        strict = mark.kwargs.get(\"strict\", item.config.getini(\"xfail_strict\"))\n        raises = mark.kwargs.get(\"raises\", None)\n        if \"condition\" not in mark.kwargs:\n            conditions = mark.args\n        else:\n            conditions = (mark.kwargs[\"condition\"],)\n\n        # Unconditional.\n        if not conditions:\n            reason = mark.kwargs.get(\"reason\", \"\")\n            return Xfail(reason, run, strict, raises)\n\n        # If any of the conditions are true.\n        for condition in conditions:\n            result, reason = evaluate_condition(item, mark, condition)\n            if result:\n                return Xfail(reason, run, strict, raises)\n\n    return None\n\n\n# Saves the xfail mark evaluation. Can be refreshed during call if None.\nxfailed_key = StashKey[Optional[Xfail]]()\n\n\n@hookimpl(tryfirst=True)\ndef pytest_runtest_setup(item: Item) -> None:\n    skipped = evaluate_skip_marks(item)\n    if skipped:\n        raise skip.Exception(skipped.reason, _use_item_location=True)\n\n    item.stash[xfailed_key] = xfailed = evaluate_xfail_marks(item)\n    if xfailed and not item.config.option.runxfail and not xfailed.run:\n        xfail(\"[NOTRUN] \" + xfailed.reason)\n\n\n@hookimpl(wrapper=True)\ndef pytest_runtest_call(item: Item) -> Generator[None]:\n    xfailed = item.stash.get(xfailed_key, None)\n    if xfailed is None:\n        item.stash[xfailed_key] = xfailed = evaluate_xfail_marks(item)\n\n    if xfailed and not item.config.option.runxfail and not xfailed.run:\n        xfail(\"[NOTRUN] \" + xfailed.reason)\n\n    try:\n        return (yield)\n    finally:\n        # The test run may have added an xfail mark dynamically.\n        xfailed = item.stash.get(xfailed_key, None)\n        if xfailed is None:\n            item.stash[xfailed_key] = xfailed = evaluate_xfail_marks(item)\n\n\n@hookimpl(wra"}, {"start_line": 1000, "end_line": 3000, "belongs_to": {"file_name": "test_skipping.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "   item = pytester.getitem(\n            \"\"\"\n            import pytest\n            @pytest.mark.skipif\n            def test_func():\n                pass\n        \"\"\"\n        )\n        skipped = evaluate_skip_marks(item)\n        assert skipped\n        assert skipped.reason == \"\"\n\n    def test_marked_one_arg(self, pytester: Pytester) -> None:\n        item = pytester.getitem(\n            \"\"\"\n            import pytest\n            @pytest.mark.skipif(\"hasattr(os, 'sep')\")\n            def test_func():\n                pass\n        \"\"\"\n        )\n        skipped = evaluate_skip_marks(item)\n        assert skipped\n        assert skipped.reason == \"condition: hasattr(os, 'sep')\"\n\n    def test_marked_one_arg_with_reason(self, pytester: Pytester) -> None:\n        item = pytester.getitem(\n            \"\"\"\n            import pytest\n            @pytest.mark.skipif(\"hasattr(os, 'sep')\", attr=2, reason=\"hello world\")\n            def test_func():\n                pass\n        \"\"\"\n        )\n        skipped = evaluate_skip_marks(item)\n        assert skipped\n        assert skipped.reason == \"hello world\"\n\n    def test_marked_one_arg_twice(self, pytester: Pytester) -> None:\n        lines = [\n            \"\"\"@pytest.mark.skipif(\"not hasattr(os, 'murks')\")\"\"\",\n            \"\"\"@pytest.mark.skipif(condition=\"hasattr(os, 'murks')\")\"\"\",\n        ]\n        for i in range(2):\n            item = pytester.getitem(\n                f\"\"\"\n                import pytest\n                {lines[i]}\n                {lines[(i + 1) % 2]}\n                def test_func():\n                    pass\n            \"\"\"\n            )\n            skipped = evaluate_skip_marks(item)\n            assert skipped\n            assert skipped.reason == \"condition: not hasattr(os, 'murks')\"\n\n    def test_marked_one_arg_twice2(self, pytester: Pytester) -> None:\n        item = pytester.getitem(\n            \"\"\"\n            import pytest\n            @pytest.mark.skipif(\"hasattr(os, 'murks')\")\n            @pytest.mark.skipif(\"not hasattr(os,"}, {"start_line": 22000, "end_line": 24000, "belongs_to": {"file_name": "test_cacheprovider.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "import pytest\n            @pytest.mark.xfail(strict=True)\n            def test(): pass\n        \"\"\"\n        )\n        result = pytester.runpytest()\n        result.stdout.fnmatch_lines([\"*1 failed*\"])\n        assert self.get_cached_last_failed(pytester) == [\n            \"test_xfail_strict_considered_failure.py::test\"\n        ]\n\n    @pytest.mark.parametrize(\"mark\", [\"mark.xfail\", \"mark.skip\"])\n    def test_failed_changed_to_xfail_or_skip(\n        self, pytester: Pytester, mark: str\n    ) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n            def test(): assert 0\n        \"\"\"\n        )\n        result = pytester.runpytest()\n        assert self.get_cached_last_failed(pytester) == [\n            \"test_failed_changed_to_xfail_or_skip.py::test\"\n        ]\n        assert result.ret == 1\n\n        pytester.makepyfile(\n            f\"\"\"\n            import pytest\n            @pytest.{mark}\n            def test(): assert 0\n        \"\"\"\n        )\n        result = pytester.runpytest()\n        assert result.ret == 0\n        assert self.get_cached_last_failed(pytester) == []\n        assert result.ret == 0\n\n    @pytest.mark.parametrize(\"quiet\", [True, False])\n    @pytest.mark.parametrize(\"opt\", [\"--ff\", \"--lf\"])\n    def test_lf_and_ff_prints_no_needless_message(\n        self, quiet: bool, opt: str, pytester: Pytester\n    ) -> None:\n        # Issue 3853\n        pytester.makepyfile(\"def test(): assert 0\")\n        args = [opt]\n        if quiet:\n            args.append(\"-q\")\n        result = pytester.runpytest(*args)\n        result.stdout.no_fnmatch_line(\"*run all*\")\n\n        result = pytester.runpytest(*args)\n        if quiet:\n            result.stdout.no_fnmatch_line(\"*run all*\")\n        else:\n            assert \"rerun previous\" in result.stdout.str()\n\n    def get_cached_last_failed(self, pytester: Pytester) -> list[str]:\n        config = pytester.parseconfigure()\n        assert config.cache is not None\n        return sorted(config.cache.get(\"cache/lastfai"}, {"start_line": 22000, "end_line": 24000, "belongs_to": {"file_name": "test_skipping.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "        \"\"\"\n        )\n        result = pytester.runpytest(p, \"-rxX\")\n        strict = strict_val == \"true\"\n        result.stdout.fnmatch_lines([\"*1 failed*\" if strict else \"*1 xpassed*\"])\n        assert result.ret == (1 if strict else 0)\n\n    def test_xfail_markeval_namespace(self, pytester: Pytester) -> None:\n        pytester.makeconftest(\n            \"\"\"\n            import pytest\n\n            def pytest_markeval_namespace():\n                return {\"color\": \"green\"}\n            \"\"\"\n        )\n        p = pytester.makepyfile(\n            \"\"\"\n            import pytest\n\n            @pytest.mark.xfail(\"color == 'green'\")\n            def test_1():\n                assert False\n\n            @pytest.mark.xfail(\"color == 'red'\")\n            def test_2():\n                assert False\n        \"\"\"\n        )\n        res = pytester.runpytest(p)\n        assert res.ret == 1\n        res.stdout.fnmatch_lines([\"*1 failed*\"])\n        res.stdout.fnmatch_lines([\"*1 xfailed*\"])\n\n\nclass TestXFailwithSetupTeardown:\n    def test_failing_setup_issue9(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n            def setup_function(func):\n                assert 0\n\n            @pytest.mark.xfail\n            def test_func():\n                pass\n        \"\"\"\n        )\n        result = pytester.runpytest()\n        result.stdout.fnmatch_lines([\"*1 xfail*\"])\n\n    def test_failing_teardown_issue9(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n            def teardown_function(func):\n                assert 0\n\n            @pytest.mark.xfail\n            def test_func():\n                pass\n        \"\"\"\n        )\n        result = pytester.runpytest()\n        result.stdout.fnmatch_lines([\"*1 xfail*\"])\n\n\nclass TestSkip:\n    def test_skip_class(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n            @pytest.mark.skip\n            clas"}], "retrieved_count": 10, "cost_time": 0.34816622734069824}
{"question": "Why does the test_parse_from_file method verify that the parser correctly handles file-based argument input through the @ prefix mechanism, and what is the purpose of storing test paths in an external file rather than passing them directly as command-line arguments?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"start_line": 5000, "end_line": 7000, "belongs_to": {"file_name": "test_parseopt.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "thon/issues/85308\n    # Can be removed once Python<3.12 support is dropped.\n    @pytest.mark.filterwarnings(\"ignore:'encoding' argument not specified\")\n    def test_parse_from_file(self, parser: parseopt.Parser, tmp_path: Path) -> None:\n        tests = [\".\", \"some.py::Test::test_method[param0]\", \"other/test_file.py\"]\n        args_file = tmp_path / \"tests.txt\"\n        args_file.write_text(\"\\n\".join(tests), encoding=\"utf-8\")\n        args = parser.parse([f\"@{args_file.absolute()}\"])\n        assert getattr(args, parseopt.FILE_OR_DIR) == tests\n\n    def test_parse_known_args(self, parser: parseopt.Parser) -> None:\n        parser.parse_known_args([Path(\".\")])\n        parser.addoption(\"--hello\", action=\"store_true\")\n        ns = parser.parse_known_args([\"x\", \"--y\", \"--hello\", \"this\"])\n        assert ns.hello\n        assert ns.file_or_dir == [\"x\"]\n\n    def test_parse_known_and_unknown_args(self, parser: parseopt.Parser) -> None:\n        parser.addoption(\"--hello\", action=\"store_true\")\n        ns, unknown = parser.parse_known_and_unknown_args(\n            [\"x\", \"--y\", \"--hello\", \"this\"]\n        )\n        assert ns.hello\n        assert ns.file_or_dir == [\"x\"]\n        assert unknown == [\"--y\", \"this\"]\n\n    def test_parse_will_set_default(self, parser: parseopt.Parser) -> None:\n        parser.addoption(\"--hello\", dest=\"hello\", default=\"x\", action=\"store\")\n        option = parser.parse([])\n        assert option.hello == \"x\"\n        del option.hello\n        parser.parse_setoption([], option)\n        assert option.hello == \"x\"\n\n    def test_parse_setoption(self, parser: parseopt.Parser) -> None:\n        parser.addoption(\"--hello\", dest=\"hello\", action=\"store\")\n        parser.addoption(\"--world\", dest=\"world\", default=42)\n\n        option = argparse.Namespace()\n        args = parser.parse_setoption([\"--hello\", \"world\"], option)\n        assert option.hello == \"world\"\n        assert option.world == 42\n        assert not args\n\n    def test_parse_special_destination(self, parser: parseop"}, {"start_line": 19000, "end_line": 21000, "belongs_to": {"file_name": "acceptance_test.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "er.runpytest(p)\n        res.assert_outcomes(passed=3)\n\n    # Warning ignore because of:\n    # https://github.com/python/cpython/issues/85308\n    # Can be removed once Python<3.12 support is dropped.\n    @pytest.mark.filterwarnings(\"ignore:'encoding' argument not specified\")\n    def test_command_line_args_from_file(\n        self, pytester: Pytester, tmp_path: Path\n    ) -> None:\n        pytester.makepyfile(\n            test_file=\"\"\"\n            import pytest\n\n            class TestClass:\n                @pytest.mark.parametrize(\"a\", [\"x\",\"y\"])\n                def test_func(self, a):\n                    pass\n            \"\"\"\n        )\n        tests = [\n            \"test_file.py::TestClass::test_func[x]\",\n            \"test_file.py::TestClass::test_func[y]\",\n            \"-q\",\n        ]\n        args_file = pytester.maketxtfile(tests=\"\\n\".join(tests))\n        result = pytester.runpytest(f\"@{args_file}\")\n        result.assert_outcomes(failed=0, passed=2)\n\n\nclass TestInvocationVariants:\n    def test_earlyinit(self, pytester: Pytester) -> None:\n        p = pytester.makepyfile(\n            \"\"\"\n            import pytest\n            assert hasattr(pytest, 'mark')\n        \"\"\"\n        )\n        result = pytester.runpython(p)\n        assert result.ret == 0\n\n    def test_pydoc(self, pytester: Pytester) -> None:\n        result = pytester.runpython_c(\"import pytest;help(pytest)\")\n        assert result.ret == 0\n        s = result.stdout.str()\n        assert \"MarkGenerator\" in s\n\n    def test_import_star_pytest(self, pytester: Pytester) -> None:\n        p = pytester.makepyfile(\n            \"\"\"\n            from pytest import *\n            #Item\n            #File\n            main\n            skip\n            xfail\n        \"\"\"\n        )\n        result = pytester.runpython(p)\n        assert result.ret == 0\n\n    def test_double_pytestcmdline(self, pytester: Pytester) -> None:\n        p = pytester.makepyfile(\n            run=\"\"\"\n            import pytest\n            pytest.main()\n            "}, {"start_line": 4000, "end_line": 6000, "belongs_to": {"file_name": "test_parseopt.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "getgroup(\"hello\")\n        with pytest.raises(ValueError):\n            group.addoption(\"-x\", action=\"store_true\")\n        assert len(group.options) == 0\n        group._addoption(\"-x\", action=\"store_true\")\n        assert len(group.options) == 1\n\n    def test_parser_addoption(self, parser: parseopt.Parser) -> None:\n        group = parser.getgroup(\"custom options\")\n        assert len(group.options) == 0\n        group.addoption(\"--option1\", action=\"store_true\")\n        assert len(group.options) == 1\n\n    def test_parse(self, parser: parseopt.Parser) -> None:\n        parser.addoption(\"--hello\", dest=\"hello\", action=\"store\")\n        args = parser.parse([\"--hello\", \"world\"])\n        assert args.hello == \"world\"\n        assert not getattr(args, parseopt.FILE_OR_DIR)\n\n    def test_parse2(self, parser: parseopt.Parser) -> None:\n        args = parser.parse([Path(\".\")])\n        assert getattr(args, parseopt.FILE_OR_DIR)[0] == \".\"\n\n    # Warning ignore because of:\n    # https://github.com/python/cpython/issues/85308\n    # Can be removed once Python<3.12 support is dropped.\n    @pytest.mark.filterwarnings(\"ignore:'encoding' argument not specified\")\n    def test_parse_from_file(self, parser: parseopt.Parser, tmp_path: Path) -> None:\n        tests = [\".\", \"some.py::Test::test_method[param0]\", \"other/test_file.py\"]\n        args_file = tmp_path / \"tests.txt\"\n        args_file.write_text(\"\\n\".join(tests), encoding=\"utf-8\")\n        args = parser.parse([f\"@{args_file.absolute()}\"])\n        assert getattr(args, parseopt.FILE_OR_DIR) == tests\n\n    def test_parse_known_args(self, parser: parseopt.Parser) -> None:\n        parser.parse_known_args([Path(\".\")])\n        parser.addoption(\"--hello\", action=\"store_true\")\n        ns = parser.parse_known_args([\"x\", \"--y\", \"--hello\", \"this\"])\n        assert ns.hello\n        assert ns.file_or_dir == [\"x\"]\n\n    def test_parse_known_and_unknown_args(self, parser: parseopt.Parser) -> None:\n        parser.addoption(\"--hello\", action=\"store_true\")\n        n"}, {"start_line": 18000, "end_line": 20000, "belongs_to": {"file_name": "acceptance_test.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "eType(\"myplugin\")\n        monkeypatch.setitem(sys.modules, \"myplugin\", mod)\n        assert pytest.main(args=[str(pytester.path)], plugins=[\"myplugin\"]) == 0\n\n    def test_parametrized_with_bytes_regex(self, pytester: Pytester) -> None:\n        p = pytester.makepyfile(\n            \"\"\"\n            import re\n            import pytest\n            @pytest.mark.parametrize('r', [re.compile(b'foo')])\n            def test_stuff(r):\n                pass\n        \"\"\"\n        )\n        res = pytester.runpytest(p)\n        res.stdout.fnmatch_lines([\"*1 passed*\"])\n\n    def test_parametrized_with_null_bytes(self, pytester: Pytester) -> None:\n        \"\"\"Test parametrization with values that contain null bytes and unicode characters (#2644, #2957)\"\"\"\n        p = pytester.makepyfile(\n            \"\"\"\\\n            import pytest\n\n            @pytest.mark.parametrize(\"data\", [b\"\\\\x00\", \"\\\\x00\", 'ao'])\n            def test_foo(data):\n                assert data\n            \"\"\"\n        )\n        res = pytester.runpytest(p)\n        res.assert_outcomes(passed=3)\n\n    # Warning ignore because of:\n    # https://github.com/python/cpython/issues/85308\n    # Can be removed once Python<3.12 support is dropped.\n    @pytest.mark.filterwarnings(\"ignore:'encoding' argument not specified\")\n    def test_command_line_args_from_file(\n        self, pytester: Pytester, tmp_path: Path\n    ) -> None:\n        pytester.makepyfile(\n            test_file=\"\"\"\n            import pytest\n\n            class TestClass:\n                @pytest.mark.parametrize(\"a\", [\"x\",\"y\"])\n                def test_func(self, a):\n                    pass\n            \"\"\"\n        )\n        tests = [\n            \"test_file.py::TestClass::test_func[x]\",\n            \"test_file.py::TestClass::test_func[y]\",\n            \"-q\",\n        ]\n        args_file = pytester.maketxtfile(tests=\"\\n\".join(tests))\n        result = pytester.runpytest(f\"@{args_file}\")\n        result.assert_outcomes(failed=0, passed=2)\n\n\nclass TestInvocationVariants:\n    def"}, {"start_line": 17000, "end_line": 19000, "belongs_to": {"file_name": "test_config.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "monkeypatch.setenv(\"PYTEST_PLUGINS\", \"myplugin\")\n        pytester.syspathinsert()\n        result = pytester.runpytest(\"--foo=1\")\n        result.stdout.fnmatch_lines(\"* no tests ran in *\")\n\n    def test_args_source_args(self, pytester: Pytester):\n        config = pytester.parseconfig(\"--\", \"test_filename.py\")\n        assert config.args_source == Config.ArgsSource.ARGS\n\n    def test_args_source_invocation_dir(self, pytester: Pytester):\n        config = pytester.parseconfig()\n        assert config.args_source == Config.ArgsSource.INVOCATION_DIR\n\n    def test_args_source_testpaths(self, pytester: Pytester):\n        pytester.makeini(\n            \"\"\"\n            [pytest]\n            testpaths=*\n        \"\"\"\n        )\n        config = pytester.parseconfig()\n        assert config.args_source == Config.ArgsSource.TESTPATHS\n\n\nclass TestConfigCmdlineParsing:\n    def test_parsing_again_fails(self, pytester: Pytester) -> None:\n        config = pytester.parseconfig()\n        pytest.raises(AssertionError, lambda: config.parse([]))\n\n    def test_explicitly_specified_config_file_is_loaded(\n        self, pytester: Pytester\n    ) -> None:\n        pytester.makeconftest(\n            \"\"\"\n            def pytest_addoption(parser):\n                parser.addini(\"custom\", \"\")\n        \"\"\"\n        )\n        pytester.makeini(\n            \"\"\"\n            [pytest]\n            custom = 0\n        \"\"\"\n        )\n        pytester.makefile(\n            \".ini\",\n            custom=\"\"\"\n            [pytest]\n            custom = 1\n        \"\"\",\n        )\n        config = pytester.parseconfig(\"-c\", \"custom.ini\")\n        assert config.getini(\"custom\") == \"1\"\n        config = pytester.parseconfig(\"--config-file\", \"custom.ini\")\n        assert config.getini(\"custom\") == \"1\"\n\n        pytester.makefile(\n            \".cfg\",\n            custom_tool_pytest_section=\"\"\"\n            [tool:pytest]\n            custom = 1\n        \"\"\",\n        )\n        config = pytester.parseconfig(\"-c\", \"custom_tool_pytest_section.cfg\")\n   "}, {"start_line": 3000, "end_line": 5000, "belongs_to": {"file_name": "test_main.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "h):\n    monkeypatch.chdir(str(tmp_path))\n    msg = \"basetemp must not be empty, the current working directory or any parent directory of it\"\n    with pytest.raises(argparse.ArgumentTypeError, match=msg):\n        if basetemp:\n            basetemp = tmp_path / basetemp\n        validate_basetemp(basetemp)\n\n\ndef test_validate_basetemp_integration(pytester: Pytester) -> None:\n    result = pytester.runpytest(\"--basetemp=.\")\n    result.stderr.fnmatch_lines(\"*basetemp must not be*\")\n\n\nclass TestResolveCollectionArgument:\n    @pytest.fixture\n    def invocation_path(self, pytester: Pytester) -> Path:\n        pytester.syspathinsert(pytester.path / \"src\")\n        pytester.chdir()\n\n        pkg = pytester.path.joinpath(\"src/pkg\")\n        pkg.mkdir(parents=True)\n        pkg.joinpath(\"__init__.py\").touch()\n        pkg.joinpath(\"test.py\").touch()\n        return pytester.path\n\n    def test_file(self, invocation_path: Path) -> None:\n        \"\"\"File and parts.\"\"\"\n        assert resolve_collection_argument(\n            invocation_path, \"src/pkg/test.py\"\n        ) == CollectionArgument(\n            path=invocation_path / \"src/pkg/test.py\",\n            parts=[],\n            module_name=None,\n        )\n        assert resolve_collection_argument(\n            invocation_path, \"src/pkg/test.py::\"\n        ) == CollectionArgument(\n            path=invocation_path / \"src/pkg/test.py\",\n            parts=[\"\"],\n            module_name=None,\n        )\n        assert resolve_collection_argument(\n            invocation_path, \"src/pkg/test.py::foo::bar\"\n        ) == CollectionArgument(\n            path=invocation_path / \"src/pkg/test.py\",\n            parts=[\"foo\", \"bar\"],\n            module_name=None,\n        )\n        assert resolve_collection_argument(\n            invocation_path, \"src/pkg/test.py::foo::bar::\"\n        ) == CollectionArgument(\n            path=invocation_path / \"src/pkg/test.py\",\n            parts=[\"foo\", \"bar\", \"\"],\n            module_name=None,\n        )\n\n    def test_dir(self, invo"}, {"start_line": 7000, "end_line": 9000, "belongs_to": {"file_name": "test_parseopt.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "t.Parser) -> None:\n        parser.addoption(\"--ultimate-answer\", type=int)\n        args = parser.parse([\"--ultimate-answer\", \"42\"])\n        assert args.ultimate_answer == 42\n\n    def test_parse_split_positional_arguments(self, parser: parseopt.Parser) -> None:\n        parser.addoption(\"-R\", action=\"store_true\")\n        parser.addoption(\"-S\", action=\"store_false\")\n        args = parser.parse([\"-R\", \"4\", \"2\", \"-S\"])\n        assert getattr(args, parseopt.FILE_OR_DIR) == [\"4\", \"2\"]\n        args = parser.parse([\"-R\", \"-S\", \"4\", \"2\", \"-R\"])\n        assert getattr(args, parseopt.FILE_OR_DIR) == [\"4\", \"2\"]\n        assert args.R is True\n        assert args.S is False\n        args = parser.parse([\"-R\", \"4\", \"-S\", \"2\"])\n        assert getattr(args, parseopt.FILE_OR_DIR) == [\"4\", \"2\"]\n        assert args.R is True\n        assert args.S is False\n\n    def test_parse_defaultgetter(self) -> None:\n        def defaultget(option):\n            if not hasattr(option, \"type\"):\n                return\n            if option.type is int:\n                option.default = 42\n            elif option.type is str:\n                option.default = \"world\"\n\n        parser = parseopt.Parser(processopt=defaultget, _ispytest=True)\n        parser.addoption(\"--this\", dest=\"this\", type=int, action=\"store\")\n        parser.addoption(\"--hello\", dest=\"hello\", type=str, action=\"store\")\n        parser.addoption(\"--no\", dest=\"no\", action=\"store_true\")\n        option = parser.parse([])\n        assert option.hello == \"world\"\n        assert option.this == 42\n        assert option.no is False\n\n    def test_drop_short_helper(self) -> None:\n        parser = argparse.ArgumentParser(\n            formatter_class=parseopt.DropShorterLongHelpFormatter, allow_abbrev=False\n        )\n        parser.add_argument(\n            \"-t\", \"--twoword\", \"--duo\", \"--two-word\", \"--two\", help=\"foo\"\n        )\n        # throws error on --deux only!\n        parser.add_argument(\n            \"-d\", \"--deuxmots\", \"--deux-mots\", action=\"store_tru"}, {"start_line": 16000, "end_line": 18000, "belongs_to": {"file_name": "test_config.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "atch.setattr(importlib.metadata, \"distributions\", my_dists)\n        monkeypatch.delenv(\"PYTEST_DISABLE_PLUGIN_AUTOLOAD\", raising=False)\n\n        pytester.makeini(ini_file_text)\n\n        if exception_text:\n            with pytest.raises(pytest.UsageError, match=exception_text):\n                pytester.parseconfig()\n        else:\n            pytester.parseconfig()\n\n    def test_early_config_cmdline(\n        self, pytester: Pytester, monkeypatch: MonkeyPatch\n    ) -> None:\n        \"\"\"early_config contains options registered by third-party plugins.\n\n        This is a regression involving pytest-cov (and possibly others) introduced in #7700.\n        \"\"\"\n        pytester.makepyfile(\n            myplugin=\"\"\"\n            def pytest_addoption(parser):\n                parser.addoption('--foo', default=None, dest='foo')\n\n            def pytest_load_initial_conftests(early_config, parser, args):\n                assert early_config.known_args_namespace.foo == \"1\"\n            \"\"\"\n        )\n        monkeypatch.setenv(\"PYTEST_PLUGINS\", \"myplugin\")\n        pytester.syspathinsert()\n        result = pytester.runpytest(\"--foo=1\")\n        result.stdout.fnmatch_lines(\"* no tests ran in *\")\n\n    def test_args_source_args(self, pytester: Pytester):\n        config = pytester.parseconfig(\"--\", \"test_filename.py\")\n        assert config.args_source == Config.ArgsSource.ARGS\n\n    def test_args_source_invocation_dir(self, pytester: Pytester):\n        config = pytester.parseconfig()\n        assert config.args_source == Config.ArgsSource.INVOCATION_DIR\n\n    def test_args_source_testpaths(self, pytester: Pytester):\n        pytester.makeini(\n            \"\"\"\n            [pytest]\n            testpaths=*\n        \"\"\"\n        )\n        config = pytester.parseconfig()\n        assert config.args_source == Config.ArgsSource.TESTPATHS\n\n\nclass TestConfigCmdlineParsing:\n    def test_parsing_again_fails(self, pytester: Pytester) -> None:\n        config = pytester.parseconfig()\n        pytest.raises(AssertionEr"}, {"start_line": 11000, "end_line": 13000, "belongs_to": {"file_name": "test_parseopt.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "gs.func_arg is False\n        assert args.file_or_dir == [\"abcd\"]\n\n    def test_drop_short_help0(self, parser: parseopt.Parser) -> None:\n        parser.addoption(\"--func-args\", \"--doit\", help=\"foo\", action=\"store_true\")\n        parser.parse([])\n        help = parser.optparser.format_help()\n        assert \"--func-args, --doit  foo\" in help\n\n    # testing would be more helpful with all help generated\n    def test_drop_short_help1(self, parser: parseopt.Parser) -> None:\n        group = parser.getgroup(\"general\")\n        group.addoption(\"--doit\", \"--func-args\", action=\"store_true\", help=\"foo\")\n        group._addoption(\n            \"-h\",\n            \"--help\",\n            action=\"store_true\",\n            dest=\"help\",\n            help=\"show help message and configuration info\",\n        )\n        parser.parse([\"-h\"])\n        help = parser.optparser.format_help()\n        assert \"-doit, --func-args  foo\" in help\n\n    def test_multiple_metavar_help(self, parser: parseopt.Parser) -> None:\n        \"\"\"\n        Help text for options with a metavar tuple should display help\n        in the form \"--preferences=value1 value2 value3\" (#2004).\n        \"\"\"\n        group = parser.getgroup(\"general\")\n        group.addoption(\n            \"--preferences\", metavar=(\"value1\", \"value2\", \"value3\"), nargs=3\n        )\n        group._addoption(\"-h\", \"--help\", action=\"store_true\", dest=\"help\")\n        parser.parse([\"-h\"])\n        help = parser.optparser.format_help()\n        assert \"--preferences=value1 value2 value3\" in help\n\n\ndef test_argcomplete(pytester: Pytester, monkeypatch: MonkeyPatch) -> None:\n    if sys.version_info >= (3, 11):\n        # New in Python 3.11, ignores utf-8 mode\n        encoding = locale.getencoding()\n    else:\n        encoding = locale.getpreferredencoding(False)\n    try:\n        bash_version = subprocess.run(\n            [\"bash\", \"--version\"],\n            stdout=subprocess.PIPE,\n            stderr=subprocess.DEVNULL,\n            check=True,\n            text=True,\n           "}, {"start_line": 38000, "end_line": 40000, "belongs_to": {"file_name": "test_config.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "   option_dict = {\"inifilename\": inifilename, \"capture\": \"no\"}\n\n        cwd = tmp_path.joinpath(\"a/b\")\n        cwd.mkdir(parents=True)\n        p2 = cwd.joinpath(\"pytest.ini\")\n        p2.touch()\n        p2.write_text(\n            textwrap.dedent(\n                \"\"\"\\\n                [pytest]\n                name = wrong-value\n                should_not_be_set = true\n                \"\"\"\n            ),\n            encoding=\"utf-8\",\n        )\n        with MonkeyPatch.context() as mp:\n            mp.chdir(cwd)\n            config = Config.fromdictargs(option_dict, ())\n            inipath = absolutepath(inifilename)\n\n        assert config.args == [str(cwd)]\n        assert config.option.inifilename == inifilename\n        assert config.option.capture == \"no\"\n\n        # this indicates this is the file used for getting configuration values\n        assert config.inipath == inipath\n        assert config.inicfg.get(\"name\") == \"value\"\n        assert config.inicfg.get(\"should_not_be_set\") is None\n\n\ndef test_options_on_small_file_do_not_blow_up(pytester: Pytester) -> None:\n    def runfiletest(opts: Sequence[str]) -> None:\n        reprec = pytester.inline_run(*opts)\n        passed, skipped, failed = reprec.countoutcomes()\n        assert failed == 2\n        assert skipped == passed == 0\n\n    path = str(\n        pytester.makepyfile(\n            \"\"\"\n        def test_f1(): assert 0\n        def test_f2(): assert 0\n    \"\"\"\n        )\n    )\n\n    runfiletest([path])\n    runfiletest([\"-l\", path])\n    runfiletest([\"-s\", path])\n    runfiletest([\"--tb=no\", path])\n    runfiletest([\"--tb=short\", path])\n    runfiletest([\"--tb=long\", path])\n    runfiletest([\"--fulltrace\", path])\n    runfiletest([\"--traceconfig\", path])\n    runfiletest([\"-v\", path])\n    runfiletest([\"-v\", \"-v\", path])\n\n\ndef test_preparse_ordering_with_setuptools(\n    pytester: Pytester, monkeypatch: MonkeyPatch\n) -> None:\n    monkeypatch.delenv(\"PYTEST_DISABLE_PLUGIN_AUTOLOAD\", raising=False)\n\n    class EntryPoint:\n        name = \"myt"}], "retrieved_count": 10, "cost_time": 0.34447193145751953}
{"question": "Why does the ensure_deletable function's resilience mechanism prevent cascading failures when both lock file removal and file status checks fail simultaneously in a concurrent directory cleanup scenario?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"start_line": 13000, "end_line": 15000, "belongs_to": {"file_name": "test_tmpdir.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "ert dir_num == 0\n\n    def test_cleanup_locked(self, tmp_path):\n        p = make_numbered_dir(root=tmp_path, prefix=self.PREFIX)\n\n        create_cleanup_lock(p)\n\n        assert not pathlib.ensure_deletable(\n            p, consider_lock_dead_if_created_before=p.stat().st_mtime - 1\n        )\n        assert pathlib.ensure_deletable(\n            p, consider_lock_dead_if_created_before=p.stat().st_mtime + 1\n        )\n\n    def test_cleanup_ignores_symlink(self, tmp_path):\n        the_symlink = tmp_path / (self.PREFIX + \"current\")\n        attempt_symlink_to(the_symlink, tmp_path / (self.PREFIX + \"5\"))\n        self._do_cleanup(tmp_path)\n\n    def test_removal_accepts_lock(self, tmp_path):\n        folder = make_numbered_dir(root=tmp_path, prefix=self.PREFIX)\n        create_cleanup_lock(folder)\n        maybe_delete_a_numbered_dir(folder)\n        assert folder.is_dir()\n\n\nclass TestRmRf:\n    def test_rm_rf(self, tmp_path):\n        adir = tmp_path / \"adir\"\n        adir.mkdir()\n        rm_rf(adir)\n\n        assert not adir.exists()\n\n        adir.mkdir()\n        afile = adir / \"afile\"\n        afile.write_bytes(b\"aa\")\n\n        rm_rf(adir)\n        assert not adir.exists()\n\n    def test_rm_rf_with_read_only_file(self, tmp_path):\n        \"\"\"Ensure rm_rf can remove directories with read-only files in them (#5524)\"\"\"\n        fn = tmp_path / \"dir/foo.txt\"\n        fn.parent.mkdir()\n\n        fn.touch()\n\n        self.chmod_r(fn)\n\n        rm_rf(fn.parent)\n\n        assert not fn.parent.is_dir()\n\n    def chmod_r(self, path):\n        mode = os.stat(str(path)).st_mode\n        os.chmod(str(path), mode & ~stat.S_IWRITE)\n\n    def test_rm_rf_with_read_only_directory(self, tmp_path):\n        \"\"\"Ensure rm_rf can remove read-only directories (#5524)\"\"\"\n        adir = tmp_path / \"dir\"\n        adir.mkdir()\n\n        (adir / \"foo.txt\").touch()\n        self.chmod_r(adir)\n\n        rm_rf(adir)\n\n        assert not adir.is_dir()\n\n    def test_on_rm_rf_error(self, tmp_path: Path) -> None:\n        adir = tmp_path / "}, {"start_line": 17000, "end_line": 19000, "belongs_to": {"file_name": "test_pathlib.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "th.isdir(extended_path)\n    maybe_delete_a_numbered_dir(path)\n    assert not os.path.isdir(extended_path)\n\n\ndef test_get_extended_length_path_str() -> None:\n    assert get_extended_length_path_str(r\"c:\\foo\") == r\"\\\\?\\c:\\foo\"\n    assert get_extended_length_path_str(r\"\\\\share\\foo\") == r\"\\\\?\\UNC\\share\\foo\"\n    assert get_extended_length_path_str(r\"\\\\?\\UNC\\share\\foo\") == r\"\\\\?\\UNC\\share\\foo\"\n    assert get_extended_length_path_str(r\"\\\\?\\c:\\foo\") == r\"\\\\?\\c:\\foo\"\n\n\ndef test_suppress_error_removing_lock(tmp_path: Path) -> None:\n    \"\"\"ensure_deletable should be resilient if lock file cannot be removed (#5456, #7491)\"\"\"\n    path = tmp_path / \"dir\"\n    path.mkdir()\n    lock = get_lock_path(path)\n    lock.touch()\n    mtime = lock.stat().st_mtime\n\n    with unittest.mock.patch.object(Path, \"unlink\", side_effect=OSError) as m:\n        assert not ensure_deletable(\n            path, consider_lock_dead_if_created_before=mtime + 30\n        )\n        assert m.call_count == 1\n    assert lock.is_file()\n\n    with unittest.mock.patch.object(Path, \"is_file\", side_effect=OSError) as m:\n        assert not ensure_deletable(\n            path, consider_lock_dead_if_created_before=mtime + 30\n        )\n        assert m.call_count == 1\n    assert lock.is_file()\n\n    # check now that we can remove the lock file in normal circumstances\n    assert ensure_deletable(path, consider_lock_dead_if_created_before=mtime + 30)\n    assert not lock.is_file()\n\n\ndef test_bestrelpath() -> None:\n    curdir = Path(\"/foo/bar/baz/path\")\n    assert bestrelpath(curdir, curdir) == \".\"\n    assert bestrelpath(curdir, curdir / \"hello\" / \"world\") == \"hello\" + os.sep + \"world\"\n    assert bestrelpath(curdir, curdir.parent / \"sister\") == \"..\" + os.sep + \"sister\"\n    assert bestrelpath(curdir, curdir.parent) == \"..\"\n    assert bestrelpath(curdir, Path(\"hello\")) == \"hello\"\n\n\ndef test_commonpath() -> None:\n    path = Path(\"/foo/bar/baz/path\")\n    subpath = path / \"sampledir\"\n    assert commonpath(path, subpath) == path\n    asser"}, {"start_line": 10000, "end_line": 12000, "belongs_to": {"file_name": "pathlib.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "ck.stat().st_mtime\n    except Exception:\n        return False\n    else:\n        if lock_time < consider_lock_dead_if_created_before:\n            # We want to ignore any errors while trying to remove the lock such as:\n            # - PermissionDenied, like the file permissions have changed since the lock creation;\n            # - FileNotFoundError, in case another pytest process got here first;\n            # and any other cause of failure.\n            with contextlib.suppress(OSError):\n                lock.unlink()\n                return True\n        return False\n\n\ndef try_cleanup(path: Path, consider_lock_dead_if_created_before: float) -> None:\n    \"\"\"Try to cleanup a folder if we can ensure it's deletable.\"\"\"\n    if ensure_deletable(path, consider_lock_dead_if_created_before):\n        maybe_delete_a_numbered_dir(path)\n\n\ndef cleanup_candidates(root: Path, prefix: str, keep: int) -> Iterator[Path]:\n    \"\"\"List candidates for numbered directories to be removed - follows py.path.\"\"\"\n    max_existing = max(map(parse_num, find_suffixes(root, prefix)), default=-1)\n    max_delete = max_existing - keep\n    entries = find_prefixed(root, prefix)\n    entries, entries2 = itertools.tee(entries)\n    numbers = map(parse_num, extract_suffixes(entries2, prefix))\n    for entry, number in zip(entries, numbers):\n        if number <= max_delete:\n            yield Path(entry)\n\n\ndef cleanup_dead_symlinks(root: Path) -> None:\n    for left_dir in root.iterdir():\n        if left_dir.is_symlink():\n            if not left_dir.resolve().exists():\n                left_dir.unlink()\n\n\ndef cleanup_numbered_dir(\n    root: Path, prefix: str, keep: int, consider_lock_dead_if_created_before: float\n) -> None:\n    \"\"\"Cleanup for lock driven numbered directories.\"\"\"\n    if not root.exists():\n        return\n    for path in cleanup_candidates(root, prefix, keep):\n        try_cleanup(path, consider_lock_dead_if_created_before)\n    for path in root.glob(\"garbage-*\"):\n        try_cleanup(path, consider_lock_de"}, {"start_line": 9000, "end_line": 11000, "belongs_to": {"file_name": "pathlib.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "rf(garbage)\n    except OSError:\n        #  known races:\n        #  * other process did a cleanup at the same time\n        #  * deletable folder was found\n        #  * process cwd (Windows)\n        return\n    finally:\n        # If we created the lock, ensure we remove it even if we failed\n        # to properly remove the numbered dir.\n        if lock_path is not None:\n            try:\n                lock_path.unlink()\n            except OSError:\n                pass\n\n\ndef ensure_deletable(path: Path, consider_lock_dead_if_created_before: float) -> bool:\n    \"\"\"Check if `path` is deletable based on whether the lock file is expired.\"\"\"\n    if path.is_symlink():\n        return False\n    lock = get_lock_path(path)\n    try:\n        if not lock.is_file():\n            return True\n    except OSError:\n        # we might not have access to the lock file at all, in this case assume\n        # we don't have access to the entire directory (#7491).\n        return False\n    try:\n        lock_time = lock.stat().st_mtime\n    except Exception:\n        return False\n    else:\n        if lock_time < consider_lock_dead_if_created_before:\n            # We want to ignore any errors while trying to remove the lock such as:\n            # - PermissionDenied, like the file permissions have changed since the lock creation;\n            # - FileNotFoundError, in case another pytest process got here first;\n            # and any other cause of failure.\n            with contextlib.suppress(OSError):\n                lock.unlink()\n                return True\n        return False\n\n\ndef try_cleanup(path: Path, consider_lock_dead_if_created_before: float) -> None:\n    \"\"\"Try to cleanup a folder if we can ensure it's deletable.\"\"\"\n    if ensure_deletable(path, consider_lock_dead_if_created_before):\n        maybe_delete_a_numbered_dir(path)\n\n\ndef cleanup_candidates(root: Path, prefix: str, keep: int) -> Iterator[Path]:\n    \"\"\"List candidates for numbered directories to be removed - follows py.path.\"\"\"\n    m"}, {"start_line": 12000, "end_line": 14000, "belongs_to": {"file_name": "test_tmpdir.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "ck(tmp_path)\n\n        registry: list[Callable[..., None]] = []\n        register_cleanup_lock_removal(lock, register=registry.append)\n\n        (cleanup_func,) = registry\n\n        assert lock.is_file()\n\n        cleanup_func(original_pid=\"intentionally_different\")\n\n        assert lock.is_file()\n\n        cleanup_func()\n\n        assert not lock.exists()\n\n        cleanup_func()\n\n        assert not lock.exists()\n\n    def _do_cleanup(self, tmp_path: Path, keep: int = 2) -> None:\n        self.test_make(tmp_path)\n        cleanup_numbered_dir(\n            root=tmp_path,\n            prefix=self.PREFIX,\n            keep=keep,\n            consider_lock_dead_if_created_before=0,\n        )\n\n    def test_cleanup_keep(self, tmp_path):\n        self._do_cleanup(tmp_path)\n        a, b = (x for x in tmp_path.iterdir() if not x.is_symlink())\n        print(a, b)\n\n    def test_cleanup_keep_0(self, tmp_path: Path):\n        self._do_cleanup(tmp_path, 0)\n        dir_num = len(list(tmp_path.iterdir()))\n        assert dir_num == 0\n\n    def test_cleanup_locked(self, tmp_path):\n        p = make_numbered_dir(root=tmp_path, prefix=self.PREFIX)\n\n        create_cleanup_lock(p)\n\n        assert not pathlib.ensure_deletable(\n            p, consider_lock_dead_if_created_before=p.stat().st_mtime - 1\n        )\n        assert pathlib.ensure_deletable(\n            p, consider_lock_dead_if_created_before=p.stat().st_mtime + 1\n        )\n\n    def test_cleanup_ignores_symlink(self, tmp_path):\n        the_symlink = tmp_path / (self.PREFIX + \"current\")\n        attempt_symlink_to(the_symlink, tmp_path / (self.PREFIX + \"5\"))\n        self._do_cleanup(tmp_path)\n\n    def test_removal_accepts_lock(self, tmp_path):\n        folder = make_numbered_dir(root=tmp_path, prefix=self.PREFIX)\n        create_cleanup_lock(folder)\n        maybe_delete_a_numbered_dir(folder)\n        assert folder.is_dir()\n\n\nclass TestRmRf:\n    def test_rm_rf(self, tmp_path):\n        adir = tmp_path / \"adir\"\n        adir.mkdir()\n        rm_rf(adir)\n\n  "}, {"start_line": 18000, "end_line": 20000, "belongs_to": {"file_name": "test_pathlib.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "    with unittest.mock.patch.object(Path, \"is_file\", side_effect=OSError) as m:\n        assert not ensure_deletable(\n            path, consider_lock_dead_if_created_before=mtime + 30\n        )\n        assert m.call_count == 1\n    assert lock.is_file()\n\n    # check now that we can remove the lock file in normal circumstances\n    assert ensure_deletable(path, consider_lock_dead_if_created_before=mtime + 30)\n    assert not lock.is_file()\n\n\ndef test_bestrelpath() -> None:\n    curdir = Path(\"/foo/bar/baz/path\")\n    assert bestrelpath(curdir, curdir) == \".\"\n    assert bestrelpath(curdir, curdir / \"hello\" / \"world\") == \"hello\" + os.sep + \"world\"\n    assert bestrelpath(curdir, curdir.parent / \"sister\") == \"..\" + os.sep + \"sister\"\n    assert bestrelpath(curdir, curdir.parent) == \"..\"\n    assert bestrelpath(curdir, Path(\"hello\")) == \"hello\"\n\n\ndef test_commonpath() -> None:\n    path = Path(\"/foo/bar/baz/path\")\n    subpath = path / \"sampledir\"\n    assert commonpath(path, subpath) == path\n    assert commonpath(subpath, path) == path\n    assert commonpath(Path(str(path) + \"suffix\"), path) == path.parent\n    assert commonpath(path, path.parent.parent) == path.parent.parent\n\n\ndef test_visit_ignores_errors(tmp_path: Path) -> None:\n    symlink_or_skip(\"recursive\", tmp_path / \"recursive\")\n    tmp_path.joinpath(\"foo\").write_bytes(b\"\")\n    tmp_path.joinpath(\"bar\").write_bytes(b\"\")\n\n    assert [\n        entry.name for entry in visit(str(tmp_path), recurse=lambda entry: False)\n    ] == [\"bar\", \"foo\"]\n\n\n@pytest.mark.skipif(not sys.platform.startswith(\"win\"), reason=\"Windows only\")\ndef test_samefile_false_negatives(tmp_path: Path, monkeypatch: MonkeyPatch) -> None:\n    \"\"\"\n    import_file() should not raise ImportPathMismatchError if the paths are exactly\n    equal on Windows. It seems directories mounted as UNC paths make os.path.samefile\n    return False, even when they are clearly equal.\n    \"\"\"\n    module_path = tmp_path.joinpath(\"my_module.py\")\n    module_path.write_text(\"def foo(): re"}, {"start_line": 8000, "end_line": 10000, "belongs_to": {"file_name": "pathlib.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": " renamed after successful creation\")\n        return lock_path\n\n\ndef register_cleanup_lock_removal(\n    lock_path: Path, register: Any = atexit.register\n) -> Any:\n    \"\"\"Register a cleanup function for removing a lock, by default on atexit.\"\"\"\n    pid = os.getpid()\n\n    def cleanup_on_exit(lock_path: Path = lock_path, original_pid: int = pid) -> None:\n        current_pid = os.getpid()\n        if current_pid != original_pid:\n            # fork\n            return\n        try:\n            lock_path.unlink()\n        except OSError:\n            pass\n\n    return register(cleanup_on_exit)\n\n\ndef maybe_delete_a_numbered_dir(path: Path) -> None:\n    \"\"\"Remove a numbered directory if its lock can be obtained and it does\n    not seem to be in use.\"\"\"\n    path = ensure_extended_length_path(path)\n    lock_path = None\n    try:\n        lock_path = create_cleanup_lock(path)\n        parent = path.parent\n\n        garbage = parent.joinpath(f\"garbage-{uuid.uuid4()}\")\n        path.rename(garbage)\n        rm_rf(garbage)\n    except OSError:\n        #  known races:\n        #  * other process did a cleanup at the same time\n        #  * deletable folder was found\n        #  * process cwd (Windows)\n        return\n    finally:\n        # If we created the lock, ensure we remove it even if we failed\n        # to properly remove the numbered dir.\n        if lock_path is not None:\n            try:\n                lock_path.unlink()\n            except OSError:\n                pass\n\n\ndef ensure_deletable(path: Path, consider_lock_dead_if_created_before: float) -> bool:\n    \"\"\"Check if `path` is deletable based on whether the lock file is expired.\"\"\"\n    if path.is_symlink():\n        return False\n    lock = get_lock_path(path)\n    try:\n        if not lock.is_file():\n            return True\n    except OSError:\n        # we might not have access to the lock file at all, in this case assume\n        # we don't have access to the entire directory (#7491).\n        return False\n    try:\n        lock_time = lo"}, {"start_line": 16000, "end_line": 18000, "belongs_to": {"file_name": "test_pathlib.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "resolve_package_path(pkg)\n\n\ndef test_access_denied_during_cleanup(tmp_path: Path, monkeypatch: MonkeyPatch) -> None:\n    \"\"\"Ensure that deleting a numbered dir does not fail because of OSErrors (#4262).\"\"\"\n    path = tmp_path / \"temp-1\"\n    path.mkdir()\n\n    def renamed_failed(*args):\n        raise OSError(\"access denied\")\n\n    monkeypatch.setattr(Path, \"rename\", renamed_failed)\n\n    lock_path = get_lock_path(path)\n    maybe_delete_a_numbered_dir(path)\n    assert not lock_path.is_file()\n\n\ndef test_long_path_during_cleanup(tmp_path: Path) -> None:\n    \"\"\"Ensure that deleting long path works (particularly on Windows (#6775)).\"\"\"\n    path = (tmp_path / (\"a\" * 250)).resolve()\n    if sys.platform == \"win32\":\n        # make sure that the full path is > 260 characters without any\n        # component being over 260 characters\n        assert len(str(path)) > 260\n        extended_path = \"\\\\\\\\?\\\\\" + str(path)\n    else:\n        extended_path = str(path)\n    os.mkdir(extended_path)\n    assert os.path.isdir(extended_path)\n    maybe_delete_a_numbered_dir(path)\n    assert not os.path.isdir(extended_path)\n\n\ndef test_get_extended_length_path_str() -> None:\n    assert get_extended_length_path_str(r\"c:\\foo\") == r\"\\\\?\\c:\\foo\"\n    assert get_extended_length_path_str(r\"\\\\share\\foo\") == r\"\\\\?\\UNC\\share\\foo\"\n    assert get_extended_length_path_str(r\"\\\\?\\UNC\\share\\foo\") == r\"\\\\?\\UNC\\share\\foo\"\n    assert get_extended_length_path_str(r\"\\\\?\\c:\\foo\") == r\"\\\\?\\c:\\foo\"\n\n\ndef test_suppress_error_removing_lock(tmp_path: Path) -> None:\n    \"\"\"ensure_deletable should be resilient if lock file cannot be removed (#5456, #7491)\"\"\"\n    path = tmp_path / \"dir\"\n    path.mkdir()\n    lock = get_lock_path(path)\n    lock.touch()\n    mtime = lock.stat().st_mtime\n\n    with unittest.mock.patch.object(Path, \"unlink\", side_effect=OSError) as m:\n        assert not ensure_deletable(\n            path, consider_lock_dead_if_created_before=mtime + 30\n        )\n        assert m.call_count == 1\n    assert lock.is_file()\n\n"}, {"start_line": 1000, "end_line": 3000, "belongs_to": {"file_name": "pathlib.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "tlib._bootstrap_external import _NamespaceLoader as NamespaceLoader\nelse:\n    from importlib.machinery import NamespaceLoader\n\nLOCK_TIMEOUT = 60 * 60 * 24 * 3\n\n_AnyPurePath = TypeVar(\"_AnyPurePath\", bound=PurePath)\n\n# The following function, variables and comments were\n# copied from cpython 3.9 Lib/pathlib.py file.\n\n# EBADF - guard against macOS `stat` throwing EBADF\n_IGNORED_ERRORS = (ENOENT, ENOTDIR, EBADF, ELOOP)\n\n_IGNORED_WINERRORS = (\n    21,  # ERROR_NOT_READY - drive exists but is not accessible\n    1921,  # ERROR_CANT_RESOLVE_FILENAME - fix for broken symlink pointing to itself\n)\n\n\ndef _ignore_error(exception: Exception) -> bool:\n    return (\n        getattr(exception, \"errno\", None) in _IGNORED_ERRORS\n        or getattr(exception, \"winerror\", None) in _IGNORED_WINERRORS\n    )\n\n\ndef get_lock_path(path: _AnyPurePath) -> _AnyPurePath:\n    return path.joinpath(\".lock\")\n\n\ndef on_rm_rf_error(\n    func: Callable[..., Any] | None,\n    path: str,\n    excinfo: BaseException\n    | tuple[type[BaseException], BaseException, types.TracebackType | None],\n    *,\n    start_path: Path,\n) -> bool:\n    \"\"\"Handle known read-only errors during rmtree.\n\n    The returned value is used only by our own tests.\n    \"\"\"\n    if isinstance(excinfo, BaseException):\n        exc = excinfo\n    else:\n        exc = excinfo[1]\n\n    # Another process removed the file in the middle of the \"rm_rf\" (xdist for example).\n    # More context: https://github.com/pytest-dev/pytest/issues/5974#issuecomment-543799018\n    if isinstance(exc, FileNotFoundError):\n        return False\n\n    if not isinstance(exc, PermissionError):\n        warnings.warn(\n            PytestWarning(f\"(rm_rf) error removing {path}\\n{type(exc)}: {exc}\")\n        )\n        return False\n\n    if func not in (os.rmdir, os.remove, os.unlink):\n        if func not in (os.open,):\n            warnings.warn(\n                PytestWarning(\n                    f\"(rm_rf) unknown function {func} when removing {path}:\\n{type(exc)}: {exc}\"\n          "}, {"start_line": 43000, "end_line": 45000, "belongs_to": {"file_name": "path.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest/_py", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": ":\n                lockfile.mksymlinkto(str(mypid))\n            else:\n                fd = error.checked_call(\n                    os.open, str(lockfile), os.O_WRONLY | os.O_CREAT | os.O_EXCL, 0o644\n                )\n                with os.fdopen(fd, \"w\") as f:\n                    f.write(str(mypid))\n            return lockfile\n\n        def atexit_remove_lockfile(lockfile):\n            \"\"\"Ensure lockfile is removed at process exit\"\"\"\n            mypid = os.getpid()\n\n            def try_remove_lockfile():\n                # in a fork() situation, only the last process should\n                # remove the .lock, otherwise the other processes run the\n                # risk of seeing their temporary dir disappear.  For now\n                # we remove the .lock in the parent only (i.e. we assume\n                # that the children finish before the parent).\n                if os.getpid() != mypid:\n                    return\n                try:\n                    lockfile.remove()\n                except error.Error:\n                    pass\n\n            atexit.register(try_remove_lockfile)\n\n        # compute the maximum number currently in use with the prefix\n        lastmax = None\n        while True:\n            maxnum = -1\n            for path in rootdir.listdir():\n                num = parse_num(path)\n                if num is not None:\n                    maxnum = max(maxnum, num)\n\n            # make the new directory\n            try:\n                udir = rootdir.mkdir(prefix + str(maxnum + 1))\n                if lock_timeout:\n                    lockfile = create_lockfile(udir)\n                    atexit_remove_lockfile(lockfile)\n            except (error.EEXIST, error.ENOENT, error.EBUSY):\n                # race condition (1): another thread/process created the dir\n                #                     in the meantime - try again\n                # race condition (2): another thread/process spuriously acquired\n                #                     lock treating emp"}], "retrieved_count": 10, "cost_time": 0.3350105285644531}
{"question": "Why does the SysCapture class maintain consistency between its captured buffer state and the original system stream when snap() and writeorg() operations are interleaved during test execution?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"start_line": 12000, "end_line": 14000, "belongs_to": {"file_name": "capture.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "ne\"\n\n    def suspend(self) -> None:\n        self._assert_state(\"suspend\", (\"started\", \"suspended\"))\n        setattr(sys, self.name, self._old)\n        self._state = \"suspended\"\n\n    def resume(self) -> None:\n        self._assert_state(\"resume\", (\"started\", \"suspended\"))\n        if self._state == \"started\":\n            return\n        setattr(sys, self.name, self.tmpfile)\n        self._state = \"started\"\n\n\nclass SysCaptureBinary(SysCaptureBase[bytes]):\n    EMPTY_BUFFER = b\"\"\n\n    def snap(self) -> bytes:\n        self._assert_state(\"snap\", (\"started\", \"suspended\"))\n        self.tmpfile.seek(0)\n        res = self.tmpfile.buffer.read()\n        self.tmpfile.seek(0)\n        self.tmpfile.truncate()\n        return res\n\n    def writeorg(self, data: bytes) -> None:\n        self._assert_state(\"writeorg\", (\"started\", \"suspended\"))\n        self._old.flush()\n        self._old.buffer.write(data)\n        self._old.buffer.flush()\n\n\nclass SysCapture(SysCaptureBase[str]):\n    EMPTY_BUFFER = \"\"\n\n    def snap(self) -> str:\n        self._assert_state(\"snap\", (\"started\", \"suspended\"))\n        assert isinstance(self.tmpfile, CaptureIO)\n        res = self.tmpfile.getvalue()\n        self.tmpfile.seek(0)\n        self.tmpfile.truncate()\n        return res\n\n    def writeorg(self, data: str) -> None:\n        self._assert_state(\"writeorg\", (\"started\", \"suspended\"))\n        self._old.write(data)\n        self._old.flush()\n\n\nclass FDCaptureBase(CaptureBase[AnyStr]):\n    def __init__(self, targetfd: int) -> None:\n        self.targetfd = targetfd\n\n        try:\n            os.fstat(targetfd)\n        except OSError:\n            # FD capturing is conceptually simple -- create a temporary file,\n            # redirect the FD to it, redirect back when done. But when the\n            # target FD is invalid it throws a wrench into this lovely scheme.\n            #\n            # Tests themselves shouldn't care if the FD is valid, FD capturing\n            # should work regardless of external circumstances. So fall"}, {"start_line": 11000, "end_line": 13000, "belongs_to": {"file_name": "capture.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "\n        )\n\n    def __repr__(self) -> str:\n        return \"<{} {} _old={} _state={!r} tmpfile={!r}>\".format(\n            self.__class__.__name__,\n            self.name,\n            (hasattr(self, \"_old\") and repr(self._old)) or \"<UNSET>\",\n            self._state,\n            self.tmpfile,\n        )\n\n    def _assert_state(self, op: str, states: tuple[str, ...]) -> None:\n        assert self._state in states, (\n            \"cannot {} in state {!r}: expected one of {}\".format(\n                op, self._state, \", \".join(states)\n            )\n        )\n\n    def start(self) -> None:\n        self._assert_state(\"start\", (\"initialized\",))\n        setattr(sys, self.name, self.tmpfile)\n        self._state = \"started\"\n\n    def done(self) -> None:\n        self._assert_state(\"done\", (\"initialized\", \"started\", \"suspended\", \"done\"))\n        if self._state == \"done\":\n            return\n        setattr(sys, self.name, self._old)\n        del self._old\n        self.tmpfile.close()\n        self._state = \"done\"\n\n    def suspend(self) -> None:\n        self._assert_state(\"suspend\", (\"started\", \"suspended\"))\n        setattr(sys, self.name, self._old)\n        self._state = \"suspended\"\n\n    def resume(self) -> None:\n        self._assert_state(\"resume\", (\"started\", \"suspended\"))\n        if self._state == \"started\":\n            return\n        setattr(sys, self.name, self.tmpfile)\n        self._state = \"started\"\n\n\nclass SysCaptureBinary(SysCaptureBase[bytes]):\n    EMPTY_BUFFER = b\"\"\n\n    def snap(self) -> bytes:\n        self._assert_state(\"snap\", (\"started\", \"suspended\"))\n        self.tmpfile.seek(0)\n        res = self.tmpfile.buffer.read()\n        self.tmpfile.seek(0)\n        self.tmpfile.truncate()\n        return res\n\n    def writeorg(self, data: bytes) -> None:\n        self._assert_state(\"writeorg\", (\"started\", \"suspended\"))\n        self._old.flush()\n        self._old.buffer.write(data)\n        self._old.buffer.flush()\n\n\nclass SysCapture(SysCaptureBase[str]):\n    EMPTY_BUFFER = \"\"\n\n    def sna"}, {"start_line": 13000, "end_line": 15000, "belongs_to": {"file_name": "capture.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "p(self) -> str:\n        self._assert_state(\"snap\", (\"started\", \"suspended\"))\n        assert isinstance(self.tmpfile, CaptureIO)\n        res = self.tmpfile.getvalue()\n        self.tmpfile.seek(0)\n        self.tmpfile.truncate()\n        return res\n\n    def writeorg(self, data: str) -> None:\n        self._assert_state(\"writeorg\", (\"started\", \"suspended\"))\n        self._old.write(data)\n        self._old.flush()\n\n\nclass FDCaptureBase(CaptureBase[AnyStr]):\n    def __init__(self, targetfd: int) -> None:\n        self.targetfd = targetfd\n\n        try:\n            os.fstat(targetfd)\n        except OSError:\n            # FD capturing is conceptually simple -- create a temporary file,\n            # redirect the FD to it, redirect back when done. But when the\n            # target FD is invalid it throws a wrench into this lovely scheme.\n            #\n            # Tests themselves shouldn't care if the FD is valid, FD capturing\n            # should work regardless of external circumstances. So falling back\n            # to just sys capturing is not a good option.\n            #\n            # Further complications are the need to support suspend() and the\n            # possibility of FD reuse (e.g. the tmpfile getting the very same\n            # target FD). The following approach is robust, I believe.\n            self.targetfd_invalid: int | None = os.open(os.devnull, os.O_RDWR)\n            os.dup2(self.targetfd_invalid, targetfd)\n        else:\n            self.targetfd_invalid = None\n        self.targetfd_save = os.dup(targetfd)\n\n        if targetfd == 0:\n            self.tmpfile = open(os.devnull, encoding=\"utf-8\")\n            self.syscapture: CaptureBase[str] = SysCapture(targetfd)\n        else:\n            self.tmpfile = EncodedFile(\n                TemporaryFile(buffering=0),\n                encoding=\"utf-8\",\n                errors=\"replace\",\n                newline=\"\",\n                write_through=True,\n            )\n            if targetfd in patchsysdict:\n                "}, {"start_line": 10000, "end_line": 12000, "belongs_to": {"file_name": "capture.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "ass\n\n    def suspend(self) -> None:\n        pass\n\n    def resume(self) -> None:\n        pass\n\n    def snap(self) -> str:\n        return \"\"\n\n    def writeorg(self, data: str) -> None:\n        pass\n\n\nclass SysCaptureBase(CaptureBase[AnyStr]):\n    def __init__(\n        self, fd: int, tmpfile: TextIO | None = None, *, tee: bool = False\n    ) -> None:\n        name = patchsysdict[fd]\n        self._old: TextIO = getattr(sys, name)\n        self.name = name\n        if tmpfile is None:\n            if name == \"stdin\":\n                tmpfile = DontReadFromInput()\n            else:\n                tmpfile = CaptureIO() if not tee else TeeCaptureIO(self._old)\n        self.tmpfile = tmpfile\n        self._state = \"initialized\"\n\n    def repr(self, class_name: str) -> str:\n        return \"<{} {} _old={} _state={!r} tmpfile={!r}>\".format(\n            class_name,\n            self.name,\n            (hasattr(self, \"_old\") and repr(self._old)) or \"<UNSET>\",\n            self._state,\n            self.tmpfile,\n        )\n\n    def __repr__(self) -> str:\n        return \"<{} {} _old={} _state={!r} tmpfile={!r}>\".format(\n            self.__class__.__name__,\n            self.name,\n            (hasattr(self, \"_old\") and repr(self._old)) or \"<UNSET>\",\n            self._state,\n            self.tmpfile,\n        )\n\n    def _assert_state(self, op: str, states: tuple[str, ...]) -> None:\n        assert self._state in states, (\n            \"cannot {} in state {!r}: expected one of {}\".format(\n                op, self._state, \", \".join(states)\n            )\n        )\n\n    def start(self) -> None:\n        self._assert_state(\"start\", (\"initialized\",))\n        setattr(sys, self.name, self.tmpfile)\n        self._state = \"started\"\n\n    def done(self) -> None:\n        self._assert_state(\"done\", (\"initialized\", \"started\", \"suspended\", \"done\"))\n        if self._state == \"done\":\n            return\n        setattr(sys, self.name, self._old)\n        del self._old\n        self.tmpfile.close()\n        self._state = \"do"}, {"start_line": 16000, "end_line": 18000, "belongs_to": {"file_name": "capture.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "    seeked to position zero.\"\"\"\n        self._assert_state(\"done\", (\"initialized\", \"started\", \"suspended\", \"done\"))\n        if self._state == \"done\":\n            return\n        os.dup2(self.targetfd_save, self.targetfd)\n        os.close(self.targetfd_save)\n        if self.targetfd_invalid is not None:\n            if self.targetfd_invalid != self.targetfd:\n                os.close(self.targetfd)\n            os.close(self.targetfd_invalid)\n        self.syscapture.done()\n        self.tmpfile.close()\n        self._state = \"done\"\n\n    def suspend(self) -> None:\n        self._assert_state(\"suspend\", (\"started\", \"suspended\"))\n        if self._state == \"suspended\":\n            return\n        self.syscapture.suspend()\n        os.dup2(self.targetfd_save, self.targetfd)\n        self._state = \"suspended\"\n\n    def resume(self) -> None:\n        self._assert_state(\"resume\", (\"started\", \"suspended\"))\n        if self._state == \"started\":\n            return\n        self.syscapture.resume()\n        os.dup2(self.tmpfile.fileno(), self.targetfd)\n        self._state = \"started\"\n\n\nclass FDCaptureBinary(FDCaptureBase[bytes]):\n    \"\"\"Capture IO to/from a given OS-level file descriptor.\n\n    snap() produces `bytes`.\n    \"\"\"\n\n    EMPTY_BUFFER = b\"\"\n\n    def snap(self) -> bytes:\n        self._assert_state(\"snap\", (\"started\", \"suspended\"))\n        self.tmpfile.seek(0)\n        res = self.tmpfile.buffer.read()\n        self.tmpfile.seek(0)\n        self.tmpfile.truncate()\n        return res  # type: ignore[return-value]\n\n    def writeorg(self, data: bytes) -> None:\n        \"\"\"Write to original file descriptor.\"\"\"\n        self._assert_state(\"writeorg\", (\"started\", \"suspended\"))\n        os.write(self.targetfd_save, data)\n\n\nclass FDCapture(FDCaptureBase[str]):\n    \"\"\"Capture IO to/from a given OS-level file descriptor.\n\n    snap() produces text.\n    \"\"\"\n\n    EMPTY_BUFFER = \"\"\n\n    def snap(self) -> str:\n        self._assert_state(\"snap\", (\"started\", \"suspended\"))\n        self.tmpfile.seek(0)\n        r"}, {"start_line": 34000, "end_line": 36000, "belongs_to": {"file_name": "test_capture.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "e.FDCapture(1)\n            cap.start()\n            data = b\"hello\"\n            os.write(1, data)\n            sys.stdout.write(\"whatever\")\n            s = cap.snap()\n            assert s == \"hellowhatever\"\n            cap.suspend()\n            os.write(1, b\"world\")\n            sys.stdout.write(\"qlwkej\")\n            assert not cap.snap()\n            cap.resume()\n            os.write(1, b\"but now\")\n            sys.stdout.write(\" yes\\n\")\n            s = cap.snap()\n            assert s == \"but now yes\\n\"\n            cap.suspend()\n            cap.done()\n            pytest.raises(AssertionError, cap.suspend)\n\n            assert repr(cap) == (\n                f\"<FDCapture 1 oldfd={cap.targetfd_save} _state='done' tmpfile={cap.tmpfile!r}>\"\n            )\n            # Should not crash with missing \"_old\".\n            assert isinstance(cap.syscapture, capture.SysCapture)\n            assert repr(cap.syscapture) == (\n                f\"<SysCapture stdout _old=<UNSET> _state='done' tmpfile={cap.syscapture.tmpfile!r}>\"\n            )\n\n    def test_capfd_sys_stdout_mode(self, capfd) -> None:\n        assert \"b\" not in sys.stdout.mode\n\n\n@contextlib.contextmanager\ndef saved_fd(fd):\n    new_fd = os.dup(fd)\n    try:\n        yield\n    finally:\n        os.dup2(new_fd, fd)\n        os.close(new_fd)\n\n\nclass TestStdCapture:\n    captureclass = staticmethod(StdCapture)\n\n    @contextlib.contextmanager\n    def getcapture(self, **kw):\n        cap = self.__class__.captureclass(**kw)\n        cap.start_capturing()\n        try:\n            yield cap\n        finally:\n            cap.stop_capturing()\n\n    def test_capturing_done_simple(self) -> None:\n        with self.getcapture() as cap:\n            sys.stdout.write(\"hello\")\n            sys.stderr.write(\"world\")\n            out, err = cap.readouterr()\n        assert out == \"hello\"\n        assert err == \"world\"\n\n    def test_capturing_reset_simple(self) -> None:\n        with self.getcapture() as cap:\n            print(\"hello world\")\n            sys.stderr"}, {"start_line": 33000, "end_line": 35000, "belongs_to": {"file_name": "test_capture.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "ne()\n        pytest.raises(AssertionError, cap.start)\n\n    def test_stderr(self) -> None:\n        cap = capture.FDCapture(2)\n        cap.start()\n        print(\"hello\", file=sys.stderr)\n        s = cap.snap()\n        cap.done()\n        assert s == \"hello\\n\"\n\n    def test_stdin(self) -> None:\n        cap = capture.FDCapture(0)\n        cap.start()\n        x = os.read(0, 100).strip()\n        cap.done()\n        assert x == b\"\"\n\n    def test_writeorg(self, tmpfile: BinaryIO) -> None:\n        data1, data2 = b\"foo\", b\"bar\"\n        cap = capture.FDCapture(tmpfile.fileno())\n        cap.start()\n        tmpfile.write(data1)\n        tmpfile.flush()\n        cap.writeorg(data2.decode(\"ascii\"))\n        scap = cap.snap()\n        cap.done()\n        assert scap == data1.decode(\"ascii\")\n        with open(tmpfile.name, \"rb\") as stmp_file:\n            stmp = stmp_file.read()\n            assert stmp == data2\n\n    def test_simple_resume_suspend(self) -> None:\n        with saved_fd(1):\n            cap = capture.FDCapture(1)\n            cap.start()\n            data = b\"hello\"\n            os.write(1, data)\n            sys.stdout.write(\"whatever\")\n            s = cap.snap()\n            assert s == \"hellowhatever\"\n            cap.suspend()\n            os.write(1, b\"world\")\n            sys.stdout.write(\"qlwkej\")\n            assert not cap.snap()\n            cap.resume()\n            os.write(1, b\"but now\")\n            sys.stdout.write(\" yes\\n\")\n            s = cap.snap()\n            assert s == \"but now yes\\n\"\n            cap.suspend()\n            cap.done()\n            pytest.raises(AssertionError, cap.suspend)\n\n            assert repr(cap) == (\n                f\"<FDCapture 1 oldfd={cap.targetfd_save} _state='done' tmpfile={cap.tmpfile!r}>\"\n            )\n            # Should not crash with missing \"_old\".\n            assert isinstance(cap.syscapture, capture.SysCapture)\n            assert repr(cap.syscapture) == (\n                f\"<SysCapture stdout _old=<UNSET> _state='done' tmpfile={cap.sysca"}, {"start_line": 43000, "end_line": 45000, "belongs_to": {"file_name": "test_capture.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "           cap = capture.FDCaptureBinary(1)\n            cap.start()\n            os.write(1, b\"started\")\n            cap.suspend()\n            os.write(1, b\" suspended\")\n            cap.resume()\n            os.write(1, b\" resumed\")\n            assert cap.snap() == b\"started resumed\"\n            cap.done()\n            with pytest.raises(OSError):\n                os.write(1, b\"done\")\n\n    def test_fdcapture_invalid_fd_without_fd_reuse(self, pytester: Pytester) -> None:\n        with saved_fd(1), saved_fd(2):\n            os.close(1)\n            os.close(2)\n            cap = capture.FDCaptureBinary(2)\n            cap.start()\n            os.write(2, b\"started\")\n            cap.suspend()\n            os.write(2, b\" suspended\")\n            cap.resume()\n            os.write(2, b\" resumed\")\n            assert cap.snap() == b\"started resumed\"\n            cap.done()\n            with pytest.raises(OSError):\n                os.write(2, b\"done\")\n\n\ndef test_capture_not_started_but_reset() -> None:\n    capsys = StdCapture()\n    capsys.stop_capturing()\n\n\ndef test_using_capsys_fixture_works_with_sys_stdout_encoding(\n    capsys: CaptureFixture[str],\n) -> None:\n    test_text = \"test text\"\n\n    print(test_text.encode(sys.stdout.encoding, \"replace\"))\n    (out, err) = capsys.readouterr()\n    assert out\n    assert err == \"\"\n\n\ndef test_capsys_results_accessible_by_attribute(capsys: CaptureFixture[str]) -> None:\n    sys.stdout.write(\"spam\")\n    sys.stderr.write(\"eggs\")\n    capture_result = capsys.readouterr()\n    assert capture_result.out == \"spam\"\n    assert capture_result.err == \"eggs\"\n\n\ndef test_fdcapture_tmpfile_remains_the_same() -> None:\n    cap = StdCaptureFD(out=False, err=True)\n    assert isinstance(cap.err, capture.FDCapture)\n    try:\n        cap.start_capturing()\n        capfile = cap.err.tmpfile\n        cap.readouterr()\n    finally:\n        cap.stop_capturing()\n    capfile2 = cap.err.tmpfile\n    assert capfile2 == capfile\n\n\ndef test_close_and_capture_again(pytester: Pytester) -> Non"}, {"start_line": 15000, "end_line": 17000, "belongs_to": {"file_name": "capture.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "self.syscapture = SysCapture(targetfd, self.tmpfile)\n            else:\n                self.syscapture = NoCapture(targetfd)\n\n        self._state = \"initialized\"\n\n    def __repr__(self) -> str:\n        return (\n            f\"<{self.__class__.__name__} {self.targetfd} oldfd={self.targetfd_save} \"\n            f\"_state={self._state!r} tmpfile={self.tmpfile!r}>\"\n        )\n\n    def _assert_state(self, op: str, states: tuple[str, ...]) -> None:\n        assert self._state in states, (\n            \"cannot {} in state {!r}: expected one of {}\".format(\n                op, self._state, \", \".join(states)\n            )\n        )\n\n    def start(self) -> None:\n        \"\"\"Start capturing on targetfd using memorized tmpfile.\"\"\"\n        self._assert_state(\"start\", (\"initialized\",))\n        os.dup2(self.tmpfile.fileno(), self.targetfd)\n        self.syscapture.start()\n        self._state = \"started\"\n\n    def done(self) -> None:\n        \"\"\"Stop capturing, restore streams, return original capture file,\n        seeked to position zero.\"\"\"\n        self._assert_state(\"done\", (\"initialized\", \"started\", \"suspended\", \"done\"))\n        if self._state == \"done\":\n            return\n        os.dup2(self.targetfd_save, self.targetfd)\n        os.close(self.targetfd_save)\n        if self.targetfd_invalid is not None:\n            if self.targetfd_invalid != self.targetfd:\n                os.close(self.targetfd)\n            os.close(self.targetfd_invalid)\n        self.syscapture.done()\n        self.tmpfile.close()\n        self._state = \"done\"\n\n    def suspend(self) -> None:\n        self._assert_state(\"suspend\", (\"started\", \"suspended\"))\n        if self._state == \"suspended\":\n            return\n        self.syscapture.suspend()\n        os.dup2(self.targetfd_save, self.targetfd)\n        self._state = \"suspended\"\n\n    def resume(self) -> None:\n        self._assert_state(\"resume\", (\"started\", \"suspended\"))\n        if self._state == \"started\":\n            return\n        self.syscapture.resume()\n        os.du"}, {"start_line": 14000, "end_line": 16000, "belongs_to": {"file_name": "capture.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "ing back\n            # to just sys capturing is not a good option.\n            #\n            # Further complications are the need to support suspend() and the\n            # possibility of FD reuse (e.g. the tmpfile getting the very same\n            # target FD). The following approach is robust, I believe.\n            self.targetfd_invalid: int | None = os.open(os.devnull, os.O_RDWR)\n            os.dup2(self.targetfd_invalid, targetfd)\n        else:\n            self.targetfd_invalid = None\n        self.targetfd_save = os.dup(targetfd)\n\n        if targetfd == 0:\n            self.tmpfile = open(os.devnull, encoding=\"utf-8\")\n            self.syscapture: CaptureBase[str] = SysCapture(targetfd)\n        else:\n            self.tmpfile = EncodedFile(\n                TemporaryFile(buffering=0),\n                encoding=\"utf-8\",\n                errors=\"replace\",\n                newline=\"\",\n                write_through=True,\n            )\n            if targetfd in patchsysdict:\n                self.syscapture = SysCapture(targetfd, self.tmpfile)\n            else:\n                self.syscapture = NoCapture(targetfd)\n\n        self._state = \"initialized\"\n\n    def __repr__(self) -> str:\n        return (\n            f\"<{self.__class__.__name__} {self.targetfd} oldfd={self.targetfd_save} \"\n            f\"_state={self._state!r} tmpfile={self.tmpfile!r}>\"\n        )\n\n    def _assert_state(self, op: str, states: tuple[str, ...]) -> None:\n        assert self._state in states, (\n            \"cannot {} in state {!r}: expected one of {}\".format(\n                op, self._state, \", \".join(states)\n            )\n        )\n\n    def start(self) -> None:\n        \"\"\"Start capturing on targetfd using memorized tmpfile.\"\"\"\n        self._assert_state(\"start\", (\"initialized\",))\n        os.dup2(self.tmpfile.fileno(), self.targetfd)\n        self.syscapture.start()\n        self._state = \"started\"\n\n    def done(self) -> None:\n        \"\"\"Stop capturing, restore streams, return original capture file,\n    "}], "retrieved_count": 10, "cost_time": 0.3379683494567871}
{"question": "Where is the precise file location and line range where the DataclassWithOneItem class is defined, and how does its definition relate to the module structure of the pytest testing infrastructure?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"start_line": 40000, "end_line": 42000, "belongs_to": {"file_name": "collect.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing/python", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "ytester: Pytester) -> None:\n        pytester.makeconftest(\n            \"\"\"\n            import pytest\n            class MyFunction(pytest.Function):\n                def reportinfo(self):\n                    return \"ABCDE\", 42, \"custom\"\n            def pytest_pycollect_makeitem(collector, name, obj):\n                if name == \"test_func\":\n                    return MyFunction.from_parent(name=name, parent=collector)\n        \"\"\"\n        )\n        item = pytester.getitem(\"def test_func(): pass\")\n        item.config.pluginmanager.getplugin(\"runner\")\n        assert item.location == (\"ABCDE\", 42, \"custom\")\n\n    def test_func_reportinfo(self, pytester: Pytester) -> None:\n        item = pytester.getitem(\"def test_func(): pass\")\n        path, lineno, modpath = item.reportinfo()\n        assert os.fspath(path) == str(item.path)\n        assert lineno == 0\n        assert modpath == \"test_func\"\n\n    def test_class_reportinfo(self, pytester: Pytester) -> None:\n        modcol = pytester.getmodulecol(\n            \"\"\"\n            # lineno 0\n            class TestClass(object):\n                def test_hello(self): pass\n        \"\"\"\n        )\n        classcol = pytester.collect_by_name(modcol, \"TestClass\")\n        assert isinstance(classcol, Class)\n        path, lineno, msg = classcol.reportinfo()\n        assert os.fspath(path) == str(modcol.path)\n        assert lineno == 1\n        assert msg == \"TestClass\"\n\n    @pytest.mark.filterwarnings(\n        \"ignore:usage of Generator.Function is deprecated, please use pytest.Function instead\"\n    )\n    def test_reportinfo_with_nasty_getattr(self, pytester: Pytester) -> None:\n        # https://github.com/pytest-dev/pytest/issues/1204\n        modcol = pytester.getmodulecol(\n            \"\"\"\n            # lineno 0\n            class TestClass:\n                def __getattr__(self, name):\n                    return \"this is not an int\"\n\n                def __class_getattr__(cls, name):\n                    return \"this is not an int\"\n\n                "}, {"start_line": 1000, "end_line": 3000, "belongs_to": {"file_name": "test_doctest.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "ec = pytester.inline_genitems(x)\n            assert len(items) == 1\n            assert isinstance(items[0], DoctestItem)\n            assert isinstance(items[0].parent, DoctestTextfile)\n        # Empty file has no items.\n        items, reprec = pytester.inline_genitems(w)\n        assert len(items) == 0\n\n    def test_collect_module_empty(self, pytester: Pytester):\n        path = pytester.makepyfile(whatever=\"#\")\n        for p in (path, pytester.path):\n            items, reprec = pytester.inline_genitems(p, \"--doctest-modules\")\n            assert len(items) == 0\n\n    def test_collect_module_single_modulelevel_doctest(self, pytester: Pytester):\n        path = pytester.makepyfile(whatever='\"\"\">>> pass\"\"\"')\n        for p in (path, pytester.path):\n            items, reprec = pytester.inline_genitems(p, \"--doctest-modules\")\n            assert len(items) == 1\n            assert isinstance(items[0], DoctestItem)\n            assert isinstance(items[0].parent, DoctestModule)\n\n    def test_collect_module_two_doctest_one_modulelevel(self, pytester: Pytester):\n        path = pytester.makepyfile(\n            whatever=\"\"\"\n            '>>> x = None'\n            def my_func():\n                \">>> magic = 42 \"\n        \"\"\"\n        )\n        for p in (path, pytester.path):\n            items, reprec = pytester.inline_genitems(p, \"--doctest-modules\")\n            assert len(items) == 2\n            assert isinstance(items[0], DoctestItem)\n            assert isinstance(items[1], DoctestItem)\n            assert isinstance(items[0].parent, DoctestModule)\n            assert items[0].parent is items[1].parent\n\n    @pytest.mark.parametrize(\"filename\", [\"__init__\", \"whatever\"])\n    def test_collect_module_two_doctest_no_modulelevel(\n        self,\n        pytester: Pytester,\n        filename: str,\n    ) -> None:\n        path = pytester.makepyfile(\n            **{\n                filename: \"\"\"\n            '# Empty'\n            def my_func():\n                \">>> magic = 42 \"\n            def useless("}, {"start_line": 8000, "end_line": 10000, "belongs_to": {"file_name": "reports.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "\"\"\"\n\n    __test__ = False\n\n    # Defined by skipping plugin.\n    # xfail reason if xfailed, otherwise not defined. Use hasattr to distinguish.\n    wasxfail: str\n\n    def __init__(\n        self,\n        nodeid: str,\n        location: tuple[str, int | None, str],\n        keywords: Mapping[str, Any],\n        outcome: Literal[\"passed\", \"failed\", \"skipped\"],\n        longrepr: None\n        | ExceptionInfo[BaseException]\n        | tuple[str, int, str]\n        | str\n        | TerminalRepr,\n        when: Literal[\"setup\", \"call\", \"teardown\"],\n        sections: Iterable[tuple[str, str]] = (),\n        duration: float = 0,\n        start: float = 0,\n        stop: float = 0,\n        user_properties: Iterable[tuple[str, object]] | None = None,\n        **extra,\n    ) -> None:\n        #: Normalized collection nodeid.\n        self.nodeid = nodeid\n\n        #: A (filesystempath, lineno, domaininfo) tuple indicating the\n        #: actual location of a test item - it might be different from the\n        #: collected one e.g. if a method is inherited from a different module.\n        #: The filesystempath may be relative to ``config.rootdir``.\n        #: The line number is 0-based.\n        self.location: tuple[str, int | None, str] = location\n\n        #: A name -> value dictionary containing all keywords and\n        #: markers associated with a test invocation.\n        self.keywords: Mapping[str, Any] = keywords\n\n        #: Test outcome, always one of \"passed\", \"failed\", \"skipped\".\n        self.outcome = outcome\n\n        #: None or a failure representation.\n        self.longrepr = longrepr\n\n        #: One of 'setup', 'call', 'teardown' to indicate runtest phase.\n        self.when: Literal[\"setup\", \"call\", \"teardown\"] = when\n\n        #: User properties is a list of tuples (name, value) that holds user\n        #: defined properties of the test.\n        self.user_properties = list(user_properties or [])\n\n        #: Tuples of str ``(heading, content)`` with extra information\n        #: for the t"}, {"start_line": 27000, "end_line": 29000, "belongs_to": {"file_name": "test_collection.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "h.context() as mp:\n            mp.chdir(subdir)\n            config = pytester.parseconfigure(x)\n        col = pytester.getnode(config, x)\n        assert col is not None\n        assert col.name == \"x.py\"\n        assert isinstance(col, pytest.Module)\n        assert isinstance(col.parent, pytest.Package)\n        assert isinstance(col.parent.parent, pytest.Session)\n        # session is batman (has no parents)\n        assert col.parent.parent.parent is None\n        for parent in col.listchain():\n            assert parent.config is config\n\n\nclass Test_genitems:\n    def test_check_collect_hashes(self, pytester: Pytester) -> None:\n        p = pytester.makepyfile(\n            \"\"\"\n            def test_1():\n                pass\n\n            def test_2():\n                pass\n        \"\"\"\n        )\n        shutil.copy(p, p.parent / (p.stem + \"2\" + \".py\"))\n        items, reprec = pytester.inline_genitems(p.parent)\n        assert len(items) == 4\n        for numi, i in enumerate(items):\n            for numj, j in enumerate(items):\n                if numj != numi:\n                    assert hash(i) != hash(j)\n                    assert i != j\n\n    def test_example_items1(self, pytester: Pytester) -> None:\n        p = pytester.makepyfile(\n            \"\"\"\n            import pytest\n\n            def testone():\n                pass\n\n            class TestX(object):\n                def testmethod_one(self):\n                    pass\n\n            class TestY(TestX):\n                @pytest.mark.parametrize(\"arg0\", [\".[\"])\n                def testmethod_two(self, arg0):\n                    pass\n        \"\"\"\n        )\n        items, reprec = pytester.inline_genitems(p)\n        assert len(items) == 4\n        assert items[0].name == \"testone\"\n        assert items[1].name == \"testmethod_one\"\n        assert items[2].name == \"testmethod_one\"\n        assert items[3].name == \"testmethod_two[.[]\"\n\n        # let's also test getmodpath here\n        assert items[0].getmodpath() == \"testone\"  # type: igno"}, {"start_line": 22000, "end_line": 24000, "belongs_to": {"file_name": "nodes.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "  .. versionadded:: 8.0\n\n    :ref:`custom directory collectors`.\n    \"\"\"\n\n\nclass Item(Node, abc.ABC):\n    \"\"\"Base class of all test invocation items.\n\n    Note that for a single function there might be multiple test invocation items.\n    \"\"\"\n\n    nextitem = None\n\n    def __init__(\n        self,\n        name,\n        parent=None,\n        config: Config | None = None,\n        session: Session | None = None,\n        nodeid: str | None = None,\n        **kw,\n    ) -> None:\n        # The first two arguments are intentionally passed positionally,\n        # to keep plugins who define a node type which inherits from\n        # (pytest.Item, pytest.File) working (see issue #8435).\n        # They can be made kwargs when the deprecation above is done.\n        super().__init__(\n            name,\n            parent,\n            config=config,\n            session=session,\n            nodeid=nodeid,\n            **kw,\n        )\n        self._report_sections: list[tuple[str, str, str]] = []\n\n        #: A list of tuples (name, value) that holds user defined properties\n        #: for this test.\n        self.user_properties: list[tuple[str, object]] = []\n\n        self._check_item_and_collector_diamond_inheritance()\n\n    def _check_item_and_collector_diamond_inheritance(self) -> None:\n        \"\"\"\n        Check if the current type inherits from both File and Collector\n        at the same time, emitting a warning accordingly (#8447).\n        \"\"\"\n        cls = type(self)\n\n        # We inject an attribute in the type to avoid issuing this warning\n        # for the same class more than once, which is not helpful.\n        # It is a hack, but was deemed acceptable in order to avoid\n        # flooding the user in the common case.\n        attr_name = \"_pytest_diamond_inheritance_warning_shown\"\n        if getattr(cls, attr_name, False):\n            return\n        setattr(cls, attr_name, True)\n\n        problems = \", \".join(\n            base.__name__ for base in cls.__bases__ if issubclass(base, Coll"}, {"start_line": 0, "end_line": 2000, "belongs_to": {"file_name": "test_session.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "# mypy: allow-untyped-defs\nfrom __future__ import annotations\n\nfrom _pytest.config import ExitCode\nfrom _pytest.monkeypatch import MonkeyPatch\nfrom _pytest.pytester import Pytester\nimport pytest\n\n\nclass SessionTests:\n    def test_basic_testitem_events(self, pytester: Pytester) -> None:\n        tfile = pytester.makepyfile(\n            \"\"\"\n            def test_one():\n                pass\n            def test_one_one():\n                assert 0\n            def test_other():\n                raise ValueError(23)\n            class TestClass(object):\n                def test_two(self, someargs):\n                    pass\n        \"\"\"\n        )\n        reprec = pytester.inline_run(tfile)\n        passed, skipped, failed = reprec.listoutcomes()\n        assert len(skipped) == 0\n        assert len(passed) == 1\n        assert len(failed) == 3\n\n        def end(x):\n            return x.nodeid.split(\"::\")[-1]\n\n        assert end(failed[0]) == \"test_one_one\"\n        assert end(failed[1]) == \"test_other\"\n        itemstarted = reprec.getcalls(\"pytest_itemcollected\")\n        assert len(itemstarted) == 4\n        # XXX check for failing funcarg setup\n        # colreports = reprec.getcalls(\"pytest_collectreport\")\n        # assert len(colreports) == 4\n        # assert colreports[1].report.failed\n\n    def test_nested_import_error(self, pytester: Pytester) -> None:\n        tfile = pytester.makepyfile(\n            \"\"\"\n            import import_fails\n            def test_this():\n                assert import_fails.a == 1\n        \"\"\",\n            import_fails=\"\"\"\n            import does_not_work\n            a = 1\n        \"\"\",\n        )\n        reprec = pytester.inline_run(tfile)\n        values = reprec.getfailedcollections()\n        assert len(values) == 1\n        out = str(values[0].longrepr)\n        assert out.find(\"does_not_work\") != -1\n\n    def test_raises_output(self, pytester: Pytester) -> None:\n        reprec = pytester.inline_runsource(\n            \"\"\"\n            import pytest\n          "}, {"start_line": 25000, "end_line": 27000, "belongs_to": {"file_name": "test_collection.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "s::test_method\"\n        items, hookrec = pytester.inline_genitems(arg)\n        assert len(items) == 1\n        (item,) = items\n        assert item.nodeid.endswith(\"TestClass::test_method\")\n        # ensure we are reporting the collection of the single test item (#2464)\n        assert [x.name for x in self.get_reported_items(hookrec)] == [\"test_method\"]\n\n    def test_collect_parametrized_order(self, pytester: Pytester) -> None:\n        p = pytester.makepyfile(\n            \"\"\"\n            import pytest\n\n            @pytest.mark.parametrize('i', [0, 1, 2])\n            def test_param(i): ...\n            \"\"\"\n        )\n        items, hookrec = pytester.inline_genitems(f\"{p}::test_param\")\n        assert len(items) == 3\n        assert [item.nodeid for item in items] == [\n            \"test_collect_parametrized_order.py::test_param[0]\",\n            \"test_collect_parametrized_order.py::test_param[1]\",\n            \"test_collect_parametrized_order.py::test_param[2]\",\n        ]\n\n\nclass Test_getinitialnodes:\n    def test_global_file(self, pytester: Pytester) -> None:\n        tmp_path = pytester.path\n        x = ensure_file(tmp_path / \"x.py\")\n        config = pytester.parseconfigure(x)\n        col = pytester.getnode(config, x)\n        assert isinstance(col, pytest.Module)\n        assert col.name == \"x.py\"\n        assert col.parent is not None\n        assert col.parent.parent is not None\n        assert col.parent.parent.parent is None\n        for parent in col.listchain():\n            assert parent.config is config\n\n    def test_pkgfile(self, pytester: Pytester, monkeypatch: MonkeyPatch) -> None:\n        \"\"\"Verify nesting when a module is within a package.\n        The parent chain should match: Module<x.py> -> Package<subdir> -> Session.\n            Session's parent should always be None.\n        \"\"\"\n        tmp_path = pytester.path\n        subdir = tmp_path.joinpath(\"subdir\")\n        x = ensure_file(subdir / \"x.py\")\n        ensure_file(subdir / \"__init__.py\")\n        with monkeypatc"}, {"start_line": 28000, "end_line": 30000, "belongs_to": {"file_name": "test_collection.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "r numj, j in enumerate(items):\n                if numj != numi:\n                    assert hash(i) != hash(j)\n                    assert i != j\n\n    def test_example_items1(self, pytester: Pytester) -> None:\n        p = pytester.makepyfile(\n            \"\"\"\n            import pytest\n\n            def testone():\n                pass\n\n            class TestX(object):\n                def testmethod_one(self):\n                    pass\n\n            class TestY(TestX):\n                @pytest.mark.parametrize(\"arg0\", [\".[\"])\n                def testmethod_two(self, arg0):\n                    pass\n        \"\"\"\n        )\n        items, reprec = pytester.inline_genitems(p)\n        assert len(items) == 4\n        assert items[0].name == \"testone\"\n        assert items[1].name == \"testmethod_one\"\n        assert items[2].name == \"testmethod_one\"\n        assert items[3].name == \"testmethod_two[.[]\"\n\n        # let's also test getmodpath here\n        assert items[0].getmodpath() == \"testone\"  # type: ignore[attr-defined]\n        assert items[1].getmodpath() == \"TestX.testmethod_one\"  # type: ignore[attr-defined]\n        assert items[2].getmodpath() == \"TestY.testmethod_one\"  # type: ignore[attr-defined]\n        # PR #6202: Fix incorrect result of getmodpath method. (Resolves issue #6189)\n        assert items[3].getmodpath() == \"TestY.testmethod_two[.[]\"  # type: ignore[attr-defined]\n\n        s = items[0].getmodpath(stopatmodule=False)  # type: ignore[attr-defined]\n        assert s.endswith(\"test_example_items1.testone\")\n        print(s)\n\n    def test_classmethod_is_discovered(self, pytester: Pytester) -> None:\n        \"\"\"Test that classmethods are discovered\"\"\"\n        p = pytester.makepyfile(\n            \"\"\"\n            class TestCase:\n                @classmethod\n                def test_classmethod(cls) -> None:\n                    pass\n            \"\"\"\n        )\n        items, reprec = pytester.inline_genitems(p)\n        ids = [x.getmodpath() for x in items]  # type: ignore[attr-def"}, {"start_line": 6000, "end_line": 8000, "belongs_to": {"file_name": "doctest.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "    if self.continue_on_failure:\n                out.append(failure)\n            else:\n                raise failure\n\n        def report_unexpected_exception(\n            self,\n            out,\n            test: doctest.DocTest,\n            example: doctest.Example,\n            exc_info: tuple[type[BaseException], BaseException, types.TracebackType],\n        ) -> None:\n            if isinstance(exc_info[1], OutcomeException):\n                raise exc_info[1]\n            if isinstance(exc_info[1], bdb.BdbQuit):\n                outcomes.exit(\"Quitting debugger\")\n            failure = doctest.UnexpectedException(test, example, exc_info)\n            if self.continue_on_failure:\n                out.append(failure)\n            else:\n                raise failure\n\n    return PytestDoctestRunner\n\n\ndef _get_runner(\n    checker: doctest.OutputChecker | None = None,\n    verbose: bool | None = None,\n    optionflags: int = 0,\n    continue_on_failure: bool = True,\n) -> doctest.DocTestRunner:\n    # We need this in order to do a lazy import on doctest\n    global RUNNER_CLASS\n    if RUNNER_CLASS is None:\n        RUNNER_CLASS = _init_runner_class()\n    # Type ignored because the continue_on_failure argument is only defined on\n    # PytestDoctestRunner, which is lazily defined so can't be used as a type.\n    return RUNNER_CLASS(  # type: ignore\n        checker=checker,\n        verbose=verbose,\n        optionflags=optionflags,\n        continue_on_failure=continue_on_failure,\n    )\n\n\nclass DoctestItem(Item):\n    def __init__(\n        self,\n        name: str,\n        parent: DoctestTextfile | DoctestModule,\n        runner: doctest.DocTestRunner,\n        dtest: doctest.DocTest,\n    ) -> None:\n        super().__init__(name, parent)\n        self.runner = runner\n        self.dtest = dtest\n\n        # Stuff needed for fixture support.\n        self.obj = None\n        fm = self.session._fixturemanager\n        fixtureinfo = fm.getfixtureinfo(node=self, func=None, cls=None)\n        self._fixturei"}, {"start_line": 13000, "end_line": 14074, "belongs_to": {"file_name": "integration.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing/python", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "def test_func(): pass\n\n        class TestIt:\n            def test_method(self): pass\n\n            @classmethod\n            def test_class(cls): pass\n\n            @staticmethod\n            def test_static(): pass\n        \"\"\"\n    )\n    assert len(items) == 4\n\n    assert isinstance(items[0], Function)\n    assert items[0].name == \"test_func\"\n    assert items[0].instance is None\n\n    assert isinstance(items[1], Function)\n    assert items[1].name == \"test_method\"\n    assert items[1].instance is not None\n    assert items[1].instance.__class__.__name__ == \"TestIt\"\n\n    # Even class and static methods get an instance!\n    # This is the instance used for bound fixture methods, which\n    # class/staticmethod tests are perfectly able to request.\n    assert isinstance(items[2], Function)\n    assert items[2].name == \"test_class\"\n    assert items[2].instance is not None\n\n    assert isinstance(items[3], Function)\n    assert items[3].name == \"test_static\"\n    assert items[3].instance is not None\n\n    assert items[1].instance is not items[2].instance is not items[3].instance\n"}], "retrieved_count": 10, "cost_time": 0.3477745056152344}
{"question": "Where does the data flow of marker information propagate from the autouse fixture in test_accessmarker_dynamic through the request object to multiple test functions, and what control flow mechanism ensures that dynamically applied markers via applymarker are visible to all dependent tests in the same scope?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"start_line": 37000, "end_line": 39000, "belongs_to": {"file_name": "fixtures.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing/python", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "  \"\"\"\n        )\n        reprec = pytester.inline_run()\n        reprec.assertoutcome(passed=1)\n\n    def test_accessmarker_dynamic(self, pytester: Pytester) -> None:\n        pytester.makeconftest(\n            \"\"\"\n            import pytest\n            @pytest.fixture()\n            def keywords(request):\n                return request.keywords\n\n            @pytest.fixture(scope=\"class\", autouse=True)\n            def marking(request):\n                request.applymarker(pytest.mark.XYZ(\"hello\"))\n        \"\"\"\n        )\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n            def test_fun1(keywords):\n                assert keywords[\"XYZ\"] is not None\n                assert \"abc\" not in keywords\n            def test_fun2(keywords):\n                assert keywords[\"XYZ\"] is not None\n                assert \"abc\" not in keywords\n        \"\"\"\n        )\n        reprec = pytester.inline_run()\n        reprec.assertoutcome(passed=2)\n\n\nclass TestFixtureUsages:\n    def test_noargfixturedec(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n            @pytest.fixture\n            def arg1():\n                return 1\n\n            def test_func(arg1):\n                assert arg1 == 1\n        \"\"\"\n        )\n        reprec = pytester.inline_run()\n        reprec.assertoutcome(passed=1)\n\n    def test_receives_funcargs(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n            @pytest.fixture()\n            def arg1():\n                return 1\n\n            @pytest.fixture()\n            def arg2(arg1):\n                return arg1 + 1\n\n            def test_add(arg2):\n                assert arg2 == 2\n            def test_all(arg1, arg2):\n                assert arg1 == 1\n                assert arg2 == 2\n        \"\"\"\n        )\n        reprec = pytester.inline_run()\n        reprec.assertoutcome(passed=2)\n\n    def test_receives_funcargs_scope_mismatch(self, pytester"}, {"start_line": 36000, "end_line": 38000, "belongs_to": {"file_name": "fixtures.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing/python", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "_func1(self, something):\n                    pass\n                def test_func2(self, something):\n                    pass\n        \"\"\"\n        )\n        assert isinstance(item1, Function)\n        req1 = TopRequest(item1, _ispytest=True)\n        assert \"xfail\" not in item1.keywords\n        req1.applymarker(pytest.mark.xfail)\n        assert \"xfail\" in item1.keywords\n        assert \"skipif\" not in item1.keywords\n        req1.applymarker(pytest.mark.skipif)\n        assert \"skipif\" in item1.keywords\n        with pytest.raises(ValueError):\n            req1.applymarker(42)  # type: ignore[arg-type]\n\n    def test_accesskeywords(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n            @pytest.fixture()\n            def keywords(request):\n                return request.keywords\n            @pytest.mark.XYZ\n            def test_function(keywords):\n                assert keywords[\"XYZ\"]\n                assert \"abc\" not in keywords\n        \"\"\"\n        )\n        reprec = pytester.inline_run()\n        reprec.assertoutcome(passed=1)\n\n    def test_accessmarker_dynamic(self, pytester: Pytester) -> None:\n        pytester.makeconftest(\n            \"\"\"\n            import pytest\n            @pytest.fixture()\n            def keywords(request):\n                return request.keywords\n\n            @pytest.fixture(scope=\"class\", autouse=True)\n            def marking(request):\n                request.applymarker(pytest.mark.XYZ(\"hello\"))\n        \"\"\"\n        )\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n            def test_fun1(keywords):\n                assert keywords[\"XYZ\"] is not None\n                assert \"abc\" not in keywords\n            def test_fun2(keywords):\n                assert keywords[\"XYZ\"] is not None\n                assert \"abc\" not in keywords\n        \"\"\"\n        )\n        reprec = pytester.inline_run()\n        reprec.assertoutcome(passed=2)\n\n\nclass TestFixtureUsages:\n    def test_noarg"}, {"start_line": 21000, "end_line": 23000, "belongs_to": {"file_name": "test_mark.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "             session.add_marker(10))\n        \"\"\"\n        )\n        pytester.makepyfile(\n            \"\"\"\n            def test_some(request):\n                assert \"mark1\" in request.keywords\n                assert \"mark2\" in request.keywords\n                assert \"mark3\" in request.keywords\n                assert 10 not in request.keywords\n                marker = request.node.get_closest_marker(\"mark1\")\n                assert marker.name == \"mark1\"\n                assert marker.args == ()\n                assert marker.kwargs == {}\n        \"\"\"\n        )\n        reprec = pytester.inline_run(\"-m\", \"mark1\")\n        reprec.assertoutcome(passed=1)\n\n    def assert_markers(self, items, **expected) -> None:\n        \"\"\"Assert that given items have expected marker names applied to them.\n        expected should be a dict of (item name -> seq of expected marker names).\n\n        Note: this could be moved to ``pytester`` if proven to be useful\n        to other modules.\n        \"\"\"\n        items = {x.name: x for x in items}\n        for name, expected_markers in expected.items():\n            markers = {m.name for m in items[name].iter_markers()}\n            assert markers == set(expected_markers)\n\n    @pytest.mark.filterwarnings(\"ignore\")\n    def test_mark_from_parameters(self, pytester: Pytester) -> None:\n        \"\"\"#1540\"\"\"\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n\n            pytestmark = pytest.mark.skipif(True, reason='skip all')\n\n            # skipifs inside fixture params\n            params = [pytest.mark.skipif(False, reason='dont skip')('parameter')]\n\n\n            @pytest.fixture(params=params)\n            def parameter(request):\n                return request.param\n\n\n            def test_1(parameter):\n                assert True\n        \"\"\"\n        )\n        reprec = pytester.inline_run()\n        reprec.assertoutcome(skipped=1)\n\n    def test_reevaluate_dynamic_expr(self, pytester: Pytester) -> None:\n        \"\"\"#7360\"\"\"\n        py_file1 = pyt"}, {"start_line": 35000, "end_line": 37000, "belongs_to": {"file_name": "fixtures.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing/python", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "est, arg):\n                assert not hasattr(request, \"param\")\n            def test_1(arg):\n                assert arg in (1,2)\n        \"\"\"\n        )\n        reprec = pytester.inline_run()\n        reprec.assertoutcome(passed=2)\n\n\nclass TestRequestSessionScoped:\n    @pytest.fixture(scope=\"session\")\n    def session_request(self, request):\n        return request\n\n    @pytest.mark.parametrize(\"name\", [\"path\", \"module\"])\n    def test_session_scoped_unavailable_attributes(self, session_request, name):\n        with pytest.raises(\n            AttributeError,\n            match=f\"{name} not available in session-scoped context\",\n        ):\n            getattr(session_request, name)\n\n\nclass TestRequestMarking:\n    def test_applymarker(self, pytester: Pytester) -> None:\n        item1, item2 = pytester.getitems(\n            \"\"\"\n            import pytest\n\n            @pytest.fixture\n            def something(request):\n                pass\n            class TestClass(object):\n                def test_func1(self, something):\n                    pass\n                def test_func2(self, something):\n                    pass\n        \"\"\"\n        )\n        assert isinstance(item1, Function)\n        req1 = TopRequest(item1, _ispytest=True)\n        assert \"xfail\" not in item1.keywords\n        req1.applymarker(pytest.mark.xfail)\n        assert \"xfail\" in item1.keywords\n        assert \"skipif\" not in item1.keywords\n        req1.applymarker(pytest.mark.skipif)\n        assert \"skipif\" in item1.keywords\n        with pytest.raises(ValueError):\n            req1.applymarker(42)  # type: ignore[arg-type]\n\n    def test_accesskeywords(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n            @pytest.fixture()\n            def keywords(request):\n                return request.keywords\n            @pytest.mark.XYZ\n            def test_function(keywords):\n                assert keywords[\"XYZ\"]\n                assert \"abc\" not in keywords\n      "}, {"start_line": 17000, "end_line": 19000, "belongs_to": {"file_name": "test_mark.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "        \"\"\"\n        )\n        items, rec = pytester.inline_genitems(p)\n        self.assert_markers(items, test_foo=(\"a\", \"b\", \"c\"), test_bar=(\"a\", \"b\", \"d\"))\n\n    def test_mark_closest(self, pytester: Pytester) -> None:\n        p = pytester.makepyfile(\n            \"\"\"\n            import pytest\n\n            @pytest.mark.c(location=\"class\")\n            class Test:\n                @pytest.mark.c(location=\"function\")\n                def test_has_own(self):\n                    pass\n\n                def test_has_inherited(self):\n                    pass\n\n        \"\"\"\n        )\n        items, rec = pytester.inline_genitems(p)\n        has_own, has_inherited = items\n        has_own_marker = has_own.get_closest_marker(\"c\")\n        has_inherited_marker = has_inherited.get_closest_marker(\"c\")\n        assert has_own_marker is not None\n        assert has_inherited_marker is not None\n        assert has_own_marker.kwargs == {\"location\": \"function\"}\n        assert has_inherited_marker.kwargs == {\"location\": \"class\"}\n        assert has_own.get_closest_marker(\"missing\") is None\n\n    def test_mark_with_wrong_marker(self, pytester: Pytester) -> None:\n        reprec = pytester.inline_runsource(\n            \"\"\"\n                import pytest\n                class pytestmark(object):\n                    pass\n                def test_func():\n                    pass\n        \"\"\"\n        )\n        values = reprec.getfailedcollections()\n        assert len(values) == 1\n        assert \"TypeError\" in str(values[0].longrepr)\n\n    def test_mark_dynamically_in_funcarg(self, pytester: Pytester) -> None:\n        pytester.makeconftest(\n            \"\"\"\n            import pytest\n            @pytest.fixture\n            def arg(request):\n                request.applymarker(pytest.mark.hello)\n            def pytest_terminal_summary(terminalreporter):\n                values = terminalreporter.stats['passed']\n                terminalreporter._tw.line(\"keyword: %s\" % values[0].keywords)\n        \"\"\"\n        )\n   "}, {"start_line": 18000, "end_line": 20000, "belongs_to": {"file_name": "test_mark.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "on\": \"class\"}\n        assert has_own.get_closest_marker(\"missing\") is None\n\n    def test_mark_with_wrong_marker(self, pytester: Pytester) -> None:\n        reprec = pytester.inline_runsource(\n            \"\"\"\n                import pytest\n                class pytestmark(object):\n                    pass\n                def test_func():\n                    pass\n        \"\"\"\n        )\n        values = reprec.getfailedcollections()\n        assert len(values) == 1\n        assert \"TypeError\" in str(values[0].longrepr)\n\n    def test_mark_dynamically_in_funcarg(self, pytester: Pytester) -> None:\n        pytester.makeconftest(\n            \"\"\"\n            import pytest\n            @pytest.fixture\n            def arg(request):\n                request.applymarker(pytest.mark.hello)\n            def pytest_terminal_summary(terminalreporter):\n                values = terminalreporter.stats['passed']\n                terminalreporter._tw.line(\"keyword: %s\" % values[0].keywords)\n        \"\"\"\n        )\n        pytester.makepyfile(\n            \"\"\"\n            def test_func(arg):\n                pass\n        \"\"\"\n        )\n        result = pytester.runpytest()\n        result.stdout.fnmatch_lines([\"keyword: *hello*\"])\n\n    def test_no_marker_match_on_unmarked_names(self, pytester: Pytester) -> None:\n        p = pytester.makepyfile(\n            \"\"\"\n            import pytest\n            @pytest.mark.shouldmatch\n            def test_marked():\n                assert 1\n\n            def test_unmarked():\n                assert 1\n        \"\"\"\n        )\n        reprec = pytester.inline_run(\"-m\", \"test_unmarked\", p)\n        passed, skipped, failed = reprec.listoutcomes()\n        assert len(passed) + len(skipped) + len(failed) == 0\n        dlist = reprec.getcalls(\"pytest_deselected\")\n        deselected_tests = dlist[0].items\n        assert len(deselected_tests) == 2\n\n    def test_keywords_at_node_level(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            import py"}, {"start_line": 16000, "end_line": 18000, "belongs_to": {"file_name": "test_skipping.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "r: Pytester) -> None:\n        p = pytester.makepyfile(\n            \"\"\"\n            import pytest\n            def setup_function(function):\n                pytest.mark.xfail(function)\n            def test_this():\n                assert 0\n            def test_that():\n                assert 1\n        \"\"\"\n        )\n        result = pytester.runpytest(p, \"-rxX\")\n        result.stdout.fnmatch_lines([\"*XFAIL*test_this*\", \"*XPASS*test_that*\"])\n\n    def test_dynamic_xfail_no_run(self, pytester: Pytester) -> None:\n        p = pytester.makepyfile(\n            \"\"\"\n            import pytest\n            @pytest.fixture\n            def arg(request):\n                request.applymarker(pytest.mark.xfail(run=False))\n            def test_this(arg):\n                assert 0\n        \"\"\"\n        )\n        result = pytester.runpytest(p, \"-rxX\")\n        result.stdout.fnmatch_lines([\"*XFAIL*test_this*NOTRUN*\"])\n\n    def test_dynamic_xfail_set_during_funcarg_setup(self, pytester: Pytester) -> None:\n        p = pytester.makepyfile(\n            \"\"\"\n            import pytest\n            @pytest.fixture\n            def arg(request):\n                request.applymarker(pytest.mark.xfail)\n            def test_this2(arg):\n                assert 0\n        \"\"\"\n        )\n        result = pytester.runpytest(p)\n        result.stdout.fnmatch_lines([\"*1 xfailed*\"])\n\n    def test_dynamic_xfail_set_during_runtest_failed(self, pytester: Pytester) -> None:\n        # Issue #7486.\n        p = pytester.makepyfile(\n            \"\"\"\n            import pytest\n            def test_this(request):\n                request.node.add_marker(pytest.mark.xfail(reason=\"xfail\"))\n                assert 0\n        \"\"\"\n        )\n        result = pytester.runpytest(p)\n        result.assert_outcomes(xfailed=1)\n\n    def test_dynamic_xfail_set_during_runtest_passed_strict(\n        self, pytester: Pytester\n    ) -> None:\n        # Issue #7486.\n        p = pytester.makepyfile(\n            \"\"\"\n            import pytest\n            def t"}, {"start_line": 20000, "end_line": 22000, "belongs_to": {"file_name": "test_mark.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "test\n            @pytest.fixture(scope=\"session\", autouse=True)\n            def some(request):\n                request.keywords[\"hello\"] = 42\n                assert \"world\" not in request.keywords\n\n            @pytest.fixture(scope=\"function\", autouse=True)\n            def funcsetup(request):\n                assert \"world\" in request.keywords\n                assert \"hello\" in  request.keywords\n\n            @pytest.mark.world\n            def test_function():\n                pass\n        \"\"\"\n        )\n        reprec = pytester.inline_run()\n        reprec.assertoutcome(passed=1)\n\n    def test_keyword_added_for_session(self, pytester: Pytester) -> None:\n        pytester.makeconftest(\n            \"\"\"\n            import pytest\n            def pytest_collection_modifyitems(session):\n                session.add_marker(\"mark1\")\n                session.add_marker(pytest.mark.mark2)\n                session.add_marker(pytest.mark.mark3)\n                pytest.raises(ValueError, lambda:\n                        session.add_marker(10))\n        \"\"\"\n        )\n        pytester.makepyfile(\n            \"\"\"\n            def test_some(request):\n                assert \"mark1\" in request.keywords\n                assert \"mark2\" in request.keywords\n                assert \"mark3\" in request.keywords\n                assert 10 not in request.keywords\n                marker = request.node.get_closest_marker(\"mark1\")\n                assert marker.name == \"mark1\"\n                assert marker.args == ()\n                assert marker.kwargs == {}\n        \"\"\"\n        )\n        reprec = pytester.inline_run(\"-m\", \"mark1\")\n        reprec.assertoutcome(passed=1)\n\n    def assert_markers(self, items, **expected) -> None:\n        \"\"\"Assert that given items have expected marker names applied to them.\n        expected should be a dict of (item name -> seq of expected marker names).\n\n        Note: this could be moved to ``pytester`` if proven to be useful\n        to other modules.\n        \"\"\"\n        items = {"}, {"start_line": 83000, "end_line": 85000, "belongs_to": {"file_name": "fixtures.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing/python", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "(calls)\n\n        \"\"\"\n        )\n\n        pytester.makepyfile(\n            \"\"\"\n            def test_first(dynamic_fixture):\n                assert dynamic_fixture == 1\n\n\n            def test_second(dynamic_fixture):\n                assert dynamic_fixture == 2\n\n        \"\"\"\n        )\n\n        reprec = pytester.inline_run()\n        reprec.assertoutcome(passed=2)\n\n        reprec = pytester.inline_run(\"--extend-scope\")\n        reprec.assertoutcome(passed=1, failed=1)\n\n    def test_dynamic_scope_bad_return(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n\n            def dynamic_scope(**_):\n                return \"wrong-scope\"\n\n            @pytest.fixture(scope=dynamic_scope)\n            def fixture():\n                pass\n\n        \"\"\"\n        )\n        result = pytester.runpytest()\n        result.stdout.fnmatch_lines(\n            \"Fixture 'fixture' from test_dynamic_scope_bad_return.py \"\n            \"got an unexpected scope value 'wrong-scope'\"\n        )\n\n    def test_register_only_with_mark(self, pytester: Pytester) -> None:\n        pytester.makeconftest(\n            \"\"\"\n            import pytest\n            @pytest.fixture()\n            def arg():\n                return 1\n        \"\"\"\n        )\n        pytester.makepyfile(\n            test_mod1=\"\"\"\n                import pytest\n                @pytest.fixture()\n                def arg(arg):\n                    return arg + 1\n                def test_1(arg):\n                    assert arg == 2\n            \"\"\"\n        )\n        reprec = pytester.inline_run()\n        reprec.assertoutcome(passed=1)\n\n    def test_parametrize_and_scope(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n            @pytest.fixture(scope=\"module\", params=[\"a\", \"b\", \"c\"])\n            def arg(request):\n                return request.param\n            values = []\n            def test_param(arg):\n                values.append(arg)\n        \""}, {"start_line": 34000, "end_line": 36000, "belongs_to": {"file_name": "fixtures.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing/python", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "d*conftest*\n            *arg1*\n        \"\"\"\n        )\n\n    def test_show_fixtures_color_yes(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\"def test_this(): assert 1\")\n        result = pytester.runpytest(\"--color=yes\", \"--fixtures\")\n        assert \"\\x1b[32mtmp_path\" in result.stdout.str()\n\n    def test_newstyle_with_request(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n            @pytest.fixture()\n            def arg(request):\n                pass\n            def test_1(arg):\n                pass\n        \"\"\"\n        )\n        reprec = pytester.inline_run()\n        reprec.assertoutcome(passed=1)\n\n    def test_setupcontext_no_param(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n            @pytest.fixture(params=[1,2])\n            def arg(request):\n                return request.param\n\n            @pytest.fixture(autouse=True)\n            def mysetup(request, arg):\n                assert not hasattr(request, \"param\")\n            def test_1(arg):\n                assert arg in (1,2)\n        \"\"\"\n        )\n        reprec = pytester.inline_run()\n        reprec.assertoutcome(passed=2)\n\n\nclass TestRequestSessionScoped:\n    @pytest.fixture(scope=\"session\")\n    def session_request(self, request):\n        return request\n\n    @pytest.mark.parametrize(\"name\", [\"path\", \"module\"])\n    def test_session_scoped_unavailable_attributes(self, session_request, name):\n        with pytest.raises(\n            AttributeError,\n            match=f\"{name} not available in session-scoped context\",\n        ):\n            getattr(session_request, name)\n\n\nclass TestRequestMarking:\n    def test_applymarker(self, pytester: Pytester) -> None:\n        item1, item2 = pytester.getitems(\n            \"\"\"\n            import pytest\n\n            @pytest.fixture\n            def something(request):\n                pass\n            class TestClass(object):\n                def test"}], "retrieved_count": 10, "cost_time": 0.34760046005249023}
{"question": "Where does the data flow from `_early_rewrite_bailout` through `_basenames_to_check_rewrite` state mutation determine whether `find_spec` will invoke expensive filesystem operations?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"start_line": 6000, "end_line": 8000, "belongs_to": {"file_name": "rewrite.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest/assertion", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "  cache_name = fn.name[:-3] + PYC_TAIL\n        pyc = cache_dir / cache_name\n        # Notice that even if we're in a read-only directory, I'm going\n        # to check for a cached pyc. This may not be optimal...\n        co = _read_pyc(fn, pyc, state.trace)\n        if co is None:\n            state.trace(f\"rewriting {fn!r}\")\n            source_stat, co = _rewrite_test(fn, self.config)\n            if write:\n                self._writing_pyc = True\n                try:\n                    _write_pyc(state, co, source_stat, pyc)\n                finally:\n                    self._writing_pyc = False\n        else:\n            state.trace(f\"found cached rewritten pyc for {fn}\")\n        exec(co, module.__dict__)\n\n    def _early_rewrite_bailout(self, name: str, state: AssertionState) -> bool:\n        \"\"\"A fast way to get out of rewriting modules.\n\n        Profiling has shown that the call to PathFinder.find_spec (inside of\n        the find_spec from this class) is a major slowdown, so, this method\n        tries to filter what we're sure won't be rewritten before getting to\n        it.\n        \"\"\"\n        if self.session is not None and not self._session_paths_checked:\n            self._session_paths_checked = True\n            for initial_path in self.session._initialpaths:\n                # Make something as c:/projects/my_project/path.py ->\n                #     ['c:', 'projects', 'my_project', 'path.py']\n                parts = str(initial_path).split(os.sep)\n                # add 'path' to basenames to be checked.\n                self._basenames_to_check_rewrite.add(os.path.splitext(parts[-1])[0])\n\n        # Note: conftest already by default in _basenames_to_check_rewrite.\n        parts = name.split(\".\")\n        if parts[-1] in self._basenames_to_check_rewrite:\n            return False\n\n        # For matching the name it must be as if it was a filename.\n        path = PurePath(*parts).with_suffix(\".py\")\n\n        for pat in self.fnpats:\n            # if the pattern contains"}, {"start_line": 5000, "end_line": 7000, "belongs_to": {"file_name": "rewrite.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest/assertion", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": " = Path(module.__spec__.origin)\n        state = self.config.stash[assertstate_key]\n\n        self._rewritten_names[module.__name__] = fn\n\n        # The requested module looks like a test file, so rewrite it. This is\n        # the most magical part of the process: load the source, rewrite the\n        # asserts, and load the rewritten source. We also cache the rewritten\n        # module code in a special pyc. We must be aware of the possibility of\n        # concurrent pytest processes rewriting and loading pycs. To avoid\n        # tricky race conditions, we maintain the following invariant: The\n        # cached pyc is always a complete, valid pyc. Operations on it must be\n        # atomic. POSIX's atomic rename comes in handy.\n        write = not sys.dont_write_bytecode\n        cache_dir = get_cache_dir(fn)\n        if write:\n            ok = try_makedirs(cache_dir)\n            if not ok:\n                write = False\n                state.trace(f\"read only directory: {cache_dir}\")\n\n        cache_name = fn.name[:-3] + PYC_TAIL\n        pyc = cache_dir / cache_name\n        # Notice that even if we're in a read-only directory, I'm going\n        # to check for a cached pyc. This may not be optimal...\n        co = _read_pyc(fn, pyc, state.trace)\n        if co is None:\n            state.trace(f\"rewriting {fn!r}\")\n            source_stat, co = _rewrite_test(fn, self.config)\n            if write:\n                self._writing_pyc = True\n                try:\n                    _write_pyc(state, co, source_stat, pyc)\n                finally:\n                    self._writing_pyc = False\n        else:\n            state.trace(f\"found cached rewritten pyc for {fn}\")\n        exec(co, module.__dict__)\n\n    def _early_rewrite_bailout(self, name: str, state: AssertionState) -> bool:\n        \"\"\"A fast way to get out of rewriting modules.\n\n        Profiling has shown that the call to PathFinder.find_spec (inside of\n        the find_spec from this class) is a major slowdown, so, this meth"}, {"start_line": 2000, "end_line": 4000, "belongs_to": {"file_name": "rewrite.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest/assertion", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "\n        self.session: Session | None = None\n        self._rewritten_names: dict[str, Path] = {}\n        self._must_rewrite: set[str] = set()\n        # flag to guard against trying to rewrite a pyc file while we are already writing another pyc file,\n        # which might result in infinite recursion (#3506)\n        self._writing_pyc = False\n        self._basenames_to_check_rewrite = {\"conftest\"}\n        self._marked_for_rewrite_cache: dict[str, bool] = {}\n        self._session_paths_checked = False\n\n    def set_session(self, session: Session | None) -> None:\n        self.session = session\n        self._session_paths_checked = False\n\n    # Indirection so we can mock calls to find_spec originated from the hook during testing\n    _find_spec = importlib.machinery.PathFinder.find_spec\n\n    def find_spec(\n        self,\n        name: str,\n        path: Sequence[str | bytes] | None = None,\n        target: types.ModuleType | None = None,\n    ) -> importlib.machinery.ModuleSpec | None:\n        if self._writing_pyc:\n            return None\n        state = self.config.stash[assertstate_key]\n        if self._early_rewrite_bailout(name, state):\n            return None\n        state.trace(f\"find_module called for: {name}\")\n\n        # Type ignored because mypy is confused about the `self` binding here.\n        spec = self._find_spec(name, path)  # type: ignore\n\n        if spec is None and path is not None:\n            # With --import-mode=importlib, PathFinder cannot find spec without modifying `sys.path`,\n            # causing inability to assert rewriting (#12659).\n            # At this point, try using the file path to find the module spec.\n            for _path_str in path:\n                spec = importlib.util.spec_from_file_location(name, _path_str)\n                if spec is not None:\n                    break\n\n        if (\n            # the import machinery could not find a file to import\n            spec is None\n            # this is a namespace package (without `__init__."}, {"start_line": 58000, "end_line": 60000, "belongs_to": {"file_name": "test_assertrewrite.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "fig)\n    spec = hook.find_spec(\"test_foo\")\n    assert spec is not None\n    module = importlib.util.module_from_spec(spec)\n    hook.exec_module(module)\n    assert len(write_pyc_called) == 1\n\n\nclass TestEarlyRewriteBailout:\n    @pytest.fixture\n    def hook(\n        self, pytestconfig, monkeypatch, pytester: Pytester\n    ) -> Generator[AssertionRewritingHook]:\n        \"\"\"Returns a patched AssertionRewritingHook instance so we can configure its initial paths and track\n        if PathFinder.find_spec has been called.\n        \"\"\"\n        import importlib.machinery\n\n        self.find_spec_calls: list[str] = []\n        self.initial_paths: set[Path] = set()\n\n        class StubSession:\n            _initialpaths = self.initial_paths\n\n            def isinitpath(self, p):\n                return p in self._initialpaths\n\n        def spy_find_spec(name, path):\n            self.find_spec_calls.append(name)\n            return importlib.machinery.PathFinder.find_spec(name, path)\n\n        hook = AssertionRewritingHook(pytestconfig)\n        # use default patterns, otherwise we inherit pytest's testing config\n        with mock.patch.object(hook, \"fnpats\", [\"test_*.py\", \"*_test.py\"]):\n            monkeypatch.setattr(hook, \"_find_spec\", spy_find_spec)\n            hook.set_session(StubSession())  # type: ignore[arg-type]\n            pytester.syspathinsert()\n            yield hook\n\n    def test_basic(self, pytester: Pytester, hook: AssertionRewritingHook) -> None:\n        \"\"\"\n        Ensure we avoid calling PathFinder.find_spec when we know for sure a certain\n        module will not be rewritten to optimize assertion rewriting (#3918).\n        \"\"\"\n        pytester.makeconftest(\n            \"\"\"\n            import pytest\n            @pytest.fixture\n            def fix(): return 1\n        \"\"\"\n        )\n        pytester.makepyfile(test_foo=\"def test_foo(): pass\")\n        pytester.makepyfile(bar=\"def bar(): pass\")\n        foobar_path = pytester.makepyfile(foobar=\"def foobar(): pass\")\n        self"}, {"start_line": 3000, "end_line": 5000, "belongs_to": {"file_name": "rewrite.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest/assertion", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "f self._writing_pyc:\n            return None\n        state = self.config.stash[assertstate_key]\n        if self._early_rewrite_bailout(name, state):\n            return None\n        state.trace(f\"find_module called for: {name}\")\n\n        # Type ignored because mypy is confused about the `self` binding here.\n        spec = self._find_spec(name, path)  # type: ignore\n\n        if spec is None and path is not None:\n            # With --import-mode=importlib, PathFinder cannot find spec without modifying `sys.path`,\n            # causing inability to assert rewriting (#12659).\n            # At this point, try using the file path to find the module spec.\n            for _path_str in path:\n                spec = importlib.util.spec_from_file_location(name, _path_str)\n                if spec is not None:\n                    break\n\n        if (\n            # the import machinery could not find a file to import\n            spec is None\n            # this is a namespace package (without `__init__.py`)\n            # there's nothing to rewrite there\n            or spec.origin is None\n            # we can only rewrite source files\n            or not isinstance(spec.loader, importlib.machinery.SourceFileLoader)\n            # if the file doesn't exist, we can't rewrite it\n            or not os.path.exists(spec.origin)\n        ):\n            return None\n        else:\n            fn = spec.origin\n\n        if not self._should_rewrite(name, fn, state):\n            return None\n\n        return importlib.util.spec_from_file_location(\n            name,\n            fn,\n            loader=self,\n            submodule_search_locations=spec.submodule_search_locations,\n        )\n\n    def create_module(\n        self, spec: importlib.machinery.ModuleSpec\n    ) -> types.ModuleType | None:\n        return None  # default behaviour is fine\n\n    def exec_module(self, module: types.ModuleType) -> None:\n        assert module.__spec__ is not None\n        assert module.__spec__.origin is not None\n        fn"}, {"start_line": 7000, "end_line": 9000, "belongs_to": {"file_name": "rewrite.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest/assertion", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "od\n        tries to filter what we're sure won't be rewritten before getting to\n        it.\n        \"\"\"\n        if self.session is not None and not self._session_paths_checked:\n            self._session_paths_checked = True\n            for initial_path in self.session._initialpaths:\n                # Make something as c:/projects/my_project/path.py ->\n                #     ['c:', 'projects', 'my_project', 'path.py']\n                parts = str(initial_path).split(os.sep)\n                # add 'path' to basenames to be checked.\n                self._basenames_to_check_rewrite.add(os.path.splitext(parts[-1])[0])\n\n        # Note: conftest already by default in _basenames_to_check_rewrite.\n        parts = name.split(\".\")\n        if parts[-1] in self._basenames_to_check_rewrite:\n            return False\n\n        # For matching the name it must be as if it was a filename.\n        path = PurePath(*parts).with_suffix(\".py\")\n\n        for pat in self.fnpats:\n            # if the pattern contains subdirectories (\"tests/**.py\" for example) we can't bail out based\n            # on the name alone because we need to match against the full path\n            if os.path.dirname(pat):\n                return False\n            if fnmatch_ex(pat, path):\n                return False\n\n        if self._is_marked_for_rewrite(name, state):\n            return False\n\n        state.trace(f\"early skip of rewriting module: {name}\")\n        return True\n\n    def _should_rewrite(self, name: str, fn: str, state: AssertionState) -> bool:\n        # always rewrite conftest files\n        if os.path.basename(fn) == \"conftest.py\":\n            state.trace(f\"rewriting conftest file: {fn!r}\")\n            return True\n\n        if self.session is not None:\n            if self.session.isinitpath(absolutepath(fn)):\n                state.trace(f\"matched test file (was specified on cmdline): {fn!r}\")\n                return True\n\n        # modules not passed explicitly on the command line are only\n        # rewritten i"}, {"start_line": 57000, "end_line": 59000, "belongs_to": {"file_name": "test_assertrewrite.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": " writing pyc files: if an import happens to be triggered when writing the pyc\n    file, this would cause another call to the hook, which would trigger another pyc writing, which could\n    trigger another import, and so on. (#3506)\"\"\"\n    from _pytest.assertion import rewrite as rewritemod\n\n    pytester.syspathinsert()\n    pytester.makepyfile(test_foo=\"def test_foo(): pass\")\n    pytester.makepyfile(test_bar=\"def test_bar(): pass\")\n\n    original_write_pyc = rewritemod._write_pyc\n\n    write_pyc_called = []\n\n    def spy_write_pyc(*args, **kwargs):\n        # make a note that we have called _write_pyc\n        write_pyc_called.append(True)\n        # try to import a module at this point: we should not try to rewrite this module\n        assert hook.find_spec(\"test_bar\") is None\n        return original_write_pyc(*args, **kwargs)\n\n    monkeypatch.setattr(rewritemod, \"_write_pyc\", spy_write_pyc)\n    monkeypatch.setattr(sys, \"dont_write_bytecode\", False)\n\n    hook = AssertionRewritingHook(pytestconfig)\n    spec = hook.find_spec(\"test_foo\")\n    assert spec is not None\n    module = importlib.util.module_from_spec(spec)\n    hook.exec_module(module)\n    assert len(write_pyc_called) == 1\n\n\nclass TestEarlyRewriteBailout:\n    @pytest.fixture\n    def hook(\n        self, pytestconfig, monkeypatch, pytester: Pytester\n    ) -> Generator[AssertionRewritingHook]:\n        \"\"\"Returns a patched AssertionRewritingHook instance so we can configure its initial paths and track\n        if PathFinder.find_spec has been called.\n        \"\"\"\n        import importlib.machinery\n\n        self.find_spec_calls: list[str] = []\n        self.initial_paths: set[Path] = set()\n\n        class StubSession:\n            _initialpaths = self.initial_paths\n\n            def isinitpath(self, p):\n                return p in self._initialpaths\n\n        def spy_find_spec(name, path):\n            self.find_spec_calls.append(name)\n            return importlib.machinery.PathFinder.find_spec(name, path)\n\n        hook = Assertion"}, {"start_line": 59000, "end_line": 61000, "belongs_to": {"file_name": "test_assertrewrite.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "RewritingHook(pytestconfig)\n        # use default patterns, otherwise we inherit pytest's testing config\n        with mock.patch.object(hook, \"fnpats\", [\"test_*.py\", \"*_test.py\"]):\n            monkeypatch.setattr(hook, \"_find_spec\", spy_find_spec)\n            hook.set_session(StubSession())  # type: ignore[arg-type]\n            pytester.syspathinsert()\n            yield hook\n\n    def test_basic(self, pytester: Pytester, hook: AssertionRewritingHook) -> None:\n        \"\"\"\n        Ensure we avoid calling PathFinder.find_spec when we know for sure a certain\n        module will not be rewritten to optimize assertion rewriting (#3918).\n        \"\"\"\n        pytester.makeconftest(\n            \"\"\"\n            import pytest\n            @pytest.fixture\n            def fix(): return 1\n        \"\"\"\n        )\n        pytester.makepyfile(test_foo=\"def test_foo(): pass\")\n        pytester.makepyfile(bar=\"def bar(): pass\")\n        foobar_path = pytester.makepyfile(foobar=\"def foobar(): pass\")\n        self.initial_paths.add(foobar_path)\n\n        # conftest files should always be rewritten\n        assert hook.find_spec(\"conftest\") is not None\n        assert self.find_spec_calls == [\"conftest\"]\n\n        # files matching \"python_files\" mask should always be rewritten\n        assert hook.find_spec(\"test_foo\") is not None\n        assert self.find_spec_calls == [\"conftest\", \"test_foo\"]\n\n        # file does not match \"python_files\": early bailout\n        assert hook.find_spec(\"bar\") is None\n        assert self.find_spec_calls == [\"conftest\", \"test_foo\"]\n\n        # file is an initial path (passed on the command-line): should be rewritten\n        assert hook.find_spec(\"foobar\") is not None\n        assert self.find_spec_calls == [\"conftest\", \"test_foo\", \"foobar\"]\n\n    def test_pattern_contains_subdirectories(\n        self, pytester: Pytester, hook: AssertionRewritingHook\n    ) -> None:\n        \"\"\"If one of the python_files patterns contain subdirectories (\"tests/**.py\") we can't bailout early\n   "}, {"start_line": 60000, "end_line": 62000, "belongs_to": {"file_name": "test_assertrewrite.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": ".initial_paths.add(foobar_path)\n\n        # conftest files should always be rewritten\n        assert hook.find_spec(\"conftest\") is not None\n        assert self.find_spec_calls == [\"conftest\"]\n\n        # files matching \"python_files\" mask should always be rewritten\n        assert hook.find_spec(\"test_foo\") is not None\n        assert self.find_spec_calls == [\"conftest\", \"test_foo\"]\n\n        # file does not match \"python_files\": early bailout\n        assert hook.find_spec(\"bar\") is None\n        assert self.find_spec_calls == [\"conftest\", \"test_foo\"]\n\n        # file is an initial path (passed on the command-line): should be rewritten\n        assert hook.find_spec(\"foobar\") is not None\n        assert self.find_spec_calls == [\"conftest\", \"test_foo\", \"foobar\"]\n\n    def test_pattern_contains_subdirectories(\n        self, pytester: Pytester, hook: AssertionRewritingHook\n    ) -> None:\n        \"\"\"If one of the python_files patterns contain subdirectories (\"tests/**.py\") we can't bailout early\n        because we need to match with the full path, which can only be found by calling PathFinder.find_spec\n        \"\"\"\n        pytester.makepyfile(\n            **{\n                \"tests/file.py\": \"\"\"\\\n                    def test_simple_failure():\n                        assert 1 + 1 == 3\n                \"\"\"\n            }\n        )\n        pytester.syspathinsert(\"tests\")\n        with mock.patch.object(hook, \"fnpats\", [\"tests/**.py\"]):\n            assert hook.find_spec(\"file\") is not None\n            assert self.find_spec_calls == [\"file\"]\n\n    @pytest.mark.skipif(\n        sys.platform.startswith(\"win32\"), reason=\"cannot remove cwd on Windows\"\n    )\n    @pytest.mark.skipif(\n        sys.platform.startswith(\"sunos5\"), reason=\"cannot remove cwd on Solaris\"\n    )\n    def test_cwd_changed(self, pytester: Pytester, monkeypatch) -> None:\n        # Setup conditions for py's fspath trying to import pathlib on py34\n        # always (previously triggered via xdist only).\n        # Ref: https://git"}, {"start_line": 8000, "end_line": 10000, "belongs_to": {"file_name": "rewrite.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest/assertion", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": " subdirectories (\"tests/**.py\" for example) we can't bail out based\n            # on the name alone because we need to match against the full path\n            if os.path.dirname(pat):\n                return False\n            if fnmatch_ex(pat, path):\n                return False\n\n        if self._is_marked_for_rewrite(name, state):\n            return False\n\n        state.trace(f\"early skip of rewriting module: {name}\")\n        return True\n\n    def _should_rewrite(self, name: str, fn: str, state: AssertionState) -> bool:\n        # always rewrite conftest files\n        if os.path.basename(fn) == \"conftest.py\":\n            state.trace(f\"rewriting conftest file: {fn!r}\")\n            return True\n\n        if self.session is not None:\n            if self.session.isinitpath(absolutepath(fn)):\n                state.trace(f\"matched test file (was specified on cmdline): {fn!r}\")\n                return True\n\n        # modules not passed explicitly on the command line are only\n        # rewritten if they match the naming convention for test files\n        fn_path = PurePath(fn)\n        for pat in self.fnpats:\n            if fnmatch_ex(pat, fn_path):\n                state.trace(f\"matched test file {fn!r}\")\n                return True\n\n        return self._is_marked_for_rewrite(name, state)\n\n    def _is_marked_for_rewrite(self, name: str, state: AssertionState) -> bool:\n        try:\n            return self._marked_for_rewrite_cache[name]\n        except KeyError:\n            for marked in self._must_rewrite:\n                if name == marked or name.startswith(marked + \".\"):\n                    state.trace(f\"matched marked file {name!r} (from {marked!r})\")\n                    self._marked_for_rewrite_cache[name] = True\n                    return True\n\n            self._marked_for_rewrite_cache[name] = False\n            return False\n\n    def mark_rewrite(self, *names: str) -> None:\n        \"\"\"Mark import names as needing to be rewritten.\n\n        The named module or package as well a"}], "retrieved_count": 10, "cost_time": 0.3467531204223633}
{"question": "Where in the LocalPath class can I locate the code logic responsible for assigning the absolute path value to the strpath attribute during initialization?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"start_line": 7000, "end_line": 9000, "belongs_to": {"file_name": "path.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest/_py", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "(group):\n    import grp\n\n    if not isinstance(group, int):\n        group = grp.getgrnam(group)[2]  # type:ignore[attr-defined,unused-ignore]\n    return group\n\n\nclass LocalPath:\n    \"\"\"Object oriented interface to os.path and other local filesystem\n    related information.\n    \"\"\"\n\n    class ImportMismatchError(ImportError):\n        \"\"\"raised on pyimport() if there is a mismatch of __file__'s\"\"\"\n\n    sep = os.sep\n\n    def __init__(self, path=None, expanduser=False):\n        \"\"\"Initialize and return a local Path instance.\n\n        Path can be relative to the current directory.\n        If path is None it defaults to the current working directory.\n        If expanduser is True, tilde-expansion is performed.\n        Note that Path instances always carry an absolute path.\n        Note also that passing in a local path object will simply return\n        the exact same path object. Use new() to get a new copy.\n        \"\"\"\n        if path is None:\n            self.strpath = error.checked_call(os.getcwd)\n        else:\n            try:\n                path = os.fspath(path)\n            except TypeError:\n                raise ValueError(\n                    \"can only pass None, Path instances \"\n                    \"or non-empty strings to LocalPath\"\n                )\n            if expanduser:\n                path = os.path.expanduser(path)\n            self.strpath = abspath(path)\n\n    if sys.platform != \"win32\":\n\n        def chown(self, user, group, rec=0):\n            \"\"\"Change ownership to the given user and group.\n            user and group may be specified by a number or\n            by a name.  if rec is True change ownership\n            recursively.\n            \"\"\"\n            uid = getuserid(user)\n            gid = getgroupid(group)\n            if rec:\n                for x in self.visit(rec=lambda x: x.check(link=0)):\n                    if x.check(link=0):\n                        error.checked_call(os.chown, str(x), uid, gid)\n            error.checked_call(os.chown, st"}, {"start_line": 13000, "end_line": 15000, "belongs_to": {"file_name": "path.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest/_py", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "    to the given 'relpath'.\n        \"\"\"\n        if not isinstance(relpath, (str, LocalPath)):\n            raise TypeError(f\"{relpath!r}: not a string or path object\")\n        strrelpath = str(relpath)\n        if strrelpath and strrelpath[-1] != self.sep:\n            strrelpath += self.sep\n        # assert strrelpath[-1] == self.sep\n        # assert strrelpath[-2] != self.sep\n        strself = self.strpath\n        if sys.platform == \"win32\" or getattr(os, \"_name\", None) == \"nt\":\n            if os.path.normcase(strself).startswith(os.path.normcase(strrelpath)):\n                return strself[len(strrelpath) :]\n        elif strself.startswith(strrelpath):\n            return strself[len(strrelpath) :]\n        return \"\"\n\n    def ensure_dir(self, *args):\n        \"\"\"Ensure the path joined with args is a directory.\"\"\"\n        return self.ensure(*args, dir=True)\n\n    def bestrelpath(self, dest):\n        \"\"\"Return a string which is a relative path from self\n        (assumed to be a directory) to dest such that\n        self.join(bestrelpath) == dest and if not such\n        path can be determined return dest.\n        \"\"\"\n        try:\n            if self == dest:\n                return os.curdir\n            base = self.common(dest)\n            if not base:  # can be the case on windows\n                return str(dest)\n            self2base = self.relto(base)\n            reldest = dest.relto(base)\n            if self2base:\n                n = self2base.count(self.sep) + 1\n            else:\n                n = 0\n            lst = [os.pardir] * n\n            if reldest:\n                lst.append(reldest)\n            target = dest.sep.join(lst)\n            return target\n        except AttributeError:\n            return str(dest)\n\n    def exists(self):\n        return self.check()\n\n    def isdir(self):\n        return self.check(dir=1)\n\n    def isfile(self):\n        return self.check(file=1)\n\n    def parts(self, reverse=False):\n        \"\"\"Return a root-first list of all ancestor direc"}, {"start_line": 21000, "end_line": 23000, "belongs_to": {"file_name": "path.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest/_py", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "me)\n        kw.setdefault(\"sep\", self.sep)\n        obj.strpath = normpath(\"{dirname}{sep}{basename}\".format(**kw))\n        return obj\n\n    def _getbyspec(self, spec: str) -> list[str]:\n        \"\"\"See new for what 'spec' can be.\"\"\"\n        res = []\n        parts = self.strpath.split(self.sep)\n\n        args = filter(None, spec.split(\",\"))\n        for name in args:\n            if name == \"drive\":\n                res.append(parts[0])\n            elif name == \"dirname\":\n                res.append(self.sep.join(parts[:-1]))\n            else:\n                basename = parts[-1]\n                if name == \"basename\":\n                    res.append(basename)\n                else:\n                    i = basename.rfind(\".\")\n                    if i == -1:\n                        purebasename, ext = basename, \"\"\n                    else:\n                        purebasename, ext = basename[:i], basename[i:]\n                    if name == \"purebasename\":\n                        res.append(purebasename)\n                    elif name == \"ext\":\n                        res.append(ext)\n                    else:\n                        raise ValueError(f\"invalid part specification {name!r}\")\n        return res\n\n    def dirpath(self, *args, **kwargs):\n        \"\"\"Return the directory path joined with any given path arguments.\"\"\"\n        if not kwargs:\n            path = object.__new__(self.__class__)\n            path.strpath = dirname(self.strpath)\n            if args:\n                path = path.join(*args)\n            return path\n        return self.new(basename=\"\").join(*args, **kwargs)\n\n    def join(self, *args: os.PathLike[str], abs: bool = False) -> LocalPath:\n        \"\"\"Return a new path by appending all 'args' as path\n        components.  if abs=1 is used restart from root if any\n        of the args is an absolute path.\n        \"\"\"\n        sep = self.sep\n        strargs = [os.fspath(arg) for arg in args]\n        strpath = self.strpath\n        if abs:\n            newargs: list["}, {"start_line": 8000, "end_line": 10000, "belongs_to": {"file_name": "path.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest/_py", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "s.getcwd)\n        else:\n            try:\n                path = os.fspath(path)\n            except TypeError:\n                raise ValueError(\n                    \"can only pass None, Path instances \"\n                    \"or non-empty strings to LocalPath\"\n                )\n            if expanduser:\n                path = os.path.expanduser(path)\n            self.strpath = abspath(path)\n\n    if sys.platform != \"win32\":\n\n        def chown(self, user, group, rec=0):\n            \"\"\"Change ownership to the given user and group.\n            user and group may be specified by a number or\n            by a name.  if rec is True change ownership\n            recursively.\n            \"\"\"\n            uid = getuserid(user)\n            gid = getgroupid(group)\n            if rec:\n                for x in self.visit(rec=lambda x: x.check(link=0)):\n                    if x.check(link=0):\n                        error.checked_call(os.chown, str(x), uid, gid)\n            error.checked_call(os.chown, str(self), uid, gid)\n\n        def readlink(self) -> str:\n            \"\"\"Return value of a symbolic link.\"\"\"\n            # https://github.com/python/mypy/issues/12278\n            return error.checked_call(os.readlink, self.strpath)  # type: ignore[arg-type,return-value,unused-ignore]\n\n        def mklinkto(self, oldname):\n            \"\"\"Posix style hard link to another name.\"\"\"\n            error.checked_call(os.link, str(oldname), str(self))\n\n        def mksymlinkto(self, value, absolute=1):\n            \"\"\"Create a symbolic link with the given value (pointing to another name).\"\"\"\n            if absolute:\n                error.checked_call(os.symlink, str(value), self.strpath)\n            else:\n                base = self.common(value)\n                # with posix local paths '/' is always a common base\n                relsource = self.__class__(value).relto(base)\n                reldest = self.relto(base)\n                n = reldest.count(self.sep)\n                target = self.sep.join((\""}, {"start_line": 22000, "end_line": 24000, "belongs_to": {"file_name": "path.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest/_py", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "ename)\n                    elif name == \"ext\":\n                        res.append(ext)\n                    else:\n                        raise ValueError(f\"invalid part specification {name!r}\")\n        return res\n\n    def dirpath(self, *args, **kwargs):\n        \"\"\"Return the directory path joined with any given path arguments.\"\"\"\n        if not kwargs:\n            path = object.__new__(self.__class__)\n            path.strpath = dirname(self.strpath)\n            if args:\n                path = path.join(*args)\n            return path\n        return self.new(basename=\"\").join(*args, **kwargs)\n\n    def join(self, *args: os.PathLike[str], abs: bool = False) -> LocalPath:\n        \"\"\"Return a new path by appending all 'args' as path\n        components.  if abs=1 is used restart from root if any\n        of the args is an absolute path.\n        \"\"\"\n        sep = self.sep\n        strargs = [os.fspath(arg) for arg in args]\n        strpath = self.strpath\n        if abs:\n            newargs: list[str] = []\n            for arg in reversed(strargs):\n                if isabs(arg):\n                    strpath = arg\n                    strargs = newargs\n                    break\n                newargs.insert(0, arg)\n        # special case for when we have e.g. strpath == \"/\"\n        actual_sep = \"\" if strpath.endswith(sep) else sep\n        for arg in strargs:\n            arg = arg.strip(sep)\n            if iswin32:\n                # allow unix style paths even on windows.\n                arg = arg.strip(\"/\")\n                arg = arg.replace(\"/\", sep)\n            strpath = strpath + actual_sep + arg\n            actual_sep = sep\n        obj = object.__new__(self.__class__)\n        obj.strpath = normpath(strpath)\n        return obj\n\n    def open(self, mode=\"r\", ensure=False, encoding=None):\n        \"\"\"Return an opened file with the given mode.\n\n        If ensure is True, create parent directories if needed.\n        \"\"\"\n        if ensure:\n            self.dirpath().ensure(dir=1)\n     "}, {"start_line": 0, "end_line": 2000, "belongs_to": {"file_name": "test_local.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing/_py", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "# mypy: allow-untyped-defs\nfrom __future__ import annotations\n\nimport contextlib\nimport multiprocessing\nimport os\nimport sys\nimport time\nfrom unittest import mock\nimport warnings\n\nfrom py import error\nfrom py.path import local\n\nimport pytest\n\n\n@contextlib.contextmanager\ndef ignore_encoding_warning():\n    with warnings.catch_warnings():\n        if sys.version_info >= (3, 10):\n            warnings.simplefilter(\"ignore\", EncodingWarning)  # noqa: F821\n        yield\n\n\nclass CommonFSTests:\n    def test_constructor_equality(self, path1):\n        p = path1.__class__(path1)\n        assert p == path1\n\n    def test_eq_nonstring(self, path1):\n        p1 = path1.join(\"sampledir\")\n        p2 = path1.join(\"sampledir\")\n        assert p1 == p2\n\n    def test_new_identical(self, path1):\n        assert path1 == path1.new()\n\n    def test_join(self, path1):\n        p = path1.join(\"sampledir\")\n        strp = str(p)\n        assert strp.endswith(\"sampledir\")\n        assert strp.startswith(str(path1))\n\n    def test_join_normalized(self, path1):\n        newpath = path1.join(path1.sep + \"sampledir\")\n        strp = str(newpath)\n        assert strp.endswith(\"sampledir\")\n        assert strp.startswith(str(path1))\n        newpath = path1.join((path1.sep * 2) + \"sampledir\")\n        strp = str(newpath)\n        assert strp.endswith(\"sampledir\")\n        assert strp.startswith(str(path1))\n\n    def test_join_noargs(self, path1):\n        newpath = path1.join()\n        assert path1 == newpath\n\n    def test_add_something(self, path1):\n        p = path1.join(\"sample\")\n        p = p + \"dir\"\n        assert p.check()\n        assert p.exists()\n        assert p.isdir()\n        assert not p.isfile()\n\n    def test_parts(self, path1):\n        newpath = path1.join(\"sampledir\", \"otherfile\")\n        par = newpath.parts()[-3:]\n        assert par == [path1, path1.join(\"sampledir\"), newpath]\n\n        revpar = newpath.parts(reverse=True)[:3]\n        assert revpar == [newpath, path1.join(\"sampledir\"), path1]\n\n    def test"}, {"start_line": 23000, "end_line": 25000, "belongs_to": {"file_name": "path.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest/_py", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "str] = []\n            for arg in reversed(strargs):\n                if isabs(arg):\n                    strpath = arg\n                    strargs = newargs\n                    break\n                newargs.insert(0, arg)\n        # special case for when we have e.g. strpath == \"/\"\n        actual_sep = \"\" if strpath.endswith(sep) else sep\n        for arg in strargs:\n            arg = arg.strip(sep)\n            if iswin32:\n                # allow unix style paths even on windows.\n                arg = arg.strip(\"/\")\n                arg = arg.replace(\"/\", sep)\n            strpath = strpath + actual_sep + arg\n            actual_sep = sep\n        obj = object.__new__(self.__class__)\n        obj.strpath = normpath(strpath)\n        return obj\n\n    def open(self, mode=\"r\", ensure=False, encoding=None):\n        \"\"\"Return an opened file with the given mode.\n\n        If ensure is True, create parent directories if needed.\n        \"\"\"\n        if ensure:\n            self.dirpath().ensure(dir=1)\n        if encoding:\n            return error.checked_call(\n                io.open,\n                self.strpath,\n                mode,\n                encoding=encoding,\n            )\n        return error.checked_call(open, self.strpath, mode)\n\n    def _fastjoin(self, name):\n        child = object.__new__(self.__class__)\n        child.strpath = self.strpath + self.sep + name\n        return child\n\n    def islink(self):\n        return islink(self.strpath)\n\n    def check(self, **kw):\n        \"\"\"Check a path for existence and properties.\n\n        Without arguments, return True if the path exists, otherwise False.\n\n        valid checkers::\n\n            file = 1  # is a file\n            file = 0  # is not a file (may not even exist)\n            dir = 1  # is a dir\n            link = 1  # is a link\n            exists = 1  # exists\n\n        You can specify multiple checker definitions, for example::\n\n            path.check(file=1, link=1)  # a link pointing to a file\n        \"\"\"\n        if not kw"}, {"start_line": 18000, "end_line": 20000, "belongs_to": {"file_name": "test_local.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing/_py", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "ncoding='utf-8')) is {actual} instead of {i}\"\n        )\n        dir_.join(\".lock\").remove(ignore_errors=True)\n    return True\n\n\nclass TestLocalPath(CommonFSTests):\n    def test_join_normpath(self, tmpdir):\n        assert tmpdir.join(\".\") == tmpdir\n        p = tmpdir.join(f\"../{tmpdir.basename}\")\n        assert p == tmpdir\n        p = tmpdir.join(f\"..//{tmpdir.basename}/\")\n        assert p == tmpdir\n\n    @skiponwin32\n    def test_dirpath_abs_no_abs(self, tmpdir):\n        p = tmpdir.join(\"foo\")\n        assert p.dirpath(\"/bar\") == tmpdir.join(\"bar\")\n        assert tmpdir.dirpath(\"/bar\", abs=True) == local(\"/bar\")\n\n    def test_gethash(self, tmpdir):\n        from hashlib import md5\n        from hashlib import sha1 as sha\n\n        fn = tmpdir.join(\"testhashfile\")\n        data = b\"hello\"\n        fn.write(data, mode=\"wb\")\n        assert fn.computehash(\"md5\") == md5(data).hexdigest()\n        assert fn.computehash(\"sha1\") == sha(data).hexdigest()\n        with pytest.raises(ValueError):\n            fn.computehash(\"asdasd\")\n\n    def test_remove_removes_readonly_file(self, tmpdir):\n        readonly_file = tmpdir.join(\"readonly\").ensure()\n        readonly_file.chmod(0)\n        readonly_file.remove()\n        assert not readonly_file.check(exists=1)\n\n    def test_remove_removes_readonly_dir(self, tmpdir):\n        readonly_dir = tmpdir.join(\"readonlydir\").ensure(dir=1)\n        readonly_dir.chmod(int(\"500\", 8))\n        readonly_dir.remove()\n        assert not readonly_dir.check(exists=1)\n\n    def test_remove_removes_dir_and_readonly_file(self, tmpdir):\n        readonly_dir = tmpdir.join(\"readonlydir\").ensure(dir=1)\n        readonly_file = readonly_dir.join(\"readonlyfile\").ensure()\n        readonly_file.chmod(0)\n        readonly_dir.remove()\n        assert not readonly_dir.check(exists=1)\n\n    def test_remove_routes_ignore_errors(self, tmpdir, monkeypatch):\n        lst = []\n        monkeypatch.setattr(\"shutil.rmtree\", lambda *args, **kwargs: lst.append(kwargs))\n        tmpdir.remove("}, {"start_line": 42000, "end_line": 44000, "belongs_to": {"file_name": "test_local.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing/_py", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "\"fiLe\")\n        t2 = path1.join(\"A_path\")\n        assert t1.relto(t2) == \"fiLe\"\n\n    def test_allow_unix_style_paths(self, path1):\n        t1 = path1.join(\"a_path\")\n        assert t1 == str(path1) + \"\\\\a_path\"\n        t1 = path1.join(\"a_path/\")\n        assert t1 == str(path1) + \"\\\\a_path\"\n        t1 = path1.join(\"dir/a_path\")\n        assert t1 == str(path1) + \"\\\\dir\\\\a_path\"\n\n    def test_sysfind_in_currentdir(self, path1):\n        cmd = local.sysfind(\"cmd\")\n        root = cmd.new(dirname=\"\", basename=\"\")  # c:\\ in most installations\n        with root.as_cwd():\n            x = local.sysfind(cmd.relto(root))\n            assert x.check(file=1)\n\n    def test_fnmatch_file_abspath_posix_pattern_on_win32(self, tmpdir):\n        # path-matching patterns might contain a posix path separator '/'\n        # Test that we can match that pattern on windows.\n        import posixpath\n\n        b = tmpdir.join(\"a\", \"b\")\n        assert b.fnmatch(posixpath.sep.join(\"ab\"))\n        pattern = posixpath.sep.join([str(tmpdir), \"*\", \"b\"])\n        assert b.fnmatch(pattern)\n\n\nclass TestPOSIXLocalPath:\n    pytestmark = skiponwin32\n\n    def test_hardlink(self, tmpdir):\n        linkpath = tmpdir.join(\"test\")\n        filepath = tmpdir.join(\"file\")\n        filepath.write_text(\"Hello\", encoding=\"utf-8\")\n        nlink = filepath.stat().nlink\n        linkpath.mklinkto(filepath)\n        assert filepath.stat().nlink == nlink + 1\n\n    def test_symlink_are_identical(self, tmpdir):\n        filepath = tmpdir.join(\"file\")\n        filepath.write_text(\"Hello\", encoding=\"utf-8\")\n        linkpath = tmpdir.join(\"test\")\n        linkpath.mksymlinkto(filepath)\n        assert linkpath.readlink() == str(filepath)\n\n    def test_symlink_isfile(self, tmpdir):\n        linkpath = tmpdir.join(\"test\")\n        filepath = tmpdir.join(\"file\")\n        filepath.write_text(\"\", encoding=\"utf-8\")\n        linkpath.mksymlinkto(filepath)\n        assert linkpath.check(file=1)\n        assert not linkpath.check(link=0, file=1)\n        asse"}, {"start_line": 12000, "end_line": 14000, "belongs_to": {"file_name": "path.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest/_py", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "\n            raise error.EINVAL(target, \"cannot move path into a subdirectory of itself\")\n        try:\n            self.rename(target)\n        except error.EXDEV:  # invalid cross-device link\n            self.copy(target)\n            self.remove()\n\n    def fnmatch(self, pattern):\n        \"\"\"Return true if the basename/fullname matches the glob-'pattern'.\n\n        valid pattern characters::\n\n            *       matches everything\n            ?       matches any single character\n            [seq]   matches any character in seq\n            [!seq]  matches any char not in seq\n\n        If the pattern contains a path-separator then the full path\n        is used for pattern matching and a '*' is prepended to the\n        pattern.\n\n        if the pattern doesn't contain a path-separator the pattern\n        is only matched against the basename.\n        \"\"\"\n        return FNMatcher(pattern)(self)\n\n    def relto(self, relpath):\n        \"\"\"Return a string which is the relative part of the path\n        to the given 'relpath'.\n        \"\"\"\n        if not isinstance(relpath, (str, LocalPath)):\n            raise TypeError(f\"{relpath!r}: not a string or path object\")\n        strrelpath = str(relpath)\n        if strrelpath and strrelpath[-1] != self.sep:\n            strrelpath += self.sep\n        # assert strrelpath[-1] == self.sep\n        # assert strrelpath[-2] != self.sep\n        strself = self.strpath\n        if sys.platform == \"win32\" or getattr(os, \"_name\", None) == \"nt\":\n            if os.path.normcase(strself).startswith(os.path.normcase(strrelpath)):\n                return strself[len(strrelpath) :]\n        elif strself.startswith(strrelpath):\n            return strself[len(strrelpath) :]\n        return \"\"\n\n    def ensure_dir(self, *args):\n        \"\"\"Ensure the path joined with args is a directory.\"\"\"\n        return self.ensure(*args, dir=True)\n\n    def bestrelpath(self, dest):\n        \"\"\"Return a string which is a relative path from self\n        (assumed to be a directory) to"}], "retrieved_count": 10, "cost_time": 0.3432316780090332}
{"question": "Where are the functions or methods in the assertion module that indirectly invoke the _HighlightFunc protocol through conditional lexer type selection between diff and python highlighting implementations?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"start_line": 1000, "end_line": 3000, "belongs_to": {"file_name": "util.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest/assertion", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "ilarly as _reprcompare attribute. Is populated with the hook call\n# when pytest_runtest_setup is called.\n_assertion_pass: Callable[[int, str, str], None] | None = None\n\n# Config object which is assigned during pytest_runtest_protocol.\n_config: Config | None = None\n\n\nclass _HighlightFunc(Protocol):\n    def __call__(self, source: str, lexer: Literal[\"diff\", \"python\"] = \"python\") -> str:\n        \"\"\"Apply highlighting to the given source.\"\"\"\n\n\ndef dummy_highlighter(source: str, lexer: Literal[\"diff\", \"python\"] = \"python\") -> str:\n    \"\"\"Dummy highlighter that returns the text unprocessed.\n\n    Needed for _notin_text, as the diff gets post-processed to only show the \"+\" part.\n    \"\"\"\n    return source\n\n\ndef format_explanation(explanation: str) -> str:\n    r\"\"\"Format an explanation.\n\n    Normally all embedded newlines are escaped, however there are\n    three exceptions: \\n{, \\n} and \\n~.  The first two are intended\n    cover nested explanations, see function and attribute explanations\n    for examples (.visit_Call(), visit_Attribute()).  The last one is\n    for when one explanation needs to span multiple lines, e.g. when\n    displaying diffs.\n    \"\"\"\n    lines = _split_explanation(explanation)\n    result = _format_lines(lines)\n    return \"\\n\".join(result)\n\n\ndef _split_explanation(explanation: str) -> list[str]:\n    r\"\"\"Return a list of individual lines in the explanation.\n\n    This will return a list of lines split on '\\n{', '\\n}' and '\\n~'.\n    Any other newlines will be escaped and appear in the line as the\n    literal '\\n' characters.\n    \"\"\"\n    raw_lines = (explanation or \"\").split(\"\\n\")\n    lines = [raw_lines[0]]\n    for values in raw_lines[1:]:\n        if values and values[0] in [\"{\", \"}\", \"~\", \">\"]:\n            lines.append(values)\n        else:\n            lines[-1] += \"\\\\n\" + values\n    return lines\n\n\ndef _format_lines(lines: Sequence[str]) -> list[str]:\n    \"\"\"Format the individual lines.\n\n    This will replace the '{', '}' and '~' characters of our mini format"}, {"start_line": 0, "end_line": 2000, "belongs_to": {"file_name": "util.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest/assertion", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "# mypy: allow-untyped-defs\n\"\"\"Utilities for assertion debugging.\"\"\"\n\nfrom __future__ import annotations\n\nimport collections.abc\nfrom collections.abc import Callable\nfrom collections.abc import Iterable\nfrom collections.abc import Mapping\nfrom collections.abc import Sequence\nfrom collections.abc import Set as AbstractSet\nimport os\nimport pprint\nfrom typing import Any\nfrom typing import Literal\nfrom typing import Protocol\nfrom unicodedata import normalize\n\nfrom _pytest import outcomes\nimport _pytest._code\nfrom _pytest._io.pprint import PrettyPrinter\nfrom _pytest._io.saferepr import saferepr\nfrom _pytest._io.saferepr import saferepr_unlimited\nfrom _pytest.config import Config\n\n\n# The _reprcompare attribute on the util module is used by the new assertion\n# interpretation code and assertion rewriter to detect this plugin was\n# loaded and in turn call the hooks defined here as part of the\n# DebugInterpreter.\n_reprcompare: Callable[[str, object, object], str | None] | None = None\n\n# Works similarly as _reprcompare attribute. Is populated with the hook call\n# when pytest_runtest_setup is called.\n_assertion_pass: Callable[[int, str, str], None] | None = None\n\n# Config object which is assigned during pytest_runtest_protocol.\n_config: Config | None = None\n\n\nclass _HighlightFunc(Protocol):\n    def __call__(self, source: str, lexer: Literal[\"diff\", \"python\"] = \"python\") -> str:\n        \"\"\"Apply highlighting to the given source.\"\"\"\n\n\ndef dummy_highlighter(source: str, lexer: Literal[\"diff\", \"python\"] = \"python\") -> str:\n    \"\"\"Dummy highlighter that returns the text unprocessed.\n\n    Needed for _notin_text, as the diff gets post-processed to only show the \"+\" part.\n    \"\"\"\n    return source\n\n\ndef format_explanation(explanation: str) -> str:\n    r\"\"\"Format an explanation.\n\n    Normally all embedded newlines are escaped, however there are\n    three exceptions: \\n{, \\n} and \\n~.  The first two are intended\n    cover nested explanations, see function and attribute explanations\n    fo"}, {"start_line": 7000, "end_line": 8849, "belongs_to": {"file_name": "terminalwriter.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest/_io", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "          assert_never(lexer)\n\n    def _get_pygments_formatter(self) -> TerminalFormatter:\n        from _pytest.config.exceptions import UsageError\n\n        theme = os.getenv(\"PYTEST_THEME\")\n        theme_mode = os.getenv(\"PYTEST_THEME_MODE\", \"dark\")\n\n        try:\n            return TerminalFormatter(bg=theme_mode, style=theme)\n        except pygments.util.ClassNotFound as e:\n            raise UsageError(\n                f\"PYTEST_THEME environment variable has an invalid value: '{theme}'. \"\n                \"Hint: See available pygments styles with `pygmentize -L styles`.\"\n            ) from e\n        except pygments.util.OptionError as e:\n            raise UsageError(\n                f\"PYTEST_THEME_MODE environment variable has an invalid value: '{theme_mode}'. \"\n                \"The allowed values are 'dark' (default) and 'light'.\"\n            ) from e\n\n    def _highlight(\n        self, source: str, lexer: Literal[\"diff\", \"python\"] = \"python\"\n    ) -> str:\n        \"\"\"Highlight the given source if we have markup support.\"\"\"\n        if not source or not self.hasmarkup or not self.code_highlight:\n            return source\n\n        pygments_lexer = self._get_pygments_lexer(lexer)\n        pygments_formatter = self._get_pygments_formatter()\n\n        highlighted: str = pygments.highlight(\n            source, pygments_lexer, pygments_formatter\n        )\n        # pygments terminal formatter may add a newline when there wasn't one.\n        # We don't want this, remove.\n        if highlighted[-1] == \"\\n\" and source[-1] != \"\\n\":\n            highlighted = highlighted[:-1]\n\n        # Some lexers will not set the initial color explicitly\n        # which may lead to the previous color being propagated to the\n        # start of the expression, so reset first.\n        highlighted = \"\\x1b[0m\" + highlighted\n\n        return highlighted\n"}, {"start_line": 6000, "end_line": 8000, "belongs_to": {"file_name": "terminalwriter.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest/_io", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "  \"\"\"Write lines of source code possibly highlighted.\n\n        Keeping this private for now because the API is clunky. We should discuss how\n        to evolve the terminal writer so we can have more precise color support, for example\n        being able to write part of a line in one color and the rest in another, and so on.\n        \"\"\"\n        if indents and len(indents) != len(lines):\n            raise ValueError(\n                f\"indents size ({len(indents)}) should have same size as lines ({len(lines)})\"\n            )\n        if not indents:\n            indents = [\"\"] * len(lines)\n        source = \"\\n\".join(lines)\n        new_lines = self._highlight(source).splitlines()\n        for indent, new_line in zip(indents, new_lines):\n            self.line(indent + new_line)\n\n    def _get_pygments_lexer(self, lexer: Literal[\"python\", \"diff\"]) -> Lexer:\n        if lexer == \"python\":\n            return PythonLexer()\n        elif lexer == \"diff\":\n            return DiffLexer()\n        else:\n            assert_never(lexer)\n\n    def _get_pygments_formatter(self) -> TerminalFormatter:\n        from _pytest.config.exceptions import UsageError\n\n        theme = os.getenv(\"PYTEST_THEME\")\n        theme_mode = os.getenv(\"PYTEST_THEME_MODE\", \"dark\")\n\n        try:\n            return TerminalFormatter(bg=theme_mode, style=theme)\n        except pygments.util.ClassNotFound as e:\n            raise UsageError(\n                f\"PYTEST_THEME environment variable has an invalid value: '{theme}'. \"\n                \"Hint: See available pygments styles with `pygmentize -L styles`.\"\n            ) from e\n        except pygments.util.OptionError as e:\n            raise UsageError(\n                f\"PYTEST_THEME_MODE environment variable has an invalid value: '{theme_mode}'. \"\n                \"The allowed values are 'dark' (default) and 'light'.\"\n            ) from e\n\n    def _highlight(\n        self, source: str, lexer: Literal[\"diff\", \"python\"] = \"python\"\n    ) -> str:\n        \"\"\"Highlight the giv"}, {"start_line": 7000, "end_line": 9000, "belongs_to": {"file_name": "util.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest/assertion", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "        explanation = _notin_text(left, right, verbose)\n        elif op == \"!=\":\n            if isset(left) and isset(right):\n                explanation = [\"Both sets are equal\"]\n        elif op == \">=\":\n            if isset(left) and isset(right):\n                explanation = _compare_gte_set(left, right, highlighter, verbose)\n        elif op == \"<=\":\n            if isset(left) and isset(right):\n                explanation = _compare_lte_set(left, right, highlighter, verbose)\n        elif op == \">\":\n            if isset(left) and isset(right):\n                explanation = _compare_gt_set(left, right, highlighter, verbose)\n        elif op == \"<\":\n            if isset(left) and isset(right):\n                explanation = _compare_lt_set(left, right, highlighter, verbose)\n\n    except outcomes.Exit:\n        raise\n    except Exception:\n        repr_crash = _pytest._code.ExceptionInfo.from_current()._getreprcrash()\n        explanation = [\n            f\"(pytest_assertion plugin: representation of details failed: {repr_crash}.\",\n            \" Probably an object has a faulty __repr__.)\",\n        ]\n\n    if not explanation:\n        return None\n\n    if explanation[0] != \"\":\n        explanation = [\"\", *explanation]\n    return [summary, *explanation]\n\n\ndef _compare_eq_any(\n    left: Any, right: Any, highlighter: _HighlightFunc, verbose: int = 0\n) -> list[str]:\n    explanation = []\n    if istext(left) and istext(right):\n        explanation = _diff_text(left, right, highlighter, verbose)\n    else:\n        from _pytest.python_api import ApproxBase\n\n        if isinstance(left, ApproxBase) or isinstance(right, ApproxBase):\n            # Although the common order should be obtained == expected, this ensures both ways\n            approx_side = left if isinstance(left, ApproxBase) else right\n            other_side = right if isinstance(left, ApproxBase) else left\n\n            explanation = approx_side._repr_compare(other_side)\n        elif type(left) is type(right) and (\n            "}, {"start_line": 5000, "end_line": 7000, "belongs_to": {"file_name": "terminalwriter.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest/_io", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "elf._current_line += current_line\n\n            msg = self.markup(msg, **markup)\n\n            try:\n                self._file.write(msg)\n            except UnicodeEncodeError:\n                # Some environments don't support printing general Unicode\n                # strings, due to misconfiguration or otherwise; in that case,\n                # print the string escaped to ASCII.\n                # When the Unicode situation improves we should consider\n                # letting the error propagate instead of masking it (see #7475\n                # for one brief attempt).\n                msg = msg.encode(\"unicode-escape\").decode(\"ascii\")\n                self._file.write(msg)\n\n            if flush:\n                self.flush()\n\n    def line(self, s: str = \"\", **markup: bool) -> None:\n        self.write(s, **markup)\n        self.write(\"\\n\")\n\n    def flush(self) -> None:\n        self._file.flush()\n\n    def _write_source(self, lines: Sequence[str], indents: Sequence[str] = ()) -> None:\n        \"\"\"Write lines of source code possibly highlighted.\n\n        Keeping this private for now because the API is clunky. We should discuss how\n        to evolve the terminal writer so we can have more precise color support, for example\n        being able to write part of a line in one color and the rest in another, and so on.\n        \"\"\"\n        if indents and len(indents) != len(lines):\n            raise ValueError(\n                f\"indents size ({len(indents)}) should have same size as lines ({len(lines)})\"\n            )\n        if not indents:\n            indents = [\"\"] * len(lines)\n        source = \"\\n\".join(lines)\n        new_lines = self._highlight(source).splitlines()\n        for indent, new_line in zip(indents, new_lines):\n            self.line(indent + new_line)\n\n    def _get_pygments_lexer(self, lexer: Literal[\"python\", \"diff\"]) -> Lexer:\n        if lexer == \"python\":\n            return PythonLexer()\n        elif lexer == \"diff\":\n            return DiffLexer()\n        else:\n  "}, {"start_line": 11000, "end_line": 13000, "belongs_to": {"file_name": "util.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest/assertion", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "= 10  # Provide some context\n                explanation += [\n                    f\"Skipping {i} identical trailing \"\n                    \"characters in diff, use -v to show\"\n                ]\n                left = left[:-i]\n                right = right[:-i]\n    keepends = True\n    if left.isspace() or right.isspace():\n        left = repr(str(left))\n        right = repr(str(right))\n        explanation += [\"Strings contain only whitespace, escaping them using repr()\"]\n    # \"right\" is the expected base against which we compare \"left\",\n    # see https://github.com/pytest-dev/pytest/issues/3333\n    explanation.extend(\n        highlighter(\n            \"\\n\".join(\n                line.strip(\"\\n\")\n                for line in ndiff(right.splitlines(keepends), left.splitlines(keepends))\n            ),\n            lexer=\"diff\",\n        ).splitlines()\n    )\n    return explanation\n\n\ndef _compare_eq_iterable(\n    left: Iterable[Any],\n    right: Iterable[Any],\n    highlighter: _HighlightFunc,\n    verbose: int = 0,\n) -> list[str]:\n    if verbose <= 0 and not running_on_ci():\n        return [\"Use -v to get more diff\"]\n    # dynamic import to speedup pytest\n    import difflib\n\n    left_formatting = PrettyPrinter().pformat(left).splitlines()\n    right_formatting = PrettyPrinter().pformat(right).splitlines()\n\n    explanation = [\"\", \"Full diff:\"]\n    # \"right\" is the expected base against which we compare \"left\",\n    # see https://github.com/pytest-dev/pytest/issues/3333\n    explanation.extend(\n        highlighter(\n            \"\\n\".join(\n                line.rstrip()\n                for line in difflib.ndiff(right_formatting, left_formatting)\n            ),\n            lexer=\"diff\",\n        ).splitlines()\n    )\n    return explanation\n\n\ndef _compare_eq_sequence(\n    left: Sequence[Any],\n    right: Sequence[Any],\n    highlighter: _HighlightFunc,\n    verbose: int = 0,\n) -> list[str]:\n    comparing_bytes = isinstance(left, bytes) and isinstance(right, bytes)\n    explanation: list[str] = "}, {"start_line": 64000, "end_line": 66000, "belongs_to": {"file_name": "test_assertion.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "n range(11)}\n    b = a.copy()\n    b[\"v2\"] += 10\n    lines = callop(\"==\", a, b, verbose=2)\n    assert lines is not None\n    assert lines[0] == (\n        \"{'v0': 0, 'v1': 1, 'v2': 2, 'v3': 3, 'v4': 4, 'v5': 5, \"\n        \"'v6': 6, 'v7': 7, 'v8': 8, 'v9': 9, 'v10': 10}\"\n        \" == \"\n        \"{'v0': 0, 'v1': 1, 'v2': 12, 'v3': 3, 'v4': 4, 'v5': 5, \"\n        \"'v6': 6, 'v7': 7, 'v8': 8, 'v9': 9, 'v10': 10}\"\n    )\n\n\n@pytest.mark.parametrize(\"enable_colors\", [True, False])\n@pytest.mark.parametrize(\n    (\"test_code\", \"expected_lines\"),\n    (\n        (\n            \"\"\"\n            def test():\n                assert [0, 1] == [0, 2]\n            \"\"\",\n            [\n                \"{bold}{red}E         At index 1 diff: {reset}{number}1{hl-reset}{endline} != {reset}{number}2*\",\n                \"{bold}{red}E         {light-red}-     2,{hl-reset}{endline}{reset}\",\n                \"{bold}{red}E         {light-green}+     1,{hl-reset}{endline}{reset}\",\n            ],\n        ),\n        (\n            \"\"\"\n            def test():\n                assert {f\"number-is-{i}\": i for i in range(1, 6)} == {\n                    f\"number-is-{i}\": i for i in range(5)\n                }\n            \"\"\",\n            [\n                \"{bold}{red}E         Common items:{reset}\",\n                \"{bold}{red}E         {reset}{{{str}'{hl-reset}{str}number-is-1{hl-reset}{str}'{hl-reset}: {number}1*\",\n                \"{bold}{red}E         Left contains 1 more item:{reset}\",\n                \"{bold}{red}E         {reset}{{{str}'{hl-reset}{str}number-is-5{hl-reset}{str}'{hl-reset}: {number}5*\",\n                \"{bold}{red}E         Right contains 1 more item:{reset}\",\n                \"{bold}{red}E         {reset}{{{str}'{hl-reset}{str}number-is-0{hl-reset}{str}'{hl-reset}: {number}0*\",\n                \"{bold}{red}E         {reset}{light-gray} {hl-reset} {{{endline}{reset}\",\n                \"{bold}{red}E         {light-gray} {hl-reset}     'number-is-1': 1,{endline}{reset}\",\n                \"{bold}{red}E      "}, {"start_line": 8000, "end_line": 10000, "belongs_to": {"file_name": "util.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest/assertion", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "ation of details failed: {repr_crash}.\",\n            \" Probably an object has a faulty __repr__.)\",\n        ]\n\n    if not explanation:\n        return None\n\n    if explanation[0] != \"\":\n        explanation = [\"\", *explanation]\n    return [summary, *explanation]\n\n\ndef _compare_eq_any(\n    left: Any, right: Any, highlighter: _HighlightFunc, verbose: int = 0\n) -> list[str]:\n    explanation = []\n    if istext(left) and istext(right):\n        explanation = _diff_text(left, right, highlighter, verbose)\n    else:\n        from _pytest.python_api import ApproxBase\n\n        if isinstance(left, ApproxBase) or isinstance(right, ApproxBase):\n            # Although the common order should be obtained == expected, this ensures both ways\n            approx_side = left if isinstance(left, ApproxBase) else right\n            other_side = right if isinstance(left, ApproxBase) else left\n\n            explanation = approx_side._repr_compare(other_side)\n        elif type(left) is type(right) and (\n            isdatacls(left) or isattrs(left) or isnamedtuple(left)\n        ):\n            # Note: unlike dataclasses/attrs, namedtuples compare only the\n            # field values, not the type or field names. But this branch\n            # intentionally only handles the same-type case, which was often\n            # used in older code bases before dataclasses/attrs were available.\n            explanation = _compare_eq_cls(left, right, highlighter, verbose)\n        elif issequence(left) and issequence(right):\n            explanation = _compare_eq_sequence(left, right, highlighter, verbose)\n        elif isset(left) and isset(right):\n            explanation = _compare_eq_set(left, right, highlighter, verbose)\n        elif isdict(left) and isdict(right):\n            explanation = _compare_eq_dict(left, right, highlighter, verbose)\n\n        if isiterable(left) and isiterable(right):\n            expl = _compare_eq_iterable(left, right, highlighter, verbose)\n            explanation.extend(expl)\n\n    retur"}, {"start_line": 92000, "end_line": 94000, "belongs_to": {"file_name": "test_terminal.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "}{kwspace}{function}test_foo{hl-reset}():{endline}\",\n                    \">       {kw}assert{hl-reset} {number}1{hl-reset} == {number}10{hl-reset}{endline}\",\n                    \"{bold}{red}E       assert 1 == 10{reset}\",\n                ]\n            )\n        )\n\n    def test_code_highlight_continuation(\n        self, pytester: Pytester, color_mapping\n    ) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            def test_foo():\n                print('''\n                '''); assert 0\n        \"\"\"\n        )\n        result = pytester.runpytest(\"--color=yes\")\n\n        result.stdout.fnmatch_lines(\n            color_mapping.format_for_fnmatch(\n                [\n                    \"    {reset}{kw}def{hl-reset}{kwspace}{function}test_foo{hl-reset}():{endline}\",\n                    \"        {print}print{hl-reset}({str}'''{hl-reset}{str}{hl-reset}\",\n                    \">   {str}    {hl-reset}{str}'''{hl-reset}); {kw}assert{hl-reset} {number}0{hl-reset}{endline}\",\n                    \"{bold}{red}E       assert 0{reset}\",\n                ]\n            )\n        )\n\n    def test_code_highlight_custom_theme(\n        self, pytester: Pytester, color_mapping, monkeypatch: MonkeyPatch\n    ) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            def test_foo():\n                assert 1 == 10\n        \"\"\"\n        )\n        monkeypatch.setenv(\"PYTEST_THEME\", \"solarized-dark\")\n        monkeypatch.setenv(\"PYTEST_THEME_MODE\", \"dark\")\n        result = pytester.runpytest(\"--color=yes\")\n        result.stdout.fnmatch_lines(\n            color_mapping.format_for_fnmatch(\n                [\n                    \"    {reset}{kw}def{hl-reset}{kwspace}{function}test_foo{hl-reset}():{endline}\",\n                    \">       {kw}assert{hl-reset} {number}1{hl-reset} == {number}10{hl-reset}{endline}\",\n                    \"{bold}{red}E       assert 1 == 10{reset}\",\n                ]\n            )\n        )\n\n    def test_code_highlight_invalid_theme(\n        self, pytester: Pytester, co"}], "retrieved_count": 10, "cost_time": 0.34247684478759766}
{"question": "Where does the data flow from pytester.inline_run() through the test execution pipeline to ultimately validate that tmp_path remains functional when the current process's user id lacks a corresponding valid user entry?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"start_line": 9000, "end_line": 11000, "belongs_to": {"file_name": "test_tmpdir.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "_dir.is_dir()\n    \"\"\"\n    )\n    reprec = pytester.inline_run()\n    reprec.assertoutcome(passed=1)\n\n\ndef test_tmp_path_fallback_tox_env(pytester: Pytester, monkeypatch) -> None:\n    \"\"\"Test that tmp_path works even if environment variables required by getpass\n    module are missing (#1010).\n    \"\"\"\n    monkeypatch.delenv(\"USER\", raising=False)\n    monkeypatch.delenv(\"USERNAME\", raising=False)\n    pytester.makepyfile(\n        \"\"\"\n        def test_some(tmp_path):\n            assert tmp_path.is_dir()\n    \"\"\"\n    )\n    reprec = pytester.inline_run()\n    reprec.assertoutcome(passed=1)\n\n\n@pytest.fixture\ndef break_getuser(monkeypatch):\n    monkeypatch.setattr(\"os.getuid\", lambda: -1)\n    # taken from python 2.7/3.4\n    for envvar in (\"LOGNAME\", \"USER\", \"LNAME\", \"USERNAME\"):\n        monkeypatch.delenv(envvar, raising=False)\n\n\n@pytest.mark.usefixtures(\"break_getuser\")\n@pytest.mark.skipif(sys.platform.startswith(\"win\"), reason=\"no os.getuid on windows\")\ndef test_tmp_path_fallback_uid_not_found(pytester: Pytester) -> None:\n    \"\"\"Test that tmp_path works even if the current process's user id does not\n    correspond to a valid user.\n    \"\"\"\n    pytester.makepyfile(\n        \"\"\"\n        def test_some(tmp_path):\n            assert tmp_path.is_dir()\n    \"\"\"\n    )\n    reprec = pytester.inline_run()\n    reprec.assertoutcome(passed=1)\n\n\n@pytest.mark.usefixtures(\"break_getuser\")\n@pytest.mark.skipif(sys.platform.startswith(\"win\"), reason=\"no os.getuid on windows\")\ndef test_get_user_uid_not_found():\n    \"\"\"Test that get_user() function works even if the current process's\n    user id does not correspond to a valid user (e.g. running pytest in a\n    Docker container with 'docker run -u'.\n    \"\"\"\n    assert get_user() is None\n\n\n@pytest.mark.skipif(not sys.platform.startswith(\"win\"), reason=\"win only\")\ndef test_get_user(monkeypatch):\n    \"\"\"Test that get_user() function works even if environment variables\n    required by getpass module are missing from the environment on Windows\n    (#1010).\n"}, {"start_line": 8000, "end_line": 10000, "belongs_to": {"file_name": "test_tmpdir.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": ")\n    attempt_symlink_to(linktemp, str(realtemp))\n    monkeypatch.setenv(\"PYTEST_DEBUG_TEMPROOT\", str(linktemp))\n    pytester.makepyfile(\n        \"\"\"\n        def test_1(tmp_path):\n            assert tmp_path.resolve() == tmp_path\n    \"\"\"\n    )\n    reprec = pytester.inline_run()\n    reprec.assertoutcome(passed=1)\n\n\ndef test_tmp_path_too_long_on_parametrization(pytester: Pytester) -> None:\n    pytester.makepyfile(\n        \"\"\"\n        import pytest\n        @pytest.mark.parametrize(\"arg\", [\"1\"*1000])\n        def test_some(arg, tmp_path):\n            tmp_path.joinpath(\"hello\").touch()\n    \"\"\"\n    )\n    reprec = pytester.inline_run()\n    reprec.assertoutcome(passed=1)\n\n\ndef test_tmp_path_factory(pytester: Pytester) -> None:\n    pytester.makepyfile(\n        \"\"\"\n        import pytest\n        @pytest.fixture(scope='session')\n        def session_dir(tmp_path_factory):\n            return tmp_path_factory.mktemp('data', numbered=False)\n        def test_some(session_dir):\n            assert session_dir.is_dir()\n    \"\"\"\n    )\n    reprec = pytester.inline_run()\n    reprec.assertoutcome(passed=1)\n\n\ndef test_tmp_path_fallback_tox_env(pytester: Pytester, monkeypatch) -> None:\n    \"\"\"Test that tmp_path works even if environment variables required by getpass\n    module are missing (#1010).\n    \"\"\"\n    monkeypatch.delenv(\"USER\", raising=False)\n    monkeypatch.delenv(\"USERNAME\", raising=False)\n    pytester.makepyfile(\n        \"\"\"\n        def test_some(tmp_path):\n            assert tmp_path.is_dir()\n    \"\"\"\n    )\n    reprec = pytester.inline_run()\n    reprec.assertoutcome(passed=1)\n\n\n@pytest.fixture\ndef break_getuser(monkeypatch):\n    monkeypatch.setattr(\"os.getuid\", lambda: -1)\n    # taken from python 2.7/3.4\n    for envvar in (\"LOGNAME\", \"USER\", \"LNAME\", \"USERNAME\"):\n        monkeypatch.delenv(envvar, raising=False)\n\n\n@pytest.mark.usefixtures(\"break_getuser\")\n@pytest.mark.skipif(sys.platform.startswith(\"win\"), reason=\"no os.getuid on windows\")\ndef test_tmp_path_fallback_uid_not_found(py"}, {"start_line": 17000, "end_line": 19000, "belongs_to": {"file_name": "test_tmpdir.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "    mode = os.stat(str(fn)).st_mode\n            os.chmod(str(fn), mode & ~stat.S_IREAD)\n    \"\"\"\n    )\n    result = pytester.runpytest(\"--basetemp=tmp\")\n    assert result.ret == 0\n    # running a second time and ensure we don't crash\n    result = pytester.runpytest(\"--basetemp=tmp\")\n    assert result.ret == 0\n\n\ndef test_tmp_path_factory_handles_invalid_dir_characters(\n    tmp_path_factory: TempPathFactory, monkeypatch: MonkeyPatch\n) -> None:\n    monkeypatch.setattr(\"getpass.getuser\", lambda: \"os/<:*?;>agnostic\")\n    # _basetemp / _given_basetemp are cached / set in parallel runs, patch them\n    monkeypatch.setattr(tmp_path_factory, \"_basetemp\", None)\n    monkeypatch.setattr(tmp_path_factory, \"_given_basetemp\", None)\n    p = tmp_path_factory.getbasetemp()\n    assert \"pytest-of-unknown\" in str(p)\n\n\n@pytest.mark.skipif(not hasattr(os, \"getuid\"), reason=\"checks unix permissions\")\ndef test_tmp_path_factory_create_directory_with_safe_permissions(\n    tmp_path: Path, monkeypatch: MonkeyPatch\n) -> None:\n    \"\"\"Verify that pytest creates directories under /tmp with private permissions.\"\"\"\n    # Use the test's tmp_path as the system temproot (/tmp).\n    monkeypatch.setenv(\"PYTEST_DEBUG_TEMPROOT\", str(tmp_path))\n    tmp_factory = TempPathFactory(None, 3, \"all\", lambda *args: None, _ispytest=True)\n    basetemp = tmp_factory.getbasetemp()\n\n    # No world-readable permissions.\n    assert (basetemp.stat().st_mode & 0o077) == 0\n    # Parent too (pytest-of-foo).\n    assert (basetemp.parent.stat().st_mode & 0o077) == 0\n\n\n@pytest.mark.skipif(not hasattr(os, \"getuid\"), reason=\"checks unix permissions\")\ndef test_tmp_path_factory_fixes_up_world_readable_permissions(\n    tmp_path: Path, monkeypatch: MonkeyPatch\n) -> None:\n    \"\"\"Verify that if a /tmp/pytest-of-foo directory already exists with\n    world-readable permissions, it is fixed.\n\n    pytest used to mkdir with such permissions, that's why we fix it up.\n    \"\"\"\n    # Use the test's tmp_path as the system temproot (/tmp).\n    monkeyp"}, {"start_line": 6000, "end_line": 8000, "belongs_to": {"file_name": "test_tmpdir.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "    )\n        pytester.makepyprojecttoml(\n            \"\"\"\n            [tool.pytest.ini_options]\n            tmp_path_retention_policy = \"all\"\n        \"\"\"\n        )\n        pytester.inline_run(p)\n\n        # Check if the whole directory is kept\n        root = pytester._test_tmproot\n        for child in root.iterdir():\n            base_dir = list(\n                filter(lambda x: x.is_dir() and not x.is_symlink(), child.iterdir())\n            )\n            assert len(base_dir) == 1\n            test_dir = list(\n                filter(\n                    lambda x: x.is_dir() and not x.is_symlink(), base_dir[0].iterdir()\n                )\n            )\n            assert len(test_dir) == 1\n\n\ntestdata = [\n    (\"mypath\", True),\n    (\"/mypath1\", False),\n    (\"./mypath1\", True),\n    (\"../mypath3\", False),\n    (\"../../mypath4\", False),\n    (\"mypath5/..\", False),\n    (\"mypath6/../mypath6\", True),\n    (\"mypath7/../mypath7/..\", False),\n]\n\n\n@pytest.mark.parametrize(\"basename, is_ok\", testdata)\ndef test_mktemp(pytester: Pytester, basename: str, is_ok: bool) -> None:\n    mytemp = pytester.mkdir(\"mytemp\")\n    p = pytester.makepyfile(\n        f\"\"\"\n        def test_abs_path(tmp_path_factory):\n            tmp_path_factory.mktemp('{basename}', numbered=False)\n        \"\"\"\n    )\n\n    result = pytester.runpytest(p, f\"--basetemp={mytemp}\")\n    if is_ok:\n        assert result.ret == 0\n        assert mytemp.joinpath(basename).exists()\n    else:\n        assert result.ret == 1\n        result.stdout.fnmatch_lines(\"*ValueError*\")\n\n\ndef test_tmp_path_always_is_realpath(pytester: Pytester, monkeypatch) -> None:\n    # the reason why tmp_path should be a realpath is that\n    # when you cd to it and do \"os.getcwd()\" you will anyway\n    # get the realpath.  Using the symlinked path can thus\n    # easily result in path-inequality\n    # XXX if that proves to be a problem, consider using\n    # os.environ[\"PWD\"]\n    realtemp = pytester.mkdir(\"myrealtemp\")\n    linktemp = pytester.path.joinpath(\"symlinktemp\""}, {"start_line": 8000, "end_line": 10000, "belongs_to": {"file_name": "test_collection.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "/0\", encoding=\"utf-8\"\n        )\n        ensure_file(tmp_path / \"xy\" / \"test_ok.py\").write_text(\n            \"def test_3(): pass\", encoding=\"utf-8\"\n        )\n        rec = pytester.inline_run()\n        rec.assertoutcome(passed=1)\n        rec = pytester.inline_run(\"xyz123/test_2.py\")\n        rec.assertoutcome(failed=1)\n\n    def test_testpaths_ini(self, pytester: Pytester, monkeypatch: MonkeyPatch) -> None:\n        pytester.makeini(\n            \"\"\"\n            [pytest]\n            testpaths = */tests\n        \"\"\"\n        )\n        tmp_path = pytester.path\n        ensure_file(tmp_path / \"a\" / \"test_1.py\").write_text(\n            \"def test_a(): pass\", encoding=\"utf-8\"\n        )\n        ensure_file(tmp_path / \"b\" / \"tests\" / \"test_2.py\").write_text(\n            \"def test_b(): pass\", encoding=\"utf-8\"\n        )\n        ensure_file(tmp_path / \"c\" / \"tests\" / \"test_3.py\").write_text(\n            \"def test_c(): pass\", encoding=\"utf-8\"\n        )\n\n        # executing from rootdir only tests from `testpaths` directories\n        # are collected\n        items, reprec = pytester.inline_genitems(\"-v\")\n        assert [x.name for x in items] == [\"test_b\", \"test_c\"]\n\n        # check that explicitly passing directories in the command-line\n        # collects the tests\n        for dirname in (\"a\", \"b\", \"c\"):\n            items, reprec = pytester.inline_genitems(tmp_path.joinpath(dirname))\n            assert [x.name for x in items] == [f\"test_{dirname}\"]\n\n        # changing cwd to each subdirectory and running pytest without\n        # arguments collects the tests in that directory normally\n        for dirname in (\"a\", \"b\", \"c\"):\n            monkeypatch.chdir(pytester.path.joinpath(dirname))\n            items, reprec = pytester.inline_genitems()\n            assert [x.name for x in items] == [f\"test_{dirname}\"]\n\n    def test_missing_permissions_on_unselected_directory_doesnt_crash(\n        self, pytester: Pytester\n    ) -> None:\n        \"\"\"Regression test for #12120.\"\"\"\n        test = pytester."}, {"start_line": 5000, "end_line": 7000, "belongs_to": {"file_name": "test_tmpdir.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "t.fixture\n            def fixt(tmp_path):\n                pytest.skip()\n\n            def test_fixt(fixt):\n                pass\n        \"\"\"\n        )\n        pytester.makepyprojecttoml(\n            \"\"\"\n            [tool.pytest.ini_options]\n            tmp_path_retention_policy = \"failed\"\n        \"\"\"\n        )\n\n        pytester.inline_run(p)\n\n        # Check if the whole directory is removed\n        root = pytester._test_tmproot\n        for child in root.iterdir():\n            base_dir = list(\n                filter(lambda x: x.is_dir() and not x.is_symlink(), child.iterdir())\n            )\n            assert len(base_dir) == 0\n\n    # issue #10502\n    def test_policy_all_keeps_dir_when_skipped_from_fixture(\n        self, pytester: Pytester\n    ) -> None:\n        p = pytester.makepyfile(\n            \"\"\"\n            import pytest\n\n            @pytest.fixture\n            def fixt(tmp_path):\n                pytest.skip()\n\n            def test_fixt(fixt):\n                pass\n        \"\"\"\n        )\n        pytester.makepyprojecttoml(\n            \"\"\"\n            [tool.pytest.ini_options]\n            tmp_path_retention_policy = \"all\"\n        \"\"\"\n        )\n        pytester.inline_run(p)\n\n        # Check if the whole directory is kept\n        root = pytester._test_tmproot\n        for child in root.iterdir():\n            base_dir = list(\n                filter(lambda x: x.is_dir() and not x.is_symlink(), child.iterdir())\n            )\n            assert len(base_dir) == 1\n            test_dir = list(\n                filter(\n                    lambda x: x.is_dir() and not x.is_symlink(), base_dir[0].iterdir()\n                )\n            )\n            assert len(test_dir) == 1\n\n\ntestdata = [\n    (\"mypath\", True),\n    (\"/mypath1\", False),\n    (\"./mypath1\", True),\n    (\"../mypath3\", False),\n    (\"../../mypath4\", False),\n    (\"mypath5/..\", False),\n    (\"mypath6/../mypath6\", True),\n    (\"mypath7/../mypath7/..\", False),\n]\n\n\n@pytest.mark.parametrize(\"basename, is_ok\", testdata)\ndef t"}, {"start_line": 3000, "end_line": 5000, "belongs_to": {"file_name": "test_tmpdir.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "        \"\"\"\n            def test_1(tmp_path):\n                assert 0 == 0\n            def test_2(tmp_path):\n                assert 0 == 1\n        \"\"\"\n        )\n        pytester.makepyprojecttoml(\n            \"\"\"\n            [tool.pytest.ini_options]\n            tmp_path_retention_policy = \"failed\"\n        \"\"\"\n        )\n\n        pytester.inline_run(p)\n        root = pytester._test_tmproot\n\n        for child in root.iterdir():\n            base_dir = list(\n                filter(lambda x: x.is_dir() and not x.is_symlink(), child.iterdir())\n            )\n            assert len(base_dir) == 1\n            test_dir = list(\n                filter(\n                    lambda x: x.is_dir() and not x.is_symlink(), base_dir[0].iterdir()\n                )\n            )\n            # Check only the failed one remains\n            assert len(test_dir) == 1\n            assert test_dir[0].name == \"test_20\"\n\n    def test_policy_failed_removes_basedir_when_all_passed(\n        self, pytester: Pytester\n    ) -> None:\n        p = pytester.makepyfile(\n            \"\"\"\n            def test_1(tmp_path):\n                assert 0 == 0\n        \"\"\"\n        )\n        pytester.makepyprojecttoml(\n            \"\"\"\n            [tool.pytest.ini_options]\n            tmp_path_retention_policy = \"failed\"\n        \"\"\"\n        )\n\n        pytester.inline_run(p)\n        root = pytester._test_tmproot\n        for child in root.iterdir():\n            # This symlink will be deleted by cleanup_numbered_dir **after**\n            # the test finishes because it's triggered by atexit.\n            # So it has to be ignored here.\n            base_dir = filter(lambda x: not x.is_symlink(), child.iterdir())\n            # Check the base dir itself is gone\n            assert len(list(base_dir)) == 0\n\n    # issue #10502\n    def test_policy_failed_removes_dir_when_skipped_from_fixture(\n        self, pytester: Pytester\n    ) -> None:\n        p = pytester.makepyfile(\n            \"\"\"\n            import pytest\n\n            @pytes"}, {"start_line": 16000, "end_line": 18000, "belongs_to": {"file_name": "test_tmpdir.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "s w:\n            exc_info4 = PermissionError()\n            on_rm_rf_error(os.open, str(fn), exc_info4, start_path=tmp_path)\n            assert fn.is_file()\n            assert not [x.message for x in w]\n\n        exc_info5 = PermissionError()\n        on_rm_rf_error(os.unlink, str(fn), exc_info5, start_path=tmp_path)\n        assert not fn.is_file()\n\n\ndef attempt_symlink_to(path, to_path):\n    \"\"\"Try to make a symlink from \"path\" to \"to_path\", skipping in case this platform\n    does not support it or we don't have sufficient privileges (common on Windows).\"\"\"\n    try:\n        Path(path).symlink_to(Path(to_path))\n    except OSError:\n        pytest.skip(\"could not create symbolic link\")\n\n\ndef test_basetemp_with_read_only_files(pytester: Pytester) -> None:\n    \"\"\"Integration test for #5524\"\"\"\n    pytester.makepyfile(\n        \"\"\"\n        import os\n        import stat\n\n        def test(tmp_path):\n            fn = tmp_path / 'foo.txt'\n            fn.write_text('hello', encoding='utf-8')\n            mode = os.stat(str(fn)).st_mode\n            os.chmod(str(fn), mode & ~stat.S_IREAD)\n    \"\"\"\n    )\n    result = pytester.runpytest(\"--basetemp=tmp\")\n    assert result.ret == 0\n    # running a second time and ensure we don't crash\n    result = pytester.runpytest(\"--basetemp=tmp\")\n    assert result.ret == 0\n\n\ndef test_tmp_path_factory_handles_invalid_dir_characters(\n    tmp_path_factory: TempPathFactory, monkeypatch: MonkeyPatch\n) -> None:\n    monkeypatch.setattr(\"getpass.getuser\", lambda: \"os/<:*?;>agnostic\")\n    # _basetemp / _given_basetemp are cached / set in parallel runs, patch them\n    monkeypatch.setattr(tmp_path_factory, \"_basetemp\", None)\n    monkeypatch.setattr(tmp_path_factory, \"_given_basetemp\", None)\n    p = tmp_path_factory.getbasetemp()\n    assert \"pytest-of-unknown\" in str(p)\n\n\n@pytest.mark.skipif(not hasattr(os, \"getuid\"), reason=\"checks unix permissions\")\ndef test_tmp_path_factory_create_directory_with_safe_permissions(\n    tmp_path: Path, monkeypatch: MonkeyPatch\n)"}, {"start_line": 2000, "end_line": 4000, "belongs_to": {"file_name": "test_legacypath.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": ")\n    dir = tmpdir_factory.mktemp(\"foo\")\n    assert dir.exists()\n\n\ndef test_tmpdir_equals_tmp_path(tmpdir: LEGACY_PATH, tmp_path: Path) -> None:\n    assert Path(tmpdir) == tmp_path\n\n\ndef test_tmpdir_always_is_realpath(pytester: pytest.Pytester) -> None:\n    # See test_tmp_path_always_is_realpath.\n    realtemp = pytester.mkdir(\"myrealtemp\")\n    linktemp = pytester.path.joinpath(\"symlinktemp\")\n    attempt_symlink_to(str(linktemp), str(realtemp))\n    p = pytester.makepyfile(\n        \"\"\"\n        def test_1(tmpdir):\n            import os\n            assert os.path.realpath(str(tmpdir)) == str(tmpdir)\n    \"\"\"\n    )\n    result = pytester.runpytest(\"-s\", p, f\"--basetemp={linktemp}/bt\")\n    assert not result.ret\n\n\ndef test_cache_makedir(cache: pytest.Cache) -> None:\n    dir = cache.makedir(\"foo\")  # type: ignore[attr-defined]\n    assert dir.exists()\n    dir.remove()\n\n\ndef test_fixturerequest_getmodulepath(pytester: pytest.Pytester) -> None:\n    modcol = pytester.getmodulecol(\"def test_somefunc(): pass\")\n    (item,) = pytester.genitems([modcol])\n    assert isinstance(item, pytest.Function)\n    req = TopRequest(item, _ispytest=True)\n    assert req.path == modcol.path\n    assert req.fspath == modcol.fspath  # type: ignore[attr-defined]\n\n\nclass TestFixtureRequestSessionScoped:\n    @pytest.fixture(scope=\"session\")\n    def session_request(self, request):\n        return request\n\n    def test_session_scoped_unavailable_attributes(self, session_request):\n        with pytest.raises(\n            AttributeError,\n            match=\"path not available in session-scoped context\",\n        ):\n            _ = session_request.fspath\n\n\n@pytest.mark.parametrize(\"config_type\", [\"ini\", \"pyproject\"])\ndef test_addini_paths(pytester: pytest.Pytester, config_type: str) -> None:\n    pytester.makeconftest(\n        \"\"\"\n        def pytest_addoption(parser):\n            parser.addini(\"paths\", \"my new ini value\", type=\"pathlist\")\n            parser.addini(\"abc\", \"abc value\")\n    \"\"\"\n    )\n    if config_type"}, {"start_line": 7000, "end_line": 9000, "belongs_to": {"file_name": "test_tmpdir.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "est_mktemp(pytester: Pytester, basename: str, is_ok: bool) -> None:\n    mytemp = pytester.mkdir(\"mytemp\")\n    p = pytester.makepyfile(\n        f\"\"\"\n        def test_abs_path(tmp_path_factory):\n            tmp_path_factory.mktemp('{basename}', numbered=False)\n        \"\"\"\n    )\n\n    result = pytester.runpytest(p, f\"--basetemp={mytemp}\")\n    if is_ok:\n        assert result.ret == 0\n        assert mytemp.joinpath(basename).exists()\n    else:\n        assert result.ret == 1\n        result.stdout.fnmatch_lines(\"*ValueError*\")\n\n\ndef test_tmp_path_always_is_realpath(pytester: Pytester, monkeypatch) -> None:\n    # the reason why tmp_path should be a realpath is that\n    # when you cd to it and do \"os.getcwd()\" you will anyway\n    # get the realpath.  Using the symlinked path can thus\n    # easily result in path-inequality\n    # XXX if that proves to be a problem, consider using\n    # os.environ[\"PWD\"]\n    realtemp = pytester.mkdir(\"myrealtemp\")\n    linktemp = pytester.path.joinpath(\"symlinktemp\")\n    attempt_symlink_to(linktemp, str(realtemp))\n    monkeypatch.setenv(\"PYTEST_DEBUG_TEMPROOT\", str(linktemp))\n    pytester.makepyfile(\n        \"\"\"\n        def test_1(tmp_path):\n            assert tmp_path.resolve() == tmp_path\n    \"\"\"\n    )\n    reprec = pytester.inline_run()\n    reprec.assertoutcome(passed=1)\n\n\ndef test_tmp_path_too_long_on_parametrization(pytester: Pytester) -> None:\n    pytester.makepyfile(\n        \"\"\"\n        import pytest\n        @pytest.mark.parametrize(\"arg\", [\"1\"*1000])\n        def test_some(arg, tmp_path):\n            tmp_path.joinpath(\"hello\").touch()\n    \"\"\"\n    )\n    reprec = pytester.inline_run()\n    reprec.assertoutcome(passed=1)\n\n\ndef test_tmp_path_factory(pytester: Pytester) -> None:\n    pytester.makepyfile(\n        \"\"\"\n        import pytest\n        @pytest.fixture(scope='session')\n        def session_dir(tmp_path_factory):\n            return tmp_path_factory.mktemp('data', numbered=False)\n        def test_some(session_dir):\n            assert session"}], "retrieved_count": 10, "cost_time": 0.3549230098724365}
{"question": "Where in the test_attr_hasmarkup function is the hasmarkup attribute of the TerminalWriter instance being bound to control the ANSI escape code injection behavior?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"start_line": 5000, "end_line": 7000, "belongs_to": {"file_name": "test_terminalwriter.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing/io", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": " native ansi\")\ndef test_attr_hasmarkup() -> None:\n    file = io.StringIO()\n    tw = terminalwriter.TerminalWriter(file)\n    assert not tw.hasmarkup\n    tw.hasmarkup = True\n    tw.line(\"hello\", bold=True)\n    s = file.getvalue()\n    assert len(s) > len(\"hello\\n\")\n    assert \"\\x1b[1m\" in s\n    assert \"\\x1b[0m\" in s\n\n\ndef assert_color(expected: bool, default: bool | None = None) -> None:\n    file = io.StringIO()\n    if default is None:\n        default = not expected\n    file.isatty = lambda: default  # type: ignore\n    tw = terminalwriter.TerminalWriter(file=file)\n    assert tw.hasmarkup is expected\n    tw.line(\"hello\", bold=True)\n    s = file.getvalue()\n    if expected:\n        assert len(s) > len(\"hello\\n\")\n        assert \"\\x1b[1m\" in s\n        assert \"\\x1b[0m\" in s\n    else:\n        assert s == \"hello\\n\"\n\n\ndef test_should_do_markup_PY_COLORS_eq_1(monkeypatch: MonkeyPatch) -> None:\n    monkeypatch.setitem(os.environ, \"PY_COLORS\", \"1\")\n    assert_color(True)\n\n\ndef test_should_not_do_markup_PY_COLORS_eq_0(monkeypatch: MonkeyPatch) -> None:\n    monkeypatch.setitem(os.environ, \"PY_COLORS\", \"0\")\n    assert_color(False)\n\n\ndef test_should_not_do_markup_NO_COLOR(monkeypatch: MonkeyPatch) -> None:\n    monkeypatch.setitem(os.environ, \"NO_COLOR\", \"1\")\n    assert_color(False)\n\n\ndef test_should_do_markup_FORCE_COLOR(monkeypatch: MonkeyPatch) -> None:\n    monkeypatch.setitem(os.environ, \"FORCE_COLOR\", \"1\")\n    assert_color(True)\n\n\n@pytest.mark.parametrize(\n    [\"NO_COLOR\", \"FORCE_COLOR\", \"expected\"],\n    [\n        (\"1\", \"1\", False),\n        (\"\", \"1\", True),\n        (\"1\", \"\", False),\n    ],\n)\ndef test_NO_COLOR_and_FORCE_COLOR(\n    monkeypatch: MonkeyPatch,\n    NO_COLOR: str,\n    FORCE_COLOR: str,\n    expected: bool,\n) -> None:\n    monkeypatch.setitem(os.environ, \"NO_COLOR\", NO_COLOR)\n    monkeypatch.setitem(os.environ, \"FORCE_COLOR\", FORCE_COLOR)\n    assert_color(expected)\n\n\ndef test_empty_NO_COLOR_and_FORCE_COLOR_ignored(monkeypatch: MonkeyPatch) -> None:\n    monkeypatch.setitem(o"}, {"start_line": 4000, "end_line": 6000, "belongs_to": {"file_name": "test_terminalwriter.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing/io", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": " @pytest.mark.parametrize(\"color\", (\"red\", \"green\"))\n    def test_markup(self, tw, bold: bool, color: str) -> None:\n        text = tw.markup(\"hello\", **{color: True, \"bold\": bold})\n        assert \"hello\" in text\n\n    def test_markup_bad(self, tw) -> None:\n        with pytest.raises(ValueError):\n            tw.markup(\"x\", wronkw=3)\n        with pytest.raises(ValueError):\n            tw.markup(\"x\", wronkw=0)\n\n    def test_line_write_markup(self, tw) -> None:\n        tw.hasmarkup = True\n        tw.line(\"x\", bold=True)\n        tw.write(\"x\\n\", red=True)\n        lines = tw.getlines()\n        if sys.platform != \"win32\":\n            assert len(lines[0]) >= 2, lines\n            assert len(lines[1]) >= 2, lines\n\n    def test_attr_fullwidth(self, tw) -> None:\n        tw.sep(\"-\", \"hello\", fullwidth=70)\n        tw.fullwidth = 70\n        tw.sep(\"-\", \"hello\")\n        lines = tw.getlines()\n        assert len(lines[0]) == len(lines[1])\n\n\n@pytest.mark.skipif(sys.platform == \"win32\", reason=\"win32 has no native ansi\")\ndef test_attr_hasmarkup() -> None:\n    file = io.StringIO()\n    tw = terminalwriter.TerminalWriter(file)\n    assert not tw.hasmarkup\n    tw.hasmarkup = True\n    tw.line(\"hello\", bold=True)\n    s = file.getvalue()\n    assert len(s) > len(\"hello\\n\")\n    assert \"\\x1b[1m\" in s\n    assert \"\\x1b[0m\" in s\n\n\ndef assert_color(expected: bool, default: bool | None = None) -> None:\n    file = io.StringIO()\n    if default is None:\n        default = not expected\n    file.isatty = lambda: default  # type: ignore\n    tw = terminalwriter.TerminalWriter(file=file)\n    assert tw.hasmarkup is expected\n    tw.line(\"hello\", bold=True)\n    s = file.getvalue()\n    if expected:\n        assert len(s) > len(\"hello\\n\")\n        assert \"\\x1b[1m\" in s\n        assert \"\\x1b[0m\" in s\n    else:\n        assert s == \"hello\\n\"\n\n\ndef test_should_do_markup_PY_COLORS_eq_1(monkeypatch: MonkeyPatch) -> None:\n    monkeypatch.setitem(os.environ, \"PY_COLORS\", \"1\")\n    assert_color(True)\n\n\ndef test_should_not_do_mark"}, {"start_line": 3000, "end_line": 5000, "belongs_to": {"file_name": "test_terminalwriter.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing/io", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "ert lines[0] == \"hello\\n\"\n\n    def test_line_unicode(self, tw) -> None:\n        msg = \"b\\u00f6y\"\n        tw.line(msg)\n        lines = tw.getlines()\n        assert lines[0] == msg + \"\\n\"\n\n    def test_sep_no_title(self, tw) -> None:\n        tw.sep(\"-\", fullwidth=60)\n        lines = tw.getlines()\n        assert len(lines) == 1\n        assert lines[0] == \"-\" * (60 - win32) + \"\\n\"\n\n    def test_sep_with_title(self, tw) -> None:\n        tw.sep(\"-\", \"hello\", fullwidth=60)\n        lines = tw.getlines()\n        assert len(lines) == 1\n        assert lines[0] == \"-\" * 26 + \" hello \" + \"-\" * (27 - win32) + \"\\n\"\n\n    def test_sep_longer_than_width(self, tw) -> None:\n        tw.sep(\"-\", \"a\" * 10, fullwidth=5)\n        (line,) = tw.getlines()\n        # even though the string is wider than the line, still have a separator\n        assert line == \"- aaaaaaaaaa -\\n\"\n\n    @pytest.mark.skipif(sys.platform == \"win32\", reason=\"win32 has no native ansi\")\n    @pytest.mark.parametrize(\"bold\", (True, False))\n    @pytest.mark.parametrize(\"color\", (\"red\", \"green\"))\n    def test_markup(self, tw, bold: bool, color: str) -> None:\n        text = tw.markup(\"hello\", **{color: True, \"bold\": bold})\n        assert \"hello\" in text\n\n    def test_markup_bad(self, tw) -> None:\n        with pytest.raises(ValueError):\n            tw.markup(\"x\", wronkw=3)\n        with pytest.raises(ValueError):\n            tw.markup(\"x\", wronkw=0)\n\n    def test_line_write_markup(self, tw) -> None:\n        tw.hasmarkup = True\n        tw.line(\"x\", bold=True)\n        tw.write(\"x\\n\", red=True)\n        lines = tw.getlines()\n        if sys.platform != \"win32\":\n            assert len(lines[0]) >= 2, lines\n            assert len(lines[1]) >= 2, lines\n\n    def test_attr_fullwidth(self, tw) -> None:\n        tw.sep(\"-\", \"hello\", fullwidth=70)\n        tw.fullwidth = 70\n        tw.sep(\"-\", \"hello\")\n        lines = tw.getlines()\n        assert len(lines[0]) == len(lines[1])\n\n\n@pytest.mark.skipif(sys.platform == \"win32\", reason=\"win32 has no"}, {"start_line": 7000, "end_line": 9000, "belongs_to": {"file_name": "test_terminalwriter.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing/io", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "s.environ, \"NO_COLOR\", \"\")\n    monkeypatch.setitem(os.environ, \"FORCE_COLOR\", \"\")\n    assert_color(True, True)\n    assert_color(False, False)\n\n\nclass TestTerminalWriterLineWidth:\n    def test_init(self) -> None:\n        tw = terminalwriter.TerminalWriter()\n        assert tw.width_of_current_line == 0\n\n    def test_update(self) -> None:\n        tw = terminalwriter.TerminalWriter()\n        tw.write(\"hello world\")\n        assert tw.width_of_current_line == 11\n\n    def test_update_with_newline(self) -> None:\n        tw = terminalwriter.TerminalWriter()\n        tw.write(\"hello\\nworld\")\n        assert tw.width_of_current_line == 5\n\n    def test_update_with_wide_text(self) -> None:\n        tw = terminalwriter.TerminalWriter()\n        tw.write(\" \")\n        assert tw.width_of_current_line == 21  # 5*2 + 1 + 5*2\n\n    def test_composed(self) -> None:\n        tw = terminalwriter.TerminalWriter()\n        text = \"caf food\"\n        assert len(text) == 9\n        tw.write(text)\n        assert tw.width_of_current_line == 9\n\n    def test_combining(self) -> None:\n        tw = terminalwriter.TerminalWriter()\n        text = \"cafe food\"\n        assert len(text) == 10\n        tw.write(text)\n        assert tw.width_of_current_line == 9\n\n\n@pytest.mark.parametrize(\n    (\"has_markup\", \"code_highlight\", \"expected\"),\n    [\n        pytest.param(\n            True,\n            True,\n            \"{reset}{kw}assert{hl-reset} {number}0{hl-reset}{endline}\\n\",\n            id=\"with markup and code_highlight\",\n        ),\n        pytest.param(\n            True,\n            False,\n            \"assert 0\\n\",\n            id=\"with markup but no code_highlight\",\n        ),\n        pytest.param(\n            False,\n            True,\n            \"assert 0\\n\",\n            id=\"without markup but with code_highlight\",\n        ),\n        pytest.param(\n            False,\n            False,\n            \"assert 0\\n\",\n            id=\"neither markup nor code_highlight\",\n        ),\n    ],\n)\ndef test_code_highligh"}, {"start_line": 6000, "end_line": 8000, "belongs_to": {"file_name": "test_terminalwriter.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing/io", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "up_PY_COLORS_eq_0(monkeypatch: MonkeyPatch) -> None:\n    monkeypatch.setitem(os.environ, \"PY_COLORS\", \"0\")\n    assert_color(False)\n\n\ndef test_should_not_do_markup_NO_COLOR(monkeypatch: MonkeyPatch) -> None:\n    monkeypatch.setitem(os.environ, \"NO_COLOR\", \"1\")\n    assert_color(False)\n\n\ndef test_should_do_markup_FORCE_COLOR(monkeypatch: MonkeyPatch) -> None:\n    monkeypatch.setitem(os.environ, \"FORCE_COLOR\", \"1\")\n    assert_color(True)\n\n\n@pytest.mark.parametrize(\n    [\"NO_COLOR\", \"FORCE_COLOR\", \"expected\"],\n    [\n        (\"1\", \"1\", False),\n        (\"\", \"1\", True),\n        (\"1\", \"\", False),\n    ],\n)\ndef test_NO_COLOR_and_FORCE_COLOR(\n    monkeypatch: MonkeyPatch,\n    NO_COLOR: str,\n    FORCE_COLOR: str,\n    expected: bool,\n) -> None:\n    monkeypatch.setitem(os.environ, \"NO_COLOR\", NO_COLOR)\n    monkeypatch.setitem(os.environ, \"FORCE_COLOR\", FORCE_COLOR)\n    assert_color(expected)\n\n\ndef test_empty_NO_COLOR_and_FORCE_COLOR_ignored(monkeypatch: MonkeyPatch) -> None:\n    monkeypatch.setitem(os.environ, \"NO_COLOR\", \"\")\n    monkeypatch.setitem(os.environ, \"FORCE_COLOR\", \"\")\n    assert_color(True, True)\n    assert_color(False, False)\n\n\nclass TestTerminalWriterLineWidth:\n    def test_init(self) -> None:\n        tw = terminalwriter.TerminalWriter()\n        assert tw.width_of_current_line == 0\n\n    def test_update(self) -> None:\n        tw = terminalwriter.TerminalWriter()\n        tw.write(\"hello world\")\n        assert tw.width_of_current_line == 11\n\n    def test_update_with_newline(self) -> None:\n        tw = terminalwriter.TerminalWriter()\n        tw.write(\"hello\\nworld\")\n        assert tw.width_of_current_line == 5\n\n    def test_update_with_wide_text(self) -> None:\n        tw = terminalwriter.TerminalWriter()\n        tw.write(\" \")\n        assert tw.width_of_current_line == 21  # 5*2 + 1 + 5*2\n\n    def test_composed(self) -> None:\n        tw = terminalwriter.TerminalWriter()\n        text = \"caf food\"\n        assert len(text) == 9\n        tw.write(text)\n        asser"}, {"start_line": 11000, "end_line": 13000, "belongs_to": {"file_name": "test_terminal.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "st_foobar():\n                pass\n        \"\"\"\n        )\n        result = pytester.runpytest()\n        result.stdout.fnmatch_lines([\"collected 1 item\"])\n\n    def test_rewrite(self, pytester: Pytester, monkeypatch) -> None:\n        config = pytester.parseconfig()\n        f = StringIO()\n        monkeypatch.setattr(f, \"isatty\", lambda *args: True)\n        tr = TerminalReporter(config, f)\n        tr._tw.fullwidth = 10\n        tr.write(\"hello\")\n        tr.rewrite(\"hey\", erase=True)\n        assert f.getvalue() == \"hello\" + \"\\r\" + \"hey\" + (6 * \" \")\n\n    @pytest.mark.parametrize(\"category\", [\"foo\", \"failed\", \"error\", \"passed\"])\n    def test_report_teststatus_explicit_markup(\n        self, monkeypatch: MonkeyPatch, pytester: Pytester, color_mapping, category: str\n    ) -> None:\n        \"\"\"Test that TerminalReporter handles markup explicitly provided by\n        a pytest_report_teststatus hook.\"\"\"\n        monkeypatch.setenv(\"PY_COLORS\", \"1\")\n        pytester.makeconftest(\n            f\"\"\"\n            def pytest_report_teststatus(report):\n                return {category!r}, 'F', ('FOO', {{'red': True}})\n        \"\"\"\n        )\n        pytester.makepyfile(\n            \"\"\"\n            def test_foobar():\n                pass\n        \"\"\"\n        )\n\n        result = pytester.runpytest(\"-v\")\n        assert not result.stderr.lines\n        result.stdout.fnmatch_lines(\n            color_mapping.format_for_fnmatch([\"*{red}FOO{reset}*\"])\n        )\n\n    def test_verbose_skip_reason(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n\n            @pytest.mark.skip(reason=\"123\")\n            def test_1():\n                pass\n\n            @pytest.mark.xfail(reason=\"456\")\n            def test_2():\n                pass\n\n            @pytest.mark.xfail(reason=\"789\")\n            def test_3():\n                assert False\n\n            @pytest.mark.xfail(reason=\"\")\n            def test_4():\n                assert False\n\n            @pytest.mark.ski"}, {"start_line": 1000, "end_line": 3000, "belongs_to": {"file_name": "test_terminalwriter.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing/io", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "al_width\", lambda: 42)\n    tw = terminalwriter.TerminalWriter()\n    assert tw.fullwidth == 42\n\n\ndef test_terminalwriter_dumb_term_no_markup(monkeypatch: MonkeyPatch) -> None:\n    monkeypatch.setattr(os, \"environ\", {\"TERM\": \"dumb\", \"PATH\": \"\"})\n\n    class MyFile:\n        closed = False\n\n        def isatty(self):\n            return True\n\n    with monkeypatch.context() as m:\n        m.setattr(sys, \"stdout\", MyFile())\n        assert sys.stdout.isatty()\n        tw = terminalwriter.TerminalWriter()\n        assert not tw.hasmarkup\n\n\ndef test_terminalwriter_not_unicode() -> None:\n    \"\"\"If the file doesn't support Unicode, the string is unicode-escaped (#7475).\"\"\"\n    buffer = io.BytesIO()\n    file = io.TextIOWrapper(buffer, encoding=\"cp1252\")\n    tw = terminalwriter.TerminalWriter(file)\n    tw.write(\"hello  wrld \", flush=True)\n    assert buffer.getvalue() == rb\"hello \\U0001f300 w\\xf4rld \\u05d0\\u05d1\\u05d2\"\n\n\nwin32 = int(sys.platform == \"win32\")\n\n\nclass TestTerminalWriter:\n    @pytest.fixture(params=[\"path\", \"stringio\"])\n    def tw(self, request, tmp_path: Path) -> Generator[terminalwriter.TerminalWriter]:\n        f: io.TextIOWrapper | StringIO\n        if request.param == \"path\":\n            p = tmp_path.joinpath(\"tmpfile\")\n            f = open(str(p), \"w+\", encoding=\"utf8\")\n            tw = terminalwriter.TerminalWriter(f)\n\n            def getlines():\n                f.flush()\n                with open(str(p), encoding=\"utf8\") as fp:\n                    return fp.readlines()\n\n        elif request.param == \"stringio\":\n            f = io.StringIO()\n            tw = terminalwriter.TerminalWriter(f)\n\n            def getlines():\n                f.seek(0)\n                return f.readlines()\n\n        tw.getlines = getlines  # type: ignore\n        tw.getvalue = lambda: \"\".join(getlines())  # type: ignore\n\n        with f:\n            yield tw\n\n    def test_line(self, tw) -> None:\n        tw.line(\"hello\")\n        lines = tw.getlines()\n        assert len(lines) == 1\n        ass"}, {"start_line": 0, "end_line": 2000, "belongs_to": {"file_name": "test_terminalwriter.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing/io", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "# mypy: allow-untyped-defs\nfrom __future__ import annotations\n\nfrom collections.abc import Generator\nimport io\nfrom io import StringIO\nimport os\nfrom pathlib import Path\nimport re\nimport shutil\nimport sys\nfrom unittest import mock\n\nfrom _pytest._io import terminalwriter\nfrom _pytest.monkeypatch import MonkeyPatch\nimport pytest\n\n\n# These tests were initially copied from py 1.8.1.\n\n\ndef test_terminal_width_COLUMNS(monkeypatch: MonkeyPatch) -> None:\n    monkeypatch.setenv(\"COLUMNS\", \"42\")\n    assert terminalwriter.get_terminal_width() == 42\n    monkeypatch.delenv(\"COLUMNS\", raising=False)\n\n\ndef test_terminalwriter_width_bogus(monkeypatch: MonkeyPatch) -> None:\n    monkeypatch.setattr(shutil, \"get_terminal_size\", mock.Mock(return_value=(10, 10)))\n    monkeypatch.delenv(\"COLUMNS\", raising=False)\n    tw = terminalwriter.TerminalWriter()\n    assert tw.fullwidth == 80\n\n\ndef test_terminalwriter_computes_width(monkeypatch: MonkeyPatch) -> None:\n    monkeypatch.setattr(terminalwriter, \"get_terminal_width\", lambda: 42)\n    tw = terminalwriter.TerminalWriter()\n    assert tw.fullwidth == 42\n\n\ndef test_terminalwriter_dumb_term_no_markup(monkeypatch: MonkeyPatch) -> None:\n    monkeypatch.setattr(os, \"environ\", {\"TERM\": \"dumb\", \"PATH\": \"\"})\n\n    class MyFile:\n        closed = False\n\n        def isatty(self):\n            return True\n\n    with monkeypatch.context() as m:\n        m.setattr(sys, \"stdout\", MyFile())\n        assert sys.stdout.isatty()\n        tw = terminalwriter.TerminalWriter()\n        assert not tw.hasmarkup\n\n\ndef test_terminalwriter_not_unicode() -> None:\n    \"\"\"If the file doesn't support Unicode, the string is unicode-escaped (#7475).\"\"\"\n    buffer = io.BytesIO()\n    file = io.TextIOWrapper(buffer, encoding=\"cp1252\")\n    tw = terminalwriter.TerminalWriter(file)\n    tw.write(\"hello  wrld \", flush=True)\n    assert buffer.getvalue() == rb\"hello \\U0001f300 w\\xf4rld \\u05d0\\u05d1\\u05d2\"\n\n\nwin32 = int(sys.platform == \"win32\")\n\n\nclass TestTerminalWriter:\n    @pytest.fix"}, {"start_line": 2000, "end_line": 4000, "belongs_to": {"file_name": "test_terminalwriter.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing/io", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "ture(params=[\"path\", \"stringio\"])\n    def tw(self, request, tmp_path: Path) -> Generator[terminalwriter.TerminalWriter]:\n        f: io.TextIOWrapper | StringIO\n        if request.param == \"path\":\n            p = tmp_path.joinpath(\"tmpfile\")\n            f = open(str(p), \"w+\", encoding=\"utf8\")\n            tw = terminalwriter.TerminalWriter(f)\n\n            def getlines():\n                f.flush()\n                with open(str(p), encoding=\"utf8\") as fp:\n                    return fp.readlines()\n\n        elif request.param == \"stringio\":\n            f = io.StringIO()\n            tw = terminalwriter.TerminalWriter(f)\n\n            def getlines():\n                f.seek(0)\n                return f.readlines()\n\n        tw.getlines = getlines  # type: ignore\n        tw.getvalue = lambda: \"\".join(getlines())  # type: ignore\n\n        with f:\n            yield tw\n\n    def test_line(self, tw) -> None:\n        tw.line(\"hello\")\n        lines = tw.getlines()\n        assert len(lines) == 1\n        assert lines[0] == \"hello\\n\"\n\n    def test_line_unicode(self, tw) -> None:\n        msg = \"b\\u00f6y\"\n        tw.line(msg)\n        lines = tw.getlines()\n        assert lines[0] == msg + \"\\n\"\n\n    def test_sep_no_title(self, tw) -> None:\n        tw.sep(\"-\", fullwidth=60)\n        lines = tw.getlines()\n        assert len(lines) == 1\n        assert lines[0] == \"-\" * (60 - win32) + \"\\n\"\n\n    def test_sep_with_title(self, tw) -> None:\n        tw.sep(\"-\", \"hello\", fullwidth=60)\n        lines = tw.getlines()\n        assert len(lines) == 1\n        assert lines[0] == \"-\" * 26 + \" hello \" + \"-\" * (27 - win32) + \"\\n\"\n\n    def test_sep_longer_than_width(self, tw) -> None:\n        tw.sep(\"-\", \"a\" * 10, fullwidth=5)\n        (line,) = tw.getlines()\n        # even though the string is wider than the line, still have a separator\n        assert line == \"- aaaaaaaaaa -\\n\"\n\n    @pytest.mark.skipif(sys.platform == \"win32\", reason=\"win32 has no native ansi\")\n    @pytest.mark.parametrize(\"bold\", (True, False))\n   "}, {"start_line": 10000, "end_line": 12000, "belongs_to": {"file_name": "test_terminal.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "_lines(\n                [\"*raise KeyboardInterrupt   # simulating the user*\"]\n            )\n        else:\n            result.stdout.fnmatch_lines(\n                [\"(to show a full traceback on KeyboardInterrupt use --full-trace)\"]\n            )\n        result.stdout.fnmatch_lines([\"*KeyboardInterrupt*\"])\n\n    def test_keyboard_in_sessionstart(self, pytester: Pytester) -> None:\n        pytester.makeconftest(\n            \"\"\"\n            def pytest_sessionstart():\n                raise KeyboardInterrupt\n        \"\"\"\n        )\n        pytester.makepyfile(\n            \"\"\"\n            def test_foobar():\n                pass\n        \"\"\"\n        )\n\n        result = pytester.runpytest(no_reraise_ctrlc=True)\n        assert result.ret == 2\n        result.stdout.fnmatch_lines([\"*KeyboardInterrupt*\"])\n\n    def test_collect_single_item(self, pytester: Pytester) -> None:\n        \"\"\"Use singular 'item' when reporting a single test item\"\"\"\n        pytester.makepyfile(\n            \"\"\"\n            def test_foobar():\n                pass\n        \"\"\"\n        )\n        result = pytester.runpytest()\n        result.stdout.fnmatch_lines([\"collected 1 item\"])\n\n    def test_rewrite(self, pytester: Pytester, monkeypatch) -> None:\n        config = pytester.parseconfig()\n        f = StringIO()\n        monkeypatch.setattr(f, \"isatty\", lambda *args: True)\n        tr = TerminalReporter(config, f)\n        tr._tw.fullwidth = 10\n        tr.write(\"hello\")\n        tr.rewrite(\"hey\", erase=True)\n        assert f.getvalue() == \"hello\" + \"\\r\" + \"hey\" + (6 * \" \")\n\n    @pytest.mark.parametrize(\"category\", [\"foo\", \"failed\", \"error\", \"passed\"])\n    def test_report_teststatus_explicit_markup(\n        self, monkeypatch: MonkeyPatch, pytester: Pytester, color_mapping, category: str\n    ) -> None:\n        \"\"\"Test that TerminalReporter handles markup explicitly provided by\n        a pytest_report_teststatus hook.\"\"\"\n        monkeypatch.setenv(\"PY_COLORS\", \"1\")\n        pytester.makeconftest(\n            f\"\"\"\n        "}], "retrieved_count": 10, "cost_time": 0.34200453758239746}
{"question": "Where is the line-wrapping logic that determines when function arguments exceed terminal width implemented in the ReprFuncArgs class?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"start_line": 8000, "end_line": 10000, "belongs_to": {"file_name": "pprint.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest/_io", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "s[-1]\n                parts.pop()  # drop empty last part\n                max_width2 = max_width\n                current = \"\"\n                for j, part in enumerate(parts):\n                    candidate = current + part\n                    if j == len(parts) - 1 and i == len(lines) - 1:\n                        max_width2 -= allowance\n                    if len(repr(candidate)) > max_width2:\n                        if current:\n                            chunks.append(repr(current))\n                        current = part\n                    else:\n                        current = candidate\n                if current:\n                    chunks.append(repr(current))\n        if len(chunks) == 1:\n            write(rep)\n            return\n        if level == 1:\n            write(\"(\")\n        for i, rep in enumerate(chunks):\n            if i > 0:\n                write(\"\\n\" + \" \" * indent)\n            write(rep)\n        if level == 1:\n            write(\")\")\n\n    _dispatch[str.__repr__] = _pprint_str\n\n    def _pprint_bytes(\n        self,\n        object: Any,\n        stream: IO[str],\n        indent: int,\n        allowance: int,\n        context: set[int],\n        level: int,\n    ) -> None:\n        write = stream.write\n        if len(object) <= 4:\n            write(repr(object))\n            return\n        parens = level == 1\n        if parens:\n            indent += 1\n            allowance += 1\n            write(\"(\")\n        delim = \"\"\n        for rep in _wrap_bytes_repr(object, self._width - indent, allowance):\n            write(delim)\n            write(rep)\n            if not delim:\n                delim = \"\\n\" + \" \" * indent\n        if parens:\n            write(\")\")\n\n    _dispatch[bytes.__repr__] = _pprint_bytes\n\n    def _pprint_bytearray(\n        self,\n        object: Any,\n        stream: IO[str],\n        indent: int,\n        allowance: int,\n        context: set[int],\n        level: int,\n    ) -> None:\n        write = stream.write\n        write(\"bytearray(\")\n        self."}, {"start_line": 26000, "end_line": 28000, "belongs_to": {"file_name": "test_excinfo.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing/code", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "rld\")'\n        assert lines[2] == \"E       ValueError: hello\"\n        assert lines[3] == \"E       world\"\n        assert not lines[4:]\n\n        loc = repr_entry.reprfileloc\n        assert loc is not None\n        assert loc.path == mod.__file__\n        assert loc.lineno == 3\n        # assert loc.message == \"ValueError: hello\"\n\n    def test_repr_tracebackentry_lines2(self, importasmod, tw_mock) -> None:\n        mod = importasmod(\n            \"\"\"\n            def func1(m, x, y, z):\n                raise ValueError(\"hello\\\\nworld\")\n        \"\"\"\n        )\n        excinfo = pytest.raises(ValueError, mod.func1, \"m\" * 90, 5, 13, \"z\" * 120)\n        excinfo.traceback = excinfo.traceback.filter(excinfo)\n        entry = excinfo.traceback[-1]\n        p = FormattedExcinfo(funcargs=True)\n        reprfuncargs = p.repr_args(entry)\n        assert reprfuncargs is not None\n        assert reprfuncargs.args[0] == (\"m\", repr(\"m\" * 90))\n        assert reprfuncargs.args[1] == (\"x\", \"5\")\n        assert reprfuncargs.args[2] == (\"y\", \"13\")\n        assert reprfuncargs.args[3] == (\"z\", repr(\"z\" * 120))\n\n        p = FormattedExcinfo(funcargs=True)\n        repr_entry = p.repr_traceback_entry(entry)\n        assert repr_entry.reprfuncargs is not None\n        assert repr_entry.reprfuncargs.args == reprfuncargs.args\n        repr_entry.toterminal(tw_mock)\n        assert tw_mock.lines[0] == \"m = \" + repr(\"m\" * 90)\n        assert tw_mock.lines[1] == \"x = 5, y = 13\"\n        assert tw_mock.lines[2] == \"z = \" + repr(\"z\" * 120)\n\n    def test_repr_tracebackentry_lines_var_kw_args(self, importasmod, tw_mock) -> None:\n        mod = importasmod(\n            \"\"\"\n            def func1(x, *y, **z):\n                raise ValueError(\"hello\\\\nworld\")\n        \"\"\"\n        )\n        excinfo = pytest.raises(ValueError, mod.func1, \"a\", \"b\", c=\"d\")\n        excinfo.traceback = excinfo.traceback.filter(excinfo)\n        entry = excinfo.traceback[-1]\n        p = FormattedExcinfo(funcargs=True)\n        reprfuncargs = p.repr_args(en"}, {"start_line": 7000, "end_line": 9000, "belongs_to": {"file_name": "pprint.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest/_io", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "dchar)\n\n    _dispatch[set.__repr__] = _pprint_set\n    _dispatch[frozenset.__repr__] = _pprint_set\n\n    def _pprint_str(\n        self,\n        object: Any,\n        stream: IO[str],\n        indent: int,\n        allowance: int,\n        context: set[int],\n        level: int,\n    ) -> None:\n        write = stream.write\n        if not len(object):\n            write(repr(object))\n            return\n        chunks = []\n        lines = object.splitlines(True)\n        if level == 1:\n            indent += 1\n            allowance += 1\n        max_width1 = max_width = self._width - indent\n        for i, line in enumerate(lines):\n            rep = repr(line)\n            if i == len(lines) - 1:\n                max_width1 -= allowance\n            if len(rep) <= max_width1:\n                chunks.append(rep)\n            else:\n                # A list of alternating (non-space, space) strings\n                parts = re.findall(r\"\\S*\\s*\", line)\n                assert parts\n                assert not parts[-1]\n                parts.pop()  # drop empty last part\n                max_width2 = max_width\n                current = \"\"\n                for j, part in enumerate(parts):\n                    candidate = current + part\n                    if j == len(parts) - 1 and i == len(lines) - 1:\n                        max_width2 -= allowance\n                    if len(repr(candidate)) > max_width2:\n                        if current:\n                            chunks.append(repr(current))\n                        current = part\n                    else:\n                        current = candidate\n                if current:\n                    chunks.append(repr(current))\n        if len(chunks) == 1:\n            write(rep)\n            return\n        if level == 1:\n            write(\"(\")\n        for i, rep in enumerate(chunks):\n            if i > 0:\n                write(\"\\n\" + \" \" * indent)\n            write(rep)\n        if level == 1:\n            write(\")\")\n\n    _dispatch[str.__repr__] = _p"}, {"start_line": 52000, "end_line": 54000, "belongs_to": {"file_name": "code.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest/_code", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "lRepr):\n    lines: Sequence[str]\n\n    def toterminal(self, tw: TerminalWriter, indent=\"\") -> None:\n        for line in self.lines:\n            tw.line(indent + line)\n\n\n@dataclasses.dataclass(eq=False)\nclass ReprFuncArgs(TerminalRepr):\n    args: Sequence[tuple[str, object]]\n\n    def toterminal(self, tw: TerminalWriter) -> None:\n        if self.args:\n            linesofar = \"\"\n            for name, value in self.args:\n                ns = f\"{name} = {value}\"\n                if len(ns) + len(linesofar) + 2 > tw.fullwidth:\n                    if linesofar:\n                        tw.line(linesofar)\n                    linesofar = ns\n                else:\n                    if linesofar:\n                        linesofar += \", \" + ns\n                    else:\n                        linesofar = ns\n            if linesofar:\n                tw.line(linesofar)\n            tw.line(\"\")\n\n\ndef getfslineno(obj: object) -> tuple[str | Path, int]:\n    \"\"\"Return source location (path, lineno) for the given object.\n\n    If the source cannot be determined return (\"\", -1).\n\n    The line number is 0-based.\n    \"\"\"\n    # xxx let decorators etc specify a sane ordering\n    # NOTE: this used to be done in _pytest.compat.getfslineno, initially added\n    #       in 6ec13a2b9.  It (\"place_as\") appears to be something very custom.\n    obj = get_real_func(obj)\n    if hasattr(obj, \"place_as\"):\n        obj = obj.place_as\n\n    try:\n        code = Code.from_function(obj)\n    except TypeError:\n        try:\n            fn = inspect.getsourcefile(obj) or inspect.getfile(obj)  # type: ignore[arg-type]\n        except TypeError:\n            return \"\", -1\n\n        fspath = (fn and absolutepath(fn)) or \"\"\n        lineno = -1\n        if fspath:\n            try:\n                _, lineno = findsource(obj)\n            except OSError:\n                pass\n        return fspath, lineno\n\n    return code.path, code.firstlineno\n\n\ndef _byte_offset_to_character_offset(str, offset):\n    \"\"\"Converts a byte based offs"}, {"start_line": 27000, "end_line": 29000, "belongs_to": {"file_name": "test_excinfo.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing/code", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "s.args[2] == (\"y\", \"13\")\n        assert reprfuncargs.args[3] == (\"z\", repr(\"z\" * 120))\n\n        p = FormattedExcinfo(funcargs=True)\n        repr_entry = p.repr_traceback_entry(entry)\n        assert repr_entry.reprfuncargs is not None\n        assert repr_entry.reprfuncargs.args == reprfuncargs.args\n        repr_entry.toterminal(tw_mock)\n        assert tw_mock.lines[0] == \"m = \" + repr(\"m\" * 90)\n        assert tw_mock.lines[1] == \"x = 5, y = 13\"\n        assert tw_mock.lines[2] == \"z = \" + repr(\"z\" * 120)\n\n    def test_repr_tracebackentry_lines_var_kw_args(self, importasmod, tw_mock) -> None:\n        mod = importasmod(\n            \"\"\"\n            def func1(x, *y, **z):\n                raise ValueError(\"hello\\\\nworld\")\n        \"\"\"\n        )\n        excinfo = pytest.raises(ValueError, mod.func1, \"a\", \"b\", c=\"d\")\n        excinfo.traceback = excinfo.traceback.filter(excinfo)\n        entry = excinfo.traceback[-1]\n        p = FormattedExcinfo(funcargs=True)\n        reprfuncargs = p.repr_args(entry)\n        assert reprfuncargs is not None\n        assert reprfuncargs.args[0] == (\"x\", repr(\"a\"))\n        assert reprfuncargs.args[1] == (\"y\", repr((\"b\",)))\n        assert reprfuncargs.args[2] == (\"z\", repr({\"c\": \"d\"}))\n\n        p = FormattedExcinfo(funcargs=True)\n        repr_entry = p.repr_traceback_entry(entry)\n        assert repr_entry.reprfuncargs\n        assert repr_entry.reprfuncargs.args == reprfuncargs.args\n        repr_entry.toterminal(tw_mock)\n        assert tw_mock.lines[0] == \"x = 'a', y = ('b',), z = {'c': 'd'}\"\n\n    def test_repr_tracebackentry_short(self, importasmod) -> None:\n        mod = importasmod(\n            \"\"\"\n            def func1():\n                raise ValueError(\"hello\")\n            def entry():\n                func1()\n        \"\"\"\n        )\n        excinfo = pytest.raises(ValueError, mod.entry)\n        p = FormattedExcinfo(style=\"short\")\n        reprtb = p.repr_traceback_entry(excinfo.traceback[-2])\n        lines = reprtb.lines\n        basename = Path(m"}, {"start_line": 49000, "end_line": 51000, "belongs_to": {"file_name": "code.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest/_code", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "      character, as doing so might break line continuations.\n        \"\"\"\n        if not self.lines:\n            return\n\n        if self.style == \"value\":\n            # Using tw.write instead of tw.line for testing purposes due to TWMock implementation;\n            # lines written with TWMock.line and TWMock._write_source cannot be distinguished\n            # from each other, whereas lines written with TWMock.write are marked with TWMock.WRITE\n            for line in self.lines:\n                tw.write(line)\n                tw.write(\"\\n\")\n            return\n\n        # separate indents and source lines that are not failures: we want to\n        # highlight the code but not the indentation, which may contain markers\n        # such as \">   assert 0\"\n        fail_marker = f\"{FormattedExcinfo.fail_marker}   \"\n        indent_size = len(fail_marker)\n        indents: list[str] = []\n        source_lines: list[str] = []\n        failure_lines: list[str] = []\n        for index, line in enumerate(self.lines):\n            is_failure_line = line.startswith(fail_marker)\n            if is_failure_line:\n                # from this point on all lines are considered part of the failure\n                failure_lines.extend(self.lines[index:])\n                break\n            else:\n                indents.append(line[:indent_size])\n                source_lines.append(line[indent_size:])\n\n        tw._write_source(source_lines, indents)\n\n        # failure lines are always completely red and bold\n        for line in failure_lines:\n            tw.line(line, bold=True, red=True)\n\n    def toterminal(self, tw: TerminalWriter) -> None:\n        if self.style == \"short\":\n            if self.reprfileloc:\n                self.reprfileloc.toterminal(tw)\n            self._write_entry_lines(tw)\n            if self.reprlocals:\n                self.reprlocals.toterminal(tw, indent=\" \" * 8)\n            return\n\n        if self.reprfuncargs:\n            self.reprfuncargs.toterminal(tw)\n\n        self._write_"}, {"start_line": 18000, "end_line": 19622, "belongs_to": {"file_name": "pprint.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest/_io", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "is tuple.__repr__\n        ):\n            if issubclass(typ, list):\n                if not object:\n                    return \"[]\"\n                format = \"[%s]\"\n            elif len(object) == 1:\n                format = \"(%s,)\"\n            else:\n                if not object:\n                    return \"()\"\n                format = \"(%s)\"\n            objid = id(object)\n            if maxlevels and level >= maxlevels:\n                return format % \"...\"\n            if objid in context:\n                return _recursion(object)\n            context.add(objid)\n            components = []\n            append = components.append\n            level += 1\n            for o in object:\n                orepr = self._safe_repr(o, context, maxlevels, level)\n                append(orepr)\n            context.remove(objid)\n            return format % \", \".join(components)\n\n        return repr(object)\n\n\n_builtin_scalars = frozenset(\n    {str, bytes, bytearray, float, complex, bool, type(None), int}\n)\n\n\ndef _recursion(object: Any) -> str:\n    return f\"<Recursion on {type(object).__name__} with id={id(object)}>\"\n\n\ndef _wrap_bytes_repr(object: Any, width: int, allowance: int) -> Iterator[str]:\n    current = b\"\"\n    last = len(object) // 4 * 4\n    for i in range(0, len(object), 4):\n        part = object[i : i + 4]\n        candidate = current + part\n        if i == last:\n            width -= allowance\n        if len(repr(candidate)) > width:\n            if current:\n                yield repr(current)\n            current = part\n        else:\n            current = candidate\n    if current:\n        yield repr(current)\n"}, {"start_line": 23000, "end_line": 25000, "belongs_to": {"file_name": "test_excinfo.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing/code", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "oom!\")\n\n        class ObjWithErrorInRepr:\n            def __repr__(self):\n                raise ExceptionWithBrokenClass()\n\n        p = FormattedExcinfo(showlocals=True, truncate_locals=False)\n        loc = {\"x\": ObjWithErrorInRepr(), \"__builtins__\": {}}\n        reprlocals = p.repr_locals(loc)\n        assert reprlocals is not None\n        assert reprlocals.lines\n        assert reprlocals.lines[0] == \"__builtins__ = <builtins>\"\n        assert \"[ExceptionWithBrokenClass() raised in repr()]\" in reprlocals.lines[1]\n\n    def test_repr_local_truncated(self) -> None:\n        loc = {\"l\": [i for i in range(10)]}\n        p = FormattedExcinfo(showlocals=True)\n        truncated_reprlocals = p.repr_locals(loc)\n        assert truncated_reprlocals is not None\n        assert truncated_reprlocals.lines\n        assert truncated_reprlocals.lines[0] == \"l          = [0, 1, 2, 3, 4, 5, ...]\"\n\n        q = FormattedExcinfo(showlocals=True, truncate_locals=False)\n        full_reprlocals = q.repr_locals(loc)\n        assert full_reprlocals is not None\n        assert full_reprlocals.lines\n        assert full_reprlocals.lines[0] == \"l          = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\"\n\n    def test_repr_args_not_truncated(self, importasmod) -> None:\n        mod = importasmod(\n            \"\"\"\n            def func1(m):\n                raise ValueError(\"hello\\\\nworld\")\n        \"\"\"\n        )\n        excinfo = pytest.raises(ValueError, mod.func1, \"m\" * 500)\n        excinfo.traceback = excinfo.traceback.filter(excinfo)\n        entry = excinfo.traceback[-1]\n        p = FormattedExcinfo(funcargs=True, truncate_args=True)\n        reprfuncargs = p.repr_args(entry)\n        assert reprfuncargs is not None\n        arg1 = cast(str, reprfuncargs.args[0][1])\n        assert len(arg1) < 500\n        assert \"...\" in arg1\n        # again without truncate\n        p = FormattedExcinfo(funcargs=True, truncate_args=False)\n        reprfuncargs = p.repr_args(entry)\n        assert reprfuncargs is not None\n        assert reprfunc"}, {"start_line": 24000, "end_line": 26000, "belongs_to": {"file_name": "test_excinfo.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing/code", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "       assert full_reprlocals is not None\n        assert full_reprlocals.lines\n        assert full_reprlocals.lines[0] == \"l          = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\"\n\n    def test_repr_args_not_truncated(self, importasmod) -> None:\n        mod = importasmod(\n            \"\"\"\n            def func1(m):\n                raise ValueError(\"hello\\\\nworld\")\n        \"\"\"\n        )\n        excinfo = pytest.raises(ValueError, mod.func1, \"m\" * 500)\n        excinfo.traceback = excinfo.traceback.filter(excinfo)\n        entry = excinfo.traceback[-1]\n        p = FormattedExcinfo(funcargs=True, truncate_args=True)\n        reprfuncargs = p.repr_args(entry)\n        assert reprfuncargs is not None\n        arg1 = cast(str, reprfuncargs.args[0][1])\n        assert len(arg1) < 500\n        assert \"...\" in arg1\n        # again without truncate\n        p = FormattedExcinfo(funcargs=True, truncate_args=False)\n        reprfuncargs = p.repr_args(entry)\n        assert reprfuncargs is not None\n        assert reprfuncargs.args[0] == (\"m\", repr(\"m\" * 500))\n        assert \"...\" not in cast(str, reprfuncargs.args[0][1])\n\n    def test_repr_tracebackentry_lines(self, importasmod) -> None:\n        mod = importasmod(\n            \"\"\"\n            def func1():\n                raise ValueError(\"hello\\\\nworld\")\n        \"\"\"\n        )\n        excinfo = pytest.raises(ValueError, mod.func1)\n        excinfo.traceback = excinfo.traceback.filter(excinfo)\n        p = FormattedExcinfo()\n        reprtb = p.repr_traceback_entry(excinfo.traceback[-1])\n\n        # test as intermittent entry\n        lines = reprtb.lines\n        assert lines[0] == \"    def func1():\"\n        assert lines[1] == '>       raise ValueError(\"hello\\\\nworld\")'\n\n        # test as last entry\n        p = FormattedExcinfo(showlocals=True)\n        repr_entry = p.repr_traceback_entry(excinfo.traceback[-1], excinfo)\n        lines = repr_entry.lines\n        assert lines[0] == \"    def func1():\"\n        assert lines[1] == '>       raise ValueError(\"hello\\\\nwo"}, {"start_line": 25000, "end_line": 27000, "belongs_to": {"file_name": "test_excinfo.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing/code", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "args.args[0] == (\"m\", repr(\"m\" * 500))\n        assert \"...\" not in cast(str, reprfuncargs.args[0][1])\n\n    def test_repr_tracebackentry_lines(self, importasmod) -> None:\n        mod = importasmod(\n            \"\"\"\n            def func1():\n                raise ValueError(\"hello\\\\nworld\")\n        \"\"\"\n        )\n        excinfo = pytest.raises(ValueError, mod.func1)\n        excinfo.traceback = excinfo.traceback.filter(excinfo)\n        p = FormattedExcinfo()\n        reprtb = p.repr_traceback_entry(excinfo.traceback[-1])\n\n        # test as intermittent entry\n        lines = reprtb.lines\n        assert lines[0] == \"    def func1():\"\n        assert lines[1] == '>       raise ValueError(\"hello\\\\nworld\")'\n\n        # test as last entry\n        p = FormattedExcinfo(showlocals=True)\n        repr_entry = p.repr_traceback_entry(excinfo.traceback[-1], excinfo)\n        lines = repr_entry.lines\n        assert lines[0] == \"    def func1():\"\n        assert lines[1] == '>       raise ValueError(\"hello\\\\nworld\")'\n        assert lines[2] == \"E       ValueError: hello\"\n        assert lines[3] == \"E       world\"\n        assert not lines[4:]\n\n        loc = repr_entry.reprfileloc\n        assert loc is not None\n        assert loc.path == mod.__file__\n        assert loc.lineno == 3\n        # assert loc.message == \"ValueError: hello\"\n\n    def test_repr_tracebackentry_lines2(self, importasmod, tw_mock) -> None:\n        mod = importasmod(\n            \"\"\"\n            def func1(m, x, y, z):\n                raise ValueError(\"hello\\\\nworld\")\n        \"\"\"\n        )\n        excinfo = pytest.raises(ValueError, mod.func1, \"m\" * 90, 5, 13, \"z\" * 120)\n        excinfo.traceback = excinfo.traceback.filter(excinfo)\n        entry = excinfo.traceback[-1]\n        p = FormattedExcinfo(funcargs=True)\n        reprfuncargs = p.repr_args(entry)\n        assert reprfuncargs is not None\n        assert reprfuncargs.args[0] == (\"m\", repr(\"m\" * 90))\n        assert reprfuncargs.args[1] == (\"x\", \"5\")\n        assert reprfuncarg"}], "retrieved_count": 10, "cost_time": 0.3484055995941162}
{"question": "Where does the MockTiming.patch method's delegation to monkeypatch.setattr establish the interception points for timing module functions, and what is the relationship between the three separate setattr calls in terms of their execution order and potential side effects on the timing module's state?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"start_line": 2000, "end_line": 3065, "belongs_to": {"file_name": "timing.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": " _pytest.timing with a known object that can be used to control timing in tests\n    deterministically.\n\n    pytest itself should always use functions from `_pytest.timing` instead of `time` directly.\n\n    This then allows us more control over time during testing, if testing code also\n    uses `_pytest.timing` functions.\n\n    Time is static, and only advances through `sleep` calls, thus tests might sleep over large\n    numbers and obtain accurate time() calls at the end, making tests reliable and instant.\"\"\"\n\n    _current_time: float = datetime(2020, 5, 22, 14, 20, 50).timestamp()\n\n    def sleep(self, seconds: float) -> None:\n        self._current_time += seconds\n\n    def time(self) -> float:\n        return self._current_time\n\n    def patch(self, monkeypatch: MonkeyPatch) -> None:\n        from _pytest import timing  # noqa: PLW0406\n\n        monkeypatch.setattr(timing, \"sleep\", self.sleep)\n        monkeypatch.setattr(timing, \"time\", self.time)\n        monkeypatch.setattr(timing, \"perf_counter\", self.time)\n\n\n__all__ = [\"perf_counter\", \"sleep\", \"time\"]\n"}, {"start_line": 6000, "end_line": 7567, "belongs_to": {"file_name": "conftest.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "       \"\"\"Straightforward replacement of color names to their ASCII codes.\"\"\"\n            return [line.format(**cls.COLORS) for line in lines]\n\n        @classmethod\n        def format_for_fnmatch(cls, lines: list[str]) -> list[str]:\n            \"\"\"Replace color names for use with LineMatcher.fnmatch_lines\"\"\"\n            return [line.format(**cls.COLORS).replace(\"[\", \"[[]\") for line in lines]\n\n        @classmethod\n        def format_for_rematch(cls, lines: list[str]) -> list[str]:\n            \"\"\"Replace color names for use with LineMatcher.re_match_lines\"\"\"\n            return [line.format(**cls.RE_COLORS) for line in lines]\n\n        @classmethod\n        def strip_colors(cls, lines: list[str]) -> list[str]:\n            \"\"\"Entirely remove every color code\"\"\"\n            return [line.format(**cls.NO_COLORS) for line in lines]\n\n    return ColorMapping\n\n\n@pytest.fixture\ndef mock_timing(monkeypatch: MonkeyPatch):\n    \"\"\"Mocks _pytest.timing with a known object that can be used to control timing in tests\n    deterministically.\n\n    pytest itself should always use functions from `_pytest.timing` instead of `time` directly.\n\n    This then allows us more control over time during testing, if testing code also\n    uses `_pytest.timing` functions.\n\n    Time is static, and only advances through `sleep` calls, thus tests might sleep over large\n    numbers and obtain accurate time() calls at the end, making tests reliable and instant.\n    \"\"\"\n    from _pytest.timing import MockTiming\n\n    result = MockTiming()\n    result.patch(monkeypatch)\n    return result\n"}, {"start_line": 1000, "end_line": 3000, "belongs_to": {"file_name": "timing.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "it=False)\n\n    # Performance counter tick of the instant, used to measure precise elapsed time.\n    # Note: using a `lambda` to correctly get the mocked time via `MockTiming`.\n    perf_count: float = dataclasses.field(\n        default_factory=lambda: perf_counter(), init=False\n    )\n\n    def elapsed(self) -> Duration:\n        \"\"\"Measure the duration since `Instant` was created.\"\"\"\n        return Duration(start=self, stop=Instant())\n\n    def as_utc(self) -> datetime:\n        \"\"\"Instant as UTC datetime.\"\"\"\n        return datetime.fromtimestamp(self.time, timezone.utc)\n\n\n@dataclasses.dataclass(frozen=True)\nclass Duration:\n    \"\"\"A span of time as measured by `Instant.elapsed()`.\"\"\"\n\n    start: Instant\n    stop: Instant\n\n    @property\n    def seconds(self) -> float:\n        \"\"\"Elapsed time of the duration in seconds, measured using a performance counter for precise timing.\"\"\"\n        return self.stop.perf_count - self.start.perf_count\n\n\n@dataclasses.dataclass\nclass MockTiming:\n    \"\"\"Mocks _pytest.timing with a known object that can be used to control timing in tests\n    deterministically.\n\n    pytest itself should always use functions from `_pytest.timing` instead of `time` directly.\n\n    This then allows us more control over time during testing, if testing code also\n    uses `_pytest.timing` functions.\n\n    Time is static, and only advances through `sleep` calls, thus tests might sleep over large\n    numbers and obtain accurate time() calls at the end, making tests reliable and instant.\"\"\"\n\n    _current_time: float = datetime(2020, 5, 22, 14, 20, 50).timestamp()\n\n    def sleep(self, seconds: float) -> None:\n        self._current_time += seconds\n\n    def time(self) -> float:\n        return self._current_time\n\n    def patch(self, monkeypatch: MonkeyPatch) -> None:\n        from _pytest import timing  # noqa: PLW0406\n\n        monkeypatch.setattr(timing, \"sleep\", self.sleep)\n        monkeypatch.setattr(timing, \"time\", self.time)\n        monkeypatch.setattr(timing, \"perf_co"}, {"start_line": 0, "end_line": 2000, "belongs_to": {"file_name": "timing.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "\"\"\"Indirection for time functions.\n\nWe intentionally grab some \"time\" functions internally to avoid tests mocking \"time\" to affect\npytest runtime information (issue #185).\n\nFixture \"mock_timing\" also interacts with this module for pytest's own tests.\n\"\"\"\n\nfrom __future__ import annotations\n\nimport dataclasses\nfrom datetime import datetime\nfrom datetime import timezone\nfrom time import perf_counter\nfrom time import sleep\nfrom time import time\nfrom typing import TYPE_CHECKING\n\n\nif TYPE_CHECKING:\n    from pytest import MonkeyPatch\n\n\n@dataclasses.dataclass(frozen=True)\nclass Instant:\n    \"\"\"\n    Represents an instant in time, used to both get the timestamp value and to measure\n    the duration of a time span.\n\n    Inspired by Rust's `std::time::Instant`.\n    \"\"\"\n\n    # Creation time of this instant, using time.time(), to measure actual time.\n    # Note: using a `lambda` to correctly get the mocked time via `MockTiming`.\n    time: float = dataclasses.field(default_factory=lambda: time(), init=False)\n\n    # Performance counter tick of the instant, used to measure precise elapsed time.\n    # Note: using a `lambda` to correctly get the mocked time via `MockTiming`.\n    perf_count: float = dataclasses.field(\n        default_factory=lambda: perf_counter(), init=False\n    )\n\n    def elapsed(self) -> Duration:\n        \"\"\"Measure the duration since `Instant` was created.\"\"\"\n        return Duration(start=self, stop=Instant())\n\n    def as_utc(self) -> datetime:\n        \"\"\"Instant as UTC datetime.\"\"\"\n        return datetime.fromtimestamp(self.time, timezone.utc)\n\n\n@dataclasses.dataclass(frozen=True)\nclass Duration:\n    \"\"\"A span of time as measured by `Instant.elapsed()`.\"\"\"\n\n    start: Instant\n    stop: Instant\n\n    @property\n    def seconds(self) -> float:\n        \"\"\"Elapsed time of the duration in seconds, measured using a performance counter for precise timing.\"\"\"\n        return self.stop.perf_count - self.start.perf_count\n\n\n@dataclasses.dataclass\nclass MockTiming:\n    \"\"\"Mocks"}, {"start_line": 4000, "end_line": 6000, "belongs_to": {"file_name": "monkeypatch.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "o call\n        :meth:`undo` explicitly.\n    \"\"\"\n\n    def __init__(self) -> None:\n        self._setattr: list[tuple[object, str, object]] = []\n        self._setitem: list[tuple[Mapping[Any, Any], object, object]] = []\n        self._cwd: str | None = None\n        self._savesyspath: list[str] | None = None\n\n    @classmethod\n    @contextmanager\n    def context(cls) -> Generator[MonkeyPatch]:\n        \"\"\"Context manager that returns a new :class:`MonkeyPatch` object\n        which undoes any patching done inside the ``with`` block upon exit.\n\n        Example:\n\n        .. code-block:: python\n\n            import functools\n\n\n            def test_partial(monkeypatch):\n                with monkeypatch.context() as m:\n                    m.setattr(functools, \"partial\", 3)\n\n        Useful in situations where it is desired to undo some patches before the test ends,\n        such as mocking ``stdlib`` functions that might break pytest itself if mocked (for examples\n        of this see :issue:`3290`).\n        \"\"\"\n        m = cls()\n        try:\n            yield m\n        finally:\n            m.undo()\n\n    @overload\n    def setattr(\n        self,\n        target: str,\n        name: object,\n        value: Notset = ...,\n        raising: bool = ...,\n    ) -> None: ...\n\n    @overload\n    def setattr(\n        self,\n        target: object,\n        name: str,\n        value: object,\n        raising: bool = ...,\n    ) -> None: ...\n\n    def setattr(\n        self,\n        target: str | object,\n        name: object | str,\n        value: object = notset,\n        raising: bool = True,\n    ) -> None:\n        \"\"\"\n        Set attribute value on target, memorizing the old value.\n\n        For example:\n\n        .. code-block:: python\n\n            import os\n\n            monkeypatch.setattr(os, \"getcwd\", lambda: \"/\")\n\n        The code above replaces the :func:`os.getcwd` function by a ``lambda`` which\n        always returns ``\"/\"``.\n\n        For convenience, you can specify a string as ``target`` which\n    "}, {"start_line": 1000, "end_line": 3000, "belongs_to": {"file_name": "monkeypatch.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "th:`monkeypatch.setitem(mapping, name, value) <pytest.MonkeyPatch.setitem>`\n    * :meth:`monkeypatch.delitem(obj, name, raising=True) <pytest.MonkeyPatch.delitem>`\n    * :meth:`monkeypatch.setenv(name, value, prepend=None) <pytest.MonkeyPatch.setenv>`\n    * :meth:`monkeypatch.delenv(name, raising=True) <pytest.MonkeyPatch.delenv>`\n    * :meth:`monkeypatch.syspath_prepend(path) <pytest.MonkeyPatch.syspath_prepend>`\n    * :meth:`monkeypatch.chdir(path) <pytest.MonkeyPatch.chdir>`\n    * :meth:`monkeypatch.context() <pytest.MonkeyPatch.context>`\n\n    All modifications will be undone after the requesting test function or\n    fixture has finished. The ``raising`` parameter determines if a :class:`KeyError`\n    or :class:`AttributeError` will be raised if the set/deletion operation does not have the\n    specified target.\n\n    To undo modifications done by the fixture in a contained scope,\n    use :meth:`context() <pytest.MonkeyPatch.context>`.\n    \"\"\"\n    mpatch = MonkeyPatch()\n    yield mpatch\n    mpatch.undo()\n\n\ndef resolve(name: str) -> object:\n    # Simplified from zope.dottedname.\n    parts = name.split(\".\")\n\n    used = parts.pop(0)\n    found: object = __import__(used)\n    for part in parts:\n        used += \".\" + part\n        try:\n            found = getattr(found, part)\n        except AttributeError:\n            pass\n        else:\n            continue\n        # We use explicit un-nesting of the handling block in order\n        # to avoid nested exceptions.\n        try:\n            __import__(used)\n        except ImportError as ex:\n            expected = str(ex).split()[-1]\n            if expected == used:\n                raise\n            else:\n                raise ImportError(f\"import error in {used}: {ex}\") from ex\n        found = annotated_getattr(found, part, used)\n    return found\n\n\ndef annotated_getattr(obj: object, name: str, ann: str) -> object:\n    try:\n        obj = getattr(obj, name)\n    except AttributeError as e:\n        raise AttributeError(\n           "}, {"start_line": 0, "end_line": 2000, "belongs_to": {"file_name": "test_monkeypatch.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "# mypy: allow-untyped-defs\nfrom __future__ import annotations\n\nfrom collections.abc import Generator\nimport os\nfrom pathlib import Path\nimport re\nimport sys\nimport textwrap\n\nimport setuptools\n\nfrom _pytest.monkeypatch import MonkeyPatch\nfrom _pytest.pytester import Pytester\nimport pytest\n\n\n@pytest.fixture\ndef mp() -> Generator[MonkeyPatch]:\n    cwd = os.getcwd()\n    sys_path = list(sys.path)\n    yield MonkeyPatch()\n    sys.path[:] = sys_path\n    os.chdir(cwd)\n\n\ndef test_setattr() -> None:\n    class A:\n        x = 1\n\n    monkeypatch = MonkeyPatch()\n    pytest.raises(AttributeError, monkeypatch.setattr, A, \"notexists\", 2)\n    monkeypatch.setattr(A, \"y\", 2, raising=False)\n    assert A.y == 2  # type: ignore\n    monkeypatch.undo()\n    assert not hasattr(A, \"y\")\n\n    monkeypatch = MonkeyPatch()\n    monkeypatch.setattr(A, \"x\", 2)\n    assert A.x == 2\n    monkeypatch.setattr(A, \"x\", 3)\n    assert A.x == 3\n    monkeypatch.undo()\n    assert A.x == 1\n\n    A.x = 5\n    monkeypatch.undo()  # double-undo makes no modification\n    assert A.x == 5\n\n    with pytest.raises(TypeError):\n        monkeypatch.setattr(A, \"y\")  # type: ignore[call-overload]\n\n\nclass TestSetattrWithImportPath:\n    def test_string_expression(self, monkeypatch: MonkeyPatch) -> None:\n        with monkeypatch.context() as mp:\n            mp.setattr(\"os.path.abspath\", lambda x: \"hello2\")\n            assert os.path.abspath(\"123\") == \"hello2\"\n\n    def test_string_expression_class(self, monkeypatch: MonkeyPatch) -> None:\n        with monkeypatch.context() as mp:\n            mp.setattr(\"_pytest.config.Config\", 42)\n            import _pytest\n\n            assert _pytest.config.Config == 42  # type: ignore\n\n    def test_unicode_string(self, monkeypatch: MonkeyPatch) -> None:\n        with monkeypatch.context() as mp:\n            mp.setattr(\"_pytest.config.Config\", 42)\n            import _pytest\n\n            assert _pytest.config.Config == 42  # type: ignore\n            mp.delattr(\"_pytest.config.Config\")\n\n    def test_wron"}, {"start_line": 0, "end_line": 2000, "belongs_to": {"file_name": "monkeypatch.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "# mypy: allow-untyped-defs\n\"\"\"Monkeypatching and mocking functionality.\"\"\"\n\nfrom __future__ import annotations\n\nfrom collections.abc import Generator\nfrom collections.abc import Mapping\nfrom collections.abc import MutableMapping\nfrom contextlib import contextmanager\nimport os\nimport re\nimport sys\nfrom typing import Any\nfrom typing import final\nfrom typing import overload\nfrom typing import TypeVar\nimport warnings\n\nfrom _pytest.fixtures import fixture\nfrom _pytest.warning_types import PytestWarning\n\n\nRE_IMPORT_ERROR_NAME = re.compile(r\"^No module named (.*)$\")\n\n\nK = TypeVar(\"K\")\nV = TypeVar(\"V\")\n\n\n@fixture\ndef monkeypatch() -> Generator[MonkeyPatch]:\n    \"\"\"A convenient fixture for monkey-patching.\n\n    The fixture provides these methods to modify objects, dictionaries, or\n    :data:`os.environ`:\n\n    * :meth:`monkeypatch.setattr(obj, name, value, raising=True) <pytest.MonkeyPatch.setattr>`\n    * :meth:`monkeypatch.delattr(obj, name, raising=True) <pytest.MonkeyPatch.delattr>`\n    * :meth:`monkeypatch.setitem(mapping, name, value) <pytest.MonkeyPatch.setitem>`\n    * :meth:`monkeypatch.delitem(obj, name, raising=True) <pytest.MonkeyPatch.delitem>`\n    * :meth:`monkeypatch.setenv(name, value, prepend=None) <pytest.MonkeyPatch.setenv>`\n    * :meth:`monkeypatch.delenv(name, raising=True) <pytest.MonkeyPatch.delenv>`\n    * :meth:`monkeypatch.syspath_prepend(path) <pytest.MonkeyPatch.syspath_prepend>`\n    * :meth:`monkeypatch.chdir(path) <pytest.MonkeyPatch.chdir>`\n    * :meth:`monkeypatch.context() <pytest.MonkeyPatch.context>`\n\n    All modifications will be undone after the requesting test function or\n    fixture has finished. The ``raising`` parameter determines if a :class:`KeyError`\n    or :class:`AttributeError` will be raised if the set/deletion operation does not have the\n    specified target.\n\n    To undo modifications done by the fixture in a contained scope,\n    use :meth:`context() <pytest.MonkeyPatch.context>`.\n    \"\"\"\n    mpatch = MonkeyPatch()\n    yield mpat"}, {"start_line": 8000, "end_line": 10000, "belongs_to": {"file_name": "test_monkeypatch.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "ef test_chdir_with_path_local(mp: MonkeyPatch, tmp_path: Path) -> None:\n    mp.chdir(tmp_path)\n    assert os.getcwd() == str(tmp_path)\n\n\ndef test_chdir_with_str(mp: MonkeyPatch, tmp_path: Path) -> None:\n    mp.chdir(str(tmp_path))\n    assert os.getcwd() == str(tmp_path)\n\n\ndef test_chdir_undo(mp: MonkeyPatch, tmp_path: Path) -> None:\n    cwd = os.getcwd()\n    mp.chdir(tmp_path)\n    mp.undo()\n    assert os.getcwd() == cwd\n\n\ndef test_chdir_double_undo(mp: MonkeyPatch, tmp_path: Path) -> None:\n    mp.chdir(str(tmp_path))\n    mp.undo()\n    os.chdir(tmp_path)\n    mp.undo()\n    assert os.getcwd() == str(tmp_path)\n\n\ndef test_issue185_time_breaks(pytester: Pytester) -> None:\n    pytester.makepyfile(\n        \"\"\"\n        import time\n        def test_m(monkeypatch):\n            def f():\n                raise Exception\n            monkeypatch.setattr(time, \"time\", f)\n    \"\"\"\n    )\n    result = pytester.runpytest()\n    result.stdout.fnmatch_lines(\n        \"\"\"\n        *1 passed*\n    \"\"\"\n    )\n\n\ndef test_importerror(pytester: Pytester) -> None:\n    p = pytester.mkpydir(\"package\")\n    p.joinpath(\"a.py\").write_text(\n        textwrap.dedent(\n            \"\"\"\\\n        import doesnotexist\n\n        x = 1\n    \"\"\"\n        ),\n        encoding=\"utf-8\",\n    )\n    pytester.path.joinpath(\"test_importerror.py\").write_text(\n        textwrap.dedent(\n            \"\"\"\\\n        def test_importerror(monkeypatch):\n            monkeypatch.setattr('package.a.x', 2)\n    \"\"\"\n        ),\n        encoding=\"utf-8\",\n    )\n    result = pytester.runpytest()\n    result.stdout.fnmatch_lines(\n        \"\"\"\n        *import error in package.a: No module named 'doesnotexist'*\n    \"\"\"\n    )\n\n\nclass Sample:\n    @staticmethod\n    def hello() -> bool:\n        return True\n\n\nclass SampleInherit(Sample):\n    pass\n\n\n@pytest.mark.parametrize(\n    \"Sample\",\n    [Sample, SampleInherit],\n    ids=[\"new\", \"new-inherit\"],\n)\ndef test_issue156_undo_staticmethod(Sample: type[Sample]) -> None:\n    monkeypatch = MonkeyPatch()\n\n    monkeypatch"}, {"start_line": 1000, "end_line": 3000, "belongs_to": {"file_name": "test_monkeypatch.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "undo makes no modification\n    assert A.x == 5\n\n    with pytest.raises(TypeError):\n        monkeypatch.setattr(A, \"y\")  # type: ignore[call-overload]\n\n\nclass TestSetattrWithImportPath:\n    def test_string_expression(self, monkeypatch: MonkeyPatch) -> None:\n        with monkeypatch.context() as mp:\n            mp.setattr(\"os.path.abspath\", lambda x: \"hello2\")\n            assert os.path.abspath(\"123\") == \"hello2\"\n\n    def test_string_expression_class(self, monkeypatch: MonkeyPatch) -> None:\n        with monkeypatch.context() as mp:\n            mp.setattr(\"_pytest.config.Config\", 42)\n            import _pytest\n\n            assert _pytest.config.Config == 42  # type: ignore\n\n    def test_unicode_string(self, monkeypatch: MonkeyPatch) -> None:\n        with monkeypatch.context() as mp:\n            mp.setattr(\"_pytest.config.Config\", 42)\n            import _pytest\n\n            assert _pytest.config.Config == 42  # type: ignore\n            mp.delattr(\"_pytest.config.Config\")\n\n    def test_wrong_target(self, monkeypatch: MonkeyPatch) -> None:\n        with pytest.raises(TypeError):\n            monkeypatch.setattr(None, None)  # type: ignore[call-overload]\n\n    def test_unknown_import(self, monkeypatch: MonkeyPatch) -> None:\n        with pytest.raises(ImportError):\n            monkeypatch.setattr(\"unkn123.classx\", None)\n\n    def test_unknown_attr(self, monkeypatch: MonkeyPatch) -> None:\n        with pytest.raises(AttributeError):\n            monkeypatch.setattr(\"os.path.qweqwe\", None)\n\n    def test_unknown_attr_non_raising(self, monkeypatch: MonkeyPatch) -> None:\n        # https://github.com/pytest-dev/pytest/issues/746\n        with monkeypatch.context() as mp:\n            mp.setattr(\"os.path.qweqwe\", 42, raising=False)\n            assert os.path.qweqwe == 42  # type: ignore\n\n    def test_delattr(self, monkeypatch: MonkeyPatch) -> None:\n        with monkeypatch.context() as mp:\n            mp.delattr(\"os.path.abspath\")\n            assert not hasattr(os.path, \"abspath\")\n       "}], "retrieved_count": 10, "cost_time": 0.3558831214904785}
{"question": "Where is the subprocess execution mechanism that `pytester.runpytest_subprocess` delegates to, and how does it handle system exception propagation during test collection?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"start_line": 50000, "end_line": 52000, "belongs_to": {"file_name": "pytester.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "r:\n            print(f\"couldn't print to {fp} because of encoding\")\n\n    def _getpytestargs(self) -> tuple[str, ...]:\n        return sys.executable, \"-mpytest\"\n\n    def runpython(self, script: os.PathLike[str]) -> RunResult:\n        \"\"\"Run a python script using sys.executable as interpreter.\"\"\"\n        return self.run(sys.executable, script)\n\n    def runpython_c(self, command: str) -> RunResult:\n        \"\"\"Run ``python -c \"command\"``.\"\"\"\n        return self.run(sys.executable, \"-c\", command)\n\n    def runpytest_subprocess(\n        self, *args: str | os.PathLike[str], timeout: float | None = None\n    ) -> RunResult:\n        \"\"\"Run pytest as a subprocess with given arguments.\n\n        Any plugins added to the :py:attr:`plugins` list will be added using the\n        ``-p`` command line option.  Additionally ``--basetemp`` is used to put\n        any temporary files and directories in a numbered directory prefixed\n        with \"runpytest-\" to not conflict with the normal numbered pytest\n        location for temporary files and directories.\n\n        :param args:\n            The sequence of arguments to pass to the pytest subprocess.\n        :param timeout:\n            The period in seconds after which to timeout and raise\n            :py:class:`Pytester.TimeoutExpired`.\n        :returns:\n            The result.\n        \"\"\"\n        __tracebackhide__ = True\n        p = make_numbered_dir(root=self.path, prefix=\"runpytest-\", mode=0o700)\n        args = (f\"--basetemp={p}\", *args)\n        for plugin in self.plugins:\n            if not isinstance(plugin, str):\n                raise ValueError(\n                    f\"Specifying plugins as objects is not supported in pytester subprocess mode; \"\n                    f\"specify by name instead: {plugin}\"\n                )\n            args = (\"-p\", plugin, *args)\n        args = self._getpytestargs() + args\n        return self.run(*args, timeout=timeout)\n\n    def spawn_pytest(self, string: str, expect_timeout: float = 10.0) -> pexpect.spawn"}, {"start_line": 40000, "end_line": 42000, "belongs_to": {"file_name": "pytester.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": " sys.stderr.write(err)\n\n        assert reprec.ret is not None\n        res = RunResult(\n            reprec.ret, out.splitlines(), err.splitlines(), instant.elapsed().seconds\n        )\n        res.reprec = reprec  # type: ignore\n        return res\n\n    def runpytest(self, *args: str | os.PathLike[str], **kwargs: Any) -> RunResult:\n        \"\"\"Run pytest inline or in a subprocess, depending on the command line\n        option \"--runpytest\" and return a :py:class:`~pytest.RunResult`.\"\"\"\n        new_args = self._ensure_basetemp(args)\n        if self._method == \"inprocess\":\n            return self.runpytest_inprocess(*new_args, **kwargs)\n        elif self._method == \"subprocess\":\n            return self.runpytest_subprocess(*new_args, **kwargs)\n        raise RuntimeError(f\"Unrecognized runpytest option: {self._method}\")\n\n    def _ensure_basetemp(\n        self, args: Sequence[str | os.PathLike[str]]\n    ) -> list[str | os.PathLike[str]]:\n        new_args = list(args)\n        for x in new_args:\n            if str(x).startswith(\"--basetemp\"):\n                break\n        else:\n            new_args.append(\n                \"--basetemp={}\".format(self.path.parent.joinpath(\"basetemp\"))\n            )\n        return new_args\n\n    def parseconfig(self, *args: str | os.PathLike[str]) -> Config:\n        \"\"\"Return a new pytest :class:`pytest.Config` instance from given\n        commandline args.\n\n        This invokes the pytest bootstrapping code in _pytest.config to create a\n        new :py:class:`pytest.PytestPluginManager` and call the\n        :hook:`pytest_cmdline_parse` hook to create a new :class:`pytest.Config`\n        instance.\n\n        If :attr:`plugins` has been populated they should be plugin modules\n        to be registered with the plugin manager.\n        \"\"\"\n        import _pytest.config\n\n        new_args = [str(x) for x in self._ensure_basetemp(args)]\n\n        config = _pytest.config._prepareconfig(new_args, self.plugins)\n        # we don't know what the test will do with"}, {"start_line": 39000, "end_line": 41000, "belongs_to": {"file_name": "pytester.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "sult of running pytest in-process, providing a similar\n        interface to what self.runpytest() provides.\"\"\"\n        syspathinsert = kwargs.pop(\"syspathinsert\", False)\n\n        if syspathinsert:\n            self.syspathinsert()\n        instant = timing.Instant()\n        capture = _get_multicapture(\"sys\")\n        capture.start_capturing()\n        try:\n            try:\n                reprec = self.inline_run(*args, **kwargs)\n            except SystemExit as e:\n                ret = e.args[0]\n                try:\n                    ret = ExitCode(e.args[0])\n                except ValueError:\n                    pass\n\n                class reprec:  # type: ignore\n                    ret = ret\n\n            except Exception:\n                traceback.print_exc()\n\n                class reprec:  # type: ignore\n                    ret = ExitCode(3)\n\n        finally:\n            out, err = capture.readouterr()\n            capture.stop_capturing()\n            sys.stdout.write(out)\n            sys.stderr.write(err)\n\n        assert reprec.ret is not None\n        res = RunResult(\n            reprec.ret, out.splitlines(), err.splitlines(), instant.elapsed().seconds\n        )\n        res.reprec = reprec  # type: ignore\n        return res\n\n    def runpytest(self, *args: str | os.PathLike[str], **kwargs: Any) -> RunResult:\n        \"\"\"Run pytest inline or in a subprocess, depending on the command line\n        option \"--runpytest\" and return a :py:class:`~pytest.RunResult`.\"\"\"\n        new_args = self._ensure_basetemp(args)\n        if self._method == \"inprocess\":\n            return self.runpytest_inprocess(*new_args, **kwargs)\n        elif self._method == \"subprocess\":\n            return self.runpytest_subprocess(*new_args, **kwargs)\n        raise RuntimeError(f\"Unrecognized runpytest option: {self._method}\")\n\n    def _ensure_basetemp(\n        self, args: Sequence[str | os.PathLike[str]]\n    ) -> list[str | os.PathLike[str]]:\n        new_args = list(args)\n        for x in new_args:\n"}, {"start_line": 15000, "end_line": 17000, "belongs_to": {"file_name": "test_runner.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "h SystemExit\"\n        rep = reports[1]\n        assert rep.failed\n        assert rep.when == \"call\"\n\n    def test_exit_propagates(self, pytester: Pytester) -> None:\n        try:\n            pytester.runitem(\n                \"\"\"\n                import pytest\n                def test_func():\n                    raise pytest.exit.Exception()\n            \"\"\"\n            )\n        except pytest.exit.Exception:\n            pass\n        else:\n            assert False, \"did not raise\"\n\n\nclass TestExecutionNonForked(BaseFunctionalTests):\n    def getrunner(self):\n        def f(item):\n            return runner.runtestprotocol(item, log=False)\n\n        return f\n\n    def test_keyboardinterrupt_propagates(self, pytester: Pytester) -> None:\n        try:\n            pytester.runitem(\n                \"\"\"\n                def test_func():\n                    raise KeyboardInterrupt(\"fake\")\n            \"\"\"\n            )\n        except KeyboardInterrupt:\n            pass\n        else:\n            assert False, \"did not raise\"\n\n\nclass TestSessionReports:\n    def test_collect_result(self, pytester: Pytester) -> None:\n        col = pytester.getmodulecol(\n            \"\"\"\n            def test_func1():\n                pass\n            class TestClass(object):\n                pass\n        \"\"\"\n        )\n        rep = runner.collect_one_node(col)\n        assert not rep.failed\n        assert not rep.skipped\n        assert rep.passed\n        locinfo = rep.location\n        assert locinfo is not None\n        assert locinfo[0] == col.path.name\n        assert not locinfo[1]\n        assert locinfo[2] == col.path.name\n        res = rep.result\n        assert len(res) == 2\n        assert res[0].name == \"test_func1\"\n        assert res[1].name == \"TestClass\"\n\n\nreporttypes: list[type[reports.BaseReport]] = [\n    reports.BaseReport,\n    reports.TestReport,\n    reports.CollectReport,\n]\n\n\n@pytest.mark.parametrize(\n    \"reporttype\", reporttypes, ids=[x.__name__ for x in reporttypes]\n)\ndef test_report_extra_parame"}, {"start_line": 14000, "end_line": 16000, "belongs_to": {"file_name": "test_runner.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "epr_failure(self, excinfo):\n                    assert 0\n        \"\"\"\n        )\n        reports = pytester.runitem(\n            \"\"\"\n            def setup_function(func):\n                raise ValueError(42)\n            def test_func():\n                pass\n        \"\"\"\n        )\n        assert len(reports) == 2\n        rep = reports[0]\n        print(rep)\n        assert not rep.skipped\n        assert not rep.passed\n        assert rep.failed\n        # assert rep.outcome.when == \"setup\"\n        # assert rep.outcome.where.lineno == 3\n        # assert rep.outcome.where.path.basename == \"test_func.py\"\n        # assert isinstance(rep.failed.failurerepr, PythonFailureRepr)\n\n    def test_systemexit_does_not_bail_out(self, pytester: Pytester) -> None:\n        try:\n            reports = pytester.runitem(\n                \"\"\"\n                def test_func():\n                    raise SystemExit(42)\n            \"\"\"\n            )\n        except SystemExit:\n            assert False, \"runner did not catch SystemExit\"\n        rep = reports[1]\n        assert rep.failed\n        assert rep.when == \"call\"\n\n    def test_exit_propagates(self, pytester: Pytester) -> None:\n        try:\n            pytester.runitem(\n                \"\"\"\n                import pytest\n                def test_func():\n                    raise pytest.exit.Exception()\n            \"\"\"\n            )\n        except pytest.exit.Exception:\n            pass\n        else:\n            assert False, \"did not raise\"\n\n\nclass TestExecutionNonForked(BaseFunctionalTests):\n    def getrunner(self):\n        def f(item):\n            return runner.runtestprotocol(item, log=False)\n\n        return f\n\n    def test_keyboardinterrupt_propagates(self, pytester: Pytester) -> None:\n        try:\n            pytester.runitem(\n                \"\"\"\n                def test_func():\n                    raise KeyboardInterrupt(\"fake\")\n            \"\"\"\n            )\n        except KeyboardInterrupt:\n            pass\n        else:\n            assert Fal"}, {"start_line": 49000, "end_line": 51000, "belongs_to": {"file_name": "pytester.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "_ = True\n\n                timeout_message = f\"{timeout} second timeout expired running: {cmdargs}\"\n\n                popen.kill()\n                popen.wait()\n                raise self.TimeoutExpired(timeout_message)\n\n            if timeout is None:\n                ret = popen.wait()\n            else:\n                try:\n                    ret = popen.wait(timeout)\n                except subprocess.TimeoutExpired:\n                    handle_timeout()\n\n        with p1.open(encoding=\"utf8\") as f1, p2.open(encoding=\"utf8\") as f2:\n            out = f1.read().splitlines()\n            err = f2.read().splitlines()\n\n        self._dump_lines(out, sys.stdout)\n        self._dump_lines(err, sys.stderr)\n\n        with contextlib.suppress(ValueError):\n            ret = ExitCode(ret)\n        return RunResult(ret, out, err, instant.elapsed().seconds)\n\n    def _dump_lines(self, lines, fp):\n        try:\n            for line in lines:\n                print(line, file=fp)\n        except UnicodeEncodeError:\n            print(f\"couldn't print to {fp} because of encoding\")\n\n    def _getpytestargs(self) -> tuple[str, ...]:\n        return sys.executable, \"-mpytest\"\n\n    def runpython(self, script: os.PathLike[str]) -> RunResult:\n        \"\"\"Run a python script using sys.executable as interpreter.\"\"\"\n        return self.run(sys.executable, script)\n\n    def runpython_c(self, command: str) -> RunResult:\n        \"\"\"Run ``python -c \"command\"``.\"\"\"\n        return self.run(sys.executable, \"-c\", command)\n\n    def runpytest_subprocess(\n        self, *args: str | os.PathLike[str], timeout: float | None = None\n    ) -> RunResult:\n        \"\"\"Run pytest as a subprocess with given arguments.\n\n        Any plugins added to the :py:attr:`plugins` list will be added using the\n        ``-p`` command line option.  Additionally ``--basetemp`` is used to put\n        any temporary files and directories in a numbered directory prefixed\n        with \"runpytest-\" to not conflict with the normal numbered pytest\n     "}, {"start_line": 34000, "end_line": 36000, "belongs_to": {"file_name": "collect.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing/python", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "_sub1\"\n            def pytest_runtest_call(item):\n                assert item.path.stem == \"test_in_sub1\"\n            def pytest_runtest_teardown(item):\n                assert item.path.stem == \"test_in_sub1\"\n            \"\"\"\n        ),\n        encoding=\"utf-8\",\n    )\n    sub2.joinpath(\"conftest.py\").write_text(\n        textwrap.dedent(\n            \"\"\"\\\n            import pytest\n            def pytest_runtest_setup(item):\n                assert item.path.stem == \"test_in_sub2\"\n            def pytest_runtest_call(item):\n                assert item.path.stem == \"test_in_sub2\"\n            def pytest_runtest_teardown(item):\n                assert item.path.stem == \"test_in_sub2\"\n            \"\"\"\n        ),\n        encoding=\"utf-8\",\n    )\n    sub1.joinpath(\"test_in_sub1.py\").write_text(\"def test_1(): pass\", encoding=\"utf-8\")\n    sub2.joinpath(\"test_in_sub2.py\").write_text(\"def test_2(): pass\", encoding=\"utf-8\")\n    result = pytester.runpytest(\"-v\", \"-s\")\n    result.assert_outcomes(passed=2)\n\n\ndef test_modulecol_roundtrip(pytester: Pytester) -> None:\n    modcol = pytester.getmodulecol(\"pass\", withinit=False)\n    trail = modcol.nodeid\n    newcol = modcol.session.perform_collect([trail], genitems=0)[0]\n    assert modcol.name == newcol.name\n\n\nclass TestTracebackCutting:\n    def test_skip_simple(self):\n        with pytest.raises(pytest.skip.Exception) as excinfo:\n            pytest.skip(\"xxx\")\n        if sys.version_info >= (3, 11):\n            assert excinfo.traceback[-1].frame.code.raw.co_qualname == \"_Skip.__call__\"\n        assert excinfo.traceback[-1].ishidden(excinfo)\n        assert excinfo.traceback[-2].frame.code.name == \"test_skip_simple\"\n        assert not excinfo.traceback[-2].ishidden(excinfo)\n\n    def test_traceback_argsetup(self, pytester: Pytester) -> None:\n        pytester.makeconftest(\n            \"\"\"\n            import pytest\n\n            @pytest.fixture\n            def hello(request):\n                raise ValueError(\"xyz\")\n        \"\"\"\n        )\n        p = py"}, {"start_line": 54000, "end_line": 56000, "belongs_to": {"file_name": "acceptance_test.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "ent directory to PYTHONPATH which avoids\n        # the bug. We also use pytest rather than python -m pytest for the same\n        # PYTHONPATH reason.\n        subprocess.run(\n            [\"pytest\", \"my_package\"],\n            capture_output=True,\n            check=True,\n            encoding=\"utf-8\",\n            text=True,\n        )\n    except subprocess.CalledProcessError as exc:\n        raise AssertionError(\n            f\"pytest command failed:\\n{exc.stdout=!s}\\n{exc.stderr=!s}\"\n        ) from exc\n\n\ndef test_no_terminal_plugin(pytester: Pytester) -> None:\n    \"\"\"Smoke test to ensure pytest can execute without the terminal plugin (#9422).\"\"\"\n    pytester.makepyfile(\"def test(): assert 1 == 2\")\n    result = pytester.runpytest(\"-pno:terminal\", \"-s\")\n    assert result.ret == ExitCode.TESTS_FAILED\n\n\ndef test_stop_iteration_from_collect(pytester: Pytester) -> None:\n    pytester.makepyfile(test_it=\"raise StopIteration('hello')\")\n    result = pytester.runpytest()\n    assert result.ret == ExitCode.INTERRUPTED\n    result.assert_outcomes(failed=0, passed=0, errors=1)\n    result.stdout.fnmatch_lines(\n        [\n            \"=* short test summary info =*\",\n            \"ERROR test_it.py - StopIteration: hello\",\n            \"!* Interrupted: 1 error during collection !*\",\n            \"=* 1 error in * =*\",\n        ]\n    )\n\n\ndef test_stop_iteration_runtest_protocol(pytester: Pytester) -> None:\n    pytester.makepyfile(\n        test_it=\"\"\"\n        import pytest\n        @pytest.fixture\n        def fail_setup():\n            raise StopIteration(1)\n        def test_fail_setup(fail_setup):\n            pass\n        def test_fail_teardown(request):\n            def stop_iteration():\n                raise StopIteration(2)\n            request.addfinalizer(stop_iteration)\n        def test_fail_call():\n            raise StopIteration(3)\n        \"\"\"\n    )\n    result = pytester.runpytest()\n    assert result.ret == ExitCode.TESTS_FAILED\n    result.assert_outcomes(failed=1, passed=1, errors=2)\n    resul"}, {"start_line": 23000, "end_line": 25000, "belongs_to": {"file_name": "test_pytester.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "epyfile(\n                \"\"\"\n                import sys\n                print(sys.stdin.read())  # empty\n                print('stdout')\n                sys.stderr.write('stderr')\n                \"\"\"\n            )\n            proc = pytester.popen([sys.executable, str(p1)], stdin=None)\n            stdout, stderr = proc.communicate(b\"ignored\")\n            assert stdout.splitlines() == [b\"\", b\"stdout\"]\n            assert stderr.splitlines() == [b\"stderr\"]\n            assert proc.returncode == 0\n        '''\n    )\n    result = pytester.runpytest(\"-p\", \"pytester\", str(p1))\n    assert result.ret == 0\n\n\ndef test_spawn_uses_tmphome(pytester: Pytester) -> None:\n    tmphome = str(pytester.path)\n    assert os.environ.get(\"HOME\") == tmphome\n\n    pytester._monkeypatch.setenv(\"CUSTOMENV\", \"42\")\n\n    p1 = pytester.makepyfile(\n        f\"\"\"\n        import os\n\n        def test():\n            assert os.environ[\"HOME\"] == {tmphome!r}\n            assert os.environ[\"CUSTOMENV\"] == \"42\"\n        \"\"\"\n    )\n    child = pytester.spawn_pytest(str(p1))\n    out = child.read()\n    assert child.wait() == 0, out.decode(\"utf8\")\n\n\ndef test_run_result_repr() -> None:\n    outlines = [\"some\", \"normal\", \"output\"]\n    errlines = [\"some\", \"nasty\", \"errors\", \"happened\"]\n\n    # known exit code\n    r = pytester_mod.RunResult(1, outlines, errlines, duration=0.5)\n    assert repr(r) == (\n        f\"<RunResult ret={pytest.ExitCode.TESTS_FAILED!s} len(stdout.lines)=3\"\n        \" len(stderr.lines)=4 duration=0.50s>\"\n    )\n\n    # unknown exit code: just the number\n    r = pytester_mod.RunResult(99, outlines, errlines, duration=0.5)\n    assert (\n        repr(r) == \"<RunResult ret=99 len(stdout.lines)=3\"\n        \" len(stderr.lines)=4 duration=0.50s>\"\n    )\n\n\ndef test_pytester_outcomes_with_multiple_errors(pytester: Pytester) -> None:\n    p1 = pytester.makepyfile(\n        \"\"\"\n        import pytest\n\n        @pytest.fixture\n        def bad_fixture():\n            raise Exception(\"bad\")\n\n        def test_error1(bad_fixture):"}, {"start_line": 35000, "end_line": 37000, "belongs_to": {"file_name": "pytester.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "  values = [*list(cmdlineargs), p]\n        return self.inline_run(*values)\n\n    def inline_genitems(self, *args) -> tuple[list[Item], HookRecorder]:\n        \"\"\"Run ``pytest.main(['--collect-only'])`` in-process.\n\n        Runs the :py:func:`pytest.main` function to run all of pytest inside\n        the test process itself like :py:meth:`inline_run`, but returns a\n        tuple of the collected items and a :py:class:`HookRecorder` instance.\n        \"\"\"\n        rec = self.inline_run(\"--collect-only\", *args)\n        items = [x.item for x in rec.getcalls(\"pytest_itemcollected\")]\n        return items, rec\n\n    def inline_run(\n        self,\n        *args: str | os.PathLike[str],\n        plugins=(),\n        no_reraise_ctrlc: bool = False,\n    ) -> HookRecorder:\n        \"\"\"Run ``pytest.main()`` in-process, returning a HookRecorder.\n\n        Runs the :py:func:`pytest.main` function to run all of pytest inside\n        the test process itself.  This means it can return a\n        :py:class:`HookRecorder` instance which gives more detailed results\n        from that run than can be done by matching stdout/stderr from\n        :py:meth:`runpytest`.\n\n        :param args:\n            Command line arguments to pass to :py:func:`pytest.main`.\n        :param plugins:\n            Extra plugin instances the ``pytest.main()`` instance should use.\n        :param no_reraise_ctrlc:\n            Typically we reraise keyboard interrupts from the child run. If\n            True, the KeyboardInterrupt exception is captured.\n        \"\"\"\n        from _pytest.unraisableexception import gc_collect_iterations_key\n\n        # (maybe a cpython bug?) the importlib cache sometimes isn't updated\n        # properly between file creation and inline_run (especially if imports\n        # are interspersed with file creation)\n        importlib.invalidate_caches()\n\n        plugins = list(plugins)\n        finalizers = []\n        try:\n            # Any sys.module or sys.path changes done while running pytest\n            "}], "retrieved_count": 10, "cost_time": 0.35352134704589844}
{"question": "Where does the `_marked_for_rewrite_cache` dictionary control the data flow through `_is_marked_for_rewrite` to prevent redundant module rewrite decisions across multiple import attempts?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"start_line": 8000, "end_line": 10000, "belongs_to": {"file_name": "rewrite.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest/assertion", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": " subdirectories (\"tests/**.py\" for example) we can't bail out based\n            # on the name alone because we need to match against the full path\n            if os.path.dirname(pat):\n                return False\n            if fnmatch_ex(pat, path):\n                return False\n\n        if self._is_marked_for_rewrite(name, state):\n            return False\n\n        state.trace(f\"early skip of rewriting module: {name}\")\n        return True\n\n    def _should_rewrite(self, name: str, fn: str, state: AssertionState) -> bool:\n        # always rewrite conftest files\n        if os.path.basename(fn) == \"conftest.py\":\n            state.trace(f\"rewriting conftest file: {fn!r}\")\n            return True\n\n        if self.session is not None:\n            if self.session.isinitpath(absolutepath(fn)):\n                state.trace(f\"matched test file (was specified on cmdline): {fn!r}\")\n                return True\n\n        # modules not passed explicitly on the command line are only\n        # rewritten if they match the naming convention for test files\n        fn_path = PurePath(fn)\n        for pat in self.fnpats:\n            if fnmatch_ex(pat, fn_path):\n                state.trace(f\"matched test file {fn!r}\")\n                return True\n\n        return self._is_marked_for_rewrite(name, state)\n\n    def _is_marked_for_rewrite(self, name: str, state: AssertionState) -> bool:\n        try:\n            return self._marked_for_rewrite_cache[name]\n        except KeyError:\n            for marked in self._must_rewrite:\n                if name == marked or name.startswith(marked + \".\"):\n                    state.trace(f\"matched marked file {name!r} (from {marked!r})\")\n                    self._marked_for_rewrite_cache[name] = True\n                    return True\n\n            self._marked_for_rewrite_cache[name] = False\n            return False\n\n    def mark_rewrite(self, *names: str) -> None:\n        \"\"\"Mark import names as needing to be rewritten.\n\n        The named module or package as well a"}, {"start_line": 9000, "end_line": 11000, "belongs_to": {"file_name": "rewrite.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest/assertion", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "f they match the naming convention for test files\n        fn_path = PurePath(fn)\n        for pat in self.fnpats:\n            if fnmatch_ex(pat, fn_path):\n                state.trace(f\"matched test file {fn!r}\")\n                return True\n\n        return self._is_marked_for_rewrite(name, state)\n\n    def _is_marked_for_rewrite(self, name: str, state: AssertionState) -> bool:\n        try:\n            return self._marked_for_rewrite_cache[name]\n        except KeyError:\n            for marked in self._must_rewrite:\n                if name == marked or name.startswith(marked + \".\"):\n                    state.trace(f\"matched marked file {name!r} (from {marked!r})\")\n                    self._marked_for_rewrite_cache[name] = True\n                    return True\n\n            self._marked_for_rewrite_cache[name] = False\n            return False\n\n    def mark_rewrite(self, *names: str) -> None:\n        \"\"\"Mark import names as needing to be rewritten.\n\n        The named module or package as well as any nested modules will\n        be rewritten on import.\n        \"\"\"\n        already_imported = (\n            set(names).intersection(sys.modules).difference(self._rewritten_names)\n        )\n        for name in already_imported:\n            mod = sys.modules[name]\n            if not AssertionRewriter.is_rewrite_disabled(\n                mod.__doc__ or \"\"\n            ) and not isinstance(mod.__loader__, type(self)):\n                self._warn_already_imported(name)\n        self._must_rewrite.update(names)\n        self._marked_for_rewrite_cache.clear()\n\n    def _warn_already_imported(self, name: str) -> None:\n        from _pytest.warning_types import PytestAssertRewriteWarning\n\n        self.config.issue_config_time_warning(\n            PytestAssertRewriteWarning(\n                f\"Module already imported so cannot be rewritten; {name}\"\n            ),\n            stacklevel=5,\n        )\n\n    def get_data(self, pathname: str | bytes) -> bytes:\n        \"\"\"Optional PEP302 get_data API.\"\"\"\n "}, {"start_line": 5000, "end_line": 7000, "belongs_to": {"file_name": "rewrite.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest/assertion", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": " = Path(module.__spec__.origin)\n        state = self.config.stash[assertstate_key]\n\n        self._rewritten_names[module.__name__] = fn\n\n        # The requested module looks like a test file, so rewrite it. This is\n        # the most magical part of the process: load the source, rewrite the\n        # asserts, and load the rewritten source. We also cache the rewritten\n        # module code in a special pyc. We must be aware of the possibility of\n        # concurrent pytest processes rewriting and loading pycs. To avoid\n        # tricky race conditions, we maintain the following invariant: The\n        # cached pyc is always a complete, valid pyc. Operations on it must be\n        # atomic. POSIX's atomic rename comes in handy.\n        write = not sys.dont_write_bytecode\n        cache_dir = get_cache_dir(fn)\n        if write:\n            ok = try_makedirs(cache_dir)\n            if not ok:\n                write = False\n                state.trace(f\"read only directory: {cache_dir}\")\n\n        cache_name = fn.name[:-3] + PYC_TAIL\n        pyc = cache_dir / cache_name\n        # Notice that even if we're in a read-only directory, I'm going\n        # to check for a cached pyc. This may not be optimal...\n        co = _read_pyc(fn, pyc, state.trace)\n        if co is None:\n            state.trace(f\"rewriting {fn!r}\")\n            source_stat, co = _rewrite_test(fn, self.config)\n            if write:\n                self._writing_pyc = True\n                try:\n                    _write_pyc(state, co, source_stat, pyc)\n                finally:\n                    self._writing_pyc = False\n        else:\n            state.trace(f\"found cached rewritten pyc for {fn}\")\n        exec(co, module.__dict__)\n\n    def _early_rewrite_bailout(self, name: str, state: AssertionState) -> bool:\n        \"\"\"A fast way to get out of rewriting modules.\n\n        Profiling has shown that the call to PathFinder.find_spec (inside of\n        the find_spec from this class) is a major slowdown, so, this meth"}, {"start_line": 6000, "end_line": 8000, "belongs_to": {"file_name": "rewrite.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest/assertion", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "  cache_name = fn.name[:-3] + PYC_TAIL\n        pyc = cache_dir / cache_name\n        # Notice that even if we're in a read-only directory, I'm going\n        # to check for a cached pyc. This may not be optimal...\n        co = _read_pyc(fn, pyc, state.trace)\n        if co is None:\n            state.trace(f\"rewriting {fn!r}\")\n            source_stat, co = _rewrite_test(fn, self.config)\n            if write:\n                self._writing_pyc = True\n                try:\n                    _write_pyc(state, co, source_stat, pyc)\n                finally:\n                    self._writing_pyc = False\n        else:\n            state.trace(f\"found cached rewritten pyc for {fn}\")\n        exec(co, module.__dict__)\n\n    def _early_rewrite_bailout(self, name: str, state: AssertionState) -> bool:\n        \"\"\"A fast way to get out of rewriting modules.\n\n        Profiling has shown that the call to PathFinder.find_spec (inside of\n        the find_spec from this class) is a major slowdown, so, this method\n        tries to filter what we're sure won't be rewritten before getting to\n        it.\n        \"\"\"\n        if self.session is not None and not self._session_paths_checked:\n            self._session_paths_checked = True\n            for initial_path in self.session._initialpaths:\n                # Make something as c:/projects/my_project/path.py ->\n                #     ['c:', 'projects', 'my_project', 'path.py']\n                parts = str(initial_path).split(os.sep)\n                # add 'path' to basenames to be checked.\n                self._basenames_to_check_rewrite.add(os.path.splitext(parts[-1])[0])\n\n        # Note: conftest already by default in _basenames_to_check_rewrite.\n        parts = name.split(\".\")\n        if parts[-1] in self._basenames_to_check_rewrite:\n            return False\n\n        # For matching the name it must be as if it was a filename.\n        path = PurePath(*parts).with_suffix(\".py\")\n\n        for pat in self.fnpats:\n            # if the pattern contains"}, {"start_line": 10000, "end_line": 12000, "belongs_to": {"file_name": "rewrite.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest/assertion", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "s any nested modules will\n        be rewritten on import.\n        \"\"\"\n        already_imported = (\n            set(names).intersection(sys.modules).difference(self._rewritten_names)\n        )\n        for name in already_imported:\n            mod = sys.modules[name]\n            if not AssertionRewriter.is_rewrite_disabled(\n                mod.__doc__ or \"\"\n            ) and not isinstance(mod.__loader__, type(self)):\n                self._warn_already_imported(name)\n        self._must_rewrite.update(names)\n        self._marked_for_rewrite_cache.clear()\n\n    def _warn_already_imported(self, name: str) -> None:\n        from _pytest.warning_types import PytestAssertRewriteWarning\n\n        self.config.issue_config_time_warning(\n            PytestAssertRewriteWarning(\n                f\"Module already imported so cannot be rewritten; {name}\"\n            ),\n            stacklevel=5,\n        )\n\n    def get_data(self, pathname: str | bytes) -> bytes:\n        \"\"\"Optional PEP302 get_data API.\"\"\"\n        with open(pathname, \"rb\") as f:\n            return f.read()\n\n    if sys.version_info >= (3, 10):\n        if sys.version_info >= (3, 12):\n            from importlib.resources.abc import TraversableResources\n        else:\n            from importlib.abc import TraversableResources\n\n        def get_resource_reader(self, name: str) -> TraversableResources:\n            if sys.version_info < (3, 11):\n                from importlib.readers import FileReader\n            else:\n                from importlib.resources.readers import FileReader\n\n            return FileReader(types.SimpleNamespace(path=self._rewritten_names[name]))\n\n\ndef _write_pyc_fp(\n    fp: IO[bytes], source_stat: os.stat_result, co: types.CodeType\n) -> None:\n    # Technically, we don't have to have the same pyc format as\n    # (C)Python, since these \"pycs\" should never be seen by builtin\n    # import. However, there's little reason to deviate.\n    fp.write(importlib.util.MAGIC_NUMBER)\n    # https://www.python.org/dev/pep"}, {"start_line": 2000, "end_line": 4000, "belongs_to": {"file_name": "rewrite.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest/assertion", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "\n        self.session: Session | None = None\n        self._rewritten_names: dict[str, Path] = {}\n        self._must_rewrite: set[str] = set()\n        # flag to guard against trying to rewrite a pyc file while we are already writing another pyc file,\n        # which might result in infinite recursion (#3506)\n        self._writing_pyc = False\n        self._basenames_to_check_rewrite = {\"conftest\"}\n        self._marked_for_rewrite_cache: dict[str, bool] = {}\n        self._session_paths_checked = False\n\n    def set_session(self, session: Session | None) -> None:\n        self.session = session\n        self._session_paths_checked = False\n\n    # Indirection so we can mock calls to find_spec originated from the hook during testing\n    _find_spec = importlib.machinery.PathFinder.find_spec\n\n    def find_spec(\n        self,\n        name: str,\n        path: Sequence[str | bytes] | None = None,\n        target: types.ModuleType | None = None,\n    ) -> importlib.machinery.ModuleSpec | None:\n        if self._writing_pyc:\n            return None\n        state = self.config.stash[assertstate_key]\n        if self._early_rewrite_bailout(name, state):\n            return None\n        state.trace(f\"find_module called for: {name}\")\n\n        # Type ignored because mypy is confused about the `self` binding here.\n        spec = self._find_spec(name, path)  # type: ignore\n\n        if spec is None and path is not None:\n            # With --import-mode=importlib, PathFinder cannot find spec without modifying `sys.path`,\n            # causing inability to assert rewriting (#12659).\n            # At this point, try using the file path to find the module spec.\n            for _path_str in path:\n                spec = importlib.util.spec_from_file_location(name, _path_str)\n                if spec is not None:\n                    break\n\n        if (\n            # the import machinery could not find a file to import\n            spec is None\n            # this is a namespace package (without `__init__."}, {"start_line": 35000, "end_line": 37000, "belongs_to": {"file_name": "test_assertrewrite.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "      pytester.makeconftest(\n            \"\"\"\n            import pytest\n            pytest.register_assert_rewrite(\"_pytest\")\n        \"\"\"\n        )\n        # needs to be a subprocess because pytester explicitly disables this warning\n        result = pytester.runpytest_subprocess()\n        result.stdout.fnmatch_lines([\"*Module already imported*; _pytest\"])\n\n    def test_rewrite_warning_ignore(self, pytester: Pytester) -> None:\n        pytester.makeconftest(\n            \"\"\"\n            import pytest\n            pytest.register_assert_rewrite(\"_pytest\")\n        \"\"\"\n        )\n        # needs to be a subprocess because pytester explicitly disables this warning\n        result = pytester.runpytest_subprocess(\n            \"-W\",\n            \"ignore:Module already imported so cannot be rewritten; _pytest:pytest.PytestAssertRewriteWarning\",\n        )\n        # Previously, when the message pattern used to contain an extra `:`, an error was raised.\n        assert not result.stderr.str().strip()\n        result.stdout.no_fnmatch_line(\"*Module already imported*; _pytest\")\n\n    def test_rewrite_module_imported_from_conftest(self, pytester: Pytester) -> None:\n        pytester.makeconftest(\n            \"\"\"\n            import test_rewrite_module_imported\n        \"\"\"\n        )\n        pytester.makepyfile(\n            test_rewrite_module_imported=\"\"\"\n            def test_rewritten():\n                assert \"@py_builtins\" in globals()\n        \"\"\"\n        )\n        assert pytester.runpytest_subprocess().ret == 0\n\n    def test_remember_rewritten_modules(\n        self, pytestconfig, pytester: Pytester, monkeypatch\n    ) -> None:\n        \"\"\"`AssertionRewriteHook` should remember rewritten modules so it\n        doesn't give false positives (#2005).\"\"\"\n        monkeypatch.syspath_prepend(pytester.path)\n        pytester.makepyfile(test_remember_rewritten_modules=\"\")\n        warnings = []\n        hook = AssertionRewritingHook(pytestconfig)\n        monkeypatch.setattr(\n            hook, \"_warn_alre"}, {"start_line": 36000, "end_line": 38000, "belongs_to": {"file_name": "test_assertrewrite.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "    result.stdout.no_fnmatch_line(\"*Module already imported*; _pytest\")\n\n    def test_rewrite_module_imported_from_conftest(self, pytester: Pytester) -> None:\n        pytester.makeconftest(\n            \"\"\"\n            import test_rewrite_module_imported\n        \"\"\"\n        )\n        pytester.makepyfile(\n            test_rewrite_module_imported=\"\"\"\n            def test_rewritten():\n                assert \"@py_builtins\" in globals()\n        \"\"\"\n        )\n        assert pytester.runpytest_subprocess().ret == 0\n\n    def test_remember_rewritten_modules(\n        self, pytestconfig, pytester: Pytester, monkeypatch\n    ) -> None:\n        \"\"\"`AssertionRewriteHook` should remember rewritten modules so it\n        doesn't give false positives (#2005).\"\"\"\n        monkeypatch.syspath_prepend(pytester.path)\n        pytester.makepyfile(test_remember_rewritten_modules=\"\")\n        warnings = []\n        hook = AssertionRewritingHook(pytestconfig)\n        monkeypatch.setattr(\n            hook, \"_warn_already_imported\", lambda code, msg: warnings.append(msg)\n        )\n        spec = hook.find_spec(\"test_remember_rewritten_modules\")\n        assert spec is not None\n        module = importlib.util.module_from_spec(spec)\n        hook.exec_module(module)\n        hook.mark_rewrite(\"test_remember_rewritten_modules\")\n        hook.mark_rewrite(\"test_remember_rewritten_modules\")\n        assert warnings == []\n\n    def test_rewrite_warning_using_pytest_plugins(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            **{\n                \"conftest.py\": \"pytest_plugins = ['core', 'gui', 'sci']\",\n                \"core.py\": \"\",\n                \"gui.py\": \"pytest_plugins = ['core', 'sci']\",\n                \"sci.py\": \"pytest_plugins = ['core']\",\n                \"test_rewrite_warning_pytest_plugins.py\": \"def test(): pass\",\n            }\n        )\n        pytester.chdir()\n        result = pytester.runpytest_subprocess()\n        result.stdout.fnmatch_lines([\"*= 1 passed in *=*\"])\n        re"}, {"start_line": 4000, "end_line": 6000, "belongs_to": {"file_name": "rewrite.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest/assertion", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "py`)\n            # there's nothing to rewrite there\n            or spec.origin is None\n            # we can only rewrite source files\n            or not isinstance(spec.loader, importlib.machinery.SourceFileLoader)\n            # if the file doesn't exist, we can't rewrite it\n            or not os.path.exists(spec.origin)\n        ):\n            return None\n        else:\n            fn = spec.origin\n\n        if not self._should_rewrite(name, fn, state):\n            return None\n\n        return importlib.util.spec_from_file_location(\n            name,\n            fn,\n            loader=self,\n            submodule_search_locations=spec.submodule_search_locations,\n        )\n\n    def create_module(\n        self, spec: importlib.machinery.ModuleSpec\n    ) -> types.ModuleType | None:\n        return None  # default behaviour is fine\n\n    def exec_module(self, module: types.ModuleType) -> None:\n        assert module.__spec__ is not None\n        assert module.__spec__.origin is not None\n        fn = Path(module.__spec__.origin)\n        state = self.config.stash[assertstate_key]\n\n        self._rewritten_names[module.__name__] = fn\n\n        # The requested module looks like a test file, so rewrite it. This is\n        # the most magical part of the process: load the source, rewrite the\n        # asserts, and load the rewritten source. We also cache the rewritten\n        # module code in a special pyc. We must be aware of the possibility of\n        # concurrent pytest processes rewriting and loading pycs. To avoid\n        # tricky race conditions, we maintain the following invariant: The\n        # cached pyc is always a complete, valid pyc. Operations on it must be\n        # atomic. POSIX's atomic rename comes in handy.\n        write = not sys.dont_write_bytecode\n        cache_dir = get_cache_dir(fn)\n        if write:\n            ok = try_makedirs(cache_dir)\n            if not ok:\n                write = False\n                state.trace(f\"read only directory: {cache_dir}\")\n\n      "}, {"start_line": 7000, "end_line": 9000, "belongs_to": {"file_name": "rewrite.py", "upper_path": "/data2/raymone/swebench-repos/pytest/src/_pytest/assertion", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "od\n        tries to filter what we're sure won't be rewritten before getting to\n        it.\n        \"\"\"\n        if self.session is not None and not self._session_paths_checked:\n            self._session_paths_checked = True\n            for initial_path in self.session._initialpaths:\n                # Make something as c:/projects/my_project/path.py ->\n                #     ['c:', 'projects', 'my_project', 'path.py']\n                parts = str(initial_path).split(os.sep)\n                # add 'path' to basenames to be checked.\n                self._basenames_to_check_rewrite.add(os.path.splitext(parts[-1])[0])\n\n        # Note: conftest already by default in _basenames_to_check_rewrite.\n        parts = name.split(\".\")\n        if parts[-1] in self._basenames_to_check_rewrite:\n            return False\n\n        # For matching the name it must be as if it was a filename.\n        path = PurePath(*parts).with_suffix(\".py\")\n\n        for pat in self.fnpats:\n            # if the pattern contains subdirectories (\"tests/**.py\" for example) we can't bail out based\n            # on the name alone because we need to match against the full path\n            if os.path.dirname(pat):\n                return False\n            if fnmatch_ex(pat, path):\n                return False\n\n        if self._is_marked_for_rewrite(name, state):\n            return False\n\n        state.trace(f\"early skip of rewriting module: {name}\")\n        return True\n\n    def _should_rewrite(self, name: str, fn: str, state: AssertionState) -> bool:\n        # always rewrite conftest files\n        if os.path.basename(fn) == \"conftest.py\":\n            state.trace(f\"rewriting conftest file: {fn!r}\")\n            return True\n\n        if self.session is not None:\n            if self.session.isinitpath(absolutepath(fn)):\n                state.trace(f\"matched test file (was specified on cmdline): {fn!r}\")\n                return True\n\n        # modules not passed explicitly on the command line are only\n        # rewritten i"}], "retrieved_count": 10, "cost_time": 0.42880964279174805}
{"question": "Where is the LocalPath class definition located that implements the comparison operators being tested in test_gt_with_strings, and how does its implementation enable mixed-type comparisons between path objects and strings?", "answer": "", "relative_code_list": null, "ground_truth": null, "score": null, "retrieved_content": [{"start_line": 21000, "end_line": 23000, "belongs_to": {"file_name": "test_local.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing/_py", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "ir.as_cwd() as x:\n            assert x == old\n            assert local() == dir\n        assert os.getcwd() == str(old)\n\n    def test_as_cwd_exception(self, path1):\n        old = local()\n        dir = path1.ensure(\"subdir\", dir=1)\n        with pytest.raises(ValueError):\n            with dir.as_cwd():\n                raise ValueError()\n        assert old == local()\n\n    def test_initialize_reldir(self, path1):\n        with path1.as_cwd():\n            p = local(\"samplefile\")\n            assert p.check()\n\n    def test_tilde_expansion(self, monkeypatch, tmpdir):\n        monkeypatch.setenv(\"HOME\", str(tmpdir))\n        p = local(\"~\", expanduser=True)\n        assert p == os.path.expanduser(\"~\")\n\n    @pytest.mark.skipif(\n        not sys.platform.startswith(\"win32\"), reason=\"case-insensitive only on windows\"\n    )\n    def test_eq_hash_are_case_insensitive_on_windows(self):\n        a = local(\"/some/path\")\n        b = local(\"/some/PATH\")\n        assert a == b\n        assert hash(a) == hash(b)\n        assert a in {b}\n        assert a in {b: \"b\"}\n\n    def test_eq_with_strings(self, path1):\n        path1 = path1.join(\"sampledir\")\n        path2 = str(path1)\n        assert path1 == path2\n        assert path2 == path1\n        path3 = path1.join(\"samplefile\")\n        assert path3 != path2\n        assert path2 != path3\n\n    def test_eq_with_none(self, path1):\n        assert path1 != None  # noqa: E711\n\n    def test_eq_non_ascii_unicode(self, path1):\n        path2 = path1.join(\"temp\")\n        path3 = path1.join(\"ao\")\n        path4 = path1.join(\"\")\n\n        assert path2 != path3\n        assert path2 != path4\n        assert path4 != path3\n\n    def test_gt_with_strings(self, path1):\n        path2 = path1.join(\"sampledir\")\n        path3 = str(path1.join(\"ttt\"))\n        assert path3 > path2\n        assert path2 < path3\n        assert path2 < \"ttt\"\n        assert \"ttt\" > path2\n        path4 = path1.join(\"aaa\")\n        lst = [path2, path4, path3]\n        assert sorted(lst) == [path4, p"}, {"start_line": 22000, "end_line": 24000, "belongs_to": {"file_name": "test_local.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing/_py", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "    assert a in {b}\n        assert a in {b: \"b\"}\n\n    def test_eq_with_strings(self, path1):\n        path1 = path1.join(\"sampledir\")\n        path2 = str(path1)\n        assert path1 == path2\n        assert path2 == path1\n        path3 = path1.join(\"samplefile\")\n        assert path3 != path2\n        assert path2 != path3\n\n    def test_eq_with_none(self, path1):\n        assert path1 != None  # noqa: E711\n\n    def test_eq_non_ascii_unicode(self, path1):\n        path2 = path1.join(\"temp\")\n        path3 = path1.join(\"ao\")\n        path4 = path1.join(\"\")\n\n        assert path2 != path3\n        assert path2 != path4\n        assert path4 != path3\n\n    def test_gt_with_strings(self, path1):\n        path2 = path1.join(\"sampledir\")\n        path3 = str(path1.join(\"ttt\"))\n        assert path3 > path2\n        assert path2 < path3\n        assert path2 < \"ttt\"\n        assert \"ttt\" > path2\n        path4 = path1.join(\"aaa\")\n        lst = [path2, path4, path3]\n        assert sorted(lst) == [path4, path2, path3]\n\n    def test_open_and_ensure(self, path1):\n        p = path1.join(\"sub1\", \"sub2\", \"file\")\n        with p.open(\"w\", ensure=1, encoding=\"utf-8\") as f:\n            f.write(\"hello\")\n        assert p.read_text(encoding=\"utf-8\") == \"hello\"\n\n    def test_write_and_ensure(self, path1):\n        p = path1.join(\"sub1\", \"sub2\", \"file\")\n        p.write_text(\"hello\", ensure=1, encoding=\"utf-8\")\n        assert p.read_text(encoding=\"utf-8\") == \"hello\"\n\n    @pytest.mark.parametrize(\"bin\", (False, True))\n    def test_dump(self, tmpdir, bin):\n        path = tmpdir.join(f\"dumpfile{int(bin)}\")\n        try:\n            d = {\"answer\": 42}\n            path.dump(d, bin=bin)\n            f = path.open(\"rb+\")\n            import pickle\n\n            dnew = pickle.load(f)\n            assert d == dnew\n        finally:\n            f.close()\n\n    def test_setmtime(self):\n        import tempfile\n\n        try:\n            fd, name = tempfile.mkstemp()\n            os.close(fd)\n        except AttributeError:\n"}, {"start_line": 18000, "end_line": 20000, "belongs_to": {"file_name": "test_local.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing/_py", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "ncoding='utf-8')) is {actual} instead of {i}\"\n        )\n        dir_.join(\".lock\").remove(ignore_errors=True)\n    return True\n\n\nclass TestLocalPath(CommonFSTests):\n    def test_join_normpath(self, tmpdir):\n        assert tmpdir.join(\".\") == tmpdir\n        p = tmpdir.join(f\"../{tmpdir.basename}\")\n        assert p == tmpdir\n        p = tmpdir.join(f\"..//{tmpdir.basename}/\")\n        assert p == tmpdir\n\n    @skiponwin32\n    def test_dirpath_abs_no_abs(self, tmpdir):\n        p = tmpdir.join(\"foo\")\n        assert p.dirpath(\"/bar\") == tmpdir.join(\"bar\")\n        assert tmpdir.dirpath(\"/bar\", abs=True) == local(\"/bar\")\n\n    def test_gethash(self, tmpdir):\n        from hashlib import md5\n        from hashlib import sha1 as sha\n\n        fn = tmpdir.join(\"testhashfile\")\n        data = b\"hello\"\n        fn.write(data, mode=\"wb\")\n        assert fn.computehash(\"md5\") == md5(data).hexdigest()\n        assert fn.computehash(\"sha1\") == sha(data).hexdigest()\n        with pytest.raises(ValueError):\n            fn.computehash(\"asdasd\")\n\n    def test_remove_removes_readonly_file(self, tmpdir):\n        readonly_file = tmpdir.join(\"readonly\").ensure()\n        readonly_file.chmod(0)\n        readonly_file.remove()\n        assert not readonly_file.check(exists=1)\n\n    def test_remove_removes_readonly_dir(self, tmpdir):\n        readonly_dir = tmpdir.join(\"readonlydir\").ensure(dir=1)\n        readonly_dir.chmod(int(\"500\", 8))\n        readonly_dir.remove()\n        assert not readonly_dir.check(exists=1)\n\n    def test_remove_removes_dir_and_readonly_file(self, tmpdir):\n        readonly_dir = tmpdir.join(\"readonlydir\").ensure(dir=1)\n        readonly_file = readonly_dir.join(\"readonlyfile\").ensure()\n        readonly_file.chmod(0)\n        readonly_dir.remove()\n        assert not readonly_dir.check(exists=1)\n\n    def test_remove_routes_ignore_errors(self, tmpdir, monkeypatch):\n        lst = []\n        monkeypatch.setattr(\"shutil.rmtree\", lambda *args, **kwargs: lst.append(kwargs))\n        tmpdir.remove("}, {"start_line": 41000, "end_line": 43000, "belongs_to": {"file_name": "test_local.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing/_py", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "p(rootdir=tmpdir)\n    assert tmpdir.listdir() == [dtmp]\n\n\nclass TestWINLocalPath:\n    pytestmark = win32only\n\n    def test_owner_group_not_implemented(self, path1):\n        with pytest.raises(NotImplementedError):\n            _ = path1.stat().owner\n        with pytest.raises(NotImplementedError):\n            _ = path1.stat().group\n\n    def test_chmod_simple_int(self, path1):\n        mode = path1.stat().mode\n        # Ensure that we actually change the mode to something different.\n        path1.chmod((mode == 0 and 1) or 0)\n        try:\n            print(path1.stat().mode)\n            print(mode)\n            assert path1.stat().mode != mode\n        finally:\n            path1.chmod(mode)\n            assert path1.stat().mode == mode\n\n    def test_path_comparison_lowercase_mixed(self, path1):\n        t1 = path1.join(\"a_path\")\n        t2 = path1.join(\"A_path\")\n        assert t1 == t1\n        assert t1 == t2\n\n    def test_relto_with_mixed_case(self, path1):\n        t1 = path1.join(\"a_path\", \"fiLe\")\n        t2 = path1.join(\"A_path\")\n        assert t1.relto(t2) == \"fiLe\"\n\n    def test_allow_unix_style_paths(self, path1):\n        t1 = path1.join(\"a_path\")\n        assert t1 == str(path1) + \"\\\\a_path\"\n        t1 = path1.join(\"a_path/\")\n        assert t1 == str(path1) + \"\\\\a_path\"\n        t1 = path1.join(\"dir/a_path\")\n        assert t1 == str(path1) + \"\\\\dir\\\\a_path\"\n\n    def test_sysfind_in_currentdir(self, path1):\n        cmd = local.sysfind(\"cmd\")\n        root = cmd.new(dirname=\"\", basename=\"\")  # c:\\ in most installations\n        with root.as_cwd():\n            x = local.sysfind(cmd.relto(root))\n            assert x.check(file=1)\n\n    def test_fnmatch_file_abspath_posix_pattern_on_win32(self, tmpdir):\n        # path-matching patterns might contain a posix path separator '/'\n        # Test that we can match that pattern on windows.\n        import posixpath\n\n        b = tmpdir.join(\"a\", \"b\")\n        assert b.fnmatch(posixpath.sep.join(\"ab\"))\n        pattern = posixpath.sep.jo"}, {"start_line": 17000, "end_line": 19000, "belongs_to": {"file_name": "test_local.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing/_py", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": " == 'win32' or getattr(os, '_name', None) == 'nt')\"\n)\nskiponwin32 = pytest.mark.skipif(\n    \"sys.platform == 'win32' or getattr(os, '_name', None) == 'nt'\"\n)\n\nATIME_RESOLUTION = 0.01\n\n\n@pytest.fixture(scope=\"session\")\ndef path1(tmpdir_factory):\n    path = tmpdir_factory.mktemp(\"path\")\n    setuptestfs(path)\n    yield path\n    assert path.join(\"samplefile\").check()\n\n\n@pytest.fixture\ndef fake_fspath_obj(request):\n    class FakeFSPathClass:\n        def __init__(self, path):\n            self._path = path\n\n        def __fspath__(self):\n            return self._path\n\n    return FakeFSPathClass(os.path.join(\"this\", \"is\", \"a\", \"fake\", \"path\"))\n\n\ndef batch_make_numbered_dirs(rootdir, repeats):\n    for i in range(repeats):\n        dir_ = local.make_numbered_dir(prefix=\"repro-\", rootdir=rootdir)\n        file_ = dir_.join(\"foo\")\n        file_.write_text(f\"{i}\", encoding=\"utf-8\")\n        actual = int(file_.read_text(encoding=\"utf-8\"))\n        assert actual == i, (\n            f\"int(file_.read_text(encoding='utf-8')) is {actual} instead of {i}\"\n        )\n        dir_.join(\".lock\").remove(ignore_errors=True)\n    return True\n\n\nclass TestLocalPath(CommonFSTests):\n    def test_join_normpath(self, tmpdir):\n        assert tmpdir.join(\".\") == tmpdir\n        p = tmpdir.join(f\"../{tmpdir.basename}\")\n        assert p == tmpdir\n        p = tmpdir.join(f\"..//{tmpdir.basename}/\")\n        assert p == tmpdir\n\n    @skiponwin32\n    def test_dirpath_abs_no_abs(self, tmpdir):\n        p = tmpdir.join(\"foo\")\n        assert p.dirpath(\"/bar\") == tmpdir.join(\"bar\")\n        assert tmpdir.dirpath(\"/bar\", abs=True) == local(\"/bar\")\n\n    def test_gethash(self, tmpdir):\n        from hashlib import md5\n        from hashlib import sha1 as sha\n\n        fn = tmpdir.join(\"testhashfile\")\n        data = b\"hello\"\n        fn.write(data, mode=\"wb\")\n        assert fn.computehash(\"md5\") == md5(data).hexdigest()\n        assert fn.computehash(\"sha1\") == sha(data).hexdigest()\n        with pytest.raises(ValueError):\n        "}, {"start_line": 40000, "end_line": 42000, "belongs_to": {"file_name": "test_local.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing/_py", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "mpdir.samefile(tmpdir)\n    p = tmpdir.ensure(\"hello\")\n    assert p.samefile(p)\n    with p.dirpath().as_cwd():\n        assert p.samefile(p.basename)\n    if sys.platform == \"win32\":\n        p1 = p.__class__(str(p).lower())\n        p2 = p.__class__(str(p).upper())\n        assert p1.samefile(p2)\n\n\n@pytest.mark.skipif(not hasattr(os, \"symlink\"), reason=\"os.symlink not available\")\ndef test_samefile_symlink(tmpdir):\n    p1 = tmpdir.ensure(\"foo.txt\")\n    p2 = tmpdir.join(\"linked.txt\")\n    try:\n        os.symlink(str(p1), str(p2))\n    except (OSError, NotImplementedError) as e:\n        # on Windows this might fail if the user doesn't have special symlink permissions\n        # pypy3 on Windows doesn't implement os.symlink and raises NotImplementedError\n        pytest.skip(str(e.args[0]))\n\n    assert p1.samefile(p2)\n\n\ndef test_listdir_single_arg(tmpdir):\n    tmpdir.ensure(\"hello\")\n    assert tmpdir.listdir(\"hello\")[0].basename == \"hello\"\n\n\ndef test_mkdtemp_rootdir(tmpdir):\n    dtmp = local.mkdtemp(rootdir=tmpdir)\n    assert tmpdir.listdir() == [dtmp]\n\n\nclass TestWINLocalPath:\n    pytestmark = win32only\n\n    def test_owner_group_not_implemented(self, path1):\n        with pytest.raises(NotImplementedError):\n            _ = path1.stat().owner\n        with pytest.raises(NotImplementedError):\n            _ = path1.stat().group\n\n    def test_chmod_simple_int(self, path1):\n        mode = path1.stat().mode\n        # Ensure that we actually change the mode to something different.\n        path1.chmod((mode == 0 and 1) or 0)\n        try:\n            print(path1.stat().mode)\n            print(mode)\n            assert path1.stat().mode != mode\n        finally:\n            path1.chmod(mode)\n            assert path1.stat().mode == mode\n\n    def test_path_comparison_lowercase_mixed(self, path1):\n        t1 = path1.join(\"a_path\")\n        t2 = path1.join(\"A_path\")\n        assert t1 == t1\n        assert t1 == t2\n\n    def test_relto_with_mixed_case(self, path1):\n        t1 = path1.join(\"a_path\", "}, {"start_line": 0, "end_line": 2000, "belongs_to": {"file_name": "test_local.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing/_py", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "# mypy: allow-untyped-defs\nfrom __future__ import annotations\n\nimport contextlib\nimport multiprocessing\nimport os\nimport sys\nimport time\nfrom unittest import mock\nimport warnings\n\nfrom py import error\nfrom py.path import local\n\nimport pytest\n\n\n@contextlib.contextmanager\ndef ignore_encoding_warning():\n    with warnings.catch_warnings():\n        if sys.version_info >= (3, 10):\n            warnings.simplefilter(\"ignore\", EncodingWarning)  # noqa: F821\n        yield\n\n\nclass CommonFSTests:\n    def test_constructor_equality(self, path1):\n        p = path1.__class__(path1)\n        assert p == path1\n\n    def test_eq_nonstring(self, path1):\n        p1 = path1.join(\"sampledir\")\n        p2 = path1.join(\"sampledir\")\n        assert p1 == p2\n\n    def test_new_identical(self, path1):\n        assert path1 == path1.new()\n\n    def test_join(self, path1):\n        p = path1.join(\"sampledir\")\n        strp = str(p)\n        assert strp.endswith(\"sampledir\")\n        assert strp.startswith(str(path1))\n\n    def test_join_normalized(self, path1):\n        newpath = path1.join(path1.sep + \"sampledir\")\n        strp = str(newpath)\n        assert strp.endswith(\"sampledir\")\n        assert strp.startswith(str(path1))\n        newpath = path1.join((path1.sep * 2) + \"sampledir\")\n        strp = str(newpath)\n        assert strp.endswith(\"sampledir\")\n        assert strp.startswith(str(path1))\n\n    def test_join_noargs(self, path1):\n        newpath = path1.join()\n        assert path1 == newpath\n\n    def test_add_something(self, path1):\n        p = path1.join(\"sample\")\n        p = p + \"dir\"\n        assert p.check()\n        assert p.exists()\n        assert p.isdir()\n        assert not p.isfile()\n\n    def test_parts(self, path1):\n        newpath = path1.join(\"sampledir\", \"otherfile\")\n        par = newpath.parts()[-3:]\n        assert par == [path1, path1.join(\"sampledir\"), newpath]\n\n        revpar = newpath.parts(reverse=True)[:3]\n        assert revpar == [newpath, path1.join(\"sampledir\"), path1]\n\n    def test"}, {"start_line": 7000, "end_line": 9000, "belongs_to": {"file_name": "test_local.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing/_py", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "ir\", pytest.mark.skip(\"sys.version_info < (3,6)\")(b\"*dir\")],\n    )\n    def test_visit_filterfunc_is_string(self, path1, fil):\n        lst = []\n        for i in path1.visit(fil):\n            lst.append(i.relto(path1))\n        assert len(lst), 2  # noqa: PLC1802,RUF040\n        assert \"sampledir\" in lst\n        assert \"otherdir\" in lst\n\n    def test_visit_ignore(self, path1):\n        p = path1.join(\"nonexisting\")\n        assert list(p.visit(ignore=error.ENOENT)) == []\n\n    def test_visit_endswith(self, path1):\n        p = []\n        for i in path1.visit(lambda x: x.check(endswith=\"file\")):\n            p.append(i.relto(path1))\n        assert path1.sep.join([\"sampledir\", \"otherfile\"]) in p\n        assert \"samplefile\" in p\n\n    def test_cmp(self, path1):\n        path1 = path1.join(\"samplefile\")\n        path2 = path1.join(\"samplefile2\")\n        assert (path1 < path2) == (\"samplefile\" < \"samplefile2\")\n        assert not (path1 < path1)\n\n    def test_simple_read(self, path1):\n        with ignore_encoding_warning():\n            x = path1.join(\"samplefile\").read(\"r\")\n        assert x == \"samplefile\\n\"\n\n    def test_join_div_operator(self, path1):\n        newpath = path1 / \"/sampledir\" / \"/test//\"\n        newpath2 = path1.join(\"sampledir\", \"test\")\n        assert newpath == newpath2\n\n    def test_ext(self, path1):\n        newpath = path1.join(\"sampledir.ext\")\n        assert newpath.ext == \".ext\"\n        newpath = path1.join(\"sampledir\")\n        assert not newpath.ext\n\n    def test_purebasename(self, path1):\n        newpath = path1.join(\"samplefile.py\")\n        assert newpath.purebasename == \"samplefile\"\n\n    def test_multiple_parts(self, path1):\n        newpath = path1.join(\"samplefile.py\")\n        dirname, purebasename, basename, ext = newpath._getbyspec(\n            \"dirname,purebasename,basename,ext\"\n        )\n        assert str(path1).endswith(dirname)  # be careful with win32 'drive'\n        assert purebasename == \"samplefile\"\n        assert basename == \"samplefile.py\"\n    "}, {"start_line": 20000, "end_line": 22000, "belongs_to": {"file_name": "test_local.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing/_py", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": ")\n        assert not lst[0][\"ignore_errors\"]\n        for val in (True, False):\n            lst[:] = []\n            tmpdir.remove(ignore_errors=val)\n            assert lst[0][\"ignore_errors\"] == val\n\n    def test_initialize_curdir(self):\n        assert str(local()) == os.getcwd()\n\n    @skiponwin32\n    def test_chdir_gone(self, path1):\n        p = path1.ensure(\"dir_to_be_removed\", dir=1)\n        p.chdir()\n        p.remove()\n        pytest.raises(error.ENOENT, local)\n        assert path1.chdir() is None\n        assert os.getcwd() == str(path1)\n\n        with pytest.raises(error.ENOENT):\n            with p.as_cwd():\n                raise NotImplementedError\n\n    @skiponwin32\n    def test_chdir_gone_in_as_cwd(self, path1):\n        p = path1.ensure(\"dir_to_be_removed\", dir=1)\n        p.chdir()\n        p.remove()\n\n        with path1.as_cwd() as old:\n            assert old is None\n\n    def test_as_cwd(self, path1):\n        dir = path1.ensure(\"subdir\", dir=1)\n        old = local()\n        with dir.as_cwd() as x:\n            assert x == old\n            assert local() == dir\n        assert os.getcwd() == str(old)\n\n    def test_as_cwd_exception(self, path1):\n        old = local()\n        dir = path1.ensure(\"subdir\", dir=1)\n        with pytest.raises(ValueError):\n            with dir.as_cwd():\n                raise ValueError()\n        assert old == local()\n\n    def test_initialize_reldir(self, path1):\n        with path1.as_cwd():\n            p = local(\"samplefile\")\n            assert p.check()\n\n    def test_tilde_expansion(self, monkeypatch, tmpdir):\n        monkeypatch.setenv(\"HOME\", str(tmpdir))\n        p = local(\"~\", expanduser=True)\n        assert p == os.path.expanduser(\"~\")\n\n    @pytest.mark.skipif(\n        not sys.platform.startswith(\"win32\"), reason=\"case-insensitive only on windows\"\n    )\n    def test_eq_hash_are_case_insensitive_on_windows(self):\n        a = local(\"/some/path\")\n        b = local(\"/some/PATH\")\n        assert a == b\n        assert hash(a) == hash(b)\n    "}, {"start_line": 24000, "end_line": 26000, "belongs_to": {"file_name": "test_local.py", "upper_path": "/data2/raymone/swebench-repos/pytest/testing/_py", "module": "", "define_class": [], "imports": []}, "relative_function": [], "code": "            name = tempfile.mktemp()\n            open(name, \"w\").close()\n        try:\n            # Do not use _pytest.timing here, as we do not want time mocking to affect this test.\n            mtime = int(time.time()) - 100\n            path = local(name)\n            assert path.mtime() != mtime\n            path.setmtime(mtime)\n            assert path.mtime() == mtime\n            path.setmtime()\n            assert path.mtime() != mtime\n        finally:\n            os.remove(name)\n\n    def test_normpath(self, path1):\n        new1 = path1.join(\"/otherdir\")\n        new2 = path1.join(\"otherdir\")\n        assert str(new1) == str(new2)\n\n    def test_mkdtemp_creation(self):\n        d = local.mkdtemp()\n        try:\n            assert d.check(dir=1)\n        finally:\n            d.remove(rec=1)\n\n    def test_tmproot(self):\n        d = local.mkdtemp()\n        tmproot = local.get_temproot()\n        try:\n            assert d.check(dir=1)\n            assert d.dirpath() == tmproot\n        finally:\n            d.remove(rec=1)\n\n    def test_chdir(self, tmpdir):\n        old = local()\n        try:\n            res = tmpdir.chdir()\n            assert str(res) == str(old)\n            assert os.getcwd() == str(tmpdir)\n        finally:\n            old.chdir()\n\n    def test_ensure_filepath_withdir(self, tmpdir):\n        newfile = tmpdir.join(\"test1\", \"test\")\n        newfile.ensure()\n        assert newfile.check(file=1)\n        newfile.write_text(\"42\", encoding=\"utf-8\")\n        newfile.ensure()\n        s = newfile.read_text(encoding=\"utf-8\")\n        assert s == \"42\"\n\n    def test_ensure_filepath_withoutdir(self, tmpdir):\n        newfile = tmpdir.join(\"test1file\")\n        t = newfile.ensure()\n        assert t == newfile\n        assert newfile.check(file=1)\n\n    def test_ensure_dirpath(self, tmpdir):\n        newfile = tmpdir.join(\"test1\", \"testfile\")\n        t = newfile.ensure(dir=1)\n        assert t == newfile\n        assert newfile.check(dir=1)\n\n    def test_ensure_non_ascii_unicode(self, t"}], "retrieved_count": 10, "cost_time": 0.5481863021850586}
